{"uid": "id_803", "premise": "some time on the night of October 1st, the Copacabana Club was burnt to the ground. The police are treating the fire as suspicious. The only facts known at this stage are: The club was insured for more than its real value. The club belonged to John Hodges. Les Braithwaite was known to dislike John Hodges. Between October 1st and October 2nd, Les Braithwaite was away from home on a business trip. There were no fatalities. A plan of the club was found in Les Braithwaite's flat.", "hypothesis": "If the insurance company pays out in full, John Hodges stands to profit from the fire.", "gold_label": "neutral"}
{"uid": "id_0", "premise": "This passage provides information on the subsidising of renewable energy and its effect on the usage of fossil fuels. The issue of subsidising sources of renewable energy came to the forefront of global politics as record emissions levels continue to be reached despite caps on carbon emissions being agreed up by several global powers. However, renewable energy sources tend more expensive than their fossil-fuel counter parts. In this way, renewable energy cannot be seen as a realistic alternative to fossil-fuel until it is at a price universally achievable. On the opposite side of the spectrum, commentators note that the average temperature is expected to rise by four degrees by the end of the decade. In order to prevent this, they suggest carbon emissions must be reduced by seventy per cent by 2050. Such commentators advocate government subsidised renewable energy forms as a way to achieve this target.", "hypothesis": "Government subsidiary could reduce renewable energy cost", "gold_label": "entailment"}
{"uid": "id_1", "premise": "This passage provides information on the subsidising of renewable energy and its effect on the usage of fossil fuels. The issue of subsidising sources of renewable energy came to the forefront of global politics as record emissions levels continue to be reached despite caps on carbon emissions being agreed up by several global powers. However, renewable energy sources tend more expensive than their fossil-fuel counter parts. In this way, renewable energy cannot be seen as a realistic alternative to fossil-fuel until it is at a price universally achievable. On the opposite side of the spectrum, commentators note that the average temperature is expected to rise by four degrees by the end of the decade. In order to prevent this, they suggest carbon emissions must be reduced by seventy per cent by 2050. Such commentators advocate government subsidised renewable energy forms as a way to achieve this target.", "hypothesis": "Fossil-fuels are currently cheaper than forms of renewable energy.", "gold_label": "entailment"}
{"uid": "id_2", "premise": "This passage provides information on the subsidising of renewable energy and its effect on the usage of fossil fuels. The issue of subsidising sources of renewable energy came to the forefront of global politics as record emissions levels continue to be reached despite caps on carbon emissions being agreed up by several global powers. However, renewable energy sources tend more expensive than their fossil-fuel counter parts. In this way, renewable energy cannot be seen as a realistic alternative to fossil-fuel until it is at a price universally achievable. On the opposite side of the spectrum, commentators note that the average temperature is expected to rise by four degrees by the end of the decade. In order to prevent this, they suggest carbon emissions must be reduced by seventy per cent by 2050. Such commentators advocate government subsidised renewable energy forms as a way to achieve this target.", "hypothesis": "The average temperature in the UK is set to rise by 4% by 2050.", "gold_label": "contradiction"}
{"uid": "id_3", "premise": "This year most of the shops and departmental stores are offering prizes and discounts on purchases to attract customers", "hypothesis": "Lots of goods are available but the sale is not shooting up. There is no cheer for the customers.", "gold_label": "entailment"}
{"uid": "id_4", "premise": "This year most of the shops and departmental stores are offering prizes and discounts on purchases to attract customers", "hypothesis": "The shops and departmental stores have so far earned a lot of profit, so now they have started sharing it with the customers.", "gold_label": "neutral"}
{"uid": "id_5", "premise": "Thomas Young The Last True Know-It-All Thomas Young (1773-1829) contributed 63 articles to the Encyclopedia Britannica, including 46 biographical entries (mostly on scientists and classicists) and substantial essays on Bridge, Chromatics, Egypt, Languages and Tides. Was someone who could write authoritatively about so many subjects a polymath, a genius or a dilettante? In an ambitious new biography, Andrew Robinson argues that Young is a good contender for the epitaph the last man who knew everything. Young has competition, however: The phrase, which Robinson takes for his title, also serves as the subtitle of two other recent biographies: Leonard Warrens 1998 life of paleontologist Joseph Leidy (1823-1891) and Paula Findlens 2004 book on Athanasius Kircher (1602-1680), another polymath. Young, of course, did more than write encyclopedia entries. He presented his first paper to the Royal Society of London at the age of 20 and was elected a Fellow a week after his 21st birthday. In the paper, Young explained the process of accommodation in the human eye on how the eye focuses properly on objects at varying distances. Young hypothesised that this was achieved by changes in the shape of the lens. Young also theorised that light traveled in waves and ho believed that, to account for the ability to see in color, there must be three receptors in the eye corresponding to the three principal colors to which the retina could respond: red, green, violet. All these hypotheses Were subsequently proved to be correct. Later in his life, when he was in his forties, Young was instrumental in cracking the code that unlocked the unknown script on the Rosetta Stone, a tablet that was found in Egypt by the Napoleonic army in 1799. The stone contains text in three alphabets: Greek, something unrecognisable and Egyptian hieroglyphs. The unrecognisable script is now known as demotic and, as Young deduced, is related directly to hieroglyphic. His initial work on this appeared in his Britannica entry on Egypt. In another entry, he coined the term Indo-European to describe the family of languages spoken throughout most of Europe and northern India. These are the landmark achievements of a man who was a child prodigy and who, unlike many remarkable children, did not disappear into oblivion as an adult. Bom in 1773 in Somerset in England, Young lived from an early age with his maternal grandfather, eventually leaving to attend boarding school. He had devoured books from the age of two, and through his own initiative he excelled at Latin, Greek, mathematics and natural philosophy. After leaving school, he was greatly encouraged by his mothers uncle, Richard Brocklesby, a physician and Fellow of the Royal Society. Following Brocklesbys lead, Young decided to pursue a career in medicine. He studied in London, following the medical circuit, and then moved on to more formal education in Edinburgh, Gottingen and Cambridge. After completing his medical training at the University of Cambridge in 1808, Young set up practice as a physician in London. He soon became a Fellow of the Royal College of Physicians and a few years later was appointed physician at St. Georges Hospital. Youngs skill as a physician, however, did not equal his skill as a scholar of natural philosophy or linguistics. Earlier, in 1801, he had been appointed to a professorship of natural philosophy at the Royal Institution, where he delivered as many as 60 lectures in a year. These were published in two volumes in 1807. In 1804 Young had become secretary to the Royal Society, a post he would hold until his death. His opinions were sought on civic and national matters, such as the introduction of gas lighting to London and methods of ship construction. From 1819 he was superintendent of the Nautical Almanac and secretary to the Board of Longitude. From 1824 to 1829 he was physician to and inspector of calculations for the Palladian Insurance Company. Between 1816 and 1825 he contributed his many and various entries to the Encyclopedia Britannica, and throughout his career he authored numerous books, essays and papers. Young is a perfect subject for a biography perfect, but daunting. Few men contributed so much to so many technical fields. Robinsons aim is to introduce non-scientists to Youngs work and life. He succeeds, providing clear expositions of the technical material (especially that on optics and Egyptian hieroglyphs). Some readers of this book will, like Robinson, find Youngs accomplishments impressive; others will see him as some historians have as a dilettante. Yet despite the rich material presented in this book, readers will not end up knowing Young personally. We catch glimpses of a playful Young, doodling Greek and Latin phrases in his notes on medical lectures and translating the verses that a young lady had written on the walls of a summerhouse into Greek elegiacs. Young was introduced into elite society, attended the theatre and learned to dance and play the flute. In addition, he was an accomplished horseman. However, his personal life looks pale next to his vibrant career and studies. Young married Eliza Maxwell in 1804, and according to Robinson, their marriage was a happy one and she appreciated his work, Almost all we know about her is that she sustained her husband through some rancorous disputes about optics and that she worried about money when his medical career was slow to take off. Very little evidence survives about the complexities of Youngs relationships with his mother and father. Robinson does not credit them, or anyone else, with shaping Youngs extraordinary mind. Despite the lack of details concerning Youngs relationships, however, anyone interested in what it means to be a genius should read this book.", "hypothesis": "All Youngs articles were published in Encyclopedia Britannica.", "gold_label": "contradiction"}
{"uid": "id_6", "premise": "Thomas Young The Last True Know-It-All Thomas Young (1773-1829) contributed 63 articles to the Encyclopedia Britannica, including 46 biographical entries (mostly on scientists and classicists) and substantial essays on Bridge, Chromatics, Egypt, Languages and Tides. Was someone who could write authoritatively about so many subjects a polymath, a genius or a dilettante? In an ambitious new biography, Andrew Robinson argues that Young is a good contender for the epitaph the last man who knew everything. Young has competition, however: The phrase, which Robinson takes for his title, also serves as the subtitle of two other recent biographies: Leonard Warrens 1998 life of paleontologist Joseph Leidy (1823-1891) and Paula Findlens 2004 book on Athanasius Kircher (1602-1680), another polymath. Young, of course, did more than write encyclopedia entries. He presented his first paper to the Royal Society of London at the age of 20 and was elected a Fellow a week after his 21st birthday. In the paper, Young explained the process of accommodation in the human eye on how the eye focuses properly on objects at varying distances. Young hypothesised that this was achieved by changes in the shape of the lens. Young also theorised that light traveled in waves and ho believed that, to account for the ability to see in color, there must be three receptors in the eye corresponding to the three principal colors to which the retina could respond: red, green, violet. All these hypotheses Were subsequently proved to be correct. Later in his life, when he was in his forties, Young was instrumental in cracking the code that unlocked the unknown script on the Rosetta Stone, a tablet that was found in Egypt by the Napoleonic army in 1799. The stone contains text in three alphabets: Greek, something unrecognisable and Egyptian hieroglyphs. The unrecognisable script is now known as demotic and, as Young deduced, is related directly to hieroglyphic. His initial work on this appeared in his Britannica entry on Egypt. In another entry, he coined the term Indo-European to describe the family of languages spoken throughout most of Europe and northern India. These are the landmark achievements of a man who was a child prodigy and who, unlike many remarkable children, did not disappear into oblivion as an adult. Bom in 1773 in Somerset in England, Young lived from an early age with his maternal grandfather, eventually leaving to attend boarding school. He had devoured books from the age of two, and through his own initiative he excelled at Latin, Greek, mathematics and natural philosophy. After leaving school, he was greatly encouraged by his mothers uncle, Richard Brocklesby, a physician and Fellow of the Royal Society. Following Brocklesbys lead, Young decided to pursue a career in medicine. He studied in London, following the medical circuit, and then moved on to more formal education in Edinburgh, Gottingen and Cambridge. After completing his medical training at the University of Cambridge in 1808, Young set up practice as a physician in London. He soon became a Fellow of the Royal College of Physicians and a few years later was appointed physician at St. Georges Hospital. Youngs skill as a physician, however, did not equal his skill as a scholar of natural philosophy or linguistics. Earlier, in 1801, he had been appointed to a professorship of natural philosophy at the Royal Institution, where he delivered as many as 60 lectures in a year. These were published in two volumes in 1807. In 1804 Young had become secretary to the Royal Society, a post he would hold until his death. His opinions were sought on civic and national matters, such as the introduction of gas lighting to London and methods of ship construction. From 1819 he was superintendent of the Nautical Almanac and secretary to the Board of Longitude. From 1824 to 1829 he was physician to and inspector of calculations for the Palladian Insurance Company. Between 1816 and 1825 he contributed his many and various entries to the Encyclopedia Britannica, and throughout his career he authored numerous books, essays and papers. Young is a perfect subject for a biography perfect, but daunting. Few men contributed so much to so many technical fields. Robinsons aim is to introduce non-scientists to Youngs work and life. He succeeds, providing clear expositions of the technical material (especially that on optics and Egyptian hieroglyphs). Some readers of this book will, like Robinson, find Youngs accomplishments impressive; others will see him as some historians have as a dilettante. Yet despite the rich material presented in this book, readers will not end up knowing Young personally. We catch glimpses of a playful Young, doodling Greek and Latin phrases in his notes on medical lectures and translating the verses that a young lady had written on the walls of a summerhouse into Greek elegiacs. Young was introduced into elite society, attended the theatre and learned to dance and play the flute. In addition, he was an accomplished horseman. However, his personal life looks pale next to his vibrant career and studies. Young married Eliza Maxwell in 1804, and according to Robinson, their marriage was a happy one and she appreciated his work, Almost all we know about her is that she sustained her husband through some rancorous disputes about optics and that she worried about money when his medical career was slow to take off. Very little evidence survives about the complexities of Youngs relationships with his mother and father. Robinson does not credit them, or anyone else, with shaping Youngs extraordinary mind. Despite the lack of details concerning Youngs relationships, however, anyone interested in what it means to be a genius should read this book.", "hypothesis": "The last man who knew everything has also been claimed to other people.", "gold_label": "entailment"}
{"uid": "id_7", "premise": "Thomas Young The Last True Know-It-All Thomas Young (1773-1829) contributed 63 articles to the Encyclopedia Britannica, including 46 biographical entries (mostly on scientists and classicists) and substantial essays on Bridge, Chromatics, Egypt, Languages and Tides. Was someone who could write authoritatively about so many subjects a polymath, a genius or a dilettante? In an ambitious new biography, Andrew Robinson argues that Young is a good contender for the epitaph the last man who knew everything. Young has competition, however: The phrase, which Robinson takes for his title, also serves as the subtitle of two other recent biographies: Leonard Warrens 1998 life of paleontologist Joseph Leidy (1823-1891) and Paula Findlens 2004 book on Athanasius Kircher (1602-1680), another polymath. Young, of course, did more than write encyclopedia entries. He presented his first paper to the Royal Society of London at the age of 20 and was elected a Fellow a week after his 21st birthday. In the paper, Young explained the process of accommodation in the human eye on how the eye focuses properly on objects at varying distances. Young hypothesised that this was achieved by changes in the shape of the lens. Young also theorised that light traveled in waves and ho believed that, to account for the ability to see in color, there must be three receptors in the eye corresponding to the three principal colors to which the retina could respond: red, green, violet. All these hypotheses Were subsequently proved to be correct. Later in his life, when he was in his forties, Young was instrumental in cracking the code that unlocked the unknown script on the Rosetta Stone, a tablet that was found in Egypt by the Napoleonic army in 1799. The stone contains text in three alphabets: Greek, something unrecognisable and Egyptian hieroglyphs. The unrecognisable script is now known as demotic and, as Young deduced, is related directly to hieroglyphic. His initial work on this appeared in his Britannica entry on Egypt. In another entry, he coined the term Indo-European to describe the family of languages spoken throughout most of Europe and northern India. These are the landmark achievements of a man who was a child prodigy and who, unlike many remarkable children, did not disappear into oblivion as an adult. Bom in 1773 in Somerset in England, Young lived from an early age with his maternal grandfather, eventually leaving to attend boarding school. He had devoured books from the age of two, and through his own initiative he excelled at Latin, Greek, mathematics and natural philosophy. After leaving school, he was greatly encouraged by his mothers uncle, Richard Brocklesby, a physician and Fellow of the Royal Society. Following Brocklesbys lead, Young decided to pursue a career in medicine. He studied in London, following the medical circuit, and then moved on to more formal education in Edinburgh, Gottingen and Cambridge. After completing his medical training at the University of Cambridge in 1808, Young set up practice as a physician in London. He soon became a Fellow of the Royal College of Physicians and a few years later was appointed physician at St. Georges Hospital. Youngs skill as a physician, however, did not equal his skill as a scholar of natural philosophy or linguistics. Earlier, in 1801, he had been appointed to a professorship of natural philosophy at the Royal Institution, where he delivered as many as 60 lectures in a year. These were published in two volumes in 1807. In 1804 Young had become secretary to the Royal Society, a post he would hold until his death. His opinions were sought on civic and national matters, such as the introduction of gas lighting to London and methods of ship construction. From 1819 he was superintendent of the Nautical Almanac and secretary to the Board of Longitude. From 1824 to 1829 he was physician to and inspector of calculations for the Palladian Insurance Company. Between 1816 and 1825 he contributed his many and various entries to the Encyclopedia Britannica, and throughout his career he authored numerous books, essays and papers. Young is a perfect subject for a biography perfect, but daunting. Few men contributed so much to so many technical fields. Robinsons aim is to introduce non-scientists to Youngs work and life. He succeeds, providing clear expositions of the technical material (especially that on optics and Egyptian hieroglyphs). Some readers of this book will, like Robinson, find Youngs accomplishments impressive; others will see him as some historians have as a dilettante. Yet despite the rich material presented in this book, readers will not end up knowing Young personally. We catch glimpses of a playful Young, doodling Greek and Latin phrases in his notes on medical lectures and translating the verses that a young lady had written on the walls of a summerhouse into Greek elegiacs. Young was introduced into elite society, attended the theatre and learned to dance and play the flute. In addition, he was an accomplished horseman. However, his personal life looks pale next to his vibrant career and studies. Young married Eliza Maxwell in 1804, and according to Robinson, their marriage was a happy one and she appreciated his work, Almost all we know about her is that she sustained her husband through some rancorous disputes about optics and that she worried about money when his medical career was slow to take off. Very little evidence survives about the complexities of Youngs relationships with his mother and father. Robinson does not credit them, or anyone else, with shaping Youngs extraordinary mind. Despite the lack of details concerning Youngs relationships, however, anyone interested in what it means to be a genius should read this book.", "hypothesis": "Young suffered from a disease in his later years.", "gold_label": "neutral"}
{"uid": "id_8", "premise": "Thomas Young The Last True Know-It-All Thomas Young (1773-1829) contributed 63 articles to the Encyclopedia Britannica, including 46 biographical entries (mostly on scientists and classicists) and substantial essays on Bridge, Chromatics, Egypt, Languages and Tides. Was someone who could write authoritatively about so many subjects a polymath, a genius or a dilettante? In an ambitious new biography, Andrew Robinson argues that Young is a good contender for the epitaph the last man who knew everything. Young has competition, however: The phrase, which Robinson takes for his title, also serves as the subtitle of two other recent biographies: Leonard Warrens 1998 life of paleontologist Joseph Leidy (1823-1891) and Paula Findlens 2004 book on Athanasius Kircher (1602-1680), another polymath. Young, of course, did more than write encyclopedia entries. He presented his first paper to the Royal Society of London at the age of 20 and was elected a Fellow a week after his 21st birthday. In the paper, Young explained the process of accommodation in the human eye on how the eye focuses properly on objects at varying distances. Young hypothesised that this was achieved by changes in the shape of the lens. Young also theorised that light traveled in waves and ho believed that, to account for the ability to see in color, there must be three receptors in the eye corresponding to the three principal colors to which the retina could respond: red, green, violet. All these hypotheses Were subsequently proved to be correct. Later in his life, when he was in his forties, Young was instrumental in cracking the code that unlocked the unknown script on the Rosetta Stone, a tablet that was found in Egypt by the Napoleonic army in 1799. The stone contains text in three alphabets: Greek, something unrecognisable and Egyptian hieroglyphs. The unrecognisable script is now known as demotic and, as Young deduced, is related directly to hieroglyphic. His initial work on this appeared in his Britannica entry on Egypt. In another entry, he coined the term Indo-European to describe the family of languages spoken throughout most of Europe and northern India. These are the landmark achievements of a man who was a child prodigy and who, unlike many remarkable children, did not disappear into oblivion as an adult. Bom in 1773 in Somerset in England, Young lived from an early age with his maternal grandfather, eventually leaving to attend boarding school. He had devoured books from the age of two, and through his own initiative he excelled at Latin, Greek, mathematics and natural philosophy. After leaving school, he was greatly encouraged by his mothers uncle, Richard Brocklesby, a physician and Fellow of the Royal Society. Following Brocklesbys lead, Young decided to pursue a career in medicine. He studied in London, following the medical circuit, and then moved on to more formal education in Edinburgh, Gottingen and Cambridge. After completing his medical training at the University of Cambridge in 1808, Young set up practice as a physician in London. He soon became a Fellow of the Royal College of Physicians and a few years later was appointed physician at St. Georges Hospital. Youngs skill as a physician, however, did not equal his skill as a scholar of natural philosophy or linguistics. Earlier, in 1801, he had been appointed to a professorship of natural philosophy at the Royal Institution, where he delivered as many as 60 lectures in a year. These were published in two volumes in 1807. In 1804 Young had become secretary to the Royal Society, a post he would hold until his death. His opinions were sought on civic and national matters, such as the introduction of gas lighting to London and methods of ship construction. From 1819 he was superintendent of the Nautical Almanac and secretary to the Board of Longitude. From 1824 to 1829 he was physician to and inspector of calculations for the Palladian Insurance Company. Between 1816 and 1825 he contributed his many and various entries to the Encyclopedia Britannica, and throughout his career he authored numerous books, essays and papers. Young is a perfect subject for a biography perfect, but daunting. Few men contributed so much to so many technical fields. Robinsons aim is to introduce non-scientists to Youngs work and life. He succeeds, providing clear expositions of the technical material (especially that on optics and Egyptian hieroglyphs). Some readers of this book will, like Robinson, find Youngs accomplishments impressive; others will see him as some historians have as a dilettante. Yet despite the rich material presented in this book, readers will not end up knowing Young personally. We catch glimpses of a playful Young, doodling Greek and Latin phrases in his notes on medical lectures and translating the verses that a young lady had written on the walls of a summerhouse into Greek elegiacs. Young was introduced into elite society, attended the theatre and learned to dance and play the flute. In addition, he was an accomplished horseman. However, his personal life looks pale next to his vibrant career and studies. Young married Eliza Maxwell in 1804, and according to Robinson, their marriage was a happy one and she appreciated his work, Almost all we know about her is that she sustained her husband through some rancorous disputes about optics and that she worried about money when his medical career was slow to take off. Very little evidence survives about the complexities of Youngs relationships with his mother and father. Robinson does not credit them, or anyone else, with shaping Youngs extraordinary mind. Despite the lack of details concerning Youngs relationships, however, anyone interested in what it means to be a genius should read this book.", "hypothesis": "Young took part in various social pastimes.", "gold_label": "entailment"}
{"uid": "id_9", "premise": "Thomas Young The Last True Know-It-All Thomas Young (1773-1829) contributed 63 articles to the Encyclopedia Britannica, including 46 biographical entries (mostly on scientists and classicists) and substantial essays on Bridge, Chromatics, Egypt, Languages and Tides. Was someone who could write authoritatively about so many subjects a polymath, a genius or a dilettante? In an ambitious new biography, Andrew Robinson argues that Young is a good contender for the epitaph the last man who knew everything. Young has competition, however: The phrase, which Robinson takes for his title, also serves as the subtitle of two other recent biographies: Leonard Warrens 1998 life of paleontologist Joseph Leidy (1823-1891) and Paula Findlens 2004 book on Athanasius Kircher (1602-1680), another polymath. Young, of course, did more than write encyclopedia entries. He presented his first paper to the Royal Society of London at the age of 20 and was elected a Fellow a week after his 21st birthday. In the paper, Young explained the process of accommodation in the human eye on how the eye focuses properly on objects at varying distances. Young hypothesised that this was achieved by changes in the shape of the lens. Young also theorised that light traveled in waves and ho believed that, to account for the ability to see in color, there must be three receptors in the eye corresponding to the three principal colors to which the retina could respond: red, green, violet. All these hypotheses Were subsequently proved to be correct. Later in his life, when he was in his forties, Young was instrumental in cracking the code that unlocked the unknown script on the Rosetta Stone, a tablet that was found in Egypt by the Napoleonic army in 1799. The stone contains text in three alphabets: Greek, something unrecognisable and Egyptian hieroglyphs. The unrecognisable script is now known as demotic and, as Young deduced, is related directly to hieroglyphic. His initial work on this appeared in his Britannica entry on Egypt. In another entry, he coined the term Indo-European to describe the family of languages spoken throughout most of Europe and northern India. These are the landmark achievements of a man who was a child prodigy and who, unlike many remarkable children, did not disappear into oblivion as an adult. Bom in 1773 in Somerset in England, Young lived from an early age with his maternal grandfather, eventually leaving to attend boarding school. He had devoured books from the age of two, and through his own initiative he excelled at Latin, Greek, mathematics and natural philosophy. After leaving school, he was greatly encouraged by his mothers uncle, Richard Brocklesby, a physician and Fellow of the Royal Society. Following Brocklesbys lead, Young decided to pursue a career in medicine. He studied in London, following the medical circuit, and then moved on to more formal education in Edinburgh, Gottingen and Cambridge. After completing his medical training at the University of Cambridge in 1808, Young set up practice as a physician in London. He soon became a Fellow of the Royal College of Physicians and a few years later was appointed physician at St. Georges Hospital. Youngs skill as a physician, however, did not equal his skill as a scholar of natural philosophy or linguistics. Earlier, in 1801, he had been appointed to a professorship of natural philosophy at the Royal Institution, where he delivered as many as 60 lectures in a year. These were published in two volumes in 1807. In 1804 Young had become secretary to the Royal Society, a post he would hold until his death. His opinions were sought on civic and national matters, such as the introduction of gas lighting to London and methods of ship construction. From 1819 he was superintendent of the Nautical Almanac and secretary to the Board of Longitude. From 1824 to 1829 he was physician to and inspector of calculations for the Palladian Insurance Company. Between 1816 and 1825 he contributed his many and various entries to the Encyclopedia Britannica, and throughout his career he authored numerous books, essays and papers. Young is a perfect subject for a biography perfect, but daunting. Few men contributed so much to so many technical fields. Robinsons aim is to introduce non-scientists to Youngs work and life. He succeeds, providing clear expositions of the technical material (especially that on optics and Egyptian hieroglyphs). Some readers of this book will, like Robinson, find Youngs accomplishments impressive; others will see him as some historians have as a dilettante. Yet despite the rich material presented in this book, readers will not end up knowing Young personally. We catch glimpses of a playful Young, doodling Greek and Latin phrases in his notes on medical lectures and translating the verses that a young lady had written on the walls of a summerhouse into Greek elegiacs. Young was introduced into elite society, attended the theatre and learned to dance and play the flute. In addition, he was an accomplished horseman. However, his personal life looks pale next to his vibrant career and studies. Young married Eliza Maxwell in 1804, and according to Robinson, their marriage was a happy one and she appreciated his work, Almost all we know about her is that she sustained her husband through some rancorous disputes about optics and that she worried about money when his medical career was slow to take off. Very little evidence survives about the complexities of Youngs relationships with his mother and father. Robinson does not credit them, or anyone else, with shaping Youngs extraordinary mind. Despite the lack of details concerning Youngs relationships, however, anyone interested in what it means to be a genius should read this book.", "hypothesis": "Youngs advice was sought by people responsible for local and national issues.", "gold_label": "entailment"}
{"uid": "id_10", "premise": "Thomas Young The Last True Know-It-All Thomas Young (1773-1829) contributed 63 articles to the Encyclopedia Britannica, including 46 biographical entries (mostly on scientists and classicists) and substantial essays on Bridge, Chromatics, Egypt, Languages and Tides. Was someone who could write authoritatively about so many subjects a polymath, a genius or a dilettante? In an ambitious new biography, Andrew Robinson argues that Young is a good contender for the epitaph the last man who knew everything. Young has competition, however: The phrase, which Robinson takes for his title, also serves as the subtitle of two other recent biographies: Leonard Warrens 1998 life of paleontologist Joseph Leidy (1823-1891) and Paula Findlens 2004 book on Athanasius Kircher (1602-1680), another polymath. Young, of course, did more than write encyclopedia entries. He presented his first paper to the Royal Society of London at the age of 20 and was elected a Fellow a week after his 21st birthday. In the paper, Young explained the process of accommodation in the human eye on how the eye focuses properly on objects at varying distances. Young hypothesised that this was achieved by changes in the shape of the lens. Young also theorised that light traveled in waves and ho believed that, to account for the ability to see in color, there must be three receptors in the eye corresponding to the three principal colors to which the retina could respond: red, green, violet. All these hypotheses Were subsequently proved to be correct. Later in his life, when he was in his forties, Young was instrumental in cracking the code that unlocked the unknown script on the Rosetta Stone, a tablet that was found in Egypt by the Napoleonic army in 1799. The stone contains text in three alphabets: Greek, something unrecognisable and Egyptian hieroglyphs. The unrecognisable script is now known as demotic and, as Young deduced, is related directly to hieroglyphic. His initial work on this appeared in his Britannica entry on Egypt. In another entry, he coined the term Indo-European to describe the family of languages spoken throughout most of Europe and northern India. These are the landmark achievements of a man who was a child prodigy and who, unlike many remarkable children, did not disappear into oblivion as an adult. Bom in 1773 in Somerset in England, Young lived from an early age with his maternal grandfather, eventually leaving to attend boarding school. He had devoured books from the age of two, and through his own initiative he excelled at Latin, Greek, mathematics and natural philosophy. After leaving school, he was greatly encouraged by his mothers uncle, Richard Brocklesby, a physician and Fellow of the Royal Society. Following Brocklesbys lead, Young decided to pursue a career in medicine. He studied in London, following the medical circuit, and then moved on to more formal education in Edinburgh, Gottingen and Cambridge. After completing his medical training at the University of Cambridge in 1808, Young set up practice as a physician in London. He soon became a Fellow of the Royal College of Physicians and a few years later was appointed physician at St. Georges Hospital. Youngs skill as a physician, however, did not equal his skill as a scholar of natural philosophy or linguistics. Earlier, in 1801, he had been appointed to a professorship of natural philosophy at the Royal Institution, where he delivered as many as 60 lectures in a year. These were published in two volumes in 1807. In 1804 Young had become secretary to the Royal Society, a post he would hold until his death. His opinions were sought on civic and national matters, such as the introduction of gas lighting to London and methods of ship construction. From 1819 he was superintendent of the Nautical Almanac and secretary to the Board of Longitude. From 1824 to 1829 he was physician to and inspector of calculations for the Palladian Insurance Company. Between 1816 and 1825 he contributed his many and various entries to the Encyclopedia Britannica, and throughout his career he authored numerous books, essays and papers. Young is a perfect subject for a biography perfect, but daunting. Few men contributed so much to so many technical fields. Robinsons aim is to introduce non-scientists to Youngs work and life. He succeeds, providing clear expositions of the technical material (especially that on optics and Egyptian hieroglyphs). Some readers of this book will, like Robinson, find Youngs accomplishments impressive; others will see him as some historians have as a dilettante. Yet despite the rich material presented in this book, readers will not end up knowing Young personally. We catch glimpses of a playful Young, doodling Greek and Latin phrases in his notes on medical lectures and translating the verses that a young lady had written on the walls of a summerhouse into Greek elegiacs. Young was introduced into elite society, attended the theatre and learned to dance and play the flute. In addition, he was an accomplished horseman. However, his personal life looks pale next to his vibrant career and studies. Young married Eliza Maxwell in 1804, and according to Robinson, their marriage was a happy one and she appreciated his work, Almost all we know about her is that she sustained her husband through some rancorous disputes about optics and that she worried about money when his medical career was slow to take off. Very little evidence survives about the complexities of Youngs relationships with his mother and father. Robinson does not credit them, or anyone else, with shaping Youngs extraordinary mind. Despite the lack of details concerning Youngs relationships, however, anyone interested in what it means to be a genius should read this book.", "hypothesis": "Youngs talent as a doctor surpassed his other skills.", "gold_label": "contradiction"}
{"uid": "id_11", "premise": "Thomas Young The Last True Know-It-All Thomas Young (1773-1829) contributed 63 articles to the Encyclopedia Britannica, including 46 biographical entries (mostly on scientists and classicists) and substantial essays on Bridge, Chromatics, Egypt, Languages and Tides. Was someone who could write authoritatively about so many subjects a polymath, a genius or a dilettante? In an ambitious new biography, Andrew Robinson argues that Young is a good contender for the epitaph the last man who knew everything. Young has competition, however: The phrase, which Robinson takes for his title, also serves as the subtitle of two other recent biographies: Leonard Warrens 1998 life of paleontologist Joseph Leidy (1823-1891) and Paula Findlens 2004 book on Athanasius Kircher (1602-1680), another polymath. Young, of course, did more than write encyclopedia entries. He presented his first paper to the Royal Society of London at the age of 20 and was elected a Fellow a week after his 21st birthday. In the paper, Young explained the process of accommodation in the human eye on how the eye focuses properly on objects at varying distances. Young hypothesised that this was achieved by changes in the shape of the lens. Young also theorised that light traveled in waves and ho believed that, to account for the ability to see in color, there must be three receptors in the eye corresponding to the three principal colors to which the retina could respond: red, green, violet. All these hypotheses Were subsequently proved to be correct. Later in his life, when he was in his forties, Young was instrumental in cracking the code that unlocked the unknown script on the Rosetta Stone, a tablet that was found in Egypt by the Napoleonic army in 1799. The stone contains text in three alphabets: Greek, something unrecognisable and Egyptian hieroglyphs. The unrecognisable script is now known as demotic and, as Young deduced, is related directly to hieroglyphic. His initial work on this appeared in his Britannica entry on Egypt. In another entry, he coined the term Indo-European to describe the family of languages spoken throughout most of Europe and northern India. These are the landmark achievements of a man who was a child prodigy and who, unlike many remarkable children, did not disappear into oblivion as an adult. Bom in 1773 in Somerset in England, Young lived from an early age with his maternal grandfather, eventually leaving to attend boarding school. He had devoured books from the age of two, and through his own initiative he excelled at Latin, Greek, mathematics and natural philosophy. After leaving school, he was greatly encouraged by his mothers uncle, Richard Brocklesby, a physician and Fellow of the Royal Society. Following Brocklesbys lead, Young decided to pursue a career in medicine. He studied in London, following the medical circuit, and then moved on to more formal education in Edinburgh, Gottingen and Cambridge. After completing his medical training at the University of Cambridge in 1808, Young set up practice as a physician in London. He soon became a Fellow of the Royal College of Physicians and a few years later was appointed physician at St. Georges Hospital. Youngs skill as a physician, however, did not equal his skill as a scholar of natural philosophy or linguistics. Earlier, in 1801, he had been appointed to a professorship of natural philosophy at the Royal Institution, where he delivered as many as 60 lectures in a year. These were published in two volumes in 1807. In 1804 Young had become secretary to the Royal Society, a post he would hold until his death. His opinions were sought on civic and national matters, such as the introduction of gas lighting to London and methods of ship construction. From 1819 he was superintendent of the Nautical Almanac and secretary to the Board of Longitude. From 1824 to 1829 he was physician to and inspector of calculations for the Palladian Insurance Company. Between 1816 and 1825 he contributed his many and various entries to the Encyclopedia Britannica, and throughout his career he authored numerous books, essays and papers. Young is a perfect subject for a biography perfect, but daunting. Few men contributed so much to so many technical fields. Robinsons aim is to introduce non-scientists to Youngs work and life. He succeeds, providing clear expositions of the technical material (especially that on optics and Egyptian hieroglyphs). Some readers of this book will, like Robinson, find Youngs accomplishments impressive; others will see him as some historians have as a dilettante. Yet despite the rich material presented in this book, readers will not end up knowing Young personally. We catch glimpses of a playful Young, doodling Greek and Latin phrases in his notes on medical lectures and translating the verses that a young lady had written on the walls of a summerhouse into Greek elegiacs. Young was introduced into elite society, attended the theatre and learned to dance and play the flute. In addition, he was an accomplished horseman. However, his personal life looks pale next to his vibrant career and studies. Young married Eliza Maxwell in 1804, and according to Robinson, their marriage was a happy one and she appreciated his work, Almost all we know about her is that she sustained her husband through some rancorous disputes about optics and that she worried about money when his medical career was slow to take off. Very little evidence survives about the complexities of Youngs relationships with his mother and father. Robinson does not credit them, or anyone else, with shaping Youngs extraordinary mind. Despite the lack of details concerning Youngs relationships, however, anyone interested in what it means to be a genius should read this book.", "hypothesis": "Like others, Young wasnt so brilliant when growing up.", "gold_label": "contradiction"}
{"uid": "id_12", "premise": "Though no heavy rain has been received in the city and water is receding from most areas in Chennai and massive relief operations are underway, the city is staring at an outbreak of epidemics with tones of stinking garbage littering the streets as bright sunshine further eased the situation.", "hypothesis": "Garbage in the city is the major concern of epidemics.", "gold_label": "entailment"}
{"uid": "id_13", "premise": "Though no heavy rain has been received in the city and water is receding from most areas in Chennai and massive relief operations are underway, the city is staring at an outbreak of epidemics with tones of stinking garbage littering the streets as bright sunshine further eased the situation.", "hypothesis": "Chennai needs proper planning to overcome heavy rains in the city.", "gold_label": "contradiction"}
{"uid": "id_14", "premise": "Though no heavy rain has been received in the city and water is receding from most areas in Chennai and massive relief operations are underway, the city is staring at an outbreak of epidemics with tones of stinking garbage littering the streets as bright sunshine further eased the situation.", "hypothesis": "Improper drainage system in Chennai is the major cause of flood in the city.", "gold_label": "contradiction"}
{"uid": "id_15", "premise": "Though no heavy rain has been received in the city and water is receding from most areas in Chennai and massive relief operations are underway, the city is staring at an outbreak of epidemics with tones of stinking garbage littering the streets as bright sunshine further eased the situation.", "hypothesis": "Massive rains are the major cause of epidemics in the cities.", "gold_label": "contradiction"}
{"uid": "id_16", "premise": "Three athletes each receive a first, second and third prize for a different sporting event. Either Anne or Josie got the second prize for Tennis. Anne got the same prize for throwing the javelin as Josie got for swimming. Tanya got the first prize for swimming, and her prize for the javelin was the same as Josies for tennis and Annes for swimming.", "hypothesis": "Anne got the first prize for tennis", "gold_label": "entailment"}
{"uid": "id_17", "premise": "Three athletes each receive a first, second and third prize for a different sporting event. Either Anne or Josie got the second prize for Tennis. Anne got the same prize for throwing the javelin as Josie got for swimming. Tanya got the first prize for swimming, and her prize for the javelin was the same as Josies for tennis and Annes for swimming.", "hypothesis": "Josie was best with the javelin", "gold_label": "entailment"}
{"uid": "id_18", "premise": "Three athletes each receive a first, second and third prize for a different sporting event. Either Anne or Josie got the second prize for Tennis. Anne got the same prize for throwing the javelin as Josie got for swimming. Tanya got the first prize for swimming, and her prize for the javelin was the same as Josies for tennis and Annes for swimming.", "hypothesis": "Anne got the second prize for swimming", "gold_label": "entailment"}
{"uid": "id_19", "premise": "Three pencils cost the same as two erasers. Four erasers cost the same as one ruler.", "hypothesis": "Pencils are more expensive than rulers.", "gold_label": "contradiction"}
{"uid": "id_20", "premise": "Throughout Europe, the three most prevalent ways of punishing an individual for a drug possession offence are warning, fine and suspended prison sentence; with the exception of a few countries, community work orders are rarely used. Those convicted of supply offences are more likely to receive a prison sentence. Notwithstanding, certain offenders receive long sentences and these are often brought up in public debate. Considerable differences between countries exist regarding where to draw the line between users as individuals needing treatment, and traffickers needing criminal punishment as deterrence. Each countrys criminal justice system recognises some people as sick, and thus tries to divert them to treatment, while punishing others.", "hypothesis": "Differentiation between drug criminals and people requiring treatment is made on a country-by-country basis.", "gold_label": "entailment"}
{"uid": "id_21", "premise": "Throughout Europe, the three most prevalent ways of punishing an individual for a drug possession offence are warning, fine and suspended prison sentence; with the exception of a few countries, community work orders are rarely used. Those convicted of supply offences are more likely to receive a prison sentence. Notwithstanding, certain offenders receive long sentences and these are often brought up in public debate. Considerable differences between countries exist regarding where to draw the line between users as individuals needing treatment, and traffickers needing criminal punishment as deterrence. Each countrys criminal justice system recognises some people as sick, and thus tries to divert them to treatment, while punishing others.", "hypothesis": "Most countries in Europe do not tend to punish individuals for drug offences; rather they recognise them as sick and send them for treatment.", "gold_label": "neutral"}
{"uid": "id_22", "premise": "Throughout Europe, the three most prevalent ways of punishing an individual for a drug possession offence are warning, fine and suspended prison sentence; with the exception of a few countries, community work orders are rarely used. Those convicted of supply offences are more likely to receive a prison sentence. Notwithstanding, certain offenders receive long sentences and these are often brought up in public debate. Considerable differences between countries exist regarding where to draw the line between users as individuals needing treatment, and traffickers needing criminal punishment as deterrence. Each countrys criminal justice system recognises some people as sick, and thus tries to divert them to treatment, while punishing others.", "hypothesis": "A person caught possessing drugs could face a warning, a fine, or a suspended prison sentence depending on the country where the arrest takes place.", "gold_label": "neutral"}
{"uid": "id_23", "premise": "Tickled pink In 1973, the Australian fruit breeder John Cripps created a new variety of apple tree by crossing a red Australian Lady Williams variety with a pale-green American Golden Delicious. The offspring first fruited in 1979 and combined the best features of its parents in an apple that had an attractive pink hue on a yellow undertone. The new, improved apple was named the Cripps Pink after its inventor. Today the Cripps Pink is one of the most popular varieties of apple and is grown extensively in Australia, New Zealand, Canada, France and in California and Washington in the USA. By switching from northern hemisphere fruit to southern hemisphere fruit the apple is available at its seasonal best all year round. The highest-quality apples are marketed worldwide under the trademark Pink LadyTM. To preserve the premium price and appeal of the Pink Lady, apples that fail to meet the highest standards are sold under the name Cripps PinkTM. These standards are based on colour and flavour, in particular, the extent of the pink coverage and the sugar/acid balance. Consumers who buy a Pink Lady apple are ensured a product that is of consistently high quality. To earn the name Pink Lady the skin of a Cripps Pink apple must be at least 40% pink. Strong sunlight increases the pink coloration and it may be necessary to remove the uppermost leaves of a tree to let the light through. The extra work required to cultivate Cripps Pink trees is offset by its advantages, which include: vigorous trees; fruit that has tolerance to sunburn; a thin skin that does not crack; flesh that is resistant to browning after being cut and exposed to air; a cold-storage life of up to six months and a retail shelf-life of about four weeks. However, the main advantage for apple growers is the premium price that the Pink Lady brand is able to command. The Cripps Red variety, also known as Cripps II, is related to the Pink Lady and was developed at the same time. The premium grade is marketed as the Sun downerTM. Unlike the genuinely pink Pink Lady, the SundownerTM is a classic bi- coloured apple, with a skin that is 45% red from Lady Williams and 55% green from Golden Delicious. Apples that fall outside of this colour ratio are rejected at the packing station and used for juice, whilst the smaller apples are retained for the home market. The Sundowner is harvested after Cripps Pink in late May or early June, and a few weeks before Lady Williams. It has better cold-storage properties than Cripps Pink and it retains an excellent shelf life. Cripps Red apples have a coarser texture than Cripps Pink, are less sweet and have a stronger flavour. Both apples are sweeter than Lady Williams but neither is as sweet as Golden Delicious. The advantage of the Pink LadyTM brand is that it is a trademark of a premium product, not just a Cripps Pink apple. This means that new and improved strains of the Cripps Pink can use the Pink Lady brand name as long as they meet the minimum quality requirement of being 40% pink. Three such strains are the Rosy Glow, The Ruby Pink and the Lady in Red. The Rosy Glow apple was discovered in an orchard of Cripps Pink trees that had been planted in South Australia in 1996. One limb of a Cripps Pink tree had red-coloured apples while the rest of the limbs bore mostly green fruit. A bud was taken from the mutated branch and grafted onto rootstock to produce the new variety. The fruit from the new Rosy Glow tree was the same colour over the entire tree and a patent for this unique apple was granted in 2003. The Rosy Glow apple benefits from a larger area of pink than the Pink Lady and it ripens earlier in the season in climates that have less hours of sunshine. As a consequence, the Cripps Pink is likely to be phased out in favour of the Rosy Glow, with the apples branded as Pink LadyTM if they have 40% or more pink coverage. Ruby Pink and Lady in Red are two mutations of the Cripps Pink that were dis covered in New Zealand. Like the Rosy Glow, these improved varieties develop a larger area of pink than the Cripps Pink, which allows more apples to meet the quality requirements of the Pink LadyTM brand. Planting of these trees may need to be controlled otherwise the supply of Pink Lady apples will exceed the demand, to then threaten the price premium. Overproduction apart, the future of what has become possibly the worlds best-known modern apple and fruit brand, looks secure.", "hypothesis": "Colour is an important factor in the selection of both of the premium grades of Cripps apples referred to.", "gold_label": "entailment"}
{"uid": "id_24", "premise": "Tickled pink In 1973, the Australian fruit breeder John Cripps created a new variety of apple tree by crossing a red Australian Lady Williams variety with a pale-green American Golden Delicious. The offspring first fruited in 1979 and combined the best features of its parents in an apple that had an attractive pink hue on a yellow undertone. The new, improved apple was named the Cripps Pink after its inventor. Today the Cripps Pink is one of the most popular varieties of apple and is grown extensively in Australia, New Zealand, Canada, France and in California and Washington in the USA. By switching from northern hemisphere fruit to southern hemisphere fruit the apple is available at its seasonal best all year round. The highest-quality apples are marketed worldwide under the trademark Pink LadyTM. To preserve the premium price and appeal of the Pink Lady, apples that fail to meet the highest standards are sold under the name Cripps PinkTM. These standards are based on colour and flavour, in particular, the extent of the pink coverage and the sugar/acid balance. Consumers who buy a Pink Lady apple are ensured a product that is of consistently high quality. To earn the name Pink Lady the skin of a Cripps Pink apple must be at least 40% pink. Strong sunlight increases the pink coloration and it may be necessary to remove the uppermost leaves of a tree to let the light through. The extra work required to cultivate Cripps Pink trees is offset by its advantages, which include: vigorous trees; fruit that has tolerance to sunburn; a thin skin that does not crack; flesh that is resistant to browning after being cut and exposed to air; a cold-storage life of up to six months and a retail shelf-life of about four weeks. However, the main advantage for apple growers is the premium price that the Pink Lady brand is able to command. The Cripps Red variety, also known as Cripps II, is related to the Pink Lady and was developed at the same time. The premium grade is marketed as the Sun downerTM. Unlike the genuinely pink Pink Lady, the SundownerTM is a classic bi- coloured apple, with a skin that is 45% red from Lady Williams and 55% green from Golden Delicious. Apples that fall outside of this colour ratio are rejected at the packing station and used for juice, whilst the smaller apples are retained for the home market. The Sundowner is harvested after Cripps Pink in late May or early June, and a few weeks before Lady Williams. It has better cold-storage properties than Cripps Pink and it retains an excellent shelf life. Cripps Red apples have a coarser texture than Cripps Pink, are less sweet and have a stronger flavour. Both apples are sweeter than Lady Williams but neither is as sweet as Golden Delicious. The advantage of the Pink LadyTM brand is that it is a trademark of a premium product, not just a Cripps Pink apple. This means that new and improved strains of the Cripps Pink can use the Pink Lady brand name as long as they meet the minimum quality requirement of being 40% pink. Three such strains are the Rosy Glow, The Ruby Pink and the Lady in Red. The Rosy Glow apple was discovered in an orchard of Cripps Pink trees that had been planted in South Australia in 1996. One limb of a Cripps Pink tree had red-coloured apples while the rest of the limbs bore mostly green fruit. A bud was taken from the mutated branch and grafted onto rootstock to produce the new variety. The fruit from the new Rosy Glow tree was the same colour over the entire tree and a patent for this unique apple was granted in 2003. The Rosy Glow apple benefits from a larger area of pink than the Pink Lady and it ripens earlier in the season in climates that have less hours of sunshine. As a consequence, the Cripps Pink is likely to be phased out in favour of the Rosy Glow, with the apples branded as Pink LadyTM if they have 40% or more pink coverage. Ruby Pink and Lady in Red are two mutations of the Cripps Pink that were dis covered in New Zealand. Like the Rosy Glow, these improved varieties develop a larger area of pink than the Cripps Pink, which allows more apples to meet the quality requirements of the Pink LadyTM brand. Planting of these trees may need to be controlled otherwise the supply of Pink Lady apples will exceed the demand, to then threaten the price premium. Overproduction apart, the future of what has become possibly the worlds best-known modern apple and fruit brand, looks secure.", "hypothesis": "One advantage of Cripps Pink trees is that they grow well.", "gold_label": "entailment"}
{"uid": "id_25", "premise": "Tickled pink In 1973, the Australian fruit breeder John Cripps created a new variety of apple tree by crossing a red Australian Lady Williams variety with a pale-green American Golden Delicious. The offspring first fruited in 1979 and combined the best features of its parents in an apple that had an attractive pink hue on a yellow undertone. The new, improved apple was named the Cripps Pink after its inventor. Today the Cripps Pink is one of the most popular varieties of apple and is grown extensively in Australia, New Zealand, Canada, France and in California and Washington in the USA. By switching from northern hemisphere fruit to southern hemisphere fruit the apple is available at its seasonal best all year round. The highest-quality apples are marketed worldwide under the trademark Pink LadyTM. To preserve the premium price and appeal of the Pink Lady, apples that fail to meet the highest standards are sold under the name Cripps PinkTM. These standards are based on colour and flavour, in particular, the extent of the pink coverage and the sugar/acid balance. Consumers who buy a Pink Lady apple are ensured a product that is of consistently high quality. To earn the name Pink Lady the skin of a Cripps Pink apple must be at least 40% pink. Strong sunlight increases the pink coloration and it may be necessary to remove the uppermost leaves of a tree to let the light through. The extra work required to cultivate Cripps Pink trees is offset by its advantages, which include: vigorous trees; fruit that has tolerance to sunburn; a thin skin that does not crack; flesh that is resistant to browning after being cut and exposed to air; a cold-storage life of up to six months and a retail shelf-life of about four weeks. However, the main advantage for apple growers is the premium price that the Pink Lady brand is able to command. The Cripps Red variety, also known as Cripps II, is related to the Pink Lady and was developed at the same time. The premium grade is marketed as the Sun downerTM. Unlike the genuinely pink Pink Lady, the SundownerTM is a classic bi- coloured apple, with a skin that is 45% red from Lady Williams and 55% green from Golden Delicious. Apples that fall outside of this colour ratio are rejected at the packing station and used for juice, whilst the smaller apples are retained for the home market. The Sundowner is harvested after Cripps Pink in late May or early June, and a few weeks before Lady Williams. It has better cold-storage properties than Cripps Pink and it retains an excellent shelf life. Cripps Red apples have a coarser texture than Cripps Pink, are less sweet and have a stronger flavour. Both apples are sweeter than Lady Williams but neither is as sweet as Golden Delicious. The advantage of the Pink LadyTM brand is that it is a trademark of a premium product, not just a Cripps Pink apple. This means that new and improved strains of the Cripps Pink can use the Pink Lady brand name as long as they meet the minimum quality requirement of being 40% pink. Three such strains are the Rosy Glow, The Ruby Pink and the Lady in Red. The Rosy Glow apple was discovered in an orchard of Cripps Pink trees that had been planted in South Australia in 1996. One limb of a Cripps Pink tree had red-coloured apples while the rest of the limbs bore mostly green fruit. A bud was taken from the mutated branch and grafted onto rootstock to produce the new variety. The fruit from the new Rosy Glow tree was the same colour over the entire tree and a patent for this unique apple was granted in 2003. The Rosy Glow apple benefits from a larger area of pink than the Pink Lady and it ripens earlier in the season in climates that have less hours of sunshine. As a consequence, the Cripps Pink is likely to be phased out in favour of the Rosy Glow, with the apples branded as Pink LadyTM if they have 40% or more pink coverage. Ruby Pink and Lady in Red are two mutations of the Cripps Pink that were dis covered in New Zealand. Like the Rosy Glow, these improved varieties develop a larger area of pink than the Cripps Pink, which allows more apples to meet the quality requirements of the Pink LadyTM brand. Planting of these trees may need to be controlled otherwise the supply of Pink Lady apples will exceed the demand, to then threaten the price premium. Overproduction apart, the future of what has become possibly the worlds best-known modern apple and fruit brand, looks secure.", "hypothesis": "Pink Lady apples are the highest grade of Cripps Pink apples.", "gold_label": "entailment"}
{"uid": "id_26", "premise": "Tickled pink In 1973, the Australian fruit breeder John Cripps created a new variety of apple tree by crossing a red Australian Lady Williams variety with a pale-green American Golden Delicious. The offspring first fruited in 1979 and combined the best features of its parents in an apple that had an attractive pink hue on a yellow undertone. The new, improved apple was named the Cripps Pink after its inventor. Today the Cripps Pink is one of the most popular varieties of apple and is grown extensively in Australia, New Zealand, Canada, France and in California and Washington in the USA. By switching from northern hemisphere fruit to southern hemisphere fruit the apple is available at its seasonal best all year round. The highest-quality apples are marketed worldwide under the trademark Pink LadyTM. To preserve the premium price and appeal of the Pink Lady, apples that fail to meet the highest standards are sold under the name Cripps PinkTM. These standards are based on colour and flavour, in particular, the extent of the pink coverage and the sugar/acid balance. Consumers who buy a Pink Lady apple are ensured a product that is of consistently high quality. To earn the name Pink Lady the skin of a Cripps Pink apple must be at least 40% pink. Strong sunlight increases the pink coloration and it may be necessary to remove the uppermost leaves of a tree to let the light through. The extra work required to cultivate Cripps Pink trees is offset by its advantages, which include: vigorous trees; fruit that has tolerance to sunburn; a thin skin that does not crack; flesh that is resistant to browning after being cut and exposed to air; a cold-storage life of up to six months and a retail shelf-life of about four weeks. However, the main advantage for apple growers is the premium price that the Pink Lady brand is able to command. The Cripps Red variety, also known as Cripps II, is related to the Pink Lady and was developed at the same time. The premium grade is marketed as the Sun downerTM. Unlike the genuinely pink Pink Lady, the SundownerTM is a classic bi- coloured apple, with a skin that is 45% red from Lady Williams and 55% green from Golden Delicious. Apples that fall outside of this colour ratio are rejected at the packing station and used for juice, whilst the smaller apples are retained for the home market. The Sundowner is harvested after Cripps Pink in late May or early June, and a few weeks before Lady Williams. It has better cold-storage properties than Cripps Pink and it retains an excellent shelf life. Cripps Red apples have a coarser texture than Cripps Pink, are less sweet and have a stronger flavour. Both apples are sweeter than Lady Williams but neither is as sweet as Golden Delicious. The advantage of the Pink LadyTM brand is that it is a trademark of a premium product, not just a Cripps Pink apple. This means that new and improved strains of the Cripps Pink can use the Pink Lady brand name as long as they meet the minimum quality requirement of being 40% pink. Three such strains are the Rosy Glow, The Ruby Pink and the Lady in Red. The Rosy Glow apple was discovered in an orchard of Cripps Pink trees that had been planted in South Australia in 1996. One limb of a Cripps Pink tree had red-coloured apples while the rest of the limbs bore mostly green fruit. A bud was taken from the mutated branch and grafted onto rootstock to produce the new variety. The fruit from the new Rosy Glow tree was the same colour over the entire tree and a patent for this unique apple was granted in 2003. The Rosy Glow apple benefits from a larger area of pink than the Pink Lady and it ripens earlier in the season in climates that have less hours of sunshine. As a consequence, the Cripps Pink is likely to be phased out in favour of the Rosy Glow, with the apples branded as Pink LadyTM if they have 40% or more pink coverage. Ruby Pink and Lady in Red are two mutations of the Cripps Pink that were dis covered in New Zealand. Like the Rosy Glow, these improved varieties develop a larger area of pink than the Cripps Pink, which allows more apples to meet the quality requirements of the Pink LadyTM brand. Planting of these trees may need to be controlled otherwise the supply of Pink Lady apples will exceed the demand, to then threaten the price premium. Overproduction apart, the future of what has become possibly the worlds best-known modern apple and fruit brand, looks secure.", "hypothesis": "Cripps Pink trees produce an abundance of fruit.", "gold_label": "neutral"}
{"uid": "id_27", "premise": "Tickled pink In 1973, the Australian fruit breeder John Cripps created a new variety of apple tree by crossing a red Australian Lady Williams variety with a pale-green American Golden Delicious. The offspring first fruited in 1979 and combined the best features of its parents in an apple that had an attractive pink hue on a yellow undertone. The new, improved apple was named the Cripps Pink after its inventor. Today the Cripps Pink is one of the most popular varieties of apple and is grown extensively in Australia, New Zealand, Canada, France and in California and Washington in the USA. By switching from northern hemisphere fruit to southern hemisphere fruit the apple is available at its seasonal best all year round. The highest-quality apples are marketed worldwide under the trademark Pink LadyTM. To preserve the premium price and appeal of the Pink Lady, apples that fail to meet the highest standards are sold under the name Cripps PinkTM. These standards are based on colour and flavour, in particular, the extent of the pink coverage and the sugar/acid balance. Consumers who buy a Pink Lady apple are ensured a product that is of consistently high quality. To earn the name Pink Lady the skin of a Cripps Pink apple must be at least 40% pink. Strong sunlight increases the pink coloration and it may be necessary to remove the uppermost leaves of a tree to let the light through. The extra work required to cultivate Cripps Pink trees is offset by its advantages, which include: vigorous trees; fruit that has tolerance to sunburn; a thin skin that does not crack; flesh that is resistant to browning after being cut and exposed to air; a cold-storage life of up to six months and a retail shelf-life of about four weeks. However, the main advantage for apple growers is the premium price that the Pink Lady brand is able to command. The Cripps Red variety, also known as Cripps II, is related to the Pink Lady and was developed at the same time. The premium grade is marketed as the Sun downerTM. Unlike the genuinely pink Pink Lady, the SundownerTM is a classic bi- coloured apple, with a skin that is 45% red from Lady Williams and 55% green from Golden Delicious. Apples that fall outside of this colour ratio are rejected at the packing station and used for juice, whilst the smaller apples are retained for the home market. The Sundowner is harvested after Cripps Pink in late May or early June, and a few weeks before Lady Williams. It has better cold-storage properties than Cripps Pink and it retains an excellent shelf life. Cripps Red apples have a coarser texture than Cripps Pink, are less sweet and have a stronger flavour. Both apples are sweeter than Lady Williams but neither is as sweet as Golden Delicious. The advantage of the Pink LadyTM brand is that it is a trademark of a premium product, not just a Cripps Pink apple. This means that new and improved strains of the Cripps Pink can use the Pink Lady brand name as long as they meet the minimum quality requirement of being 40% pink. Three such strains are the Rosy Glow, The Ruby Pink and the Lady in Red. The Rosy Glow apple was discovered in an orchard of Cripps Pink trees that had been planted in South Australia in 1996. One limb of a Cripps Pink tree had red-coloured apples while the rest of the limbs bore mostly green fruit. A bud was taken from the mutated branch and grafted onto rootstock to produce the new variety. The fruit from the new Rosy Glow tree was the same colour over the entire tree and a patent for this unique apple was granted in 2003. The Rosy Glow apple benefits from a larger area of pink than the Pink Lady and it ripens earlier in the season in climates that have less hours of sunshine. As a consequence, the Cripps Pink is likely to be phased out in favour of the Rosy Glow, with the apples branded as Pink LadyTM if they have 40% or more pink coverage. Ruby Pink and Lady in Red are two mutations of the Cripps Pink that were dis covered in New Zealand. Like the Rosy Glow, these improved varieties develop a larger area of pink than the Cripps Pink, which allows more apples to meet the quality requirements of the Pink LadyTM brand. Planting of these trees may need to be controlled otherwise the supply of Pink Lady apples will exceed the demand, to then threaten the price premium. Overproduction apart, the future of what has become possibly the worlds best-known modern apple and fruit brand, looks secure.", "hypothesis": "Pink Lady apples are less expensive to buy than Cripps Pink apples.", "gold_label": "contradiction"}
{"uid": "id_28", "premise": "Tickled pink In 1973, the Australian fruit breeder John Cripps created a new variety of apple tree by crossing a red Australian Lady Williams variety with a pale-green American Golden Delicious. The offspring first fruited in 1979 and combined the best features of its parents in an apple that had an attractive pink hue on a yellow undertone. The new, improved apple was named the Cripps Pink after its inventor. Today the Cripps Pink is one of the most popular varieties of apple and is grown extensively in Australia, New Zealand, Canada, France and in California and Washington in the USA. By switching from northern hemisphere fruit to southern hemisphere fruit the apple is available at its seasonal best all year round. The highest-quality apples are marketed worldwide under the trademark Pink LadyTM. To preserve the premium price and appeal of the Pink Lady, apples that fail to meet the highest standards are sold under the name Cripps PinkTM. These standards are based on colour and flavour, in particular, the extent of the pink coverage and the sugar/acid balance. Consumers who buy a Pink Lady apple are ensured a product that is of consistently high quality. To earn the name Pink Lady the skin of a Cripps Pink apple must be at least 40% pink. Strong sunlight increases the pink coloration and it may be necessary to remove the uppermost leaves of a tree to let the light through. The extra work required to cultivate Cripps Pink trees is offset by its advantages, which include: vigorous trees; fruit that has tolerance to sunburn; a thin skin that does not crack; flesh that is resistant to browning after being cut and exposed to air; a cold-storage life of up to six months and a retail shelf-life of about four weeks. However, the main advantage for apple growers is the premium price that the Pink Lady brand is able to command. The Cripps Red variety, also known as Cripps II, is related to the Pink Lady and was developed at the same time. The premium grade is marketed as the Sun downerTM. Unlike the genuinely pink Pink Lady, the SundownerTM is a classic bi- coloured apple, with a skin that is 45% red from Lady Williams and 55% green from Golden Delicious. Apples that fall outside of this colour ratio are rejected at the packing station and used for juice, whilst the smaller apples are retained for the home market. The Sundowner is harvested after Cripps Pink in late May or early June, and a few weeks before Lady Williams. It has better cold-storage properties than Cripps Pink and it retains an excellent shelf life. Cripps Red apples have a coarser texture than Cripps Pink, are less sweet and have a stronger flavour. Both apples are sweeter than Lady Williams but neither is as sweet as Golden Delicious. The advantage of the Pink LadyTM brand is that it is a trademark of a premium product, not just a Cripps Pink apple. This means that new and improved strains of the Cripps Pink can use the Pink Lady brand name as long as they meet the minimum quality requirement of being 40% pink. Three such strains are the Rosy Glow, The Ruby Pink and the Lady in Red. The Rosy Glow apple was discovered in an orchard of Cripps Pink trees that had been planted in South Australia in 1996. One limb of a Cripps Pink tree had red-coloured apples while the rest of the limbs bore mostly green fruit. A bud was taken from the mutated branch and grafted onto rootstock to produce the new variety. The fruit from the new Rosy Glow tree was the same colour over the entire tree and a patent for this unique apple was granted in 2003. The Rosy Glow apple benefits from a larger area of pink than the Pink Lady and it ripens earlier in the season in climates that have less hours of sunshine. As a consequence, the Cripps Pink is likely to be phased out in favour of the Rosy Glow, with the apples branded as Pink LadyTM if they have 40% or more pink coverage. Ruby Pink and Lady in Red are two mutations of the Cripps Pink that were dis covered in New Zealand. Like the Rosy Glow, these improved varieties develop a larger area of pink than the Cripps Pink, which allows more apples to meet the quality requirements of the Pink LadyTM brand. Planting of these trees may need to be controlled otherwise the supply of Pink Lady apples will exceed the demand, to then threaten the price premium. Overproduction apart, the future of what has become possibly the worlds best-known modern apple and fruit brand, looks secure.", "hypothesis": "Lady Williams apples are sweeter than Golden Delicious.", "gold_label": "contradiction"}
{"uid": "id_29", "premise": "Time and temperature Food poisoning is still prevalent in the UK, with more than 90,000 reported cases in 2007, though unreported cases could be as much as 10 times higher, because most people with mild symptoms fail to report the incident. Millions of bacteria are needed to produce food poisoning. Under favourable conditions, rapid multiplication takes place by binary fission every 10 to 20 minutes. Pathogenic bacteria can grow at temperatures as low as 5 C and as high as 63 C; food kept in this danger zone should never be reheated. Fridges and cold stores at 1 to 4 C stop the multiplication of pathogenic bacteria but not of food spoilage bacteria. The latter can continue to grow at temperatures as low as minus 18 C, below which they remain dormant. Bacteria are not destroyed by freezing and can multiply again after the food thaws out. Campylobacter is responsible for most of the food poisoning in the UK, with about four times as many cases as occur with Salmonella. Campylobacter is also referred to as a food-borne disease because it remains dormant at room temperature but multiplies rapidly at body temperature (37 C); it is destroyed at temperatures above 48 C. Most cases of Salmonella food poisoning are caused by storing prepared food at room temperature. Salmonella is quickly destroyed at temperatures above 74 C. Other food-borne pathogens include Listeria, E. coli and Clostridium perfringens, which is spore forming and can survive cooking. Both Campylobacter and Salmonella are associated with raw meat, poultry, eggs and unpasteurised milk. Examples of cross-contamination include kitchen staff failing to wash their hands when taking eggs out of the fridge, a drop of juice from a fresh chicken at the top of the fridge contaminating cooked foods below, and using the same chopping board to prepare meat and vegetables. Spread is not normally from person to person.", "hypothesis": "A single cell of Campylobacter can multiply to more than 1,000 bacteria in less than two hours on food at room temperature.", "gold_label": "contradiction"}
{"uid": "id_30", "premise": "Time and temperature Food poisoning is still prevalent in the UK, with more than 90,000 reported cases in 2007, though unreported cases could be as much as 10 times higher, because most people with mild symptoms fail to report the incident. Millions of bacteria are needed to produce food poisoning. Under favourable conditions, rapid multiplication takes place by binary fission every 10 to 20 minutes. Pathogenic bacteria can grow at temperatures as low as 5 C and as high as 63 C; food kept in this danger zone should never be reheated. Fridges and cold stores at 1 to 4 C stop the multiplication of pathogenic bacteria but not of food spoilage bacteria. The latter can continue to grow at temperatures as low as minus 18 C, below which they remain dormant. Bacteria are not destroyed by freezing and can multiply again after the food thaws out. Campylobacter is responsible for most of the food poisoning in the UK, with about four times as many cases as occur with Salmonella. Campylobacter is also referred to as a food-borne disease because it remains dormant at room temperature but multiplies rapidly at body temperature (37 C); it is destroyed at temperatures above 48 C. Most cases of Salmonella food poisoning are caused by storing prepared food at room temperature. Salmonella is quickly destroyed at temperatures above 74 C. Other food-borne pathogens include Listeria, E. coli and Clostridium perfringens, which is spore forming and can survive cooking. Both Campylobacter and Salmonella are associated with raw meat, poultry, eggs and unpasteurised milk. Examples of cross-contamination include kitchen staff failing to wash their hands when taking eggs out of the fridge, a drop of juice from a fresh chicken at the top of the fridge contaminating cooked foods below, and using the same chopping board to prepare meat and vegetables. Spread is not normally from person to person.", "hypothesis": "The ingestion of a small number of Campylobacter cells could make you ill.", "gold_label": "entailment"}
{"uid": "id_31", "premise": "Time and temperature Food poisoning is still prevalent in the UK, with more than 90,000 reported cases in 2007, though unreported cases could be as much as 10 times higher, because most people with mild symptoms fail to report the incident. Millions of bacteria are needed to produce food poisoning. Under favourable conditions, rapid multiplication takes place by binary fission every 10 to 20 minutes. Pathogenic bacteria can grow at temperatures as low as 5 C and as high as 63 C; food kept in this danger zone should never be reheated. Fridges and cold stores at 1 to 4 C stop the multiplication of pathogenic bacteria but not of food spoilage bacteria. The latter can continue to grow at temperatures as low as minus 18 C, below which they remain dormant. Bacteria are not destroyed by freezing and can multiply again after the food thaws out. Campylobacter is responsible for most of the food poisoning in the UK, with about four times as many cases as occur with Salmonella. Campylobacter is also referred to as a food-borne disease because it remains dormant at room temperature but multiplies rapidly at body temperature (37 C); it is destroyed at temperatures above 48 C. Most cases of Salmonella food poisoning are caused by storing prepared food at room temperature. Salmonella is quickly destroyed at temperatures above 74 C. Other food-borne pathogens include Listeria, E. coli and Clostridium perfringens, which is spore forming and can survive cooking. Both Campylobacter and Salmonella are associated with raw meat, poultry, eggs and unpasteurised milk. Examples of cross-contamination include kitchen staff failing to wash their hands when taking eggs out of the fridge, a drop of juice from a fresh chicken at the top of the fridge contaminating cooked foods below, and using the same chopping board to prepare meat and vegetables. Spread is not normally from person to person.", "hypothesis": "Heating food to 75 C will destroy most bacteria responsible for food poisoning in the UK.", "gold_label": "entailment"}
{"uid": "id_32", "premise": "Time and temperature Food poisoning is still prevalent in the UK, with more than 90,000 reported cases in 2007, though unreported cases could be as much as 10 times higher, because most people with mild symptoms fail to report the incident. Millions of bacteria are needed to produce food poisoning. Under favourable conditions, rapid multiplication takes place by binary fission every 10 to 20 minutes. Pathogenic bacteria can grow at temperatures as low as 5 C and as high as 63 C; food kept in this danger zone should never be reheated. Fridges and cold stores at 1 to 4 C stop the multiplication of pathogenic bacteria but not of food spoilage bacteria. The latter can continue to grow at temperatures as low as minus 18 C, below which they remain dormant. Bacteria are not destroyed by freezing and can multiply again after the food thaws out. Campylobacter is responsible for most of the food poisoning in the UK, with about four times as many cases as occur with Salmonella. Campylobacter is also referred to as a food-borne disease because it remains dormant at room temperature but multiplies rapidly at body temperature (37 C); it is destroyed at temperatures above 48 C. Most cases of Salmonella food poisoning are caused by storing prepared food at room temperature. Salmonella is quickly destroyed at temperatures above 74 C. Other food-borne pathogens include Listeria, E. coli and Clostridium perfringens, which is spore forming and can survive cooking. Both Campylobacter and Salmonella are associated with raw meat, poultry, eggs and unpasteurised milk. Examples of cross-contamination include kitchen staff failing to wash their hands when taking eggs out of the fridge, a drop of juice from a fresh chicken at the top of the fridge contaminating cooked foods below, and using the same chopping board to prepare meat and vegetables. Spread is not normally from person to person.", "hypothesis": "Pathogenic and food spoilage bacteria remain dormant below minus 18 C.", "gold_label": "entailment"}
{"uid": "id_33", "premise": "Time to cool it REFRIGERATORS are the epitome of clunky technology: solid, reliable and just a little bit dull. They have not changed much over the past century, but then they have not needed to. They are based on a robust and effective idea--draw heat from the thing you want to cool by evaporating a liquid next to it, and then dump that heat by pumping the vapour elsewhere and condensing it. This method of pumping heat from one place to another served mankind well when refrigerators' main jobs were preserving food and, as air conditioners, cooling buildings. Today's high-tech world, however, demands high-tech refrigeration. Heat pumps are no longer up to the job. The search is on for something to replace them. One set of candidates are known as paraelectric materials. These act like batteries when they undergo a temperature change: attach electrodes to them and they generate a current. This effect is used in infra-red cameras. An array of tiny pieces of paraelectric material can sense the heat radiated by, for example, a person, and the pattern of the array's electrical outputs can then be used to construct an image. But until recently no one had bothered much with the inverse of this process. That inverse exists, however. Apply an appropriate current to a paraelectric material and it will cool down. Someone who is looking at this inverse effect is Alex Mischenko, of Cambridge University. Using commercially available paraelectric film, he and his colleagues have generated temperature drops five times bigger than any previously recorded. That may be enough to change the phenomenon from a laboratory curiosity to something with commercial applications. As to what those applications might be, Dr Mischenko is still a little hazy. He has, nevertheless, set up a company to pursue them. He foresees putting his discovery to use in more efficient domestic fridges and air conditioners. The real money, though, may be in cooling computers. Gadgets containing microprocessors have been getting hotter for a long time. One consequence of Moore's Law, which describes the doubling of the number of transistors on a chip every 18 months, is that the amount of heat produced doubles as well. In fact, it more than doubles, because besides increasing in number, the components are getting faster. Heat is released every time a logical operation is performed inside a microprocessor, so the faster the processor is, the more heat it generates. Doubling the frequency quadruples the heat output. And the frequency has doubled a lot. The first Pentium chips sold by Dr Moore's company, Intel, in 1993, ran at 60m cycles a second. The Pentium 4--the last \"single-core\" desktop processor--clocked up 3.2 billion cycles a second. Disposing of this heat is a big obstruction to further miniaturisation and higher speeds. The innards of a desktop computer commonly hit 80C. At 85C, they stop working. Tweaking the processor's heat sinks (copper or aluminium boxes designed to radiate heat away) has reached its limit. So has tweaking the fans that circulate air over those heat sinks. And the idea of shifting from single-core processors to systems that divided processing power between first two, and then four, subunits, in order to spread the thermal load, also seems to have the end of the road in sight. One way out of this may be a second curious physical phenomenon, the thermoelectric effect. Like paraelectric materials, this generates electricity from a heat source and produces cooling from an electrical source. Unlike paraelectrics, a significant body of researchers is already working on it. The trick to a good thermoelectric material is a crystal structure in which electrons can flow freely, but the path of phonons--heat-carrying vibrations that are larger than electrons--is constantly interrupted. In practice, this trick is hard to pull off, and thermoelectric materials are thus less efficient than paraelectric ones (or, at least, than those examined by Dr Mischenko). Nevertheless, Rama Venkatasubramanian, of Nextreme Thermal Solutions in North Carolina, claims to have made thermoelectric refrigerators that can sit on the back of computer chips and cool hotspots by 10C. Ali Shakouri, of the University of California, Santa Cruz, says his are even smaller--so small that they can go inside the chip. The last word in computer cooling, though, may go to a system even less techy than a heat pump--a miniature version of a car radiator. Last year Apple launched a personal computer that is cooled by liquid that is pumped through little channels in the processor, and thence to a radiator, where it gives up its heat to the atmosphere. To improve on this, IBM's research laboratory in Zurich is experimenting with tiny jets that stir the liquid up and thus make sure all of it eventually touches the outside of the channel--the part where the heat exchange takes place. In the future, therefore, a combination of microchannels and either thermoelectrics or paraelectrics might cool computers. The old, as it were, hand in hand with the new.", "hypothesis": "IBM will achieve better computer cooling by combining microchannels with paraelectrics.", "gold_label": "neutral"}
{"uid": "id_34", "premise": "Time to cool it REFRIGERATORS are the epitome of clunky technology: solid, reliable and just a little bit dull. They have not changed much over the past century, but then they have not needed to. They are based on a robust and effective idea--draw heat from the thing you want to cool by evaporating a liquid next to it, and then dump that heat by pumping the vapour elsewhere and condensing it. This method of pumping heat from one place to another served mankind well when refrigerators' main jobs were preserving food and, as air conditioners, cooling buildings. Today's high-tech world, however, demands high-tech refrigeration. Heat pumps are no longer up to the job. The search is on for something to replace them. One set of candidates are known as paraelectric materials. These act like batteries when they undergo a temperature change: attach electrodes to them and they generate a current. This effect is used in infra-red cameras. An array of tiny pieces of paraelectric material can sense the heat radiated by, for example, a person, and the pattern of the array's electrical outputs can then be used to construct an image. But until recently no one had bothered much with the inverse of this process. That inverse exists, however. Apply an appropriate current to a paraelectric material and it will cool down. Someone who is looking at this inverse effect is Alex Mischenko, of Cambridge University. Using commercially available paraelectric film, he and his colleagues have generated temperature drops five times bigger than any previously recorded. That may be enough to change the phenomenon from a laboratory curiosity to something with commercial applications. As to what those applications might be, Dr Mischenko is still a little hazy. He has, nevertheless, set up a company to pursue them. He foresees putting his discovery to use in more efficient domestic fridges and air conditioners. The real money, though, may be in cooling computers. Gadgets containing microprocessors have been getting hotter for a long time. One consequence of Moore's Law, which describes the doubling of the number of transistors on a chip every 18 months, is that the amount of heat produced doubles as well. In fact, it more than doubles, because besides increasing in number, the components are getting faster. Heat is released every time a logical operation is performed inside a microprocessor, so the faster the processor is, the more heat it generates. Doubling the frequency quadruples the heat output. And the frequency has doubled a lot. The first Pentium chips sold by Dr Moore's company, Intel, in 1993, ran at 60m cycles a second. The Pentium 4--the last \"single-core\" desktop processor--clocked up 3.2 billion cycles a second. Disposing of this heat is a big obstruction to further miniaturisation and higher speeds. The innards of a desktop computer commonly hit 80C. At 85C, they stop working. Tweaking the processor's heat sinks (copper or aluminium boxes designed to radiate heat away) has reached its limit. So has tweaking the fans that circulate air over those heat sinks. And the idea of shifting from single-core processors to systems that divided processing power between first two, and then four, subunits, in order to spread the thermal load, also seems to have the end of the road in sight. One way out of this may be a second curious physical phenomenon, the thermoelectric effect. Like paraelectric materials, this generates electricity from a heat source and produces cooling from an electrical source. Unlike paraelectrics, a significant body of researchers is already working on it. The trick to a good thermoelectric material is a crystal structure in which electrons can flow freely, but the path of phonons--heat-carrying vibrations that are larger than electrons--is constantly interrupted. In practice, this trick is hard to pull off, and thermoelectric materials are thus less efficient than paraelectric ones (or, at least, than those examined by Dr Mischenko). Nevertheless, Rama Venkatasubramanian, of Nextreme Thermal Solutions in North Carolina, claims to have made thermoelectric refrigerators that can sit on the back of computer chips and cool hotspots by 10C. Ali Shakouri, of the University of California, Santa Cruz, says his are even smaller--so small that they can go inside the chip. The last word in computer cooling, though, may go to a system even less techy than a heat pump--a miniature version of a car radiator. Last year Apple launched a personal computer that is cooled by liquid that is pumped through little channels in the processor, and thence to a radiator, where it gives up its heat to the atmosphere. To improve on this, IBM's research laboratory in Zurich is experimenting with tiny jets that stir the liquid up and thus make sure all of it eventually touches the outside of the channel--the part where the heat exchange takes place. In the future, therefore, a combination of microchannels and either thermoelectrics or paraelectrics might cool computers. The old, as it were, hand in hand with the new.", "hypothesis": "Dr. Mischenko has successfully applied his laboratory discovery to manufacturing more efficient referigerators.", "gold_label": "contradiction"}
{"uid": "id_35", "premise": "Time to cool it REFRIGERATORS are the epitome of clunky technology: solid, reliable and just a little bit dull. They have not changed much over the past century, but then they have not needed to. They are based on a robust and effective idea--draw heat from the thing you want to cool by evaporating a liquid next to it, and then dump that heat by pumping the vapour elsewhere and condensing it. This method of pumping heat from one place to another served mankind well when refrigerators' main jobs were preserving food and, as air conditioners, cooling buildings. Today's high-tech world, however, demands high-tech refrigeration. Heat pumps are no longer up to the job. The search is on for something to replace them. One set of candidates are known as paraelectric materials. These act like batteries when they undergo a temperature change: attach electrodes to them and they generate a current. This effect is used in infra-red cameras. An array of tiny pieces of paraelectric material can sense the heat radiated by, for example, a person, and the pattern of the array's electrical outputs can then be used to construct an image. But until recently no one had bothered much with the inverse of this process. That inverse exists, however. Apply an appropriate current to a paraelectric material and it will cool down. Someone who is looking at this inverse effect is Alex Mischenko, of Cambridge University. Using commercially available paraelectric film, he and his colleagues have generated temperature drops five times bigger than any previously recorded. That may be enough to change the phenomenon from a laboratory curiosity to something with commercial applications. As to what those applications might be, Dr Mischenko is still a little hazy. He has, nevertheless, set up a company to pursue them. He foresees putting his discovery to use in more efficient domestic fridges and air conditioners. The real money, though, may be in cooling computers. Gadgets containing microprocessors have been getting hotter for a long time. One consequence of Moore's Law, which describes the doubling of the number of transistors on a chip every 18 months, is that the amount of heat produced doubles as well. In fact, it more than doubles, because besides increasing in number, the components are getting faster. Heat is released every time a logical operation is performed inside a microprocessor, so the faster the processor is, the more heat it generates. Doubling the frequency quadruples the heat output. And the frequency has doubled a lot. The first Pentium chips sold by Dr Moore's company, Intel, in 1993, ran at 60m cycles a second. The Pentium 4--the last \"single-core\" desktop processor--clocked up 3.2 billion cycles a second. Disposing of this heat is a big obstruction to further miniaturisation and higher speeds. The innards of a desktop computer commonly hit 80C. At 85C, they stop working. Tweaking the processor's heat sinks (copper or aluminium boxes designed to radiate heat away) has reached its limit. So has tweaking the fans that circulate air over those heat sinks. And the idea of shifting from single-core processors to systems that divided processing power between first two, and then four, subunits, in order to spread the thermal load, also seems to have the end of the road in sight. One way out of this may be a second curious physical phenomenon, the thermoelectric effect. Like paraelectric materials, this generates electricity from a heat source and produces cooling from an electrical source. Unlike paraelectrics, a significant body of researchers is already working on it. The trick to a good thermoelectric material is a crystal structure in which electrons can flow freely, but the path of phonons--heat-carrying vibrations that are larger than electrons--is constantly interrupted. In practice, this trick is hard to pull off, and thermoelectric materials are thus less efficient than paraelectric ones (or, at least, than those examined by Dr Mischenko). Nevertheless, Rama Venkatasubramanian, of Nextreme Thermal Solutions in North Carolina, claims to have made thermoelectric refrigerators that can sit on the back of computer chips and cool hotspots by 10C. Ali Shakouri, of the University of California, Santa Cruz, says his are even smaller--so small that they can go inside the chip. The last word in computer cooling, though, may go to a system even less techy than a heat pump--a miniature version of a car radiator. Last year Apple launched a personal computer that is cooled by liquid that is pumped through little channels in the processor, and thence to a radiator, where it gives up its heat to the atmosphere. To improve on this, IBM's research laboratory in Zurich is experimenting with tiny jets that stir the liquid up and thus make sure all of it eventually touches the outside of the channel--the part where the heat exchange takes place. In the future, therefore, a combination of microchannels and either thermoelectrics or paraelectrics might cool computers. The old, as it were, hand in hand with the new.", "hypothesis": "Doubling the frequency of logical operations inside a microprocessor doubles the heat output.", "gold_label": "contradiction"}
{"uid": "id_36", "premise": "Time to cool it REFRIGERATORS are the epitome of clunky technology: solid, reliable and just a little bit dull. They have not changed much over the past century, but then they have not needed to. They are based on a robust and effective idea--draw heat from the thing you want to cool by evaporating a liquid next to it, and then dump that heat by pumping the vapour elsewhere and condensing it. This method of pumping heat from one place to another served mankind well when refrigerators' main jobs were preserving food and, as air conditioners, cooling buildings. Today's high-tech world, however, demands high-tech refrigeration. Heat pumps are no longer up to the job. The search is on for something to replace them. One set of candidates are known as paraelectric materials. These act like batteries when they undergo a temperature change: attach electrodes to them and they generate a current. This effect is used in infra-red cameras. An array of tiny pieces of paraelectric material can sense the heat radiated by, for example, a person, and the pattern of the array's electrical outputs can then be used to construct an image. But until recently no one had bothered much with the inverse of this process. That inverse exists, however. Apply an appropriate current to a paraelectric material and it will cool down. Someone who is looking at this inverse effect is Alex Mischenko, of Cambridge University. Using commercially available paraelectric film, he and his colleagues have generated temperature drops five times bigger than any previously recorded. That may be enough to change the phenomenon from a laboratory curiosity to something with commercial applications. As to what those applications might be, Dr Mischenko is still a little hazy. He has, nevertheless, set up a company to pursue them. He foresees putting his discovery to use in more efficient domestic fridges and air conditioners. The real money, though, may be in cooling computers. Gadgets containing microprocessors have been getting hotter for a long time. One consequence of Moore's Law, which describes the doubling of the number of transistors on a chip every 18 months, is that the amount of heat produced doubles as well. In fact, it more than doubles, because besides increasing in number, the components are getting faster. Heat is released every time a logical operation is performed inside a microprocessor, so the faster the processor is, the more heat it generates. Doubling the frequency quadruples the heat output. And the frequency has doubled a lot. The first Pentium chips sold by Dr Moore's company, Intel, in 1993, ran at 60m cycles a second. The Pentium 4--the last \"single-core\" desktop processor--clocked up 3.2 billion cycles a second. Disposing of this heat is a big obstruction to further miniaturisation and higher speeds. The innards of a desktop computer commonly hit 80C. At 85C, they stop working. Tweaking the processor's heat sinks (copper or aluminium boxes designed to radiate heat away) has reached its limit. So has tweaking the fans that circulate air over those heat sinks. And the idea of shifting from single-core processors to systems that divided processing power between first two, and then four, subunits, in order to spread the thermal load, also seems to have the end of the road in sight. One way out of this may be a second curious physical phenomenon, the thermoelectric effect. Like paraelectric materials, this generates electricity from a heat source and produces cooling from an electrical source. Unlike paraelectrics, a significant body of researchers is already working on it. The trick to a good thermoelectric material is a crystal structure in which electrons can flow freely, but the path of phonons--heat-carrying vibrations that are larger than electrons--is constantly interrupted. In practice, this trick is hard to pull off, and thermoelectric materials are thus less efficient than paraelectric ones (or, at least, than those examined by Dr Mischenko). Nevertheless, Rama Venkatasubramanian, of Nextreme Thermal Solutions in North Carolina, claims to have made thermoelectric refrigerators that can sit on the back of computer chips and cool hotspots by 10C. Ali Shakouri, of the University of California, Santa Cruz, says his are even smaller--so small that they can go inside the chip. The last word in computer cooling, though, may go to a system even less techy than a heat pump--a miniature version of a car radiator. Last year Apple launched a personal computer that is cooled by liquid that is pumped through little channels in the processor, and thence to a radiator, where it gives up its heat to the atmosphere. To improve on this, IBM's research laboratory in Zurich is experimenting with tiny jets that stir the liquid up and thus make sure all of it eventually touches the outside of the channel--the part where the heat exchange takes place. In the future, therefore, a combination of microchannels and either thermoelectrics or paraelectrics might cool computers. The old, as it were, hand in hand with the new.", "hypothesis": "Paraelectric materials can generate a current when electrodes are attached to them.", "gold_label": "entailment"}
{"uid": "id_37", "premise": "Timekeeper 2 Invention of Marine Chronometer It was, as Dava Sobel has described a phenomenon: the greatest scientific problem of the age. The reality was that in the 18th century no one had ever made a clock that could suffer the great rolling and pitching of a ship and the large changes in temperature whilst still keeping time accurately enough to be of any use. Indeed, most of the scientific community thought such clock impossibility. Knowing one's position on the earth requires two very simple but essential coordinates; rather like using a street map where one thinks in terms of how far one is up/down and how far side to side. The longitude is a measure of how far around the world one has come from home and has no naturally occurring base line like the equator. The crew of a given ship was naturally only concerned with how far round they were from their own particular home base. Even when in the middle of the ocean, with no land in sight, knowing this longitude position is very simple in theory. The key to knowing how far around the world you are from home is to know, at that very moment, what time it is back home. A comparison with your local time (easily found by checking the position of the Sim) will then tell you the time difference between you and home, and thus how far round the Earth you are from home. Up until the middle of the 18th century, navigators hadbeen unable to determine their position at sea with accuracy and they faced the huge attendant risks of shipwreck or running out of supplies before reaching then destination. The angular position of Moon and other bright stars was recorded in three-hour intervals of Greenwich Time. In order to determine longitude, sailors had to measure the angle between Moon centre and a given star - lunar distance - together with height of both planets using the naval sextant. The sailors also had to calculate the Moons position if seen form the centre of Earth. Time corresponding to Greenwich Time was determined using the nautical almanac. Then the difference between the obtained time and local time served for calculation in longitude from Greenwich. The great flaw in this simple theory was - how does the sailor know time back home when he is in the middle of an ocean? The obvious and again simple answer is that he takes an accurate clock with him, which he sets to home time before leaving. All he has to do is keep it wound up and running, and he must never reset the hands throughout the voyage This clock then provides home time, so if, for example, it is midday on board your ship and your home time clock says that at that same moment it is midnight at home, you know immediately there is a twelve hour time-difference and you must be exactly round the other side of the world, 180 degrees of longitude from home. After 1714 when the British government offered the huge sum of 20,000 for a solution to the problem, with the prize to be administered by die splendidly titled Board of Longitude. The Government prize of 20,000 was the highest of three sums on offer for varying degrees of accuracy, the full prize only payable for a method that could find the longitude at sea within half a degree. If the solution was to be by timekeeper (and there were other methods since the prize was offered for any solution to the problem), then the timekeeping required to achieve this goal would have to be within 2.8 seconds a day, a performance considered impossible for any clock at sea and unthinkable for a watch, even under the very best conditions. It was this prize, worth about 2 million today, which inspired the self-taught Yorkshfre carpenter, John Harrison, to attempt a design for a practical marineclock. During the latter part of his early career, he worked with his younger brother James. Their first major project was a revolutionary turret clock for the stables at Brocklesby Park, seat of the Pelham family. The clock was revolutionary because it required no lubrication. 18th century clock oils were uniformly poor and one of the major causes of failure in clocks of the period. Rather than concentrating on improvements to the oil, Harrison designed a clock which didn't need it. In 1730 Harrison created a description and drawings for a proposed marine clock to compete for the Longitude Prize and went to London seeking financial assistance. He presented his ideas to Edmond Halley, the Astronomer Royal. Halley referred him to George Graham, the country's foremost clockmaker. He must have been impressed by Harrison, for Graham personally loaned Harrison money to build a model of his marine clock. It took Harrison five years to build Harrison Number One or HI. He demonstrated it to members of the Royal Society who spoke on his behalf to the Board of Longitude. The clock was the first proposal that the Board considered to be worthy of a sea trial. In 1736, After several attempts to design a betterment of HI, Harrison believed that the ' solution to the longitude problem lay in an entirely different design. H4 is completely different from the other three timekeepers. It looks like a very large pocket watch. Harrison's son William set sail for the West Indies, with H4, aboard the ship Deptford on 18 November 1761. It was a remarkable achievement but it would be some time before the Board of Longitude was sufficiently satisfied to award Harrison the prize. John Hadley, an English mathematician, developed sextant, who was a competitor of Harrison at that time for the luring prize. A sextant is an instrument used for measuring angles, for example between the sun and the horizon, so that the position of a ship or aeroplane can be calculated. Making this measurement is known as sighting the object, shooting the object, or taking a sight and it is an essential part of celestial navigation. The angle, and the time when it was measured, can be used to calculate a position line on a nautical or aeronautical chart. A sextant can also be used to measure the Lunar distance between the moon and another celestial object (e. g. , star, planet) in order to determine Greenwich time which is important because it can then be used to determine the longitude. The majority within this next generation of chronometer pioneers were English, but the story is by no means wholly that of English achievement. One French name, Pierre Le Roy of Paris, stands out as a major presence in the early history of the chronometer. Another great name in the story is that of theLancastrian, Thomas Eamshaw, a slightly younger contemporary of John Arnold's. It was Eamshaw who created the final form of chronometer escapement, the spring detent escapement, and finalized the format and the production system for the marine chronometer, making it truly an article of commerce, and a practical means of safer navigation at sea over the next century and half.", "hypothesis": "In theory, by calculating the longitude degrees covered by a sail journey, the distance between the start and the end points can be obtained.", "gold_label": "neutral"}
{"uid": "id_38", "premise": "Timekeeper 2 Invention of Marine Chronometer It was, as Dava Sobel has described a phenomenon: the greatest scientific problem of the age. The reality was that in the 18th century no one had ever made a clock that could suffer the great rolling and pitching of a ship and the large changes in temperature whilst still keeping time accurately enough to be of any use. Indeed, most of the scientific community thought such clock impossibility. Knowing one's position on the earth requires two very simple but essential coordinates; rather like using a street map where one thinks in terms of how far one is up/down and how far side to side. The longitude is a measure of how far around the world one has come from home and has no naturally occurring base line like the equator. The crew of a given ship was naturally only concerned with how far round they were from their own particular home base. Even when in the middle of the ocean, with no land in sight, knowing this longitude position is very simple in theory. The key to knowing how far around the world you are from home is to know, at that very moment, what time it is back home. A comparison with your local time (easily found by checking the position of the Sim) will then tell you the time difference between you and home, and thus how far round the Earth you are from home. Up until the middle of the 18th century, navigators hadbeen unable to determine their position at sea with accuracy and they faced the huge attendant risks of shipwreck or running out of supplies before reaching then destination. The angular position of Moon and other bright stars was recorded in three-hour intervals of Greenwich Time. In order to determine longitude, sailors had to measure the angle between Moon centre and a given star - lunar distance - together with height of both planets using the naval sextant. The sailors also had to calculate the Moons position if seen form the centre of Earth. Time corresponding to Greenwich Time was determined using the nautical almanac. Then the difference between the obtained time and local time served for calculation in longitude from Greenwich. The great flaw in this simple theory was - how does the sailor know time back home when he is in the middle of an ocean? The obvious and again simple answer is that he takes an accurate clock with him, which he sets to home time before leaving. All he has to do is keep it wound up and running, and he must never reset the hands throughout the voyage This clock then provides home time, so if, for example, it is midday on board your ship and your home time clock says that at that same moment it is midnight at home, you know immediately there is a twelve hour time-difference and you must be exactly round the other side of the world, 180 degrees of longitude from home. After 1714 when the British government offered the huge sum of 20,000 for a solution to the problem, with the prize to be administered by die splendidly titled Board of Longitude. The Government prize of 20,000 was the highest of three sums on offer for varying degrees of accuracy, the full prize only payable for a method that could find the longitude at sea within half a degree. If the solution was to be by timekeeper (and there were other methods since the prize was offered for any solution to the problem), then the timekeeping required to achieve this goal would have to be within 2.8 seconds a day, a performance considered impossible for any clock at sea and unthinkable for a watch, even under the very best conditions. It was this prize, worth about 2 million today, which inspired the self-taught Yorkshfre carpenter, John Harrison, to attempt a design for a practical marineclock. During the latter part of his early career, he worked with his younger brother James. Their first major project was a revolutionary turret clock for the stables at Brocklesby Park, seat of the Pelham family. The clock was revolutionary because it required no lubrication. 18th century clock oils were uniformly poor and one of the major causes of failure in clocks of the period. Rather than concentrating on improvements to the oil, Harrison designed a clock which didn't need it. In 1730 Harrison created a description and drawings for a proposed marine clock to compete for the Longitude Prize and went to London seeking financial assistance. He presented his ideas to Edmond Halley, the Astronomer Royal. Halley referred him to George Graham, the country's foremost clockmaker. He must have been impressed by Harrison, for Graham personally loaned Harrison money to build a model of his marine clock. It took Harrison five years to build Harrison Number One or HI. He demonstrated it to members of the Royal Society who spoke on his behalf to the Board of Longitude. The clock was the first proposal that the Board considered to be worthy of a sea trial. In 1736, After several attempts to design a betterment of HI, Harrison believed that the ' solution to the longitude problem lay in an entirely different design. H4 is completely different from the other three timekeepers. It looks like a very large pocket watch. Harrison's son William set sail for the West Indies, with H4, aboard the ship Deptford on 18 November 1761. It was a remarkable achievement but it would be some time before the Board of Longitude was sufficiently satisfied to award Harrison the prize. John Hadley, an English mathematician, developed sextant, who was a competitor of Harrison at that time for the luring prize. A sextant is an instrument used for measuring angles, for example between the sun and the horizon, so that the position of a ship or aeroplane can be calculated. Making this measurement is known as sighting the object, shooting the object, or taking a sight and it is an essential part of celestial navigation. The angle, and the time when it was measured, can be used to calculate a position line on a nautical or aeronautical chart. A sextant can also be used to measure the Lunar distance between the moon and another celestial object (e. g. , star, planet) in order to determine Greenwich time which is important because it can then be used to determine the longitude. The majority within this next generation of chronometer pioneers were English, but the story is by no means wholly that of English achievement. One French name, Pierre Le Roy of Paris, stands out as a major presence in the early history of the chronometer. Another great name in the story is that of theLancastrian, Thomas Eamshaw, a slightly younger contemporary of John Arnold's. It was Eamshaw who created the final form of chronometer escapement, the spring detent escapement, and finalized the format and the production system for the marine chronometer, making it truly an article of commerce, and a practical means of safer navigation at sea over the next century and half.", "hypothesis": "To determine the longitude, a measurement of distance from moon to a given star is a must.", "gold_label": "contradiction"}
{"uid": "id_39", "premise": "Timekeeper 2 Invention of Marine Chronometer It was, as Dava Sobel has described a phenomenon: the greatest scientific problem of the age. The reality was that in the 18th century no one had ever made a clock that could suffer the great rolling and pitching of a ship and the large changes in temperature whilst still keeping time accurately enough to be of any use. Indeed, most of the scientific community thought such clock impossibility. Knowing one's position on the earth requires two very simple but essential coordinates; rather like using a street map where one thinks in terms of how far one is up/down and how far side to side. The longitude is a measure of how far around the world one has come from home and has no naturally occurring base line like the equator. The crew of a given ship was naturally only concerned with how far round they were from their own particular home base. Even when in the middle of the ocean, with no land in sight, knowing this longitude position is very simple in theory. The key to knowing how far around the world you are from home is to know, at that very moment, what time it is back home. A comparison with your local time (easily found by checking the position of the Sim) will then tell you the time difference between you and home, and thus how far round the Earth you are from home. Up until the middle of the 18th century, navigators hadbeen unable to determine their position at sea with accuracy and they faced the huge attendant risks of shipwreck or running out of supplies before reaching then destination. The angular position of Moon and other bright stars was recorded in three-hour intervals of Greenwich Time. In order to determine longitude, sailors had to measure the angle between Moon centre and a given star - lunar distance - together with height of both planets using the naval sextant. The sailors also had to calculate the Moons position if seen form the centre of Earth. Time corresponding to Greenwich Time was determined using the nautical almanac. Then the difference between the obtained time and local time served for calculation in longitude from Greenwich. The great flaw in this simple theory was - how does the sailor know time back home when he is in the middle of an ocean? The obvious and again simple answer is that he takes an accurate clock with him, which he sets to home time before leaving. All he has to do is keep it wound up and running, and he must never reset the hands throughout the voyage This clock then provides home time, so if, for example, it is midday on board your ship and your home time clock says that at that same moment it is midnight at home, you know immediately there is a twelve hour time-difference and you must be exactly round the other side of the world, 180 degrees of longitude from home. After 1714 when the British government offered the huge sum of 20,000 for a solution to the problem, with the prize to be administered by die splendidly titled Board of Longitude. The Government prize of 20,000 was the highest of three sums on offer for varying degrees of accuracy, the full prize only payable for a method that could find the longitude at sea within half a degree. If the solution was to be by timekeeper (and there were other methods since the prize was offered for any solution to the problem), then the timekeeping required to achieve this goal would have to be within 2.8 seconds a day, a performance considered impossible for any clock at sea and unthinkable for a watch, even under the very best conditions. It was this prize, worth about 2 million today, which inspired the self-taught Yorkshfre carpenter, John Harrison, to attempt a design for a practical marineclock. During the latter part of his early career, he worked with his younger brother James. Their first major project was a revolutionary turret clock for the stables at Brocklesby Park, seat of the Pelham family. The clock was revolutionary because it required no lubrication. 18th century clock oils were uniformly poor and one of the major causes of failure in clocks of the period. Rather than concentrating on improvements to the oil, Harrison designed a clock which didn't need it. In 1730 Harrison created a description and drawings for a proposed marine clock to compete for the Longitude Prize and went to London seeking financial assistance. He presented his ideas to Edmond Halley, the Astronomer Royal. Halley referred him to George Graham, the country's foremost clockmaker. He must have been impressed by Harrison, for Graham personally loaned Harrison money to build a model of his marine clock. It took Harrison five years to build Harrison Number One or HI. He demonstrated it to members of the Royal Society who spoke on his behalf to the Board of Longitude. The clock was the first proposal that the Board considered to be worthy of a sea trial. In 1736, After several attempts to design a betterment of HI, Harrison believed that the ' solution to the longitude problem lay in an entirely different design. H4 is completely different from the other three timekeepers. It looks like a very large pocket watch. Harrison's son William set sail for the West Indies, with H4, aboard the ship Deptford on 18 November 1761. It was a remarkable achievement but it would be some time before the Board of Longitude was sufficiently satisfied to award Harrison the prize. John Hadley, an English mathematician, developed sextant, who was a competitor of Harrison at that time for the luring prize. A sextant is an instrument used for measuring angles, for example between the sun and the horizon, so that the position of a ship or aeroplane can be calculated. Making this measurement is known as sighting the object, shooting the object, or taking a sight and it is an essential part of celestial navigation. The angle, and the time when it was measured, can be used to calculate a position line on a nautical or aeronautical chart. A sextant can also be used to measure the Lunar distance between the moon and another celestial object (e. g. , star, planet) in order to determine Greenwich time which is important because it can then be used to determine the longitude. The majority within this next generation of chronometer pioneers were English, but the story is by no means wholly that of English achievement. One French name, Pierre Le Roy of Paris, stands out as a major presence in the early history of the chronometer. Another great name in the story is that of theLancastrian, Thomas Eamshaw, a slightly younger contemporary of John Arnold's. It was Eamshaw who created the final form of chronometer escapement, the spring detent escapement, and finalized the format and the production system for the marine chronometer, making it truly an article of commerce, and a practical means of safer navigation at sea over the next century and half.", "hypothesis": "It is with no great effort by sailors to calculate the position when in the center of the ocean theoretically.", "gold_label": "entailment"}
{"uid": "id_40", "premise": "Timekeeper: Invention of Marine Chronometer Up to the middle of the 18th century, the navigators were still unable to exactly identify the position at sea, so they might face a great number of risks such as the shipwreck or running out of supplies before arriving at the destination. Knowing ones position on the earth requires two simple but essential coordinates, one of which is the longitude. The longitude is a term that can be used to measure the distance that one has covered from ones home to another place around the world without the limitations of naturally occurring baseline like the equator. To determine longitude, navigators had no choice but to measure the angle with the naval sextant between Moon centre and a specific star lunar distancealong with the height of both heavenly bodies. Together with the nautical almanac, Greenwich Mean Time (GMT) was determined, which could be adopted to calculate longitude because one hour in GMT means 15-degree longitude. Unfortunately, this approach laid great reliance on the weather conditions, which brought great inconvenience to the crew members. Therefore, another method was proposed, that is, the time difference between the home time and the local time served for the measurement. Theoretically, knowing the longitude position was quite simple, even for the people in the middle of the sea with no land in sight. The key element for calculating the distance travelled was to know, at the very moment, the accurate home time. But the greatest problem is: how can a sailor know the home time at sea? The simple and again obvious answer is that one takes an accurate clock with him, which he sets to the home time before leaving. A comparison with the local time (easily identified by checking the position of the Sun) would indicate the time difference between the home time and the local time, and thus the distance from home was obtained. The truth was that nobody in the 18th century had ever managed to create a clock that could endure the violent shaking of a ship and the fluctuating temperature while still maintaining the accuracy of time for navigation. After 1714, as an attempt to find a solution to the problem, the British government offered a tremendous amount of 20,000, which were to be managed by the magnificently named Board of Longitude. If timekeeper was the answer (and there could be other proposed solutions, since the money wasnt only offered for timekeeper), then the error of the required timekeeping for achieving this goal needed to be within 2.8 seconds a day, which was considered impossible for any clock or watch at sea, even when they were in their finest conditions. This award, worth about 2 million today, inspired the self-taught Yorkshire carpenter John Harrison to attempt a design for a practical marine clock. In the later stage of his early career, he worked alongside his younger brother James. The first big project of theirs was to build a turret clock for the stables at Brockelsby Park, which was revolutionary because it required no lubrication. Harrison designed a marine clock in 1730, and he travelled to London in seek of financial aid. He explained his ideas to Edmond Halley, the Astronomer Royal, who then introduced him to George Graham, Britains first-class clockmaker. Graham provided him with financial aid for his early-stage work on sea clocks. It took Harrison five years to build Harrison Number One or HI. Later, he sought the improvement from alternate design and produced H4 with the giant clock appearance. Remarkable as it was, the Board of Longitude wouldnt grant him the prize for some time until it was adequately satisfied. Harrison had a principal contestant for the tempting prize at that time, an English mathematician called John Hadley, who developed the sextant. The sextant is the tool that people adopt to measure angles, such as the one between the Sun and the horizon, for a calculation of the location of ships or planes. In addition, his invention is significant since it can help determine longitude. Most chronometer forerunners of that particular generation were English, but that doesnt mean every achievement was made by them. One wonderful figure in the history is the Lancastrian Thomas Earnshaw, who created the ultimate form of chronometer escapementthe spring detent escapementand made the final decision on format and productions system for the marine chronometer, which turns it into a genuine modem commercial product, as well as a safe and pragmatic way of navigation at sea over the next century and half.", "hypothesis": "Greenwich Mean Time was set up by the English navigators.", "gold_label": "neutral"}
{"uid": "id_41", "premise": "Timekeeper: Invention of Marine Chronometer Up to the middle of the 18th century, the navigators were still unable to exactly identify the position at sea, so they might face a great number of risks such as the shipwreck or running out of supplies before arriving at the destination. Knowing ones position on the earth requires two simple but essential coordinates, one of which is the longitude. The longitude is a term that can be used to measure the distance that one has covered from ones home to another place around the world without the limitations of naturally occurring baseline like the equator. To determine longitude, navigators had no choice but to measure the angle with the naval sextant between Moon centre and a specific star lunar distancealong with the height of both heavenly bodies. Together with the nautical almanac, Greenwich Mean Time (GMT) was determined, which could be adopted to calculate longitude because one hour in GMT means 15-degree longitude. Unfortunately, this approach laid great reliance on the weather conditions, which brought great inconvenience to the crew members. Therefore, another method was proposed, that is, the time difference between the home time and the local time served for the measurement. Theoretically, knowing the longitude position was quite simple, even for the people in the middle of the sea with no land in sight. The key element for calculating the distance travelled was to know, at the very moment, the accurate home time. But the greatest problem is: how can a sailor know the home time at sea? The simple and again obvious answer is that one takes an accurate clock with him, which he sets to the home time before leaving. A comparison with the local time (easily identified by checking the position of the Sun) would indicate the time difference between the home time and the local time, and thus the distance from home was obtained. The truth was that nobody in the 18th century had ever managed to create a clock that could endure the violent shaking of a ship and the fluctuating temperature while still maintaining the accuracy of time for navigation. After 1714, as an attempt to find a solution to the problem, the British government offered a tremendous amount of 20,000, which were to be managed by the magnificently named Board of Longitude. If timekeeper was the answer (and there could be other proposed solutions, since the money wasnt only offered for timekeeper), then the error of the required timekeeping for achieving this goal needed to be within 2.8 seconds a day, which was considered impossible for any clock or watch at sea, even when they were in their finest conditions. This award, worth about 2 million today, inspired the self-taught Yorkshire carpenter John Harrison to attempt a design for a practical marine clock. In the later stage of his early career, he worked alongside his younger brother James. The first big project of theirs was to build a turret clock for the stables at Brockelsby Park, which was revolutionary because it required no lubrication. Harrison designed a marine clock in 1730, and he travelled to London in seek of financial aid. He explained his ideas to Edmond Halley, the Astronomer Royal, who then introduced him to George Graham, Britains first-class clockmaker. Graham provided him with financial aid for his early-stage work on sea clocks. It took Harrison five years to build Harrison Number One or HI. Later, he sought the improvement from alternate design and produced H4 with the giant clock appearance. Remarkable as it was, the Board of Longitude wouldnt grant him the prize for some time until it was adequately satisfied. Harrison had a principal contestant for the tempting prize at that time, an English mathematician called John Hadley, who developed the sextant. The sextant is the tool that people adopt to measure angles, such as the one between the Sun and the horizon, for a calculation of the location of ships or planes. In addition, his invention is significant since it can help determine longitude. Most chronometer forerunners of that particular generation were English, but that doesnt mean every achievement was made by them. One wonderful figure in the history is the Lancastrian Thomas Earnshaw, who created the ultimate form of chronometer escapementthe spring detent escapementand made the final decision on format and productions system for the marine chronometer, which turns it into a genuine modem commercial product, as well as a safe and pragmatic way of navigation at sea over the next century and half.", "hypothesis": "To determine longitude, the measurement of the distance from the Moon to a given star is essential.", "gold_label": "entailment"}
{"uid": "id_42", "premise": "Timekeeper: Invention of Marine Chronometer Up to the middle of the 18th century, the navigators were still unable to exactly identify the position at sea, so they might face a great number of risks such as the shipwreck or running out of supplies before arriving at the destination. Knowing ones position on the earth requires two simple but essential coordinates, one of which is the longitude. The longitude is a term that can be used to measure the distance that one has covered from ones home to another place around the world without the limitations of naturally occurring baseline like the equator. To determine longitude, navigators had no choice but to measure the angle with the naval sextant between Moon centre and a specific star lunar distancealong with the height of both heavenly bodies. Together with the nautical almanac, Greenwich Mean Time (GMT) was determined, which could be adopted to calculate longitude because one hour in GMT means 15-degree longitude. Unfortunately, this approach laid great reliance on the weather conditions, which brought great inconvenience to the crew members. Therefore, another method was proposed, that is, the time difference between the home time and the local time served for the measurement. Theoretically, knowing the longitude position was quite simple, even for the people in the middle of the sea with no land in sight. The key element for calculating the distance travelled was to know, at the very moment, the accurate home time. But the greatest problem is: how can a sailor know the home time at sea? The simple and again obvious answer is that one takes an accurate clock with him, which he sets to the home time before leaving. A comparison with the local time (easily identified by checking the position of the Sun) would indicate the time difference between the home time and the local time, and thus the distance from home was obtained. The truth was that nobody in the 18th century had ever managed to create a clock that could endure the violent shaking of a ship and the fluctuating temperature while still maintaining the accuracy of time for navigation. After 1714, as an attempt to find a solution to the problem, the British government offered a tremendous amount of 20,000, which were to be managed by the magnificently named Board of Longitude. If timekeeper was the answer (and there could be other proposed solutions, since the money wasnt only offered for timekeeper), then the error of the required timekeeping for achieving this goal needed to be within 2.8 seconds a day, which was considered impossible for any clock or watch at sea, even when they were in their finest conditions. This award, worth about 2 million today, inspired the self-taught Yorkshire carpenter John Harrison to attempt a design for a practical marine clock. In the later stage of his early career, he worked alongside his younger brother James. The first big project of theirs was to build a turret clock for the stables at Brockelsby Park, which was revolutionary because it required no lubrication. Harrison designed a marine clock in 1730, and he travelled to London in seek of financial aid. He explained his ideas to Edmond Halley, the Astronomer Royal, who then introduced him to George Graham, Britains first-class clockmaker. Graham provided him with financial aid for his early-stage work on sea clocks. It took Harrison five years to build Harrison Number One or HI. Later, he sought the improvement from alternate design and produced H4 with the giant clock appearance. Remarkable as it was, the Board of Longitude wouldnt grant him the prize for some time until it was adequately satisfied. Harrison had a principal contestant for the tempting prize at that time, an English mathematician called John Hadley, who developed the sextant. The sextant is the tool that people adopt to measure angles, such as the one between the Sun and the horizon, for a calculation of the location of ships or planes. In addition, his invention is significant since it can help determine longitude. Most chronometer forerunners of that particular generation were English, but that doesnt mean every achievement was made by them. One wonderful figure in the history is the Lancastrian Thomas Earnshaw, who created the ultimate form of chronometer escapementthe spring detent escapementand made the final decision on format and productions system for the marine chronometer, which turns it into a genuine modem commercial product, as well as a safe and pragmatic way of navigation at sea over the next century and half.", "hypothesis": "In theory, sailors can easily calculate their longitude position at sea.", "gold_label": "entailment"}
{"uid": "id_43", "premise": "To determine whether interbreeding took place among Homo species before the populations that became modern humans left Africa, evolutionary biologists studied DNA from two African hunter-gatherer groups, the Biaka Pygmies and the San, and from a West African agricultural population, the Mandenka. Each of these groups is descended from populations thought to have remained in Africa, meaning they would have avoided the genetic bottleneck effect that usually occurs with migration. This means the groups show particularly high genetic diversity, which makes their genomes more likely to have retained evidence of ancient genetic mixing. The researchers looked at 61 non-coding DNA regions in all three groups. Because direct comparison to archaic specimens wasn't possible, the authors used computer models to simulate how infiltration from different populations might have affected patterns of variation within modern genomes. On chromosomes 4, 13 and 18 of the three African populations, the researchers found genetic regions that were more divergent on average than known modern sequences at the same locations, hinting at a different origin.", "hypothesis": "When population groups migrate, they apparently do not breed much with different groups at first.", "gold_label": "entailment"}
{"uid": "id_44", "premise": "To determine whether interbreeding took place among Homo species before the populations that became modern humans left Africa, evolutionary biologists studied DNA from two African hunter-gatherer groups, the Biaka Pygmies and the San, and from a West African agricultural population, the Mandenka. Each of these groups is descended from populations thought to have remained in Africa, meaning they would have avoided the genetic bottleneck effect that usually occurs with migration. This means the groups show particularly high genetic diversity, which makes their genomes more likely to have retained evidence of ancient genetic mixing. The researchers looked at 61 non-coding DNA regions in all three groups. Because direct comparison to archaic specimens wasn't possible, the authors used computer models to simulate how infiltration from different populations might have affected patterns of variation within modern genomes. On chromosomes 4, 13 and 18 of the three African populations, the researchers found genetic regions that were more divergent on average than known modern sequences at the same locations, hinting at a different origin.", "hypothesis": "Since the genetic diversity of the three African populations was high, while that of the indigenous population was low, researchers concluded that the three African populations had interbred.", "gold_label": "contradiction"}
{"uid": "id_45", "premise": "To determine whether interbreeding took place among Homo species before the populations that became modern humans left Africa, evolutionary biologists studied DNA from two African hunter-gatherer groups, the Biaka Pygmies and the San, and from a West African agricultural population, the Mandenka. Each of these groups is descended from populations thought to have remained in Africa, meaning they would have avoided the genetic bottleneck effect that usually occurs with migration. This means the groups show particularly high genetic diversity, which makes their genomes more likely to have retained evidence of ancient genetic mixing. The researchers looked at 61 non-coding DNA regions in all three groups. Because direct comparison to archaic specimens wasn't possible, the authors used computer models to simulate how infiltration from different populations might have affected patterns of variation within modern genomes. On chromosomes 4, 13 and 18 of the three African populations, the researchers found genetic regions that were more divergent on average than known modern sequences at the same locations, hinting at a different origin.", "hypothesis": "These African groups were selected for the study because they represent both the early hunter-gatherers as well as the later farmers.", "gold_label": "contradiction"}
{"uid": "id_46", "premise": "To enjoy a comfortable retirement, many retired people recommend retiring on two- thirds of final salary and around 4 million workers have paid into pension schemes for the bulk of their working lives in order to realize this goal. Those who have contributed to a final salary pension scheme will reach that standard and in fact exceed it when the persons state pension is added to the equation. Those workers who have contributed to a pension scheme that lacks the final salary guarantee and instead depend on the investment value of their total contributions to purchase their pension on retirement are less fortunate. Even when their state pension is included the bulk of these people will retire on an income of around 40 per cent of their final salary. As for the remaining 11 million workers who have made little or no contri- bution to any other pension scheme than the compulsory state scheme, it is feared that they will find themselves dependent on means-tested benefits.", "hypothesis": "Workers with pension schemes without the final salary guarantee will have to manage on a lot less than the amount thought to be needed for a secure retirement.", "gold_label": "neutral"}
{"uid": "id_47", "premise": "To enjoy a comfortable retirement, many retired people recommend retiring on two- thirds of final salary and around 4 million workers have paid into pension schemes for the bulk of their working lives in order to realize this goal. Those who have contributed to a final salary pension scheme will reach that standard and in fact exceed it when the persons state pension is added to the equation. Those workers who have contributed to a pension scheme that lacks the final salary guarantee and instead depend on the investment value of their total contributions to purchase their pension on retirement are less fortunate. Even when their state pension is included the bulk of these people will retire on an income of around 40 per cent of their final salary. As for the remaining 11 million workers who have made little or no contri- bution to any other pension scheme than the compulsory state scheme, it is feared that they will find themselves dependent on means-tested benefits.", "hypothesis": "The country to which the passage refers has a total population of 15 million.", "gold_label": "contradiction"}
{"uid": "id_48", "premise": "To enjoy a comfortable retirement, many retired people recommend retiring on two- thirds of final salary and around 4 million workers have paid into pension schemes for the bulk of their working lives in order to realize this goal. Those who have contributed to a final salary pension scheme will reach that standard and in fact exceed it when the persons state pension is added to the equation. Those workers who have contributed to a pension scheme that lacks the final salary guarantee and instead depend on the investment value of their total contributions to purchase their pension on retirement are less fortunate. Even when their state pension is included the bulk of these people will retire on an income of around 40 per cent of their final salary. As for the remaining 11 million workers who have made little or no contri- bution to any other pension scheme than the compulsory state scheme, it is feared that they will find themselves dependent on means-tested benefits.", "hypothesis": "Four million workers will reach or exceed the standard where they retire on two-thirds of the final salary.", "gold_label": "contradiction"}
{"uid": "id_49", "premise": "To get to his home at Tranton Park, Geoff takes the 17.45 train from Central Station. Rona avoids public transport whenever possible, but walks with him to the station, where she has left her car. Her drive to her home in Hampton takes 15 minutes, although it would have taken exactly the same time by train. Like Geoff, Sam takes the train, but avoids the rush by taking the 17.15 from Central Station. Bella, who works in the same office as the rest and who prefers the train, always makes the journey with Sam as far as Hampton, where she lives. Sam continues to Nately, which is his hometown, a journey that is three times as long as hers. Geoff arrives at Tranton Park an hour and a quarter after Bella gets to Hampton.", "hypothesis": "Sam never travels by train", "gold_label": "neutral"}
{"uid": "id_50", "premise": "To get to his home at Tranton Park, Geoff takes the 17.45 train from Central Station. Rona avoids public transport whenever possible, but walks with him to the station, where she has left her car. Her drive to her home in Hampton takes 15 minutes, although it would have taken exactly the same time by train. Like Geoff, Sam takes the train, but avoids the rush by taking the 17.15 from Central Station. Bella, who works in the same office as the rest and who prefers the train, always makes the journey with Sam as far as Hampton, where she lives. Sam continues to Nately, which is his hometown, a journey that is three times as long as hers. Geoff arrives at Tranton Park an hour and a quarter after Bella gets to Hampton.", "hypothesis": "Bella, apart from Geoff, is most likely to travel by train.", "gold_label": "entailment"}
{"uid": "id_51", "premise": "To get to his home at Tranton Park, Geoff takes the 17.45 train from Central Station. Rona avoids public transport whenever possible, but walks with him to the station, where she has left her car. Her drive to her home in Hampton takes 15 minutes, although it would have taken exactly the same time by train. Like Geoff, Sam takes the train, but avoids the rush by taking the 17.15 from Central Station. Bella, who works in the same office as the rest and who prefers the train, always makes the journey with Sam as far as Hampton, where she lives. Sam continues to Nately, which is his hometown, a journey that is three times as long as hers. Geoff arrives at Tranton Park an hour and a quarter after Bella gets to Hampton.", "hypothesis": "Bella is most likely to arrive home first", "gold_label": "entailment"}
{"uid": "id_52", "premise": "To get to his home at Tranton Park, Geoff takes the 17.45 train from Central Station. Rona avoids public transport whenever possible, but walks with him to the station, where she has left her car. Her drive to her home in Hampton takes 15 minutes, although it would have taken exactly the same time by train. Like Geoff, Sam takes the train, but avoids the rush by taking the 17.15 from Central Station. Bella, who works in the same office as the rest and who prefers the train, always makes the journey with Sam as far as Hampton, where she lives. Sam continues to Nately, which is his hometown, a journey that is three times as long as hers. Geoff arrives at Tranton Park an hour and a quarter after Bella gets to Hampton.", "hypothesis": "the journey time between Nately and Tranton Park is 15 minutes.", "gold_label": "entailment"}
{"uid": "id_53", "premise": "To get to his home at Tranton Park, Geoff takes the 17.45 train from Central Station. Rona avoids public transport whenever possible, but walks with him to the station, where she has left her car. Her drive to her home in Hampton takes 15 minutes, although it would have taken exactly the same time by train. Like Geoff, Sam takes the train, but avoids the rush by taking the 17.15 from Central Station. Bella, who works in the same office as the rest and who prefers the train, always makes the journey with Sam as far as Hampton, where she lives. Sam continues to Nately, which is his hometown, a journey that is three times as long as hers. Geoff arrives at Tranton Park an hour and a quarter after Bella gets to Hampton.", "hypothesis": "Geoff probably has the longest journey.", "gold_label": "entailment"}
{"uid": "id_54", "premise": "To keep myself up to date, i always listen to 9:00 p. m. news on radio. ---- A candidate tells the interview board.", "hypothesis": "Recent news are broadcast only on radio.", "gold_label": "neutral"}
{"uid": "id_55", "premise": "To keep myself up to date, i always listen to 9:00 p. m. news on radio. ---- A candidate tells the interview board.", "hypothesis": "The candidate does not read newspaper", "gold_label": "neutral"}
{"uid": "id_56", "premise": "To save the environment enforce total ban on illegal mining throughout the country.", "hypothesis": "Mining is one of the factors responsible for environment degradation. Syndicate Bank (PO)", "gold_label": "entailment"}
{"uid": "id_57", "premise": "To save the environment enforce total ban on illegal mining throughout the country.", "hypothesis": "Mining which is done legally does not cause any harm to the environment", "gold_label": "neutral"}
{"uid": "id_58", "premise": "To what extent does advertising a product at a sporting event increase sales? In light of the London Olympics, the relationship between sporting events and advertising is under greater scrutiny by British companies than ever before. Research suggests that in the year prior to the Games, twelve percent of adults talked about the Olympics on a typical day. With this in mind, it is estimated that more than one billion pounds have been invested in the Games in the form of sponsorship from companies. In return for their investment, the exposure gained by sponsors is now legally protected by statute to prevent non-official sponsors from profiting.", "hypothesis": "As a result of the London Olympics sporting events and advertising is receiving more attention from adults.", "gold_label": "neutral"}
{"uid": "id_59", "premise": "To what extent does advertising a product at a sporting event increase sales? In light of the London Olympics, the relationship between sporting events and advertising is under greater scrutiny by British companies than ever before. Research suggests that in the year prior to the Games, twelve percent of adults talked about the Olympics on a typical day. With this in mind, it is estimated that more than one billion pounds have been invested in the Games in the form of sponsorship from companies. In return for their investment, the exposure gained by sponsors is now legally protected by statute to prevent non-official sponsors from profiting.", "hypothesis": "As a result of the London Olympics sporting events and advertising has been researched for the first time.", "gold_label": "neutral"}
{"uid": "id_60", "premise": "To what extent does advertising a product at a sporting event increase sales? In light of the London Olympics, the relationship between sporting events and advertising is under greater scrutiny by British companies than ever before. Research suggests that in the year prior to the Games, twelve percent of adults talked about the Olympics on a typical day. With this in mind, it is estimated that more than one billion pounds have been invested in the Games in the form of sponsorship from companies. In return for their investment, the exposure gained by sponsors is now legally protected by statute to prevent non-official sponsors from profiting.", "hypothesis": "As a result of the London Olympics sporting events and advertising is now protected by statute.", "gold_label": "contradiction"}
{"uid": "id_61", "premise": "To what extent does advertising a product at a sporting event increase sales? In light of the London Olympics, the relationship between sporting events and advertising is under greater scrutiny by British companies than ever before. Research suggests that in the year prior to the Games, twelve percent of adults talked about the Olympics on a typical day. With this in mind, it is estimated that more than one billion pounds have been invested in the Games in the form of sponsorship from companies. In return for their investment, the exposure gained by sponsors is now legally protected by statute to prevent non-official sponsors from profiting.", "hypothesis": "As a result of the London Olympics sporting events and advertising is receiving more attention from companies", "gold_label": "entailment"}
{"uid": "id_62", "premise": "Toby, Rob and Frank all take a holiday by the sea, whilst Sam, Jo and Tony go hiking in the mountains. Frank, Sam and Jo travel by air. Jo, Rob and Tony do not enjoy their holiday.", "hypothesis": "Tony does not travel by air and goes hiking", "gold_label": "entailment"}
{"uid": "id_63", "premise": "Toby, Rob and Frank all take a holiday by the sea, whilst Sam, Jo and Tony go hiking in the mountains. Frank, Sam and Jo travel by air. Jo, Rob and Tony do not enjoy their holiday.", "hypothesis": "Rob goes to the sea and does not enjoy the holiday", "gold_label": "entailment"}
{"uid": "id_64", "premise": "Today, the term surreal is used to denote a curious imaginative effect. The words provenance can be traced back to the revolutionary surrealism movement which grew out of Dadaism in the mid-1920s. Surrealism spread quite quickly across European arts and literature, particularly in France, between the two world wars. The movements founder French poet Andre Breton was influenced heavily by Freuds theories, as he reacted against reason and logic in order to free the imagination from the unconscious mind. Surrealist works, both visual and oral, juxtaposed seemingly unrelated everyday objects and placed these in dreamlike settings. Thus, the popularity of surrealist paintings, including Salvador Dalis, lies in the unconventional positioning of powerful images such as leaping tigers, melting watches and metronomes. Surrealist art is widely known today, unlike the less easily accessible works of the French surrealist writers who, ignoring the literal meanings of words, focused instead on word associations and implications. That said, the literary surrealist tradition still survives in modern-day proponents of experimental writing.", "hypothesis": "Salvador Dalis work is more popular than Andre Bretons output.", "gold_label": "entailment"}
{"uid": "id_65", "premise": "Today, the term surreal is used to denote a curious imaginative effect. The words provenance can be traced back to the revolutionary surrealism movement which grew out of Dadaism in the mid-1920s. Surrealism spread quite quickly across European arts and literature, particularly in France, between the two world wars. The movements founder French poet Andre Breton was influenced heavily by Freuds theories, as he reacted against reason and logic in order to free the imagination from the unconscious mind. Surrealist works, both visual and oral, juxtaposed seemingly unrelated everyday objects and placed these in dreamlike settings. Thus, the popularity of surrealist paintings, including Salvador Dalis, lies in the unconventional positioning of powerful images such as leaping tigers, melting watches and metronomes. Surrealist art is widely known today, unlike the less easily accessible works of the French surrealist writers who, ignoring the literal meanings of words, focused instead on word associations and implications. That said, the literary surrealist tradition still survives in modern-day proponents of experimental writing.", "hypothesis": "At one time Dadaism and Surrealism were closely affiliated.", "gold_label": "entailment"}
{"uid": "id_66", "premise": "Today, the term surreal is used to denote a curious imaginative effect. The words provenance can be traced back to the revolutionary surrealism movement which grew out of Dadaism in the mid-1920s. Surrealism spread quite quickly across European arts and literature, particularly in France, between the two world wars. The movements founder French poet Andre Breton was influenced heavily by Freuds theories, as he reacted against reason and logic in order to free the imagination from the unconscious mind. Surrealist works, both visual and oral, juxtaposed seemingly unrelated everyday objects and placed these in dreamlike settings. Thus, the popularity of surrealist paintings, including Salvador Dalis, lies in the unconventional positioning of powerful images such as leaping tigers, melting watches and metronomes. Surrealist art is widely known today, unlike the less easily accessible works of the French surrealist writers who, ignoring the literal meanings of words, focused instead on word associations and implications. That said, the literary surrealist tradition still survives in modern-day proponents of experimental writing.", "hypothesis": "Some experimental writing is surreal.", "gold_label": "entailment"}
{"uid": "id_67", "premise": "Today, the term surreal is used to denote a curious imaginative effect. The words provenance can be traced back to the revolutionary surrealism movement which grew out of Dadaism in the mid-1920s. Surrealism spread quite quickly across European arts and literature, particularly in France, between the two world wars. The movements founder French poet Andre Breton was influenced heavily by Freuds theories, as he reacted against reason and logic in order to free the imagination from the unconscious mind. Surrealist works, both visual and oral, juxtaposed seemingly unrelated everyday objects and placed these in dreamlike settings. Thus, the popularity of surrealist paintings, including Salvador Dalis, lies in the unconventional positioning of powerful images such as leaping tigers, melting watches and metronomes. Surrealist art is widely known today, unlike the less easily accessible works of the French surrealist writers who, ignoring the literal meanings of words, focused instead on word associations and implications. That said, the literary surrealist tradition still survives in modern-day proponents of experimental writing.", "hypothesis": "Surrealist painting is renowned for the arbitrary portrayal of everyday objects.", "gold_label": "entailment"}
{"uid": "id_68", "premise": "Today, the term surreal is used to denote a curious imaginative effect. The words provenance can be traced back to the revolutionary surrealism movement which grew out of Dadaism in the mid-1920s. Surrealism spread quite quickly across European arts and literature, particularly in France, between the two world wars. The movements founder French poet Andre Breton was influenced heavily by Freuds theories, as he reacted against reason and logic in order to free the imagination from the unconscious mind. Surrealist works, both visual and oral, juxtaposed seemingly unrelated everyday objects and placed these in dreamlike settings. Thus, the popularity of surrealist paintings, including Salvador Dalis, lies in the unconventional positioning of powerful images such as leaping tigers, melting watches and metronomes. Surrealist art is widely known today, unlike the less easily accessible works of the French surrealist writers who, ignoring the literal meanings of words, focused instead on word associations and implications. That said, the literary surrealist tradition still survives in modern-day proponents of experimental writing.", "hypothesis": "Salvador Dali was a French surrealist painter.", "gold_label": "neutral"}
{"uid": "id_69", "premise": "Todays historians aim to construct a record of human activities and to use this record to achieve a more profound understanding of humanity. This conception of their task is quite recent, dating from the development from 18th and early 19th centuries of scientific history, and cultivated largely by professional historians who adopted the assumption that the study of natural, inevitable human activity. Before the late 18th century, history was taught in virtually no schools, and it did not attempt to provide an interpretation of human life as a whole. This is more appropriately the function of religion, of philosophy, or even perhaps of poetry.", "hypothesis": "That which constitutes the study of history has changed over time.", "gold_label": "neutral"}
{"uid": "id_70", "premise": "Todays historians aim to construct a record of human activities and to use this record to achieve a more profound understanding of humanity. This conception of their task is quite recent, dating from the development from 18th and early 19th centuries of scientific history, and cultivated largely by professional historians who adopted the assumption that the study of natural, inevitable human activity. Before the late 18th century, history was taught in virtually no schools, and it did not attempt to provide an interpretation of human life as a whole. This is more appropriately the function of religion, of philosophy, or even perhaps of poetry.", "hypothesis": "In the 17th century, history would not have been thought of as a way of understanding humanity.", "gold_label": "entailment"}
{"uid": "id_71", "premise": "Todays historians aim to construct a record of human activities and to use this record to achieve a more profound understanding of humanity. This conception of their task is quite recent, dating from the development from 18th and early 19th centuries of scientific history, and cultivated largely by professional historians who adopted the assumption that the study of natural, inevitable human activity. Before the late 18th century, history was taught in virtually no schools, and it did not attempt to provide an interpretation of human life as a whole. This is more appropriately the function of religion, of philosophy, or even perhaps of poetry.", "hypothesis": "Professional historians did not exist before 18th century.", "gold_label": "neutral"}
{"uid": "id_72", "premise": "Todays historians aim to construct a record of human activities and to use this record to achieve a more profound understanding of humanity. This conception of their task is quite recent, dating from the development from 18th and early 19th centuries of scientific history, and cultivated largely by professional historians who adopted the assumption that the study of natural, inevitable human activity. Before the late 18th century, history was taught in virtually no schools, and it did not attempt to provide an interpretation of human life as a whole. This is more appropriately the function of religion, of philosophy, or even perhaps of poetry.", "hypothesis": "That which constitutes the study of history has changed over time.", "gold_label": "entailment"}
{"uid": "id_73", "premise": "Tom puts on his socks before he puts on his shoes. He puts on his shirt before he puts on his jacket.", "hypothesis": "Tom puts on his shoes before he puts on his shirt.", "gold_label": "neutral"}
{"uid": "id_74", "premise": "Total stocks of most minerals in the earths crust are still large in relation to the current rates of use, and a high proportion of the minerals that are consumed in the production process could, in principle, be recycled. The technological and financial constraints on recycling such concentrations of minerals are considerable, however, and there is no guarantee that these constraints could be overcome. Substitution of abundant for scarce resources would avoid the problem, but such substitution is not always technologically feasible.", "hypothesis": "The technical constraints of recovering any mineral are considerable.", "gold_label": "contradiction"}
{"uid": "id_75", "premise": "Total stocks of most minerals in the earths crust are still large in relation to the current rates of use, and a high proportion of the minerals that are consumed in the production process could, in principle, be recycled. The technological and financial constraints on recycling such concentrations of minerals are considerable, however, and there is no guarantee that these constraints could be overcome. Substitution of abundant for scarce resources would avoid the problem, but such substitution is not always technologically feasible.", "hypothesis": "It is wrong to assume that the substitution of abundant for scarce resources will create insurmountable technical problems on every occasion.", "gold_label": "entailment"}
{"uid": "id_76", "premise": "Total stocks of most minerals in the earths crust are still large in relation to the current rates of use, and a high proportion of the minerals that are consumed in the production process could, in principle, be recycled. The technological and financial constraints on recycling such concentrations of minerals are considerable, however, and there is no guarantee that these constraints could be overcome. Substitution of abundant for scarce resources would avoid the problem, but such substitution is not always technologically feasible.", "hypothesis": "Most of the minerals consumed in the production process can be economically recycled.", "gold_label": "neutral"}
{"uid": "id_77", "premise": "Tourism in Mexico They appear out of nowhere like a heat-addled mirage on the flat, straight, mangrove-fringed road. The first sign of humanity in 40 miles, the tourists have ripened to pink under the glare of the tropical sun, with their legs wrapped around shiny red all-terrain vehicles buzzing down the asphalt like one giant invasive insect. It's a strange sight, all right. But it's eclipsed moments later by an even stranger one. Looming on the Caribbean just beyond the end of the road is the world's largest cruise ship, the Independence of the Seas, harboring a bounty of 3,811 passengers. Thanks to cruise ships like this one, Mexico's Costa Maya (not to be confused with the Riviera Maya farther north), set along a once mostly deserted stretch of the Yucatan Peninsula, is becoming one of the most visited, albeit least known, tourist regions in the nation. In 2006, just five years after the opening of the cruise ship facility here, 850,000 passengers sailed into port. By then, the once tiny fishing village of Mahahual had exploded from 80 souls dependent on the sea, to 3,500 dependent on tourism. The region begins about 80 miles south of Cancun and stretches from the vast Sian Ka'an Biosphere Reserve almost to the Belize border. It encompasses huge swaths of protected jungle, a number of lesser-known Maya archaeological sites, indigenous villages, pristine lagoons and top-notch diving. Plans call for low-rise, low-density development emphasizing small, eco-friendly hotels that cater to adventure seekers and cultural travelers. South of Tulum, a lengthy stretch of almost uninterrupted resort development comes to an abrupt halt at the northern edge of the Sian Ka'an Reserve. The UNESCO World Heritage site (whose name is Maya for \"where the sky is born\") is a 1.3-million-acre haven of tropical forest and wetlands. It's alive with more than 300 bird species, pig-like peccaries, monkeys, puma and jaguar. It harbors turquoise lagoons where orchids and bromeliads cling to mangroves whose spiny roots grasp the earth like gnarled fingers. Save for a few fishing lodges, Sian Ka'an isn't set up for overnight visitors. But day trips are organized by a number of tour operators, including Community Tours of Sian Ka'an, a cooperative formed in an attempt to keep profits - and residents - in the small Maya town of Muyil.", "hypothesis": "Costa Maya is still not well-known by tourists.", "gold_label": "contradiction"}
{"uid": "id_78", "premise": "Tourism in Mexico They appear out of nowhere like a heat-addled mirage on the flat, straight, mangrove-fringed road. The first sign of humanity in 40 miles, the tourists have ripened to pink under the glare of the tropical sun, with their legs wrapped around shiny red all-terrain vehicles buzzing down the asphalt like one giant invasive insect. It's a strange sight, all right. But it's eclipsed moments later by an even stranger one. Looming on the Caribbean just beyond the end of the road is the world's largest cruise ship, the Independence of the Seas, harboring a bounty of 3,811 passengers. Thanks to cruise ships like this one, Mexico's Costa Maya (not to be confused with the Riviera Maya farther north), set along a once mostly deserted stretch of the Yucatan Peninsula, is becoming one of the most visited, albeit least known, tourist regions in the nation. In 2006, just five years after the opening of the cruise ship facility here, 850,000 passengers sailed into port. By then, the once tiny fishing village of Mahahual had exploded from 80 souls dependent on the sea, to 3,500 dependent on tourism. The region begins about 80 miles south of Cancun and stretches from the vast Sian Ka'an Biosphere Reserve almost to the Belize border. It encompasses huge swaths of protected jungle, a number of lesser-known Maya archaeological sites, indigenous villages, pristine lagoons and top-notch diving. Plans call for low-rise, low-density development emphasizing small, eco-friendly hotels that cater to adventure seekers and cultural travelers. South of Tulum, a lengthy stretch of almost uninterrupted resort development comes to an abrupt halt at the northern edge of the Sian Ka'an Reserve. The UNESCO World Heritage site (whose name is Maya for \"where the sky is born\") is a 1.3-million-acre haven of tropical forest and wetlands. It's alive with more than 300 bird species, pig-like peccaries, monkeys, puma and jaguar. It harbors turquoise lagoons where orchids and bromeliads cling to mangroves whose spiny roots grasp the earth like gnarled fingers. Save for a few fishing lodges, Sian Ka'an isn't set up for overnight visitors. But day trips are organized by a number of tour operators, including Community Tours of Sian Ka'an, a cooperative formed in an attempt to keep profits - and residents - in the small Maya town of Muyil.", "hypothesis": "The UNESCO site has a larger area of tropical forest than any other area of Mexico.", "gold_label": "neutral"}
{"uid": "id_79", "premise": "Tourism in Mexico They appear out of nowhere like a heat-addled mirage on the flat, straight, mangrove-fringed road. The first sign of humanity in 40 miles, the tourists have ripened to pink under the glare of the tropical sun, with their legs wrapped around shiny red all-terrain vehicles buzzing down the asphalt like one giant invasive insect. It's a strange sight, all right. But it's eclipsed moments later by an even stranger one. Looming on the Caribbean just beyond the end of the road is the world's largest cruise ship, the Independence of the Seas, harboring a bounty of 3,811 passengers. Thanks to cruise ships like this one, Mexico's Costa Maya (not to be confused with the Riviera Maya farther north), set along a once mostly deserted stretch of the Yucatan Peninsula, is becoming one of the most visited, albeit least known, tourist regions in the nation. In 2006, just five years after the opening of the cruise ship facility here, 850,000 passengers sailed into port. By then, the once tiny fishing village of Mahahual had exploded from 80 souls dependent on the sea, to 3,500 dependent on tourism. The region begins about 80 miles south of Cancun and stretches from the vast Sian Ka'an Biosphere Reserve almost to the Belize border. It encompasses huge swaths of protected jungle, a number of lesser-known Maya archaeological sites, indigenous villages, pristine lagoons and top-notch diving. Plans call for low-rise, low-density development emphasizing small, eco-friendly hotels that cater to adventure seekers and cultural travelers. South of Tulum, a lengthy stretch of almost uninterrupted resort development comes to an abrupt halt at the northern edge of the Sian Ka'an Reserve. The UNESCO World Heritage site (whose name is Maya for \"where the sky is born\") is a 1.3-million-acre haven of tropical forest and wetlands. It's alive with more than 300 bird species, pig-like peccaries, monkeys, puma and jaguar. It harbors turquoise lagoons where orchids and bromeliads cling to mangroves whose spiny roots grasp the earth like gnarled fingers. Save for a few fishing lodges, Sian Ka'an isn't set up for overnight visitors. But day trips are organized by a number of tour operators, including Community Tours of Sian Ka'an, a cooperative formed in an attempt to keep profits - and residents - in the small Maya town of Muyil.", "hypothesis": "It's difficult to find a hotel with vacancies in Sian Ka'an.", "gold_label": "entailment"}
{"uid": "id_80", "premise": "Tourism in Mexico They appear out of nowhere like a heat-addled mirage on the flat, straight, mangrove-fringed road. The first sign of humanity in 40 miles, the tourists have ripened to pink under the glare of the tropical sun, with their legs wrapped around shiny red all-terrain vehicles buzzing down the asphalt like one giant invasive insect. It's a strange sight, all right. But it's eclipsed moments later by an even stranger one. Looming on the Caribbean just beyond the end of the road is the world's largest cruise ship, the Independence of the Seas, harboring a bounty of 3,811 passengers. Thanks to cruise ships like this one, Mexico's Costa Maya (not to be confused with the Riviera Maya farther north), set along a once mostly deserted stretch of the Yucatan Peninsula, is becoming one of the most visited, albeit least known, tourist regions in the nation. In 2006, just five years after the opening of the cruise ship facility here, 850,000 passengers sailed into port. By then, the once tiny fishing village of Mahahual had exploded from 80 souls dependent on the sea, to 3,500 dependent on tourism. The region begins about 80 miles south of Cancun and stretches from the vast Sian Ka'an Biosphere Reserve almost to the Belize border. It encompasses huge swaths of protected jungle, a number of lesser-known Maya archaeological sites, indigenous villages, pristine lagoons and top-notch diving. Plans call for low-rise, low-density development emphasizing small, eco-friendly hotels that cater to adventure seekers and cultural travelers. South of Tulum, a lengthy stretch of almost uninterrupted resort development comes to an abrupt halt at the northern edge of the Sian Ka'an Reserve. The UNESCO World Heritage site (whose name is Maya for \"where the sky is born\") is a 1.3-million-acre haven of tropical forest and wetlands. It's alive with more than 300 bird species, pig-like peccaries, monkeys, puma and jaguar. It harbors turquoise lagoons where orchids and bromeliads cling to mangroves whose spiny roots grasp the earth like gnarled fingers. Save for a few fishing lodges, Sian Ka'an isn't set up for overnight visitors. But day trips are organized by a number of tour operators, including Community Tours of Sian Ka'an, a cooperative formed in an attempt to keep profits - and residents - in the small Maya town of Muyil.", "hypothesis": "The Independence of the Seas is currently the largest ship in the Caribbean.", "gold_label": "neutral"}
{"uid": "id_81", "premise": "Tourism in Mexico They appear out of nowhere like a heat-addled mirage on the flat, straight, mangrove-fringed road. The first sign of humanity in 40 miles, the tourists have ripened to pink under the glare of the tropical sun, with their legs wrapped around shiny red all-terrain vehicles buzzing down the asphalt like one giant invasive insect. It's a strange sight, all right. But it's eclipsed moments later by an even stranger one. Looming on the Caribbean just beyond the end of the road is the world's largest cruise ship, the Independence of the Seas, harboring a bounty of 3,811 passengers. Thanks to cruise ships like this one, Mexico's Costa Maya (not to be confused with the Riviera Maya farther north), set along a once mostly deserted stretch of the Yucatan Peninsula, is becoming one of the most visited, albeit least known, tourist regions in the nation. In 2006, just five years after the opening of the cruise ship facility here, 850,000 passengers sailed into port. By then, the once tiny fishing village of Mahahual had exploded from 80 souls dependent on the sea, to 3,500 dependent on tourism. The region begins about 80 miles south of Cancun and stretches from the vast Sian Ka'an Biosphere Reserve almost to the Belize border. It encompasses huge swaths of protected jungle, a number of lesser-known Maya archaeological sites, indigenous villages, pristine lagoons and top-notch diving. Plans call for low-rise, low-density development emphasizing small, eco-friendly hotels that cater to adventure seekers and cultural travelers. South of Tulum, a lengthy stretch of almost uninterrupted resort development comes to an abrupt halt at the northern edge of the Sian Ka'an Reserve. The UNESCO World Heritage site (whose name is Maya for \"where the sky is born\") is a 1.3-million-acre haven of tropical forest and wetlands. It's alive with more than 300 bird species, pig-like peccaries, monkeys, puma and jaguar. It harbors turquoise lagoons where orchids and bromeliads cling to mangroves whose spiny roots grasp the earth like gnarled fingers. Save for a few fishing lodges, Sian Ka'an isn't set up for overnight visitors. But day trips are organized by a number of tour operators, including Community Tours of Sian Ka'an, a cooperative formed in an attempt to keep profits - and residents - in the small Maya town of Muyil.", "hypothesis": "Costa Maya is a great place for tourists who enjoy diving.", "gold_label": "entailment"}
{"uid": "id_82", "premise": "Tourism in Mexico They appear out of nowhere like a heat-addled mirage on the flat, straight, mangrove-fringed road. The first sign of humanity in 40 miles, the tourists have ripened to pink under the glare of the tropical sun, with their legs wrapped around shiny red all-terrain vehicles buzzing down the asphalt like one giant invasive insect. It's a strange sight, all right. But it's eclipsed moments later by an even stranger one. Looming on the Caribbean just beyond the end of the road is the world's largest cruise ship, the Independence of the Seas, harboring a bounty of 3,811 passengers. Thanks to cruise ships like this one, Mexico's Costa Maya (not to be confused with the Riviera Maya farther north), set along a once mostly deserted stretch of the Yucatan Peninsula, is becoming one of the most visited, albeit least known, tourist regions in the nation. In 2006, just five years after the opening of the cruise ship facility here, 850,000 passengers sailed into port. By then, the once tiny fishing village of Mahahual had exploded from 80 souls dependent on the sea, to 3,500 dependent on tourism. The region begins about 80 miles south of Cancun and stretches from the vast Sian Ka'an Biosphere Reserve almost to the Belize border. It encompasses huge swaths of protected jungle, a number of lesser-known Maya archaeological sites, indigenous villages, pristine lagoons and top-notch diving. Plans call for low-rise, low-density development emphasizing small, eco-friendly hotels that cater to adventure seekers and cultural travelers. South of Tulum, a lengthy stretch of almost uninterrupted resort development comes to an abrupt halt at the northern edge of the Sian Ka'an Reserve. The UNESCO World Heritage site (whose name is Maya for \"where the sky is born\") is a 1.3-million-acre haven of tropical forest and wetlands. It's alive with more than 300 bird species, pig-like peccaries, monkeys, puma and jaguar. It harbors turquoise lagoons where orchids and bromeliads cling to mangroves whose spiny roots grasp the earth like gnarled fingers. Save for a few fishing lodges, Sian Ka'an isn't set up for overnight visitors. But day trips are organized by a number of tour operators, including Community Tours of Sian Ka'an, a cooperative formed in an attempt to keep profits - and residents - in the small Maya town of Muyil.", "hypothesis": "Mahahual now has a population of 3,500.", "gold_label": "neutral"}
{"uid": "id_83", "premise": "Tourism is big business. The annual profit and popularity of several top tourist attractions in the United Kingdom has been researched and presented by visitengland. com. Almost 30 million international visitors travel to London every year, marking the city as the most popular international travel destination in the world. In 2011, Londons most popular tourist attraction was the British Museum. The second most popular destination was Madame Tussauds. Outside of the capital, popular tourist destinations include Alton Towers and the Cadburys Factory. Tourist attractions contribute over two billion pounds to the UK economy and can be seen as one of the most profitable sectors. This information has not bypassed local authorities keen to bolster their income; some are spending hundreds of thousands of pounds on publicity drives. Whilst Essex County Council wont receive a penny from ticket sales, they are part-funding a new stadium in the hope that the increased spending by visitors will filter through to them in the form of business rates and local taxes.", "hypothesis": "In 2011 the British Museum received the most visits of any tourist attraction in the UK.", "gold_label": "neutral"}
{"uid": "id_84", "premise": "Tourism is big business. The annual profit and popularity of several top tourist attractions in the United Kingdom has been researched and presented by visitengland. com. Almost 30 million international visitors travel to London every year, marking the city as the most popular international travel destination in the world. In 2011, Londons most popular tourist attraction was the British Museum. The second most popular destination was Madame Tussauds. Outside of the capital, popular tourist destinations include Alton Towers and the Cadburys Factory. Tourist attractions contribute over two billion pounds to the UK economy and can be seen as one of the most profitable sectors. This information has not bypassed local authorities keen to bolster their income; some are spending hundreds of thousands of pounds on publicity drives. Whilst Essex County Council wont receive a penny from ticket sales, they are part-funding a new stadium in the hope that the increased spending by visitors will filter through to them in the form of business rates and local taxes.", "hypothesis": "New York typically receives less than 30 million international visitors each year.", "gold_label": "entailment"}
{"uid": "id_85", "premise": "Tourism is big business. The annual profit and popularity of several top tourist attractions in the United Kingdom has been researched and presented by visitengland. com. Almost 30 million international visitors travel to London every year, marking the city as the most popular international travel destination in the world. In 2011, Londons most popular tourist attraction was the British Museum. The second most popular destination was Madame Tussauds. Outside of the capital, popular tourist destinations include Alton Towers and the Cadburys Factory. Tourist attractions contribute over two billion pounds to the UK economy and can be seen as one of the most profitable sectors. This information has not bypassed local authorities keen to bolster their income; some are spending hundreds of thousands of pounds on publicity drives. Whilst Essex County Council wont receive a penny from ticket sales, they are part-funding a new stadium in the hope that the increased spending by visitors will filter through to them in the form of business rates and local taxes.", "hypothesis": "Whilst tourism brings in lots of money, the industry is one of the least profitable.", "gold_label": "contradiction"}
{"uid": "id_86", "premise": "Towns that have become commuter and second-home hotspots are valued for their housing stock, schools and unspoilt civic centres. It is now possible for working families to relocate away from cities without affecting their earning power. Commuting three days a week and working from home the rest has meant that many more people are willing to give up the city life and move to more rural areas to fulfil their dream of homes with gardens and cricket on the green. So many metropolitan dwellers have made the move that property prices in the more popular locations have become amongst the most expensive in the country.", "hypothesis": "New technology is the reason why it is possible for working families to relocate without affecting their earning power.", "gold_label": "neutral"}
{"uid": "id_87", "premise": "Towns that have become commuter and second-home hotspots are valued for their housing stock, schools and unspoilt civic centres. It is now possible for working families to relocate away from cities without affecting their earning power. Commuting three days a week and working from home the rest has meant that many more people are willing to give up the city life and move to more rural areas to fulfil their dream of homes with gardens and cricket on the green. So many metropolitan dwellers have made the move that property prices in the more popular locations have become amongst the most expensive in the country.", "hypothesis": "An idea of an unspoilt civic centre could include, along with cricket on the green, a traditional high street with local shops.", "gold_label": "entailment"}
{"uid": "id_88", "premise": "Towns that have become commuter and second-home hotspots are valued for their housing stock, schools and unspoilt civic centres. It is now possible for working families to relocate away from cities without affecting their earning power. Commuting three days a week and working from home the rest has meant that many more people are willing to give up the city life and move to more rural areas to fulfil their dream of homes with gardens and cricket on the green. So many metropolitan dwellers have made the move that property prices in the more popular locations have become amongst the most expensive in the country.", "hypothesis": "The only reason for these locations becoming so popular is only due to commuting even if for just part of the week.", "gold_label": "contradiction"}
{"uid": "id_89", "premise": "Trade and Early State Formation Bartering was a basic trade mechanism for many thousands of years; often sporadic and usually based on notions of reciprocity, it involved the mutual exchange of commodities or objects between individuals or groups. Redistribution of these goods through society lay in the hands of chiefs, religious leaders, or kin groups. Such redistribution was a basic element in chiefdoms. The change from redistribution to formal trade often based on regulated commerce that perhaps involved fixed prices and even currency was closely tied to growing political and social complexity and hence to the development of the state in the ancient world. In the 1970s, a number of archaeologists gave trade a primary role in the rise of ancient states. British archaeologist Colin Renfrew attributed the dramatic flowering of the Minoan civilization on Crete and through the Aegean to intensified trading contacts and to the impact of olive and vine cultivation on local communities. As agricultural economies became more diversified and local food supplies could be purchased both locally and over longer distances, a far-reaching economic interdependence resulted. Eventually, this led to redistribution systems for luxuries and basic commodities, systems that were organized and controlled by Minoan rulers from their palaces. As time went on, the self-sufficiency of communities was replaced by mutual dependence. Interest in long-distance trade brought about some cultural homogeneity from trade and gift exchange, and perhaps even led to piracy. Thus, intensified trade and interaction, and the flowering of specialist crafts, in a complex process of positive feedback, led to much more complex societies based on palaces, which were the economic hubs of a new Minoan civilization. Renfrew's model made some assumptions that are now discounted. For example, he argued that the introduction of domesticated vines and olives allowed a substantial expansion of land under cultivation and helped to power the emergence of complex society. Many archaeologists and paleobotanists now question this view, pointing out that the available evidence for cultivated vines and olives suggests that they were present only in the later Bronze Age. Trade, nevertheless, was probably one of many variables that led to the emergence of palace economies in Minoan Crete. American archaeologist William Rathje developed a hypothesis that considered an explosion in long-distance exchange a fundamental cause of Mayan civilization in Mesoamerica. He suggested that the lowland Mayan environment was deficient in many vital resources, among them obsidian, salt, stone for grinding maize, and many luxury materials. All these could be obtained from the nearby highlands, from the Valley of Mexico, and from other regions, if the necessary trading networks came into being. Such connections, and the trading expeditions to maintain them, could not be organized by individual villages. The Maya lived in a relatively uniform environment, where every community suffered from the same resource deficiencies. Thus, argued Rathje, long-distance trade networks were organized through local ceremonial centers and their leaders. In time, this organization became a state, and knowledge of its functioning was exportable, as were pottery, tropical bird feathers, specialized stone materials, and other local commodities. Rathje's hypothesis probably explains part of the complex process of Mayan state formation, but it suffers from the objection that suitable alternative raw materials can be found in the lowlands. It could be, too, that warfare became a competitive response to population growth and to the increasing scarcity of prime agricultural land, and that it played an important role in the emergence of the Mayan states.", "hypothesis": "The regulation of profits provided incentives for future trade.", "gold_label": "entailment"}
{"uid": "id_90", "premise": "Trade and Early State Formation Bartering was a basic trade mechanism for many thousands of years; often sporadic and usually based on notions of reciprocity, it involved the mutual exchange of commodities or objects between individuals or groups. Redistribution of these goods through society lay in the hands of chiefs, religious leaders, or kin groups. Such redistribution was a basic element in chiefdoms. The change from redistribution to formal trade often based on regulated commerce that perhaps involved fixed prices and even currency was closely tied to growing political and social complexity and hence to the development of the state in the ancient world. In the 1970s, a number of archaeologists gave trade a primary role in the rise of ancient states. British archaeologist Colin Renfrew attributed the dramatic flowering of the Minoan civilization on Crete and through the Aegean to intensified trading contacts and to the impact of olive and vine cultivation on local communities. As agricultural economies became more diversified and local food supplies could be purchased both locally and over longer distances, a far-reaching economic interdependence resulted. Eventually, this led to redistribution systems for luxuries and basic commodities, systems that were organized and controlled by Minoan rulers from their palaces. As time went on, the self-sufficiency of communities was replaced by mutual dependence. Interest in long-distance trade brought about some cultural homogeneity from trade and gift exchange, and perhaps even led to piracy. Thus, intensified trade and interaction, and the flowering of specialist crafts, in a complex process of positive feedback, led to much more complex societies based on palaces, which were the economic hubs of a new Minoan civilization. Renfrew's model made some assumptions that are now discounted. For example, he argued that the introduction of domesticated vines and olives allowed a substantial expansion of land under cultivation and helped to power the emergence of complex society. Many archaeologists and paleobotanists now question this view, pointing out that the available evidence for cultivated vines and olives suggests that they were present only in the later Bronze Age. Trade, nevertheless, was probably one of many variables that led to the emergence of palace economies in Minoan Crete. American archaeologist William Rathje developed a hypothesis that considered an explosion in long-distance exchange a fundamental cause of Mayan civilization in Mesoamerica. He suggested that the lowland Mayan environment was deficient in many vital resources, among them obsidian, salt, stone for grinding maize, and many luxury materials. All these could be obtained from the nearby highlands, from the Valley of Mexico, and from other regions, if the necessary trading networks came into being. Such connections, and the trading expeditions to maintain them, could not be organized by individual villages. The Maya lived in a relatively uniform environment, where every community suffered from the same resource deficiencies. Thus, argued Rathje, long-distance trade networks were organized through local ceremonial centers and their leaders. In time, this organization became a state, and knowledge of its functioning was exportable, as were pottery, tropical bird feathers, specialized stone materials, and other local commodities. Rathje's hypothesis probably explains part of the complex process of Mayan state formation, but it suffers from the objection that suitable alternative raw materials can be found in the lowlands. It could be, too, that warfare became a competitive response to population growth and to the increasing scarcity of prime agricultural land, and that it played an important role in the emergence of the Mayan states.", "hypothesis": "Some markets had clearly established trading routes.", "gold_label": "entailment"}
{"uid": "id_91", "premise": "Trade and Early State Formation Bartering was a basic trade mechanism for many thousands of years; often sporadic and usually based on notions of reciprocity, it involved the mutual exchange of commodities or objects between individuals or groups. Redistribution of these goods through society lay in the hands of chiefs, religious leaders, or kin groups. Such redistribution was a basic element in chiefdoms. The change from redistribution to formal trade often based on regulated commerce that perhaps involved fixed prices and even currency was closely tied to growing political and social complexity and hence to the development of the state in the ancient world. In the 1970s, a number of archaeologists gave trade a primary role in the rise of ancient states. British archaeologist Colin Renfrew attributed the dramatic flowering of the Minoan civilization on Crete and through the Aegean to intensified trading contacts and to the impact of olive and vine cultivation on local communities. As agricultural economies became more diversified and local food supplies could be purchased both locally and over longer distances, a far-reaching economic interdependence resulted. Eventually, this led to redistribution systems for luxuries and basic commodities, systems that were organized and controlled by Minoan rulers from their palaces. As time went on, the self-sufficiency of communities was replaced by mutual dependence. Interest in long-distance trade brought about some cultural homogeneity from trade and gift exchange, and perhaps even led to piracy. Thus, intensified trade and interaction, and the flowering of specialist crafts, in a complex process of positive feedback, led to much more complex societies based on palaces, which were the economic hubs of a new Minoan civilization. Renfrew's model made some assumptions that are now discounted. For example, he argued that the introduction of domesticated vines and olives allowed a substantial expansion of land under cultivation and helped to power the emergence of complex society. Many archaeologists and paleobotanists now question this view, pointing out that the available evidence for cultivated vines and olives suggests that they were present only in the later Bronze Age. Trade, nevertheless, was probably one of many variables that led to the emergence of palace economies in Minoan Crete. American archaeologist William Rathje developed a hypothesis that considered an explosion in long-distance exchange a fundamental cause of Mayan civilization in Mesoamerica. He suggested that the lowland Mayan environment was deficient in many vital resources, among them obsidian, salt, stone for grinding maize, and many luxury materials. All these could be obtained from the nearby highlands, from the Valley of Mexico, and from other regions, if the necessary trading networks came into being. Such connections, and the trading expeditions to maintain them, could not be organized by individual villages. The Maya lived in a relatively uniform environment, where every community suffered from the same resource deficiencies. Thus, argued Rathje, long-distance trade networks were organized through local ceremonial centers and their leaders. In time, this organization became a state, and knowledge of its functioning was exportable, as were pottery, tropical bird feathers, specialized stone materials, and other local commodities. Rathje's hypothesis probably explains part of the complex process of Mayan state formation, but it suffers from the objection that suitable alternative raw materials can be found in the lowlands. It could be, too, that warfare became a competitive response to population growth and to the increasing scarcity of prime agricultural land, and that it played an important role in the emergence of the Mayan states.", "hypothesis": "Political conditions were more important than demand for goods in the development of trade.", "gold_label": "neutral"}
{"uid": "id_92", "premise": "Trade and Early State Formation Bartering was a basic trade mechanism for many thousands of years; often sporadic and usually based on notions of reciprocity, it involved the mutual exchange of commodities or objects between individuals or groups. Redistribution of these goods through society lay in the hands of chiefs, religious leaders, or kin groups. Such redistribution was a basic element in chiefdoms. The change from redistribution to formal trade often based on regulated commerce that perhaps involved fixed prices and even currency was closely tied to growing political and social complexity and hence to the development of the state in the ancient world. In the 1970s, a number of archaeologists gave trade a primary role in the rise of ancient states. British archaeologist Colin Renfrew attributed the dramatic flowering of the Minoan civilization on Crete and through the Aegean to intensified trading contacts and to the impact of olive and vine cultivation on local communities. As agricultural economies became more diversified and local food supplies could be purchased both locally and over longer distances, a far-reaching economic interdependence resulted. Eventually, this led to redistribution systems for luxuries and basic commodities, systems that were organized and controlled by Minoan rulers from their palaces. As time went on, the self-sufficiency of communities was replaced by mutual dependence. Interest in long-distance trade brought about some cultural homogeneity from trade and gift exchange, and perhaps even led to piracy. Thus, intensified trade and interaction, and the flowering of specialist crafts, in a complex process of positive feedback, led to much more complex societies based on palaces, which were the economic hubs of a new Minoan civilization. Renfrew's model made some assumptions that are now discounted. For example, he argued that the introduction of domesticated vines and olives allowed a substantial expansion of land under cultivation and helped to power the emergence of complex society. Many archaeologists and paleobotanists now question this view, pointing out that the available evidence for cultivated vines and olives suggests that they were present only in the later Bronze Age. Trade, nevertheless, was probably one of many variables that led to the emergence of palace economies in Minoan Crete. American archaeologist William Rathje developed a hypothesis that considered an explosion in long-distance exchange a fundamental cause of Mayan civilization in Mesoamerica. He suggested that the lowland Mayan environment was deficient in many vital resources, among them obsidian, salt, stone for grinding maize, and many luxury materials. All these could be obtained from the nearby highlands, from the Valley of Mexico, and from other regions, if the necessary trading networks came into being. Such connections, and the trading expeditions to maintain them, could not be organized by individual villages. The Maya lived in a relatively uniform environment, where every community suffered from the same resource deficiencies. Thus, argued Rathje, long-distance trade networks were organized through local ceremonial centers and their leaders. In time, this organization became a state, and knowledge of its functioning was exportable, as were pottery, tropical bird feathers, specialized stone materials, and other local commodities. Rathje's hypothesis probably explains part of the complex process of Mayan state formation, but it suffers from the objection that suitable alternative raw materials can be found in the lowlands. It could be, too, that warfare became a competitive response to population growth and to the increasing scarcity of prime agricultural land, and that it played an important role in the emergence of the Mayan states.", "hypothesis": "The spread of trade was influenced by many variables, none of which was the main cause.", "gold_label": "entailment"}
{"uid": "id_93", "premise": "Traditional Farming System in Africa A. By tradition land in Luapula is not owned by individuals, but as in many other parts of Africa is allocated by the headman or headwoman of a village to people of either sex, according to need. Since land is generally prepared by hand, one ulupwa cannot take on a very large area; in this sense land has not been a limiting resource over large parts of the province. The situation has already changed near the main townships, and there has long been a scarcity of land for cultivation in the Valley. In these areas registered ownership patterns are becoming prevalent. B. Most of the traditional cropping in Luapula, as in the Bemba area to the east, is based on citemene, a system whereby crops are grown on the ashes of tree branches. As a rule, entire trees are not felled, but are pollarded so that they can regenerate. Branches are cut over an area of varying size early in the dry season, and stacked to dry over a rough circle about a fifth to a tenth of the pollarded area. The wood is fired before the rains and in the first year planted with the African cereal finger millet (Eleusine coracana). C. During the second season, and possibly for a few seasons more the area is planted to variously mixed combinations of annuals such as maize, pumpkins (Telfiria occidentalis) and other cucurbits, sweet potatoes, groundnuts, Phaseolus beans and various leafy vegetables, grown with a certain amount of rotation. The diverse sequence ends with vegetable cassava, which is often planted into the developing last-but-one crop as a relay. D. Richards (1969) observed that the practice of citemene entails a definite division of labour between men and women. A man stakes out a plot in an unobtrusive manner, since it is considered provocative towards one's neighbours to mark boundaries in an explicit way. The dangerous work of felling branches is the men's province, and involves much pride. Branches are stacke by the women, and fired by the men. Formerly women and men cooperated in the planting work, but the harvesting was always done by the women. At the beginning of thecycle little weeding is necessary, since the firing of the branches effectively destroys weeds. As the cycle progresses weeds increase and nutrients eventually become depleted to a point where further effort with annual crops is judged to be not worthwhile: at this point the cassava is planted, since it can produce a crop on nearly exhausted soil. Thereafter the plot is abandoned, and a new area pollarded for the next citemene cycle. E. When forest is not available - this is increasingly the case nowadays - various ridging systems (ibala) are built on small areas, to be planted with combinations of maize, beans, groundnuts and sweet potatoes, usually relayed with cassava. These plots are usually tended by women, and provide subsistence. Where their roots have year-round access to water tables mango, guava and oil-palm trees often grow around houses, forming a traditional agroforestry system. In season some of the fruit is sold by the roadside or in local markets. F. The margins of dambos are sometimes planted to local varieties of rice during the rainy season, and areas adjacent to vegetables irrigated with water from the dambo during the dry season. The extent of cultivation is very limited, no doubt because the growing of crops under dambo conditions calls for a great deal of skill. Near towns some of the vegetable produce is sold in local markets. G. Fishing has long provided a much needed protein supplement to the diet of Luapulans, as well as being the one substantial source of cash. Much fish is dried for sale to areas away from the main waterways. The Mweru and Bangweulu Lake Basins are the main areas of year-round fishing, but the Luapula River is also exploited during the latter part of the dry season. Several previously abundant and desirable species, such as the Luapula salmon or mpumbu (Labeoaltivelis) and pale (Sarotherodon machochir) have all but disappeared from Lake Mweru, apparently due to mismanagement. H. Fishing has always been a far more remunerative activity in Luapula that crop husbandry. A fisherman may earn more in a week than a bean or maize grower in a whole season. I sometimes heard claims that the relatively high earnings to be obtained from fishing induced an easy come, easy go outlook among Luapulan men. On the other hand, someone who secures good but erratic earnings may feel that their investment in an economically productive activity is not worthwhile because Luapulans fail to cooperate well in such activities. Besides, a fisherman with spare cash will find little in the way of working equipment to spend his money on. Better spend one's money in the bars and have a good time! I. Only small numbers of cattle or oxen are kept in the province owing to the prevalence of the tse-tse fly. For the few herds, the dambos provide subsistence grazing during the dry season. The absence of animal draft power greatly limits peoples' ability to plough and cultivate land: a married couple can rarely manage to prepare by hand-hoeing. Most people keep freely roaming chickens and goats. These act as a reserve for bartering, but may also be occasionally slaughtered for ceremonies or for entertaining important visitors. These animals are not a regular part of most peoples' diet. J. Citemene has been an ingenious system for providing people with seasonal production of high quality cereals and vegetables in regions of acid, heavily leached soils. Nutritionally, the most serious deficiency was that of protein. This could at times be alleviated when fish was available, provided that cultivators lived near the Valley and could find the means of bartering for dried fish. The citemene/fishing system was well adapted to the ecology of the miombo regions and sustainable for long periods, but only as long as human population densities stayed at low levels. Although population densities are still much lower than in several countries of South-East Asia, neither the fisheries nor the forests and woodlands of Luapula are capable, with unmodified traditional practices, of supporting the people in a sustainable manner. Overall, people must learn to intensify and diversify their productive systems while yet ensuring that these systems will remain productive in the future, when even more people will need food. Increasing overall production offood, though a vast challenge in itself, will not be enough, however. At the same time storage and distribution systems must allow everyone access to at least a moderate share of the total.", "hypothesis": "People rarely use animals to cultivate land.", "gold_label": "entailment"}
{"uid": "id_94", "premise": "Traditional Farming System in Africa A. By tradition land in Luapula is not owned by individuals, but as in many other parts of Africa is allocated by the headman or headwoman of a village to people of either sex, according to need. Since land is generally prepared by hand, one ulupwa cannot take on a very large area; in this sense land has not been a limiting resource over large parts of the province. The situation has already changed near the main townships, and there has long been a scarcity of land for cultivation in the Valley. In these areas registered ownership patterns are becoming prevalent. B. Most of the traditional cropping in Luapula, as in the Bemba area to the east, is based on citemene, a system whereby crops are grown on the ashes of tree branches. As a rule, entire trees are not felled, but are pollarded so that they can regenerate. Branches are cut over an area of varying size early in the dry season, and stacked to dry over a rough circle about a fifth to a tenth of the pollarded area. The wood is fired before the rains and in the first year planted with the African cereal finger millet (Eleusine coracana). C. During the second season, and possibly for a few seasons more the area is planted to variously mixed combinations of annuals such as maize, pumpkins (Telfiria occidentalis) and other cucurbits, sweet potatoes, groundnuts, Phaseolus beans and various leafy vegetables, grown with a certain amount of rotation. The diverse sequence ends with vegetable cassava, which is often planted into the developing last-but-one crop as a relay. D. Richards (1969) observed that the practice of citemene entails a definite division of labour between men and women. A man stakes out a plot in an unobtrusive manner, since it is considered provocative towards one's neighbours to mark boundaries in an explicit way. The dangerous work of felling branches is the men's province, and involves much pride. Branches are stacke by the women, and fired by the men. Formerly women and men cooperated in the planting work, but the harvesting was always done by the women. At the beginning of thecycle little weeding is necessary, since the firing of the branches effectively destroys weeds. As the cycle progresses weeds increase and nutrients eventually become depleted to a point where further effort with annual crops is judged to be not worthwhile: at this point the cassava is planted, since it can produce a crop on nearly exhausted soil. Thereafter the plot is abandoned, and a new area pollarded for the next citemene cycle. E. When forest is not available - this is increasingly the case nowadays - various ridging systems (ibala) are built on small areas, to be planted with combinations of maize, beans, groundnuts and sweet potatoes, usually relayed with cassava. These plots are usually tended by women, and provide subsistence. Where their roots have year-round access to water tables mango, guava and oil-palm trees often grow around houses, forming a traditional agroforestry system. In season some of the fruit is sold by the roadside or in local markets. F. The margins of dambos are sometimes planted to local varieties of rice during the rainy season, and areas adjacent to vegetables irrigated with water from the dambo during the dry season. The extent of cultivation is very limited, no doubt because the growing of crops under dambo conditions calls for a great deal of skill. Near towns some of the vegetable produce is sold in local markets. G. Fishing has long provided a much needed protein supplement to the diet of Luapulans, as well as being the one substantial source of cash. Much fish is dried for sale to areas away from the main waterways. The Mweru and Bangweulu Lake Basins are the main areas of year-round fishing, but the Luapula River is also exploited during the latter part of the dry season. Several previously abundant and desirable species, such as the Luapula salmon or mpumbu (Labeoaltivelis) and pale (Sarotherodon machochir) have all but disappeared from Lake Mweru, apparently due to mismanagement. H. Fishing has always been a far more remunerative activity in Luapula that crop husbandry. A fisherman may earn more in a week than a bean or maize grower in a whole season. I sometimes heard claims that the relatively high earnings to be obtained from fishing induced an easy come, easy go outlook among Luapulan men. On the other hand, someone who secures good but erratic earnings may feel that their investment in an economically productive activity is not worthwhile because Luapulans fail to cooperate well in such activities. Besides, a fisherman with spare cash will find little in the way of working equipment to spend his money on. Better spend one's money in the bars and have a good time! I. Only small numbers of cattle or oxen are kept in the province owing to the prevalence of the tse-tse fly. For the few herds, the dambos provide subsistence grazing during the dry season. The absence of animal draft power greatly limits peoples' ability to plough and cultivate land: a married couple can rarely manage to prepare by hand-hoeing. Most people keep freely roaming chickens and goats. These act as a reserve for bartering, but may also be occasionally slaughtered for ceremonies or for entertaining important visitors. These animals are not a regular part of most peoples' diet. J. Citemene has been an ingenious system for providing people with seasonal production of high quality cereals and vegetables in regions of acid, heavily leached soils. Nutritionally, the most serious deficiency was that of protein. This could at times be alleviated when fish was available, provided that cultivators lived near the Valley and could find the means of bartering for dried fish. The citemene/fishing system was well adapted to the ecology of the miombo regions and sustainable for long periods, but only as long as human population densities stayed at low levels. Although population densities are still much lower than in several countries of South-East Asia, neither the fisheries nor the forests and woodlands of Luapula are capable, with unmodified traditional practices, of supporting the people in a sustainable manner. Overall, people must learn to intensify and diversify their productive systems while yet ensuring that these systems will remain productive in the future, when even more people will need food. Increasing overall production offood, though a vast challenge in itself, will not be enough, however. At the same time storage and distribution systems must allow everyone access to at least a moderate share of the total.", "hypothesis": "Though citemene has been a sophisticated system, it could not provide enough protein.", "gold_label": "entailment"}
{"uid": "id_95", "premise": "Traditional Farming System in Africa A. By tradition land in Luapula is not owned by individuals, but as in many other parts of Africa is allocated by the headman or headwoman of a village to people of either sex, according to need. Since land is generally prepared by hand, one ulupwa cannot take on a very large area; in this sense land has not been a limiting resource over large parts of the province. The situation has already changed near the main townships, and there has long been a scarcity of land for cultivation in the Valley. In these areas registered ownership patterns are becoming prevalent. B. Most of the traditional cropping in Luapula, as in the Bemba area to the east, is based on citemene, a system whereby crops are grown on the ashes of tree branches. As a rule, entire trees are not felled, but are pollarded so that they can regenerate. Branches are cut over an area of varying size early in the dry season, and stacked to dry over a rough circle about a fifth to a tenth of the pollarded area. The wood is fired before the rains and in the first year planted with the African cereal finger millet (Eleusine coracana). C. During the second season, and possibly for a few seasons more the area is planted to variously mixed combinations of annuals such as maize, pumpkins (Telfiria occidentalis) and other cucurbits, sweet potatoes, groundnuts, Phaseolus beans and various leafy vegetables, grown with a certain amount of rotation. The diverse sequence ends with vegetable cassava, which is often planted into the developing last-but-one crop as a relay. D. Richards (1969) observed that the practice of citemene entails a definite division of labour between men and women. A man stakes out a plot in an unobtrusive manner, since it is considered provocative towards one's neighbours to mark boundaries in an explicit way. The dangerous work of felling branches is the men's province, and involves much pride. Branches are stacke by the women, and fired by the men. Formerly women and men cooperated in the planting work, but the harvesting was always done by the women. At the beginning of thecycle little weeding is necessary, since the firing of the branches effectively destroys weeds. As the cycle progresses weeds increase and nutrients eventually become depleted to a point where further effort with annual crops is judged to be not worthwhile: at this point the cassava is planted, since it can produce a crop on nearly exhausted soil. Thereafter the plot is abandoned, and a new area pollarded for the next citemene cycle. E. When forest is not available - this is increasingly the case nowadays - various ridging systems (ibala) are built on small areas, to be planted with combinations of maize, beans, groundnuts and sweet potatoes, usually relayed with cassava. These plots are usually tended by women, and provide subsistence. Where their roots have year-round access to water tables mango, guava and oil-palm trees often grow around houses, forming a traditional agroforestry system. In season some of the fruit is sold by the roadside or in local markets. F. The margins of dambos are sometimes planted to local varieties of rice during the rainy season, and areas adjacent to vegetables irrigated with water from the dambo during the dry season. The extent of cultivation is very limited, no doubt because the growing of crops under dambo conditions calls for a great deal of skill. Near towns some of the vegetable produce is sold in local markets. G. Fishing has long provided a much needed protein supplement to the diet of Luapulans, as well as being the one substantial source of cash. Much fish is dried for sale to areas away from the main waterways. The Mweru and Bangweulu Lake Basins are the main areas of year-round fishing, but the Luapula River is also exploited during the latter part of the dry season. Several previously abundant and desirable species, such as the Luapula salmon or mpumbu (Labeoaltivelis) and pale (Sarotherodon machochir) have all but disappeared from Lake Mweru, apparently due to mismanagement. H. Fishing has always been a far more remunerative activity in Luapula that crop husbandry. A fisherman may earn more in a week than a bean or maize grower in a whole season. I sometimes heard claims that the relatively high earnings to be obtained from fishing induced an easy come, easy go outlook among Luapulan men. On the other hand, someone who secures good but erratic earnings may feel that their investment in an economically productive activity is not worthwhile because Luapulans fail to cooperate well in such activities. Besides, a fisherman with spare cash will find little in the way of working equipment to spend his money on. Better spend one's money in the bars and have a good time! I. Only small numbers of cattle or oxen are kept in the province owing to the prevalence of the tse-tse fly. For the few herds, the dambos provide subsistence grazing during the dry season. The absence of animal draft power greatly limits peoples' ability to plough and cultivate land: a married couple can rarely manage to prepare by hand-hoeing. Most people keep freely roaming chickens and goats. These act as a reserve for bartering, but may also be occasionally slaughtered for ceremonies or for entertaining important visitors. These animals are not a regular part of most peoples' diet. J. Citemene has been an ingenious system for providing people with seasonal production of high quality cereals and vegetables in regions of acid, heavily leached soils. Nutritionally, the most serious deficiency was that of protein. This could at times be alleviated when fish was available, provided that cultivators lived near the Valley and could find the means of bartering for dried fish. The citemene/fishing system was well adapted to the ecology of the miombo regions and sustainable for long periods, but only as long as human population densities stayed at low levels. Although population densities are still much lower than in several countries of South-East Asia, neither the fisheries nor the forests and woodlands of Luapula are capable, with unmodified traditional practices, of supporting the people in a sustainable manner. Overall, people must learn to intensify and diversify their productive systems while yet ensuring that these systems will remain productive in the future, when even more people will need food. Increasing overall production offood, though a vast challenge in itself, will not be enough, however. At the same time storage and distribution systems must allow everyone access to at least a moderate share of the total.", "hypothesis": "When it is a busy time, children usually took part in the labor force.", "gold_label": "neutral"}
{"uid": "id_96", "premise": "Traditional Farming System in Africa A. By tradition land in Luapula is not owned by individuals, but as in many other parts of Africa is allocated by the headman or headwoman of a village to people of either sex, according to need. Since land is generally prepared by hand, one ulupwa cannot take on a very large area; in this sense land has not been a limiting resource over large parts of the province. The situation has already changed near the main townships, and there has long been a scarcity of land for cultivation in the Valley. In these areas registered ownership patterns are becoming prevalent. B. Most of the traditional cropping in Luapula, as in the Bemba area to the east, is based on citemene, a system whereby crops are grown on the ashes of tree branches. As a rule, entire trees are not felled, but are pollarded so that they can regenerate. Branches are cut over an area of varying size early in the dry season, and stacked to dry over a rough circle about a fifth to a tenth of the pollarded area. The wood is fired before the rains and in the first year planted with the African cereal finger millet (Eleusine coracana). C. During the second season, and possibly for a few seasons more the area is planted to variously mixed combinations of annuals such as maize, pumpkins (Telfiria occidentalis) and other cucurbits, sweet potatoes, groundnuts, Phaseolus beans and various leafy vegetables, grown with a certain amount of rotation. The diverse sequence ends with vegetable cassava, which is often planted into the developing last-but-one crop as a relay. D. Richards (1969) observed that the practice of citemene entails a definite division of labour between men and women. A man stakes out a plot in an unobtrusive manner, since it is considered provocative towards one's neighbours to mark boundaries in an explicit way. The dangerous work of felling branches is the men's province, and involves much pride. Branches are stacke by the women, and fired by the men. Formerly women and men cooperated in the planting work, but the harvesting was always done by the women. At the beginning of thecycle little weeding is necessary, since the firing of the branches effectively destroys weeds. As the cycle progresses weeds increase and nutrients eventually become depleted to a point where further effort with annual crops is judged to be not worthwhile: at this point the cassava is planted, since it can produce a crop on nearly exhausted soil. Thereafter the plot is abandoned, and a new area pollarded for the next citemene cycle. E. When forest is not available - this is increasingly the case nowadays - various ridging systems (ibala) are built on small areas, to be planted with combinations of maize, beans, groundnuts and sweet potatoes, usually relayed with cassava. These plots are usually tended by women, and provide subsistence. Where their roots have year-round access to water tables mango, guava and oil-palm trees often grow around houses, forming a traditional agroforestry system. In season some of the fruit is sold by the roadside or in local markets. F. The margins of dambos are sometimes planted to local varieties of rice during the rainy season, and areas adjacent to vegetables irrigated with water from the dambo during the dry season. The extent of cultivation is very limited, no doubt because the growing of crops under dambo conditions calls for a great deal of skill. Near towns some of the vegetable produce is sold in local markets. G. Fishing has long provided a much needed protein supplement to the diet of Luapulans, as well as being the one substantial source of cash. Much fish is dried for sale to areas away from the main waterways. The Mweru and Bangweulu Lake Basins are the main areas of year-round fishing, but the Luapula River is also exploited during the latter part of the dry season. Several previously abundant and desirable species, such as the Luapula salmon or mpumbu (Labeoaltivelis) and pale (Sarotherodon machochir) have all but disappeared from Lake Mweru, apparently due to mismanagement. H. Fishing has always been a far more remunerative activity in Luapula that crop husbandry. A fisherman may earn more in a week than a bean or maize grower in a whole season. I sometimes heard claims that the relatively high earnings to be obtained from fishing induced an easy come, easy go outlook among Luapulan men. On the other hand, someone who secures good but erratic earnings may feel that their investment in an economically productive activity is not worthwhile because Luapulans fail to cooperate well in such activities. Besides, a fisherman with spare cash will find little in the way of working equipment to spend his money on. Better spend one's money in the bars and have a good time! I. Only small numbers of cattle or oxen are kept in the province owing to the prevalence of the tse-tse fly. For the few herds, the dambos provide subsistence grazing during the dry season. The absence of animal draft power greatly limits peoples' ability to plough and cultivate land: a married couple can rarely manage to prepare by hand-hoeing. Most people keep freely roaming chickens and goats. These act as a reserve for bartering, but may also be occasionally slaughtered for ceremonies or for entertaining important visitors. These animals are not a regular part of most peoples' diet. J. Citemene has been an ingenious system for providing people with seasonal production of high quality cereals and vegetables in regions of acid, heavily leached soils. Nutritionally, the most serious deficiency was that of protein. This could at times be alleviated when fish was available, provided that cultivators lived near the Valley and could find the means of bartering for dried fish. The citemene/fishing system was well adapted to the ecology of the miombo regions and sustainable for long periods, but only as long as human population densities stayed at low levels. Although population densities are still much lower than in several countries of South-East Asia, neither the fisheries nor the forests and woodlands of Luapula are capable, with unmodified traditional practices, of supporting the people in a sustainable manner. Overall, people must learn to intensify and diversify their productive systems while yet ensuring that these systems will remain productive in the future, when even more people will need food. Increasing overall production offood, though a vast challenge in itself, will not be enough, however. At the same time storage and distribution systems must allow everyone access to at least a moderate share of the total.", "hypothesis": "The local residents eat goats on a regular time.", "gold_label": "entailment"}
{"uid": "id_97", "premise": "Traditionally medicine was the science of curing illness with treatments. For thousands of years people would have used plants and would have turned to priests for cures. In more recent times illness has been attributed less to the intervention of gods or magic and instead to natural causes. Medicine today is as much concerned with prevention as cure. Doctors use treatments of many types, including radiation and vaccination, both of which were unknown until very recent times. Other treatments have been known about and practised for centuries. Muslim doctors were skilled surgeons and treated pain with opium. When Europeans first reached the Americas they found healers who used many plants to cure illnesses. The Europeans adopted many of these treatments and some are still effective and in use today.", "hypothesis": "Vaccination is a relatively recent discovery.", "gold_label": "entailment"}
{"uid": "id_98", "premise": "Traditionally medicine was the science of curing illness with treatments. For thousands of years people would have used plants and would have turned to priests for cures. In more recent times illness has been attributed less to the intervention of gods or magic and instead to natural causes. Medicine today is as much concerned with prevention as cure. Doctors use treatments of many types, including radiation and vaccination, both of which were unknown until very recent times. Other treatments have been known about and practised for centuries. Muslim doctors were skilled surgeons and treated pain with opium. When Europeans first reached the Americas they found healers who used many plants to cure illnesses. The Europeans adopted many of these treatments and some are still effective and in use today.", "hypothesis": "Practitioners of modern medicine make use of many techniques and technologies.", "gold_label": "entailment"}
{"uid": "id_99", "premise": "Traditionally medicine was the science of curing illness with treatments. For thousands of years people would have used plants and would have turned to priests for cures. In more recent times illness has been attributed less to the intervention of gods or magic and instead to natural causes. Medicine today is as much concerned with prevention as cure. Doctors use treatments of many types, including radiation and vaccination, both of which were unknown until very recent times. Other treatments have been known about and practised for centuries. Muslim doctors were skilled surgeons and treated pain with opium. When Europeans first reached the Americas they found healers who used many plants to cure illnesses. The Europeans adopted many of these treatments and some are still effective and in use today.", "hypothesis": "The author of the passage believes that prevention is better than cure.", "gold_label": "neutral"}
{"uid": "id_100", "premise": "Traditionally medicine was the science of curing illness with treatments. For thousands of years people would have used plants and would have turned to priests for cures. In more recent times illness has been attributed less to the intervention of gods or magic and instead to natural causes. Medicine today is as much concerned with prevention as cure. Doctors use treatments of many types, including radiation and vaccination, both of which were unknown until very recent times. Other treatments have been known about and practised for centuries. Muslim doctors were skilled surgeons and treated pain with opium. When Europeans first reached the Americas they found healers who used many plants to cure illnesses. The Europeans adopted many of these treatments and some are still effective and in use today.", "hypothesis": "Medicine is a science that owes its success to modern treatments.", "gold_label": "contradiction"}
{"uid": "id_101", "premise": "Traditionally medicine was the science of curing illness with treatments. For thousands of years people would have used plants and would have turned to priests for cures. In more recent times illness has been attributed less to the intervention of gods or magic and instead to natural causes. Medicine today is as much concerned with prevention as cure. Doctors use treatments of many types, including radiation and vaccination, both of which were unknown until very recent times. Other treatments have been known about and practised for centuries. Muslim doctors were skilled surgeons and treated pain with opium. When Europeans first reached the Americas they found healers who used many plants to cure illnesses. The Europeans adopted many of these treatments and some are still effective and in use today.", "hypothesis": "Modern medicine is the science of curing illness.", "gold_label": "contradiction"}
{"uid": "id_102", "premise": "Traditionally uniforms were and for some industries still are manufactured to protect the worker. When they were first designed, it is also likely that all uniforms made symbolic sense - those for the military, for example, were originally intended to impress and even terrify the enemy; other uniforms denoted a hierarchy - chefs wore white because they worked with flour, but the main chef wore a black hat to show he supervised. The last 30 years, however, have seen an increasing emphasis on their role in projecting the image of an organisation and in uniting the workforce into a homogeneous unit particularly in customer facing\" industries, and especially in financial services and retailing. From uniforms and workwear has emerged corporate clothing. \"The people you employ are your ambassadors, \" says Peter Griffin, managing director of a major retailer in the UK. \"What they say, how they look, and how they behave is terribly important. \" The result is a new way of looking at corporate workwear. From being a simple means of identifying who is a member of staff, the uniform is emerging as a new channel of marketing communication. Truly effective marketing through visual cues such as uniforms is a subtle art, however. Wittingly or unwittingly, how we look sends all sorts of powerful subliminal messages to other people. Dark colours give an aura of authority while lighter pastel shades suggest approachability. Certain dress style creates a sense of conservatism, others a sense of openness to new ideas. Neatness can suggest efficiency but, if it is overdone, it can spill over and indicate an obsession with power. \"If the company is selling quality, then it must have quality uniforms. If it is selling style, its uniforms must be stylish. If it wants to appear innovative, everybody cant look exactly the same. Subliminally we see all these things, \" says Lynn Elvy, a director of image consultants House of Colour. But translating corporate philosophies into the right mix of colour, style, degree of branding and uniformity can be a fraught process. And it is not always successful. According to Company Clothing magazine, there are 1000 companies supplying the workwear and corporate clothing market. Of these, 22 account for 85% of total sales - 380 million in 1994. A successful uniform needs to balance two key sets of needs. On the one hand, no uniform will work if staff feel uncomfortable or ugly. Giving the wearers a choice has become a key element in the way corporate clothing is introduced and managed. On the other, it is pointless if the look doesnt express the businesss marketing strategy. The greatest challenge in this respect is time. When it comes to human perceptions, first impressions count. Customers will size up the way staff look in just a few seconds, and that few seconds will colour their attitudes from then on. Those few seconds can beReading so important that big companies are prepared to invest years, and millions of pounds, getting them right. In addition, some uniform companies also offer rental services. \"There will be an increasing specialisation in the marketplace, \" predicts Mr Blyth, Customer Services Manager of a large UK bank. The past two or three years have seen consolidation. Increasingly, the big suppliers are becoming managing agents, which means they offer a total service to put together the whole complex operation of a companys corporate clothing package - which includes reliable sourcing, managing the inventory, budget control and distribution to either central locations or to each staff member individually. Huge investments have been made in new systems, information technology and amassing quality assurance accreditations. Corporate clothing does have potential for further growth. Some banks have yet to introduce a full corporate look; police forces are researching a complete new look for the 21st century. And many employees now welcome a company wardrobe. A recent survey of staff found that 90 per cent welcomed having clothing which reflected the corporate identity.", "hypothesis": "Clothing companies are planning to offer financial services in the future.", "gold_label": "contradiction"}
{"uid": "id_103", "premise": "Traditionally uniforms were and for some industries still are manufactured to protect the worker. When they were first designed, it is also likely that all uniforms made symbolic sense - those for the military, for example, were originally intended to impress and even terrify the enemy; other uniforms denoted a hierarchy - chefs wore white because they worked with flour, but the main chef wore a black hat to show he supervised. The last 30 years, however, have seen an increasing emphasis on their role in projecting the image of an organisation and in uniting the workforce into a homogeneous unit particularly in customer facing\" industries, and especially in financial services and retailing. From uniforms and workwear has emerged corporate clothing. \"The people you employ are your ambassadors, \" says Peter Griffin, managing director of a major retailer in the UK. \"What they say, how they look, and how they behave is terribly important. \" The result is a new way of looking at corporate workwear. From being a simple means of identifying who is a member of staff, the uniform is emerging as a new channel of marketing communication. Truly effective marketing through visual cues such as uniforms is a subtle art, however. Wittingly or unwittingly, how we look sends all sorts of powerful subliminal messages to other people. Dark colours give an aura of authority while lighter pastel shades suggest approachability. Certain dress style creates a sense of conservatism, others a sense of openness to new ideas. Neatness can suggest efficiency but, if it is overdone, it can spill over and indicate an obsession with power. \"If the company is selling quality, then it must have quality uniforms. If it is selling style, its uniforms must be stylish. If it wants to appear innovative, everybody cant look exactly the same. Subliminally we see all these things, \" says Lynn Elvy, a director of image consultants House of Colour. But translating corporate philosophies into the right mix of colour, style, degree of branding and uniformity can be a fraught process. And it is not always successful. According to Company Clothing magazine, there are 1000 companies supplying the workwear and corporate clothing market. Of these, 22 account for 85% of total sales - 380 million in 1994. A successful uniform needs to balance two key sets of needs. On the one hand, no uniform will work if staff feel uncomfortable or ugly. Giving the wearers a choice has become a key element in the way corporate clothing is introduced and managed. On the other, it is pointless if the look doesnt express the businesss marketing strategy. The greatest challenge in this respect is time. When it comes to human perceptions, first impressions count. Customers will size up the way staff look in just a few seconds, and that few seconds will colour their attitudes from then on. Those few seconds can beReading so important that big companies are prepared to invest years, and millions of pounds, getting them right. In addition, some uniform companies also offer rental services. \"There will be an increasing specialisation in the marketplace, \" predicts Mr Blyth, Customer Services Manager of a large UK bank. The past two or three years have seen consolidation. Increasingly, the big suppliers are becoming managing agents, which means they offer a total service to put together the whole complex operation of a companys corporate clothing package - which includes reliable sourcing, managing the inventory, budget control and distribution to either central locations or to each staff member individually. Huge investments have been made in new systems, information technology and amassing quality assurance accreditations. Corporate clothing does have potential for further growth. Some banks have yet to introduce a full corporate look; police forces are researching a complete new look for the 21st century. And many employees now welcome a company wardrobe. A recent survey of staff found that 90 per cent welcomed having clothing which reflected the corporate identity.", "hypothesis": "Uniforms are best selected by marketing consultants.", "gold_label": "neutral"}
{"uid": "id_104", "premise": "Traditionally uniforms were and for some industries still are manufactured to protect the worker. When they were first designed, it is also likely that all uniforms made symbolic sense - those for the military, for example, were originally intended to impress and even terrify the enemy; other uniforms denoted a hierarchy - chefs wore white because they worked with flour, but the main chef wore a black hat to show he supervised. The last 30 years, however, have seen an increasing emphasis on their role in projecting the image of an organisation and in uniting the workforce into a homogeneous unit particularly in customer facing\" industries, and especially in financial services and retailing. From uniforms and workwear has emerged corporate clothing. \"The people you employ are your ambassadors, \" says Peter Griffin, managing director of a major retailer in the UK. \"What they say, how they look, and how they behave is terribly important. \" The result is a new way of looking at corporate workwear. From being a simple means of identifying who is a member of staff, the uniform is emerging as a new channel of marketing communication. Truly effective marketing through visual cues such as uniforms is a subtle art, however. Wittingly or unwittingly, how we look sends all sorts of powerful subliminal messages to other people. Dark colours give an aura of authority while lighter pastel shades suggest approachability. Certain dress style creates a sense of conservatism, others a sense of openness to new ideas. Neatness can suggest efficiency but, if it is overdone, it can spill over and indicate an obsession with power. \"If the company is selling quality, then it must have quality uniforms. If it is selling style, its uniforms must be stylish. If it wants to appear innovative, everybody cant look exactly the same. Subliminally we see all these things, \" says Lynn Elvy, a director of image consultants House of Colour. But translating corporate philosophies into the right mix of colour, style, degree of branding and uniformity can be a fraught process. And it is not always successful. According to Company Clothing magazine, there are 1000 companies supplying the workwear and corporate clothing market. Of these, 22 account for 85% of total sales - 380 million in 1994. A successful uniform needs to balance two key sets of needs. On the one hand, no uniform will work if staff feel uncomfortable or ugly. Giving the wearers a choice has become a key element in the way corporate clothing is introduced and managed. On the other, it is pointless if the look doesnt express the businesss marketing strategy. The greatest challenge in this respect is time. When it comes to human perceptions, first impressions count. Customers will size up the way staff look in just a few seconds, and that few seconds will colour their attitudes from then on. Those few seconds can beReading so important that big companies are prepared to invest years, and millions of pounds, getting them right. In addition, some uniform companies also offer rental services. \"There will be an increasing specialisation in the marketplace, \" predicts Mr Blyth, Customer Services Manager of a large UK bank. The past two or three years have seen consolidation. Increasingly, the big suppliers are becoming managing agents, which means they offer a total service to put together the whole complex operation of a companys corporate clothing package - which includes reliable sourcing, managing the inventory, budget control and distribution to either central locations or to each staff member individually. Huge investments have been made in new systems, information technology and amassing quality assurance accreditations. Corporate clothing does have potential for further growth. Some banks have yet to introduce a full corporate look; police forces are researching a complete new look for the 21st century. And many employees now welcome a company wardrobe. A recent survey of staff found that 90 per cent welcomed having clothing which reflected the corporate identity.", "hypothesis": "Most businesses that supply company clothing are successful.", "gold_label": "contradiction"}
{"uid": "id_105", "premise": "Traditionally uniforms were and for some industries still are manufactured to protect the worker. When they were first designed, it is also likely that all uniforms made symbolic sense - those for the military, for example, were originally intended to impress and even terrify the enemy; other uniforms denoted a hierarchy - chefs wore white because they worked with flour, but the main chef wore a black hat to show he supervised. The last 30 years, however, have seen an increasing emphasis on their role in projecting the image of an organisation and in uniting the workforce into a homogeneous unit particularly in customer facing\" industries, and especially in financial services and retailing. From uniforms and workwear has emerged corporate clothing. \"The people you employ are your ambassadors, \" says Peter Griffin, managing director of a major retailer in the UK. \"What they say, how they look, and how they behave is terribly important. \" The result is a new way of looking at corporate workwear. From being a simple means of identifying who is a member of staff, the uniform is emerging as a new channel of marketing communication. Truly effective marketing through visual cues such as uniforms is a subtle art, however. Wittingly or unwittingly, how we look sends all sorts of powerful subliminal messages to other people. Dark colours give an aura of authority while lighter pastel shades suggest approachability. Certain dress style creates a sense of conservatism, others a sense of openness to new ideas. Neatness can suggest efficiency but, if it is overdone, it can spill over and indicate an obsession with power. \"If the company is selling quality, then it must have quality uniforms. If it is selling style, its uniforms must be stylish. If it wants to appear innovative, everybody cant look exactly the same. Subliminally we see all these things, \" says Lynn Elvy, a director of image consultants House of Colour. But translating corporate philosophies into the right mix of colour, style, degree of branding and uniformity can be a fraught process. And it is not always successful. According to Company Clothing magazine, there are 1000 companies supplying the workwear and corporate clothing market. Of these, 22 account for 85% of total sales - 380 million in 1994. A successful uniform needs to balance two key sets of needs. On the one hand, no uniform will work if staff feel uncomfortable or ugly. Giving the wearers a choice has become a key element in the way corporate clothing is introduced and managed. On the other, it is pointless if the look doesnt express the businesss marketing strategy. The greatest challenge in this respect is time. When it comes to human perceptions, first impressions count. Customers will size up the way staff look in just a few seconds, and that few seconds will colour their attitudes from then on. Those few seconds can beReading so important that big companies are prepared to invest years, and millions of pounds, getting them right. In addition, some uniform companies also offer rental services. \"There will be an increasing specialisation in the marketplace, \" predicts Mr Blyth, Customer Services Manager of a large UK bank. The past two or three years have seen consolidation. Increasingly, the big suppliers are becoming managing agents, which means they offer a total service to put together the whole complex operation of a companys corporate clothing package - which includes reliable sourcing, managing the inventory, budget control and distribution to either central locations or to each staff member individually. Huge investments have been made in new systems, information technology and amassing quality assurance accreditations. Corporate clothing does have potential for further growth. Some banks have yet to introduce a full corporate look; police forces are researching a complete new look for the 21st century. And many employees now welcome a company wardrobe. A recent survey of staff found that 90 per cent welcomed having clothing which reflected the corporate identity.", "hypothesis": "Being too smart could have a negative impact on customers.", "gold_label": "entailment"}
{"uid": "id_106", "premise": "Traditionally uniforms were and for some industries still are manufactured to protect the worker. When they were first designed, it is also likely that all uniforms made symbolic sense - those for the military, for example, were originally intended to impress and even terrify the enemy; other uniforms denoted a hierarchy - chefs wore white because they worked with flour, but the main chef wore a black hat to show he supervised. The last 30 years, however, have seen an increasing emphasis on their role in projecting the image of an organisation and in uniting the workforce into a homogeneous unit particularly in customer facing\" industries, and especially in financial services and retailing. From uniforms and workwear has emerged corporate clothing. \"The people you employ are your ambassadors, \" says Peter Griffin, managing director of a major retailer in the UK. \"What they say, how they look, and how they behave is terribly important. \" The result is a new way of looking at corporate workwear. From being a simple means of identifying who is a member of staff, the uniform is emerging as a new channel of marketing communication. Truly effective marketing through visual cues such as uniforms is a subtle art, however. Wittingly or unwittingly, how we look sends all sorts of powerful subliminal messages to other people. Dark colours give an aura of authority while lighter pastel shades suggest approachability. Certain dress style creates a sense of conservatism, others a sense of openness to new ideas. Neatness can suggest efficiency but, if it is overdone, it can spill over and indicate an obsession with power. \"If the company is selling quality, then it must have quality uniforms. If it is selling style, its uniforms must be stylish. If it wants to appear innovative, everybody cant look exactly the same. Subliminally we see all these things, \" says Lynn Elvy, a director of image consultants House of Colour. But translating corporate philosophies into the right mix of colour, style, degree of branding and uniformity can be a fraught process. And it is not always successful. According to Company Clothing magazine, there are 1000 companies supplying the workwear and corporate clothing market. Of these, 22 account for 85% of total sales - 380 million in 1994. A successful uniform needs to balance two key sets of needs. On the one hand, no uniform will work if staff feel uncomfortable or ugly. Giving the wearers a choice has become a key element in the way corporate clothing is introduced and managed. On the other, it is pointless if the look doesnt express the businesss marketing strategy. The greatest challenge in this respect is time. When it comes to human perceptions, first impressions count. Customers will size up the way staff look in just a few seconds, and that few seconds will colour their attitudes from then on. Those few seconds can beReading so important that big companies are prepared to invest years, and millions of pounds, getting them right. In addition, some uniform companies also offer rental services. \"There will be an increasing specialisation in the marketplace, \" predicts Mr Blyth, Customer Services Manager of a large UK bank. The past two or three years have seen consolidation. Increasingly, the big suppliers are becoming managing agents, which means they offer a total service to put together the whole complex operation of a companys corporate clothing package - which includes reliable sourcing, managing the inventory, budget control and distribution to either central locations or to each staff member individually. Huge investments have been made in new systems, information technology and amassing quality assurance accreditations. Corporate clothing does have potential for further growth. Some banks have yet to introduce a full corporate look; police forces are researching a complete new look for the 21st century. And many employees now welcome a company wardrobe. A recent survey of staff found that 90 per cent welcomed having clothing which reflected the corporate identity.", "hypothesis": "Uniforms were more carefully made in the past than they are today.", "gold_label": "neutral"}
{"uid": "id_107", "premise": "Traditionally uniforms were and for some industries still are manufactured to protect the worker. When they were first designed, it is also likely that all uniforms made symbolic sense - those for the military, for example, were originally intended to impress and even terrify the enemy; other uniforms denoted a hierarchy - chefs wore white because they worked with flour, but the main chef wore a black hat to show he supervised. The last 30 years, however, have seen an increasing emphasis on their role in projecting the image of an organisation and in uniting the workforce into a homogeneous unit particularly in customer facing\" industries, and especially in financial services and retailing. From uniforms and workwear has emerged corporate clothing. \"The people you employ are your ambassadors, \" says Peter Griffin, managing director of a major retailer in the UK. \"What they say, how they look, and how they behave is terribly important. \" The result is a new way of looking at corporate workwear. From being a simple means of identifying who is a member of staff, the uniform is emerging as a new channel of marketing communication. Truly effective marketing through visual cues such as uniforms is a subtle art, however. Wittingly or unwittingly, how we look sends all sorts of powerful subliminal messages to other people. Dark colours give an aura of authority while lighter pastel shades suggest approachability. Certain dress style creates a sense of conservatism, others a sense of openness to new ideas. Neatness can suggest efficiency but, if it is overdone, it can spill over and indicate an obsession with power. \"If the company is selling quality, then it must have quality uniforms. If it is selling style, its uniforms must be stylish. If it wants to appear innovative, everybody cant look exactly the same. Subliminally we see all these things, \" says Lynn Elvy, a director of image consultants House of Colour. But translating corporate philosophies into the right mix of colour, style, degree of branding and uniformity can be a fraught process. And it is not always successful. According to Company Clothing magazine, there are 1000 companies supplying the workwear and corporate clothing market. Of these, 22 account for 85% of total sales - 380 million in 1994. A successful uniform needs to balance two key sets of needs. On the one hand, no uniform will work if staff feel uncomfortable or ugly. Giving the wearers a choice has become a key element in the way corporate clothing is introduced and managed. On the other, it is pointless if the look doesnt express the businesss marketing strategy. The greatest challenge in this respect is time. When it comes to human perceptions, first impressions count. Customers will size up the way staff look in just a few seconds, and that few seconds will colour their attitudes from then on. Those few seconds can beReading so important that big companies are prepared to invest years, and millions of pounds, getting them right. In addition, some uniform companies also offer rental services. \"There will be an increasing specialisation in the marketplace, \" predicts Mr Blyth, Customer Services Manager of a large UK bank. The past two or three years have seen consolidation. Increasingly, the big suppliers are becoming managing agents, which means they offer a total service to put together the whole complex operation of a companys corporate clothing package - which includes reliable sourcing, managing the inventory, budget control and distribution to either central locations or to each staff member individually. Huge investments have been made in new systems, information technology and amassing quality assurance accreditations. Corporate clothing does have potential for further growth. Some banks have yet to introduce a full corporate look; police forces are researching a complete new look for the 21st century. And many employees now welcome a company wardrobe. A recent survey of staff found that 90 per cent welcomed having clothing which reflected the corporate identity.", "hypothesis": "Uniforms make employees feel part of a team.", "gold_label": "entailment"}
{"uid": "id_108", "premise": "Traditionally uniforms were and for some industries still are manufactured to protect the worker. When they were first designed, it is also likely that all uniforms made symbolic sense - those for the military, for example, were originally intended to impress and even terrify the enemy; other uniforms denoted a hierarchy - chefs wore white because they worked with flour, but the main chef wore a black hat to show he supervised. The last 30 years, however, have seen an increasing emphasis on their role in projecting the image of an organisation and in uniting the workforce into a homogeneous unit particularly in customer facing\" industries, and especially in financial services and retailing. From uniforms and workwear has emerged corporate clothing. \"The people you employ are your ambassadors, \" says Peter Griffin, managing director of a major retailer in the UK. \"What they say, how they look, and how they behave is terribly important. \" The result is a new way of looking at corporate workwear. From being a simple means of identifying who is a member of staff, the uniform is emerging as a new channel of marketing communication. Truly effective marketing through visual cues such as uniforms is a subtle art, however. Wittingly or unwittingly, how we look sends all sorts of powerful subliminal messages to other people. Dark colours give an aura of authority while lighter pastel shades suggest approachability. Certain dress style creates a sense of conservatism, others a sense of openness to new ideas. Neatness can suggest efficiency but, if it is overdone, it can spill over and indicate an obsession with power. \"If the company is selling quality, then it must have quality uniforms. If it is selling style, its uniforms must be stylish. If it wants to appear innovative, everybody cant look exactly the same. Subliminally we see all these things, \" says Lynn Elvy, a director of image consultants House of Colour. But translating corporate philosophies into the right mix of colour, style, degree of branding and uniformity can be a fraught process. And it is not always successful. According to Company Clothing magazine, there are 1000 companies supplying the workwear and corporate clothing market. Of these, 22 account for 85% of total sales - 380 million in 1994. A successful uniform needs to balance two key sets of needs. On the one hand, no uniform will work if staff feel uncomfortable or ugly. Giving the wearers a choice has become a key element in the way corporate clothing is introduced and managed. On the other, it is pointless if the look doesnt express the businesss marketing strategy. The greatest challenge in this respect is time. When it comes to human perceptions, first impressions count. Customers will size up the way staff look in just a few seconds, and that few seconds will colour their attitudes from then on. Those few seconds can beReading so important that big companies are prepared to invest years, and millions of pounds, getting them right. In addition, some uniform companies also offer rental services. \"There will be an increasing specialisation in the marketplace, \" predicts Mr Blyth, Customer Services Manager of a large UK bank. The past two or three years have seen consolidation. Increasingly, the big suppliers are becoming managing agents, which means they offer a total service to put together the whole complex operation of a companys corporate clothing package - which includes reliable sourcing, managing the inventory, budget control and distribution to either central locations or to each staff member individually. Huge investments have been made in new systems, information technology and amassing quality assurance accreditations. Corporate clothing does have potential for further growth. Some banks have yet to introduce a full corporate look; police forces are researching a complete new look for the 21st century. And many employees now welcome a company wardrobe. A recent survey of staff found that 90 per cent welcomed having clothing which reflected the corporate identity.", "hypothesis": "Using uniforms as a marketing tool requires great care.", "gold_label": "entailment"}
{"uid": "id_109", "premise": "Traffic jams on most of the roads in the city have become a regular feature during monsoon.", "hypothesis": "Material used for road construction cannot withstand the fury of monsoon resulting into innumerable pot holes on the roads.", "gold_label": "entailment"}
{"uid": "id_110", "premise": "Traffic jams on most of the roads in the city have become a regular feature during monsoon.", "hypothesis": "Number of vehicles coming on the roads is much more in monsoon as compared to other seasons.", "gold_label": "neutral"}
{"uid": "id_111", "premise": "Traffic levels have fallen by 15% and congestion is down by a third. In August the Mayor of London announced a plan to extend the 5 charge for driving in central London during the working week westwards to Kensington and Chelsea. This was despite a consultative process in which almost 70,000 people and the vast majority of respondents said they did not want the scheme extended. However, the problem with the proposed extension is not only political. Extending the zone to a thickly populated area of London will mean that many people will qualify for the residents discount, allowing them to drive to the city without paying any extra. Extending the scheme therefore may mean that total revenues drop from the current 90 million a year.", "hypothesis": "The extended scheme may face continued public opposition.", "gold_label": "entailment"}
{"uid": "id_112", "premise": "Traffic levels have fallen by 15% and congestion is down by a third. In August the Mayor of London announced a plan to extend the 5 charge for driving in central London during the working week westwards to Kensington and Chelsea. This was despite a consultative process in which almost 70,000 people and the vast majority of respondents said they did not want the scheme extended. However, the problem with the proposed extension is not only political. Extending the zone to a thickly populated area of London will mean that many people will qualify for the residents discount, allowing them to drive to the city without paying any extra. Extending the scheme therefore may mean that total revenues drop from the current 90 million a year.", "hypothesis": "Kensington and Chelsea have high residential populations.", "gold_label": "entailment"}
{"uid": "id_113", "premise": "Traffic levels have fallen by 15% and congestion is down by a third. In August the Mayor of London announced a plan to extend the 5 charge for driving in central London during the working week westwards to Kensington and Chelsea. This was despite a consultative process in which almost 70,000 people and the vast majority of respondents said they did not want the scheme extended. However, the problem with the proposed extension is not only political. Extending the zone to a thickly populated area of London will mean that many people will qualify for the residents discount, allowing them to drive to the city without paying any extra. Extending the scheme therefore may mean that total revenues drop from the current 90 million a year.", "hypothesis": "Whilst the majority of respondents voted against the extension it is possible that they welcomed the fall in traffic levels and lower congestion.", "gold_label": "entailment"}
{"uid": "id_114", "premise": "Traffic levels have fallen by 15% and congestion is down by a third. In August the Mayor of London announced a plan to extend the 5 charge for driving in central London during the working week westwards to Kensington and Chelsea. This was despite a consultative process in which almost 70,000 people and the vast majority of respondents said they did not want the scheme extended. However, the problem with the proposed extension is not only political. Extending the zone to a thickly populated area of London will mean that many people will qualify for the residents discount, allowing them to drive to the city without paying any extra. Extending the scheme therefore may mean that total revenues drop from the current 90 million a year.", "hypothesis": "People who live in Kensington currently do not have to pay 5 to drive to the city.", "gold_label": "contradiction"}
{"uid": "id_115", "premise": "Training Facilities The International College of Hospitality Management has more than 120 professional lecturers and international-standard, training facilities. These include three public restaurants, ten commercial training kitchens, simulated front office training facilities, four computer suites, a fully operational winery, and a food science laboratory. The Learning Resource Centre collection is extensive. The student support services provide professional counselling in the areas of health, learning support, language skills, accommodation and welfare. Childcare facilities are also available on campus. International Home The International College of Hospitality Management has students enrolled from more than 20 countries, some of whom stay on campus in International House. Built in 1999, International House is accommodation comprising villa-style units. Each student has their own bedroom, sharing en suite facilities with another student. An adjoining kitchenette and lounge area is shared by the four students in the villa. All meals are served in the College dining room which is next to the student common room. Student privacy and security are priorities. A computer outlet in each bedroom enables student to connect into the College network, providing 24 hour-a-day access. The residence is a two-minute walk to the Colleges sporting and training facilities, and is on a regular bus service to the city centre 10 km away. International House is also being used to enhance on-campus training, from Monday to Friday, Year 1 students, supervised by 2nd Years, are assigned kitchen, waiting, housekeeping and receptionist duties. Simulated check-in/check-out exercises, receptionist duties and breakfast service to a limited number of rooms are also part of the program.", "hypothesis": "The training facility has 10 kitchens", "gold_label": "entailment"}
{"uid": "id_116", "premise": "Training Facilities The International College of Hospitality Management has more than 120 professional lecturers and international-standard, training facilities. These include three public restaurants, ten commercial training kitchens, simulated front office training facilities, four computer suites, a fully operational winery, and a food science laboratory. The Learning Resource Centre collection is extensive. The student support services provide professional counselling in the areas of health, learning support, language skills, accommodation and welfare. Childcare facilities are also available on campus. International Home The International College of Hospitality Management has students enrolled from more than 20 countries, some of whom stay on campus in International House. Built in 1999, International House is accommodation comprising villa-style units. Each student has their own bedroom, sharing en suite facilities with another student. An adjoining kitchenette and lounge area is shared by the four students in the villa. All meals are served in the College dining room which is next to the student common room. Student privacy and security are priorities. A computer outlet in each bedroom enables student to connect into the College network, providing 24 hour-a-day access. The residence is a two-minute walk to the Colleges sporting and training facilities, and is on a regular bus service to the city centre 10 km away. International House is also being used to enhance on-campus training, from Monday to Friday, Year 1 students, supervised by 2nd Years, are assigned kitchen, waiting, housekeeping and receptionist duties. Simulated check-in/check-out exercises, receptionist duties and breakfast service to a limited number of rooms are also part of the program.", "hypothesis": "All students in the program live at International House", "gold_label": "contradiction"}
{"uid": "id_117", "premise": "Training Facilities The International College of Hospitality Management has more than 120 professional lecturers and international-standard, training facilities. These include three public restaurants, ten commercial training kitchens, simulated front office training facilities, four computer suites, a fully operational winery, and a food science laboratory. The Learning Resource Centre collection is extensive. The student support services provide professional counselling in the areas of health, learning support, language skills, accommodation and welfare. Childcare facilities are also available on campus. International Home The International College of Hospitality Management has students enrolled from more than 20 countries, some of whom stay on campus in International House. Built in 1999, International House is accommodation comprising villa-style units. Each student has their own bedroom, sharing en suite facilities with another student. An adjoining kitchenette and lounge area is shared by the four students in the villa. All meals are served in the College dining room which is next to the student common room. Student privacy and security are priorities. A computer outlet in each bedroom enables student to connect into the College network, providing 24 hour-a-day access. The residence is a two-minute walk to the Colleges sporting and training facilities, and is on a regular bus service to the city centre 10 km away. International House is also being used to enhance on-campus training, from Monday to Friday, Year 1 students, supervised by 2nd Years, are assigned kitchen, waiting, housekeeping and receptionist duties. Simulated check-in/check-out exercises, receptionist duties and breakfast service to a limited number of rooms are also part of the program.", "hypothesis": "Four students share a unit in the residence", "gold_label": "entailment"}
{"uid": "id_118", "premise": "Training Facilities The International College of Hospitality Management has more than 120 professional lecturers and international-standard, training facilities. These include three public restaurants, ten commercial training kitchens, simulated front office training facilities, four computer suites, a fully operational winery, and a food science laboratory. The Learning Resource Centre collection is extensive. The student support services provide professional counselling in the areas of health, learning support, language skills, accommodation and welfare. Childcare facilities are also available on campus. International Home The International College of Hospitality Management has students enrolled from more than 20 countries, some of whom stay on campus in International House. Built in 1999, International House is accommodation comprising villa-style units. Each student has their own bedroom, sharing en suite facilities with another student. An adjoining kitchenette and lounge area is shared by the four students in the villa. All meals are served in the College dining room which is next to the student common room. Student privacy and security are priorities. A computer outlet in each bedroom enables student to connect into the College network, providing 24 hour-a-day access. The residence is a two-minute walk to the Colleges sporting and training facilities, and is on a regular bus service to the city centre 10 km away. International House is also being used to enhance on-campus training, from Monday to Friday, Year 1 students, supervised by 2nd Years, are assigned kitchen, waiting, housekeeping and receptionist duties. Simulated check-in/check-out exercises, receptionist duties and breakfast service to a limited number of rooms are also part of the program.", "hypothesis": "The residence is used as part of the training program", "gold_label": "entailment"}
{"uid": "id_119", "premise": "Training Facilities The International College of Hospitality Management has more than 120 professional lecturers and international-standard, training facilities. These include three public restaurants, ten commercial training kitchens, simulated front office training facilities, four computer suites, a fully operational winery, and a food science laboratory. The Learning Resource Centre collection is extensive. The student support services provide professional counselling in the areas of health, learning support, language skills, accommodation and welfare. Childcare facilities are also available on campus. International Home The International College of Hospitality Management has students enrolled from more than 20 countries, some of whom stay on campus in International House. Built in 1999, International House is accommodation comprising villa-style units. Each student has their own bedroom, sharing en suite facilities with another student. An adjoining kitchenette and lounge area is shared by the four students in the villa. All meals are served in the College dining room which is next to the student common room. Student privacy and security are priorities. A computer outlet in each bedroom enables student to connect into the College network, providing 24 hour-a-day access. The residence is a two-minute walk to the Colleges sporting and training facilities, and is on a regular bus service to the city centre 10 km away. International House is also being used to enhance on-campus training, from Monday to Friday, Year 1 students, supervised by 2nd Years, are assigned kitchen, waiting, housekeeping and receptionist duties. Simulated check-in/check-out exercises, receptionist duties and breakfast service to a limited number of rooms are also part of the program.", "hypothesis": "All meals in the residence are prepared by the students", "gold_label": "neutral"}
{"uid": "id_120", "premise": "Trans Fatty Acids A recent editorial in the British Medical Journal (BMJ), written by researchers from the University of Oxford, has called for food labels to list trans fats as well as cholesterol and saturated fat. Trans fats (or trans fatty acids) are a type of unsaturated fatty acid. They occur naturally in small amounts in foods produced from ruminant animals e. g. milk, beef and lamb. However, most of the trans fatty acids in the diet are produced during the process of partial hydrogenation (hardening) of vegetable oils into semi-solid fats. They are therefore found in hard margarines, partially hydrogenated cooking oils, and in some bakery products, fried foods, and other processed foods that are made using these. Trans fatty acids have an adverse effect on certain chemicals, known as lipids, which are found in the blood and have been shown to increase the risk of heart disease. They also increase LDL-cholesterol (the bad cholesterol) and decrease HDL-cholesterol (the good cholesterol). They may also have adverse effects on cardiovascular disease risk that are independent of an effect on blood lipids (Mozaffarian et al. 2006). In a recent review of prospective studies investigating the effects of trans fatty acids, a 2% increase in energy intake from trans fatty acids was associated with a 23% increase in the incidence of heart disease. The authors also reported that the adverse effects of trans fatty acids were observed even at very low intakes (3% of total daily energy intake, or about 2-7g per day) (Mozaffarian et al. 2006). However, in this recent review it is only trans fatty acids produced during the hardening of vegetable oils that are found to be harmful to health. The public health implications of consuming trans fatty acids from ruminant products are considered to be relatively limited. Over the last decade, population intakes of trans fatty acids in the UK fell and are now, on average, well below the recommended 2% of total energy set by the Department of Health in 1991, at 1.2% of energy (Henderson et al. 2003). This is not to say that intakes of trans fatty acids are not still a problem, and dietary advice states that those individuals who are in the top end of the distribution of intake should still make efforts to reduce their intakes. Currently, trans fatty acids in foods are labelled in the USA, but not in the UK and Europe. The UK Food Standards Agency (FSA) is in favour of the revision of the European directive that governs the content and format of food labels so that trans fatty acids are labelled. This should enable consumers to make better food choices with regard to heart health (Clarke & Lewington 2006). Recognising the adverse health effects of trans fatty acids, many food manufacturers and retailers have been systematically removing them from their products in recent years. For example, they have been absent for some time from major brands of margarine and other fat spreads, which are now manufactured using a different technique. Also, many companies now have guidelines in place that are resulting in reformulation and reduction or elimination of trans fatty acids in products where they have in the past been found, such as snack products, fried products and baked goods. Consequently, the vast majority of savoury biscuits and crisps produced in the UK do not contain partially hydrogenated oils. Similarly, changes are being made to the way bakery products are manufactured. For example, a leading European manufacturer of major brands of biscuits, cakes and snacks has recently announced that these are now made without partially hydrogenated vegetable oils, a transition that began in 2004. Alongside these changes, the manufacturer has also reported a cut in the amount of saturates. It is clear that a major technical challenge in achieving such changes is to avoid simply exchanging trans fatty acids for saturated fatty acids, which also have damaging health effects. Foods that are labelled as containing partially-hydrogenated oils or fats are a source of trans fatty acids (sometimes partially-hydrogenated fats are just labelled as hydrogenated fats). These foods include hard margarines, some fried products and some manufactured bakery products e. g. biscuits, pastries and cakes. It is important to note that intake may have changed in the light of reformulation of foods that has taken place over the past six years in the UK, as referred to earlier. Furthermore, the average intake of trans fatty acids is lower in the UK than in the USA (where legislation has now been introduced). However, this does not mean there is room for complacency, as the intake in some sectors of the population is known to be higher than recommended.", "hypothesis": "The amount of saturated fats in processed meats is being reduced by some major producers.", "gold_label": "neutral"}
{"uid": "id_121", "premise": "Trans Fatty Acids A recent editorial in the British Medical Journal (BMJ), written by researchers from the University of Oxford, has called for food labels to list trans fats as well as cholesterol and saturated fat. Trans fats (or trans fatty acids) are a type of unsaturated fatty acid. They occur naturally in small amounts in foods produced from ruminant animals e. g. milk, beef and lamb. However, most of the trans fatty acids in the diet are produced during the process of partial hydrogenation (hardening) of vegetable oils into semi-solid fats. They are therefore found in hard margarines, partially hydrogenated cooking oils, and in some bakery products, fried foods, and other processed foods that are made using these. Trans fatty acids have an adverse effect on certain chemicals, known as lipids, which are found in the blood and have been shown to increase the risk of heart disease. They also increase LDL-cholesterol (the bad cholesterol) and decrease HDL-cholesterol (the good cholesterol). They may also have adverse effects on cardiovascular disease risk that are independent of an effect on blood lipids (Mozaffarian et al. 2006). In a recent review of prospective studies investigating the effects of trans fatty acids, a 2% increase in energy intake from trans fatty acids was associated with a 23% increase in the incidence of heart disease. The authors also reported that the adverse effects of trans fatty acids were observed even at very low intakes (3% of total daily energy intake, or about 2-7g per day) (Mozaffarian et al. 2006). However, in this recent review it is only trans fatty acids produced during the hardening of vegetable oils that are found to be harmful to health. The public health implications of consuming trans fatty acids from ruminant products are considered to be relatively limited. Over the last decade, population intakes of trans fatty acids in the UK fell and are now, on average, well below the recommended 2% of total energy set by the Department of Health in 1991, at 1.2% of energy (Henderson et al. 2003). This is not to say that intakes of trans fatty acids are not still a problem, and dietary advice states that those individuals who are in the top end of the distribution of intake should still make efforts to reduce their intakes. Currently, trans fatty acids in foods are labelled in the USA, but not in the UK and Europe. The UK Food Standards Agency (FSA) is in favour of the revision of the European directive that governs the content and format of food labels so that trans fatty acids are labelled. This should enable consumers to make better food choices with regard to heart health (Clarke & Lewington 2006). Recognising the adverse health effects of trans fatty acids, many food manufacturers and retailers have been systematically removing them from their products in recent years. For example, they have been absent for some time from major brands of margarine and other fat spreads, which are now manufactured using a different technique. Also, many companies now have guidelines in place that are resulting in reformulation and reduction or elimination of trans fatty acids in products where they have in the past been found, such as snack products, fried products and baked goods. Consequently, the vast majority of savoury biscuits and crisps produced in the UK do not contain partially hydrogenated oils. Similarly, changes are being made to the way bakery products are manufactured. For example, a leading European manufacturer of major brands of biscuits, cakes and snacks has recently announced that these are now made without partially hydrogenated vegetable oils, a transition that began in 2004. Alongside these changes, the manufacturer has also reported a cut in the amount of saturates. It is clear that a major technical challenge in achieving such changes is to avoid simply exchanging trans fatty acids for saturated fatty acids, which also have damaging health effects. Foods that are labelled as containing partially-hydrogenated oils or fats are a source of trans fatty acids (sometimes partially-hydrogenated fats are just labelled as hydrogenated fats). These foods include hard margarines, some fried products and some manufactured bakery products e. g. biscuits, pastries and cakes. It is important to note that intake may have changed in the light of reformulation of foods that has taken place over the past six years in the UK, as referred to earlier. Furthermore, the average intake of trans fatty acids is lower in the UK than in the USA (where legislation has now been introduced). However, this does not mean there is room for complacency, as the intake in some sectors of the population is known to be higher than recommended.", "hypothesis": "In Britain, the intake of trans fatty acids is continuing to decline.", "gold_label": "neutral"}
{"uid": "id_122", "premise": "Trans Fatty Acids A recent editorial in the British Medical Journal (BMJ), written by researchers from the University of Oxford, has called for food labels to list trans fats as well as cholesterol and saturated fat. Trans fats (or trans fatty acids) are a type of unsaturated fatty acid. They occur naturally in small amounts in foods produced from ruminant animals e. g. milk, beef and lamb. However, most of the trans fatty acids in the diet are produced during the process of partial hydrogenation (hardening) of vegetable oils into semi-solid fats. They are therefore found in hard margarines, partially hydrogenated cooking oils, and in some bakery products, fried foods, and other processed foods that are made using these. Trans fatty acids have an adverse effect on certain chemicals, known as lipids, which are found in the blood and have been shown to increase the risk of heart disease. They also increase LDL-cholesterol (the bad cholesterol) and decrease HDL-cholesterol (the good cholesterol). They may also have adverse effects on cardiovascular disease risk that are independent of an effect on blood lipids (Mozaffarian et al. 2006). In a recent review of prospective studies investigating the effects of trans fatty acids, a 2% increase in energy intake from trans fatty acids was associated with a 23% increase in the incidence of heart disease. The authors also reported that the adverse effects of trans fatty acids were observed even at very low intakes (3% of total daily energy intake, or about 2-7g per day) (Mozaffarian et al. 2006). However, in this recent review it is only trans fatty acids produced during the hardening of vegetable oils that are found to be harmful to health. The public health implications of consuming trans fatty acids from ruminant products are considered to be relatively limited. Over the last decade, population intakes of trans fatty acids in the UK fell and are now, on average, well below the recommended 2% of total energy set by the Department of Health in 1991, at 1.2% of energy (Henderson et al. 2003). This is not to say that intakes of trans fatty acids are not still a problem, and dietary advice states that those individuals who are in the top end of the distribution of intake should still make efforts to reduce their intakes. Currently, trans fatty acids in foods are labelled in the USA, but not in the UK and Europe. The UK Food Standards Agency (FSA) is in favour of the revision of the European directive that governs the content and format of food labels so that trans fatty acids are labelled. This should enable consumers to make better food choices with regard to heart health (Clarke & Lewington 2006). Recognising the adverse health effects of trans fatty acids, many food manufacturers and retailers have been systematically removing them from their products in recent years. For example, they have been absent for some time from major brands of margarine and other fat spreads, which are now manufactured using a different technique. Also, many companies now have guidelines in place that are resulting in reformulation and reduction or elimination of trans fatty acids in products where they have in the past been found, such as snack products, fried products and baked goods. Consequently, the vast majority of savoury biscuits and crisps produced in the UK do not contain partially hydrogenated oils. Similarly, changes are being made to the way bakery products are manufactured. For example, a leading European manufacturer of major brands of biscuits, cakes and snacks has recently announced that these are now made without partially hydrogenated vegetable oils, a transition that began in 2004. Alongside these changes, the manufacturer has also reported a cut in the amount of saturates. It is clear that a major technical challenge in achieving such changes is to avoid simply exchanging trans fatty acids for saturated fatty acids, which also have damaging health effects. Foods that are labelled as containing partially-hydrogenated oils or fats are a source of trans fatty acids (sometimes partially-hydrogenated fats are just labelled as hydrogenated fats). These foods include hard margarines, some fried products and some manufactured bakery products e. g. biscuits, pastries and cakes. It is important to note that intake may have changed in the light of reformulation of foods that has taken place over the past six years in the UK, as referred to earlier. Furthermore, the average intake of trans fatty acids is lower in the UK than in the USA (where legislation has now been introduced). However, this does not mean there is room for complacency, as the intake in some sectors of the population is known to be higher than recommended.", "hypothesis": "It is proving difficult to find a safe substitute for trans fatty acids.", "gold_label": "entailment"}
{"uid": "id_123", "premise": "Trans Fatty Acids A recent editorial in the British Medical Journal (BMJ), written by researchers from the University of Oxford, has called for food labels to list trans fats as well as cholesterol and saturated fat. Trans fats (or trans fatty acids) are a type of unsaturated fatty acid. They occur naturally in small amounts in foods produced from ruminant animals e. g. milk, beef and lamb. However, most of the trans fatty acids in the diet are produced during the process of partial hydrogenation (hardening) of vegetable oils into semi-solid fats. They are therefore found in hard margarines, partially hydrogenated cooking oils, and in some bakery products, fried foods, and other processed foods that are made using these. Trans fatty acids have an adverse effect on certain chemicals, known as lipids, which are found in the blood and have been shown to increase the risk of heart disease. They also increase LDL-cholesterol (the bad cholesterol) and decrease HDL-cholesterol (the good cholesterol). They may also have adverse effects on cardiovascular disease risk that are independent of an effect on blood lipids (Mozaffarian et al. 2006). In a recent review of prospective studies investigating the effects of trans fatty acids, a 2% increase in energy intake from trans fatty acids was associated with a 23% increase in the incidence of heart disease. The authors also reported that the adverse effects of trans fatty acids were observed even at very low intakes (3% of total daily energy intake, or about 2-7g per day) (Mozaffarian et al. 2006). However, in this recent review it is only trans fatty acids produced during the hardening of vegetable oils that are found to be harmful to health. The public health implications of consuming trans fatty acids from ruminant products are considered to be relatively limited. Over the last decade, population intakes of trans fatty acids in the UK fell and are now, on average, well below the recommended 2% of total energy set by the Department of Health in 1991, at 1.2% of energy (Henderson et al. 2003). This is not to say that intakes of trans fatty acids are not still a problem, and dietary advice states that those individuals who are in the top end of the distribution of intake should still make efforts to reduce their intakes. Currently, trans fatty acids in foods are labelled in the USA, but not in the UK and Europe. The UK Food Standards Agency (FSA) is in favour of the revision of the European directive that governs the content and format of food labels so that trans fatty acids are labelled. This should enable consumers to make better food choices with regard to heart health (Clarke & Lewington 2006). Recognising the adverse health effects of trans fatty acids, many food manufacturers and retailers have been systematically removing them from their products in recent years. For example, they have been absent for some time from major brands of margarine and other fat spreads, which are now manufactured using a different technique. Also, many companies now have guidelines in place that are resulting in reformulation and reduction or elimination of trans fatty acids in products where they have in the past been found, such as snack products, fried products and baked goods. Consequently, the vast majority of savoury biscuits and crisps produced in the UK do not contain partially hydrogenated oils. Similarly, changes are being made to the way bakery products are manufactured. For example, a leading European manufacturer of major brands of biscuits, cakes and snacks has recently announced that these are now made without partially hydrogenated vegetable oils, a transition that began in 2004. Alongside these changes, the manufacturer has also reported a cut in the amount of saturates. It is clear that a major technical challenge in achieving such changes is to avoid simply exchanging trans fatty acids for saturated fatty acids, which also have damaging health effects. Foods that are labelled as containing partially-hydrogenated oils or fats are a source of trans fatty acids (sometimes partially-hydrogenated fats are just labelled as hydrogenated fats). These foods include hard margarines, some fried products and some manufactured bakery products e. g. biscuits, pastries and cakes. It is important to note that intake may have changed in the light of reformulation of foods that has taken place over the past six years in the UK, as referred to earlier. Furthermore, the average intake of trans fatty acids is lower in the UK than in the USA (where legislation has now been introduced). However, this does not mean there is room for complacency, as the intake in some sectors of the population is known to be higher than recommended.", "hypothesis": "Trans fatty acids are found in all types of meat.", "gold_label": "contradiction"}
{"uid": "id_124", "premise": "Trans Fatty Acids A recent editorial in the British Medical Journal (BMJ), written by researchers from the University of Oxford, has called for food labels to list trans fats as well as cholesterol and saturated fat. Trans fats (or trans fatty acids) are a type of unsaturated fatty acid. They occur naturally in small amounts in foods produced from ruminant animals e. g. milk, beef and lamb. However, most of the trans fatty acids in the diet are produced during the process of partial hydrogenation (hardening) of vegetable oils into semi-solid fats. They are therefore found in hard margarines, partially hydrogenated cooking oils, and in some bakery products, fried foods, and other processed foods that are made using these. Trans fatty acids have an adverse effect on certain chemicals, known as lipids, which are found in the blood and have been shown to increase the risk of heart disease. They also increase LDL-cholesterol (the bad cholesterol) and decrease HDL-cholesterol (the good cholesterol). They may also have adverse effects on cardiovascular disease risk that are independent of an effect on blood lipids (Mozaffarian et al. 2006). In a recent review of prospective studies investigating the effects of trans fatty acids, a 2% increase in energy intake from trans fatty acids was associated with a 23% increase in the incidence of heart disease. The authors also reported that the adverse effects of trans fatty acids were observed even at very low intakes (3% of total daily energy intake, or about 2-7g per day) (Mozaffarian et al. 2006). However, in this recent review it is only trans fatty acids produced during the hardening of vegetable oils that are found to be harmful to health. The public health implications of consuming trans fatty acids from ruminant products are considered to be relatively limited. Over the last decade, population intakes of trans fatty acids in the UK fell and are now, on average, well below the recommended 2% of total energy set by the Department of Health in 1991, at 1.2% of energy (Henderson et al. 2003). This is not to say that intakes of trans fatty acids are not still a problem, and dietary advice states that those individuals who are in the top end of the distribution of intake should still make efforts to reduce their intakes. Currently, trans fatty acids in foods are labelled in the USA, but not in the UK and Europe. The UK Food Standards Agency (FSA) is in favour of the revision of the European directive that governs the content and format of food labels so that trans fatty acids are labelled. This should enable consumers to make better food choices with regard to heart health (Clarke & Lewington 2006). Recognising the adverse health effects of trans fatty acids, many food manufacturers and retailers have been systematically removing them from their products in recent years. For example, they have been absent for some time from major brands of margarine and other fat spreads, which are now manufactured using a different technique. Also, many companies now have guidelines in place that are resulting in reformulation and reduction or elimination of trans fatty acids in products where they have in the past been found, such as snack products, fried products and baked goods. Consequently, the vast majority of savoury biscuits and crisps produced in the UK do not contain partially hydrogenated oils. Similarly, changes are being made to the way bakery products are manufactured. For example, a leading European manufacturer of major brands of biscuits, cakes and snacks has recently announced that these are now made without partially hydrogenated vegetable oils, a transition that began in 2004. Alongside these changes, the manufacturer has also reported a cut in the amount of saturates. It is clear that a major technical challenge in achieving such changes is to avoid simply exchanging trans fatty acids for saturated fatty acids, which also have damaging health effects. Foods that are labelled as containing partially-hydrogenated oils or fats are a source of trans fatty acids (sometimes partially-hydrogenated fats are just labelled as hydrogenated fats). These foods include hard margarines, some fried products and some manufactured bakery products e. g. biscuits, pastries and cakes. It is important to note that intake may have changed in the light of reformulation of foods that has taken place over the past six years in the UK, as referred to earlier. Furthermore, the average intake of trans fatty acids is lower in the UK than in the USA (where legislation has now been introduced). However, this does not mean there is room for complacency, as the intake in some sectors of the population is known to be higher than recommended.", "hypothesis": "Some people are still consuming larger quantities of trans fatty acids than the experts consider safe.", "gold_label": "entailment"}
{"uid": "id_125", "premise": "Trans Fatty Acids A recent editorial in the British Medical Journal (BMJ), written by researchers from the University of Oxford, has called for food labels to list trans fats as well as cholesterol and saturated fat. Trans fats (or trans fatty acids) are a type of unsaturated fatty acid. They occur naturally in small amounts in foods produced from ruminant animals e. g. milk, beef and lamb. However, most of the trans fatty acids in the diet are produced during the process of partial hydrogenation (hardening) of vegetable oils into semi-solid fats. They are therefore found in hard margarines, partially hydrogenated cooking oils, and in some bakery products, fried foods, and other processed foods that are made using these. Trans fatty acids have an adverse effect on certain chemicals, known as lipids, which are found in the blood and have been shown to increase the risk of heart disease. They also increase LDL-cholesterol (the bad cholesterol) and decrease HDL-cholesterol (the good cholesterol). They may also have adverse effects on cardiovascular disease risk that are independent of an effect on blood lipids (Mozaffarian et al. 2006). In a recent review of prospective studies investigating the effects of trans fatty acids, a 2% increase in energy intake from trans fatty acids was associated with a 23% increase in the incidence of heart disease. The authors also reported that the adverse effects of trans fatty acids were observed even at very low intakes (3% of total daily energy intake, or about 2-7g per day) (Mozaffarian et al. 2006). However, in this recent review it is only trans fatty acids produced during the hardening of vegetable oils that are found to be harmful to health. The public health implications of consuming trans fatty acids from ruminant products are considered to be relatively limited. Over the last decade, population intakes of trans fatty acids in the UK fell and are now, on average, well below the recommended 2% of total energy set by the Department of Health in 1991, at 1.2% of energy (Henderson et al. 2003). This is not to say that intakes of trans fatty acids are not still a problem, and dietary advice states that those individuals who are in the top end of the distribution of intake should still make efforts to reduce their intakes. Currently, trans fatty acids in foods are labelled in the USA, but not in the UK and Europe. The UK Food Standards Agency (FSA) is in favour of the revision of the European directive that governs the content and format of food labels so that trans fatty acids are labelled. This should enable consumers to make better food choices with regard to heart health (Clarke & Lewington 2006). Recognising the adverse health effects of trans fatty acids, many food manufacturers and retailers have been systematically removing them from their products in recent years. For example, they have been absent for some time from major brands of margarine and other fat spreads, which are now manufactured using a different technique. Also, many companies now have guidelines in place that are resulting in reformulation and reduction or elimination of trans fatty acids in products where they have in the past been found, such as snack products, fried products and baked goods. Consequently, the vast majority of savoury biscuits and crisps produced in the UK do not contain partially hydrogenated oils. Similarly, changes are being made to the way bakery products are manufactured. For example, a leading European manufacturer of major brands of biscuits, cakes and snacks has recently announced that these are now made without partially hydrogenated vegetable oils, a transition that began in 2004. Alongside these changes, the manufacturer has also reported a cut in the amount of saturates. It is clear that a major technical challenge in achieving such changes is to avoid simply exchanging trans fatty acids for saturated fatty acids, which also have damaging health effects. Foods that are labelled as containing partially-hydrogenated oils or fats are a source of trans fatty acids (sometimes partially-hydrogenated fats are just labelled as hydrogenated fats). These foods include hard margarines, some fried products and some manufactured bakery products e. g. biscuits, pastries and cakes. It is important to note that intake may have changed in the light of reformulation of foods that has taken place over the past six years in the UK, as referred to earlier. Furthermore, the average intake of trans fatty acids is lower in the UK than in the USA (where legislation has now been introduced). However, this does not mean there is room for complacency, as the intake in some sectors of the population is known to be higher than recommended.", "hypothesis": "Experts consider that the trans fatty acids contained in animal products are unlikely to be a serious health risk.", "gold_label": "entailment"}
{"uid": "id_126", "premise": "Trans Fatty Acids A recent editorial in the British Medical Journal (BMJ), written by researchers from the University of Oxford, has called for food labels to list trans fats as well as cholesterol and saturated fat. Trans fats (or trans fatty acids) are a type of unsaturated fatty acid. They occur naturally in small amounts in foods produced from ruminant animals e. g. milk, beef and lamb. However, most of the trans fatty acids in the diet are produced during the process of partial hydrogenation (hardening) of vegetable oils into semi-solid fats. They are therefore found in hard margarines, partially hydrogenated cooking oils, and in some bakery products, fried foods, and other processed foods that are made using these. Trans fatty acids have an adverse effect on certain chemicals, known as lipids, which are found in the blood and have been shown to increase the risk of heart disease. They also increase LDL-cholesterol (the bad cholesterol) and decrease HDL-cholesterol (the good cholesterol). They may also have adverse effects on cardiovascular disease risk that are independent of an effect on blood lipids (Mozaffarian et al. 2006). In a recent review of prospective studies investigating the effects of trans fatty acids, a 2% increase in energy intake from trans fatty acids was associated with a 23% increase in the incidence of heart disease. The authors also reported that the adverse effects of trans fatty acids were observed even at very low intakes (3% of total daily energy intake, or about 2-7g per day) (Mozaffarian et al. 2006). However, in this recent review it is only trans fatty acids produced during the hardening of vegetable oils that are found to be harmful to health. The public health implications of consuming trans fatty acids from ruminant products are considered to be relatively limited. Over the last decade, population intakes of trans fatty acids in the UK fell and are now, on average, well below the recommended 2% of total energy set by the Department of Health in 1991, at 1.2% of energy (Henderson et al. 2003). This is not to say that intakes of trans fatty acids are not still a problem, and dietary advice states that those individuals who are in the top end of the distribution of intake should still make efforts to reduce their intakes. Currently, trans fatty acids in foods are labelled in the USA, but not in the UK and Europe. The UK Food Standards Agency (FSA) is in favour of the revision of the European directive that governs the content and format of food labels so that trans fatty acids are labelled. This should enable consumers to make better food choices with regard to heart health (Clarke & Lewington 2006). Recognising the adverse health effects of trans fatty acids, many food manufacturers and retailers have been systematically removing them from their products in recent years. For example, they have been absent for some time from major brands of margarine and other fat spreads, which are now manufactured using a different technique. Also, many companies now have guidelines in place that are resulting in reformulation and reduction or elimination of trans fatty acids in products where they have in the past been found, such as snack products, fried products and baked goods. Consequently, the vast majority of savoury biscuits and crisps produced in the UK do not contain partially hydrogenated oils. Similarly, changes are being made to the way bakery products are manufactured. For example, a leading European manufacturer of major brands of biscuits, cakes and snacks has recently announced that these are now made without partially hydrogenated vegetable oils, a transition that began in 2004. Alongside these changes, the manufacturer has also reported a cut in the amount of saturates. It is clear that a major technical challenge in achieving such changes is to avoid simply exchanging trans fatty acids for saturated fatty acids, which also have damaging health effects. Foods that are labelled as containing partially-hydrogenated oils or fats are a source of trans fatty acids (sometimes partially-hydrogenated fats are just labelled as hydrogenated fats). These foods include hard margarines, some fried products and some manufactured bakery products e. g. biscuits, pastries and cakes. It is important to note that intake may have changed in the light of reformulation of foods that has taken place over the past six years in the UK, as referred to earlier. Furthermore, the average intake of trans fatty acids is lower in the UK than in the USA (where legislation has now been introduced). However, this does not mean there is room for complacency, as the intake in some sectors of the population is known to be higher than recommended.", "hypothesis": "Health problems can be caused by the consumption of small amounts of trans fatty acids.", "gold_label": "entailment"}
{"uid": "id_127", "premise": "Transgenic Plants Genes from virtually any organism, from viruses to humans, can now be inserted into plants, creating what are known as transgenic plants. Now used in agriculture, there are approximately 109 million acres of transgenic crops grown worldwide, 68 percent of which are in the United States. The most common transgenic crops are soybeans, corn, cotton, and canola. Most often, these plants either contain a gene making them resistant to the herbicide glyphosate or they contain an insect-resistant gene that produces a protein called Bt toxin. On the positive side, proponents of transgenic crops argue that these crops are environmentally friendly because they allow farmers to use fewer and less noxious chemicals for crop production. For example, a 21 percent reduction in the use of insecticide has been reported on Bt cotton (transgenic cotton that produces Bt toxin). In addition, when glyphosate is used to control weeds, other, more persistent herbicides do not need to be applied. On the negative side, opponents of transgenic crops suggest that there are many questions that need to be answered before transgenic crops are grown on a large scale. One question deals with the effects that Bt plants have on nontarget organisms such as beneficial insects, worms, and birds that consume the genetically engineered crop. For example, monarch caterpillars feeding on milkweed plants near Bt cornfields will eat some corn pollen that has fallen on the milkweed leaves. Laboratory studies indicate that caterpillars can die from eating Bt pollen. However, field tests indicate that Bt corn is not likely to harm monarchs. Furthermore, the application of pesticides (the alternative to growing Bt plants) has been demonstrated to cause widespread harm to nontarget insects. Another unanswered question is whether herbicide-resistant genes will move into the populations of weeds. Crop plants are sometimes grown in areas where weedy relatives also live. If the crop plants hybridize and reproduce with weedy relatives, then this herbicide-resistant gene will be perpetuated in the offspring. In this way, the resistant gene can make its way into the weed population. If this happens, a farmer can no longer use glyphosate, for example, to kill those weeds. This scenario is not likely to occur in many instances because there are no weedy relatives growing near the crop plant. However, in some cases, it may become a serious problem. For example, canola readily hybridizes with mustard weed species and could transfer its herbicide-resistant genes to those weeds. We know that evolution will occur when transgenic plants are grown on a large scale over a period of time. Of special concern is the development of insect populations resistant to the Bt toxin. This pesticide has been applied to plants for decades without the development of insect-resistant populations. However, transgenic Bt plants express the toxin in all tissues throughout the growing season. Therefore, all insects carrying genes that make them susceptible to the toxin will die. That leaves only the genetically resistant insects alive to perpetuate the population. When these resistant insects mate, they will produce a high proportion of offspring capable of surviving in the presence of the Bt toxin. Farmers are attempting to slow the development of insect resistance in Bt crops by, for example, planting nontransgenic border rows to provide a refuge for susceptible insects. These insects may allow Bt susceptibility to remain in the population. Perhaps the most serious concern about the transgenic crop plants currently in use is that they encourage farmers to move farther away from sustainable agricultural farming practices, meaning ones that allow natural resources to continually regenerate over the long run. Transgenics, at least superficially, simplify farming by reducing the choices made by the manager. Planting a glyphosate-resistant crop commits a farmer to using that herbicide for the season, probably to the exclusion of all other herbicides and other weed-control practices. Farmers who use Bt transgenics may not feel that they need to follow through with integrated pest-management practices that use beneficial insects and timely applications of pesticides to control insect pests. A more sustainable approach would be to plant nontransgenic corn, monitor the fields throughout the growing season, and then apply a pesticide only if and when needed.", "hypothesis": "Planting nontransgenic plants alongside Bt plants may help Bt-susceptible insects to remain part of the population.", "gold_label": "entailment"}
{"uid": "id_128", "premise": "Transgenic Plants Genes from virtually any organism, from viruses to humans, can now be inserted into plants, creating what are known as transgenic plants. Now used in agriculture, there are approximately 109 million acres of transgenic crops grown worldwide, 68 percent of which are in the United States. The most common transgenic crops are soybeans, corn, cotton, and canola. Most often, these plants either contain a gene making them resistant to the herbicide glyphosate or they contain an insect-resistant gene that produces a protein called Bt toxin. On the positive side, proponents of transgenic crops argue that these crops are environmentally friendly because they allow farmers to use fewer and less noxious chemicals for crop production. For example, a 21 percent reduction in the use of insecticide has been reported on Bt cotton (transgenic cotton that produces Bt toxin). In addition, when glyphosate is used to control weeds, other, more persistent herbicides do not need to be applied. On the negative side, opponents of transgenic crops suggest that there are many questions that need to be answered before transgenic crops are grown on a large scale. One question deals with the effects that Bt plants have on nontarget organisms such as beneficial insects, worms, and birds that consume the genetically engineered crop. For example, monarch caterpillars feeding on milkweed plants near Bt cornfields will eat some corn pollen that has fallen on the milkweed leaves. Laboratory studies indicate that caterpillars can die from eating Bt pollen. However, field tests indicate that Bt corn is not likely to harm monarchs. Furthermore, the application of pesticides (the alternative to growing Bt plants) has been demonstrated to cause widespread harm to nontarget insects. Another unanswered question is whether herbicide-resistant genes will move into the populations of weeds. Crop plants are sometimes grown in areas where weedy relatives also live. If the crop plants hybridize and reproduce with weedy relatives, then this herbicide-resistant gene will be perpetuated in the offspring. In this way, the resistant gene can make its way into the weed population. If this happens, a farmer can no longer use glyphosate, for example, to kill those weeds. This scenario is not likely to occur in many instances because there are no weedy relatives growing near the crop plant. However, in some cases, it may become a serious problem. For example, canola readily hybridizes with mustard weed species and could transfer its herbicide-resistant genes to those weeds. We know that evolution will occur when transgenic plants are grown on a large scale over a period of time. Of special concern is the development of insect populations resistant to the Bt toxin. This pesticide has been applied to plants for decades without the development of insect-resistant populations. However, transgenic Bt plants express the toxin in all tissues throughout the growing season. Therefore, all insects carrying genes that make them susceptible to the toxin will die. That leaves only the genetically resistant insects alive to perpetuate the population. When these resistant insects mate, they will produce a high proportion of offspring capable of surviving in the presence of the Bt toxin. Farmers are attempting to slow the development of insect resistance in Bt crops by, for example, planting nontransgenic border rows to provide a refuge for susceptible insects. These insects may allow Bt susceptibility to remain in the population. Perhaps the most serious concern about the transgenic crop plants currently in use is that they encourage farmers to move farther away from sustainable agricultural farming practices, meaning ones that allow natural resources to continually regenerate over the long run. Transgenics, at least superficially, simplify farming by reducing the choices made by the manager. Planting a glyphosate-resistant crop commits a farmer to using that herbicide for the season, probably to the exclusion of all other herbicides and other weed-control practices. Farmers who use Bt transgenics may not feel that they need to follow through with integrated pest-management practices that use beneficial insects and timely applications of pesticides to control insect pests. A more sustainable approach would be to plant nontransgenic corn, monitor the fields throughout the growing season, and then apply a pesticide only if and when needed.", "hypothesis": "Because Bt plants are toxic at all times and in all tissues, they allow only Bt-resistant insects to survive and reproduce.", "gold_label": "entailment"}
{"uid": "id_129", "premise": "Transgenic Plants Genes from virtually any organism, from viruses to humans, can now be inserted into plants, creating what are known as transgenic plants. Now used in agriculture, there are approximately 109 million acres of transgenic crops grown worldwide, 68 percent of which are in the United States. The most common transgenic crops are soybeans, corn, cotton, and canola. Most often, these plants either contain a gene making them resistant to the herbicide glyphosate or they contain an insect-resistant gene that produces a protein called Bt toxin. On the positive side, proponents of transgenic crops argue that these crops are environmentally friendly because they allow farmers to use fewer and less noxious chemicals for crop production. For example, a 21 percent reduction in the use of insecticide has been reported on Bt cotton (transgenic cotton that produces Bt toxin). In addition, when glyphosate is used to control weeds, other, more persistent herbicides do not need to be applied. On the negative side, opponents of transgenic crops suggest that there are many questions that need to be answered before transgenic crops are grown on a large scale. One question deals with the effects that Bt plants have on nontarget organisms such as beneficial insects, worms, and birds that consume the genetically engineered crop. For example, monarch caterpillars feeding on milkweed plants near Bt cornfields will eat some corn pollen that has fallen on the milkweed leaves. Laboratory studies indicate that caterpillars can die from eating Bt pollen. However, field tests indicate that Bt corn is not likely to harm monarchs. Furthermore, the application of pesticides (the alternative to growing Bt plants) has been demonstrated to cause widespread harm to nontarget insects. Another unanswered question is whether herbicide-resistant genes will move into the populations of weeds. Crop plants are sometimes grown in areas where weedy relatives also live. If the crop plants hybridize and reproduce with weedy relatives, then this herbicide-resistant gene will be perpetuated in the offspring. In this way, the resistant gene can make its way into the weed population. If this happens, a farmer can no longer use glyphosate, for example, to kill those weeds. This scenario is not likely to occur in many instances because there are no weedy relatives growing near the crop plant. However, in some cases, it may become a serious problem. For example, canola readily hybridizes with mustard weed species and could transfer its herbicide-resistant genes to those weeds. We know that evolution will occur when transgenic plants are grown on a large scale over a period of time. Of special concern is the development of insect populations resistant to the Bt toxin. This pesticide has been applied to plants for decades without the development of insect-resistant populations. However, transgenic Bt plants express the toxin in all tissues throughout the growing season. Therefore, all insects carrying genes that make them susceptible to the toxin will die. That leaves only the genetically resistant insects alive to perpetuate the population. When these resistant insects mate, they will produce a high proportion of offspring capable of surviving in the presence of the Bt toxin. Farmers are attempting to slow the development of insect resistance in Bt crops by, for example, planting nontransgenic border rows to provide a refuge for susceptible insects. These insects may allow Bt susceptibility to remain in the population. Perhaps the most serious concern about the transgenic crop plants currently in use is that they encourage farmers to move farther away from sustainable agricultural farming practices, meaning ones that allow natural resources to continually regenerate over the long run. Transgenics, at least superficially, simplify farming by reducing the choices made by the manager. Planting a glyphosate-resistant crop commits a farmer to using that herbicide for the season, probably to the exclusion of all other herbicides and other weed-control practices. Farmers who use Bt transgenics may not feel that they need to follow through with integrated pest-management practices that use beneficial insects and timely applications of pesticides to control insect pests. A more sustainable approach would be to plant nontransgenic corn, monitor the fields throughout the growing season, and then apply a pesticide only if and when needed.", "hypothesis": "Regular use of Bt pesticides has not created resistant insect populations, so the use of Bt plants is probably safe as well.", "gold_label": "contradiction"}
{"uid": "id_130", "premise": "Transgenic Plants Genes from virtually any organism, from viruses to humans, can now be inserted into plants, creating what are known as transgenic plants. Now used in agriculture, there are approximately 109 million acres of transgenic crops grown worldwide, 68 percent of which are in the United States. The most common transgenic crops are soybeans, corn, cotton, and canola. Most often, these plants either contain a gene making them resistant to the herbicide glyphosate or they contain an insect-resistant gene that produces a protein called Bt toxin. On the positive side, proponents of transgenic crops argue that these crops are environmentally friendly because they allow farmers to use fewer and less noxious chemicals for crop production. For example, a 21 percent reduction in the use of insecticide has been reported on Bt cotton (transgenic cotton that produces Bt toxin). In addition, when glyphosate is used to control weeds, other, more persistent herbicides do not need to be applied. On the negative side, opponents of transgenic crops suggest that there are many questions that need to be answered before transgenic crops are grown on a large scale. One question deals with the effects that Bt plants have on nontarget organisms such as beneficial insects, worms, and birds that consume the genetically engineered crop. For example, monarch caterpillars feeding on milkweed plants near Bt cornfields will eat some corn pollen that has fallen on the milkweed leaves. Laboratory studies indicate that caterpillars can die from eating Bt pollen. However, field tests indicate that Bt corn is not likely to harm monarchs. Furthermore, the application of pesticides (the alternative to growing Bt plants) has been demonstrated to cause widespread harm to nontarget insects. Another unanswered question is whether herbicide-resistant genes will move into the populations of weeds. Crop plants are sometimes grown in areas where weedy relatives also live. If the crop plants hybridize and reproduce with weedy relatives, then this herbicide-resistant gene will be perpetuated in the offspring. In this way, the resistant gene can make its way into the weed population. If this happens, a farmer can no longer use glyphosate, for example, to kill those weeds. This scenario is not likely to occur in many instances because there are no weedy relatives growing near the crop plant. However, in some cases, it may become a serious problem. For example, canola readily hybridizes with mustard weed species and could transfer its herbicide-resistant genes to those weeds. We know that evolution will occur when transgenic plants are grown on a large scale over a period of time. Of special concern is the development of insect populations resistant to the Bt toxin. This pesticide has been applied to plants for decades without the development of insect-resistant populations. However, transgenic Bt plants express the toxin in all tissues throughout the growing season. Therefore, all insects carrying genes that make them susceptible to the toxin will die. That leaves only the genetically resistant insects alive to perpetuate the population. When these resistant insects mate, they will produce a high proportion of offspring capable of surviving in the presence of the Bt toxin. Farmers are attempting to slow the development of insect resistance in Bt crops by, for example, planting nontransgenic border rows to provide a refuge for susceptible insects. These insects may allow Bt susceptibility to remain in the population. Perhaps the most serious concern about the transgenic crop plants currently in use is that they encourage farmers to move farther away from sustainable agricultural farming practices, meaning ones that allow natural resources to continually regenerate over the long run. Transgenics, at least superficially, simplify farming by reducing the choices made by the manager. Planting a glyphosate-resistant crop commits a farmer to using that herbicide for the season, probably to the exclusion of all other herbicides and other weed-control practices. Farmers who use Bt transgenics may not feel that they need to follow through with integrated pest-management practices that use beneficial insects and timely applications of pesticides to control insect pests. A more sustainable approach would be to plant nontransgenic corn, monitor the fields throughout the growing season, and then apply a pesticide only if and when needed.", "hypothesis": "The evolution of Bt-resistant insect populations will happen eventually if use of transgenic plants becomes widespread.", "gold_label": "entailment"}
{"uid": "id_131", "premise": "Translated novels written by female writers are a small subset. Translations make up a tiny fraction of the books published in the UK and US, and roughly a quarter of them are written by women. Various recent counts have found that about 26% of English translations are female-authored books (although the gender balance among the translators of this subgroup is roughly equal). That means that fewer than 100 foreign-language books authored by women make their way to the UK every year. But things may be changing. Two new publishing houses have been founded in the UK, whose mission is to publish only translations of books authored by women. There is still plenty of non-English writing waiting to be published.", "hypothesis": "Many more books written by women will be translated in the future.", "gold_label": "neutral"}
{"uid": "id_132", "premise": "Translated novels written by female writers are a small subset. Translations make up a tiny fraction of the books published in the UK and US, and roughly a quarter of them are written by women. Various recent counts have found that about 26% of English translations are female-authored books (although the gender balance among the translators of this subgroup is roughly equal). That means that fewer than 100 foreign-language books authored by women make their way to the UK every year. But things may be changing. Two new publishing houses have been founded in the UK, whose mission is to publish only translations of books authored by women. There is still plenty of non-English writing waiting to be published.", "hypothesis": "Each year, at most 400 English-translated books are published in the UK", "gold_label": "entailment"}
{"uid": "id_133", "premise": "Translated novels written by female writers are a small subset. Translations make up a tiny fraction of the books published in the UK and US, and roughly a quarter of them are written by women. Various recent counts have found that about 26% of English translations are female-authored books (although the gender balance among the translators of this subgroup is roughly equal). That means that fewer than 100 foreign-language books authored by women make their way to the UK every year. But things may be changing. Two new publishing houses have been founded in the UK, whose mission is to publish only translations of books authored by women. There is still plenty of non-English writing waiting to be published.", "hypothesis": "About half of translators in the UK are women.", "gold_label": "neutral"}
{"uid": "id_134", "premise": "Trends in the Indian fashion and textile industries During the 1950s, the Indian fashion scene was exciting, stylish and very graceful. There were no celebrity designers or models, nor were there any labels that were widely recognised. The value of a garment was judged by its style and fabric rather than by who made it. It was regarded as perfectly acceptable, even for high-society women, to approach an unknown tailor who could make a garment for a few rupees, providing the perfect fit, finish and style. They were proud of getting a bargain, and of giving their own name to the end result. The 1960s was an era full of mischievousness and celebration in the arts, music and cinema. The period was characterised by freedom from restrictions and, in the fashion world, an acceptance of innovative types of material such as plastic and coated polyester. Tight-fitting kurtas and churidars and high coiffures were a trend among women. The following decade witnessed an increase in the export of traditional materials, and the arrival in India of international fashion. Synthetics became trendy, and the disco culture affected the fashion scene. It was in the early 80s when the first fashion store Ravissant opened in Mumbai. At that time garments were retailed for a four-figure price tag. American designers like Calvin Klein became popular. In India too, contours became more masculine, and even the salwar kameez was designed with shoulder pads. With the evolution of designer stores came the culture of designer fashion, along with its hefty price tags. Whatever a garment was like, consumers were convinced that a higher price tag signified elegant designer fashion, so garments were sold at unbelievable prices. Meanwhile, designers decided to get themselves noticed by making showy outfits and associating with the right celebrities. Soon, fashion shows became competitive, each designer attempting to out-do the other in theme, guest list and media coverage. In the last decade of the millennium, the market shrank and ethnic wear made a comeback. During the recession, there was a push to sell at any cost. With fierce competition the inevitable occurred: the once hefty price tags began their downward journey, and the fashion-show industry followed suit. However, the liveliness of the Indian fashion scene had not ended it had merely reached a stable level. At the beginning of the 21st century, with new designers and models, and more sensible designs, the fashion industry accelerated once again. As far as the global fashion industry is concerned, Indian ethnic designs and materials are currently in demand from fashion houses and garment manufacturers. India is the third largest producer of cotton, the second largest producer of silk, and the fifth largest producer of man-made fibres in the world. The Indian garment and fabric industries have many fundamental advantages, in terms of a cheaper, skilled work force, cost-effective production, raw materials, flexibility, and a wide range of designs with sequins, beadwork, and embroidery. In addition, that India provides garments to international fashion houses at competitive prices, with a shorter lead time, and an effective monopoly on certain designs, is accepted the whole world over. India has always been regarded as the default source in the embroidered garments segment, but changes in the rate of exchange between the rupee and the dollar has further depressed prices, thereby attracting more buyers. So the international fashion houses walk away with customised goods, and craftwork is sold at very low rates. As far as the fabric market is concerned, the range available in India can attract as well as confuse the buyer. Much of the production takes place in the small town of Chapa in the eastern state of Bihar, a name one might never have heard of. Here fabric-making is a family industry; the range and quality of raw silks churned out here belie the crude production methods and equipment. Surat in Gujarat, is the supplier of an amazing set of jacquards, moss crepes and georgette sheers all fabrics in high demand. Another Indian fabric design that has been adopted by the fashion industry is the Madras check, originally utilised for the universal lungi, a simple lower-body wrap worn in southern India. This design has now found its way on to bandannas, blouses, home furnishings and almost anything one can think of. Ethnic Indian designs with batik and hand-embroidered motifs have also become popular across the world. Decorative bead work is another product in demand in the international market. Beads are used to prepare accessory items like belts and bags, and beadwork is now available for haute couture evening wear too.", "hypothesis": "At the start of the 21st century, key elements in the Indian fashion industry changed.", "gold_label": "entailment"}
{"uid": "id_135", "premise": "Trends in the Indian fashion and textile industries During the 1950s, the Indian fashion scene was exciting, stylish and very graceful. There were no celebrity designers or models, nor were there any labels that were widely recognised. The value of a garment was judged by its style and fabric rather than by who made it. It was regarded as perfectly acceptable, even for high-society women, to approach an unknown tailor who could make a garment for a few rupees, providing the perfect fit, finish and style. They were proud of getting a bargain, and of giving their own name to the end result. The 1960s was an era full of mischievousness and celebration in the arts, music and cinema. The period was characterised by freedom from restrictions and, in the fashion world, an acceptance of innovative types of material such as plastic and coated polyester. Tight-fitting kurtas and churidars and high coiffures were a trend among women. The following decade witnessed an increase in the export of traditional materials, and the arrival in India of international fashion. Synthetics became trendy, and the disco culture affected the fashion scene. It was in the early 80s when the first fashion store Ravissant opened in Mumbai. At that time garments were retailed for a four-figure price tag. American designers like Calvin Klein became popular. In India too, contours became more masculine, and even the salwar kameez was designed with shoulder pads. With the evolution of designer stores came the culture of designer fashion, along with its hefty price tags. Whatever a garment was like, consumers were convinced that a higher price tag signified elegant designer fashion, so garments were sold at unbelievable prices. Meanwhile, designers decided to get themselves noticed by making showy outfits and associating with the right celebrities. Soon, fashion shows became competitive, each designer attempting to out-do the other in theme, guest list and media coverage. In the last decade of the millennium, the market shrank and ethnic wear made a comeback. During the recession, there was a push to sell at any cost. With fierce competition the inevitable occurred: the once hefty price tags began their downward journey, and the fashion-show industry followed suit. However, the liveliness of the Indian fashion scene had not ended it had merely reached a stable level. At the beginning of the 21st century, with new designers and models, and more sensible designs, the fashion industry accelerated once again. As far as the global fashion industry is concerned, Indian ethnic designs and materials are currently in demand from fashion houses and garment manufacturers. India is the third largest producer of cotton, the second largest producer of silk, and the fifth largest producer of man-made fibres in the world. The Indian garment and fabric industries have many fundamental advantages, in terms of a cheaper, skilled work force, cost-effective production, raw materials, flexibility, and a wide range of designs with sequins, beadwork, and embroidery. In addition, that India provides garments to international fashion houses at competitive prices, with a shorter lead time, and an effective monopoly on certain designs, is accepted the whole world over. India has always been regarded as the default source in the embroidered garments segment, but changes in the rate of exchange between the rupee and the dollar has further depressed prices, thereby attracting more buyers. So the international fashion houses walk away with customised goods, and craftwork is sold at very low rates. As far as the fabric market is concerned, the range available in India can attract as well as confuse the buyer. Much of the production takes place in the small town of Chapa in the eastern state of Bihar, a name one might never have heard of. Here fabric-making is a family industry; the range and quality of raw silks churned out here belie the crude production methods and equipment. Surat in Gujarat, is the supplier of an amazing set of jacquards, moss crepes and georgette sheers all fabrics in high demand. Another Indian fabric design that has been adopted by the fashion industry is the Madras check, originally utilised for the universal lungi, a simple lower-body wrap worn in southern India. This design has now found its way on to bandannas, blouses, home furnishings and almost anything one can think of. Ethnic Indian designs with batik and hand-embroidered motifs have also become popular across the world. Decorative bead work is another product in demand in the international market. Beads are used to prepare accessory items like belts and bags, and beadwork is now available for haute couture evening wear too.", "hypothesis": "India now exports more than half of the cotton it produces.", "gold_label": "neutral"}
{"uid": "id_136", "premise": "Trends in the Indian fashion and textile industries During the 1950s, the Indian fashion scene was exciting, stylish and very graceful. There were no celebrity designers or models, nor were there any labels that were widely recognised. The value of a garment was judged by its style and fabric rather than by who made it. It was regarded as perfectly acceptable, even for high-society women, to approach an unknown tailor who could make a garment for a few rupees, providing the perfect fit, finish and style. They were proud of getting a bargain, and of giving their own name to the end result. The 1960s was an era full of mischievousness and celebration in the arts, music and cinema. The period was characterised by freedom from restrictions and, in the fashion world, an acceptance of innovative types of material such as plastic and coated polyester. Tight-fitting kurtas and churidars and high coiffures were a trend among women. The following decade witnessed an increase in the export of traditional materials, and the arrival in India of international fashion. Synthetics became trendy, and the disco culture affected the fashion scene. It was in the early 80s when the first fashion store Ravissant opened in Mumbai. At that time garments were retailed for a four-figure price tag. American designers like Calvin Klein became popular. In India too, contours became more masculine, and even the salwar kameez was designed with shoulder pads. With the evolution of designer stores came the culture of designer fashion, along with its hefty price tags. Whatever a garment was like, consumers were convinced that a higher price tag signified elegant designer fashion, so garments were sold at unbelievable prices. Meanwhile, designers decided to get themselves noticed by making showy outfits and associating with the right celebrities. Soon, fashion shows became competitive, each designer attempting to out-do the other in theme, guest list and media coverage. In the last decade of the millennium, the market shrank and ethnic wear made a comeback. During the recession, there was a push to sell at any cost. With fierce competition the inevitable occurred: the once hefty price tags began their downward journey, and the fashion-show industry followed suit. However, the liveliness of the Indian fashion scene had not ended it had merely reached a stable level. At the beginning of the 21st century, with new designers and models, and more sensible designs, the fashion industry accelerated once again. As far as the global fashion industry is concerned, Indian ethnic designs and materials are currently in demand from fashion houses and garment manufacturers. India is the third largest producer of cotton, the second largest producer of silk, and the fifth largest producer of man-made fibres in the world. The Indian garment and fabric industries have many fundamental advantages, in terms of a cheaper, skilled work force, cost-effective production, raw materials, flexibility, and a wide range of designs with sequins, beadwork, and embroidery. In addition, that India provides garments to international fashion houses at competitive prices, with a shorter lead time, and an effective monopoly on certain designs, is accepted the whole world over. India has always been regarded as the default source in the embroidered garments segment, but changes in the rate of exchange between the rupee and the dollar has further depressed prices, thereby attracting more buyers. So the international fashion houses walk away with customised goods, and craftwork is sold at very low rates. As far as the fabric market is concerned, the range available in India can attract as well as confuse the buyer. Much of the production takes place in the small town of Chapa in the eastern state of Bihar, a name one might never have heard of. Here fabric-making is a family industry; the range and quality of raw silks churned out here belie the crude production methods and equipment. Surat in Gujarat, is the supplier of an amazing set of jacquards, moss crepes and georgette sheers all fabrics in high demand. Another Indian fabric design that has been adopted by the fashion industry is the Madras check, originally utilised for the universal lungi, a simple lower-body wrap worn in southern India. This design has now found its way on to bandannas, blouses, home furnishings and almost anything one can think of. Ethnic Indian designs with batik and hand-embroidered motifs have also become popular across the world. Decorative bead work is another product in demand in the international market. Beads are used to prepare accessory items like belts and bags, and beadwork is now available for haute couture evening wear too.", "hypothesis": "Modern machinery accounts for the high quality of Chapas silk.", "gold_label": "contradiction"}
{"uid": "id_137", "premise": "Trends in the Indian fashion and textile industries During the 1950s, the Indian fashion scene was exciting, stylish and very graceful. There were no celebrity designers or models, nor were there any labels that were widely recognised. The value of a garment was judged by its style and fabric rather than by who made it. It was regarded as perfectly acceptable, even for high-society women, to approach an unknown tailor who could make a garment for a few rupees, providing the perfect fit, finish and style. They were proud of getting a bargain, and of giving their own name to the end result. The 1960s was an era full of mischievousness and celebration in the arts, music and cinema. The period was characterised by freedom from restrictions and, in the fashion world, an acceptance of innovative types of material such as plastic and coated polyester. Tight-fitting kurtas and churidars and high coiffures were a trend among women. The following decade witnessed an increase in the export of traditional materials, and the arrival in India of international fashion. Synthetics became trendy, and the disco culture affected the fashion scene. It was in the early 80s when the first fashion store Ravissant opened in Mumbai. At that time garments were retailed for a four-figure price tag. American designers like Calvin Klein became popular. In India too, contours became more masculine, and even the salwar kameez was designed with shoulder pads. With the evolution of designer stores came the culture of designer fashion, along with its hefty price tags. Whatever a garment was like, consumers were convinced that a higher price tag signified elegant designer fashion, so garments were sold at unbelievable prices. Meanwhile, designers decided to get themselves noticed by making showy outfits and associating with the right celebrities. Soon, fashion shows became competitive, each designer attempting to out-do the other in theme, guest list and media coverage. In the last decade of the millennium, the market shrank and ethnic wear made a comeback. During the recession, there was a push to sell at any cost. With fierce competition the inevitable occurred: the once hefty price tags began their downward journey, and the fashion-show industry followed suit. However, the liveliness of the Indian fashion scene had not ended it had merely reached a stable level. At the beginning of the 21st century, with new designers and models, and more sensible designs, the fashion industry accelerated once again. As far as the global fashion industry is concerned, Indian ethnic designs and materials are currently in demand from fashion houses and garment manufacturers. India is the third largest producer of cotton, the second largest producer of silk, and the fifth largest producer of man-made fibres in the world. The Indian garment and fabric industries have many fundamental advantages, in terms of a cheaper, skilled work force, cost-effective production, raw materials, flexibility, and a wide range of designs with sequins, beadwork, and embroidery. In addition, that India provides garments to international fashion houses at competitive prices, with a shorter lead time, and an effective monopoly on certain designs, is accepted the whole world over. India has always been regarded as the default source in the embroidered garments segment, but changes in the rate of exchange between the rupee and the dollar has further depressed prices, thereby attracting more buyers. So the international fashion houses walk away with customised goods, and craftwork is sold at very low rates. As far as the fabric market is concerned, the range available in India can attract as well as confuse the buyer. Much of the production takes place in the small town of Chapa in the eastern state of Bihar, a name one might never have heard of. Here fabric-making is a family industry; the range and quality of raw silks churned out here belie the crude production methods and equipment. Surat in Gujarat, is the supplier of an amazing set of jacquards, moss crepes and georgette sheers all fabrics in high demand. Another Indian fabric design that has been adopted by the fashion industry is the Madras check, originally utilised for the universal lungi, a simple lower-body wrap worn in southern India. This design has now found its way on to bandannas, blouses, home furnishings and almost anything one can think of. Ethnic Indian designs with batik and hand-embroidered motifs have also become popular across the world. Decorative bead work is another product in demand in the international market. Beads are used to prepare accessory items like belts and bags, and beadwork is now available for haute couture evening wear too.", "hypothesis": "Some types of Indian craftwork which are internationally popular had humble origins.", "gold_label": "entailment"}
{"uid": "id_138", "premise": "Trends in the Indian fashion and textile industries During the 1950s, the Indian fashion scene was exciting, stylish and very graceful. There were no celebrity designers or models, nor were there any labels that were widely recognised. The value of a garment was judged by its style and fabric rather than by who made it. It was regarded as perfectly acceptable, even for high-society women, to approach an unknown tailor who could make a garment for a few rupees, providing the perfect fit, finish and style. They were proud of getting a bargain, and of giving their own name to the end result. The 1960s was an era full of mischievousness and celebration in the arts, music and cinema. The period was characterised by freedom from restrictions and, in the fashion world, an acceptance of innovative types of material such as plastic and coated polyester. Tight-fitting kurtas and churidars and high coiffures were a trend among women. The following decade witnessed an increase in the export of traditional materials, and the arrival in India of international fashion. Synthetics became trendy, and the disco culture affected the fashion scene. It was in the early 80s when the first fashion store Ravissant opened in Mumbai. At that time garments were retailed for a four-figure price tag. American designers like Calvin Klein became popular. In India too, contours became more masculine, and even the salwar kameez was designed with shoulder pads. With the evolution of designer stores came the culture of designer fashion, along with its hefty price tags. Whatever a garment was like, consumers were convinced that a higher price tag signified elegant designer fashion, so garments were sold at unbelievable prices. Meanwhile, designers decided to get themselves noticed by making showy outfits and associating with the right celebrities. Soon, fashion shows became competitive, each designer attempting to out-do the other in theme, guest list and media coverage. In the last decade of the millennium, the market shrank and ethnic wear made a comeback. During the recession, there was a push to sell at any cost. With fierce competition the inevitable occurred: the once hefty price tags began their downward journey, and the fashion-show industry followed suit. However, the liveliness of the Indian fashion scene had not ended it had merely reached a stable level. At the beginning of the 21st century, with new designers and models, and more sensible designs, the fashion industry accelerated once again. As far as the global fashion industry is concerned, Indian ethnic designs and materials are currently in demand from fashion houses and garment manufacturers. India is the third largest producer of cotton, the second largest producer of silk, and the fifth largest producer of man-made fibres in the world. The Indian garment and fabric industries have many fundamental advantages, in terms of a cheaper, skilled work force, cost-effective production, raw materials, flexibility, and a wide range of designs with sequins, beadwork, and embroidery. In addition, that India provides garments to international fashion houses at competitive prices, with a shorter lead time, and an effective monopoly on certain designs, is accepted the whole world over. India has always been regarded as the default source in the embroidered garments segment, but changes in the rate of exchange between the rupee and the dollar has further depressed prices, thereby attracting more buyers. So the international fashion houses walk away with customised goods, and craftwork is sold at very low rates. As far as the fabric market is concerned, the range available in India can attract as well as confuse the buyer. Much of the production takes place in the small town of Chapa in the eastern state of Bihar, a name one might never have heard of. Here fabric-making is a family industry; the range and quality of raw silks churned out here belie the crude production methods and equipment. Surat in Gujarat, is the supplier of an amazing set of jacquards, moss crepes and georgette sheers all fabrics in high demand. Another Indian fabric design that has been adopted by the fashion industry is the Madras check, originally utilised for the universal lungi, a simple lower-body wrap worn in southern India. This design has now found its way on to bandannas, blouses, home furnishings and almost anything one can think of. Ethnic Indian designs with batik and hand-embroidered motifs have also become popular across the world. Decorative bead work is another product in demand in the international market. Beads are used to prepare accessory items like belts and bags, and beadwork is now available for haute couture evening wear too.", "hypothesis": "Conditions in India are generally well suited to the manufacture of clothing.", "gold_label": "entailment"}
{"uid": "id_139", "premise": "Trends in the Indian fashion and textile industries During the 1950s, the Indian fashion scene was exciting, stylish and very graceful. There were no celebrity designers or models, nor were there any labels that were widely recognised. The value of a garment was judged by its style and fabric rather than by who made it. It was regarded as perfectly acceptable, even for high-society women, to approach an unknown tailor who could make a garment for a few rupees, providing the perfect fit, finish and style. They were proud of getting a bargain, and of giving their own name to the end result. The 1960s was an era full of mischievousness and celebration in the arts, music and cinema. The period was characterised by freedom from restrictions and, in the fashion world, an acceptance of innovative types of material such as plastic and coated polyester. Tight-fitting kurtas and churidars and high coiffures were a trend among women. The following decade witnessed an increase in the export of traditional materials, and the arrival in India of international fashion. Synthetics became trendy, and the disco culture affected the fashion scene. It was in the early 80s when the first fashion store Ravissant opened in Mumbai. At that time garments were retailed for a four-figure price tag. American designers like Calvin Klein became popular. In India too, contours became more masculine, and even the salwar kameez was designed with shoulder pads. With the evolution of designer stores came the culture of designer fashion, along with its hefty price tags. Whatever a garment was like, consumers were convinced that a higher price tag signified elegant designer fashion, so garments were sold at unbelievable prices. Meanwhile, designers decided to get themselves noticed by making showy outfits and associating with the right celebrities. Soon, fashion shows became competitive, each designer attempting to out-do the other in theme, guest list and media coverage. In the last decade of the millennium, the market shrank and ethnic wear made a comeback. During the recession, there was a push to sell at any cost. With fierce competition the inevitable occurred: the once hefty price tags began their downward journey, and the fashion-show industry followed suit. However, the liveliness of the Indian fashion scene had not ended it had merely reached a stable level. At the beginning of the 21st century, with new designers and models, and more sensible designs, the fashion industry accelerated once again. As far as the global fashion industry is concerned, Indian ethnic designs and materials are currently in demand from fashion houses and garment manufacturers. India is the third largest producer of cotton, the second largest producer of silk, and the fifth largest producer of man-made fibres in the world. The Indian garment and fabric industries have many fundamental advantages, in terms of a cheaper, skilled work force, cost-effective production, raw materials, flexibility, and a wide range of designs with sequins, beadwork, and embroidery. In addition, that India provides garments to international fashion houses at competitive prices, with a shorter lead time, and an effective monopoly on certain designs, is accepted the whole world over. India has always been regarded as the default source in the embroidered garments segment, but changes in the rate of exchange between the rupee and the dollar has further depressed prices, thereby attracting more buyers. So the international fashion houses walk away with customised goods, and craftwork is sold at very low rates. As far as the fabric market is concerned, the range available in India can attract as well as confuse the buyer. Much of the production takes place in the small town of Chapa in the eastern state of Bihar, a name one might never have heard of. Here fabric-making is a family industry; the range and quality of raw silks churned out here belie the crude production methods and equipment. Surat in Gujarat, is the supplier of an amazing set of jacquards, moss crepes and georgette sheers all fabrics in high demand. Another Indian fabric design that has been adopted by the fashion industry is the Madras check, originally utilised for the universal lungi, a simple lower-body wrap worn in southern India. This design has now found its way on to bandannas, blouses, home furnishings and almost anything one can think of. Ethnic Indian designs with batik and hand-embroidered motifs have also become popular across the world. Decorative bead work is another product in demand in the international market. Beads are used to prepare accessory items like belts and bags, and beadwork is now available for haute couture evening wear too.", "hypothesis": "Indian clothing exports have suffered from changes in the value of its currency.", "gold_label": "contradiction"}
{"uid": "id_140", "premise": "Trespassing occurs when a person enters a building without permission from the owner and (1) posted signs or verbal warnings prohibit the presence of unauthorized persons, or (2) the owner or other authorized person asks that person to leave.", "hypothesis": "Frank is looking at new cars at a dealership after hours when a security guard tells him to leave, which he does immediately. This is the best example of Trespassing.", "gold_label": "contradiction"}
{"uid": "id_141", "premise": "Trespassing occurs when a person enters a building without permission from the owner and (1) posted signs or verbal warnings prohibit the presence of unauthorized persons, or (2) the owner or other authorized person asks that person to leave.", "hypothesis": "A transient is sleeping in a vacant office building. Posted on the wall is a sign that reads No Trespassing. Private Property.", "gold_label": "entailment"}
{"uid": "id_142", "premise": "Trespassing occurs when a person enters a building without permission from the owner and (1) posted signs or verbal warnings prohibit the presence of unauthorized persons, or (2) the owner or other authorized person asks that person to leave.", "hypothesis": "Alonzo is hosting a party with his roommate, Manny, who gets angry and tells Alonzo to leave or he'll have him arrested for trespassing. This is the best example of Trespassing.", "gold_label": "contradiction"}
{"uid": "id_143", "premise": "Trespassing occurs when a person enters a building without permission from the owner and (1) posted signs or verbal warnings prohibit the presence of unauthorized persons, or (2) the owner or other authorized person asks that person to leave.", "hypothesis": "Ben is walking home from school one afternoon, takes a shortcut through Mrs. Benson's front yard, and then hears her yelling at him that she is going to have him arrested for trespassing. This is the best example of Trespassing.", "gold_label": "contradiction"}
{"uid": "id_144", "premise": "Twenty-four billion is invested in premium bonds and in the past 10 years the number of bonds in the draw has increased sevenfold. The chances of winning have recently changed from 27,500 to one to 24,000 to one. Record sales have meant that a new machine to select winning numbers randomly was required. The predecessor took five and a half hours to complete the draw, while the new machine can complete the task in half that time. Each month there are 1 million winners.", "hypothesis": "The new machine takes 150 minutes to draw the 1 million winning numbers.", "gold_label": "contradiction"}
{"uid": "id_145", "premise": "Twenty-four billion is invested in premium bonds and in the past 10 years the number of bonds in the draw has increased sevenfold. The chances of winning have recently changed from 27,500 to one to 24,000 to one. Record sales have meant that a new machine to select winning numbers randomly was required. The predecessor took five and a half hours to complete the draw, while the new machine can complete the task in half that time. Each month there are 1 million winners.", "hypothesis": "The chances of winning a prize have increased and there are now more winners numbers.", "gold_label": "entailment"}
{"uid": "id_146", "premise": "Twenty-four billion is invested in premium bonds and in the past 10 years the number of bonds in the draw has increased sevenfold. The chances of winning have recently changed from 27,500 to one to 24,000 to one. Record sales have meant that a new machine to select winning numbers randomly was required. The predecessor took five and a half hours to complete the draw, while the new machine can complete the task in half that time. Each month there are 1 million winners.", "hypothesis": "The new machine is a computer.", "gold_label": "neutral"}
{"uid": "id_147", "premise": "Twenty-seven-year-old Tom Smith is a very successful long distance runner. Because he is classified as an elite athlete he receives financial support. When he was at school Tom won the European Junior Cross-country Championship. As an adult Tom has repre- sented Great Britain on many occasions. His form has improved dramatically over the last two years. On the basis of coming third in the 10,000 metres at the European Championships and second in the marathon at the World Championships, he was selected to run in the 10,000 metres and the marathon at the Olympic Games. However, following random drug testing Tom was found to have taken a banned stimulant. It is also known that: Tom maintains his innocence and has appealed against the finding. Tom has been tested and found to be clean on several previous occasions. Tom has been using a nasal decongestant spray. Tom is coached by a former East German coach who had links with athletes who have been banned for using performance- enhancing drugs. Tom claims his performance has improved because he can now afford to train at altitude in the USA.", "hypothesis": "Tom was third in the marathon at the World Championships.", "gold_label": "contradiction"}
{"uid": "id_148", "premise": "Twenty-seven-year-old Tom Smith is a very successful long distance runner. Because he is classified as an elite athlete he receives financial support. When he was at school Tom won the European Junior Cross-country Championship. As an adult Tom has repre- sented Great Britain on many occasions. His form has improved dramatically over the last two years. On the basis of coming third in the 10,000 metres at the European Championships and second in the marathon at the World Championships, he was selected to run in the 10,000 metres and the marathon at the Olympic Games. However, following random drug testing Tom was found to have taken a banned stimulant. It is also known that: Tom maintains his innocence and has appealed against the finding. Tom has been tested and found to be clean on several previous occasions. Tom has been using a nasal decongestant spray. Tom is coached by a former East German coach who had links with athletes who have been banned for using performance- enhancing drugs. Tom claims his performance has improved because he can now afford to train at altitude in the USA.", "hypothesis": "Tom was given an illegal stimulant by his coach.", "gold_label": "neutral"}
{"uid": "id_149", "premise": "Twenty-seven-year-old Tom Smith is a very successful long distance runner. Because he is classified as an elite athlete he receives financial support. When he was at school Tom won the European Junior Cross-country Championship. As an adult Tom has repre- sented Great Britain on many occasions. His form has improved dramatically over the last two years. On the basis of coming third in the 10,000 metres at the European Championships and second in the marathon at the World Championships, he was selected to run in the 10,000 metres and the marathon at the Olympic Games. However, following random drug testing Tom was found to have taken a banned stimulant. It is also known that: Tom maintains his innocence and has appealed against the finding. Tom has been tested and found to be clean on several previous occasions. Tom has been using a nasal decongestant spray. Tom is coached by a former East German coach who had links with athletes who have been banned for using performance- enhancing drugs. Tom claims his performance has improved because he can now afford to train at altitude in the USA.", "hypothesis": "Tom had been the European Junior Cross-country champion.", "gold_label": "entailment"}
{"uid": "id_150", "premise": "Twenty-seven-year-old Tom Smith is a very successful long distance runner. Because he is classified as an elite athlete he receives financial support. When he was at school Tom won the European Junior Cross-country Championship. As an adult Tom has repre- sented Great Britain on many occasions. His form has improved dramatically over the last two years. On the basis of coming third in the 10,000 metres at the European Championships and second in the marathon at the World Championships, he was selected to run in the 10,000 metres and the marathon at the Olympic Games. However, following random drug testing Tom was found to have taken a banned stimulant. It is also known that: Tom maintains his innocence and has appealed against the finding. Tom has been tested and found to be clean on several previous occasions. Tom has been using a nasal decongestant spray. Tom is coached by a former East German coach who had links with athletes who have been banned for using performance- enhancing drugs. Tom claims his performance has improved because he can now afford to train at altitude in the USA.", "hypothesis": "Tom had been taking medication.", "gold_label": "entailment"}
{"uid": "id_151", "premise": "Twenty-seven-year-old Tom Smith is a very successful long distance runner. Because he is classified as an elite athlete he receives financial support. When he was at school Tom won the European Junior Cross-country Championship. As an adult Tom has repre- sented Great Britain on many occasions. His form has improved dramatically over the last two years. On the basis of coming third in the 10,000 metres at the European Championships and second in the marathon at the World Championships, he was selected to run in the 10,000 metres and the marathon at the Olympic Games. However, following random drug testing Tom was found to have taken a banned stimulant. It is also known that: Tom maintains his innocence and has appealed against the finding. Tom has been tested and found to be clean on several previous occasions. Tom has been using a nasal decongestant spray. Tom is coached by a former East German coach who had links with athletes who have been banned for using performance- enhancing drugs. Tom claims his performance has improved because he can now afford to train at altitude in the USA.", "hypothesis": "Tom depends entirely on his winnings for his income.", "gold_label": "contradiction"}
{"uid": "id_152", "premise": "Twice as many people live till they are 100 in France as in Britain. Yet the two coun- tries have similar sized populations and have diets with similar amounts of fat. In fact life expectancy is considerably better in France from the age of 65 onwards and it seems that lifestyle and diet may have a lot to do with it. Leaving aside the fact that the French probably have the best national health service in the world, statistics suggest that the French remain active longer and consume more units of fruit and vegetables. They also enjoy considerably more glasses of red wine and it seems these differences give rise to far lower levels of death caused by heart disease and this allows significant numbers of people to live until their centenary.", "hypothesis": "Four differences are attributed to the reason the French have a far lower level of death caused by heart disease: the best national health service, remaining active, consuming more fruit and vegetables and enjoying more red wine.", "gold_label": "contradiction"}
{"uid": "id_153", "premise": "Twice as many people live till they are 100 in France as in Britain. Yet the two coun- tries have similar sized populations and have diets with similar amounts of fat. In fact life expectancy is considerably better in France from the age of 65 onwards and it seems that lifestyle and diet may have a lot to do with it. Leaving aside the fact that the French probably have the best national health service in the world, statistics suggest that the French remain active longer and consume more units of fruit and vegetables. They also enjoy considerably more glasses of red wine and it seems these differences give rise to far lower levels of death caused by heart disease and this allows significant numbers of people to live until their centenary.", "hypothesis": "Even if twice as many people in France see their centenary it may be that very few people live to see their 100th birthday in either country.", "gold_label": "contradiction"}
{"uid": "id_154", "premise": "Two Wings and a Toolkit Betty and her mate Abel are captive crows in the care of Alex Kacelnik, an expert in animal behaviour at Oxford University. They belong to a forest-dwelling species of bird (Corvus rnoneduloides) confined to two islands in the South Pacific. New Caledonian crows are tenacious predators, and the only birds that habitually use a wide selection of self-made tools to find food. One of the wild crows cleverest tools is the crochet hook, made by detaching a side twig from a larger one, leaving enough of the larger twig to shape into a hook. Equally cunning is a tool crafted from the barbed vine-leaf, which consists of a central rib with paired leaflets each with a rose-like thorn at its base. They strip out a piece of this rib, removing the leaflets and all but one thorn at the top, which remains as a ready-made hook to prise out insects from awkward cracks. The crows also make an ingenious tool called a padanus probe from padanus tree leaves. The tool has a broad base, sharp tip, a row of tiny hooks along one edge, and a tapered shape created by the crow nipping and tearing to form a progression of three or four steps along the other edge of the leaf. What makes this tool special is that they manufacture it to a standard design, as if following a set of instructions. Although it is rare to catch a crow in the act of clipping out a padanus probe, we do have ample proof of their workmanship: the discarded leaves from which the tools are cut. The remarkable thing that these counterpart leaves tell us is that crows consistently produce the same design every time, with no in-between or trial versions. Its left the researchers wondering whether, like people, they envisage the tool before they start and perform the actions they know are needed to make it. Research has revealed that genetics plays a part in the less sophisticated toolmaking skills of finches in the Galapagos islands. No one knows if thats also the case for New Caledonian crows, but its highly unlikely that their toolmaking skills are hardwired into the brain. The picture so far points to a combination of cultural transmission from parent birds to their young and individual resourcefulness, says Kacelnik. In a test at Oxford, Kacelniks team offered Betty and Abel an original challenge food in a bucket at the bottom of a well. The only way to get the food was to hook the bucket out by its handle. Given a choice of tools a straight length of wire and one with a hooked end the birds immediately picked the hook, showing that they did indeed understand the functional properties of the tool. But do they also have the foresight and creativity to plan the construction of their tools? It appears they do. In one bucket-in-the-well test, Abel carried off the hook, leaving Betty with nothing but the straight wire. What happened next was absolutely amazing, says Kacelnik. She wedged the tip of the wire into a crack in a plastic dish and pulled the other end to fashion her own hook. Wild crows dont have access to pliable, bendable material that retains its shape, and Bettys only similar experience was a brief encounter with some pipe cleaners a year earlier. In nine out of ten further tests, she again made hooks and retrieved the bucket. The question of whats going on in a crows mind will take time and a lot more experiments to answer, but there could be a lesson in it for understanding our own evolution. Maybe our ancestors, who suddenly began to create symmetrical tools with carefully worked edges some 1.5 million years ago, didnt actually have the sophisticated mental abilities with which we credit them. Closer scrutiny of the brains of New Caledonian crows might provide a few pointers to the special attributes they would have needed. If were lucky we may find specific developments in the brain that set these animals apart, says Kacelnik. One of these might be a very strong degree of laterality the specialisation of one side of the brain to perform specific tasks. In people, the left side of the brain controls the processing of complex sequential tasks, and also language and speech. One of the consequences of this is thought to be right-handedness. Interestingly, biologists have noticed that most padanus probes are cut from the left side of the leaf, meaning that the birds clip them with the right side of their beaks the crow equivalent of right- handedness. The team thinks this reflects the fact that the left side of the crows brain is specialised to handle the sequential processing required to make complex tools. Under what conditions might this extraordinary talent have emerged in these two species? They are both social creatures, and wide-ranging in their feeding habits. These factors were probably important but, ironically, it may have been their shortcomings that triggered the evolution of toolmaking. Maybe the ancestors of crows and humans found themselves in a position where they couldnt make the physical adaptations required for survival so they had to change their behaviour instead. The stage was then set for the evolution of those rare cognitive skills that produce sophisticated tools. New Caledonian crows may tell us what those crucial skills are.", "hypothesis": "Research into how the padanus probe is made has helped to explain the toolmaking skills of many other bird species.", "gold_label": "neutral"}
{"uid": "id_155", "premise": "Two Wings and a Toolkit Betty and her mate Abel are captive crows in the care of Alex Kacelnik, an expert in animal behaviour at Oxford University. They belong to a forest-dwelling species of bird (Corvus rnoneduloides) confined to two islands in the South Pacific. New Caledonian crows are tenacious predators, and the only birds that habitually use a wide selection of self-made tools to find food. One of the wild crows cleverest tools is the crochet hook, made by detaching a side twig from a larger one, leaving enough of the larger twig to shape into a hook. Equally cunning is a tool crafted from the barbed vine-leaf, which consists of a central rib with paired leaflets each with a rose-like thorn at its base. They strip out a piece of this rib, removing the leaflets and all but one thorn at the top, which remains as a ready-made hook to prise out insects from awkward cracks. The crows also make an ingenious tool called a padanus probe from padanus tree leaves. The tool has a broad base, sharp tip, a row of tiny hooks along one edge, and a tapered shape created by the crow nipping and tearing to form a progression of three or four steps along the other edge of the leaf. What makes this tool special is that they manufacture it to a standard design, as if following a set of instructions. Although it is rare to catch a crow in the act of clipping out a padanus probe, we do have ample proof of their workmanship: the discarded leaves from which the tools are cut. The remarkable thing that these counterpart leaves tell us is that crows consistently produce the same design every time, with no in-between or trial versions. Its left the researchers wondering whether, like people, they envisage the tool before they start and perform the actions they know are needed to make it. Research has revealed that genetics plays a part in the less sophisticated toolmaking skills of finches in the Galapagos islands. No one knows if thats also the case for New Caledonian crows, but its highly unlikely that their toolmaking skills are hardwired into the brain. The picture so far points to a combination of cultural transmission from parent birds to their young and individual resourcefulness, says Kacelnik. In a test at Oxford, Kacelniks team offered Betty and Abel an original challenge food in a bucket at the bottom of a well. The only way to get the food was to hook the bucket out by its handle. Given a choice of tools a straight length of wire and one with a hooked end the birds immediately picked the hook, showing that they did indeed understand the functional properties of the tool. But do they also have the foresight and creativity to plan the construction of their tools? It appears they do. In one bucket-in-the-well test, Abel carried off the hook, leaving Betty with nothing but the straight wire. What happened next was absolutely amazing, says Kacelnik. She wedged the tip of the wire into a crack in a plastic dish and pulled the other end to fashion her own hook. Wild crows dont have access to pliable, bendable material that retains its shape, and Bettys only similar experience was a brief encounter with some pipe cleaners a year earlier. In nine out of ten further tests, she again made hooks and retrieved the bucket. The question of whats going on in a crows mind will take time and a lot more experiments to answer, but there could be a lesson in it for understanding our own evolution. Maybe our ancestors, who suddenly began to create symmetrical tools with carefully worked edges some 1.5 million years ago, didnt actually have the sophisticated mental abilities with which we credit them. Closer scrutiny of the brains of New Caledonian crows might provide a few pointers to the special attributes they would have needed. If were lucky we may find specific developments in the brain that set these animals apart, says Kacelnik. One of these might be a very strong degree of laterality the specialisation of one side of the brain to perform specific tasks. In people, the left side of the brain controls the processing of complex sequential tasks, and also language and speech. One of the consequences of this is thought to be right-handedness. Interestingly, biologists have noticed that most padanus probes are cut from the left side of the leaf, meaning that the birds clip them with the right side of their beaks the crow equivalent of right- handedness. The team thinks this reflects the fact that the left side of the crows brain is specialised to handle the sequential processing required to make complex tools. Under what conditions might this extraordinary talent have emerged in these two species? They are both social creatures, and wide-ranging in their feeding habits. These factors were probably important but, ironically, it may have been their shortcomings that triggered the evolution of toolmaking. Maybe the ancestors of crows and humans found themselves in a position where they couldnt make the physical adaptations required for survival so they had to change their behaviour instead. The stage was then set for the evolution of those rare cognitive skills that produce sophisticated tools. New Caledonian crows may tell us what those crucial skills are.", "hypothesis": "There appears to be a fixed pattern for the padanus probes construction.", "gold_label": "entailment"}
{"uid": "id_156", "premise": "Two Wings and a Toolkit Betty and her mate Abel are captive crows in the care of Alex Kacelnik, an expert in animal behaviour at Oxford University. They belong to a forest-dwelling species of bird (Corvus rnoneduloides) confined to two islands in the South Pacific. New Caledonian crows are tenacious predators, and the only birds that habitually use a wide selection of self-made tools to find food. One of the wild crows cleverest tools is the crochet hook, made by detaching a side twig from a larger one, leaving enough of the larger twig to shape into a hook. Equally cunning is a tool crafted from the barbed vine-leaf, which consists of a central rib with paired leaflets each with a rose-like thorn at its base. They strip out a piece of this rib, removing the leaflets and all but one thorn at the top, which remains as a ready-made hook to prise out insects from awkward cracks. The crows also make an ingenious tool called a padanus probe from padanus tree leaves. The tool has a broad base, sharp tip, a row of tiny hooks along one edge, and a tapered shape created by the crow nipping and tearing to form a progression of three or four steps along the other edge of the leaf. What makes this tool special is that they manufacture it to a standard design, as if following a set of instructions. Although it is rare to catch a crow in the act of clipping out a padanus probe, we do have ample proof of their workmanship: the discarded leaves from which the tools are cut. The remarkable thing that these counterpart leaves tell us is that crows consistently produce the same design every time, with no in-between or trial versions. Its left the researchers wondering whether, like people, they envisage the tool before they start and perform the actions they know are needed to make it. Research has revealed that genetics plays a part in the less sophisticated toolmaking skills of finches in the Galapagos islands. No one knows if thats also the case for New Caledonian crows, but its highly unlikely that their toolmaking skills are hardwired into the brain. The picture so far points to a combination of cultural transmission from parent birds to their young and individual resourcefulness, says Kacelnik. In a test at Oxford, Kacelniks team offered Betty and Abel an original challenge food in a bucket at the bottom of a well. The only way to get the food was to hook the bucket out by its handle. Given a choice of tools a straight length of wire and one with a hooked end the birds immediately picked the hook, showing that they did indeed understand the functional properties of the tool. But do they also have the foresight and creativity to plan the construction of their tools? It appears they do. In one bucket-in-the-well test, Abel carried off the hook, leaving Betty with nothing but the straight wire. What happened next was absolutely amazing, says Kacelnik. She wedged the tip of the wire into a crack in a plastic dish and pulled the other end to fashion her own hook. Wild crows dont have access to pliable, bendable material that retains its shape, and Bettys only similar experience was a brief encounter with some pipe cleaners a year earlier. In nine out of ten further tests, she again made hooks and retrieved the bucket. The question of whats going on in a crows mind will take time and a lot more experiments to answer, but there could be a lesson in it for understanding our own evolution. Maybe our ancestors, who suddenly began to create symmetrical tools with carefully worked edges some 1.5 million years ago, didnt actually have the sophisticated mental abilities with which we credit them. Closer scrutiny of the brains of New Caledonian crows might provide a few pointers to the special attributes they would have needed. If were lucky we may find specific developments in the brain that set these animals apart, says Kacelnik. One of these might be a very strong degree of laterality the specialisation of one side of the brain to perform specific tasks. In people, the left side of the brain controls the processing of complex sequential tasks, and also language and speech. One of the consequences of this is thought to be right-handedness. Interestingly, biologists have noticed that most padanus probes are cut from the left side of the leaf, meaning that the birds clip them with the right side of their beaks the crow equivalent of right- handedness. The team thinks this reflects the fact that the left side of the crows brain is specialised to handle the sequential processing required to make complex tools. Under what conditions might this extraordinary talent have emerged in these two species? They are both social creatures, and wide-ranging in their feeding habits. These factors were probably important but, ironically, it may have been their shortcomings that triggered the evolution of toolmaking. Maybe the ancestors of crows and humans found themselves in a position where they couldnt make the physical adaptations required for survival so they had to change their behaviour instead. The stage was then set for the evolution of those rare cognitive skills that produce sophisticated tools. New Caledonian crows may tell us what those crucial skills are.", "hypothesis": "Crows seem to practise a number of times before making a usable padanus probe.", "gold_label": "contradiction"}
{"uid": "id_157", "premise": "Two Wings and a Toolkit Betty and her mate Abel are captive crows in the care of Alex Kacelnik, an expert in animal behaviour at Oxford University. They belong to a forest-dwelling species of bird (Corvus rnoneduloides) confined to two islands in the South Pacific. New Caledonian crows are tenacious predators, and the only birds that habitually use a wide selection of self-made tools to find food. One of the wild crows cleverest tools is the crochet hook, made by detaching a side twig from a larger one, leaving enough of the larger twig to shape into a hook. Equally cunning is a tool crafted from the barbed vine-leaf, which consists of a central rib with paired leaflets each with a rose-like thorn at its base. They strip out a piece of this rib, removing the leaflets and all but one thorn at the top, which remains as a ready-made hook to prise out insects from awkward cracks. The crows also make an ingenious tool called a padanus probe from padanus tree leaves. The tool has a broad base, sharp tip, a row of tiny hooks along one edge, and a tapered shape created by the crow nipping and tearing to form a progression of three or four steps along the other edge of the leaf. What makes this tool special is that they manufacture it to a standard design, as if following a set of instructions. Although it is rare to catch a crow in the act of clipping out a padanus probe, we do have ample proof of their workmanship: the discarded leaves from which the tools are cut. The remarkable thing that these counterpart leaves tell us is that crows consistently produce the same design every time, with no in-between or trial versions. Its left the researchers wondering whether, like people, they envisage the tool before they start and perform the actions they know are needed to make it. Research has revealed that genetics plays a part in the less sophisticated toolmaking skills of finches in the Galapagos islands. No one knows if thats also the case for New Caledonian crows, but its highly unlikely that their toolmaking skills are hardwired into the brain. The picture so far points to a combination of cultural transmission from parent birds to their young and individual resourcefulness, says Kacelnik. In a test at Oxford, Kacelniks team offered Betty and Abel an original challenge food in a bucket at the bottom of a well. The only way to get the food was to hook the bucket out by its handle. Given a choice of tools a straight length of wire and one with a hooked end the birds immediately picked the hook, showing that they did indeed understand the functional properties of the tool. But do they also have the foresight and creativity to plan the construction of their tools? It appears they do. In one bucket-in-the-well test, Abel carried off the hook, leaving Betty with nothing but the straight wire. What happened next was absolutely amazing, says Kacelnik. She wedged the tip of the wire into a crack in a plastic dish and pulled the other end to fashion her own hook. Wild crows dont have access to pliable, bendable material that retains its shape, and Bettys only similar experience was a brief encounter with some pipe cleaners a year earlier. In nine out of ten further tests, she again made hooks and retrieved the bucket. The question of whats going on in a crows mind will take time and a lot more experiments to answer, but there could be a lesson in it for understanding our own evolution. Maybe our ancestors, who suddenly began to create symmetrical tools with carefully worked edges some 1.5 million years ago, didnt actually have the sophisticated mental abilities with which we credit them. Closer scrutiny of the brains of New Caledonian crows might provide a few pointers to the special attributes they would have needed. If were lucky we may find specific developments in the brain that set these animals apart, says Kacelnik. One of these might be a very strong degree of laterality the specialisation of one side of the brain to perform specific tasks. In people, the left side of the brain controls the processing of complex sequential tasks, and also language and speech. One of the consequences of this is thought to be right-handedness. Interestingly, biologists have noticed that most padanus probes are cut from the left side of the leaf, meaning that the birds clip them with the right side of their beaks the crow equivalent of right- handedness. The team thinks this reflects the fact that the left side of the crows brain is specialised to handle the sequential processing required to make complex tools. Under what conditions might this extraordinary talent have emerged in these two species? They are both social creatures, and wide-ranging in their feeding habits. These factors were probably important but, ironically, it may have been their shortcomings that triggered the evolution of toolmaking. Maybe the ancestors of crows and humans found themselves in a position where they couldnt make the physical adaptations required for survival so they had to change their behaviour instead. The stage was then set for the evolution of those rare cognitive skills that produce sophisticated tools. New Caledonian crows may tell us what those crucial skills are.", "hypothesis": "The researchers suspect the crows have a mental image of the padanus probe before they create it.", "gold_label": "entailment"}
{"uid": "id_158", "premise": "Two Wings and a Toolkit Betty and her mate Abel are captive crows in the care of Alex Kacelnik, an expert in animal behaviour at Oxford University. They belong to a forest-dwelling species of bird (Corvus rnoneduloides) confined to two islands in the South Pacific. New Caledonian crows are tenacious predators, and the only birds that habitually use a wide selection of self-made tools to find food. One of the wild crows cleverest tools is the crochet hook, made by detaching a side twig from a larger one, leaving enough of the larger twig to shape into a hook. Equally cunning is a tool crafted from the barbed vine-leaf, which consists of a central rib with paired leaflets each with a rose-like thorn at its base. They strip out a piece of this rib, removing the leaflets and all but one thorn at the top, which remains as a ready-made hook to prise out insects from awkward cracks. The crows also make an ingenious tool called a padanus probe from padanus tree leaves. The tool has a broad base, sharp tip, a row of tiny hooks along one edge, and a tapered shape created by the crow nipping and tearing to form a progression of three or four steps along the other edge of the leaf. What makes this tool special is that they manufacture it to a standard design, as if following a set of instructions. Although it is rare to catch a crow in the act of clipping out a padanus probe, we do have ample proof of their workmanship: the discarded leaves from which the tools are cut. The remarkable thing that these counterpart leaves tell us is that crows consistently produce the same design every time, with no in-between or trial versions. Its left the researchers wondering whether, like people, they envisage the tool before they start and perform the actions they know are needed to make it. Research has revealed that genetics plays a part in the less sophisticated toolmaking skills of finches in the Galapagos islands. No one knows if thats also the case for New Caledonian crows, but its highly unlikely that their toolmaking skills are hardwired into the brain. The picture so far points to a combination of cultural transmission from parent birds to their young and individual resourcefulness, says Kacelnik. In a test at Oxford, Kacelniks team offered Betty and Abel an original challenge food in a bucket at the bottom of a well. The only way to get the food was to hook the bucket out by its handle. Given a choice of tools a straight length of wire and one with a hooked end the birds immediately picked the hook, showing that they did indeed understand the functional properties of the tool. But do they also have the foresight and creativity to plan the construction of their tools? It appears they do. In one bucket-in-the-well test, Abel carried off the hook, leaving Betty with nothing but the straight wire. What happened next was absolutely amazing, says Kacelnik. She wedged the tip of the wire into a crack in a plastic dish and pulled the other end to fashion her own hook. Wild crows dont have access to pliable, bendable material that retains its shape, and Bettys only similar experience was a brief encounter with some pipe cleaners a year earlier. In nine out of ten further tests, she again made hooks and retrieved the bucket. The question of whats going on in a crows mind will take time and a lot more experiments to answer, but there could be a lesson in it for understanding our own evolution. Maybe our ancestors, who suddenly began to create symmetrical tools with carefully worked edges some 1.5 million years ago, didnt actually have the sophisticated mental abilities with which we credit them. Closer scrutiny of the brains of New Caledonian crows might provide a few pointers to the special attributes they would have needed. If were lucky we may find specific developments in the brain that set these animals apart, says Kacelnik. One of these might be a very strong degree of laterality the specialisation of one side of the brain to perform specific tasks. In people, the left side of the brain controls the processing of complex sequential tasks, and also language and speech. One of the consequences of this is thought to be right-handedness. Interestingly, biologists have noticed that most padanus probes are cut from the left side of the leaf, meaning that the birds clip them with the right side of their beaks the crow equivalent of right- handedness. The team thinks this reflects the fact that the left side of the crows brain is specialised to handle the sequential processing required to make complex tools. Under what conditions might this extraordinary talent have emerged in these two species? They are both social creatures, and wide-ranging in their feeding habits. These factors were probably important but, ironically, it may have been their shortcomings that triggered the evolution of toolmaking. Maybe the ancestors of crows and humans found themselves in a position where they couldnt make the physical adaptations required for survival so they had to change their behaviour instead. The stage was then set for the evolution of those rare cognitive skills that produce sophisticated tools. New Caledonian crows may tell us what those crucial skills are.", "hypothesis": "There is plenty of evidence to indicate how the crows manufacture the padanus probe.", "gold_label": "entailment"}
{"uid": "id_159", "premise": "Two Wings and a Toolkit Betty and her mate Abel are captive crows in the care of Alex Kacelnik, an expert in animal behaviour at Oxford University. They belong to a forest-dwelling species of bird (Corvus rnoneduloides) confined to two islands in the South Pacific. New Caledonian crows are tenacious predators, and the only birds that habitually use a wide selection of self-made tools to find food. One of the wild crows cleverest tools is the crochet hook, made by detaching a side twig from a larger one, leaving enough of the larger twig to shape into a hook. Equally cunning is a tool crafted from the barbed vine-leaf, which consists of a central rib with paired leaflets each with a rose-like thorn at its base. They strip out a piece of this rib, removing the leaflets and all but one thorn at the top, which remains as a ready-made hook to prise out insects from awkward cracks. The crows also make an ingenious tool called a padanus probe from padanus tree leaves. The tool has a broad base, sharp tip, a row of tiny hooks along one edge, and a tapered shape created by the crow nipping and tearing to form a progression of three or four steps along the other edge of the leaf. What makes this tool special is that they manufacture it to a standard design, as if following a set of instructions. Although it is rare to catch a crow in the act of clipping out a padanus probe, we do have ample proof of their workmanship: the discarded leaves from which the tools are cut. The remarkable thing that these counterpart leaves tell us is that crows consistently produce the same design every time, with no in-between or trial versions. Its left the researchers wondering whether, like people, they envisage the tool before they start and perform the actions they know are needed to make it. Research has revealed that genetics plays a part in the less sophisticated toolmaking skills of finches in the Galapagos islands. No one knows if thats also the case for New Caledonian crows, but its highly unlikely that their toolmaking skills are hardwired into the brain. The picture so far points to a combination of cultural transmission from parent birds to their young and individual resourcefulness, says Kacelnik. In a test at Oxford, Kacelniks team offered Betty and Abel an original challenge food in a bucket at the bottom of a well. The only way to get the food was to hook the bucket out by its handle. Given a choice of tools a straight length of wire and one with a hooked end the birds immediately picked the hook, showing that they did indeed understand the functional properties of the tool. But do they also have the foresight and creativity to plan the construction of their tools? It appears they do. In one bucket-in-the-well test, Abel carried off the hook, leaving Betty with nothing but the straight wire. What happened next was absolutely amazing, says Kacelnik. She wedged the tip of the wire into a crack in a plastic dish and pulled the other end to fashion her own hook. Wild crows dont have access to pliable, bendable material that retains its shape, and Bettys only similar experience was a brief encounter with some pipe cleaners a year earlier. In nine out of ten further tests, she again made hooks and retrieved the bucket. The question of whats going on in a crows mind will take time and a lot more experiments to answer, but there could be a lesson in it for understanding our own evolution. Maybe our ancestors, who suddenly began to create symmetrical tools with carefully worked edges some 1.5 million years ago, didnt actually have the sophisticated mental abilities with which we credit them. Closer scrutiny of the brains of New Caledonian crows might provide a few pointers to the special attributes they would have needed. If were lucky we may find specific developments in the brain that set these animals apart, says Kacelnik. One of these might be a very strong degree of laterality the specialisation of one side of the brain to perform specific tasks. In people, the left side of the brain controls the processing of complex sequential tasks, and also language and speech. One of the consequences of this is thought to be right-handedness. Interestingly, biologists have noticed that most padanus probes are cut from the left side of the leaf, meaning that the birds clip them with the right side of their beaks the crow equivalent of right- handedness. The team thinks this reflects the fact that the left side of the crows brain is specialised to handle the sequential processing required to make complex tools. Under what conditions might this extraordinary talent have emerged in these two species? They are both social creatures, and wide-ranging in their feeding habits. These factors were probably important but, ironically, it may have been their shortcomings that triggered the evolution of toolmaking. Maybe the ancestors of crows and humans found themselves in a position where they couldnt make the physical adaptations required for survival so they had to change their behaviour instead. The stage was then set for the evolution of those rare cognitive skills that produce sophisticated tools. New Caledonian crows may tell us what those crucial skills are.", "hypothesis": "The researchers believe the ability to make the padanus probe is passed down to the crows in their genes.", "gold_label": "contradiction"}
{"uid": "id_160", "premise": "Two charities have delivered a petition to the Prime Minister that has been signed by over 35,000 people. The petition, jointly organised by the 'Health Food Group (HFG) and 'Happy Heart and Mind is calling for a ban on junk food adverts before 9pm on any channel. The Government is also being urged to tighten advertising regulations and protect children in this regard more widely. The current regulations restrict junk food adverts from being showing during children's programming but there is nothing to stop them being shown during popular family slots, such as Saturday evenings when many children watch television with their families. Casey Stemp coordinated the petition and is a strong advocate of the proposed changes. 'By removing junk food adverts from television at any time before 99m, we would be seeing a simple, popular and effective move that would help parents to tackle the increasing desire of young people to consume such foods. ' The loopholes that junk food companies find mean that our younger generation are faced with a constant bombardment of junk food adverts. As future generations are becoming more and more obese, we have to look for opportunities to alleviate the temptations they are facing on a daily, if not hourly basis!", "hypothesis": "Saturday evenings are a time when many families would be tempted to indulge in junk food.", "gold_label": "neutral"}
{"uid": "id_161", "premise": "Two families of venomous snakes are native to the United States. The vast majority are pit vipers, of the family Crotalidae, which include rattlesnakes, copperheads and cottonmouths. Virtually all of the venomous bites in this country are from pit vipers. Some, Mojave rattlesnakes or canebrake rattlesnakes, for example, carry a neurotoxic venom that can affect the brain or spinal cord. Copperheads, on the other hand, have a milder and less dangerous venom that sometimes may not require antivenin treatment. The other family is Elapidae, which includes two species of coral snakes found chiefly in the Southern states. Related to the much more dangerous Asian cobras and kraits, coral snakes have small mouths and short teeth, which give them a less efficient venom delivery than pit vipers. People bitten by coral snakes lack the characteristic fang marks of pit vipers, sometimes making the bite hard to detect.", "hypothesis": "Coral snakes are found in Florida and Alabama.", "gold_label": "neutral"}
{"uid": "id_162", "premise": "Two families of venomous snakes are native to the United States. The vast majority are pit vipers, of the family Crotalidae, which include rattlesnakes, copperheads and cottonmouths. Virtually all of the venomous bites in this country are from pit vipers. Some, Mojave rattlesnakes or canebrake rattlesnakes, for example, carry a neurotoxic venom that can affect the brain or spinal cord. Copperheads, on the other hand, have a milder and less dangerous venom that sometimes may not require antivenin treatment. The other family is Elapidae, which includes two species of coral snakes found chiefly in the Southern states. Related to the much more dangerous Asian cobras and kraits, coral snakes have small mouths and short teeth, which give them a less efficient venom delivery than pit vipers. People bitten by coral snakes lack the characteristic fang marks of pit vipers, sometimes making the bite hard to detect.", "hypothesis": "Bite marks from pit vipers can be hard to detect.", "gold_label": "neutral"}
{"uid": "id_163", "premise": "Two families of venomous snakes are native to the United States. The vast majority are pit vipers, of the family Crotalidae, which include rattlesnakes, copperheads and cottonmouths. Virtually all of the venomous bites in this country are from pit vipers. Some, Mojave rattlesnakes or canebrake rattlesnakes, for example, carry a neurotoxic venom that can affect the brain or spinal cord. Copperheads, on the other hand, have a milder and less dangerous venom that sometimes may not require antivenin treatment. The other family is Elapidae, which includes two species of coral snakes found chiefly in the Southern states. Related to the much more dangerous Asian cobras and kraits, coral snakes have small mouths and short teeth, which give them a less efficient venom delivery than pit vipers. People bitten by coral snakes lack the characteristic fang marks of pit vipers, sometimes making the bite hard to detect.", "hypothesis": "Coral snakes are less dangerous than Asian cobras.", "gold_label": "entailment"}
{"uid": "id_164", "premise": "Two families of venomous snakes are native to the United States. The vast majority are pit vipers, of the family Crotalidae, which include rattlesnakes, copperheads and cottonmouths. Virtually all of the venomous bites in this country are from pit vipers. Some, Mojave rattlesnakes or canebrake rattlesnakes, for example, carry a neurotoxic venom that can affect the brain or spinal cord. Copperheads, on the other hand, have a milder and less dangerous venom that sometimes may not require antivenin treatment. The other family is Elapidae, which includes two species of coral snakes found chiefly in the Southern states. Related to the much more dangerous Asian cobras and kraits, coral snakes have small mouths and short teeth, which give them a less efficient venom delivery than pit vipers. People bitten by coral snakes lack the characteristic fang marks of pit vipers, sometimes making the bite hard to detect.", "hypothesis": "Cottonmouths are also known as Water Moccasins.", "gold_label": "contradiction"}
{"uid": "id_165", "premise": "Two families of venomous snakes are native to the United States. The vast majority are pit vipers, of the family Crotalidae, which include rattlesnakes, copperheads and cottonmouths. Virtually all of the venomous bites in this country are from pit vipers. Some, Mojave rattlesnakes or canebrake rattlesnakes, for example, carry a neurotoxic venom that can affect the brain or spinal cord. Copperheads, on the other hand, have a milder and less dangerous venom that sometimes may not require antivenin treatment. The other family is Elapidae, which includes two species of coral snakes found chiefly in the Southern states. Related to the much more dangerous Asian cobras and kraits, coral snakes have small mouths and short teeth, which give them a less efficient venom delivery than pit vipers. People bitten by coral snakes lack the characteristic fang marks of pit vipers, sometimes making the bite hard to detect.", "hypothesis": "Crotalidae and Elapidae are native to the United States.", "gold_label": "entailment"}
{"uid": "id_166", "premise": "Two inter-city railway carriages were found ablaze last night (10 March) on a siding near Glundal station. Three elderly men were seen at the station at 19.00 last night and reliable witnesses say that they were all over 6 ft tall and that one of the men had a bad limp. It is also known that: The carriages belonged to Southern Trains and were waiting to be repaired. Fred Wish is 6 ft 5 in tall and 58 years old. Bob Tuck is a retired train driver. The railway company made Rod Debbs redundant in January. The carriages had been taken out of service because of electrical faults. A violent thunderstorm occurred over Glundal on 10 March. John Plum is 64 years old and has just left hospital after a knee operation. Sixty-one-year-old Dennis White, a former railway worker, is 5 ft 6 in tall.", "hypothesis": "Dennis White was one of the three elderly men seen at the station at 19.00 on the night of the fire.", "gold_label": "contradiction"}
{"uid": "id_167", "premise": "Two inter-city railway carriages were found ablaze last night (10 March) on a siding near Glundal station. Three elderly men were seen at the station at 19.00 last night and reliable witnesses say that they were all over 6 ft tall and that one of the men had a bad limp. It is also known that: The carriages belonged to Southern Trains and were waiting to be repaired. Fred Wish is 6 ft 5 in tall and 58 years old. Bob Tuck is a retired train driver. The railway company made Rod Debbs redundant in January. The carriages had been taken out of service because of electrical faults. A violent thunderstorm occurred over Glundal on 10 March. John Plum is 64 years old and has just left hospital after a knee operation. Sixty-one-year-old Dennis White, a former railway worker, is 5 ft 6 in tall.", "hypothesis": "Lightning could have started the fire in the railway carriages.", "gold_label": "entailment"}
{"uid": "id_168", "premise": "Two inter-city railway carriages were found ablaze last night (10 March) on a siding near Glundal station. Three elderly men were seen at the station at 19.00 last night and reliable witnesses say that they were all over 6 ft tall and that one of the men had a bad limp. It is also known that: The carriages belonged to Southern Trains and were waiting to be repaired. Fred Wish is 6 ft 5 in tall and 58 years old. Bob Tuck is a retired train driver. The railway company made Rod Debbs redundant in January. The carriages had been taken out of service because of electrical faults. A violent thunderstorm occurred over Glundal on 10 March. John Plum is 64 years old and has just left hospital after a knee operation. Sixty-one-year-old Dennis White, a former railway worker, is 5 ft 6 in tall.", "hypothesis": "Fred Wish could have been one of the three elderly men seen at the station.", "gold_label": "entailment"}
{"uid": "id_169", "premise": "Two inter-city railway carriages were found ablaze last night (10 March) on a siding near Glundal station. Three elderly men were seen at the station at 19.00 last night and reliable witnesses say that they were all over 6 ft tall and that one of the men had a bad limp. It is also known that: The carriages belonged to Southern Trains and were waiting to be repaired. Fred Wish is 6 ft 5 in tall and 58 years old. Bob Tuck is a retired train driver. The railway company made Rod Debbs redundant in January. The carriages had been taken out of service because of electrical faults. A violent thunderstorm occurred over Glundal on 10 March. John Plum is 64 years old and has just left hospital after a knee operation. Sixty-one-year-old Dennis White, a former railway worker, is 5 ft 6 in tall.", "hypothesis": "Bob Tuck is over 65 years old.", "gold_label": "neutral"}
{"uid": "id_170", "premise": "Two inter-city railway carriages were found ablaze last night (10 March) on a siding near Glundal station. Three elderly men were seen at the station at 19.00 last night and reliable witnesses say that they were all over 6 ft tall and that one of the men had a bad limp. It is also known that: The carriages belonged to Southern Trains and were waiting to be repaired. Fred Wish is 6 ft 5 in tall and 58 years old. Bob Tuck is a retired train driver. The railway company made Rod Debbs redundant in January. The carriages had been taken out of service because of electrical faults. A violent thunderstorm occurred over Glundal on 10 March. John Plum is 64 years old and has just left hospital after a knee operation. Sixty-one-year-old Dennis White, a former railway worker, is 5 ft 6 in tall.", "hypothesis": "Rod Debbs had a motive for the arson attack.", "gold_label": "neutral"}
{"uid": "id_171", "premise": "Two masked gunmen held up the only bank in Tuisdale at 10.30 on Wednesday 23 May. They made a successful getaway with over 500,000. The police say that three men are helping them with their enquiries. It is also known that: Four people work at the bank. Six customers were in the bank at 10.30. No shots were fired. Ms Grainger left the bank at 10.28 on Wednesday 23 May. All the people in the bank were made to lie on the floor face down on their stomachs. The police chased the getaway car for 16 km, and then lost it. An alarm alerted the police to the hold-up. A red Ford Mondeo drove away from the bank at high speed at 10.30 on Wednesday 23 May.", "hypothesis": "The getaway car was a red Ford Mondeo.", "gold_label": "neutral"}
{"uid": "id_172", "premise": "Two masked gunmen held up the only bank in Tuisdale at 10.30 on Wednesday 23 May. They made a successful getaway with over 500,000. The police say that three men are helping them with their enquiries. It is also known that: Four people work at the bank. Six customers were in the bank at 10.30. No shots were fired. Ms Grainger left the bank at 10.28 on Wednesday 23 May. All the people in the bank were made to lie on the floor face down on their stomachs. The police chased the getaway car for 16 km, and then lost it. An alarm alerted the police to the hold-up. A red Ford Mondeo drove away from the bank at high speed at 10.30 on Wednesday 23 May.", "hypothesis": "As a goodwill gesture, Tuisdales other bank provided emergency access to cash for customers after their ordeal.", "gold_label": "contradiction"}
{"uid": "id_173", "premise": "Two masked gunmen held up the only bank in Tuisdale at 10.30 on Wednesday 23 May. They made a successful getaway with over 500,000. The police say that three men are helping them with their enquiries. It is also known that: Four people work at the bank. Six customers were in the bank at 10.30. No shots were fired. Ms Grainger left the bank at 10.28 on Wednesday 23 May. All the people in the bank were made to lie on the floor face down on their stomachs. The police chased the getaway car for 16 km, and then lost it. An alarm alerted the police to the hold-up. A red Ford Mondeo drove away from the bank at high speed at 10.30 on Wednesday 23 May.", "hypothesis": "At least six people were lying on the floor in the bank.", "gold_label": "entailment"}
{"uid": "id_174", "premise": "Two masked gunmen held up the only bank in Tuisdale at 10.30 on Wednesday 23 May. They made a successful getaway with over 500,000. The police say that three men are helping them with their enquiries. It is also known that: Four people work at the bank. Six customers were in the bank at 10.30. No shots were fired. Ms Grainger left the bank at 10.28 on Wednesday 23 May. All the people in the bank were made to lie on the floor face down on their stomachs. The police chased the getaway car for 16 km, and then lost it. An alarm alerted the police to the hold-up. A red Ford Mondeo drove away from the bank at high speed at 10.30 on Wednesday 23 May.", "hypothesis": "The cashier pressed an alarm in the bank, which is connected to the police station.", "gold_label": "neutral"}
{"uid": "id_175", "premise": "Two masked gunmen held up the only bank in Tuisdale at 10.30 on Wednesday 23 May. They made a successful getaway with over 500,000. The police say that three men are helping them with their enquiries. It is also known that: Four people work at the bank. Six customers were in the bank at 10.30. No shots were fired. Ms Grainger left the bank at 10.28 on Wednesday 23 May. All the people in the bank were made to lie on the floor face down on their stomachs. The police chased the getaway car for 16 km, and then lost it. An alarm alerted the police to the hold-up. A red Ford Mondeo drove away from the bank at high speed at 10.30 on Wednesday 23 May.", "hypothesis": "One of the gunmen fired a shot to make everyone lie down on the floor.", "gold_label": "contradiction"}
{"uid": "id_176", "premise": "Two men posing as council workers have been accused of stealing 500 from an 84-year-old man after offering to clear up leaves from the driveway of his home. The two men called at a house in Aspenwood Drive, Sherlston, owned and lived in by Mr Stephen Pimblett during the morning of 12 October. After introducing them- selves, they offered to sweep up the leaves and remove them for the sum of 20, which he accepted. When the two men had completed the task he invited them into the house in order to pay them the agreed sum. At that point they informed him that the cost had risen to 75 because: they had cleared the garden of leaves in addition to the drive; and, he would have to bear the cost of transporting the large quantity leaves to the council refuge collection point. He paid them the amount they had asked for, but he later claimed that they had stolen an additional sum of money from his house. It is also known that: Thieves posing as council workers and representatives of the utilities companies were known to have been operating in the area, and to have been targeting older people living on their own. Verbal logical reasoning tests Stephen Pimblett had a comprehensive home contents insurance policy which covered him against losses by accidental damage, fire and theft. Mr Pimblett had a large garden, which was surrounded by tall hedges and included many bushes and a number of fruit trees. The autumn weather had been very windy causing the trees to shed their leaves. Mr Pimblett preferred to pay for everything by cash and had a reputation for keeping substantial sums of money hidden in the house. Mr Pimblett was in good health but his family was concerned that he was becoming a bit forgetful and had a habit of falling asleep in an armchair while sitting watching television.", "hypothesis": "Stephen Pimblett was the owner-occupier of a house in Aspenwood Drive, Sherlston.", "gold_label": "entailment"}
{"uid": "id_177", "premise": "Two men posing as council workers have been accused of stealing 500 from an 84-year-old man after offering to clear up leaves from the driveway of his home. The two men called at a house in Aspenwood Drive, Sherlston, owned and lived in by Mr Stephen Pimblett during the morning of 12 October. After introducing them- selves, they offered to sweep up the leaves and remove them for the sum of 20, which he accepted. When the two men had completed the task he invited them into the house in order to pay them the agreed sum. At that point they informed him that the cost had risen to 75 because: they had cleared the garden of leaves in addition to the drive; and, he would have to bear the cost of transporting the large quantity leaves to the council refuge collection point. He paid them the amount they had asked for, but he later claimed that they had stolen an additional sum of money from his house. It is also known that: Thieves posing as council workers and representatives of the utilities companies were known to have been operating in the area, and to have been targeting older people living on their own. Verbal logical reasoning tests Stephen Pimblett had a comprehensive home contents insurance policy which covered him against losses by accidental damage, fire and theft. Mr Pimblett had a large garden, which was surrounded by tall hedges and included many bushes and a number of fruit trees. The autumn weather had been very windy causing the trees to shed their leaves. Mr Pimblett preferred to pay for everything by cash and had a reputation for keeping substantial sums of money hidden in the house. Mr Pimblett was in good health but his family was concerned that he was becoming a bit forgetful and had a habit of falling asleep in an armchair while sitting watching television.", "hypothesis": "If it had it been stolen from his house by the two men as Mr Pimblett claimed, he would have had no means of recovering the lost money.", "gold_label": "contradiction"}
{"uid": "id_178", "premise": "Two men posing as council workers have been accused of stealing 500 from an 84-year-old man after offering to clear up leaves from the driveway of his home. The two men called at a house in Aspenwood Drive, Sherlston, owned and lived in by Mr Stephen Pimblett during the morning of 12 October. After introducing them- selves, they offered to sweep up the leaves and remove them for the sum of 20, which he accepted. When the two men had completed the task he invited them into the house in order to pay them the agreed sum. At that point they informed him that the cost had risen to 75 because: they had cleared the garden of leaves in addition to the drive; and, he would have to bear the cost of transporting the large quantity leaves to the council refuge collection point. He paid them the amount they had asked for, but he later claimed that they had stolen an additional sum of money from his house. It is also known that: Thieves posing as council workers and representatives of the utilities companies were known to have been operating in the area, and to have been targeting older people living on their own. Verbal logical reasoning tests Stephen Pimblett had a comprehensive home contents insurance policy which covered him against losses by accidental damage, fire and theft. Mr Pimblett had a large garden, which was surrounded by tall hedges and included many bushes and a number of fruit trees. The autumn weather had been very windy causing the trees to shed their leaves. Mr Pimblett preferred to pay for everything by cash and had a reputation for keeping substantial sums of money hidden in the house. Mr Pimblett was in good health but his family was concerned that he was becoming a bit forgetful and had a habit of falling asleep in an armchair while sitting watching television.", "hypothesis": "One of the two men entered the house and stole the money while Mr Pimblett was asleep in an armchair in front of the television.", "gold_label": "neutral"}
{"uid": "id_179", "premise": "Two men posing as council workers have been accused of stealing 500 from an 84-year-old man after offering to clear up leaves from the driveway of his home. The two men called at a house in Aspenwood Drive, Sherlston, owned and lived in by Mr Stephen Pimblett during the morning of 12 October. After introducing them- selves, they offered to sweep up the leaves and remove them for the sum of 20, which he accepted. When the two men had completed the task he invited them into the house in order to pay them the agreed sum. At that point they informed him that the cost had risen to 75 because: they had cleared the garden of leaves in addition to the drive; and, he would have to bear the cost of transporting the large quantity leaves to the council refuge collection point. He paid them the amount they had asked for, but he later claimed that they had stolen an additional sum of money from his house. It is also known that: Thieves posing as council workers and representatives of the utilities companies were known to have been operating in the area, and to have been targeting older people living on their own. Verbal logical reasoning tests Stephen Pimblett had a comprehensive home contents insurance policy which covered him against losses by accidental damage, fire and theft. Mr Pimblett had a large garden, which was surrounded by tall hedges and included many bushes and a number of fruit trees. The autumn weather had been very windy causing the trees to shed their leaves. Mr Pimblett preferred to pay for everything by cash and had a reputation for keeping substantial sums of money hidden in the house. Mr Pimblett was in good health but his family was concerned that he was becoming a bit forgetful and had a habit of falling asleep in an armchair while sitting watching television.", "hypothesis": "The two men that called at Mr Pimbletts house and offered to clear up the fallen leaves from his driveway were part of a gang of confidence tricksters known to have been operating in the area.", "gold_label": "neutral"}
{"uid": "id_180", "premise": "Two men posing as council workers have been accused of stealing 500 from an 84-year-old man after offering to clear up leaves from the driveway of his home. The two men called at a house in Aspenwood Drive, Sherlston, owned and lived in by Mr Stephen Pimblett during the morning of 12 October. After introducing them- selves, they offered to sweep up the leaves and remove them for the sum of 20, which he accepted. When the two men had completed the task he invited them into the house in order to pay them the agreed sum. At that point they informed him that the cost had risen to 75 because: they had cleared the garden of leaves in addition to the drive; and, he would have to bear the cost of transporting the large quantity leaves to the council refuge collection point. He paid them the amount they had asked for, but he later claimed that they had stolen an additional sum of money from his house. It is also known that: Thieves posing as council workers and representatives of the utilities companies were known to have been operating in the area, and to have been targeting older people living on their own. Verbal logical reasoning tests Stephen Pimblett had a comprehensive home contents insurance policy which covered him against losses by accidental damage, fire and theft. Mr Pimblett had a large garden, which was surrounded by tall hedges and included many bushes and a number of fruit trees. The autumn weather had been very windy causing the trees to shed their leaves. Mr Pimblett preferred to pay for everything by cash and had a reputation for keeping substantial sums of money hidden in the house. Mr Pimblett was in good health but his family was concerned that he was becoming a bit forgetful and had a habit of falling asleep in an armchair while sitting watching television.", "hypothesis": "A thorough search of the house would probably have shown that the sum of money Mr Pimblett claimed to have been stolen was still in the place where he had hidden it.", "gold_label": "neutral"}
{"uid": "id_181", "premise": "Two months ago, it was announced that Central Government pensioners would get dearness relief with immediate effect but till date, banks have not credited the arrears.", "hypothesis": "Most of the banks normally take care of the pensioners", "gold_label": "neutral"}
{"uid": "id_182", "premise": "Two months ago, it was announced that Central Government pensioners would get dearness relief with immediate effect but till date, banks have not credited the arrears.", "hypothesis": "Two months time is sufficient for the government machinery to move and give effect to pensioners.", "gold_label": "entailment"}
{"uid": "id_183", "premise": "Two studies published recently show that 13 of 16 children treated with gene therapy treating diseases by correcting a patient's faulty genes - for severe combined immune deficiency, or SCID, have had their immune systems restored. The best treatment for the disease is a bone marrow transplant from an immunologically matched sibling. But when no matched donor is available, unmatched donors, such as parents, are recruited; these transplants are only around 70 percent successful. The success of gene therapy now rivals or betters that seen in these unmatched donor situations. In 2001, a child in the trial developed leukemia, thought to have been induced by a component in the modified virus, or vector, the researchers used to insert the correct gene into the boy's cells. Of the 30 children worldwide who have been treated with gene therapy for another form of SCID, marked by a deficiency in the enzyme adenosine deaminase (ADA), none has developed leukemia. Yet medical researchers maintain that gene therapy is still a better alternative than the conventional treatment for X-linked SCID in some children because 19 of the 20 children who have received gene therapy for X-linked SCID are still alive. When told these odds, all parents of children with X-linked SCID have opted for gene therapy", "hypothesis": "In most instances, gene therapy is preferable to bone marrow transplants.", "gold_label": "neutral"}
{"uid": "id_184", "premise": "Two studies published recently show that 13 of 16 children treated with gene therapy treating diseases by correcting a patient's faulty genes - for severe combined immune deficiency, or SCID, have had their immune systems restored. The best treatment for the disease is a bone marrow transplant from an immunologically matched sibling. But when no matched donor is available, unmatched donors, such as parents, are recruited; these transplants are only around 70 percent successful. The success of gene therapy now rivals or betters that seen in these unmatched donor situations. In 2001, a child in the trial developed leukemia, thought to have been induced by a component in the modified virus, or vector, the researchers used to insert the correct gene into the boy's cells. Of the 30 children worldwide who have been treated with gene therapy for another form of SCID, marked by a deficiency in the enzyme adenosine deaminase (ADA), none has developed leukemia. Yet medical researchers maintain that gene therapy is still a better alternative than the conventional treatment for X-linked SCID in some children because 19 of the 20 children who have received gene therapy for X-linked SCID are still alive. When told these odds, all parents of children with X-linked SCID have opted for gene therapy", "hypothesis": "Siblings are always immunologically matched.", "gold_label": "neutral"}
{"uid": "id_185", "premise": "Two studies published recently show that 13 of 16 children treated with gene therapy treating diseases by correcting a patient's faulty genes - for severe combined immune deficiency, or SCID, have had their immune systems restored. The best treatment for the disease is a bone marrow transplant from an immunologically matched sibling. But when no matched donor is available, unmatched donors, such as parents, are recruited; these transplants are only around 70 percent successful. The success of gene therapy now rivals or betters that seen in these unmatched donor situations. In 2001, a child in the trial developed leukemia, thought to have been induced by a component in the modified virus, or vector, the researchers used to insert the correct gene into the boy's cells. Of the 30 children worldwide who have been treated with gene therapy for another form of SCID, marked by a deficiency in the enzyme adenosine deaminase (ADA), none has developed leukemia. Yet medical researchers maintain that gene therapy is still a better alternative than the conventional treatment for X-linked SCID in some children because 19 of the 20 children who have received gene therapy for X-linked SCID are still alive. When told these odds, all parents of children with X-linked SCID have opted for gene therapy", "hypothesis": "Of the remedies mentioned, bone marrow transplant from an immunologically unmatched donor has the lowest rate of success.", "gold_label": "entailment"}
{"uid": "id_186", "premise": "U3b Networks (U3b being short for the underprivileged three billion who lack internet access) is a company in Jersey set up by Greg Wyler, former owner of Rwandas national telephone company. His company intends to provide cheap, high-speed internet access to remote areas in developing countries, which up to now has been the reserve of developed countries. Mr Wyler plans to charge $500 per megabit per month, compared with the $4,000 charged by existing companies. Mr Wyler has so far raised 40m from investors, but this seems like a risky investment, especially as billions were lost on similar projects in the past. So why are people investing in the hope of finding customers in the worlds poorest regions? The reason is that previous projects were over-ambitious and set out to provide global coverage, whereas U3bs project is far more modest in its optimism and its services will be available only to a 100km wide corridor around the equator, which happens to cover most developing countries. It will initially use just five satellites circling 8,000km above the equator and further expansion will be determined by customer appetite.", "hypothesis": "The majority of developing countries lie within 100km of the equator.", "gold_label": "entailment"}
{"uid": "id_187", "premise": "U3b Networks (U3b being short for the underprivileged three billion who lack internet access) is a company in Jersey set up by Greg Wyler, former owner of Rwandas national telephone company. His company intends to provide cheap, high-speed internet access to remote areas in developing countries, which up to now has been the reserve of developed countries. Mr Wyler plans to charge $500 per megabit per month, compared with the $4,000 charged by existing companies. Mr Wyler has so far raised 40m from investors, but this seems like a risky investment, especially as billions were lost on similar projects in the past. So why are people investing in the hope of finding customers in the worlds poorest regions? The reason is that previous projects were over-ambitious and set out to provide global coverage, whereas U3bs project is far more modest in its optimism and its services will be available only to a 100km wide corridor around the equator, which happens to cover most developing countries. It will initially use just five satellites circling 8,000km above the equator and further expansion will be determined by customer appetite.", "hypothesis": "Greg Wyler had a background in telecoms.", "gold_label": "entailment"}
{"uid": "id_188", "premise": "U3b Networks (U3b being short for the underprivileged three billion who lack internet access) is a company in Jersey set up by Greg Wyler, former owner of Rwandas national telephone company. His company intends to provide cheap, high-speed internet access to remote areas in developing countries, which up to now has been the reserve of developed countries. Mr Wyler plans to charge $500 per megabit per month, compared with the $4,000 charged by existing companies. Mr Wyler has so far raised 40m from investors, but this seems like a risky investment, especially as billions were lost on similar projects in the past. So why are people investing in the hope of finding customers in the worlds poorest regions? The reason is that previous projects were over-ambitious and set out to provide global coverage, whereas U3bs project is far more modest in its optimism and its services will be available only to a 100km wide corridor around the equator, which happens to cover most developing countries. It will initially use just five satellites circling 8,000km above the equator and further expansion will be determined by customer appetite.", "hypothesis": "The satellites for the project will cost 8m each.", "gold_label": "neutral"}
{"uid": "id_189", "premise": "UK companies need more effective boards of directors After a number of serious failures of governance (that is, how they are managed at the highest level), companies in Britain, as well as elsewhere, should consider radical changes to their directors' roles. It is clear that the role of a board director today is not an easy one. Following the 2008 financial meltdown, which resulted in a deeper and more prolonged period of economic downturn than anyone expected, the search for explanations in the many post-mortems of the crisis has meant blame has been spread far and wide. Governments, regulators, central banks and auditors have all been in the frame. The role of bank directors and management and their widely publicised failures have been extensively picked over and examined in reports, inquiries and commentaries. The knock-on effect of this scrutiny has been to make the governance of companies in general an issue of intense public debate and has significantly increased the pressures on, and the responsibilities of, directors. At the simplest and most practical level, the time involved in fulfilling the demands of a board directorship has increased significantly, calling into question the effectiveness of the classic model of corporate governance by part-time, independent non-executive directors. Where once a board schedule may have consisted of between eight and ten meetings a year, in many companies the number of events requiring board input and decisions has dramatically risen. Furthermore, the amount of reading and preparation required for each meeting is increasing. Agendas can become overloaded and this can mean the time for constructive debate must necessarily be restricted in favour of getting through the business. Often, board business is devolved to committees in order to cope with the workload, which may be more efficient but can mean that the board as a whole is less involved in fully addressing some of the most important issues. It is not uncommon for the audit committee meeting to last longer than the main board meeting itself. Process may take the place of discussion and be at the expense of real collaboration, so that boxes are ticked rather than issues tackled. A radical solution, which may work for some very large companies whose businesses are extensive and complex, is the professional board, whose members would work up to three or four days a week, supported by their own dedicated staff and advisers. There are obvious risks to this and it would be important to establish clear guidelines for such a board to ensure that it did not step on the toes of management by becoming too engaged in the day-to-day running of the company. Problems of recruitment, remuneration and independence could also arise and this structure would not be appropriate for all companies. However, more professional and better-informed boards would have been particularly appropriate for banks where the executives had access to information that part-time non-executive directors lacked, leaving the latter unable to comprehend or anticipate the 2008 crash. One of the main criticisms of boards and their directors is that they do not focus sufficiently on longer-term matters of strategy, sustainability and governance, but instead concentrate too much on short-term financial metrics. Regulatory requirements and the structure of the market encourage this behaviour. The tyranny of quarterly reporting can distort board decision-making, as directors have to 'make the numbers' every four months to meet the insatiable appetite of the market for more data. This serves to encourage the trading methodology of a certain kind of investor who moves in and out of a stock without engaging in constructive dialogue with the company about strategy or performance, and is simply seeking a short-term financial gain. This effect has been made worse by the changing profile of investors due to the globalisation of capital and the increasing use of automated trading systems. Corporate culture adapts and management teams are largely incentivised to meet financial goals. Compensation for chief executives has become a combat zone where pitched battles between investors, management and board members are fought, often behind closed doors but increasingly frequently in the full glare of press attention. Many would argue that this is in the interest of transparency and good governance as shareholders use their muscle in the area of pay to pressure boards to remove underperforming chief executives. Their powers to vote down executive remuneration policies increased when binding votes came into force. The chair of the remuneration committee can be an exposed and lonely role, as Alison Carnwath, chair of Barclays Bank's remuneration committee, found when she had to resign, having been roundly criticised for trying to defend the enormous bonus to be paid to the chief executive; the irony being that she was widely understood to have spoken out against it in the privacy of the committee. The financial crisis stimulated a debate about the role and purpose of the company and a heightened awareness of corporate ethics. Trust in the corporation has been eroded and academics such as Michael Sandel, in his thoughtful and bestselling book What Money Can't Buy, are questioning the morality of capitalism and the market economy. Boards of companies in all sectors will need to widen their perspective to encompass these issues and this may involve a realignment of corporate goals. We live in challenging times.", "hypothesis": "Using a committee structure would ensure that board members are fully informed about significant issues.", "gold_label": "contradiction"}
{"uid": "id_190", "premise": "UK companies need more effective boards of directors After a number of serious failures of governance (that is, how they are managed at the highest level), companies in Britain, as well as elsewhere, should consider radical changes to their directors' roles. It is clear that the role of a board director today is not an easy one. Following the 2008 financial meltdown, which resulted in a deeper and more prolonged period of economic downturn than anyone expected, the search for explanations in the many post-mortems of the crisis has meant blame has been spread far and wide. Governments, regulators, central banks and auditors have all been in the frame. The role of bank directors and management and their widely publicised failures have been extensively picked over and examined in reports, inquiries and commentaries. The knock-on effect of this scrutiny has been to make the governance of companies in general an issue of intense public debate and has significantly increased the pressures on, and the responsibilities of, directors. At the simplest and most practical level, the time involved in fulfilling the demands of a board directorship has increased significantly, calling into question the effectiveness of the classic model of corporate governance by part-time, independent non-executive directors. Where once a board schedule may have consisted of between eight and ten meetings a year, in many companies the number of events requiring board input and decisions has dramatically risen. Furthermore, the amount of reading and preparation required for each meeting is increasing. Agendas can become overloaded and this can mean the time for constructive debate must necessarily be restricted in favour of getting through the business. Often, board business is devolved to committees in order to cope with the workload, which may be more efficient but can mean that the board as a whole is less involved in fully addressing some of the most important issues. It is not uncommon for the audit committee meeting to last longer than the main board meeting itself. Process may take the place of discussion and be at the expense of real collaboration, so that boxes are ticked rather than issues tackled. A radical solution, which may work for some very large companies whose businesses are extensive and complex, is the professional board, whose members would work up to three or four days a week, supported by their own dedicated staff and advisers. There are obvious risks to this and it would be important to establish clear guidelines for such a board to ensure that it did not step on the toes of management by becoming too engaged in the day-to-day running of the company. Problems of recruitment, remuneration and independence could also arise and this structure would not be appropriate for all companies. However, more professional and better-informed boards would have been particularly appropriate for banks where the executives had access to information that part-time non-executive directors lacked, leaving the latter unable to comprehend or anticipate the 2008 crash. One of the main criticisms of boards and their directors is that they do not focus sufficiently on longer-term matters of strategy, sustainability and governance, but instead concentrate too much on short-term financial metrics. Regulatory requirements and the structure of the market encourage this behaviour. The tyranny of quarterly reporting can distort board decision-making, as directors have to 'make the numbers' every four months to meet the insatiable appetite of the market for more data. This serves to encourage the trading methodology of a certain kind of investor who moves in and out of a stock without engaging in constructive dialogue with the company about strategy or performance, and is simply seeking a short-term financial gain. This effect has been made worse by the changing profile of investors due to the globalisation of capital and the increasing use of automated trading systems. Corporate culture adapts and management teams are largely incentivised to meet financial goals. Compensation for chief executives has become a combat zone where pitched battles between investors, management and board members are fought, often behind closed doors but increasingly frequently in the full glare of press attention. Many would argue that this is in the interest of transparency and good governance as shareholders use their muscle in the area of pay to pressure boards to remove underperforming chief executives. Their powers to vote down executive remuneration policies increased when binding votes came into force. The chair of the remuneration committee can be an exposed and lonely role, as Alison Carnwath, chair of Barclays Bank's remuneration committee, found when she had to resign, having been roundly criticised for trying to defend the enormous bonus to be paid to the chief executive; the irony being that she was widely understood to have spoken out against it in the privacy of the committee. The financial crisis stimulated a debate about the role and purpose of the company and a heightened awareness of corporate ethics. Trust in the corporation has been eroded and academics such as Michael Sandel, in his thoughtful and bestselling book What Money Can't Buy, are questioning the morality of capitalism and the market economy. Boards of companies in all sectors will need to widen their perspective to encompass these issues and this may involve a realignment of corporate goals. We live in challenging times.", "hypothesis": "Board meetings normally continue for as long as necessary to debate matters in full.", "gold_label": "contradiction"}
{"uid": "id_191", "premise": "UK companies need more effective boards of directors After a number of serious failures of governance (that is, how they are managed at the highest level), companies in Britain, as well as elsewhere, should consider radical changes to their directors' roles. It is clear that the role of a board director today is not an easy one. Following the 2008 financial meltdown, which resulted in a deeper and more prolonged period of economic downturn than anyone expected, the search for explanations in the many post-mortems of the crisis has meant blame has been spread far and wide. Governments, regulators, central banks and auditors have all been in the frame. The role of bank directors and management and their widely publicised failures have been extensively picked over and examined in reports, inquiries and commentaries. The knock-on effect of this scrutiny has been to make the governance of companies in general an issue of intense public debate and has significantly increased the pressures on, and the responsibilities of, directors. At the simplest and most practical level, the time involved in fulfilling the demands of a board directorship has increased significantly, calling into question the effectiveness of the classic model of corporate governance by part-time, independent non-executive directors. Where once a board schedule may have consisted of between eight and ten meetings a year, in many companies the number of events requiring board input and decisions has dramatically risen. Furthermore, the amount of reading and preparation required for each meeting is increasing. Agendas can become overloaded and this can mean the time for constructive debate must necessarily be restricted in favour of getting through the business. Often, board business is devolved to committees in order to cope with the workload, which may be more efficient but can mean that the board as a whole is less involved in fully addressing some of the most important issues. It is not uncommon for the audit committee meeting to last longer than the main board meeting itself. Process may take the place of discussion and be at the expense of real collaboration, so that boxes are ticked rather than issues tackled. A radical solution, which may work for some very large companies whose businesses are extensive and complex, is the professional board, whose members would work up to three or four days a week, supported by their own dedicated staff and advisers. There are obvious risks to this and it would be important to establish clear guidelines for such a board to ensure that it did not step on the toes of management by becoming too engaged in the day-to-day running of the company. Problems of recruitment, remuneration and independence could also arise and this structure would not be appropriate for all companies. However, more professional and better-informed boards would have been particularly appropriate for banks where the executives had access to information that part-time non-executive directors lacked, leaving the latter unable to comprehend or anticipate the 2008 crash. One of the main criticisms of boards and their directors is that they do not focus sufficiently on longer-term matters of strategy, sustainability and governance, but instead concentrate too much on short-term financial metrics. Regulatory requirements and the structure of the market encourage this behaviour. The tyranny of quarterly reporting can distort board decision-making, as directors have to 'make the numbers' every four months to meet the insatiable appetite of the market for more data. This serves to encourage the trading methodology of a certain kind of investor who moves in and out of a stock without engaging in constructive dialogue with the company about strategy or performance, and is simply seeking a short-term financial gain. This effect has been made worse by the changing profile of investors due to the globalisation of capital and the increasing use of automated trading systems. Corporate culture adapts and management teams are largely incentivised to meet financial goals. Compensation for chief executives has become a combat zone where pitched battles between investors, management and board members are fought, often behind closed doors but increasingly frequently in the full glare of press attention. Many would argue that this is in the interest of transparency and good governance as shareholders use their muscle in the area of pay to pressure boards to remove underperforming chief executives. Their powers to vote down executive remuneration policies increased when binding votes came into force. The chair of the remuneration committee can be an exposed and lonely role, as Alison Carnwath, chair of Barclays Bank's remuneration committee, found when she had to resign, having been roundly criticised for trying to defend the enormous bonus to be paid to the chief executive; the irony being that she was widely understood to have spoken out against it in the privacy of the committee. The financial crisis stimulated a debate about the role and purpose of the company and a heightened awareness of corporate ethics. Trust in the corporation has been eroded and academics such as Michael Sandel, in his thoughtful and bestselling book What Money Can't Buy, are questioning the morality of capitalism and the market economy. Boards of companies in all sectors will need to widen their perspective to encompass these issues and this may involve a realignment of corporate goals. We live in challenging times.", "hypothesis": "Banks have been mismanaged to a greater extent than other businesses.", "gold_label": "neutral"}
{"uid": "id_192", "premise": "UK companies need more effective boards of directors After a number of serious failures of governance (that is, how they are managed at the highest level), companies in Britain, as well as elsewhere, should consider radical changes to their directors' roles. It is clear that the role of a board director today is not an easy one. Following the 2008 financial meltdown, which resulted in a deeper and more prolonged period of economic downturn than anyone expected, the search for explanations in the many post-mortems of the crisis has meant blame has been spread far and wide. Governments, regulators, central banks and auditors have all been in the frame. The role of bank directors and management and their widely publicised failures have been extensively picked over and examined in reports, inquiries and commentaries. The knock-on effect of this scrutiny has been to make the governance of companies in general an issue of intense public debate and has significantly increased the pressures on, and the responsibilities of, directors. At the simplest and most practical level, the time involved in fulfilling the demands of a board directorship has increased significantly, calling into question the effectiveness of the classic model of corporate governance by part-time, independent non-executive directors. Where once a board schedule may have consisted of between eight and ten meetings a year, in many companies the number of events requiring board input and decisions has dramatically risen. Furthermore, the amount of reading and preparation required for each meeting is increasing. Agendas can become overloaded and this can mean the time for constructive debate must necessarily be restricted in favour of getting through the business. Often, board business is devolved to committees in order to cope with the workload, which may be more efficient but can mean that the board as a whole is less involved in fully addressing some of the most important issues. It is not uncommon for the audit committee meeting to last longer than the main board meeting itself. Process may take the place of discussion and be at the expense of real collaboration, so that boxes are ticked rather than issues tackled. A radical solution, which may work for some very large companies whose businesses are extensive and complex, is the professional board, whose members would work up to three or four days a week, supported by their own dedicated staff and advisers. There are obvious risks to this and it would be important to establish clear guidelines for such a board to ensure that it did not step on the toes of management by becoming too engaged in the day-to-day running of the company. Problems of recruitment, remuneration and independence could also arise and this structure would not be appropriate for all companies. However, more professional and better-informed boards would have been particularly appropriate for banks where the executives had access to information that part-time non-executive directors lacked, leaving the latter unable to comprehend or anticipate the 2008 crash. One of the main criticisms of boards and their directors is that they do not focus sufficiently on longer-term matters of strategy, sustainability and governance, but instead concentrate too much on short-term financial metrics. Regulatory requirements and the structure of the market encourage this behaviour. The tyranny of quarterly reporting can distort board decision-making, as directors have to 'make the numbers' every four months to meet the insatiable appetite of the market for more data. This serves to encourage the trading methodology of a certain kind of investor who moves in and out of a stock without engaging in constructive dialogue with the company about strategy or performance, and is simply seeking a short-term financial gain. This effect has been made worse by the changing profile of investors due to the globalisation of capital and the increasing use of automated trading systems. Corporate culture adapts and management teams are largely incentivised to meet financial goals. Compensation for chief executives has become a combat zone where pitched battles between investors, management and board members are fought, often behind closed doors but increasingly frequently in the full glare of press attention. Many would argue that this is in the interest of transparency and good governance as shareholders use their muscle in the area of pay to pressure boards to remove underperforming chief executives. Their powers to vote down executive remuneration policies increased when binding votes came into force. The chair of the remuneration committee can be an exposed and lonely role, as Alison Carnwath, chair of Barclays Bank's remuneration committee, found when she had to resign, having been roundly criticised for trying to defend the enormous bonus to be paid to the chief executive; the irony being that she was widely understood to have spoken out against it in the privacy of the committee. The financial crisis stimulated a debate about the role and purpose of the company and a heightened awareness of corporate ethics. Trust in the corporation has been eroded and academics such as Michael Sandel, in his thoughtful and bestselling book What Money Can't Buy, are questioning the morality of capitalism and the market economy. Boards of companies in all sectors will need to widen their perspective to encompass these issues and this may involve a realignment of corporate goals. We live in challenging times.", "hypothesis": "Close scrutiny of the behaviour of boards has increased since the economic downturn.", "gold_label": "entailment"}
{"uid": "id_193", "premise": "UK rail services how do l claim for my delayed train? Generally, if you have been delayed on a train journey, you may be able to claim compensation, but train companies all have different rules, so it can be confusing to work out what youre entitled to. The type of delay you can claim for depends on whether the train company runs a Delay Repay scheme or a less generous, older-style scheme. Delay Repay is a train operator scheme to compensate passengers when trains are late, and the train company will pay out even if it was not responsible for the delay. The scheme varies between companies, but up to 2016 most paid 50 percent of the single ticket cost for 30 minutes delay and 100 percent for an hour. On the London Underground, you get a full refund for 15-minute delays. Companies that do not use Delay Repay and still use the older scheme will not usually pay compensation if the problem is considered to be out of their control. But it is still worth asking them for compensation, as some may pay out. You are unlikely to get compensation for a delay if any of the following occur: Accidents involving people getting onto the line illegally Gas leaks or fires in buildings next to the line which were not caused by a train company Line closures at the request of the emergency services Exceptionally severe weather conditions Strike action National Rail Conditions of Travel state that you are entitled to compensation in the same form that you paid for the ticket. Some train companies are still paying using rail vouchers, which they are allowed to do if you do not ask for a cash refund. Since 2016, rail passengers have acquired further rights for compensation through the Consumer Rights Act. This means that passengers could now be eligible for compensation due to: a severely overcrowded train with too few carriages available; a consistently late running service; and a service that is delayed for less than the time limit that applied under existing compensation schemes. However, in order to exercise their rights beyond the existing compensation schemes, for instance Delay Repay, and where the train operating company refuses to compensate despite letters threatening court action, passengers may need to bring their claims to a court of law.", "hypothesis": "Under Delay Repay, a train company will only provide compensation if it caused the delay.", "gold_label": "contradiction"}
{"uid": "id_194", "premise": "UK rail services how do l claim for my delayed train? Generally, if you have been delayed on a train journey, you may be able to claim compensation, but train companies all have different rules, so it can be confusing to work out what youre entitled to. The type of delay you can claim for depends on whether the train company runs a Delay Repay scheme or a less generous, older-style scheme. Delay Repay is a train operator scheme to compensate passengers when trains are late, and the train company will pay out even if it was not responsible for the delay. The scheme varies between companies, but up to 2016 most paid 50 percent of the single ticket cost for 30 minutes delay and 100 percent for an hour. On the London Underground, you get a full refund for 15-minute delays. Companies that do not use Delay Repay and still use the older scheme will not usually pay compensation if the problem is considered to be out of their control. But it is still worth asking them for compensation, as some may pay out. You are unlikely to get compensation for a delay if any of the following occur: Accidents involving people getting onto the line illegally Gas leaks or fires in buildings next to the line which were not caused by a train company Line closures at the request of the emergency services Exceptionally severe weather conditions Strike action National Rail Conditions of Travel state that you are entitled to compensation in the same form that you paid for the ticket. Some train companies are still paying using rail vouchers, which they are allowed to do if you do not ask for a cash refund. Since 2016, rail passengers have acquired further rights for compensation through the Consumer Rights Act. This means that passengers could now be eligible for compensation due to: a severely overcrowded train with too few carriages available; a consistently late running service; and a service that is delayed for less than the time limit that applied under existing compensation schemes. However, in order to exercise their rights beyond the existing compensation schemes, for instance Delay Repay, and where the train operating company refuses to compensate despite letters threatening court action, passengers may need to bring their claims to a court of law.", "hypothesis": "The system for claiming compensation varies from one company to another.", "gold_label": "entailment"}
{"uid": "id_195", "premise": "UK rail services how do l claim for my delayed train? Generally, if you have been delayed on a train journey, you may be able to claim compensation, but train companies all have different rules, so it can be confusing to work out what youre entitled to. The type of delay you can claim for depends on whether the train company runs a Delay Repay scheme or a less generous, older-style scheme. Delay Repay is a train operator scheme to compensate passengers when trains are late, and the train company will pay out even if it was not responsible for the delay. The scheme varies between companies, but up to 2016 most paid 50 percent of the single ticket cost for 30 minutes delay and 100 percent for an hour. On the London Underground, you get a full refund for 15-minute delays. Companies that do not use Delay Repay and still use the older scheme will not usually pay compensation if the problem is considered to be out of their control. But it is still worth asking them for compensation, as some may pay out. You are unlikely to get compensation for a delay if any of the following occur: Accidents involving people getting onto the line illegally Gas leaks or fires in buildings next to the line which were not caused by a train company Line closures at the request of the emergency services Exceptionally severe weather conditions Strike action National Rail Conditions of Travel state that you are entitled to compensation in the same form that you paid for the ticket. Some train companies are still paying using rail vouchers, which they are allowed to do if you do not ask for a cash refund. Since 2016, rail passengers have acquired further rights for compensation through the Consumer Rights Act. This means that passengers could now be eligible for compensation due to: a severely overcrowded train with too few carriages available; a consistently late running service; and a service that is delayed for less than the time limit that applied under existing compensation schemes. However, in order to exercise their rights beyond the existing compensation schemes, for instance Delay Repay, and where the train operating company refuses to compensate despite letters threatening court action, passengers may need to bring their claims to a court of law.", "hypothesis": "It is doubtful whether companies using the older scheme will provide compensation if a delay is caused by a strike.", "gold_label": "entailment"}
{"uid": "id_196", "premise": "UK rail services how do l claim for my delayed train? Generally, if you have been delayed on a train journey, you may be able to claim compensation, but train companies all have different rules, so it can be confusing to work out what youre entitled to. The type of delay you can claim for depends on whether the train company runs a Delay Repay scheme or a less generous, older-style scheme. Delay Repay is a train operator scheme to compensate passengers when trains are late, and the train company will pay out even if it was not responsible for the delay. The scheme varies between companies, but up to 2016 most paid 50 percent of the single ticket cost for 30 minutes delay and 100 percent for an hour. On the London Underground, you get a full refund for 15-minute delays. Companies that do not use Delay Repay and still use the older scheme will not usually pay compensation if the problem is considered to be out of their control. But it is still worth asking them for compensation, as some may pay out. You are unlikely to get compensation for a delay if any of the following occur: Accidents involving people getting onto the line illegally Gas leaks or fires in buildings next to the line which were not caused by a train company Line closures at the request of the emergency services Exceptionally severe weather conditions Strike action National Rail Conditions of Travel state that you are entitled to compensation in the same form that you paid for the ticket. Some train companies are still paying using rail vouchers, which they are allowed to do if you do not ask for a cash refund. Since 2016, rail passengers have acquired further rights for compensation through the Consumer Rights Act. This means that passengers could now be eligible for compensation due to: a severely overcrowded train with too few carriages available; a consistently late running service; and a service that is delayed for less than the time limit that applied under existing compensation schemes. However, in order to exercise their rights beyond the existing compensation schemes, for instance Delay Repay, and where the train operating company refuses to compensate despite letters threatening court action, passengers may need to bring their claims to a court of law.", "hypothesis": "An increasing number of train companies are willing to pay compensation for problems they are not responsible for.", "gold_label": "neutral"}
{"uid": "id_197", "premise": "UK rail services how do l claim for my delayed train? Generally, if you have been delayed on a train journey, you may be able to claim compensation, but train companies all have different rules, so it can be confusing to work out what youre entitled to. The type of delay you can claim for depends on whether the train company runs a Delay Repay scheme or a less generous, older-style scheme. Delay Repay is a train operator scheme to compensate passengers when trains are late, and the train company will pay out even if it was not responsible for the delay. The scheme varies between companies, but up to 2016 most paid 50 percent of the single ticket cost for 30 minutes delay and 100 percent for an hour. On the London Underground, you get a full refund for 15-minute delays. Companies that do not use Delay Repay and still use the older scheme will not usually pay compensation if the problem is considered to be out of their control. But it is still worth asking them for compensation, as some may pay out. You are unlikely to get compensation for a delay if any of the following occur: Accidents involving people getting onto the line illegally Gas leaks or fires in buildings next to the line which were not caused by a train company Line closures at the request of the emergency services Exceptionally severe weather conditions Strike action National Rail Conditions of Travel state that you are entitled to compensation in the same form that you paid for the ticket. Some train companies are still paying using rail vouchers, which they are allowed to do if you do not ask for a cash refund. Since 2016, rail passengers have acquired further rights for compensation through the Consumer Rights Act. This means that passengers could now be eligible for compensation due to: a severely overcrowded train with too few carriages available; a consistently late running service; and a service that is delayed for less than the time limit that applied under existing compensation schemes. However, in order to exercise their rights beyond the existing compensation schemes, for instance Delay Repay, and where the train operating company refuses to compensate despite letters threatening court action, passengers may need to bring their claims to a court of law.", "hypothesis": "Under Delay Repay, underground and other train companies give exactly the same amounts of money in compensation.", "gold_label": "contradiction"}
{"uid": "id_198", "premise": "UK rail services how do l claim for my delayed train? Generally, if you have been delayed on a train journey, you may be able to claim compensation, but train companies all have different rules, so it can be confusing to work out what youre entitled to. The type of delay you can claim for depends on whether the train company runs a Delay Repay scheme or a less generous, older-style scheme. Delay Repay is a train operator scheme to compensate passengers when trains are late, and the train company will pay out even if it was not responsible for the delay. The scheme varies between companies, but up to 2016 most paid 50 percent of the single ticket cost for 30 minutes delay and 100 percent for an hour. On the London Underground, you get a full refund for 15-minute delays. Companies that do not use Delay Repay and still use the older scheme will not usually pay compensation if the problem is considered to be out of their control. But it is still worth asking them for compensation, as some may pay out. You are unlikely to get compensation for a delay if any of the following occur: Accidents involving people getting onto the line illegally Gas leaks or fires in buildings next to the line which were not caused by a train company Line closures at the request of the emergency services Exceptionally severe weather conditions Strike action National Rail Conditions of Travel state that you are entitled to compensation in the same form that you paid for the ticket. Some train companies are still paying using rail vouchers, which they are allowed to do if you do not ask for a cash refund. Since 2016, rail passengers have acquired further rights for compensation through the Consumer Rights Act. This means that passengers could now be eligible for compensation due to: a severely overcrowded train with too few carriages available; a consistently late running service; and a service that is delayed for less than the time limit that applied under existing compensation schemes. However, in order to exercise their rights beyond the existing compensation schemes, for instance Delay Repay, and where the train operating company refuses to compensate despite letters threatening court action, passengers may need to bring their claims to a court of law.", "hypothesis": "Passengers may receive compensation in the form of a train voucher if they forget to request cash.", "gold_label": "entailment"}
{"uid": "id_199", "premise": "UK unemployment has reached a new high after the public sector made a new wave of cuts this week. Statistics suggest that those particularly hit by the cuts will be youths, as a record high of over 1 million youths were recorded as unemployed at the beginning of this month. This figure is just under half of the total national statistic for unemployment, a reported 2.5 million. Yet, the number of people claiming unemployment benefits has not risen as far as it was expected to. Economists predicted that the number of people claiming support would rise by an estimated 15,000, yet the actual figure demonstrates a rise of less than 4,000. Perhaps things are not as bad as they seem after all.", "hypothesis": "Unemployment is about to fall, improving the economic outlook.", "gold_label": "neutral"}
{"uid": "id_200", "premise": "UK unemployment has reached a new high after the public sector made a new wave of cuts this week. Statistics suggest that those particularly hit by the cuts will be youths, as a record high of over 1 million youths were recorded as unemployed at the beginning of this month. This figure is just under half of the total national statistic for unemployment, a reported 2.5 million. Yet, the number of people claiming unemployment benefits has not risen as far as it was expected to. Economists predicted that the number of people claiming support would rise by an estimated 15,000, yet the actual figure demonstrates a rise of less than 4,000. Perhaps things are not as bad as they seem after all.", "hypothesis": "The government is likely to make new public sector cuts.", "gold_label": "neutral"}
{"uid": "id_201", "premise": "UK unemployment has reached a new high after the public sector made a new wave of cuts this week. Statistics suggest that those particularly hit by the cuts will be youths, as a record high of over 1 million youths were recorded as unemployed at the beginning of this month. This figure is just under half of the total national statistic for unemployment, a reported 2.5 million. Yet, the number of people claiming unemployment benefits has not risen as far as it was expected to. Economists predicted that the number of people claiming support would rise by an estimated 15,000, yet the actual figure demonstrates a rise of less than 4,000. Perhaps things are not as bad as they seem after all.", "hypothesis": "Economists over-estimated the number rise in benefits claims", "gold_label": "entailment"}
{"uid": "id_202", "premise": "UK unemployment has reached a new high after the public sector made a new wave of cuts this week. Statistics suggest that those particularly hit by the cuts will be youths, as a record high of over 1 million youths were recorded as unemployed at the beginning of this month. This figure is just under half of the total national statistic for unemployment, a reported 2.5 million. Yet, the number of people claiming unemployment benefits has not risen as far as it was expected to. Economists predicted that the number of people claiming support would rise by an estimated 15,000, yet the actual figure demonstrates a rise of less than 4,000. Perhaps things are not as bad as they seem after all.", "hypothesis": "Economists are mistaken and unemployment is lower.", "gold_label": "contradiction"}
{"uid": "id_203", "premise": "UNMASKING SKIN If you took off your skin and laid it flat, it would cover an area of about twenty-one square feet, making it by far the bodys largest organ. Draped in place over our bodies, skin forms the barrier between whats inside us and whats outside. It protects us from a multitude of external forces. It serves as an avenue to our most intimate physical and psychological selves. This impervious yet permeable barrier, less than a millimetre thick in places, is composed of three layers. The outermost layer is the bloodless epidermis. The dermis includes collagen, elastin, and nerve endings. The innermost layer, subcutaneous fat, contains tissue that acts as an energy source, cushion and insulator for the body. From these familiar characteristics of skin emerge the profound mysteries of touch, arguably our most essential source of sensory stimulation. We can live without seeing or hearing in fact, without any of our other senses. But babies born without effective nerve connections between skin and brain can fail to thrive and may even die. Laboratory experiments decades ago, now considered unethical and inhumane, kept baby monkeys from being touched by their mothers. It made no difference that the babies could see, hear and smell their mothers; without touching, the babies became apathetic, and failed to progress. For humans, insufficient touching in early years can have lifelong results. In touching cultures, adult aggression is low, whereas, in cultures where touch is limited, adult aggression is high, writes Tiffany Field, director of the Touch Research Institutes at the University of Miami School of Medicine. Studies of a variety of cultures show a correspondence between high rates of physical affection in childhood and low rates of adult physical violence. While the effects of touching are easy to understand, the mechanics of it are less so. Your skin has millions of nerve cells of various shapes at different depths, explains Stanley Bolanowski, a neuroscientist and associate director of the Institute for Sensory Research at Syracuse University. When the nerve cells are stimulated, physical energy is transformed into energy used by the nervous system and passed from the skin to the spinal cord and brain. Its called transduction, and no one knows exactly how it takes place. Suffice it to say that the process involves the intricate, split-second operation of a complex system of signals between neurons in the skin and brain. This is starting to sound very confusing until Bolanowski says: In simple terms, people perceive three basic things via skin: pressure, temperature, and pain. And then Im sure hes wrong. When I get wet, my skin feels wet, I protest. Close your eyes and lean back, says Bolanowski. Something cold and wet is on my forehead so wet, in fact, that I wait for water to start dripping down my cheeks. Open your eyes. Bolanowski says, showing me that the sensation comes from a chilled, but dry, metal cylinder. The combination of pressure and cold, he explains, is what makes my skin perceive wetness. He gives me a surgical glove to put on and has me put a finger in a glass of cold water. My finger feels wet, even though I have visual proof that its not touching water. My skin, which seemed so reliable, has been deceiving me my entire life. When I shower or wash my hands, I now realize, my skin feels pressure and temperature. Its my brain that says I feel wet. Perceptions of pressure, temperature and pain manifest themselves in many different ways. Gentle stimulation of pressure receptors can result in ticklishness; gentle stimulation of pain receptors, in itching. Both sensations arise from a neurological transmission, not from something that physically exists. Skin, Im realizing, is under constant assault, both from within the body and from forces outside. Repairs occur with varying success. Take the spot where I nicked myself with a knife while slicing fruit. I have a crusty scab surrounded by pink tissue about a quarter inch long on my right palm. Under the scab, epidermal cells are migrating into the wound to close it up. When the process is complete, the scab will fall off to reveal new epidermis. Its only been a few days, but my little self-repair is almost complete. Likewise, we recover quickly from slight burns. If you ever happen to touch a hot burner, just put your finger in cold water. The chances are you will have no blister, little pain and no scar. Severe burns, though, are a different matter.", "hypothesis": "The skin is more sensitive to pressure than to temperature or pain.", "gold_label": "neutral"}
{"uid": "id_204", "premise": "UNMASKING SKIN If you took off your skin and laid it flat, it would cover an area of about twenty-one square feet, making it by far the bodys largest organ. Draped in place over our bodies, skin forms the barrier between whats inside us and whats outside. It protects us from a multitude of external forces. It serves as an avenue to our most intimate physical and psychological selves. This impervious yet permeable barrier, less than a millimetre thick in places, is composed of three layers. The outermost layer is the bloodless epidermis. The dermis includes collagen, elastin, and nerve endings. The innermost layer, subcutaneous fat, contains tissue that acts as an energy source, cushion and insulator for the body. From these familiar characteristics of skin emerge the profound mysteries of touch, arguably our most essential source of sensory stimulation. We can live without seeing or hearing in fact, without any of our other senses. But babies born without effective nerve connections between skin and brain can fail to thrive and may even die. Laboratory experiments decades ago, now considered unethical and inhumane, kept baby monkeys from being touched by their mothers. It made no difference that the babies could see, hear and smell their mothers; without touching, the babies became apathetic, and failed to progress. For humans, insufficient touching in early years can have lifelong results. In touching cultures, adult aggression is low, whereas, in cultures where touch is limited, adult aggression is high, writes Tiffany Field, director of the Touch Research Institutes at the University of Miami School of Medicine. Studies of a variety of cultures show a correspondence between high rates of physical affection in childhood and low rates of adult physical violence. While the effects of touching are easy to understand, the mechanics of it are less so. Your skin has millions of nerve cells of various shapes at different depths, explains Stanley Bolanowski, a neuroscientist and associate director of the Institute for Sensory Research at Syracuse University. When the nerve cells are stimulated, physical energy is transformed into energy used by the nervous system and passed from the skin to the spinal cord and brain. Its called transduction, and no one knows exactly how it takes place. Suffice it to say that the process involves the intricate, split-second operation of a complex system of signals between neurons in the skin and brain. This is starting to sound very confusing until Bolanowski says: In simple terms, people perceive three basic things via skin: pressure, temperature, and pain. And then Im sure hes wrong. When I get wet, my skin feels wet, I protest. Close your eyes and lean back, says Bolanowski. Something cold and wet is on my forehead so wet, in fact, that I wait for water to start dripping down my cheeks. Open your eyes. Bolanowski says, showing me that the sensation comes from a chilled, but dry, metal cylinder. The combination of pressure and cold, he explains, is what makes my skin perceive wetness. He gives me a surgical glove to put on and has me put a finger in a glass of cold water. My finger feels wet, even though I have visual proof that its not touching water. My skin, which seemed so reliable, has been deceiving me my entire life. When I shower or wash my hands, I now realize, my skin feels pressure and temperature. Its my brain that says I feel wet. Perceptions of pressure, temperature and pain manifest themselves in many different ways. Gentle stimulation of pressure receptors can result in ticklishness; gentle stimulation of pain receptors, in itching. Both sensations arise from a neurological transmission, not from something that physically exists. Skin, Im realizing, is under constant assault, both from within the body and from forces outside. Repairs occur with varying success. Take the spot where I nicked myself with a knife while slicing fruit. I have a crusty scab surrounded by pink tissue about a quarter inch long on my right palm. Under the scab, epidermal cells are migrating into the wound to close it up. When the process is complete, the scab will fall off to reveal new epidermis. Its only been a few days, but my little self-repair is almost complete. Likewise, we recover quickly from slight burns. If you ever happen to touch a hot burner, just put your finger in cold water. The chances are you will have no blister, little pain and no scar. Severe burns, though, are a different matter.", "hypothesis": "The human skin is always good at repairing itself.", "gold_label": "contradiction"}
{"uid": "id_205", "premise": "UNMASKING SKIN If you took off your skin and laid it flat, it would cover an area of about twenty-one square feet, making it by far the bodys largest organ. Draped in place over our bodies, skin forms the barrier between whats inside us and whats outside. It protects us from a multitude of external forces. It serves as an avenue to our most intimate physical and psychological selves. This impervious yet permeable barrier, less than a millimetre thick in places, is composed of three layers. The outermost layer is the bloodless epidermis. The dermis includes collagen, elastin, and nerve endings. The innermost layer, subcutaneous fat, contains tissue that acts as an energy source, cushion and insulator for the body. From these familiar characteristics of skin emerge the profound mysteries of touch, arguably our most essential source of sensory stimulation. We can live without seeing or hearing in fact, without any of our other senses. But babies born without effective nerve connections between skin and brain can fail to thrive and may even die. Laboratory experiments decades ago, now considered unethical and inhumane, kept baby monkeys from being touched by their mothers. It made no difference that the babies could see, hear and smell their mothers; without touching, the babies became apathetic, and failed to progress. For humans, insufficient touching in early years can have lifelong results. In touching cultures, adult aggression is low, whereas, in cultures where touch is limited, adult aggression is high, writes Tiffany Field, director of the Touch Research Institutes at the University of Miami School of Medicine. Studies of a variety of cultures show a correspondence between high rates of physical affection in childhood and low rates of adult physical violence. While the effects of touching are easy to understand, the mechanics of it are less so. Your skin has millions of nerve cells of various shapes at different depths, explains Stanley Bolanowski, a neuroscientist and associate director of the Institute for Sensory Research at Syracuse University. When the nerve cells are stimulated, physical energy is transformed into energy used by the nervous system and passed from the skin to the spinal cord and brain. Its called transduction, and no one knows exactly how it takes place. Suffice it to say that the process involves the intricate, split-second operation of a complex system of signals between neurons in the skin and brain. This is starting to sound very confusing until Bolanowski says: In simple terms, people perceive three basic things via skin: pressure, temperature, and pain. And then Im sure hes wrong. When I get wet, my skin feels wet, I protest. Close your eyes and lean back, says Bolanowski. Something cold and wet is on my forehead so wet, in fact, that I wait for water to start dripping down my cheeks. Open your eyes. Bolanowski says, showing me that the sensation comes from a chilled, but dry, metal cylinder. The combination of pressure and cold, he explains, is what makes my skin perceive wetness. He gives me a surgical glove to put on and has me put a finger in a glass of cold water. My finger feels wet, even though I have visual proof that its not touching water. My skin, which seemed so reliable, has been deceiving me my entire life. When I shower or wash my hands, I now realize, my skin feels pressure and temperature. Its my brain that says I feel wet. Perceptions of pressure, temperature and pain manifest themselves in many different ways. Gentle stimulation of pressure receptors can result in ticklishness; gentle stimulation of pain receptors, in itching. Both sensations arise from a neurological transmission, not from something that physically exists. Skin, Im realizing, is under constant assault, both from within the body and from forces outside. Repairs occur with varying success. Take the spot where I nicked myself with a knife while slicing fruit. I have a crusty scab surrounded by pink tissue about a quarter inch long on my right palm. Under the scab, epidermal cells are migrating into the wound to close it up. When the process is complete, the scab will fall off to reveal new epidermis. Its only been a few days, but my little self-repair is almost complete. Likewise, we recover quickly from slight burns. If you ever happen to touch a hot burner, just put your finger in cold water. The chances are you will have no blister, little pain and no scar. Severe burns, though, are a different matter.", "hypothesis": "Even scientists have difficulty understanding how our sense of touch works.", "gold_label": "entailment"}
{"uid": "id_206", "premise": "USE OF UNIVERSITY GROUNDS BY VEHICULAR TRAFFIC The University grounds are private. The University authorities only allow authorised members of the University, visitors and drivers of vehicles servicing the University to enter the grounds. Members of staff who have paid the requisite fee and display the appropriate permit may bring a vehicle into the grounds. A University permit does not entitle them to park in Hall car parks however, unless authorised by the Warden of the Hall concerned. Students may not bring vehicles into the grounds during the working day unless they have been given special permission by the Security Officer and have paid for and are displaying an appropriate entry permit. Students living in Halls of Residence must obtain permission from the Warden to keep a motor vehicle at their residence. Students are reminded that if they park a motor vehicle on University premises without a valid permit, they will be fined 20", "hypothesis": "The campus roads are not open to general members of the public.", "gold_label": "entailment"}
{"uid": "id_207", "premise": "USE OF UNIVERSITY GROUNDS BY VEHICULAR TRAFFIC The University grounds are private. The University authorities only allow authorised members of the University, visitors and drivers of vehicles servicing the University to enter the grounds. Members of staff who have paid the requisite fee and display the appropriate permit may bring a vehicle into the grounds. A University permit does not entitle them to park in Hall car parks however, unless authorised by the Warden of the Hall concerned. Students may not bring vehicles into the grounds during the working day unless they have been given special permission by the Security Officer and have paid for and are displaying an appropriate entry permit. Students living in Halls of Residence must obtain permission from the Warden to keep a motor vehicle at their residence. Students are reminded that if they park a motor vehicle on University premises without a valid permit, they will be fined 20", "hypothesis": "Students living in Hall do not need permission to park in Hall car parks.", "gold_label": "contradiction"}
{"uid": "id_208", "premise": "USE OF UNIVERSITY GROUNDS BY VEHICULAR TRAFFIC The University grounds are private. The University authorities only allow authorised members of the University, visitors and drivers of vehicles servicing the University to enter the grounds. Members of staff who have paid the requisite fee and display the appropriate permit may bring a vehicle into the grounds. A University permit does not entitle them to park in Hall car parks however, unless authorised by the Warden of the Hall concerned. Students may not bring vehicles into the grounds during the working day unless they have been given special permission by the Security Officer and have paid for and are displaying an appropriate entry permit. Students living in Halls of Residence must obtain permission from the Warden to keep a motor vehicle at their residence. Students are reminded that if they park a motor vehicle on University premises without a valid permit, they will be fined 20", "hypothesis": "Parking permits cost 20 a year.", "gold_label": "neutral"}
{"uid": "id_209", "premise": "USE OF UNIVERSITY GROUNDS BY VEHICULAR TRAFFIC The University grounds are private. The University authorities only allow authorised members of the University, visitors and drivers of vehicles servicing the University to enter the grounds. Members of staff who have paid the requisite fee and display the appropriate permit may bring a vehicle into the grounds. A University permit does not entitle them to park in Hall car parks however, unless authorised by the Warden of the Hall concerned. Students may not bring vehicles into the grounds during the working day unless they have been given special permission by the Security Officer and have paid for and are displaying an appropriate entry permit. Students living in Halls of Residence must obtain permission from the Warden to keep a motor vehicle at their residence. Students are reminded that if they park a motor vehicle on University premises without a valid permit, they will be fined 20", "hypothesis": "Having a University permit does not allow staff to park at Halls.", "gold_label": "entailment"}
{"uid": "id_210", "premise": "USE OF UNIVERSITY GROUNDS BY VEHICULAR TRAFFIC The University grounds are private. The University authorities only allow authorised members of the University, visitors and drivers of vehicles servicing the University to enter the grounds. Members of staff who have paid the requisite fee and display the appropriate permit may bring a vehicle into the grounds. A University permit does not entitle them to park in Hall car parks however, unless authorised by the Warden of the Hall concerned. Students may not bring vehicles into the grounds during the working day unless they have been given special permission by the Security Officer and have paid for and are displaying an appropriate entry permit. Students living in Halls of Residence must obtain permission from the Warden to keep a motor vehicle at their residence. Students are reminded that if they park a motor vehicle on University premises without a valid permit, they will be fined 20", "hypothesis": "Parking in Halls of Residence is handled by the Wardens of the Halls.", "gold_label": "entailment"}
{"uid": "id_211", "premise": "USE OF UNIVERSITY GROUNDS BY VEHICULAR TRAFFIC The University grounds are private. The University authorities only allow authorised members of the University, visitors and drivers of vehicles servicing the University to enter the grounds. Members of staff who have paid the requisite fee and display the appropriate permit may bring a vehicle into the grounds. A University permit does not entitle them to park in Hall car parks however, unless authorised by the Warden of the Hall concerned. Students may not bring vehicles into the grounds during the working day unless they have been given special permission by the Security Officer and have paid for and are displaying an appropriate entry permit. Students living in Halls of Residence must obtain permission from the Warden to keep a motor vehicle at their residence. Students are reminded that if they park a motor vehicle on University premises without a valid permit, they will be fined 20", "hypothesis": "University employees do not need to pay for their parking permits.", "gold_label": "contradiction"}
{"uid": "id_212", "premise": "USE THE RIGHT TYPE OF FIRE EXTINGUISHER! Fire extinguishers come in different types depending on the material combusted. The five main types of fire extinguisher are described below. Pressurized water Used for Class A fires only. Carbon-dioxide Used for Class E fires because it does not damage electrical equipment such as computers. Limited use for Class B fires because there is a risk of re-ignition due to a lack of cooling. Foam-filled Used for Class B fires. Also used for Class A fires, though not in confined spaces. They are NOT for electrical equipment fires or cooking oil. Dry powder Used for Class A, B, C and E fires, with specialist powders for Class D fires. Smothers the fire but does not cool it or penetrate very well so there is a risk of re-ignition. Wet chemical Used for Class F fires, especially high temperature deep fat fryers. There are six classifications of combustible material as shown below. Class A: flammable organic solids (eg wood, paper, coal, plastics, textiles) Class B: flammable liquids (eg gasoline, spirits) but not cooking oil Class C: flammable gas (eg propane, butane) Class D: combustible metals (eg magnesium, lithium) Class E: electrical equipment (eg computers, photocopiers) Class F: cooking oil and fat The above classifications apply to Europe and Australia.", "hypothesis": "Only one type of fire extinguisher is suitable for a lithium battery fire.", "gold_label": "neutral"}
{"uid": "id_213", "premise": "USE THE RIGHT TYPE OF FIRE EXTINGUISHER! Fire extinguishers come in different types depending on the material combusted. The five main types of fire extinguisher are described below. Pressurized water Used for Class A fires only. Carbon-dioxide Used for Class E fires because it does not damage electrical equipment such as computers. Limited use for Class B fires because there is a risk of re-ignition due to a lack of cooling. Foam-filled Used for Class B fires. Also used for Class A fires, though not in confined spaces. They are NOT for electrical equipment fires or cooking oil. Dry powder Used for Class A, B, C and E fires, with specialist powders for Class D fires. Smothers the fire but does not cool it or penetrate very well so there is a risk of re-ignition. Wet chemical Used for Class F fires, especially high temperature deep fat fryers. There are six classifications of combustible material as shown below. Class A: flammable organic solids (eg wood, paper, coal, plastics, textiles) Class B: flammable liquids (eg gasoline, spirits) but not cooking oil Class C: flammable gas (eg propane, butane) Class D: combustible metals (eg magnesium, lithium) Class E: electrical equipment (eg computers, photocopiers) Class F: cooking oil and fat The above classifications apply to Europe and Australia.", "hypothesis": "Foam-filled extinguishers should NOT be used outdoors.", "gold_label": "contradiction"}
{"uid": "id_214", "premise": "USE THE RIGHT TYPE OF FIRE EXTINGUISHER! Fire extinguishers come in different types depending on the material combusted. The five main types of fire extinguisher are described below. Pressurized water Used for Class A fires only. Carbon-dioxide Used for Class E fires because it does not damage electrical equipment such as computers. Limited use for Class B fires because there is a risk of re-ignition due to a lack of cooling. Foam-filled Used for Class B fires. Also used for Class A fires, though not in confined spaces. They are NOT for electrical equipment fires or cooking oil. Dry powder Used for Class A, B, C and E fires, with specialist powders for Class D fires. Smothers the fire but does not cool it or penetrate very well so there is a risk of re-ignition. Wet chemical Used for Class F fires, especially high temperature deep fat fryers. There are six classifications of combustible material as shown below. Class A: flammable organic solids (eg wood, paper, coal, plastics, textiles) Class B: flammable liquids (eg gasoline, spirits) but not cooking oil Class C: flammable gas (eg propane, butane) Class D: combustible metals (eg magnesium, lithium) Class E: electrical equipment (eg computers, photocopiers) Class F: cooking oil and fat The above classifications apply to Europe and Australia.", "hypothesis": "Cooking oil fires should only be tackled with Class F fire extinguishers.", "gold_label": "entailment"}
{"uid": "id_215", "premise": "USE THE RIGHT TYPE OF FIRE EXTINGUISHER! Fire extinguishers come in different types depending on the material combusted. The five main types of fire extinguisher are described below. Pressurized water Used for Class A fires only. Carbon-dioxide Used for Class E fires because it does not damage electrical equipment such as computers. Limited use for Class B fires because there is a risk of re-ignition due to a lack of cooling. Foam-filled Used for Class B fires. Also used for Class A fires, though not in confined spaces. They are NOT for electrical equipment fires or cooking oil. Dry powder Used for Class A, B, C and E fires, with specialist powders for Class D fires. Smothers the fire but does not cool it or penetrate very well so there is a risk of re-ignition. Wet chemical Used for Class F fires, especially high temperature deep fat fryers. There are six classifications of combustible material as shown below. Class A: flammable organic solids (eg wood, paper, coal, plastics, textiles) Class B: flammable liquids (eg gasoline, spirits) but not cooking oil Class C: flammable gas (eg propane, butane) Class D: combustible metals (eg magnesium, lithium) Class E: electrical equipment (eg computers, photocopiers) Class F: cooking oil and fat The above classifications apply to Europe and Australia.", "hypothesis": "Foam-filled extinguishers can be used on fires involving plastics.", "gold_label": "entailment"}
{"uid": "id_216", "premise": "USE THE RIGHT TYPE OF FIRE EXTINGUISHER! Fire extinguishers come in different types depending on the material combusted. The five main types of fire extinguisher are described below. Pressurized water Used for Class A fires only. Carbon-dioxide Used for Class E fires because it does not damage electrical equipment such as computers. Limited use for Class B fires because there is a risk of re-ignition due to a lack of cooling. Foam-filled Used for Class B fires. Also used for Class A fires, though not in confined spaces. They are NOT for electrical equipment fires or cooking oil. Dry powder Used for Class A, B, C and E fires, with specialist powders for Class D fires. Smothers the fire but does not cool it or penetrate very well so there is a risk of re-ignition. Wet chemical Used for Class F fires, especially high temperature deep fat fryers. There are six classifications of combustible material as shown below. Class A: flammable organic solids (eg wood, paper, coal, plastics, textiles) Class B: flammable liquids (eg gasoline, spirits) but not cooking oil Class C: flammable gas (eg propane, butane) Class D: combustible metals (eg magnesium, lithium) Class E: electrical equipment (eg computers, photocopiers) Class F: cooking oil and fat The above classifications apply to Europe and Australia.", "hypothesis": "A gasoline fire extinguished with carbon-dioxide might ignite again.", "gold_label": "entailment"}
{"uid": "id_217", "premise": "USE THE RIGHT TYPE OF FIRE EXTINGUISHER! Fire extinguishers come in different types depending on the material combusted. The five main types of fire extinguisher are described below. Pressurized water Used for Class A fires only. Carbon-dioxide Used for Class E fires because it does not damage electrical equipment such as computers. Limited use for Class B fires because there is a risk of re-ignition due to a lack of cooling. Foam-filled Used for Class B fires. Also used for Class A fires, though not in confined spaces. They are NOT for electrical equipment fires or cooking oil. Dry powder Used for Class A, B, C and E fires, with specialist powders for Class D fires. Smothers the fire but does not cool it or penetrate very well so there is a risk of re-ignition. Wet chemical Used for Class F fires, especially high temperature deep fat fryers. There are six classifications of combustible material as shown below. Class A: flammable organic solids (eg wood, paper, coal, plastics, textiles) Class B: flammable liquids (eg gasoline, spirits) but not cooking oil Class C: flammable gas (eg propane, butane) Class D: combustible metals (eg magnesium, lithium) Class E: electrical equipment (eg computers, photocopiers) Class F: cooking oil and fat The above classifications apply to Europe and Australia.", "hypothesis": "Flammable liquids are more likely to reignite than flammable solids.", "gold_label": "neutral"}
{"uid": "id_218", "premise": "USE THE RIGHT TYPE OF FIRE EXTINGUISHER! Fire extinguishers come in different types depending on the material combusted. The five main types of fire extinguisher are described below. Pressurized water Used for Class A fires only. Carbon-dioxide Used for Class E fires because it does not damage electrical equipment such as computers. Limited use for Class B fires because there is a risk of re-ignition due to a lack of cooling. Foam-filled Used for Class B fires. Also used for Class A fires, though not in confined spaces. They are NOT for electrical equipment fires or cooking oil. Dry powder Used for Class A, B, C and E fires, with specialist powders for Class D fires. Smothers the fire but does not cool it or penetrate very well so there is a risk of re-ignition. Wet chemical Used for Class F fires, especially high temperature deep fat fryers. There are six classifications of combustible material as shown below. Class A: flammable organic solids (eg wood, paper, coal, plastics, textiles) Class B: flammable liquids (eg gasoline, spirits) but not cooking oil Class C: flammable gas (eg propane, butane) Class D: combustible metals (eg magnesium, lithium) Class E: electrical equipment (eg computers, photocopiers) Class F: cooking oil and fat The above classifications apply to Europe and Australia.", "hypothesis": "Class A fires can be tackled with three types of extinguisher.", "gold_label": "entailment"}
{"uid": "id_219", "premise": "USE THE RIGHT TYPE OF FIRE EXTINGUISHER! Fire extinguishers come in different types depending on the material combusted. The five main types of fire extinguisher are described below. Pressurized water Used for Class A fires only. Carbon-dioxide Used for Class E fires because it does not damage electrical equipment such as computers. Limited use for Class B fires because there is a risk of re-ignition due to a lack of cooling. Foam-filled Used for Class B fires. Also used for Class A fires, though not in confined spaces. They are NOT for electrical equipment fires or cooking oil. Dry powder Used for Class A, B, C and E fires, with specialist powders for Class D fires. Smothers the fire but does not cool it or penetrate very well so there is a risk of re-ignition. Wet chemical Used for Class F fires, especially high temperature deep fat fryers. There are six classifications of combustible material as shown below. Class A: flammable organic solids (eg wood, paper, coal, plastics, textiles) Class B: flammable liquids (eg gasoline, spirits) but not cooking oil Class C: flammable gas (eg propane, butane) Class D: combustible metals (eg magnesium, lithium) Class E: electrical equipment (eg computers, photocopiers) Class F: cooking oil and fat The above classifications apply to Europe and Australia.", "hypothesis": "Only one type of fire extinguisher is suitable for a lithium battery fire.", "gold_label": "entailment"}
{"uid": "id_220", "premise": "Under 5% of employers test their staff for the use of recreational drugs and the vast majority do not consider substance abuse to be a significant issue in their workplace. Evidence of a link between drug abuse and accidents or low productivity is hard to find. More studies found a link between alcoholism and a detrimental impact on safety and performance than a link with drugs, either so-called soft drugs such as cannabis or class 1 drugs such as cocaine. Employers face problems if they decide that they should test staff for drugs. In addition to ethical considerations, employees have a right to privacy under the Human Rights Act; however, the employer also has a duty to provide a safe workplace and has a duty of care to take every reasonable step to ensure safety at work under the Health and Safety at Work Act. In some industries, for example the transport and nuclear power industries, employers do routinely test their staff for drug use.", "hypothesis": "Society cannot afford the risk of an accident caused by an employee on drugs in the transport or nuclear industry and that is why testing takes place in those industries.", "gold_label": "neutral"}
{"uid": "id_221", "premise": "Under 5% of employers test their staff for the use of recreational drugs and the vast majority do not consider substance abuse to be a significant issue in their workplace. Evidence of a link between drug abuse and accidents or low productivity is hard to find. More studies found a link between alcoholism and a detrimental impact on safety and performance than a link with drugs, either so-called soft drugs such as cannabis or class 1 drugs such as cocaine. Employers face problems if they decide that they should test staff for drugs. In addition to ethical considerations, employees have a right to privacy under the Human Rights Act; however, the employer also has a duty to provide a safe workplace and has a duty of care to take every reasonable step to ensure safety at work under the Health and Safety at Work Act. In some industries, for example the transport and nuclear power industries, employers do routinely test their staff for drug use.", "hypothesis": "There is evidence that the use of recreational drugs is irrelevant to most employers.", "gold_label": "entailment"}
{"uid": "id_222", "premise": "Under 5% of employers test their staff for the use of recreational drugs and the vast majority do not consider substance abuse to be a significant issue in their workplace. Evidence of a link between drug abuse and accidents or low productivity is hard to find. More studies found a link between alcoholism and a detrimental impact on safety and performance than a link with drugs, either so-called soft drugs such as cannabis or class 1 drugs such as cocaine. Employers face problems if they decide that they should test staff for drugs. In addition to ethical considerations, employees have a right to privacy under the Human Rights Act; however, the employer also has a duty to provide a safe workplace and has a duty of care to take every reasonable step to ensure safety at work under the Health and Safety at Work Act. In some industries, for example the transport and nuclear power industries, employers do routinely test their staff for drug use.", "hypothesis": "There is no conflict between the right to privacy and the right to a safe place of work.", "gold_label": "contradiction"}
{"uid": "id_223", "premise": "Under law, negligence is usually defined in the context of jury instructions wherein a judge instructs the jury that a party is to be considered negligent if they failed to exercise the standard of care that a reasonable person would have exercised under the same circumstances. In most jurisdictions, it is necessary to show first that a person had a duty to exercise care in a given situation, and that they breached that duty. In brief: Negligence, a tort, is a civil wrong consisting of five criteria: Duty or reasonable standard of care (as decided by judge as a matter of law), Breach (or negligence in laymens terms, decided as a matter of fact), Injury (the fact that the plaintiff suffered an injury, and is determined at a matter of fact), Cause in Fact or conduct of defendant that causes plaintiffs injury(s)(decided as a matter of fact), Legal Cause (now perceived as the foreseeability of the type of injury caused but not the specific injury or extent of injury, determined as a matter of fact). Matters of law are decided by a judge, matters of fact are decided by a jury. In order to prove negligence, it is not necessary to prove harm, but in order for a cause of action to rest in tort, harm must be proven. Hence, it would be meaningless to sue someone for negligence if no harm resulted. Conversely, it is not enough that a harm was done. In order for the harm to be compensable in a negligence lawsuit, the defendant must be shown to have been negligent, and it must be demonstrated that his negligence was the proximate cause of the harm sustained by the plaintiff.", "hypothesis": "In some cases negligence can be proven but harm cannot be proven.", "gold_label": "entailment"}
{"uid": "id_224", "premise": "Under law, negligence is usually defined in the context of jury instructions wherein a judge instructs the jury that a party is to be considered negligent if they failed to exercise the standard of care that a reasonable person would have exercised under the same circumstances. In most jurisdictions, it is necessary to show first that a person had a duty to exercise care in a given situation, and that they breached that duty. In brief: Negligence, a tort, is a civil wrong consisting of five criteria: Duty or reasonable standard of care (as decided by judge as a matter of law), Breach (or negligence in laymens terms, decided as a matter of fact), Injury (the fact that the plaintiff suffered an injury, and is determined at a matter of fact), Cause in Fact or conduct of defendant that causes plaintiffs injury(s)(decided as a matter of fact), Legal Cause (now perceived as the foreseeability of the type of injury caused but not the specific injury or extent of injury, determined as a matter of fact). Matters of law are decided by a judge, matters of fact are decided by a jury. In order to prove negligence, it is not necessary to prove harm, but in order for a cause of action to rest in tort, harm must be proven. Hence, it would be meaningless to sue someone for negligence if no harm resulted. Conversely, it is not enough that a harm was done. In order for the harm to be compensable in a negligence lawsuit, the defendant must be shown to have been negligent, and it must be demonstrated that his negligence was the proximate cause of the harm sustained by the plaintiff.", "hypothesis": "The defendant must be shown to have been negligent before compensation can be awarded.", "gold_label": "neutral"}
{"uid": "id_225", "premise": "Under law, negligence is usually defined in the context of jury instructions wherein a judge instructs the jury that a party is to be considered negligent if they failed to exercise the standard of care that a reasonable person would have exercised under the same circumstances. In most jurisdictions, it is necessary to show first that a person had a duty to exercise care in a given situation, and that they breached that duty. In brief: Negligence, a tort, is a civil wrong consisting of five criteria: Duty or reasonable standard of care (as decided by judge as a matter of law), Breach (or negligence in laymens terms, decided as a matter of fact), Injury (the fact that the plaintiff suffered an injury, and is determined at a matter of fact), Cause in Fact or conduct of defendant that causes plaintiffs injury(s)(decided as a matter of fact), Legal Cause (now perceived as the foreseeability of the type of injury caused but not the specific injury or extent of injury, determined as a matter of fact). Matters of law are decided by a judge, matters of fact are decided by a jury. In order to prove negligence, it is not necessary to prove harm, but in order for a cause of action to rest in tort, harm must be proven. Hence, it would be meaningless to sue someone for negligence if no harm resulted. Conversely, it is not enough that a harm was done. In order for the harm to be compensable in a negligence lawsuit, the defendant must be shown to have been negligent, and it must be demonstrated that his negligence was the proximate cause of the harm sustained by the plaintiff.", "hypothesis": "Proximate cause is an important concept in cases of negligence.", "gold_label": "entailment"}
{"uid": "id_226", "premise": "Under law, negligence is usually defined in the context of jury instructions wherein a judge instructs the jury that a party is to be considered negligent if they failed to exercise the standard of care that a reasonable person would have exercised under the same circumstances. In most jurisdictions, it is necessary to show first that a person had a duty to exercise care in a given situation, and that they breached that duty. In brief: Negligence, a tort, is a civil wrong consisting of five criteria: Duty or reasonable standard of care (as decided by judge as a matter of law), Breach (or negligence in laymens terms, decided as a matter of fact), Injury (the fact that the plaintiff suffered an injury, and is determined at a matter of fact), Cause in Fact or conduct of defendant that causes plaintiffs injury(s)(decided as a matter of fact), Legal Cause (now perceived as the foreseeability of the type of injury caused but not the specific injury or extent of injury, determined as a matter of fact). Matters of law are decided by a judge, matters of fact are decided by a jury. In order to prove negligence, it is not necessary to prove harm, but in order for a cause of action to rest in tort, harm must be proven. Hence, it would be meaningless to sue someone for negligence if no harm resulted. Conversely, it is not enough that a harm was done. In order for the harm to be compensable in a negligence lawsuit, the defendant must be shown to have been negligent, and it must be demonstrated that his negligence was the proximate cause of the harm sustained by the plaintiff.", "hypothesis": "Matters of fact and matters of law are decided by a judge and jury respectively.", "gold_label": "contradiction"}
{"uid": "id_227", "premise": "Under law, negligence is usually defined in the context of jury instructions wherein a judge instructs the jury that a party is to be considered negligent if they failed to exercise the standard of care that a reasonable person would have exercised under the same circumstances. In most jurisdictions, it is necessary to show first that a person had a duty to exercise care in a given situation, and that they breached that duty. In brief: Negligence, a tort, is a civil wrong consisting of five criteria: Duty or reasonable standard of care (as decided by judge as a matter of law), Breach (or negligence in laymens terms, decided as a matter of fact), Injury (the fact that the plaintiff suffered an injury, and is determined at a matter of fact), Cause in Fact or conduct of defendant that causes plaintiffs injury(s)(decided as a matter of fact), Legal Cause (now perceived as the foreseeability of the type of injury caused but not the specific injury or extent of injury, determined as a matter of fact). Matters of law are decided by a judge, matters of fact are decided by a jury. In order to prove negligence, it is not necessary to prove harm, but in order for a cause of action to rest in tort, harm must be proven. Hence, it would be meaningless to sue someone for negligence if no harm resulted. Conversely, it is not enough that a harm was done. In order for the harm to be compensable in a negligence lawsuit, the defendant must be shown to have been negligent, and it must be demonstrated that his negligence was the proximate cause of the harm sustained by the plaintiff.", "hypothesis": "Legal cause is one of the criteria which is determined by a judge.", "gold_label": "contradiction"}
{"uid": "id_228", "premise": "Under section 36 of the Trade Descriptions Act 1968, goods are deemed to have been manufactured or produced in the country in which they last underwent a treatment or process resulting in a substantial change. Meat from animals coming into the UK and then cured here can be described as UK produce. Most well- known brands of ham or bacon are often advertised with packaging depicting a British countryside scene and described as farmhouse, which would lead shoppers to believe they are buying products made from British meat, but most are in fact made using imported meat.", "hypothesis": "The passage leads the reader to agree that the practice of importing foods and then processing them so that they are substantially changed should be stopped.", "gold_label": "contradiction"}
{"uid": "id_229", "premise": "Under section 36 of the Trade Descriptions Act 1968, goods are deemed to have been manufactured or produced in the country in which they last underwent a treatment or process resulting in a substantial change. Meat from animals coming into the UK and then cured here can be described as UK produce. Most well- known brands of ham or bacon are often advertised with packaging depicting a British countryside scene and described as farmhouse, which would lead shoppers to believe they are buying products made from British meat, but most are in fact made using imported meat.", "hypothesis": "Under section 36 of the Act, British lamb exported to France and slaughtered there is sold as French.", "gold_label": "neutral"}
{"uid": "id_230", "premise": "Under section 36 of the Trade Descriptions Act 1968, goods are deemed to have been manufactured or produced in the country in which they last underwent a treatment or process resulting in a substantial change. Meat from animals coming into the UK and then cured here can be described as UK produce. Most well- known brands of ham or bacon are often advertised with packaging depicting a British countryside scene and described as farmhouse, which would lead shoppers to believe they are buying products made from British meat, but most are in fact made using imported meat.", "hypothesis": "The author of the passage believes that the practice risks some consumers being duped.", "gold_label": "entailment"}
{"uid": "id_231", "premise": "Understanding Your Gas Bill How can I get a duplicate bill or information on my latest bill The easiest way to view or print a copy of your most recent or past bill is to register or log on to My Account. You can receive, view and pay your bill -- all online. When you log on to My Account, go to View My Bill, then Bill History. There you can view and print out your account history -- up to 25 months. Just click on the bill you'd like to see. Try it now. Or, if you'd prefer, you can call our automated service line 24 hours a day, at 1-800-772-5050*. Note, requests made through our phone line will take approximately 3-5 working days to complete. Billing information can only be sent to the mailing address on record. CCF: Hundred of Cubic Feet: Method used for gas measurement. The quantity of gas at a temperature of sixty degrees Fahrenheit and a pressure of 14.73 pounds per square inch makes up one cubic foot. Billing Terms BTU: British Thermal Unit: One BTU is the amount of heat required to raise the temperature of one pound of water one degree Fahrenheit. A more practical definition would be: how much gas an appliance will use to produce heat or cooling. As a result, gas appliances are sized by a BTU rating. 100,000 BTU's equal 1 therm. For example, a 400,000 BTU heater, when in use, would use 4 therms of gas per hour. A 30,000 BTU range would use .3 therms per hour of use. Billing Factor: An adjuster used to convert CCF into therms. It adjusts the amount of gas used to reflect the heat value of the gas at a given altitude. The heating value can vary from month to month; therefore, the billing factor is not always the same. Therm: A therm is approximately 100,000 BTUs. It is a standard unit of measurement. CCFs are converted to therms for purposes of billing. Natural Gas Conversions 1 cubic foot = 1050 Btu Therm = 100,000 Btu Ccf = 100 cubic foot, or 1 therm Mcf = 1000 cubic feet = 10.20 therms MMcf = 1 million cubic feet Bcf = 1 billion cubic feet Decatherm (Dth) = 10 therms = 1 million Btu Mmbtu = 1 million btu = 10 therms About gas rates and how bills are calculated Natural gas rates are made up of two primary charges: Gas delivery service, which The Gas Company provides - the \"delivery\" (or \"transmission\") charge; and, The cost of the natural gas itself -- which is reflected in the \"procurement\" charge. Many people believe that The Gas Company produces natural gas, but we don't. For our residential and smaller business customers, we buy natural gas from producers and marketers at the best possible prices on the open market. The wholesale gas prices we pay are based on market supply and demand. They're not marked up by The Gas Company, and are shown on your monthly bill as the \"commodity charge. \" The Gas Company's delivery service charge covers the costs of transporting natural gas through our pipeline system. It is approved annually by the Public Utilities Commission and is not impacted by the price of natural gas. Monthly Gas rates vary based on monthly gas prices Since 1997, the cost of natural gas that customers pay in their rates is based on a forecasted monthly price instead of a forecasted annual price. This allows rates to more closely follow current natural gas market prices. With monthly pricing, gas rates are based upon a 30-day forecast of natural gas market prices. This gives customers a better picture of the current price of natural gas, and means they no longer have to wait for annual adjustments to their bills to make up for differences between the 12-month forecast price and the actual price paid by The Gas Company on a monthly basis. Does The Gas Company benefit from higher gas prices? We do not produce natural gas; energy production companies produce natural gas. The Gas Company just delivers natural gas to its customers. Baseline therm allowance As determined by the Public Utilities Commission, under the direction of the State Legislature, \"baseline therm allowances\" are the amounts of natural gas needed to meet the minimum basic needs of the average home. The Gas Company is required to bill these \"baseline\" amounts at its lowest residential rates. The goal of these \"baseline\" amounts is to encourage efficient use of natural gas. Charges on Your Bill from a Third Party For bill questions and charges on your gas bill from third-party vendors -- Commerce Energy (formerly ACN) 1-877-226-3649 HomeServe 1-888-302-0137", "hypothesis": "Phone requests for a copy of your bill are processed within a working week.", "gold_label": "entailment"}
{"uid": "id_232", "premise": "Understanding Your Gas Bill How can I get a duplicate bill or information on my latest bill The easiest way to view or print a copy of your most recent or past bill is to register or log on to My Account. You can receive, view and pay your bill -- all online. When you log on to My Account, go to View My Bill, then Bill History. There you can view and print out your account history -- up to 25 months. Just click on the bill you'd like to see. Try it now. Or, if you'd prefer, you can call our automated service line 24 hours a day, at 1-800-772-5050*. Note, requests made through our phone line will take approximately 3-5 working days to complete. Billing information can only be sent to the mailing address on record. CCF: Hundred of Cubic Feet: Method used for gas measurement. The quantity of gas at a temperature of sixty degrees Fahrenheit and a pressure of 14.73 pounds per square inch makes up one cubic foot. Billing Terms BTU: British Thermal Unit: One BTU is the amount of heat required to raise the temperature of one pound of water one degree Fahrenheit. A more practical definition would be: how much gas an appliance will use to produce heat or cooling. As a result, gas appliances are sized by a BTU rating. 100,000 BTU's equal 1 therm. For example, a 400,000 BTU heater, when in use, would use 4 therms of gas per hour. A 30,000 BTU range would use .3 therms per hour of use. Billing Factor: An adjuster used to convert CCF into therms. It adjusts the amount of gas used to reflect the heat value of the gas at a given altitude. The heating value can vary from month to month; therefore, the billing factor is not always the same. Therm: A therm is approximately 100,000 BTUs. It is a standard unit of measurement. CCFs are converted to therms for purposes of billing. Natural Gas Conversions 1 cubic foot = 1050 Btu Therm = 100,000 Btu Ccf = 100 cubic foot, or 1 therm Mcf = 1000 cubic feet = 10.20 therms MMcf = 1 million cubic feet Bcf = 1 billion cubic feet Decatherm (Dth) = 10 therms = 1 million Btu Mmbtu = 1 million btu = 10 therms About gas rates and how bills are calculated Natural gas rates are made up of two primary charges: Gas delivery service, which The Gas Company provides - the \"delivery\" (or \"transmission\") charge; and, The cost of the natural gas itself -- which is reflected in the \"procurement\" charge. Many people believe that The Gas Company produces natural gas, but we don't. For our residential and smaller business customers, we buy natural gas from producers and marketers at the best possible prices on the open market. The wholesale gas prices we pay are based on market supply and demand. They're not marked up by The Gas Company, and are shown on your monthly bill as the \"commodity charge. \" The Gas Company's delivery service charge covers the costs of transporting natural gas through our pipeline system. It is approved annually by the Public Utilities Commission and is not impacted by the price of natural gas. Monthly Gas rates vary based on monthly gas prices Since 1997, the cost of natural gas that customers pay in their rates is based on a forecasted monthly price instead of a forecasted annual price. This allows rates to more closely follow current natural gas market prices. With monthly pricing, gas rates are based upon a 30-day forecast of natural gas market prices. This gives customers a better picture of the current price of natural gas, and means they no longer have to wait for annual adjustments to their bills to make up for differences between the 12-month forecast price and the actual price paid by The Gas Company on a monthly basis. Does The Gas Company benefit from higher gas prices? We do not produce natural gas; energy production companies produce natural gas. The Gas Company just delivers natural gas to its customers. Baseline therm allowance As determined by the Public Utilities Commission, under the direction of the State Legislature, \"baseline therm allowances\" are the amounts of natural gas needed to meet the minimum basic needs of the average home. The Gas Company is required to bill these \"baseline\" amounts at its lowest residential rates. The goal of these \"baseline\" amounts is to encourage efficient use of natural gas. Charges on Your Bill from a Third Party For bill questions and charges on your gas bill from third-party vendors -- Commerce Energy (formerly ACN) 1-877-226-3649 HomeServe 1-888-302-0137", "hypothesis": "CCFs are calculated at a temperature of 60 degrees C.", "gold_label": "contradiction"}
{"uid": "id_233", "premise": "Understanding Your Gas Bill How can I get a duplicate bill or information on my latest bill The easiest way to view or print a copy of your most recent or past bill is to register or log on to My Account. You can receive, view and pay your bill -- all online. When you log on to My Account, go to View My Bill, then Bill History. There you can view and print out your account history -- up to 25 months. Just click on the bill you'd like to see. Try it now. Or, if you'd prefer, you can call our automated service line 24 hours a day, at 1-800-772-5050*. Note, requests made through our phone line will take approximately 3-5 working days to complete. Billing information can only be sent to the mailing address on record. CCF: Hundred of Cubic Feet: Method used for gas measurement. The quantity of gas at a temperature of sixty degrees Fahrenheit and a pressure of 14.73 pounds per square inch makes up one cubic foot. Billing Terms BTU: British Thermal Unit: One BTU is the amount of heat required to raise the temperature of one pound of water one degree Fahrenheit. A more practical definition would be: how much gas an appliance will use to produce heat or cooling. As a result, gas appliances are sized by a BTU rating. 100,000 BTU's equal 1 therm. For example, a 400,000 BTU heater, when in use, would use 4 therms of gas per hour. A 30,000 BTU range would use .3 therms per hour of use. Billing Factor: An adjuster used to convert CCF into therms. It adjusts the amount of gas used to reflect the heat value of the gas at a given altitude. The heating value can vary from month to month; therefore, the billing factor is not always the same. Therm: A therm is approximately 100,000 BTUs. It is a standard unit of measurement. CCFs are converted to therms for purposes of billing. Natural Gas Conversions 1 cubic foot = 1050 Btu Therm = 100,000 Btu Ccf = 100 cubic foot, or 1 therm Mcf = 1000 cubic feet = 10.20 therms MMcf = 1 million cubic feet Bcf = 1 billion cubic feet Decatherm (Dth) = 10 therms = 1 million Btu Mmbtu = 1 million btu = 10 therms About gas rates and how bills are calculated Natural gas rates are made up of two primary charges: Gas delivery service, which The Gas Company provides - the \"delivery\" (or \"transmission\") charge; and, The cost of the natural gas itself -- which is reflected in the \"procurement\" charge. Many people believe that The Gas Company produces natural gas, but we don't. For our residential and smaller business customers, we buy natural gas from producers and marketers at the best possible prices on the open market. The wholesale gas prices we pay are based on market supply and demand. They're not marked up by The Gas Company, and are shown on your monthly bill as the \"commodity charge. \" The Gas Company's delivery service charge covers the costs of transporting natural gas through our pipeline system. It is approved annually by the Public Utilities Commission and is not impacted by the price of natural gas. Monthly Gas rates vary based on monthly gas prices Since 1997, the cost of natural gas that customers pay in their rates is based on a forecasted monthly price instead of a forecasted annual price. This allows rates to more closely follow current natural gas market prices. With monthly pricing, gas rates are based upon a 30-day forecast of natural gas market prices. This gives customers a better picture of the current price of natural gas, and means they no longer have to wait for annual adjustments to their bills to make up for differences between the 12-month forecast price and the actual price paid by The Gas Company on a monthly basis. Does The Gas Company benefit from higher gas prices? We do not produce natural gas; energy production companies produce natural gas. The Gas Company just delivers natural gas to its customers. Baseline therm allowance As determined by the Public Utilities Commission, under the direction of the State Legislature, \"baseline therm allowances\" are the amounts of natural gas needed to meet the minimum basic needs of the average home. The Gas Company is required to bill these \"baseline\" amounts at its lowest residential rates. The goal of these \"baseline\" amounts is to encourage efficient use of natural gas. Charges on Your Bill from a Third Party For bill questions and charges on your gas bill from third-party vendors -- Commerce Energy (formerly ACN) 1-877-226-3649 HomeServe 1-888-302-0137", "hypothesis": "The Gas Company receives a discount on the market price of the day.", "gold_label": "contradiction"}
{"uid": "id_234", "premise": "Understanding Your Gas Bill How can I get a duplicate bill or information on my latest bill The easiest way to view or print a copy of your most recent or past bill is to register or log on to My Account. You can receive, view and pay your bill -- all online. When you log on to My Account, go to View My Bill, then Bill History. There you can view and print out your account history -- up to 25 months. Just click on the bill you'd like to see. Try it now. Or, if you'd prefer, you can call our automated service line 24 hours a day, at 1-800-772-5050*. Note, requests made through our phone line will take approximately 3-5 working days to complete. Billing information can only be sent to the mailing address on record. CCF: Hundred of Cubic Feet: Method used for gas measurement. The quantity of gas at a temperature of sixty degrees Fahrenheit and a pressure of 14.73 pounds per square inch makes up one cubic foot. Billing Terms BTU: British Thermal Unit: One BTU is the amount of heat required to raise the temperature of one pound of water one degree Fahrenheit. A more practical definition would be: how much gas an appliance will use to produce heat or cooling. As a result, gas appliances are sized by a BTU rating. 100,000 BTU's equal 1 therm. For example, a 400,000 BTU heater, when in use, would use 4 therms of gas per hour. A 30,000 BTU range would use .3 therms per hour of use. Billing Factor: An adjuster used to convert CCF into therms. It adjusts the amount of gas used to reflect the heat value of the gas at a given altitude. The heating value can vary from month to month; therefore, the billing factor is not always the same. Therm: A therm is approximately 100,000 BTUs. It is a standard unit of measurement. CCFs are converted to therms for purposes of billing. Natural Gas Conversions 1 cubic foot = 1050 Btu Therm = 100,000 Btu Ccf = 100 cubic foot, or 1 therm Mcf = 1000 cubic feet = 10.20 therms MMcf = 1 million cubic feet Bcf = 1 billion cubic feet Decatherm (Dth) = 10 therms = 1 million Btu Mmbtu = 1 million btu = 10 therms About gas rates and how bills are calculated Natural gas rates are made up of two primary charges: Gas delivery service, which The Gas Company provides - the \"delivery\" (or \"transmission\") charge; and, The cost of the natural gas itself -- which is reflected in the \"procurement\" charge. Many people believe that The Gas Company produces natural gas, but we don't. For our residential and smaller business customers, we buy natural gas from producers and marketers at the best possible prices on the open market. The wholesale gas prices we pay are based on market supply and demand. They're not marked up by The Gas Company, and are shown on your monthly bill as the \"commodity charge. \" The Gas Company's delivery service charge covers the costs of transporting natural gas through our pipeline system. It is approved annually by the Public Utilities Commission and is not impacted by the price of natural gas. Monthly Gas rates vary based on monthly gas prices Since 1997, the cost of natural gas that customers pay in their rates is based on a forecasted monthly price instead of a forecasted annual price. This allows rates to more closely follow current natural gas market prices. With monthly pricing, gas rates are based upon a 30-day forecast of natural gas market prices. This gives customers a better picture of the current price of natural gas, and means they no longer have to wait for annual adjustments to their bills to make up for differences between the 12-month forecast price and the actual price paid by The Gas Company on a monthly basis. Does The Gas Company benefit from higher gas prices? We do not produce natural gas; energy production companies produce natural gas. The Gas Company just delivers natural gas to its customers. Baseline therm allowance As determined by the Public Utilities Commission, under the direction of the State Legislature, \"baseline therm allowances\" are the amounts of natural gas needed to meet the minimum basic needs of the average home. The Gas Company is required to bill these \"baseline\" amounts at its lowest residential rates. The goal of these \"baseline\" amounts is to encourage efficient use of natural gas. Charges on Your Bill from a Third Party For bill questions and charges on your gas bill from third-party vendors -- Commerce Energy (formerly ACN) 1-877-226-3649 HomeServe 1-888-302-0137", "hypothesis": "Therms are converted to CCFs to calculate your bill.", "gold_label": "contradiction"}
{"uid": "id_235", "premise": "Understanding Your Gas Bill How can I get a duplicate bill or information on my latest bill The easiest way to view or print a copy of your most recent or past bill is to register or log on to My Account. You can receive, view and pay your bill -- all online. When you log on to My Account, go to View My Bill, then Bill History. There you can view and print out your account history -- up to 25 months. Just click on the bill you'd like to see. Try it now. Or, if you'd prefer, you can call our automated service line 24 hours a day, at 1-800-772-5050*. Note, requests made through our phone line will take approximately 3-5 working days to complete. Billing information can only be sent to the mailing address on record. CCF: Hundred of Cubic Feet: Method used for gas measurement. The quantity of gas at a temperature of sixty degrees Fahrenheit and a pressure of 14.73 pounds per square inch makes up one cubic foot. Billing Terms BTU: British Thermal Unit: One BTU is the amount of heat required to raise the temperature of one pound of water one degree Fahrenheit. A more practical definition would be: how much gas an appliance will use to produce heat or cooling. As a result, gas appliances are sized by a BTU rating. 100,000 BTU's equal 1 therm. For example, a 400,000 BTU heater, when in use, would use 4 therms of gas per hour. A 30,000 BTU range would use .3 therms per hour of use. Billing Factor: An adjuster used to convert CCF into therms. It adjusts the amount of gas used to reflect the heat value of the gas at a given altitude. The heating value can vary from month to month; therefore, the billing factor is not always the same. Therm: A therm is approximately 100,000 BTUs. It is a standard unit of measurement. CCFs are converted to therms for purposes of billing. Natural Gas Conversions 1 cubic foot = 1050 Btu Therm = 100,000 Btu Ccf = 100 cubic foot, or 1 therm Mcf = 1000 cubic feet = 10.20 therms MMcf = 1 million cubic feet Bcf = 1 billion cubic feet Decatherm (Dth) = 10 therms = 1 million Btu Mmbtu = 1 million btu = 10 therms About gas rates and how bills are calculated Natural gas rates are made up of two primary charges: Gas delivery service, which The Gas Company provides - the \"delivery\" (or \"transmission\") charge; and, The cost of the natural gas itself -- which is reflected in the \"procurement\" charge. Many people believe that The Gas Company produces natural gas, but we don't. For our residential and smaller business customers, we buy natural gas from producers and marketers at the best possible prices on the open market. The wholesale gas prices we pay are based on market supply and demand. They're not marked up by The Gas Company, and are shown on your monthly bill as the \"commodity charge. \" The Gas Company's delivery service charge covers the costs of transporting natural gas through our pipeline system. It is approved annually by the Public Utilities Commission and is not impacted by the price of natural gas. Monthly Gas rates vary based on monthly gas prices Since 1997, the cost of natural gas that customers pay in their rates is based on a forecasted monthly price instead of a forecasted annual price. This allows rates to more closely follow current natural gas market prices. With monthly pricing, gas rates are based upon a 30-day forecast of natural gas market prices. This gives customers a better picture of the current price of natural gas, and means they no longer have to wait for annual adjustments to their bills to make up for differences between the 12-month forecast price and the actual price paid by The Gas Company on a monthly basis. Does The Gas Company benefit from higher gas prices? We do not produce natural gas; energy production companies produce natural gas. The Gas Company just delivers natural gas to its customers. Baseline therm allowance As determined by the Public Utilities Commission, under the direction of the State Legislature, \"baseline therm allowances\" are the amounts of natural gas needed to meet the minimum basic needs of the average home. The Gas Company is required to bill these \"baseline\" amounts at its lowest residential rates. The goal of these \"baseline\" amounts is to encourage efficient use of natural gas. Charges on Your Bill from a Third Party For bill questions and charges on your gas bill from third-party vendors -- Commerce Energy (formerly ACN) 1-877-226-3649 HomeServe 1-888-302-0137", "hypothesis": "Since 1997, customers have not had to wait for annual adjustments.", "gold_label": "entailment"}
{"uid": "id_236", "premise": "University Union The job of the University Union is to represent the interests of the studentsboth to the University and to the outside worldand provide students with cultural, sporting and welfare facilitie. When you arrive at the University, you will be given a Student Guide, explaining in detail what the Union has to offer. All full-time registered students are automatically members of the University Union, which is affiliated to the National Union of Students (although under Section 22(2)(c) of the Education Act 1994, a student has the right not to be a member of the Union if he or she so wishes). The Union is run by students (Sabbatical Officers) elected in cross-campus ballots, who work full-time, taking a year of from their university courses. International students are represented by an Overseas Students Officer, a part-time Union post. The Graduate Association All postgraduate students at the University of St James are automatically members of the Graduate Association. It plays an important role in representing the interests of all postgraduate students, and also acts as a social club. The Graduate Association elects annually international officers, representing the interests of students from Europe and from outside Europe. Societies and Groups National and Cultural Societies There are some 18 societies affiliated to the Union with memberships of nationals from those countries and other international and UK students interested in finding out more about their culture and language. The current list of National and Cultural societies as of January 2000 can be obtained at the Union office. The presidents of all these societies can be contacted through their pigeonholes in the Union. If there is no society for your nationality, why not start one? Wives International Group This group was formed to foster contact amongst the wives of overseas students, Coffee mornings are held every Wednesday morning in the Senior Common Room, Clifton Hill House, where children can play with the many toys provided, and their mothers can enjoy a cup of tea or coffee and chat. Language tuition can also be arranged by qualified teachers at a reduced rate for wives who do not have much knowledge of the English language.", "hypothesis": "The representative of the international students studies as well as works.", "gold_label": "neutral"}
{"uid": "id_237", "premise": "University Union The job of the University Union is to represent the interests of the studentsboth to the University and to the outside worldand provide students with cultural, sporting and welfare facilitie. When you arrive at the University, you will be given a Student Guide, explaining in detail what the Union has to offer. All full-time registered students are automatically members of the University Union, which is affiliated to the National Union of Students (although under Section 22(2)(c) of the Education Act 1994, a student has the right not to be a member of the Union if he or she so wishes). The Union is run by students (Sabbatical Officers) elected in cross-campus ballots, who work full-time, taking a year of from their university courses. International students are represented by an Overseas Students Officer, a part-time Union post. The Graduate Association All postgraduate students at the University of St James are automatically members of the Graduate Association. It plays an important role in representing the interests of all postgraduate students, and also acts as a social club. The Graduate Association elects annually international officers, representing the interests of students from Europe and from outside Europe. Societies and Groups National and Cultural Societies There are some 18 societies affiliated to the Union with memberships of nationals from those countries and other international and UK students interested in finding out more about their culture and language. The current list of National and Cultural societies as of January 2000 can be obtained at the Union office. The presidents of all these societies can be contacted through their pigeonholes in the Union. If there is no society for your nationality, why not start one? Wives International Group This group was formed to foster contact amongst the wives of overseas students, Coffee mornings are held every Wednesday morning in the Senior Common Room, Clifton Hill House, where children can play with the many toys provided, and their mothers can enjoy a cup of tea or coffee and chat. Language tuition can also be arranged by qualified teachers at a reduced rate for wives who do not have much knowledge of the English language.", "hypothesis": "National and Cultural clubs may be started by student", "gold_label": "entailment"}
{"uid": "id_238", "premise": "University Union The job of the University Union is to represent the interests of the studentsboth to the University and to the outside worldand provide students with cultural, sporting and welfare facilitie. When you arrive at the University, you will be given a Student Guide, explaining in detail what the Union has to offer. All full-time registered students are automatically members of the University Union, which is affiliated to the National Union of Students (although under Section 22(2)(c) of the Education Act 1994, a student has the right not to be a member of the Union if he or she so wishes). The Union is run by students (Sabbatical Officers) elected in cross-campus ballots, who work full-time, taking a year of from their university courses. International students are represented by an Overseas Students Officer, a part-time Union post. The Graduate Association All postgraduate students at the University of St James are automatically members of the Graduate Association. It plays an important role in representing the interests of all postgraduate students, and also acts as a social club. The Graduate Association elects annually international officers, representing the interests of students from Europe and from outside Europe. Societies and Groups National and Cultural Societies There are some 18 societies affiliated to the Union with memberships of nationals from those countries and other international and UK students interested in finding out more about their culture and language. The current list of National and Cultural societies as of January 2000 can be obtained at the Union office. The presidents of all these societies can be contacted through their pigeonholes in the Union. If there is no society for your nationality, why not start one? Wives International Group This group was formed to foster contact amongst the wives of overseas students, Coffee mornings are held every Wednesday morning in the Senior Common Room, Clifton Hill House, where children can play with the many toys provided, and their mothers can enjoy a cup of tea or coffee and chat. Language tuition can also be arranged by qualified teachers at a reduced rate for wives who do not have much knowledge of the English language.", "hypothesis": "Full-time students should register to be members of the University Union.", "gold_label": "contradiction"}
{"uid": "id_239", "premise": "University Union The job of the University Union is to represent the interests of the studentsboth to the University and to the outside worldand provide students with cultural, sporting and welfare facilitie. When you arrive at the University, you will be given a Student Guide, explaining in detail what the Union has to offer. All full-time registered students are automatically members of the University Union, which is affiliated to the National Union of Students (although under Section 22(2)(c) of the Education Act 1994, a student has the right not to be a member of the Union if he or she so wishes). The Union is run by students (Sabbatical Officers) elected in cross-campus ballots, who work full-time, taking a year of from their university courses. International students are represented by an Overseas Students Officer, a part-time Union post. The Graduate Association All postgraduate students at the University of St James are automatically members of the Graduate Association. It plays an important role in representing the interests of all postgraduate students, and also acts as a social club. The Graduate Association elects annually international officers, representing the interests of students from Europe and from outside Europe. Societies and Groups National and Cultural Societies There are some 18 societies affiliated to the Union with memberships of nationals from those countries and other international and UK students interested in finding out more about their culture and language. The current list of National and Cultural societies as of January 2000 can be obtained at the Union office. The presidents of all these societies can be contacted through their pigeonholes in the Union. If there is no society for your nationality, why not start one? Wives International Group This group was formed to foster contact amongst the wives of overseas students, Coffee mornings are held every Wednesday morning in the Senior Common Room, Clifton Hill House, where children can play with the many toys provided, and their mothers can enjoy a cup of tea or coffee and chat. Language tuition can also be arranged by qualified teachers at a reduced rate for wives who do not have much knowledge of the English language.", "hypothesis": "As with the University Union, all students are automatic members of the Graduate Society.", "gold_label": "contradiction"}
{"uid": "id_240", "premise": "University Union The job of the University Union is to represent the interests of the studentsboth to the University and to the outside worldand provide students with cultural, sporting and welfare facilitie. When you arrive at the University, you will be given a Student Guide, explaining in detail what the Union has to offer. All full-time registered students are automatically members of the University Union, which is affiliated to the National Union of Students (although under Section 22(2)(c) of the Education Act 1994, a student has the right not to be a member of the Union if he or she so wishes). The Union is run by students (Sabbatical Officers) elected in cross-campus ballots, who work full-time, taking a year of from their university courses. International students are represented by an Overseas Students Officer, a part-time Union post. The Graduate Association All postgraduate students at the University of St James are automatically members of the Graduate Association. It plays an important role in representing the interests of all postgraduate students, and also acts as a social club. The Graduate Association elects annually international officers, representing the interests of students from Europe and from outside Europe. Societies and Groups National and Cultural Societies There are some 18 societies affiliated to the Union with memberships of nationals from those countries and other international and UK students interested in finding out more about their culture and language. The current list of National and Cultural societies as of January 2000 can be obtained at the Union office. The presidents of all these societies can be contacted through their pigeonholes in the Union. If there is no society for your nationality, why not start one? Wives International Group This group was formed to foster contact amongst the wives of overseas students, Coffee mornings are held every Wednesday morning in the Senior Common Room, Clifton Hill House, where children can play with the many toys provided, and their mothers can enjoy a cup of tea or coffee and chat. Language tuition can also be arranged by qualified teachers at a reduced rate for wives who do not have much knowledge of the English language.", "hypothesis": "The people who run the University Union do not study at the same time as they work.", "gold_label": "entailment"}
{"uid": "id_241", "premise": "University Union The job of the University Union is to represent the interests of the studentsboth to the University and to the outside worldand provide students with cultural, sporting and welfare facilitie. When you arrive at the University, you will be given a Student Guide, explaining in detail what the Union has to offer. All full-time registered students are automatically members of the University Union, which is affiliated to the National Union of Students (although under Section 22(2)(c) of the Education Act 1994, a student has the right not to be a member of the Union if he or she so wishes). The Union is run by students (Sabbatical Officers) elected in cross-campus ballots, who work full-time, taking a year of from their university courses. International students are represented by an Overseas Students Officer, a part-time Union post. The Graduate Association All postgraduate students at the University of St James are automatically members of the Graduate Association. It plays an important role in representing the interests of all postgraduate students, and also acts as a social club. The Graduate Association elects annually international officers, representing the interests of students from Europe and from outside Europe. Societies and Groups National and Cultural Societies There are some 18 societies affiliated to the Union with memberships of nationals from those countries and other international and UK students interested in finding out more about their culture and language. The current list of National and Cultural societies as of January 2000 can be obtained at the Union office. The presidents of all these societies can be contacted through their pigeonholes in the Union. If there is no society for your nationality, why not start one? Wives International Group This group was formed to foster contact amongst the wives of overseas students, Coffee mornings are held every Wednesday morning in the Senior Common Room, Clifton Hill House, where children can play with the many toys provided, and their mothers can enjoy a cup of tea or coffee and chat. Language tuition can also be arranged by qualified teachers at a reduced rate for wives who do not have much knowledge of the English language.", "hypothesis": "The wives of Wives International Group are able to receive free language instruction.", "gold_label": "contradiction"}
{"uid": "id_242", "premise": "University Union The job of the University Union is to represent the interests of the studentsboth to the University and to the outside worldand provide students with cultural, sporting and welfare facilitie. When you arrive at the University, you will be given a Student Guide, explaining in detail what the Union has to offer. All full-time registered students are automatically members of the University Union, which is affiliated to the National Union of Students (although under Section 22(2)(c) of the Education Act 1994, a student has the right not to be a member of the Union if he or she so wishes). The Union is run by students (Sabbatical Officers) elected in cross-campus ballots, who work full-time, taking a year of from their university courses. International students are represented by an Overseas Students Officer, a part-time Union post. The Graduate Association All postgraduate students at the University of St James are automatically members of the Graduate Association. It plays an important role in representing the interests of all postgraduate students, and also acts as a social club. The Graduate Association elects annually international officers, representing the interests of students from Europe and from outside Europe. Societies and Groups National and Cultural Societies There are some 18 societies affiliated to the Union with memberships of nationals from those countries and other international and UK students interested in finding out more about their culture and language. The current list of National and Cultural societies as of January 2000 can be obtained at the Union office. The presidents of all these societies can be contacted through their pigeonholes in the Union. If there is no society for your nationality, why not start one? Wives International Group This group was formed to foster contact amongst the wives of overseas students, Coffee mornings are held every Wednesday morning in the Senior Common Room, Clifton Hill House, where children can play with the many toys provided, and their mothers can enjoy a cup of tea or coffee and chat. Language tuition can also be arranged by qualified teachers at a reduced rate for wives who do not have much knowledge of the English language.", "hypothesis": "All students must be members of the Union.", "gold_label": "contradiction"}
{"uid": "id_243", "premise": "Unless companies have some knowledge of buyer behavior, they would be unaware of and unfamiliar with the complex range of behavioral factors that impinge upon purchasing behavior. The truth is that, like much of human behavior, purchase behavior is complex and multi-faceted. Even the simplest of purchasing decisions is an amalgam of behavioral forces and factors of which even the purchaser may not be aware. However, even though consumer behavior is a complex subject, marketing planners should at least have some understanding of it. Marketers are specifically interested in the behavior associated with groups or segments of consumers as it would be impossible to serve the exact needs and wants of specific individuals in a market and remain profitable.", "hypothesis": "Even if one could predict the behavior of an individual buyer, it would not be profitable for marketers to try to do so.", "gold_label": "neutral"}
{"uid": "id_244", "premise": "Unless companies have some knowledge of buyer behavior, they would be unaware of and unfamiliar with the complex range of behavioral factors that impinge upon purchasing behavior. The truth is that, like much of human behavior, purchase behavior is complex and multi-faceted. Even the simplest of purchasing decisions is an amalgam of behavioral forces and factors of which even the purchaser may not be aware. However, even though consumer behavior is a complex subject, marketing planners should at least have some understanding of it. Marketers are specifically interested in the behavior associated with groups or segments of consumers as it would be impossible to serve the exact needs and wants of specific individuals in a market and remain profitable.", "hypothesis": "The purchasing behavior of consumers is unpredictable.", "gold_label": "neutral"}
{"uid": "id_245", "premise": "Unless companies have some knowledge of buyer behavior, they would be unaware of and unfamiliar with the complex range of behavioral factors that impinge upon purchasing behavior. The truth is that, like much of human behavior, purchase behavior is complex and multi-faceted. Even the simplest of purchasing decisions is an amalgam of behavioral forces and factors of which even the purchaser may not be aware. However, even though consumer behavior is a complex subject, marketing planners should at least have some understanding of it. Marketers are specifically interested in the behavior associated with groups or segments of consumers as it would be impossible to serve the exact needs and wants of specific individuals in a market and remain profitable.", "hypothesis": "Some consumer groups exhibit more complex behavior than others do.", "gold_label": "neutral"}
{"uid": "id_246", "premise": "Unless companies have some knowledge of buyer behavior, they would be unaware of and unfamiliar with the complex range of behavioral factors that impinge upon purchasing behavior. The truth is that, like much of human behavior, purchase behavior is complex and multi-faceted. Even the simplest of purchasing decisions is an amalgam of behavioral forces and factors of which even the purchaser may not be aware. However, even though consumer behavior is a complex subject, marketing planners should at least have some understanding of it. Marketers are specifically interested in the behavior associated with groups or segments of consumers as it would be impossible to serve the exact needs and wants of specific individuals in a market and remain profitable.", "hypothesis": "Purchase behavior is not subject to the same whims as other aspects of human behavior.", "gold_label": "contradiction"}
{"uid": "id_247", "premise": "Unless companies have some knowledge of buyer behaviour, they would be unaware of and unfamiliar with the complex range of behavioural factors that impinge upon purchasing behaviour. The truth is that, like much of human behaviour, purchase behaviour is complex and multi-faceted. Even the simplest of purchasing decisions is an amalgam of behavioural forces and factors of which even the purchaser may not be aware. However, even though consumer behaviour is a complex subject, marketing planners should at least have some understanding of it. Marketers are Specifically interested in the behaviour associated with groups or segments of consumers as it would be impossible to serve the exact needs and wants of specific individuals in a market and remain profitable.", "hypothesis": "Some consumer groups exhibit more complex behaviour than others do.", "gold_label": "neutral"}
{"uid": "id_248", "premise": "Unless companies have some knowledge of buyer behaviour, they would be unaware of and unfamiliar with the complex range of behavioural factors that impinge upon purchasing behaviour. The truth is that, like much of human behaviour, purchase behaviour is complex and multi-faceted. Even the simplest of purchasing decisions is an amalgam of behavioural forces and factors of which even the purchaser may not be aware. However, even though consumer behaviour is a complex subject, marketing planners should at least have some understanding of it. Marketers are Specifically interested in the behaviour associated with groups or segments of consumers as it would be impossible to serve the exact needs and wants of specific individuals in a market and remain profitable.", "hypothesis": "Purchase behaviour is not subject to the same whims as other aspects of human behaviour.", "gold_label": "contradiction"}
{"uid": "id_249", "premise": "Unless companies have some knowledge of buyer behaviour, they would be unaware of and unfamiliar with the complex range of behavioural factors that impinge upon purchasing behaviour. The truth is that, like much of human behaviour, purchase behaviour is complex and multi-faceted. Even the simplest of purchasing decisions is an amalgam of behavioural forces and factors of which even the purchaser may not be aware. However, even though consumer behaviour is a complex subject, marketing planners should at least have some understanding of it. Marketers are Specifically interested in the behaviour associated with groups or segments of consumers as it would be impossible to serve the exact needs and wants of specific individuals in a market and remain profitable.", "hypothesis": "The purchasing behavior of consumers is unpredictable.", "gold_label": "neutral"}
{"uid": "id_250", "premise": "Unless companies have some knowledge of buyer behaviour, they would be unaware of and unfamiliar with the complex range of behavioural factors that impinge upon purchasing behaviour. The truth is that, like much of human behaviour, purchase behaviour is complex and multi-faceted. Even the simplest of purchasing decisions is an amalgam of behavioural forces and factors of which even the purchaser may not be aware. However, even though consumer behaviour is a complex subject, marketing planners should at least have some understanding of it. Marketers are Specifically interested in the behaviour associated with groups or segments of consumers as it would be impossible to serve the exact needs and wants of specific individuals in a market and remain profitable.", "hypothesis": "Even if one could predict the behaviour of an individual buyer, it would not be profitable for marketers to try to do so.", "gold_label": "entailment"}
{"uid": "id_251", "premise": "Until 1995, the use of bicycles had remained virtually static for many years. However, in recent years the number of people using bicycles has grown with increasing pressure from environmentalists, transport agencies and health officials. The trend has been to produce more fashionable bicycles in a variety of styles, lighter cycles, and more comfortable cycles. The diversity of models has increased enormously, though their general shape has not changed radically.", "hypothesis": "There is now a greater diversity of bicycles available than before 1995.", "gold_label": "entailment"}
{"uid": "id_252", "premise": "Until 1995, the use of bicycles had remained virtually static for many years. However, in recent years the number of people using bicycles has grown with increasing pressure from environmentalists, transport agencies and health officials. The trend has been to produce more fashionable bicycles in a variety of styles, lighter cycles, and more comfortable cycles. The diversity of models has increased enormously, though their general shape has not changed radically.", "hypothesis": "There has been an increasing pressure from transport agencies to use bicycles.", "gold_label": "entailment"}
{"uid": "id_253", "premise": "Until 1995, the use of bicycles has remained virtually static for many years. However, in recent years the number of people using bicycles has grown with increasing pressure from environmentalists, transport agencies and health officials. The trend has been to produce more fashionable bicycles in a variety of styles, lighter cycles, and more comfortable cycles. The diversity of models has increased enormously, though their general shape has not changed Radically.", "hypothesis": "There is now a greater diversity of bicycles available than before 1995.", "gold_label": "entailment"}
{"uid": "id_254", "premise": "Until 1995, the use of bicycles has remained virtually static for many years. However, in recent years the number of people using bicycles has grown with increasing pressure from environmentalists, transport agencies and health officials. The trend has been to produce more fashionable bicycles in a variety of styles, lighter cycles, and more comfortable cycles. The diversity of models has increased enormously, though their general shape has not changed Radically.", "hypothesis": "There has been an increasing pressure from transport agencies to use bicycles.", "gold_label": "entailment"}
{"uid": "id_255", "premise": "Urban planning in Singapore British merchants established a trading post in Singapore in the early nineteenth century, and for more than a century trading interests dominated. However, in 1965 the newly independent island state was cut off from its hinterland, and so it set about pursuing a survival strategy. The good international communications it already enjoyed provided a useful base, but it was decided that if Singapore was to secure its economic future, it must develop its industry. To this end, new institutional structures were needed to facilitate, develop, and control foreign investment. One of the most important of these was the Economic Development Board (EDB), an arm of government that developed strategies for attracting investment. Thus from the outset, the Singaporean government was involved in city promotion. Towards the end of the twentieth century, the government realised that, due to limits on both the size of the countrys workforce and its land area, its labour-intensive industries were becoming increasingly uncompetitive. So an economic committee was established which concluded that Singapore should focus on developing as a service centre, and seek to attract company headquarters to serve South East Asia, and develop tourism, banking, and offshore activities. The land required for this service-sector orientation had been acquired in the early 1970s, when the government realised that it lacked the banking infrastructure for a modern economy. So a new banking and corporate district, known as the Golden Shoe, was planned, incorporating the historic commercial area. This district now houses all the major companies and various government financial agencies. Singapores current economic strategy is closely linked to land use and development planning. Although it is already a major city, the current development plan seeks to ensure Singapores continued economic growth through restructuring, to ensure that the facilities needed by future business are planned now. These include transport and telecommunication infrastructure, land, and environmental quality. A major concern is to avoid congestion in the central area, and so the latest plan deviates from previous plans by having a strong decentralisation policy. The plan makes provision for four major regional centres, each serving 800,000 people, but this does not mean that the existing central business district will not also grow. A major extension planned around Marina Bay draws on examples of other world cities, especially those with waterside central areas such as Sydney and San Francisco. The project involves major land reclamation of 667 hectares in total. Part of this has already been developed as a conference and exhibition zone, and the rest will be used for other facilities. However the need for vitality has been recognised and a mixed zoning approach has been adopted, to include housing and entertainment. One of the new features of the current plan is a broader conception of what contributes to economic success. It encompasses high quality residential provision, a good environment, leisure facilities and exciting city life. Thus there is more provision for low-density housing, often in waterfront communities linked to beaches and recreational facilities. However, the lower housing densities will put considerable pressure on the very limited land available for development, and this creates problems for another of the plans aims, which is to stress environmental quality. More and more of the remaining open area will be developed, and the only natural landscape surviving will be a small zone in the centre of the island which serves as a water catchment area. Environmental policy is therefore very much concerned with making the built environment more green by introducing more plants what is referred to as the beautification of Singapore. The plan focuses on green zones defining the boundaries of settlements, and running along transport corridors. The incidental green provision within housing areas is also given considerable attention. Much of the environmental provision, for example golf courses, recreation areas, and beaches, is linked to the prime objective of attracting business. The plan places much emphasis on good leisure provision and the need to exploit Singapores island setting. One way of doing this is through further land reclamation, to create a whole new island devoted to leisure and luxury housing which will stretch from the central area to the airport. A current concern also appears to be how to use the planning system to create opportunities for greater spontaneity: planners have recently given much attention to the concept of the 24-hour city and the cafe society. For example, a promotion has taken place along the Singapore river to create a cafe zone. This has included the realisation, rather late in the day, of the value of retaining older buildings, and the creation of a continuous riverside promenade. Since the relaxation in 1996 of strict guidelines on outdoor eating areas, this has become an extremely popular area in the evenings. Also, in 1998 the Urban Redevelopment Authority created a new entertainment area in the centre of the city which they are promoting as the citys one-stop, dynamic entertainment scene. In conclusion, the economic development of Singapore has been very consciously centrally planned, and the latest strategy is very clearly oriented to establishing Singapore as a leading world city. It is well placed to succeed, for a variety of reasons. It can draw upon its historic roots as a world trading centre; it has invested heavily in telecommunications and air transport infrastructure; it is well located in relation to other Asian economies; it has developed a safe and clean environment; and it has utilised the international language of English.", "hypothesis": "Singapore will find it difficult to compete with leading cities in other parts of the world.", "gold_label": "contradiction"}
{"uid": "id_256", "premise": "Urban planning in Singapore British merchants established a trading post in Singapore in the early nineteenth century, and for more than a century trading interests dominated. However, in 1965 the newly independent island state was cut off from its hinterland, and so it set about pursuing a survival strategy. The good international communications it already enjoyed provided a useful base, but it was decided that if Singapore was to secure its economic future, it must develop its industry. To this end, new institutional structures were needed to facilitate, develop, and control foreign investment. One of the most important of these was the Economic Development Board (EDB), an arm of government that developed strategies for attracting investment. Thus from the outset, the Singaporean government was involved in city promotion. Towards the end of the twentieth century, the government realised that, due to limits on both the size of the countrys workforce and its land area, its labour-intensive industries were becoming increasingly uncompetitive. So an economic committee was established which concluded that Singapore should focus on developing as a service centre, and seek to attract company headquarters to serve South East Asia, and develop tourism, banking, and offshore activities. The land required for this service-sector orientation had been acquired in the early 1970s, when the government realised that it lacked the banking infrastructure for a modern economy. So a new banking and corporate district, known as the Golden Shoe, was planned, incorporating the historic commercial area. This district now houses all the major companies and various government financial agencies. Singapores current economic strategy is closely linked to land use and development planning. Although it is already a major city, the current development plan seeks to ensure Singapores continued economic growth through restructuring, to ensure that the facilities needed by future business are planned now. These include transport and telecommunication infrastructure, land, and environmental quality. A major concern is to avoid congestion in the central area, and so the latest plan deviates from previous plans by having a strong decentralisation policy. The plan makes provision for four major regional centres, each serving 800,000 people, but this does not mean that the existing central business district will not also grow. A major extension planned around Marina Bay draws on examples of other world cities, especially those with waterside central areas such as Sydney and San Francisco. The project involves major land reclamation of 667 hectares in total. Part of this has already been developed as a conference and exhibition zone, and the rest will be used for other facilities. However the need for vitality has been recognised and a mixed zoning approach has been adopted, to include housing and entertainment. One of the new features of the current plan is a broader conception of what contributes to economic success. It encompasses high quality residential provision, a good environment, leisure facilities and exciting city life. Thus there is more provision for low-density housing, often in waterfront communities linked to beaches and recreational facilities. However, the lower housing densities will put considerable pressure on the very limited land available for development, and this creates problems for another of the plans aims, which is to stress environmental quality. More and more of the remaining open area will be developed, and the only natural landscape surviving will be a small zone in the centre of the island which serves as a water catchment area. Environmental policy is therefore very much concerned with making the built environment more green by introducing more plants what is referred to as the beautification of Singapore. The plan focuses on green zones defining the boundaries of settlements, and running along transport corridors. The incidental green provision within housing areas is also given considerable attention. Much of the environmental provision, for example golf courses, recreation areas, and beaches, is linked to the prime objective of attracting business. The plan places much emphasis on good leisure provision and the need to exploit Singapores island setting. One way of doing this is through further land reclamation, to create a whole new island devoted to leisure and luxury housing which will stretch from the central area to the airport. A current concern also appears to be how to use the planning system to create opportunities for greater spontaneity: planners have recently given much attention to the concept of the 24-hour city and the cafe society. For example, a promotion has taken place along the Singapore river to create a cafe zone. This has included the realisation, rather late in the day, of the value of retaining older buildings, and the creation of a continuous riverside promenade. Since the relaxation in 1996 of strict guidelines on outdoor eating areas, this has become an extremely popular area in the evenings. Also, in 1998 the Urban Redevelopment Authority created a new entertainment area in the centre of the city which they are promoting as the citys one-stop, dynamic entertainment scene. In conclusion, the economic development of Singapore has been very consciously centrally planned, and the latest strategy is very clearly oriented to establishing Singapore as a leading world city. It is well placed to succeed, for a variety of reasons. It can draw upon its historic roots as a world trading centre; it has invested heavily in telecommunications and air transport infrastructure; it is well located in relation to other Asian economies; it has developed a safe and clean environment; and it has utilised the international language of English.", "hypothesis": "After 1965, the Singaporean government switched the focus of the islands economy.", "gold_label": "entailment"}
{"uid": "id_257", "premise": "Urban planning in Singapore British merchants established a trading post in Singapore in the early nineteenth century, and for more than a century trading interests dominated. However, in 1965 the newly independent island state was cut off from its hinterland, and so it set about pursuing a survival strategy. The good international communications it already enjoyed provided a useful base, but it was decided that if Singapore was to secure its economic future, it must develop its industry. To this end, new institutional structures were needed to facilitate, develop, and control foreign investment. One of the most important of these was the Economic Development Board (EDB), an arm of government that developed strategies for attracting investment. Thus from the outset, the Singaporean government was involved in city promotion. Towards the end of the twentieth century, the government realised that, due to limits on both the size of the countrys workforce and its land area, its labour-intensive industries were becoming increasingly uncompetitive. So an economic committee was established which concluded that Singapore should focus on developing as a service centre, and seek to attract company headquarters to serve South East Asia, and develop tourism, banking, and offshore activities. The land required for this service-sector orientation had been acquired in the early 1970s, when the government realised that it lacked the banking infrastructure for a modern economy. So a new banking and corporate district, known as the Golden Shoe, was planned, incorporating the historic commercial area. This district now houses all the major companies and various government financial agencies. Singapores current economic strategy is closely linked to land use and development planning. Although it is already a major city, the current development plan seeks to ensure Singapores continued economic growth through restructuring, to ensure that the facilities needed by future business are planned now. These include transport and telecommunication infrastructure, land, and environmental quality. A major concern is to avoid congestion in the central area, and so the latest plan deviates from previous plans by having a strong decentralisation policy. The plan makes provision for four major regional centres, each serving 800,000 people, but this does not mean that the existing central business district will not also grow. A major extension planned around Marina Bay draws on examples of other world cities, especially those with waterside central areas such as Sydney and San Francisco. The project involves major land reclamation of 667 hectares in total. Part of this has already been developed as a conference and exhibition zone, and the rest will be used for other facilities. However the need for vitality has been recognised and a mixed zoning approach has been adopted, to include housing and entertainment. One of the new features of the current plan is a broader conception of what contributes to economic success. It encompasses high quality residential provision, a good environment, leisure facilities and exciting city life. Thus there is more provision for low-density housing, often in waterfront communities linked to beaches and recreational facilities. However, the lower housing densities will put considerable pressure on the very limited land available for development, and this creates problems for another of the plans aims, which is to stress environmental quality. More and more of the remaining open area will be developed, and the only natural landscape surviving will be a small zone in the centre of the island which serves as a water catchment area. Environmental policy is therefore very much concerned with making the built environment more green by introducing more plants what is referred to as the beautification of Singapore. The plan focuses on green zones defining the boundaries of settlements, and running along transport corridors. The incidental green provision within housing areas is also given considerable attention. Much of the environmental provision, for example golf courses, recreation areas, and beaches, is linked to the prime objective of attracting business. The plan places much emphasis on good leisure provision and the need to exploit Singapores island setting. One way of doing this is through further land reclamation, to create a whole new island devoted to leisure and luxury housing which will stretch from the central area to the airport. A current concern also appears to be how to use the planning system to create opportunities for greater spontaneity: planners have recently given much attention to the concept of the 24-hour city and the cafe society. For example, a promotion has taken place along the Singapore river to create a cafe zone. This has included the realisation, rather late in the day, of the value of retaining older buildings, and the creation of a continuous riverside promenade. Since the relaxation in 1996 of strict guidelines on outdoor eating areas, this has become an extremely popular area in the evenings. Also, in 1998 the Urban Redevelopment Authority created a new entertainment area in the centre of the city which they are promoting as the citys one-stop, dynamic entertainment scene. In conclusion, the economic development of Singapore has been very consciously centrally planned, and the latest strategy is very clearly oriented to establishing Singapore as a leading world city. It is well placed to succeed, for a variety of reasons. It can draw upon its historic roots as a world trading centre; it has invested heavily in telecommunications and air transport infrastructure; it is well located in relation to other Asian economies; it has developed a safe and clean environment; and it has utilised the international language of English.", "hypothesis": "The government has enacted new laws to protect Singapores old buildings.", "gold_label": "neutral"}
{"uid": "id_258", "premise": "Urban planning in Singapore British merchants established a trading post in Singapore in the early nineteenth century, and for more than a century trading interests dominated. However, in 1965 the newly independent island state was cut off from its hinterland, and so it set about pursuing a survival strategy. The good international communications it already enjoyed provided a useful base, but it was decided that if Singapore was to secure its economic future, it must develop its industry. To this end, new institutional structures were needed to facilitate, develop, and control foreign investment. One of the most important of these was the Economic Development Board (EDB), an arm of government that developed strategies for attracting investment. Thus from the outset, the Singaporean government was involved in city promotion. Towards the end of the twentieth century, the government realised that, due to limits on both the size of the countrys workforce and its land area, its labour-intensive industries were becoming increasingly uncompetitive. So an economic committee was established which concluded that Singapore should focus on developing as a service centre, and seek to attract company headquarters to serve South East Asia, and develop tourism, banking, and offshore activities. The land required for this service-sector orientation had been acquired in the early 1970s, when the government realised that it lacked the banking infrastructure for a modern economy. So a new banking and corporate district, known as the Golden Shoe, was planned, incorporating the historic commercial area. This district now houses all the major companies and various government financial agencies. Singapores current economic strategy is closely linked to land use and development planning. Although it is already a major city, the current development plan seeks to ensure Singapores continued economic growth through restructuring, to ensure that the facilities needed by future business are planned now. These include transport and telecommunication infrastructure, land, and environmental quality. A major concern is to avoid congestion in the central area, and so the latest plan deviates from previous plans by having a strong decentralisation policy. The plan makes provision for four major regional centres, each serving 800,000 people, but this does not mean that the existing central business district will not also grow. A major extension planned around Marina Bay draws on examples of other world cities, especially those with waterside central areas such as Sydney and San Francisco. The project involves major land reclamation of 667 hectares in total. Part of this has already been developed as a conference and exhibition zone, and the rest will be used for other facilities. However the need for vitality has been recognised and a mixed zoning approach has been adopted, to include housing and entertainment. One of the new features of the current plan is a broader conception of what contributes to economic success. It encompasses high quality residential provision, a good environment, leisure facilities and exciting city life. Thus there is more provision for low-density housing, often in waterfront communities linked to beaches and recreational facilities. However, the lower housing densities will put considerable pressure on the very limited land available for development, and this creates problems for another of the plans aims, which is to stress environmental quality. More and more of the remaining open area will be developed, and the only natural landscape surviving will be a small zone in the centre of the island which serves as a water catchment area. Environmental policy is therefore very much concerned with making the built environment more green by introducing more plants what is referred to as the beautification of Singapore. The plan focuses on green zones defining the boundaries of settlements, and running along transport corridors. The incidental green provision within housing areas is also given considerable attention. Much of the environmental provision, for example golf courses, recreation areas, and beaches, is linked to the prime objective of attracting business. The plan places much emphasis on good leisure provision and the need to exploit Singapores island setting. One way of doing this is through further land reclamation, to create a whole new island devoted to leisure and luxury housing which will stretch from the central area to the airport. A current concern also appears to be how to use the planning system to create opportunities for greater spontaneity: planners have recently given much attention to the concept of the 24-hour city and the cafe society. For example, a promotion has taken place along the Singapore river to create a cafe zone. This has included the realisation, rather late in the day, of the value of retaining older buildings, and the creation of a continuous riverside promenade. Since the relaxation in 1996 of strict guidelines on outdoor eating areas, this has become an extremely popular area in the evenings. Also, in 1998 the Urban Redevelopment Authority created a new entertainment area in the centre of the city which they are promoting as the citys one-stop, dynamic entertainment scene. In conclusion, the economic development of Singapore has been very consciously centrally planned, and the latest strategy is very clearly oriented to establishing Singapore as a leading world city. It is well placed to succeed, for a variety of reasons. It can draw upon its historic roots as a world trading centre; it has invested heavily in telecommunications and air transport infrastructure; it is well located in relation to other Asian economies; it has developed a safe and clean environment; and it has utilised the international language of English.", "hypothesis": "The creation of Singapores financial centre was delayed while a suitable site was found.", "gold_label": "contradiction"}
{"uid": "id_259", "premise": "Urban planning in Singapore British merchants established a trading post in Singapore in the early nineteenth century, and for more than a century trading interests dominated. However, in 1965 the newly independent island state was cut off from its hinterland, and so it set about pursuing a survival strategy. The good international communications it already enjoyed provided a useful base, but it was decided that if Singapore was to secure its economic future, it must develop its industry. To this end, new institutional structures were needed to facilitate, develop, and control foreign investment. One of the most important of these was the Economic Development Board (EDB), an arm of government that developed strategies for attracting investment. Thus from the outset, the Singaporean government was involved in city promotion. Towards the end of the twentieth century, the government realised that, due to limits on both the size of the countrys workforce and its land area, its labour-intensive industries were becoming increasingly uncompetitive. So an economic committee was established which concluded that Singapore should focus on developing as a service centre, and seek to attract company headquarters to serve South East Asia, and develop tourism, banking, and offshore activities. The land required for this service-sector orientation had been acquired in the early 1970s, when the government realised that it lacked the banking infrastructure for a modern economy. So a new banking and corporate district, known as the Golden Shoe, was planned, incorporating the historic commercial area. This district now houses all the major companies and various government financial agencies. Singapores current economic strategy is closely linked to land use and development planning. Although it is already a major city, the current development plan seeks to ensure Singapores continued economic growth through restructuring, to ensure that the facilities needed by future business are planned now. These include transport and telecommunication infrastructure, land, and environmental quality. A major concern is to avoid congestion in the central area, and so the latest plan deviates from previous plans by having a strong decentralisation policy. The plan makes provision for four major regional centres, each serving 800,000 people, but this does not mean that the existing central business district will not also grow. A major extension planned around Marina Bay draws on examples of other world cities, especially those with waterside central areas such as Sydney and San Francisco. The project involves major land reclamation of 667 hectares in total. Part of this has already been developed as a conference and exhibition zone, and the rest will be used for other facilities. However the need for vitality has been recognised and a mixed zoning approach has been adopted, to include housing and entertainment. One of the new features of the current plan is a broader conception of what contributes to economic success. It encompasses high quality residential provision, a good environment, leisure facilities and exciting city life. Thus there is more provision for low-density housing, often in waterfront communities linked to beaches and recreational facilities. However, the lower housing densities will put considerable pressure on the very limited land available for development, and this creates problems for another of the plans aims, which is to stress environmental quality. More and more of the remaining open area will be developed, and the only natural landscape surviving will be a small zone in the centre of the island which serves as a water catchment area. Environmental policy is therefore very much concerned with making the built environment more green by introducing more plants what is referred to as the beautification of Singapore. The plan focuses on green zones defining the boundaries of settlements, and running along transport corridors. The incidental green provision within housing areas is also given considerable attention. Much of the environmental provision, for example golf courses, recreation areas, and beaches, is linked to the prime objective of attracting business. The plan places much emphasis on good leisure provision and the need to exploit Singapores island setting. One way of doing this is through further land reclamation, to create a whole new island devoted to leisure and luxury housing which will stretch from the central area to the airport. A current concern also appears to be how to use the planning system to create opportunities for greater spontaneity: planners have recently given much attention to the concept of the 24-hour city and the cafe society. For example, a promotion has taken place along the Singapore river to create a cafe zone. This has included the realisation, rather late in the day, of the value of retaining older buildings, and the creation of a continuous riverside promenade. Since the relaxation in 1996 of strict guidelines on outdoor eating areas, this has become an extremely popular area in the evenings. Also, in 1998 the Urban Redevelopment Authority created a new entertainment area in the centre of the city which they are promoting as the citys one-stop, dynamic entertainment scene. In conclusion, the economic development of Singapore has been very consciously centrally planned, and the latest strategy is very clearly oriented to establishing Singapore as a leading world city. It is well placed to succeed, for a variety of reasons. It can draw upon its historic roots as a world trading centre; it has invested heavily in telecommunications and air transport infrastructure; it is well located in relation to other Asian economies; it has developed a safe and clean environment; and it has utilised the international language of English.", "hypothesis": "Singapores four regional centres will eventually be the same size as its central business district.", "gold_label": "neutral"}
{"uid": "id_260", "premise": "Urban planning in Singapore British merchants established a trading post in Singapore in the early nineteenth century, and for more than a century trading interests dominated. However, in 1965 the newly independent island state was cut off from its hinterland, and so it set about pursuing a survival strategy. The good international communications it already enjoyed provided a useful base, but it was decided that if Singapore was to secure its economic future, it must develop its industry. To this end, new institutional structures were needed to facilitate, develop, and control foreign investment. One of the most important of these was the Economic Development Board (EDB), an arm of government that developed strategies for attracting investment. Thus from the outset, the Singaporean government was involved in city promotion. Towards the end of the twentieth century, the government realised that, due to limits on both the size of the countrys workforce and its land area, its labour-intensive industries were becoming increasingly uncompetitive. So an economic committee was established which concluded that Singapore should focus on developing as a service centre, and seek to attract company headquarters to serve South East Asia, and develop tourism, banking, and offshore activities. The land required for this service-sector orientation had been acquired in the early 1970s, when the government realised that it lacked the banking infrastructure for a modern economy. So a new banking and corporate district, known as the Golden Shoe, was planned, incorporating the historic commercial area. This district now houses all the major companies and various government financial agencies. Singapores current economic strategy is closely linked to land use and development planning. Although it is already a major city, the current development plan seeks to ensure Singapores continued economic growth through restructuring, to ensure that the facilities needed by future business are planned now. These include transport and telecommunication infrastructure, land, and environmental quality. A major concern is to avoid congestion in the central area, and so the latest plan deviates from previous plans by having a strong decentralisation policy. The plan makes provision for four major regional centres, each serving 800,000 people, but this does not mean that the existing central business district will not also grow. A major extension planned around Marina Bay draws on examples of other world cities, especially those with waterside central areas such as Sydney and San Francisco. The project involves major land reclamation of 667 hectares in total. Part of this has already been developed as a conference and exhibition zone, and the rest will be used for other facilities. However the need for vitality has been recognised and a mixed zoning approach has been adopted, to include housing and entertainment. One of the new features of the current plan is a broader conception of what contributes to economic success. It encompasses high quality residential provision, a good environment, leisure facilities and exciting city life. Thus there is more provision for low-density housing, often in waterfront communities linked to beaches and recreational facilities. However, the lower housing densities will put considerable pressure on the very limited land available for development, and this creates problems for another of the plans aims, which is to stress environmental quality. More and more of the remaining open area will be developed, and the only natural landscape surviving will be a small zone in the centre of the island which serves as a water catchment area. Environmental policy is therefore very much concerned with making the built environment more green by introducing more plants what is referred to as the beautification of Singapore. The plan focuses on green zones defining the boundaries of settlements, and running along transport corridors. The incidental green provision within housing areas is also given considerable attention. Much of the environmental provision, for example golf courses, recreation areas, and beaches, is linked to the prime objective of attracting business. The plan places much emphasis on good leisure provision and the need to exploit Singapores island setting. One way of doing this is through further land reclamation, to create a whole new island devoted to leisure and luxury housing which will stretch from the central area to the airport. A current concern also appears to be how to use the planning system to create opportunities for greater spontaneity: planners have recently given much attention to the concept of the 24-hour city and the cafe society. For example, a promotion has taken place along the Singapore river to create a cafe zone. This has included the realisation, rather late in the day, of the value of retaining older buildings, and the creation of a continuous riverside promenade. Since the relaxation in 1996 of strict guidelines on outdoor eating areas, this has become an extremely popular area in the evenings. Also, in 1998 the Urban Redevelopment Authority created a new entertainment area in the centre of the city which they are promoting as the citys one-stop, dynamic entertainment scene. In conclusion, the economic development of Singapore has been very consciously centrally planned, and the latest strategy is very clearly oriented to establishing Singapore as a leading world city. It is well placed to succeed, for a variety of reasons. It can draw upon its historic roots as a world trading centre; it has invested heavily in telecommunications and air transport infrastructure; it is well located in relation to other Asian economies; it has developed a safe and clean environment; and it has utilised the international language of English.", "hypothesis": "Planners have modelled new urban developments on other coastal cities.", "gold_label": "entailment"}
{"uid": "id_261", "premise": "Urban planning in Singapore British merchants established a trading post in Singapore in the early nineteenth century, and for more than a century trading interests dominated. However, in 1965 the newly independent island state was cut off from its hinterland, and so it set about pursuing a survival strategy. The good international communications it already enjoyed provided a useful base, but it was decided that if Singapore was to secure its economic future, it must develop its industry. To this end, new institutional structures were needed to facilitate, develop, and control foreign investment. One of the most important of these was the Economic Development Board (EDB), an arm of government that developed strategies for attracting investment. Thus from the outset, the Singaporean government was involved in city promotion. Towards the end of the twentieth century, the government realised that, due to limits on both the size of the countrys workforce and its land area, its labour-intensive industries were becoming increasingly uncompetitive. So an economic committee was established which concluded that Singapore should focus on developing as a service centre, and seek to attract company headquarters to serve South East Asia, and develop tourism, banking, and offshore activities. The land required for this service-sector orientation had been acquired in the early 1970s, when the government realised that it lacked the banking infrastructure for a modern economy. So a new banking and corporate district, known as the Golden Shoe, was planned, incorporating the historic commercial area. This district now houses all the major companies and various government financial agencies. Singapores current economic strategy is closely linked to land use and development planning. Although it is already a major city, the current development plan seeks to ensure Singapores continued economic growth through restructuring, to ensure that the facilities needed by future business are planned now. These include transport and telecommunication infrastructure, land, and environmental quality. A major concern is to avoid congestion in the central area, and so the latest plan deviates from previous plans by having a strong decentralisation policy. The plan makes provision for four major regional centres, each serving 800,000 people, but this does not mean that the existing central business district will not also grow. A major extension planned around Marina Bay draws on examples of other world cities, especially those with waterside central areas such as Sydney and San Francisco. The project involves major land reclamation of 667 hectares in total. Part of this has already been developed as a conference and exhibition zone, and the rest will be used for other facilities. However the need for vitality has been recognised and a mixed zoning approach has been adopted, to include housing and entertainment. One of the new features of the current plan is a broader conception of what contributes to economic success. It encompasses high quality residential provision, a good environment, leisure facilities and exciting city life. Thus there is more provision for low-density housing, often in waterfront communities linked to beaches and recreational facilities. However, the lower housing densities will put considerable pressure on the very limited land available for development, and this creates problems for another of the plans aims, which is to stress environmental quality. More and more of the remaining open area will be developed, and the only natural landscape surviving will be a small zone in the centre of the island which serves as a water catchment area. Environmental policy is therefore very much concerned with making the built environment more green by introducing more plants what is referred to as the beautification of Singapore. The plan focuses on green zones defining the boundaries of settlements, and running along transport corridors. The incidental green provision within housing areas is also given considerable attention. Much of the environmental provision, for example golf courses, recreation areas, and beaches, is linked to the prime objective of attracting business. The plan places much emphasis on good leisure provision and the need to exploit Singapores island setting. One way of doing this is through further land reclamation, to create a whole new island devoted to leisure and luxury housing which will stretch from the central area to the airport. A current concern also appears to be how to use the planning system to create opportunities for greater spontaneity: planners have recently given much attention to the concept of the 24-hour city and the cafe society. For example, a promotion has taken place along the Singapore river to create a cafe zone. This has included the realisation, rather late in the day, of the value of retaining older buildings, and the creation of a continuous riverside promenade. Since the relaxation in 1996 of strict guidelines on outdoor eating areas, this has become an extremely popular area in the evenings. Also, in 1998 the Urban Redevelopment Authority created a new entertainment area in the centre of the city which they are promoting as the citys one-stop, dynamic entertainment scene. In conclusion, the economic development of Singapore has been very consciously centrally planned, and the latest strategy is very clearly oriented to establishing Singapore as a leading world city. It is well placed to succeed, for a variety of reasons. It can draw upon its historic roots as a world trading centre; it has invested heavily in telecommunications and air transport infrastructure; it is well located in relation to other Asian economies; it has developed a safe and clean environment; and it has utilised the international language of English.", "hypothesis": "Plants and trees are amongst the current priorities for Singapores city planners.", "gold_label": "entailment"}
{"uid": "id_262", "premise": "Use of cell phones and pagers is not allowed inside the auditorium. Please switch off such devices while you are inside the auditorium. ------ A notice.", "hypothesis": "All those who have such devices will switch them off before they take their seatin the auditorium.", "gold_label": "entailment"}
{"uid": "id_263", "premise": "Use of cell phones and pagers is not allowed inside the auditorium. Please switch off such devices while you are inside the auditorium. ------ A notice.", "hypothesis": "Generally people do not bring such devices when they come to attend functions in the auditorium.", "gold_label": "contradiction"}
{"uid": "id_264", "premise": "Use our product to improve memory of our child. It is based on natural herbs and has no harmful side effects. ---- An advertisement of a pharmaceutical company.", "hypothesis": "People generally opt for a medical product which is useful and has no harmful side effects.", "gold_label": "entailment"}
{"uid": "id_265", "premise": "Use our product to improve memory of our child. It is based on natural herbs and has no harmful side effects. ---- An advertisement of a pharmaceutical company.", "hypothesis": "Improving memory of child is considered as important by many parents.", "gold_label": "entailment"}
{"uid": "id_266", "premise": "Using Wind-up Cell Phone Chargers So what do you do when your battery on your cell phone runs out and you're forced to use some muscle with your wind-up charger? Fortunately, most chargers are very small and lightweight, even smaller than most cell phones, so they're easy to carry with you and could easily store in a car's glove compartment, a purse or backpack. They typically weigh no more than a couple of ounces. When your phone needs some extra juice, simply connect the wind-up charger to your cell phone's input. To give the phone's battery its power, you'll need to turn the crank vigorously. Most wind-up charger instructions say to crank at a rate of two revolutions per second, although turning the crank slower or faster is fine and will still provide power to the battery. Depending on the model, you can get 25-30 minutes of extra standby power to a cell phone after just a few minutes of solid cranking. You should only be able to get about 6 minutes of call time from the same amount of exercise, however, since it requires more power to send out signals. If you have a hands free set like a Bluetooth earpiece, you can even hold the charger and talk at the same time, since charging is a two-handed operation. As long as you keep turning the handle, the power you provide to charge the phone should be greater than the power needed to keep the phone on. This allows you to talk and provide a charge continuously. What about the different types of inputs on cell phones? Often one of the more frustrating things about losing battery power on your cell phone is when someone else actually has a charger available, but the parts don't fit. Fortunately, many wind-up cell phone chargers come with adapters that fit most phones so you should be able to find the right charge input.", "hypothesis": "Charging your phone with the wind-up charger should give you 25-30 minutes more call time.", "gold_label": "contradiction"}
{"uid": "id_267", "premise": "Using Wind-up Cell Phone Chargers So what do you do when your battery on your cell phone runs out and you're forced to use some muscle with your wind-up charger? Fortunately, most chargers are very small and lightweight, even smaller than most cell phones, so they're easy to carry with you and could easily store in a car's glove compartment, a purse or backpack. They typically weigh no more than a couple of ounces. When your phone needs some extra juice, simply connect the wind-up charger to your cell phone's input. To give the phone's battery its power, you'll need to turn the crank vigorously. Most wind-up charger instructions say to crank at a rate of two revolutions per second, although turning the crank slower or faster is fine and will still provide power to the battery. Depending on the model, you can get 25-30 minutes of extra standby power to a cell phone after just a few minutes of solid cranking. You should only be able to get about 6 minutes of call time from the same amount of exercise, however, since it requires more power to send out signals. If you have a hands free set like a Bluetooth earpiece, you can even hold the charger and talk at the same time, since charging is a two-handed operation. As long as you keep turning the handle, the power you provide to charge the phone should be greater than the power needed to keep the phone on. This allows you to talk and provide a charge continuously. What about the different types of inputs on cell phones? Often one of the more frustrating things about losing battery power on your cell phone is when someone else actually has a charger available, but the parts don't fit. Fortunately, many wind-up cell phone chargers come with adapters that fit most phones so you should be able to find the right charge input.", "hypothesis": "The light on the Sidewinder can be difficult to illuminate.", "gold_label": "contradiction"}
{"uid": "id_268", "premise": "Using Wind-up Cell Phone Chargers So what do you do when your battery on your cell phone runs out and you're forced to use some muscle with your wind-up charger? Fortunately, most chargers are very small and lightweight, even smaller than most cell phones, so they're easy to carry with you and could easily store in a car's glove compartment, a purse or backpack. They typically weigh no more than a couple of ounces. When your phone needs some extra juice, simply connect the wind-up charger to your cell phone's input. To give the phone's battery its power, you'll need to turn the crank vigorously. Most wind-up charger instructions say to crank at a rate of two revolutions per second, although turning the crank slower or faster is fine and will still provide power to the battery. Depending on the model, you can get 25-30 minutes of extra standby power to a cell phone after just a few minutes of solid cranking. You should only be able to get about 6 minutes of call time from the same amount of exercise, however, since it requires more power to send out signals. If you have a hands free set like a Bluetooth earpiece, you can even hold the charger and talk at the same time, since charging is a two-handed operation. As long as you keep turning the handle, the power you provide to charge the phone should be greater than the power needed to keep the phone on. This allows you to talk and provide a charge continuously. What about the different types of inputs on cell phones? Often one of the more frustrating things about losing battery power on your cell phone is when someone else actually has a charger available, but the parts don't fit. Fortunately, many wind-up cell phone chargers come with adapters that fit most phones so you should be able to find the right charge input.", "hypothesis": "You can charge your phone with the wind-up charger while having a conversation on your phone.", "gold_label": "entailment"}
{"uid": "id_269", "premise": "Using Wind-up Cell Phone Chargers So what do you do when your battery on your cell phone runs out and you're forced to use some muscle with your wind-up charger? Fortunately, most chargers are very small and lightweight, even smaller than most cell phones, so they're easy to carry with you and could easily store in a car's glove compartment, a purse or backpack. They typically weigh no more than a couple of ounces. When your phone needs some extra juice, simply connect the wind-up charger to your cell phone's input. To give the phone's battery its power, you'll need to turn the crank vigorously. Most wind-up charger instructions say to crank at a rate of two revolutions per second, although turning the crank slower or faster is fine and will still provide power to the battery. Depending on the model, you can get 25-30 minutes of extra standby power to a cell phone after just a few minutes of solid cranking. You should only be able to get about 6 minutes of call time from the same amount of exercise, however, since it requires more power to send out signals. If you have a hands free set like a Bluetooth earpiece, you can even hold the charger and talk at the same time, since charging is a two-handed operation. As long as you keep turning the handle, the power you provide to charge the phone should be greater than the power needed to keep the phone on. This allows you to talk and provide a charge continuously. What about the different types of inputs on cell phones? Often one of the more frustrating things about losing battery power on your cell phone is when someone else actually has a charger available, but the parts don't fit. Fortunately, many wind-up cell phone chargers come with adapters that fit most phones so you should be able to find the right charge input.", "hypothesis": "Adapters for most cell phones can be purchased for the wind-up charger.", "gold_label": "neutral"}
{"uid": "id_270", "premise": "Using Wind-up Cell Phone Chargers So what do you do when your battery on your cell phone runs out and you're forced to use some muscle with your wind-up charger? Fortunately, most chargers are very small and lightweight, even smaller than most cell phones, so they're easy to carry with you and could easily store in a car's glove compartment, a purse or backpack. They typically weigh no more than a couple of ounces. When your phone needs some extra juice, simply connect the wind-up charger to your cell phone's input. To give the phone's battery its power, you'll need to turn the crank vigorously. Most wind-up charger instructions say to crank at a rate of two revolutions per second, although turning the crank slower or faster is fine and will still provide power to the battery. Depending on the model, you can get 25-30 minutes of extra standby power to a cell phone after just a few minutes of solid cranking. You should only be able to get about 6 minutes of call time from the same amount of exercise, however, since it requires more power to send out signals. If you have a hands free set like a Bluetooth earpiece, you can even hold the charger and talk at the same time, since charging is a two-handed operation. As long as you keep turning the handle, the power you provide to charge the phone should be greater than the power needed to keep the phone on. This allows you to talk and provide a charge continuously. What about the different types of inputs on cell phones? Often one of the more frustrating things about losing battery power on your cell phone is when someone else actually has a charger available, but the parts don't fit. Fortunately, many wind-up cell phone chargers come with adapters that fit most phones so you should be able to find the right charge input.", "hypothesis": "The Sidewinder could help you in the even of you losing your phone.", "gold_label": "entailment"}
{"uid": "id_271", "premise": "Using Wind-up Cell Phone Chargers So what do you do when your battery on your cell phone runs out and you're forced to use some muscle with your wind-up charger? Fortunately, most chargers are very small and lightweight, even smaller than most cell phones, so they're easy to carry with you and could easily store in a car's glove compartment, a purse or backpack. They typically weigh no more than a couple of ounces. When your phone needs some extra juice, simply connect the wind-up charger to your cell phone's input. To give the phone's battery its power, you'll need to turn the crank vigorously. Most wind-up charger instructions say to crank at a rate of two revolutions per second, although turning the crank slower or faster is fine and will still provide power to the battery. Depending on the model, you can get 25-30 minutes of extra standby power to a cell phone after just a few minutes of solid cranking. You should only be able to get about 6 minutes of call time from the same amount of exercise, however, since it requires more power to send out signals. If you have a hands free set like a Bluetooth earpiece, you can even hold the charger and talk at the same time, since charging is a two-handed operation. As long as you keep turning the handle, the power you provide to charge the phone should be greater than the power needed to keep the phone on. This allows you to talk and provide a charge continuously. What about the different types of inputs on cell phones? Often one of the more frustrating things about losing battery power on your cell phone is when someone else actually has a charger available, but the parts don't fit. Fortunately, many wind-up cell phone chargers come with adapters that fit most phones so you should be able to find the right charge input.", "hypothesis": "To charge the phone's battery the wind-up charger needs to be rotated gently.", "gold_label": "contradiction"}
{"uid": "id_272", "premise": "Using Wind-up Cell Phone Chargers So what do you do when your battery on your cell phone runs out and you're forced to use some muscle with your wind-up charger? Fortunately, most chargers are very small and lightweight, even smaller than most cell phones, so they're easy to carry with you and could easily store in a car's glove compartment, a purse or backpack. They typically weigh no more than a couple of ounces. When your phone needs some extra juice, simply connect the wind-up charger to your cell phone's input. To give the phone's battery its power, you'll need to turn the crank vigorously. Most wind-up charger instructions say to crank at a rate of two revolutions per second, although turning the crank slower or faster is fine and will still provide power to the battery. Depending on the model, you can get 25-30 minutes of extra standby power to a cell phone after just a few minutes of solid cranking. You should only be able to get about 6 minutes of call time from the same amount of exercise, however, since it requires more power to send out signals. If you have a hands free set like a Bluetooth earpiece, you can even hold the charger and talk at the same time, since charging is a two-handed operation. As long as you keep turning the handle, the power you provide to charge the phone should be greater than the power needed to keep the phone on. This allows you to talk and provide a charge continuously. What about the different types of inputs on cell phones? Often one of the more frustrating things about losing battery power on your cell phone is when someone else actually has a charger available, but the parts don't fit. Fortunately, many wind-up cell phone chargers come with adapters that fit most phones so you should be able to find the right charge input.", "hypothesis": "The wind-up cell phone chargers are smaller enough to fit inside a glove.", "gold_label": "neutral"}
{"uid": "id_273", "premise": "Venus Flytrap From indigenous myths to John Wyndhams Day of the Triffids and the off-Broadway musical Little Shop of Horrors, the idea of cerebral, carnivorous flora has spooked audiences and readers for centuries. While shrubs and shoots have yet to uproot themselves or show any interest in human beings, however, for some of earths smaller inhabitants arachnids and insects the risk of being trapped and ingested by a plant can be a threat to their daily existence. Easily, the most famous of these predators is the Venus Flytrap, one of only two types of snap traps in the world. Though rarely found growing wild, the Flytrap has captured popular imagination and can be purchased in florists and plant retailers around the world. Part of the Venus Flytraps mysterious aura begins with the tide itself. While it is fairly clear that the second half of the epithet has been given for its insect-trapping ability, the origin of Venus is somewhat more ambiguous. According to the International Carnivorous Plant Society, the plant was first studied in the 17th and 18th centuries, when puritanical mores ruled Western societies and obsession was rife with forbidden human impulses and urges, women were often portrayed in these times as seductresses and temptresses, and botanists are believed to have seen a parallel between the behaviour of the plant in luring and devouring insects and the imagined behaviour of women in luring and trapping witless men. The plant was thus named after the pagan goddess of love and money Venus. The Venus Flytrap is a small plant with six to seven leaves growing out of a bulb-like stem. At the end of each leaf is a trap, which is an opened pod with cilia around the edges like stiff eyelashes. The pod is lined with anthocyanin pigments and sweet-smelling sap to attract flies and other insects. When they fly in, trigger hairs inside the pod sense the intruders movement, and the pod snaps shut. The trigger mechanism is so sophisticated that the plant can differentiate between living creatures and non-edible debris by requiring two trigger hairs to be touched within twenty seconds of each other, or one hair to be touched in quick succession. The plant has no nervous system, and researchers can only hypothesise as to how the rapid shutting movement works. This uncertainty adds to the Venus Flytraps allure. The pod shuts quickly but does not seal entirely at first; scientists have found that tins mechanism allows miniscule insects to escape, as they will not be a source of useful nourishment for the plant. If the creature is large enough, however, the plants flaps will eventually meet to form an airtight compress, and at this point, the digestive process begins. A Venus Flytraps digestive system is remarkably similar to how a human stomach works. For somewhere between five and twelve days, the trap secretes acidic digestive juices that dissolve the soft tissue and cell membranes of the insect. These juices also kill any bacteria that have entered with the food, ensuring the plant maintains its hygiene so that it does not begin to rot. Enzymes in the acid help with the digestion of DNA, amino acids, and cell molecules so that every fleshy part of the animal can be consumed. Once the plant has reabsorbed the digestive fluid this time with the added nourishment, the trap reopens and the exoskeleton blows away in the wind. Although transplanted to other locations around the world, the Venus Flytrap is only found natively in an area around Wilmington, North Carolina in the United States. It thrives in bogs, marshes, and wetlands and grows in wet sand and peaty soils. Because these environments are so depleted in nitrogen, they asphyxiate other flora, but the Flytrap overcomes this nutritional poverty by sourcing protein from its insect prey. One of the plants curious features is resilience to flame. It is speculated that the Flytrap evolved this to endure through periodic blazes and to act as a means of survival that its competition lacks. While the Venus Flytrap will not become extinct any time soon (an estimated 3-6 million plants are presently in cultivation), its natural existence is uncertain. In the last survey, only 35,800 Flytraps were found remaining in the wild, and some prominent conservationists have suggested the plant be given the status of vulnerable. Since this research is considerably dated, having taken place in 1992, the present number is considerably lower. The draining and destruction of natural wetlands where the Flytrap lives is considered to be the biggest threat to its existence, as well as people removing the plants from their natural habitat. Punitive measures have been introduced to prevent people from doing this. Ironically, while cultural depictions of perennial killers may persist, the bigger threat is not what meat-eating plants might do to us but what we may do to them.", "hypothesis": "Many botanists would like the Venus Flytrap to be officially recognised as an endangered plant species.", "gold_label": "neutral"}
{"uid": "id_274", "premise": "Venus Flytrap From indigenous myths to John Wyndhams Day of the Triffids and the off-Broadway musical Little Shop of Horrors, the idea of cerebral, carnivorous flora has spooked audiences and readers for centuries. While shrubs and shoots have yet to uproot themselves or show any interest in human beings, however, for some of earths smaller inhabitants arachnids and insects the risk of being trapped and ingested by a plant can be a threat to their daily existence. Easily, the most famous of these predators is the Venus Flytrap, one of only two types of snap traps in the world. Though rarely found growing wild, the Flytrap has captured popular imagination and can be purchased in florists and plant retailers around the world. Part of the Venus Flytraps mysterious aura begins with the tide itself. While it is fairly clear that the second half of the epithet has been given for its insect-trapping ability, the origin of Venus is somewhat more ambiguous. According to the International Carnivorous Plant Society, the plant was first studied in the 17th and 18th centuries, when puritanical mores ruled Western societies and obsession was rife with forbidden human impulses and urges, women were often portrayed in these times as seductresses and temptresses, and botanists are believed to have seen a parallel between the behaviour of the plant in luring and devouring insects and the imagined behaviour of women in luring and trapping witless men. The plant was thus named after the pagan goddess of love and money Venus. The Venus Flytrap is a small plant with six to seven leaves growing out of a bulb-like stem. At the end of each leaf is a trap, which is an opened pod with cilia around the edges like stiff eyelashes. The pod is lined with anthocyanin pigments and sweet-smelling sap to attract flies and other insects. When they fly in, trigger hairs inside the pod sense the intruders movement, and the pod snaps shut. The trigger mechanism is so sophisticated that the plant can differentiate between living creatures and non-edible debris by requiring two trigger hairs to be touched within twenty seconds of each other, or one hair to be touched in quick succession. The plant has no nervous system, and researchers can only hypothesise as to how the rapid shutting movement works. This uncertainty adds to the Venus Flytraps allure. The pod shuts quickly but does not seal entirely at first; scientists have found that tins mechanism allows miniscule insects to escape, as they will not be a source of useful nourishment for the plant. If the creature is large enough, however, the plants flaps will eventually meet to form an airtight compress, and at this point, the digestive process begins. A Venus Flytraps digestive system is remarkably similar to how a human stomach works. For somewhere between five and twelve days, the trap secretes acidic digestive juices that dissolve the soft tissue and cell membranes of the insect. These juices also kill any bacteria that have entered with the food, ensuring the plant maintains its hygiene so that it does not begin to rot. Enzymes in the acid help with the digestion of DNA, amino acids, and cell molecules so that every fleshy part of the animal can be consumed. Once the plant has reabsorbed the digestive fluid this time with the added nourishment, the trap reopens and the exoskeleton blows away in the wind. Although transplanted to other locations around the world, the Venus Flytrap is only found natively in an area around Wilmington, North Carolina in the United States. It thrives in bogs, marshes, and wetlands and grows in wet sand and peaty soils. Because these environments are so depleted in nitrogen, they asphyxiate other flora, but the Flytrap overcomes this nutritional poverty by sourcing protein from its insect prey. One of the plants curious features is resilience to flame. It is speculated that the Flytrap evolved this to endure through periodic blazes and to act as a means of survival that its competition lacks. While the Venus Flytrap will not become extinct any time soon (an estimated 3-6 million plants are presently in cultivation), its natural existence is uncertain. In the last survey, only 35,800 Flytraps were found remaining in the wild, and some prominent conservationists have suggested the plant be given the status of vulnerable. Since this research is considerably dated, having taken place in 1992, the present number is considerably lower. The draining and destruction of natural wetlands where the Flytrap lives is considered to be the biggest threat to its existence, as well as people removing the plants from their natural habitat. Punitive measures have been introduced to prevent people from doing this. Ironically, while cultural depictions of perennial killers may persist, the bigger threat is not what meat-eating plants might do to us but what we may do to them.", "hypothesis": "The Venus Flytrap can withstand some exposure to fire.", "gold_label": "entailment"}
{"uid": "id_275", "premise": "Venus Flytrap From indigenous myths to John Wyndhams Day of the Triffids and the off-Broadway musical Little Shop of Horrors, the idea of cerebral, carnivorous flora has spooked audiences and readers for centuries. While shrubs and shoots have yet to uproot themselves or show any interest in human beings, however, for some of earths smaller inhabitants arachnids and insects the risk of being trapped and ingested by a plant can be a threat to their daily existence. Easily, the most famous of these predators is the Venus Flytrap, one of only two types of snap traps in the world. Though rarely found growing wild, the Flytrap has captured popular imagination and can be purchased in florists and plant retailers around the world. Part of the Venus Flytraps mysterious aura begins with the tide itself. While it is fairly clear that the second half of the epithet has been given for its insect-trapping ability, the origin of Venus is somewhat more ambiguous. According to the International Carnivorous Plant Society, the plant was first studied in the 17th and 18th centuries, when puritanical mores ruled Western societies and obsession was rife with forbidden human impulses and urges, women were often portrayed in these times as seductresses and temptresses, and botanists are believed to have seen a parallel between the behaviour of the plant in luring and devouring insects and the imagined behaviour of women in luring and trapping witless men. The plant was thus named after the pagan goddess of love and money Venus. The Venus Flytrap is a small plant with six to seven leaves growing out of a bulb-like stem. At the end of each leaf is a trap, which is an opened pod with cilia around the edges like stiff eyelashes. The pod is lined with anthocyanin pigments and sweet-smelling sap to attract flies and other insects. When they fly in, trigger hairs inside the pod sense the intruders movement, and the pod snaps shut. The trigger mechanism is so sophisticated that the plant can differentiate between living creatures and non-edible debris by requiring two trigger hairs to be touched within twenty seconds of each other, or one hair to be touched in quick succession. The plant has no nervous system, and researchers can only hypothesise as to how the rapid shutting movement works. This uncertainty adds to the Venus Flytraps allure. The pod shuts quickly but does not seal entirely at first; scientists have found that tins mechanism allows miniscule insects to escape, as they will not be a source of useful nourishment for the plant. If the creature is large enough, however, the plants flaps will eventually meet to form an airtight compress, and at this point, the digestive process begins. A Venus Flytraps digestive system is remarkably similar to how a human stomach works. For somewhere between five and twelve days, the trap secretes acidic digestive juices that dissolve the soft tissue and cell membranes of the insect. These juices also kill any bacteria that have entered with the food, ensuring the plant maintains its hygiene so that it does not begin to rot. Enzymes in the acid help with the digestion of DNA, amino acids, and cell molecules so that every fleshy part of the animal can be consumed. Once the plant has reabsorbed the digestive fluid this time with the added nourishment, the trap reopens and the exoskeleton blows away in the wind. Although transplanted to other locations around the world, the Venus Flytrap is only found natively in an area around Wilmington, North Carolina in the United States. It thrives in bogs, marshes, and wetlands and grows in wet sand and peaty soils. Because these environments are so depleted in nitrogen, they asphyxiate other flora, but the Flytrap overcomes this nutritional poverty by sourcing protein from its insect prey. One of the plants curious features is resilience to flame. It is speculated that the Flytrap evolved this to endure through periodic blazes and to act as a means of survival that its competition lacks. While the Venus Flytrap will not become extinct any time soon (an estimated 3-6 million plants are presently in cultivation), its natural existence is uncertain. In the last survey, only 35,800 Flytraps were found remaining in the wild, and some prominent conservationists have suggested the plant be given the status of vulnerable. Since this research is considerably dated, having taken place in 1992, the present number is considerably lower. The draining and destruction of natural wetlands where the Flytrap lives is considered to be the biggest threat to its existence, as well as people removing the plants from their natural habitat. Punitive measures have been introduced to prevent people from doing this. Ironically, while cultural depictions of perennial killers may persist, the bigger threat is not what meat-eating plants might do to us but what we may do to them.", "hypothesis": "Only 35,800 Venus Flytraps now survive in their natural habitats.", "gold_label": "contradiction"}
{"uid": "id_276", "premise": "Venus Flytrap From indigenous myths to John Wyndhams Day of the Triffids and the off-Broadway musical Little Shop of Horrors, the idea of cerebral, carnivorous flora has spooked audiences and readers for centuries. While shrubs and shoots have yet to uproot themselves or show any interest in human beings, however, for some of earths smaller inhabitants arachnids and insects the risk of being trapped and ingested by a plant can be a threat to their daily existence. Easily, the most famous of these predators is the Venus Flytrap, one of only two types of snap traps in the world. Though rarely found growing wild, the Flytrap has captured popular imagination and can be purchased in florists and plant retailers around the world. Part of the Venus Flytraps mysterious aura begins with the tide itself. While it is fairly clear that the second half of the epithet has been given for its insect-trapping ability, the origin of Venus is somewhat more ambiguous. According to the International Carnivorous Plant Society, the plant was first studied in the 17th and 18th centuries, when puritanical mores ruled Western societies and obsession was rife with forbidden human impulses and urges, women were often portrayed in these times as seductresses and temptresses, and botanists are believed to have seen a parallel between the behaviour of the plant in luring and devouring insects and the imagined behaviour of women in luring and trapping witless men. The plant was thus named after the pagan goddess of love and money Venus. The Venus Flytrap is a small plant with six to seven leaves growing out of a bulb-like stem. At the end of each leaf is a trap, which is an opened pod with cilia around the edges like stiff eyelashes. The pod is lined with anthocyanin pigments and sweet-smelling sap to attract flies and other insects. When they fly in, trigger hairs inside the pod sense the intruders movement, and the pod snaps shut. The trigger mechanism is so sophisticated that the plant can differentiate between living creatures and non-edible debris by requiring two trigger hairs to be touched within twenty seconds of each other, or one hair to be touched in quick succession. The plant has no nervous system, and researchers can only hypothesise as to how the rapid shutting movement works. This uncertainty adds to the Venus Flytraps allure. The pod shuts quickly but does not seal entirely at first; scientists have found that tins mechanism allows miniscule insects to escape, as they will not be a source of useful nourishment for the plant. If the creature is large enough, however, the plants flaps will eventually meet to form an airtight compress, and at this point, the digestive process begins. A Venus Flytraps digestive system is remarkably similar to how a human stomach works. For somewhere between five and twelve days, the trap secretes acidic digestive juices that dissolve the soft tissue and cell membranes of the insect. These juices also kill any bacteria that have entered with the food, ensuring the plant maintains its hygiene so that it does not begin to rot. Enzymes in the acid help with the digestion of DNA, amino acids, and cell molecules so that every fleshy part of the animal can be consumed. Once the plant has reabsorbed the digestive fluid this time with the added nourishment, the trap reopens and the exoskeleton blows away in the wind. Although transplanted to other locations around the world, the Venus Flytrap is only found natively in an area around Wilmington, North Carolina in the United States. It thrives in bogs, marshes, and wetlands and grows in wet sand and peaty soils. Because these environments are so depleted in nitrogen, they asphyxiate other flora, but the Flytrap overcomes this nutritional poverty by sourcing protein from its insect prey. One of the plants curious features is resilience to flame. It is speculated that the Flytrap evolved this to endure through periodic blazes and to act as a means of survival that its competition lacks. While the Venus Flytrap will not become extinct any time soon (an estimated 3-6 million plants are presently in cultivation), its natural existence is uncertain. In the last survey, only 35,800 Flytraps were found remaining in the wild, and some prominent conservationists have suggested the plant be given the status of vulnerable. Since this research is considerably dated, having taken place in 1992, the present number is considerably lower. The draining and destruction of natural wetlands where the Flytrap lives is considered to be the biggest threat to its existence, as well as people removing the plants from their natural habitat. Punitive measures have been introduced to prevent people from doing this. Ironically, while cultural depictions of perennial killers may persist, the bigger threat is not what meat-eating plants might do to us but what we may do to them.", "hypothesis": "Human interference is a major factor in the decline of wild Venus Flytraps.", "gold_label": "entailment"}
{"uid": "id_277", "premise": "Venus in Transit On 8 June 2004, more than half the population of the world were treated to a rare astronomical event. For over six hours, the planet Venus steadily inched its way over the surface of the Sun. This transit of Venus was the first since 6 December 1882. On that occasion, the American astronomer Professor Simon Newcomb led a party to South Africa to observe the event. They were based at a girls school, where it is alleged the combined forces of three schoolmistresses outperformed the professionals with the accuracy of their observations. For centuries, transits of Venus have drawn explorers and astronomers alike to the four corners of the globe. And you can put it all down to the extraordinary polymath Edmond Halley. In November 1677, Halley observed a transit of the innermost planet, Mercury, from the desolate island of St Helena in the South Pacific. He realised that, from different latitudes, the passage of the planet across the Suns disc would appear to differ. By timing the transit from two widely-separated locations, teams of astronomers could calculate the parallax angle the apparent difference in position of an astronomical body due to a difference in the observers position. Calculating this angle would allow astronomers to measure what was then the ultimate goal: the distance of the Earth from the Sun. This distance is known as the astronomical unit or AU. Halley was aware that the AU was one of the most fundamental of all astronomical measurements. Johannes Kepler, in the early 17th century, had shown that the distances of the planets from the Sun governed their orbital speeds, which were easily measurable. But no-one had found a way to calculate accurate distances to the planets from the Earth. The goal was to measure the AU; then, knowing the orbital speeds of all the other planets round the Sun, the scale of the Solar System would fall into place. However, Halley realised that Mercury was so far away that its parallax angle would be very difficult to determine. As Venus was closer to the Earth, its parallax angle would be larger, and Halley worked out that by using Venus it would be possible to measure the Suns distance to 1 part in 500. But there was a problem: transits of Venus, unlike those of Mercury, are rare, occurring in pairs roughly eight years apart every hundred or so years. Nevertheless, he accurately predicted that Venus would cross the face of the Sun in both 1761 and 1769 though he didnt survive to see either. Inspired by Halleys suggestion of a way to pin down the scale of the Solar System, teams of British and French astronomers set out on expeditions to places as diverse as India and Siberia. But things werent helped by Britain and France being at war. The person who deserves most sympathy is the French astronomer Guillaume Le Gentil. He was thwarted by the fact that the British were besieging his observation site at Pondicherry in India. Fleeing on a French warship crossing the Indian Ocean, Le Gentil saw a wonderful transit but the ships pitching and rolling ruled out any attempt at making accurate observations. Undaunted, he remained south of the equator, keeping himself busy by studying the islands of Mauritius and Madagascar before setting off to observe the next transit in the Philippines. Ironically after travelling nearly 50,000 kilometres, his view was clouded out at the last moment, a very dispiriting experience. While the early transit timings were as precise as instruments would allow, the measurements were dogged by the black drop effect. When Venus begins to cross the Suns disc, it looks smeared not circular which makes it difficult to establish timings. This is due to diffraction of light. The second problem is that Venus exhibits a halo of light when it is seen just outside the Suns disc. While this showed astronomers that Venus was surrounded by a thick layer of gases refracting sunlight around it, both effects made it impossible to obtain accurate timings. But astronomers laboured hard to analyse the results of these expeditions to observe Venus transits. Johann Franz Encke, Director of the Berlin Observatory, finally determined a value for the AU based on all these parallax measurements: 153,340,000 km. Reasonably accurate for the time, that is quite close to todays value of 149,597,870 km, determined by radar, which has now superseded transits and all other methods in accuracy. The AU is a cosmic measuring rod, and the basis of how we scale the Universe today. The parallax principle can be extended to measure the distances to the stars. If we look at a star in January when Earth is at one point in its orbit it will seem to be in a different position from where it appears six months later. Knowing the width of Earths orbit, the parallax shift lets astronomers calculate the distance. June 2004s transit of Venus was thus more of an astronomical spectacle than a scientifically important event. But such transits have paved the way for what might prove to be one of the most vital breakthroughs in the cosmos detecting Earth-sized planets orbiting other stars.", "hypothesis": "Le Gentil managed to observe a second Venus transit.", "gold_label": "contradiction"}
{"uid": "id_278", "premise": "Venus in Transit On 8 June 2004, more than half the population of the world were treated to a rare astronomical event. For over six hours, the planet Venus steadily inched its way over the surface of the Sun. This transit of Venus was the first since 6 December 1882. On that occasion, the American astronomer Professor Simon Newcomb led a party to South Africa to observe the event. They were based at a girls school, where it is alleged the combined forces of three schoolmistresses outperformed the professionals with the accuracy of their observations. For centuries, transits of Venus have drawn explorers and astronomers alike to the four corners of the globe. And you can put it all down to the extraordinary polymath Edmond Halley. In November 1677, Halley observed a transit of the innermost planet, Mercury, from the desolate island of St Helena in the South Pacific. He realised that, from different latitudes, the passage of the planet across the Suns disc would appear to differ. By timing the transit from two widely-separated locations, teams of astronomers could calculate the parallax angle the apparent difference in position of an astronomical body due to a difference in the observers position. Calculating this angle would allow astronomers to measure what was then the ultimate goal: the distance of the Earth from the Sun. This distance is known as the astronomical unit or AU. Halley was aware that the AU was one of the most fundamental of all astronomical measurements. Johannes Kepler, in the early 17th century, had shown that the distances of the planets from the Sun governed their orbital speeds, which were easily measurable. But no-one had found a way to calculate accurate distances to the planets from the Earth. The goal was to measure the AU; then, knowing the orbital speeds of all the other planets round the Sun, the scale of the Solar System would fall into place. However, Halley realised that Mercury was so far away that its parallax angle would be very difficult to determine. As Venus was closer to the Earth, its parallax angle would be larger, and Halley worked out that by using Venus it would be possible to measure the Suns distance to 1 part in 500. But there was a problem: transits of Venus, unlike those of Mercury, are rare, occurring in pairs roughly eight years apart every hundred or so years. Nevertheless, he accurately predicted that Venus would cross the face of the Sun in both 1761 and 1769 though he didnt survive to see either. Inspired by Halleys suggestion of a way to pin down the scale of the Solar System, teams of British and French astronomers set out on expeditions to places as diverse as India and Siberia. But things werent helped by Britain and France being at war. The person who deserves most sympathy is the French astronomer Guillaume Le Gentil. He was thwarted by the fact that the British were besieging his observation site at Pondicherry in India. Fleeing on a French warship crossing the Indian Ocean, Le Gentil saw a wonderful transit but the ships pitching and rolling ruled out any attempt at making accurate observations. Undaunted, he remained south of the equator, keeping himself busy by studying the islands of Mauritius and Madagascar before setting off to observe the next transit in the Philippines. Ironically after travelling nearly 50,000 kilometres, his view was clouded out at the last moment, a very dispiriting experience. While the early transit timings were as precise as instruments would allow, the measurements were dogged by the black drop effect. When Venus begins to cross the Suns disc, it looks smeared not circular which makes it difficult to establish timings. This is due to diffraction of light. The second problem is that Venus exhibits a halo of light when it is seen just outside the Suns disc. While this showed astronomers that Venus was surrounded by a thick layer of gases refracting sunlight around it, both effects made it impossible to obtain accurate timings. But astronomers laboured hard to analyse the results of these expeditions to observe Venus transits. Johann Franz Encke, Director of the Berlin Observatory, finally determined a value for the AU based on all these parallax measurements: 153,340,000 km. Reasonably accurate for the time, that is quite close to todays value of 149,597,870 km, determined by radar, which has now superseded transits and all other methods in accuracy. The AU is a cosmic measuring rod, and the basis of how we scale the Universe today. The parallax principle can be extended to measure the distances to the stars. If we look at a star in January when Earth is at one point in its orbit it will seem to be in a different position from where it appears six months later. Knowing the width of Earths orbit, the parallax shift lets astronomers calculate the distance. June 2004s transit of Venus was thus more of an astronomical spectacle than a scientifically important event. But such transits have paved the way for what might prove to be one of the most vital breakthroughs in the cosmos detecting Earth-sized planets orbiting other stars.", "hypothesis": "Halley observed one transit of the planet Venus.", "gold_label": "contradiction"}
{"uid": "id_279", "premise": "Venus in Transit On 8 June 2004, more than half the population of the world were treated to a rare astronomical event. For over six hours, the planet Venus steadily inched its way over the surface of the Sun. This transit of Venus was the first since 6 December 1882. On that occasion, the American astronomer Professor Simon Newcomb led a party to South Africa to observe the event. They were based at a girls school, where it is alleged the combined forces of three schoolmistresses outperformed the professionals with the accuracy of their observations. For centuries, transits of Venus have drawn explorers and astronomers alike to the four corners of the globe. And you can put it all down to the extraordinary polymath Edmond Halley. In November 1677, Halley observed a transit of the innermost planet, Mercury, from the desolate island of St Helena in the South Pacific. He realised that, from different latitudes, the passage of the planet across the Suns disc would appear to differ. By timing the transit from two widely-separated locations, teams of astronomers could calculate the parallax angle the apparent difference in position of an astronomical body due to a difference in the observers position. Calculating this angle would allow astronomers to measure what was then the ultimate goal: the distance of the Earth from the Sun. This distance is known as the astronomical unit or AU. Halley was aware that the AU was one of the most fundamental of all astronomical measurements. Johannes Kepler, in the early 17th century, had shown that the distances of the planets from the Sun governed their orbital speeds, which were easily measurable. But no-one had found a way to calculate accurate distances to the planets from the Earth. The goal was to measure the AU; then, knowing the orbital speeds of all the other planets round the Sun, the scale of the Solar System would fall into place. However, Halley realised that Mercury was so far away that its parallax angle would be very difficult to determine. As Venus was closer to the Earth, its parallax angle would be larger, and Halley worked out that by using Venus it would be possible to measure the Suns distance to 1 part in 500. But there was a problem: transits of Venus, unlike those of Mercury, are rare, occurring in pairs roughly eight years apart every hundred or so years. Nevertheless, he accurately predicted that Venus would cross the face of the Sun in both 1761 and 1769 though he didnt survive to see either. Inspired by Halleys suggestion of a way to pin down the scale of the Solar System, teams of British and French astronomers set out on expeditions to places as diverse as India and Siberia. But things werent helped by Britain and France being at war. The person who deserves most sympathy is the French astronomer Guillaume Le Gentil. He was thwarted by the fact that the British were besieging his observation site at Pondicherry in India. Fleeing on a French warship crossing the Indian Ocean, Le Gentil saw a wonderful transit but the ships pitching and rolling ruled out any attempt at making accurate observations. Undaunted, he remained south of the equator, keeping himself busy by studying the islands of Mauritius and Madagascar before setting off to observe the next transit in the Philippines. Ironically after travelling nearly 50,000 kilometres, his view was clouded out at the last moment, a very dispiriting experience. While the early transit timings were as precise as instruments would allow, the measurements were dogged by the black drop effect. When Venus begins to cross the Suns disc, it looks smeared not circular which makes it difficult to establish timings. This is due to diffraction of light. The second problem is that Venus exhibits a halo of light when it is seen just outside the Suns disc. While this showed astronomers that Venus was surrounded by a thick layer of gases refracting sunlight around it, both effects made it impossible to obtain accurate timings. But astronomers laboured hard to analyse the results of these expeditions to observe Venus transits. Johann Franz Encke, Director of the Berlin Observatory, finally determined a value for the AU based on all these parallax measurements: 153,340,000 km. Reasonably accurate for the time, that is quite close to todays value of 149,597,870 km, determined by radar, which has now superseded transits and all other methods in accuracy. The AU is a cosmic measuring rod, and the basis of how we scale the Universe today. The parallax principle can be extended to measure the distances to the stars. If we look at a star in January when Earth is at one point in its orbit it will seem to be in a different position from where it appears six months later. Knowing the width of Earths orbit, the parallax shift lets astronomers calculate the distance. June 2004s transit of Venus was thus more of an astronomical spectacle than a scientifically important event. But such transits have paved the way for what might prove to be one of the most vital breakthroughs in the cosmos detecting Earth-sized planets orbiting other stars.", "hypothesis": "Early astronomers suspected that the atmosphere on Venus was toxic.", "gold_label": "neutral"}
{"uid": "id_280", "premise": "Venus in Transit On 8 June 2004, more than half the population of the world were treated to a rare astronomical event. For over six hours, the planet Venus steadily inched its way over the surface of the Sun. This transit of Venus was the first since 6 December 1882. On that occasion, the American astronomer Professor Simon Newcomb led a party to South Africa to observe the event. They were based at a girls school, where it is alleged the combined forces of three schoolmistresses outperformed the professionals with the accuracy of their observations. For centuries, transits of Venus have drawn explorers and astronomers alike to the four corners of the globe. And you can put it all down to the extraordinary polymath Edmond Halley. In November 1677, Halley observed a transit of the innermost planet, Mercury, from the desolate island of St Helena in the South Pacific. He realised that, from different latitudes, the passage of the planet across the Suns disc would appear to differ. By timing the transit from two widely-separated locations, teams of astronomers could calculate the parallax angle the apparent difference in position of an astronomical body due to a difference in the observers position. Calculating this angle would allow astronomers to measure what was then the ultimate goal: the distance of the Earth from the Sun. This distance is known as the astronomical unit or AU. Halley was aware that the AU was one of the most fundamental of all astronomical measurements. Johannes Kepler, in the early 17th century, had shown that the distances of the planets from the Sun governed their orbital speeds, which were easily measurable. But no-one had found a way to calculate accurate distances to the planets from the Earth. The goal was to measure the AU; then, knowing the orbital speeds of all the other planets round the Sun, the scale of the Solar System would fall into place. However, Halley realised that Mercury was so far away that its parallax angle would be very difficult to determine. As Venus was closer to the Earth, its parallax angle would be larger, and Halley worked out that by using Venus it would be possible to measure the Suns distance to 1 part in 500. But there was a problem: transits of Venus, unlike those of Mercury, are rare, occurring in pairs roughly eight years apart every hundred or so years. Nevertheless, he accurately predicted that Venus would cross the face of the Sun in both 1761 and 1769 though he didnt survive to see either. Inspired by Halleys suggestion of a way to pin down the scale of the Solar System, teams of British and French astronomers set out on expeditions to places as diverse as India and Siberia. But things werent helped by Britain and France being at war. The person who deserves most sympathy is the French astronomer Guillaume Le Gentil. He was thwarted by the fact that the British were besieging his observation site at Pondicherry in India. Fleeing on a French warship crossing the Indian Ocean, Le Gentil saw a wonderful transit but the ships pitching and rolling ruled out any attempt at making accurate observations. Undaunted, he remained south of the equator, keeping himself busy by studying the islands of Mauritius and Madagascar before setting off to observe the next transit in the Philippines. Ironically after travelling nearly 50,000 kilometres, his view was clouded out at the last moment, a very dispiriting experience. While the early transit timings were as precise as instruments would allow, the measurements were dogged by the black drop effect. When Venus begins to cross the Suns disc, it looks smeared not circular which makes it difficult to establish timings. This is due to diffraction of light. The second problem is that Venus exhibits a halo of light when it is seen just outside the Suns disc. While this showed astronomers that Venus was surrounded by a thick layer of gases refracting sunlight around it, both effects made it impossible to obtain accurate timings. But astronomers laboured hard to analyse the results of these expeditions to observe Venus transits. Johann Franz Encke, Director of the Berlin Observatory, finally determined a value for the AU based on all these parallax measurements: 153,340,000 km. Reasonably accurate for the time, that is quite close to todays value of 149,597,870 km, determined by radar, which has now superseded transits and all other methods in accuracy. The AU is a cosmic measuring rod, and the basis of how we scale the Universe today. The parallax principle can be extended to measure the distances to the stars. If we look at a star in January when Earth is at one point in its orbit it will seem to be in a different position from where it appears six months later. Knowing the width of Earths orbit, the parallax shift lets astronomers calculate the distance. June 2004s transit of Venus was thus more of an astronomical spectacle than a scientifically important event. But such transits have paved the way for what might prove to be one of the most vital breakthroughs in the cosmos detecting Earth-sized planets orbiting other stars.", "hypothesis": "The shape of Venus appears distorted when it starts to pass in front of the Sun.", "gold_label": "entailment"}
{"uid": "id_281", "premise": "Venus in Transit On 8 June 2004, more than half the population of the world were treated to a rare astronomical event. For over six hours, the planet Venus steadily inched its way over the surface of the Sun. This transit of Venus was the first since 6 December 1882. On that occasion, the American astronomer Professor Simon Newcomb led a party to South Africa to observe the event. They were based at a girls school, where it is alleged the combined forces of three schoolmistresses outperformed the professionals with the accuracy of their observations. For centuries, transits of Venus have drawn explorers and astronomers alike to the four corners of the globe. And you can put it all down to the extraordinary polymath Edmond Halley. In November 1677, Halley observed a transit of the innermost planet, Mercury, from the desolate island of St Helena in the South Pacific. He realised that, from different latitudes, the passage of the planet across the Suns disc would appear to differ. By timing the transit from two widely-separated locations, teams of astronomers could calculate the parallax angle the apparent difference in position of an astronomical body due to a difference in the observers position. Calculating this angle would allow astronomers to measure what was then the ultimate goal: the distance of the Earth from the Sun. This distance is known as the astronomical unit or AU. Halley was aware that the AU was one of the most fundamental of all astronomical measurements. Johannes Kepler, in the early 17th century, had shown that the distances of the planets from the Sun governed their orbital speeds, which were easily measurable. But no-one had found a way to calculate accurate distances to the planets from the Earth. The goal was to measure the AU; then, knowing the orbital speeds of all the other planets round the Sun, the scale of the Solar System would fall into place. However, Halley realised that Mercury was so far away that its parallax angle would be very difficult to determine. As Venus was closer to the Earth, its parallax angle would be larger, and Halley worked out that by using Venus it would be possible to measure the Suns distance to 1 part in 500. But there was a problem: transits of Venus, unlike those of Mercury, are rare, occurring in pairs roughly eight years apart every hundred or so years. Nevertheless, he accurately predicted that Venus would cross the face of the Sun in both 1761 and 1769 though he didnt survive to see either. Inspired by Halleys suggestion of a way to pin down the scale of the Solar System, teams of British and French astronomers set out on expeditions to places as diverse as India and Siberia. But things werent helped by Britain and France being at war. The person who deserves most sympathy is the French astronomer Guillaume Le Gentil. He was thwarted by the fact that the British were besieging his observation site at Pondicherry in India. Fleeing on a French warship crossing the Indian Ocean, Le Gentil saw a wonderful transit but the ships pitching and rolling ruled out any attempt at making accurate observations. Undaunted, he remained south of the equator, keeping himself busy by studying the islands of Mauritius and Madagascar before setting off to observe the next transit in the Philippines. Ironically after travelling nearly 50,000 kilometres, his view was clouded out at the last moment, a very dispiriting experience. While the early transit timings were as precise as instruments would allow, the measurements were dogged by the black drop effect. When Venus begins to cross the Suns disc, it looks smeared not circular which makes it difficult to establish timings. This is due to diffraction of light. The second problem is that Venus exhibits a halo of light when it is seen just outside the Suns disc. While this showed astronomers that Venus was surrounded by a thick layer of gases refracting sunlight around it, both effects made it impossible to obtain accurate timings. But astronomers laboured hard to analyse the results of these expeditions to observe Venus transits. Johann Franz Encke, Director of the Berlin Observatory, finally determined a value for the AU based on all these parallax measurements: 153,340,000 km. Reasonably accurate for the time, that is quite close to todays value of 149,597,870 km, determined by radar, which has now superseded transits and all other methods in accuracy. The AU is a cosmic measuring rod, and the basis of how we scale the Universe today. The parallax principle can be extended to measure the distances to the stars. If we look at a star in January when Earth is at one point in its orbit it will seem to be in a different position from where it appears six months later. Knowing the width of Earths orbit, the parallax shift lets astronomers calculate the distance. June 2004s transit of Venus was thus more of an astronomical spectacle than a scientifically important event. But such transits have paved the way for what might prove to be one of the most vital breakthroughs in the cosmos detecting Earth-sized planets orbiting other stars.", "hypothesis": "The parallax principle allows astronomers to work out how far away distant stars are from the Earth.", "gold_label": "entailment"}
{"uid": "id_282", "premise": "Venus in transit June 2004 saw the first passage, known as a transit, of the planet Venus across the face of the Sun in 122 years. Transits have helped shape our view of the whole Universe, as Heather Cooper and Nigel Henbest explain On 8 June 2004, more than half the population of the world were treated to a rare astronomical event. For over six hours, the planet Venus steadily inched its way over the surface of the Sun. This transit of Venus was the first since 6 December 1882. On that occasion, the American astronomer Professor Simon Newcomb led a party to South Africa to observe the event. They were based at a girls school, where - it is alleged - the combined forces of three schoolmistresses outperformed the professionals with the accuracy of their observations. For centuries, transits of Venus have drawn explorers and astronomers alike to the four corners of the globe. And you can put it all down to the extraordinary polymath Edmond Halley. In November 1677, Halley observed a transit of the innermost planet, Mercury, from the desolate island of St Helena in the South Pacific. He realised that, from different latitudes, the passage of the planet across the Suns disc would appear to differ. By timing the transit from two widely-separated locations, teams of astronomers could calculate the parallax angle - the apparent difference in position of an astronomical body due to a difference in the observers position. Calculating this angle would allow astronomers to measure what was then the ultimate goal: the distance of the Earth from the Sun. This distance is known as the astronomical unit or AU. Halley was aware that the AU was one of the most fundamental of all astronomical measurements. Johannes Kepler, in the early 17 th century, had shown that the distances of the planets from the Sun governed their orbital speeds, which were easily measurable. But no-one had found a way to calculate accurate distances to the planets from the Earth. The goal was to measure the AU; then, knowing the orbital speeds of all the other planets round the Sun, the scale of the Solar System would fall into place. However, Halley realised that Mercury was so far away that its parallax angle would be very difficult to determine. As Venus was closer to the Earth, its parallax angle would be larger, and Halley worked out that by using Venus it would be possible to measure the Suns distance to 1 part in 500. But there was a problem: transits of Venus, unlike those of Mercury, are rare, occurring in pairs roughly eight years apart every hundred or so years. Nevertheless, he accurately predicted that Venus would cross the face of the Sun in both 1761 and 1769 - though he didnt survive to see either. Inspired by Halleys suggestion of a way to pin down the scale of the Solar System, teams of British and French astronomers set out on expeditions to places as diverse as India and Siberia. But things werent helped by Britain and France being at war. The person who deserves most sympathy is the French astronomer Guillaume Le Gentil. He was thwarted by the fact that the British were besieging his observation site at Pondicherry in India. Fleeing on a French warship crossing the Indian Ocean, Le Gentil saw a wonderful transit - but the ships pitching and rolling ruled out any attempt at making accurate observations. Undaunted, he remained south of the equator, keeping himself busy by studying the islands of Mauritius and Madagascar before setting off to observe the next transit in the Philippines. Ironically after travelling nearly 50,000 kilometres, his view was clouded out at the last moment, a very dispiriting experience. While the early transit timings were as precise as instruments would allow, the measurements were dogged by the black drop effect. When Venus begins to cross the Suns disc, it looks smeared not circular - which 32makes it difficult to establish timings. This is due to diffraction of light. The second problem is that Venus exhibits a halo of light when it is seen just outside the Suns disc. While this showed astronomers that Venus was surrounded by a thick layer of gases refracting sunlight around it, both effects made it impossible to obtain accurate timings. But astronomers laboured hard to analyse the results of these expeditions to observe Venus transits. Johann Franz Encke, Director of the Berlin Observatory, finally determined a value for the AU based on all these parallax measurements: 153,340,000 km. Reasonably accurate for the time, that is quite close to todays value of 149,597,870 km, determined by radar, which has now superseded transits and all other methods in accuracy. The AU is a cosmic measuring rod, and the basis of how we scale the Universe today. The parallax principle can be extended to measure the distances to the stars. If we look at a star in January - when Earth is at one point in its orbit - it will seem to be in a different position from where it appears six months later. Knowing the width of Earths orbit, the parallax shift lets astronomers calculate the distance. June 2004s transit of Venus was thus more of an astronomical spectacle than a scientifically important event. But such transits have paved the way for what might prove to be one of the most vital breakthroughs in the cosmos - detecting Earth-sized planets orbiting other stars .", "hypothesis": "Halley observed one transit of the planet Venus.", "gold_label": "contradiction"}
{"uid": "id_283", "premise": "Venus in transit June 2004 saw the first passage, known as a transit, of the planet Venus across the face of the Sun in 122 years. Transits have helped shape our view of the whole Universe, as Heather Cooper and Nigel Henbest explain On 8 June 2004, more than half the population of the world were treated to a rare astronomical event. For over six hours, the planet Venus steadily inched its way over the surface of the Sun. This transit of Venus was the first since 6 December 1882. On that occasion, the American astronomer Professor Simon Newcomb led a party to South Africa to observe the event. They were based at a girls school, where - it is alleged - the combined forces of three schoolmistresses outperformed the professionals with the accuracy of their observations. For centuries, transits of Venus have drawn explorers and astronomers alike to the four corners of the globe. And you can put it all down to the extraordinary polymath Edmond Halley. In November 1677, Halley observed a transit of the innermost planet, Mercury, from the desolate island of St Helena in the South Pacific. He realised that, from different latitudes, the passage of the planet across the Suns disc would appear to differ. By timing the transit from two widely-separated locations, teams of astronomers could calculate the parallax angle - the apparent difference in position of an astronomical body due to a difference in the observers position. Calculating this angle would allow astronomers to measure what was then the ultimate goal: the distance of the Earth from the Sun. This distance is known as the astronomical unit or AU. Halley was aware that the AU was one of the most fundamental of all astronomical measurements. Johannes Kepler, in the early 17 th century, had shown that the distances of the planets from the Sun governed their orbital speeds, which were easily measurable. But no-one had found a way to calculate accurate distances to the planets from the Earth. The goal was to measure the AU; then, knowing the orbital speeds of all the other planets round the Sun, the scale of the Solar System would fall into place. However, Halley realised that Mercury was so far away that its parallax angle would be very difficult to determine. As Venus was closer to the Earth, its parallax angle would be larger, and Halley worked out that by using Venus it would be possible to measure the Suns distance to 1 part in 500. But there was a problem: transits of Venus, unlike those of Mercury, are rare, occurring in pairs roughly eight years apart every hundred or so years. Nevertheless, he accurately predicted that Venus would cross the face of the Sun in both 1761 and 1769 - though he didnt survive to see either. Inspired by Halleys suggestion of a way to pin down the scale of the Solar System, teams of British and French astronomers set out on expeditions to places as diverse as India and Siberia. But things werent helped by Britain and France being at war. The person who deserves most sympathy is the French astronomer Guillaume Le Gentil. He was thwarted by the fact that the British were besieging his observation site at Pondicherry in India. Fleeing on a French warship crossing the Indian Ocean, Le Gentil saw a wonderful transit - but the ships pitching and rolling ruled out any attempt at making accurate observations. Undaunted, he remained south of the equator, keeping himself busy by studying the islands of Mauritius and Madagascar before setting off to observe the next transit in the Philippines. Ironically after travelling nearly 50,000 kilometres, his view was clouded out at the last moment, a very dispiriting experience. While the early transit timings were as precise as instruments would allow, the measurements were dogged by the black drop effect. When Venus begins to cross the Suns disc, it looks smeared not circular - which 32makes it difficult to establish timings. This is due to diffraction of light. The second problem is that Venus exhibits a halo of light when it is seen just outside the Suns disc. While this showed astronomers that Venus was surrounded by a thick layer of gases refracting sunlight around it, both effects made it impossible to obtain accurate timings. But astronomers laboured hard to analyse the results of these expeditions to observe Venus transits. Johann Franz Encke, Director of the Berlin Observatory, finally determined a value for the AU based on all these parallax measurements: 153,340,000 km. Reasonably accurate for the time, that is quite close to todays value of 149,597,870 km, determined by radar, which has now superseded transits and all other methods in accuracy. The AU is a cosmic measuring rod, and the basis of how we scale the Universe today. The parallax principle can be extended to measure the distances to the stars. If we look at a star in January - when Earth is at one point in its orbit - it will seem to be in a different position from where it appears six months later. Knowing the width of Earths orbit, the parallax shift lets astronomers calculate the distance. June 2004s transit of Venus was thus more of an astronomical spectacle than a scientifically important event. But such transits have paved the way for what might prove to be one of the most vital breakthroughs in the cosmos - detecting Earth-sized planets orbiting other stars .", "hypothesis": "Le Gentil managed to observe a second Venus transit.", "gold_label": "contradiction"}
{"uid": "id_284", "premise": "Venus in transit June 2004 saw the first passage, known as a transit, of the planet Venus across the face of the Sun in 122 years. Transits have helped shape our view of the whole Universe, as Heather Cooper and Nigel Henbest explain On 8 June 2004, more than half the population of the world were treated to a rare astronomical event. For over six hours, the planet Venus steadily inched its way over the surface of the Sun. This transit of Venus was the first since 6 December 1882. On that occasion, the American astronomer Professor Simon Newcomb led a party to South Africa to observe the event. They were based at a girls school, where - it is alleged - the combined forces of three schoolmistresses outperformed the professionals with the accuracy of their observations. For centuries, transits of Venus have drawn explorers and astronomers alike to the four corners of the globe. And you can put it all down to the extraordinary polymath Edmond Halley. In November 1677, Halley observed a transit of the innermost planet, Mercury, from the desolate island of St Helena in the South Pacific. He realised that, from different latitudes, the passage of the planet across the Suns disc would appear to differ. By timing the transit from two widely-separated locations, teams of astronomers could calculate the parallax angle - the apparent difference in position of an astronomical body due to a difference in the observers position. Calculating this angle would allow astronomers to measure what was then the ultimate goal: the distance of the Earth from the Sun. This distance is known as the astronomical unit or AU. Halley was aware that the AU was one of the most fundamental of all astronomical measurements. Johannes Kepler, in the early 17 th century, had shown that the distances of the planets from the Sun governed their orbital speeds, which were easily measurable. But no-one had found a way to calculate accurate distances to the planets from the Earth. The goal was to measure the AU; then, knowing the orbital speeds of all the other planets round the Sun, the scale of the Solar System would fall into place. However, Halley realised that Mercury was so far away that its parallax angle would be very difficult to determine. As Venus was closer to the Earth, its parallax angle would be larger, and Halley worked out that by using Venus it would be possible to measure the Suns distance to 1 part in 500. But there was a problem: transits of Venus, unlike those of Mercury, are rare, occurring in pairs roughly eight years apart every hundred or so years. Nevertheless, he accurately predicted that Venus would cross the face of the Sun in both 1761 and 1769 - though he didnt survive to see either. Inspired by Halleys suggestion of a way to pin down the scale of the Solar System, teams of British and French astronomers set out on expeditions to places as diverse as India and Siberia. But things werent helped by Britain and France being at war. The person who deserves most sympathy is the French astronomer Guillaume Le Gentil. He was thwarted by the fact that the British were besieging his observation site at Pondicherry in India. Fleeing on a French warship crossing the Indian Ocean, Le Gentil saw a wonderful transit - but the ships pitching and rolling ruled out any attempt at making accurate observations. Undaunted, he remained south of the equator, keeping himself busy by studying the islands of Mauritius and Madagascar before setting off to observe the next transit in the Philippines. Ironically after travelling nearly 50,000 kilometres, his view was clouded out at the last moment, a very dispiriting experience. While the early transit timings were as precise as instruments would allow, the measurements were dogged by the black drop effect. When Venus begins to cross the Suns disc, it looks smeared not circular - which 32makes it difficult to establish timings. This is due to diffraction of light. The second problem is that Venus exhibits a halo of light when it is seen just outside the Suns disc. While this showed astronomers that Venus was surrounded by a thick layer of gases refracting sunlight around it, both effects made it impossible to obtain accurate timings. But astronomers laboured hard to analyse the results of these expeditions to observe Venus transits. Johann Franz Encke, Director of the Berlin Observatory, finally determined a value for the AU based on all these parallax measurements: 153,340,000 km. Reasonably accurate for the time, that is quite close to todays value of 149,597,870 km, determined by radar, which has now superseded transits and all other methods in accuracy. The AU is a cosmic measuring rod, and the basis of how we scale the Universe today. The parallax principle can be extended to measure the distances to the stars. If we look at a star in January - when Earth is at one point in its orbit - it will seem to be in a different position from where it appears six months later. Knowing the width of Earths orbit, the parallax shift lets astronomers calculate the distance. June 2004s transit of Venus was thus more of an astronomical spectacle than a scientifically important event. But such transits have paved the way for what might prove to be one of the most vital breakthroughs in the cosmos - detecting Earth-sized planets orbiting other stars .", "hypothesis": "Early astronomers suspected that the atmosphere on Venus was toxic.", "gold_label": "neutral"}
{"uid": "id_285", "premise": "Venus in transit June 2004 saw the first passage, known as a transit, of the planet Venus across the face of the Sun in 122 years. Transits have helped shape our view of the whole Universe, as Heather Cooper and Nigel Henbest explain On 8 June 2004, more than half the population of the world were treated to a rare astronomical event. For over six hours, the planet Venus steadily inched its way over the surface of the Sun. This transit of Venus was the first since 6 December 1882. On that occasion, the American astronomer Professor Simon Newcomb led a party to South Africa to observe the event. They were based at a girls school, where - it is alleged - the combined forces of three schoolmistresses outperformed the professionals with the accuracy of their observations. For centuries, transits of Venus have drawn explorers and astronomers alike to the four corners of the globe. And you can put it all down to the extraordinary polymath Edmond Halley. In November 1677, Halley observed a transit of the innermost planet, Mercury, from the desolate island of St Helena in the South Pacific. He realised that, from different latitudes, the passage of the planet across the Suns disc would appear to differ. By timing the transit from two widely-separated locations, teams of astronomers could calculate the parallax angle - the apparent difference in position of an astronomical body due to a difference in the observers position. Calculating this angle would allow astronomers to measure what was then the ultimate goal: the distance of the Earth from the Sun. This distance is known as the astronomical unit or AU. Halley was aware that the AU was one of the most fundamental of all astronomical measurements. Johannes Kepler, in the early 17 th century, had shown that the distances of the planets from the Sun governed their orbital speeds, which were easily measurable. But no-one had found a way to calculate accurate distances to the planets from the Earth. The goal was to measure the AU; then, knowing the orbital speeds of all the other planets round the Sun, the scale of the Solar System would fall into place. However, Halley realised that Mercury was so far away that its parallax angle would be very difficult to determine. As Venus was closer to the Earth, its parallax angle would be larger, and Halley worked out that by using Venus it would be possible to measure the Suns distance to 1 part in 500. But there was a problem: transits of Venus, unlike those of Mercury, are rare, occurring in pairs roughly eight years apart every hundred or so years. Nevertheless, he accurately predicted that Venus would cross the face of the Sun in both 1761 and 1769 - though he didnt survive to see either. Inspired by Halleys suggestion of a way to pin down the scale of the Solar System, teams of British and French astronomers set out on expeditions to places as diverse as India and Siberia. But things werent helped by Britain and France being at war. The person who deserves most sympathy is the French astronomer Guillaume Le Gentil. He was thwarted by the fact that the British were besieging his observation site at Pondicherry in India. Fleeing on a French warship crossing the Indian Ocean, Le Gentil saw a wonderful transit - but the ships pitching and rolling ruled out any attempt at making accurate observations. Undaunted, he remained south of the equator, keeping himself busy by studying the islands of Mauritius and Madagascar before setting off to observe the next transit in the Philippines. Ironically after travelling nearly 50,000 kilometres, his view was clouded out at the last moment, a very dispiriting experience. While the early transit timings were as precise as instruments would allow, the measurements were dogged by the black drop effect. When Venus begins to cross the Suns disc, it looks smeared not circular - which 32makes it difficult to establish timings. This is due to diffraction of light. The second problem is that Venus exhibits a halo of light when it is seen just outside the Suns disc. While this showed astronomers that Venus was surrounded by a thick layer of gases refracting sunlight around it, both effects made it impossible to obtain accurate timings. But astronomers laboured hard to analyse the results of these expeditions to observe Venus transits. Johann Franz Encke, Director of the Berlin Observatory, finally determined a value for the AU based on all these parallax measurements: 153,340,000 km. Reasonably accurate for the time, that is quite close to todays value of 149,597,870 km, determined by radar, which has now superseded transits and all other methods in accuracy. The AU is a cosmic measuring rod, and the basis of how we scale the Universe today. The parallax principle can be extended to measure the distances to the stars. If we look at a star in January - when Earth is at one point in its orbit - it will seem to be in a different position from where it appears six months later. Knowing the width of Earths orbit, the parallax shift lets astronomers calculate the distance. June 2004s transit of Venus was thus more of an astronomical spectacle than a scientifically important event. But such transits have paved the way for what might prove to be one of the most vital breakthroughs in the cosmos - detecting Earth-sized planets orbiting other stars .", "hypothesis": "The parallax principle allows astronomers to work out how far away distant stars are from the Earth.", "gold_label": "entailment"}
{"uid": "id_286", "premise": "Venus in transit June 2004 saw the first passage, known as a transit, of the planet Venus across the face of the Sun in 122 years. Transits have helped shape our view of the whole Universe, as Heather Cooper and Nigel Henbest explain On 8 June 2004, more than half the population of the world were treated to a rare astronomical event. For over six hours, the planet Venus steadily inched its way over the surface of the Sun. This transit of Venus was the first since 6 December 1882. On that occasion, the American astronomer Professor Simon Newcomb led a party to South Africa to observe the event. They were based at a girls school, where - it is alleged - the combined forces of three schoolmistresses outperformed the professionals with the accuracy of their observations. For centuries, transits of Venus have drawn explorers and astronomers alike to the four corners of the globe. And you can put it all down to the extraordinary polymath Edmond Halley. In November 1677, Halley observed a transit of the innermost planet, Mercury, from the desolate island of St Helena in the South Pacific. He realised that, from different latitudes, the passage of the planet across the Suns disc would appear to differ. By timing the transit from two widely-separated locations, teams of astronomers could calculate the parallax angle - the apparent difference in position of an astronomical body due to a difference in the observers position. Calculating this angle would allow astronomers to measure what was then the ultimate goal: the distance of the Earth from the Sun. This distance is known as the astronomical unit or AU. Halley was aware that the AU was one of the most fundamental of all astronomical measurements. Johannes Kepler, in the early 17 th century, had shown that the distances of the planets from the Sun governed their orbital speeds, which were easily measurable. But no-one had found a way to calculate accurate distances to the planets from the Earth. The goal was to measure the AU; then, knowing the orbital speeds of all the other planets round the Sun, the scale of the Solar System would fall into place. However, Halley realised that Mercury was so far away that its parallax angle would be very difficult to determine. As Venus was closer to the Earth, its parallax angle would be larger, and Halley worked out that by using Venus it would be possible to measure the Suns distance to 1 part in 500. But there was a problem: transits of Venus, unlike those of Mercury, are rare, occurring in pairs roughly eight years apart every hundred or so years. Nevertheless, he accurately predicted that Venus would cross the face of the Sun in both 1761 and 1769 - though he didnt survive to see either. Inspired by Halleys suggestion of a way to pin down the scale of the Solar System, teams of British and French astronomers set out on expeditions to places as diverse as India and Siberia. But things werent helped by Britain and France being at war. The person who deserves most sympathy is the French astronomer Guillaume Le Gentil. He was thwarted by the fact that the British were besieging his observation site at Pondicherry in India. Fleeing on a French warship crossing the Indian Ocean, Le Gentil saw a wonderful transit - but the ships pitching and rolling ruled out any attempt at making accurate observations. Undaunted, he remained south of the equator, keeping himself busy by studying the islands of Mauritius and Madagascar before setting off to observe the next transit in the Philippines. Ironically after travelling nearly 50,000 kilometres, his view was clouded out at the last moment, a very dispiriting experience. While the early transit timings were as precise as instruments would allow, the measurements were dogged by the black drop effect. When Venus begins to cross the Suns disc, it looks smeared not circular - which 32makes it difficult to establish timings. This is due to diffraction of light. The second problem is that Venus exhibits a halo of light when it is seen just outside the Suns disc. While this showed astronomers that Venus was surrounded by a thick layer of gases refracting sunlight around it, both effects made it impossible to obtain accurate timings. But astronomers laboured hard to analyse the results of these expeditions to observe Venus transits. Johann Franz Encke, Director of the Berlin Observatory, finally determined a value for the AU based on all these parallax measurements: 153,340,000 km. Reasonably accurate for the time, that is quite close to todays value of 149,597,870 km, determined by radar, which has now superseded transits and all other methods in accuracy. The AU is a cosmic measuring rod, and the basis of how we scale the Universe today. The parallax principle can be extended to measure the distances to the stars. If we look at a star in January - when Earth is at one point in its orbit - it will seem to be in a different position from where it appears six months later. Knowing the width of Earths orbit, the parallax shift lets astronomers calculate the distance. June 2004s transit of Venus was thus more of an astronomical spectacle than a scientifically important event. But such transits have paved the way for what might prove to be one of the most vital breakthroughs in the cosmos - detecting Earth-sized planets orbiting other stars .", "hypothesis": "The shape of Venus appears distorted when it starts to pass in front of the Sun.", "gold_label": "entailment"}
{"uid": "id_287", "premise": "Venus in transit. June 2004 saw the first passage, known as a transit, of the planet Venus across the face of the Sun in 122 years. Transits have helped shape our view of the whole Universe, as Heather Cooper and Nigel Henbest explain On 8 June 2004, more than half the population of the world were treated to a rare astronomical event. For over six hours, the planet Venus steadily inched its way over the surface of the Sun. This transit of Venus was the first since 6 December 1882. On that occasion, the American astronomer Professor Simon Newcomb led a party to South Africa to observe the event. They were based at girls school, where it is alleged the combined forces of three schoolmistresses outperformed the professionals with the accuracy of their observations. For centuries, transits of Venus have drawn explorers and astronomers alike to the four corners of the globe. And you can put it all down to the extraordinary polymath Edmond Halley. In November 1677, Halley observed a transit of the innermost planet, Mercury, from the desolate island of St Helena in the South Pacific. He realized that, from different latitudes, the passage of the planet across the Suns disc would appear to differ. By timing the transit from two widely-separated locations, teams of astronomers could calculate the parallax angle the apparent difference in position of an astronomical body due to a difference in the observers position. Calculating this angle would allow astronomers to measure what was then the ultimate goal: the distance of the Earth from the Sun. This distance is known as the astronomical unit or AU. Halley was aware that the AU was one of the most fundamental of all astronomical measurements. Johannes Kepler, in the early 17th century, had shown that the distances of the planets from the Sun governed their orbital speeds, which were easily measurable. But no-one had found a way to calculate accurate distances to the planets from the Earth. The goal was to measure the AU; then, knowing the orbital speeds of all the other planets round the Sun, the scale of the Solar System would fall into place. However, Halley realized that Mercury was so far away that its parallax angle would be very difficult to determine. As Venus was closer to the Earth, its parallax angle would be larger, and Halley worked out that by using Venus it would be possible to measure the Suns distance to 1 part in 500. But there was a problem: transits of Venus, unlike those of Mercury, are rare, occurring in pairs roughly eight years apart every hundred or so years. Nevertheless, he accurately predicted that Venus would cross the face of the Sun in both 1761 and 1769 though he didnt survive to see either. Inspired by Halleys suggestion of a way to pin down the scale of the Solar System, teams of British and French astronomers set out on expeditions to places as diverse as India and Siberia. But things werent helped by Britain and France being at war. The person who deserves most sympathy is the French astronomer Guillaume Le Gentil. He was thwarted by the fact that the British were besieging his observation site at Pondicherry in India. Fleeing on a French warship crossing the Indian Ocean, Le Gentil saw a wonderful transit but the ships pitching and rolling ruled out any attempt at making accurate observations. Undaunted, he remained south of the equator, keeping himself busy by studying the islands of Maurtius and Madagascar before setting off to observe the next transit in the Philippines. Ironically after travelling nearly 50,000 kilometres, his view was clouded out at the last moment, a very dispiriting experience. While the early transit timings were as precise as instruments would allow, the measurements were dogged by the black drop effect. When Venus begins to cross the Suns disc, it looks smeared not circular which makes it difficult to establish timings. This is due to diffraction of light. The second problem is that Venus exhibits a halo of light when it is seen just outside the suns disc. While this showed astronomers that Venus was surrounded by a thick layer of gases refracting sunlight around it, both effects made it impossible to obtain accurate timings. But astronomers laboured hard to analyse the results of these expeditions to observe Venus transits. Johann Franz Encke, Director of the Berlin Observatory, finally determined a value for the AU based on all these parallax measurements: 153,340,000 km. Reasonably accurate for the time, that is quite close to todays value of 149,597,870 km, determined by radar, which has now superseded transits and all other methods in accuracy. The AU is a cosmic measuring rod, and the basis of how we scale the Universe today. The parallax principle can be extended to measure the distances to the stars. If we look at a star in January when Earth is at one point in its orbit it will seem to be in a different position from where it appears six months late. Knowing the width of Earths orbit, the parallax shift lets astronomers calculate the distance. June 2004s transit of Venus was thus more of an astronomical spectacle than a scientifically important event. But such transits have paved the way for what might prove to be one of the most vital breakthroughs in the cosmos detecting Earth-sized planets orbiting other stars.", "hypothesis": "Le Gentil managed to observe a second Venus transit.", "gold_label": "contradiction"}
{"uid": "id_288", "premise": "Venus in transit. June 2004 saw the first passage, known as a transit, of the planet Venus across the face of the Sun in 122 years. Transits have helped shape our view of the whole Universe, as Heather Cooper and Nigel Henbest explain On 8 June 2004, more than half the population of the world were treated to a rare astronomical event. For over six hours, the planet Venus steadily inched its way over the surface of the Sun. This transit of Venus was the first since 6 December 1882. On that occasion, the American astronomer Professor Simon Newcomb led a party to South Africa to observe the event. They were based at girls school, where it is alleged the combined forces of three schoolmistresses outperformed the professionals with the accuracy of their observations. For centuries, transits of Venus have drawn explorers and astronomers alike to the four corners of the globe. And you can put it all down to the extraordinary polymath Edmond Halley. In November 1677, Halley observed a transit of the innermost planet, Mercury, from the desolate island of St Helena in the South Pacific. He realized that, from different latitudes, the passage of the planet across the Suns disc would appear to differ. By timing the transit from two widely-separated locations, teams of astronomers could calculate the parallax angle the apparent difference in position of an astronomical body due to a difference in the observers position. Calculating this angle would allow astronomers to measure what was then the ultimate goal: the distance of the Earth from the Sun. This distance is known as the astronomical unit or AU. Halley was aware that the AU was one of the most fundamental of all astronomical measurements. Johannes Kepler, in the early 17th century, had shown that the distances of the planets from the Sun governed their orbital speeds, which were easily measurable. But no-one had found a way to calculate accurate distances to the planets from the Earth. The goal was to measure the AU; then, knowing the orbital speeds of all the other planets round the Sun, the scale of the Solar System would fall into place. However, Halley realized that Mercury was so far away that its parallax angle would be very difficult to determine. As Venus was closer to the Earth, its parallax angle would be larger, and Halley worked out that by using Venus it would be possible to measure the Suns distance to 1 part in 500. But there was a problem: transits of Venus, unlike those of Mercury, are rare, occurring in pairs roughly eight years apart every hundred or so years. Nevertheless, he accurately predicted that Venus would cross the face of the Sun in both 1761 and 1769 though he didnt survive to see either. Inspired by Halleys suggestion of a way to pin down the scale of the Solar System, teams of British and French astronomers set out on expeditions to places as diverse as India and Siberia. But things werent helped by Britain and France being at war. The person who deserves most sympathy is the French astronomer Guillaume Le Gentil. He was thwarted by the fact that the British were besieging his observation site at Pondicherry in India. Fleeing on a French warship crossing the Indian Ocean, Le Gentil saw a wonderful transit but the ships pitching and rolling ruled out any attempt at making accurate observations. Undaunted, he remained south of the equator, keeping himself busy by studying the islands of Maurtius and Madagascar before setting off to observe the next transit in the Philippines. Ironically after travelling nearly 50,000 kilometres, his view was clouded out at the last moment, a very dispiriting experience. While the early transit timings were as precise as instruments would allow, the measurements were dogged by the black drop effect. When Venus begins to cross the Suns disc, it looks smeared not circular which makes it difficult to establish timings. This is due to diffraction of light. The second problem is that Venus exhibits a halo of light when it is seen just outside the suns disc. While this showed astronomers that Venus was surrounded by a thick layer of gases refracting sunlight around it, both effects made it impossible to obtain accurate timings. But astronomers laboured hard to analyse the results of these expeditions to observe Venus transits. Johann Franz Encke, Director of the Berlin Observatory, finally determined a value for the AU based on all these parallax measurements: 153,340,000 km. Reasonably accurate for the time, that is quite close to todays value of 149,597,870 km, determined by radar, which has now superseded transits and all other methods in accuracy. The AU is a cosmic measuring rod, and the basis of how we scale the Universe today. The parallax principle can be extended to measure the distances to the stars. If we look at a star in January when Earth is at one point in its orbit it will seem to be in a different position from where it appears six months late. Knowing the width of Earths orbit, the parallax shift lets astronomers calculate the distance. June 2004s transit of Venus was thus more of an astronomical spectacle than a scientifically important event. But such transits have paved the way for what might prove to be one of the most vital breakthroughs in the cosmos detecting Earth-sized planets orbiting other stars.", "hypothesis": "The parallax principle allows astronomers to work out how far away distant stars are from the Earth.", "gold_label": "entailment"}
{"uid": "id_289", "premise": "Venus in transit. June 2004 saw the first passage, known as a transit, of the planet Venus across the face of the Sun in 122 years. Transits have helped shape our view of the whole Universe, as Heather Cooper and Nigel Henbest explain On 8 June 2004, more than half the population of the world were treated to a rare astronomical event. For over six hours, the planet Venus steadily inched its way over the surface of the Sun. This transit of Venus was the first since 6 December 1882. On that occasion, the American astronomer Professor Simon Newcomb led a party to South Africa to observe the event. They were based at girls school, where it is alleged the combined forces of three schoolmistresses outperformed the professionals with the accuracy of their observations. For centuries, transits of Venus have drawn explorers and astronomers alike to the four corners of the globe. And you can put it all down to the extraordinary polymath Edmond Halley. In November 1677, Halley observed a transit of the innermost planet, Mercury, from the desolate island of St Helena in the South Pacific. He realized that, from different latitudes, the passage of the planet across the Suns disc would appear to differ. By timing the transit from two widely-separated locations, teams of astronomers could calculate the parallax angle the apparent difference in position of an astronomical body due to a difference in the observers position. Calculating this angle would allow astronomers to measure what was then the ultimate goal: the distance of the Earth from the Sun. This distance is known as the astronomical unit or AU. Halley was aware that the AU was one of the most fundamental of all astronomical measurements. Johannes Kepler, in the early 17th century, had shown that the distances of the planets from the Sun governed their orbital speeds, which were easily measurable. But no-one had found a way to calculate accurate distances to the planets from the Earth. The goal was to measure the AU; then, knowing the orbital speeds of all the other planets round the Sun, the scale of the Solar System would fall into place. However, Halley realized that Mercury was so far away that its parallax angle would be very difficult to determine. As Venus was closer to the Earth, its parallax angle would be larger, and Halley worked out that by using Venus it would be possible to measure the Suns distance to 1 part in 500. But there was a problem: transits of Venus, unlike those of Mercury, are rare, occurring in pairs roughly eight years apart every hundred or so years. Nevertheless, he accurately predicted that Venus would cross the face of the Sun in both 1761 and 1769 though he didnt survive to see either. Inspired by Halleys suggestion of a way to pin down the scale of the Solar System, teams of British and French astronomers set out on expeditions to places as diverse as India and Siberia. But things werent helped by Britain and France being at war. The person who deserves most sympathy is the French astronomer Guillaume Le Gentil. He was thwarted by the fact that the British were besieging his observation site at Pondicherry in India. Fleeing on a French warship crossing the Indian Ocean, Le Gentil saw a wonderful transit but the ships pitching and rolling ruled out any attempt at making accurate observations. Undaunted, he remained south of the equator, keeping himself busy by studying the islands of Maurtius and Madagascar before setting off to observe the next transit in the Philippines. Ironically after travelling nearly 50,000 kilometres, his view was clouded out at the last moment, a very dispiriting experience. While the early transit timings were as precise as instruments would allow, the measurements were dogged by the black drop effect. When Venus begins to cross the Suns disc, it looks smeared not circular which makes it difficult to establish timings. This is due to diffraction of light. The second problem is that Venus exhibits a halo of light when it is seen just outside the suns disc. While this showed astronomers that Venus was surrounded by a thick layer of gases refracting sunlight around it, both effects made it impossible to obtain accurate timings. But astronomers laboured hard to analyse the results of these expeditions to observe Venus transits. Johann Franz Encke, Director of the Berlin Observatory, finally determined a value for the AU based on all these parallax measurements: 153,340,000 km. Reasonably accurate for the time, that is quite close to todays value of 149,597,870 km, determined by radar, which has now superseded transits and all other methods in accuracy. The AU is a cosmic measuring rod, and the basis of how we scale the Universe today. The parallax principle can be extended to measure the distances to the stars. If we look at a star in January when Earth is at one point in its orbit it will seem to be in a different position from where it appears six months late. Knowing the width of Earths orbit, the parallax shift lets astronomers calculate the distance. June 2004s transit of Venus was thus more of an astronomical spectacle than a scientifically important event. But such transits have paved the way for what might prove to be one of the most vital breakthroughs in the cosmos detecting Earth-sized planets orbiting other stars.", "hypothesis": "Early astronomers suspected that the atmosphere on Venus was toxic.", "gold_label": "neutral"}
{"uid": "id_290", "premise": "Venus in transit. June 2004 saw the first passage, known as a transit, of the planet Venus across the face of the Sun in 122 years. Transits have helped shape our view of the whole Universe, as Heather Cooper and Nigel Henbest explain On 8 June 2004, more than half the population of the world were treated to a rare astronomical event. For over six hours, the planet Venus steadily inched its way over the surface of the Sun. This transit of Venus was the first since 6 December 1882. On that occasion, the American astronomer Professor Simon Newcomb led a party to South Africa to observe the event. They were based at girls school, where it is alleged the combined forces of three schoolmistresses outperformed the professionals with the accuracy of their observations. For centuries, transits of Venus have drawn explorers and astronomers alike to the four corners of the globe. And you can put it all down to the extraordinary polymath Edmond Halley. In November 1677, Halley observed a transit of the innermost planet, Mercury, from the desolate island of St Helena in the South Pacific. He realized that, from different latitudes, the passage of the planet across the Suns disc would appear to differ. By timing the transit from two widely-separated locations, teams of astronomers could calculate the parallax angle the apparent difference in position of an astronomical body due to a difference in the observers position. Calculating this angle would allow astronomers to measure what was then the ultimate goal: the distance of the Earth from the Sun. This distance is known as the astronomical unit or AU. Halley was aware that the AU was one of the most fundamental of all astronomical measurements. Johannes Kepler, in the early 17th century, had shown that the distances of the planets from the Sun governed their orbital speeds, which were easily measurable. But no-one had found a way to calculate accurate distances to the planets from the Earth. The goal was to measure the AU; then, knowing the orbital speeds of all the other planets round the Sun, the scale of the Solar System would fall into place. However, Halley realized that Mercury was so far away that its parallax angle would be very difficult to determine. As Venus was closer to the Earth, its parallax angle would be larger, and Halley worked out that by using Venus it would be possible to measure the Suns distance to 1 part in 500. But there was a problem: transits of Venus, unlike those of Mercury, are rare, occurring in pairs roughly eight years apart every hundred or so years. Nevertheless, he accurately predicted that Venus would cross the face of the Sun in both 1761 and 1769 though he didnt survive to see either. Inspired by Halleys suggestion of a way to pin down the scale of the Solar System, teams of British and French astronomers set out on expeditions to places as diverse as India and Siberia. But things werent helped by Britain and France being at war. The person who deserves most sympathy is the French astronomer Guillaume Le Gentil. He was thwarted by the fact that the British were besieging his observation site at Pondicherry in India. Fleeing on a French warship crossing the Indian Ocean, Le Gentil saw a wonderful transit but the ships pitching and rolling ruled out any attempt at making accurate observations. Undaunted, he remained south of the equator, keeping himself busy by studying the islands of Maurtius and Madagascar before setting off to observe the next transit in the Philippines. Ironically after travelling nearly 50,000 kilometres, his view was clouded out at the last moment, a very dispiriting experience. While the early transit timings were as precise as instruments would allow, the measurements were dogged by the black drop effect. When Venus begins to cross the Suns disc, it looks smeared not circular which makes it difficult to establish timings. This is due to diffraction of light. The second problem is that Venus exhibits a halo of light when it is seen just outside the suns disc. While this showed astronomers that Venus was surrounded by a thick layer of gases refracting sunlight around it, both effects made it impossible to obtain accurate timings. But astronomers laboured hard to analyse the results of these expeditions to observe Venus transits. Johann Franz Encke, Director of the Berlin Observatory, finally determined a value for the AU based on all these parallax measurements: 153,340,000 km. Reasonably accurate for the time, that is quite close to todays value of 149,597,870 km, determined by radar, which has now superseded transits and all other methods in accuracy. The AU is a cosmic measuring rod, and the basis of how we scale the Universe today. The parallax principle can be extended to measure the distances to the stars. If we look at a star in January when Earth is at one point in its orbit it will seem to be in a different position from where it appears six months late. Knowing the width of Earths orbit, the parallax shift lets astronomers calculate the distance. June 2004s transit of Venus was thus more of an astronomical spectacle than a scientifically important event. But such transits have paved the way for what might prove to be one of the most vital breakthroughs in the cosmos detecting Earth-sized planets orbiting other stars.", "hypothesis": "Halley observed one transit of the planet Venus.", "gold_label": "contradiction"}
{"uid": "id_291", "premise": "Venus in transit. June 2004 saw the first passage, known as a transit, of the planet Venus across the face of the Sun in 122 years. Transits have helped shape our view of the whole Universe, as Heather Cooper and Nigel Henbest explain On 8 June 2004, more than half the population of the world were treated to a rare astronomical event. For over six hours, the planet Venus steadily inched its way over the surface of the Sun. This transit of Venus was the first since 6 December 1882. On that occasion, the American astronomer Professor Simon Newcomb led a party to South Africa to observe the event. They were based at girls school, where it is alleged the combined forces of three schoolmistresses outperformed the professionals with the accuracy of their observations. For centuries, transits of Venus have drawn explorers and astronomers alike to the four corners of the globe. And you can put it all down to the extraordinary polymath Edmond Halley. In November 1677, Halley observed a transit of the innermost planet, Mercury, from the desolate island of St Helena in the South Pacific. He realized that, from different latitudes, the passage of the planet across the Suns disc would appear to differ. By timing the transit from two widely-separated locations, teams of astronomers could calculate the parallax angle the apparent difference in position of an astronomical body due to a difference in the observers position. Calculating this angle would allow astronomers to measure what was then the ultimate goal: the distance of the Earth from the Sun. This distance is known as the astronomical unit or AU. Halley was aware that the AU was one of the most fundamental of all astronomical measurements. Johannes Kepler, in the early 17th century, had shown that the distances of the planets from the Sun governed their orbital speeds, which were easily measurable. But no-one had found a way to calculate accurate distances to the planets from the Earth. The goal was to measure the AU; then, knowing the orbital speeds of all the other planets round the Sun, the scale of the Solar System would fall into place. However, Halley realized that Mercury was so far away that its parallax angle would be very difficult to determine. As Venus was closer to the Earth, its parallax angle would be larger, and Halley worked out that by using Venus it would be possible to measure the Suns distance to 1 part in 500. But there was a problem: transits of Venus, unlike those of Mercury, are rare, occurring in pairs roughly eight years apart every hundred or so years. Nevertheless, he accurately predicted that Venus would cross the face of the Sun in both 1761 and 1769 though he didnt survive to see either. Inspired by Halleys suggestion of a way to pin down the scale of the Solar System, teams of British and French astronomers set out on expeditions to places as diverse as India and Siberia. But things werent helped by Britain and France being at war. The person who deserves most sympathy is the French astronomer Guillaume Le Gentil. He was thwarted by the fact that the British were besieging his observation site at Pondicherry in India. Fleeing on a French warship crossing the Indian Ocean, Le Gentil saw a wonderful transit but the ships pitching and rolling ruled out any attempt at making accurate observations. Undaunted, he remained south of the equator, keeping himself busy by studying the islands of Maurtius and Madagascar before setting off to observe the next transit in the Philippines. Ironically after travelling nearly 50,000 kilometres, his view was clouded out at the last moment, a very dispiriting experience. While the early transit timings were as precise as instruments would allow, the measurements were dogged by the black drop effect. When Venus begins to cross the Suns disc, it looks smeared not circular which makes it difficult to establish timings. This is due to diffraction of light. The second problem is that Venus exhibits a halo of light when it is seen just outside the suns disc. While this showed astronomers that Venus was surrounded by a thick layer of gases refracting sunlight around it, both effects made it impossible to obtain accurate timings. But astronomers laboured hard to analyse the results of these expeditions to observe Venus transits. Johann Franz Encke, Director of the Berlin Observatory, finally determined a value for the AU based on all these parallax measurements: 153,340,000 km. Reasonably accurate for the time, that is quite close to todays value of 149,597,870 km, determined by radar, which has now superseded transits and all other methods in accuracy. The AU is a cosmic measuring rod, and the basis of how we scale the Universe today. The parallax principle can be extended to measure the distances to the stars. If we look at a star in January when Earth is at one point in its orbit it will seem to be in a different position from where it appears six months late. Knowing the width of Earths orbit, the parallax shift lets astronomers calculate the distance. June 2004s transit of Venus was thus more of an astronomical spectacle than a scientifically important event. But such transits have paved the way for what might prove to be one of the most vital breakthroughs in the cosmos detecting Earth-sized planets orbiting other stars.", "hypothesis": "The shape of Venus appears distorted when it starts to pass in front of the Sun.", "gold_label": "entailment"}
{"uid": "id_292", "premise": "Vertical transport A DEATH DEFYING STUNT THAT SHAPED THE SKYLINE OF THE WORLD A The raising of water from a well using a bucket suspended from a rope can be traced back to ancient times. If the rope was passed over a pulley wheel it made the lifting less strenuous. The method could be improved upon by attaching an empty bucket to the opposite end of the rope, then lowering it down the well as the full bucket came up, to counterbalance the weight. B Some medieval monasteries were perched on the tops of cliffs that could not be readily scaled. To overcome the problem, a basket was lowered to the base of the cliff on the end of a rope coiled round a wooden rod, known as a windlass. It was possible to lift heavy weights with a windlass, especially if a small cog wheel on the cranking handle drove a larger cog wheel on a second rod. Materials and people were hoisted in this fashion, but it was a slow process and if the rope were to break the basket plummeted to the ground. C In the middle of the nineteenth century the general public considered elevators supported by a rope to be too dangerous for personal use. Without an elevator, the height of a commercial building was limited by the number of steps people could be expected to climb within an economic time period. It was the American inventor and manufacturer Elisha Graves Otis (181161) who finally solved the problem of passenger elevators. D In 1852, Otis pioneered the idea of a safety brake, and two years later he demon strated it in spectacular fashion at the New York Crystal Palace Exhibition of Industry. Otis stood on the lifting platform, four storeys above an expectant crowd. The rope was cut, and after a small jolt, the platform came to a halt. Otis stunt increased peoples confidence in elevators and sales increased. E The operating principle of the safety elevator was described and illustrated in its pattern documentation of 1861. The lifting platform was suspended between two vertical posts each lined with a toothed guide rail. A hook was set into the sides of the platform to engage with the teeth, allowing movement vertically upwards but not downwards. Descent of the elevator was possible only if the hooks were pulled in, which could only happen when the rope was in tension. If the rope were to break, the tension would be lost and the hooks would spring outwards to engage the teeth and stop the fall. Modern elevators incorporate similar safety mechanisms. F Otis installed the first passenger elevator in a store in New York City in 1957. Following the success of the elevator, taller buildings were constructed, and sales increased once more as the business expanded into Europe. Englands first Otis passenger elevator (or lift as the British say) appeared four years later with the open ing of Londons Grosvenor Hotel. Today, the Otis Elevator Company continues to be the worlds leading manufacturer of elevators, employing over 60,000 people with markets in 200 countries. More significantly perhaps, the advent of passenger lifts marked the birth of the modern skyscraper. G Passenger elevators were powered by steam prior to 1902. A rope carrying the cab was wound round a revolving drum driven by a steam engine. The method was too slow for a tall building, which needed a large drum to hold a long coil of rope. By the following year, Otis had developed a compact electric traction elevator that used a cable but did away with the winding gear, allowing the passenger cab to be raised over 100 storeys both quickly and efficiently. H In the electric elevator, the cable was routed from the top of the passenger cab to a pulley wheel at the head of the lift shaft and then back down to a weight acting as a counterbalance. A geared-down electric motor rotated the pulley wheel, which contained a groove to grip the cable and provide the traction. Following the success of the electric elevator, skyscraper buildings began to spring up in the major cities. The Woolworths building in New York, constructed in 1913, was a significant land mark, being the worlds tallest building for the next 27 years. It had 57 floors and the Otis high-speed electric elevators could reach the top floor in a little over one minute. I Each elevator used several cables and pulley wheels, though one cable was enough to support the weight of the car. As a further safety feature, an oil-filled shock piston was mounted at the base of the lift shaft to act as a buffer, slowing the car down at a safe rate in the unlikely event of every cable failing as well as the safety brake.", "hypothesis": "Only people could be hoisted with a windlass.", "gold_label": "contradiction"}
{"uid": "id_293", "premise": "Vertical transport A DEATH DEFYING STUNT THAT SHAPED THE SKYLINE OF THE WORLD A The raising of water from a well using a bucket suspended from a rope can be traced back to ancient times. If the rope was passed over a pulley wheel it made the lifting less strenuous. The method could be improved upon by attaching an empty bucket to the opposite end of the rope, then lowering it down the well as the full bucket came up, to counterbalance the weight. B Some medieval monasteries were perched on the tops of cliffs that could not be readily scaled. To overcome the problem, a basket was lowered to the base of the cliff on the end of a rope coiled round a wooden rod, known as a windlass. It was possible to lift heavy weights with a windlass, especially if a small cog wheel on the cranking handle drove a larger cog wheel on a second rod. Materials and people were hoisted in this fashion, but it was a slow process and if the rope were to break the basket plummeted to the ground. C In the middle of the nineteenth century the general public considered elevators supported by a rope to be too dangerous for personal use. Without an elevator, the height of a commercial building was limited by the number of steps people could be expected to climb within an economic time period. It was the American inventor and manufacturer Elisha Graves Otis (181161) who finally solved the problem of passenger elevators. D In 1852, Otis pioneered the idea of a safety brake, and two years later he demon strated it in spectacular fashion at the New York Crystal Palace Exhibition of Industry. Otis stood on the lifting platform, four storeys above an expectant crowd. The rope was cut, and after a small jolt, the platform came to a halt. Otis stunt increased peoples confidence in elevators and sales increased. E The operating principle of the safety elevator was described and illustrated in its pattern documentation of 1861. The lifting platform was suspended between two vertical posts each lined with a toothed guide rail. A hook was set into the sides of the platform to engage with the teeth, allowing movement vertically upwards but not downwards. Descent of the elevator was possible only if the hooks were pulled in, which could only happen when the rope was in tension. If the rope were to break, the tension would be lost and the hooks would spring outwards to engage the teeth and stop the fall. Modern elevators incorporate similar safety mechanisms. F Otis installed the first passenger elevator in a store in New York City in 1957. Following the success of the elevator, taller buildings were constructed, and sales increased once more as the business expanded into Europe. Englands first Otis passenger elevator (or lift as the British say) appeared four years later with the open ing of Londons Grosvenor Hotel. Today, the Otis Elevator Company continues to be the worlds leading manufacturer of elevators, employing over 60,000 people with markets in 200 countries. More significantly perhaps, the advent of passenger lifts marked the birth of the modern skyscraper. G Passenger elevators were powered by steam prior to 1902. A rope carrying the cab was wound round a revolving drum driven by a steam engine. The method was too slow for a tall building, which needed a large drum to hold a long coil of rope. By the following year, Otis had developed a compact electric traction elevator that used a cable but did away with the winding gear, allowing the passenger cab to be raised over 100 storeys both quickly and efficiently. H In the electric elevator, the cable was routed from the top of the passenger cab to a pulley wheel at the head of the lift shaft and then back down to a weight acting as a counterbalance. A geared-down electric motor rotated the pulley wheel, which contained a groove to grip the cable and provide the traction. Following the success of the electric elevator, skyscraper buildings began to spring up in the major cities. The Woolworths building in New York, constructed in 1913, was a significant land mark, being the worlds tallest building for the next 27 years. It had 57 floors and the Otis high-speed electric elevators could reach the top floor in a little over one minute. I Each elevator used several cables and pulley wheels, though one cable was enough to support the weight of the car. As a further safety feature, an oil-filled shock piston was mounted at the base of the lift shaft to act as a buffer, slowing the car down at a safe rate in the unlikely event of every cable failing as well as the safety brake.", "hypothesis": "Tall commercial buildings were not economic without an elevator.", "gold_label": "entailment"}
{"uid": "id_294", "premise": "Vertical transport A DEATH DEFYING STUNT THAT SHAPED THE SKYLINE OF THE WORLD A The raising of water from a well using a bucket suspended from a rope can be traced back to ancient times. If the rope was passed over a pulley wheel it made the lifting less strenuous. The method could be improved upon by attaching an empty bucket to the opposite end of the rope, then lowering it down the well as the full bucket came up, to counterbalance the weight. B Some medieval monasteries were perched on the tops of cliffs that could not be readily scaled. To overcome the problem, a basket was lowered to the base of the cliff on the end of a rope coiled round a wooden rod, known as a windlass. It was possible to lift heavy weights with a windlass, especially if a small cog wheel on the cranking handle drove a larger cog wheel on a second rod. Materials and people were hoisted in this fashion, but it was a slow process and if the rope were to break the basket plummeted to the ground. C In the middle of the nineteenth century the general public considered elevators supported by a rope to be too dangerous for personal use. Without an elevator, the height of a commercial building was limited by the number of steps people could be expected to climb within an economic time period. It was the American inventor and manufacturer Elisha Graves Otis (181161) who finally solved the problem of passenger elevators. D In 1852, Otis pioneered the idea of a safety brake, and two years later he demon strated it in spectacular fashion at the New York Crystal Palace Exhibition of Industry. Otis stood on the lifting platform, four storeys above an expectant crowd. The rope was cut, and after a small jolt, the platform came to a halt. Otis stunt increased peoples confidence in elevators and sales increased. E The operating principle of the safety elevator was described and illustrated in its pattern documentation of 1861. The lifting platform was suspended between two vertical posts each lined with a toothed guide rail. A hook was set into the sides of the platform to engage with the teeth, allowing movement vertically upwards but not downwards. Descent of the elevator was possible only if the hooks were pulled in, which could only happen when the rope was in tension. If the rope were to break, the tension would be lost and the hooks would spring outwards to engage the teeth and stop the fall. Modern elevators incorporate similar safety mechanisms. F Otis installed the first passenger elevator in a store in New York City in 1957. Following the success of the elevator, taller buildings were constructed, and sales increased once more as the business expanded into Europe. Englands first Otis passenger elevator (or lift as the British say) appeared four years later with the open ing of Londons Grosvenor Hotel. Today, the Otis Elevator Company continues to be the worlds leading manufacturer of elevators, employing over 60,000 people with markets in 200 countries. More significantly perhaps, the advent of passenger lifts marked the birth of the modern skyscraper. G Passenger elevators were powered by steam prior to 1902. A rope carrying the cab was wound round a revolving drum driven by a steam engine. The method was too slow for a tall building, which needed a large drum to hold a long coil of rope. By the following year, Otis had developed a compact electric traction elevator that used a cable but did away with the winding gear, allowing the passenger cab to be raised over 100 storeys both quickly and efficiently. H In the electric elevator, the cable was routed from the top of the passenger cab to a pulley wheel at the head of the lift shaft and then back down to a weight acting as a counterbalance. A geared-down electric motor rotated the pulley wheel, which contained a groove to grip the cable and provide the traction. Following the success of the electric elevator, skyscraper buildings began to spring up in the major cities. The Woolworths building in New York, constructed in 1913, was a significant land mark, being the worlds tallest building for the next 27 years. It had 57 floors and the Otis high-speed electric elevators could reach the top floor in a little over one minute. I Each elevator used several cables and pulley wheels, though one cable was enough to support the weight of the car. As a further safety feature, an oil-filled shock piston was mounted at the base of the lift shaft to act as a buffer, slowing the car down at a safe rate in the unlikely event of every cable failing as well as the safety brake.", "hypothesis": "Otis pattern documents contained a diagram.", "gold_label": "entailment"}
{"uid": "id_295", "premise": "Vertical transport A DEATH DEFYING STUNT THAT SHAPED THE SKYLINE OF THE WORLD A The raising of water from a well using a bucket suspended from a rope can be traced back to ancient times. If the rope was passed over a pulley wheel it made the lifting less strenuous. The method could be improved upon by attaching an empty bucket to the opposite end of the rope, then lowering it down the well as the full bucket came up, to counterbalance the weight. B Some medieval monasteries were perched on the tops of cliffs that could not be readily scaled. To overcome the problem, a basket was lowered to the base of the cliff on the end of a rope coiled round a wooden rod, known as a windlass. It was possible to lift heavy weights with a windlass, especially if a small cog wheel on the cranking handle drove a larger cog wheel on a second rod. Materials and people were hoisted in this fashion, but it was a slow process and if the rope were to break the basket plummeted to the ground. C In the middle of the nineteenth century the general public considered elevators supported by a rope to be too dangerous for personal use. Without an elevator, the height of a commercial building was limited by the number of steps people could be expected to climb within an economic time period. It was the American inventor and manufacturer Elisha Graves Otis (181161) who finally solved the problem of passenger elevators. D In 1852, Otis pioneered the idea of a safety brake, and two years later he demon strated it in spectacular fashion at the New York Crystal Palace Exhibition of Industry. Otis stood on the lifting platform, four storeys above an expectant crowd. The rope was cut, and after a small jolt, the platform came to a halt. Otis stunt increased peoples confidence in elevators and sales increased. E The operating principle of the safety elevator was described and illustrated in its pattern documentation of 1861. The lifting platform was suspended between two vertical posts each lined with a toothed guide rail. A hook was set into the sides of the platform to engage with the teeth, allowing movement vertically upwards but not downwards. Descent of the elevator was possible only if the hooks were pulled in, which could only happen when the rope was in tension. If the rope were to break, the tension would be lost and the hooks would spring outwards to engage the teeth and stop the fall. Modern elevators incorporate similar safety mechanisms. F Otis installed the first passenger elevator in a store in New York City in 1957. Following the success of the elevator, taller buildings were constructed, and sales increased once more as the business expanded into Europe. Englands first Otis passenger elevator (or lift as the British say) appeared four years later with the open ing of Londons Grosvenor Hotel. Today, the Otis Elevator Company continues to be the worlds leading manufacturer of elevators, employing over 60,000 people with markets in 200 countries. More significantly perhaps, the advent of passenger lifts marked the birth of the modern skyscraper. G Passenger elevators were powered by steam prior to 1902. A rope carrying the cab was wound round a revolving drum driven by a steam engine. The method was too slow for a tall building, which needed a large drum to hold a long coil of rope. By the following year, Otis had developed a compact electric traction elevator that used a cable but did away with the winding gear, allowing the passenger cab to be raised over 100 storeys both quickly and efficiently. H In the electric elevator, the cable was routed from the top of the passenger cab to a pulley wheel at the head of the lift shaft and then back down to a weight acting as a counterbalance. A geared-down electric motor rotated the pulley wheel, which contained a groove to grip the cable and provide the traction. Following the success of the electric elevator, skyscraper buildings began to spring up in the major cities. The Woolworths building in New York, constructed in 1913, was a significant land mark, being the worlds tallest building for the next 27 years. It had 57 floors and the Otis high-speed electric elevators could reach the top floor in a little over one minute. I Each elevator used several cables and pulley wheels, though one cable was enough to support the weight of the car. As a further safety feature, an oil-filled shock piston was mounted at the base of the lift shaft to act as a buffer, slowing the car down at a safe rate in the unlikely event of every cable failing as well as the safety brake.", "hypothesis": "The first passenger elevator was installed in a hotel.", "gold_label": "contradiction"}
{"uid": "id_296", "premise": "Vertical transport A DEATH DEFYING STUNT THAT SHAPED THE SKYLINE OF THE WORLD A The raising of water from a well using a bucket suspended from a rope can be traced back to ancient times. If the rope was passed over a pulley wheel it made the lifting less strenuous. The method could be improved upon by attaching an empty bucket to the opposite end of the rope, then lowering it down the well as the full bucket came up, to counterbalance the weight. B Some medieval monasteries were perched on the tops of cliffs that could not be readily scaled. To overcome the problem, a basket was lowered to the base of the cliff on the end of a rope coiled round a wooden rod, known as a windlass. It was possible to lift heavy weights with a windlass, especially if a small cog wheel on the cranking handle drove a larger cog wheel on a second rod. Materials and people were hoisted in this fashion, but it was a slow process and if the rope were to break the basket plummeted to the ground. C In the middle of the nineteenth century the general public considered elevators supported by a rope to be too dangerous for personal use. Without an elevator, the height of a commercial building was limited by the number of steps people could be expected to climb within an economic time period. It was the American inventor and manufacturer Elisha Graves Otis (181161) who finally solved the problem of passenger elevators. D In 1852, Otis pioneered the idea of a safety brake, and two years later he demon strated it in spectacular fashion at the New York Crystal Palace Exhibition of Industry. Otis stood on the lifting platform, four storeys above an expectant crowd. The rope was cut, and after a small jolt, the platform came to a halt. Otis stunt increased peoples confidence in elevators and sales increased. E The operating principle of the safety elevator was described and illustrated in its pattern documentation of 1861. The lifting platform was suspended between two vertical posts each lined with a toothed guide rail. A hook was set into the sides of the platform to engage with the teeth, allowing movement vertically upwards but not downwards. Descent of the elevator was possible only if the hooks were pulled in, which could only happen when the rope was in tension. If the rope were to break, the tension would be lost and the hooks would spring outwards to engage the teeth and stop the fall. Modern elevators incorporate similar safety mechanisms. F Otis installed the first passenger elevator in a store in New York City in 1957. Following the success of the elevator, taller buildings were constructed, and sales increased once more as the business expanded into Europe. Englands first Otis passenger elevator (or lift as the British say) appeared four years later with the open ing of Londons Grosvenor Hotel. Today, the Otis Elevator Company continues to be the worlds leading manufacturer of elevators, employing over 60,000 people with markets in 200 countries. More significantly perhaps, the advent of passenger lifts marked the birth of the modern skyscraper. G Passenger elevators were powered by steam prior to 1902. A rope carrying the cab was wound round a revolving drum driven by a steam engine. The method was too slow for a tall building, which needed a large drum to hold a long coil of rope. By the following year, Otis had developed a compact electric traction elevator that used a cable but did away with the winding gear, allowing the passenger cab to be raised over 100 storeys both quickly and efficiently. H In the electric elevator, the cable was routed from the top of the passenger cab to a pulley wheel at the head of the lift shaft and then back down to a weight acting as a counterbalance. A geared-down electric motor rotated the pulley wheel, which contained a groove to grip the cable and provide the traction. Following the success of the electric elevator, skyscraper buildings began to spring up in the major cities. The Woolworths building in New York, constructed in 1913, was a significant land mark, being the worlds tallest building for the next 27 years. It had 57 floors and the Otis high-speed electric elevators could reach the top floor in a little over one minute. I Each elevator used several cables and pulley wheels, though one cable was enough to support the weight of the car. As a further safety feature, an oil-filled shock piston was mounted at the base of the lift shaft to act as a buffer, slowing the car down at a safe rate in the unlikely event of every cable failing as well as the safety brake.", "hypothesis": "Electric elevators use similar principles to ancient water-wells.", "gold_label": "entailment"}
{"uid": "id_297", "premise": "Vertical transport A DEATH DEFYING STUNT THAT SHAPED THE SKYLINE OF THE WORLD The raising of water from a well using a bucket suspended from a rope can be traced back to ancient times. If the rope was passed over a pulley wheel it made the lifting less strenuous. The method could be improved upon by attaching an empty bucket to the opposite end of the rope, then lowering it down the well as the full bucket came up, to counterbalance the weight. Some medieval monasteries were perched on the tops of cliffs that could not be readily scaled. To overcome the problem, a basket was lowered to the base of the cliff on the end of a rope coiled round a wooden rod, known as a windlass. It was possible to lift heavy weights with a windlass, especially if a small cog wheel on the cranking handle drove a larger cog wheel on a second rod. Materials and people were hoisted in this fashion, but it was a slow process and if the rope were to break the basket plummeted to the ground. In the middle of the nineteenth century the general public considered elevators supported by a rope to be too dangerous for personal use. Without an elevator, the height of a commercial building was limited by the number of steps people could be expected to climb within an economic time period. It was the American inventor and manufacturer Elisha Graves Otis (181161) who finally solved the problem of passenger elevators. In 1852, Otis pioneered the idea of a safety brake, and two years later he demonstrated it in spectacular fashion at the New York Crystal Palace Exhibition of Industry. Otis stood on the lifting platform, four storeys above an expectant crowd. The rope was cut, and after a small jolt, the platform came to a halt. Otis stunt increased peoples confidence in elevators and sales increased. The operating principle of the safety elevator was described and illustrated in its pattern documentation of 1861. The lifting platform was suspended between two vertical posts each lined with a toothed guide rail. A hook was set into the sides of the platform to engage with the teeth, allowing movement vertically upwards but not downwards. Descent of the elevator was possible only if the hooks were pulled in, which could only happen when the rope was in tension. If the rope were to break, the tension would be lost and the hooks would spring outwards to engage the teeth and stop the fall. Modern elevators incorporate similar safety mechanisms. Otis installed the first passenger elevator in a store in New York City in 1957. Following the success of the elevator, taller buildings were constructed, and sales increased once more as the business expanded into Europe. Englands first Otis passenger elevator (or lift as the British say) appeared four years later with the opening of Londons Grosvenor Hotel. Today, the Otis Elevator Company continues to be the worlds leading manufacturer of elevators, employing over 60,000 people with markets in 200 countries. More significantly perhaps, the advent of passenger lifts marked the birth of the modern skyscraper. Passenger elevators were powered by steam prior to 1902. A rope carrying the cab was wound round a revolving drum driven by a steam engine. The method was too slow for a tall building, which needed a large drum to hold a long coil of rope. By the following year, Otis had developed a compact electric traction elevator that used a cable but did away with the winding gear, allowing the passenger cab to be raised over 100 storeys both quickly and efficiently. In the electric elevator, the cable was routed from the top of the passenger cab to a pulley wheel at the head of the lift shaft and then back down to a weight acting as a counterbalance. A geared-down electric motor rotated the pulley wheel, which contained a groove to grip the cable and provide the traction. Following the success of the electric elevator, skyscraper buildings began to spring up in the major cities. The Woolworths building in New York, constructed in 1913, was a significant landmark, being the worlds tallest building for the next 27 years. It had 57 floors and the Otis high-speed electric elevators could reach the top floor in a little over one minute. Each elevator used several cables and pulley wheels, though one cable was enough to support the weight of the car. As a further safety feature, an oil-filled shock piston was mounted at the base of the lift shaft to act as a buffer, slowing the car down at a safe rate in the unlikely event of every cable failing as well as the safety brake.", "hypothesis": "Only people could be hoisted with a windlass.", "gold_label": "contradiction"}
{"uid": "id_298", "premise": "Vertical transport A DEATH DEFYING STUNT THAT SHAPED THE SKYLINE OF THE WORLD The raising of water from a well using a bucket suspended from a rope can be traced back to ancient times. If the rope was passed over a pulley wheel it made the lifting less strenuous. The method could be improved upon by attaching an empty bucket to the opposite end of the rope, then lowering it down the well as the full bucket came up, to counterbalance the weight. Some medieval monasteries were perched on the tops of cliffs that could not be readily scaled. To overcome the problem, a basket was lowered to the base of the cliff on the end of a rope coiled round a wooden rod, known as a windlass. It was possible to lift heavy weights with a windlass, especially if a small cog wheel on the cranking handle drove a larger cog wheel on a second rod. Materials and people were hoisted in this fashion, but it was a slow process and if the rope were to break the basket plummeted to the ground. In the middle of the nineteenth century the general public considered elevators supported by a rope to be too dangerous for personal use. Without an elevator, the height of a commercial building was limited by the number of steps people could be expected to climb within an economic time period. It was the American inventor and manufacturer Elisha Graves Otis (181161) who finally solved the problem of passenger elevators. In 1852, Otis pioneered the idea of a safety brake, and two years later he demonstrated it in spectacular fashion at the New York Crystal Palace Exhibition of Industry. Otis stood on the lifting platform, four storeys above an expectant crowd. The rope was cut, and after a small jolt, the platform came to a halt. Otis stunt increased peoples confidence in elevators and sales increased. The operating principle of the safety elevator was described and illustrated in its pattern documentation of 1861. The lifting platform was suspended between two vertical posts each lined with a toothed guide rail. A hook was set into the sides of the platform to engage with the teeth, allowing movement vertically upwards but not downwards. Descent of the elevator was possible only if the hooks were pulled in, which could only happen when the rope was in tension. If the rope were to break, the tension would be lost and the hooks would spring outwards to engage the teeth and stop the fall. Modern elevators incorporate similar safety mechanisms. Otis installed the first passenger elevator in a store in New York City in 1957. Following the success of the elevator, taller buildings were constructed, and sales increased once more as the business expanded into Europe. Englands first Otis passenger elevator (or lift as the British say) appeared four years later with the opening of Londons Grosvenor Hotel. Today, the Otis Elevator Company continues to be the worlds leading manufacturer of elevators, employing over 60,000 people with markets in 200 countries. More significantly perhaps, the advent of passenger lifts marked the birth of the modern skyscraper. Passenger elevators were powered by steam prior to 1902. A rope carrying the cab was wound round a revolving drum driven by a steam engine. The method was too slow for a tall building, which needed a large drum to hold a long coil of rope. By the following year, Otis had developed a compact electric traction elevator that used a cable but did away with the winding gear, allowing the passenger cab to be raised over 100 storeys both quickly and efficiently. In the electric elevator, the cable was routed from the top of the passenger cab to a pulley wheel at the head of the lift shaft and then back down to a weight acting as a counterbalance. A geared-down electric motor rotated the pulley wheel, which contained a groove to grip the cable and provide the traction. Following the success of the electric elevator, skyscraper buildings began to spring up in the major cities. The Woolworths building in New York, constructed in 1913, was a significant landmark, being the worlds tallest building for the next 27 years. It had 57 floors and the Otis high-speed electric elevators could reach the top floor in a little over one minute. Each elevator used several cables and pulley wheels, though one cable was enough to support the weight of the car. As a further safety feature, an oil-filled shock piston was mounted at the base of the lift shaft to act as a buffer, slowing the car down at a safe rate in the unlikely event of every cable failing as well as the safety brake.", "hypothesis": "Electric elevators use similar principles to ancient water-wells.", "gold_label": "entailment"}
{"uid": "id_299", "premise": "Vertical transport A DEATH DEFYING STUNT THAT SHAPED THE SKYLINE OF THE WORLD The raising of water from a well using a bucket suspended from a rope can be traced back to ancient times. If the rope was passed over a pulley wheel it made the lifting less strenuous. The method could be improved upon by attaching an empty bucket to the opposite end of the rope, then lowering it down the well as the full bucket came up, to counterbalance the weight. Some medieval monasteries were perched on the tops of cliffs that could not be readily scaled. To overcome the problem, a basket was lowered to the base of the cliff on the end of a rope coiled round a wooden rod, known as a windlass. It was possible to lift heavy weights with a windlass, especially if a small cog wheel on the cranking handle drove a larger cog wheel on a second rod. Materials and people were hoisted in this fashion, but it was a slow process and if the rope were to break the basket plummeted to the ground. In the middle of the nineteenth century the general public considered elevators supported by a rope to be too dangerous for personal use. Without an elevator, the height of a commercial building was limited by the number of steps people could be expected to climb within an economic time period. It was the American inventor and manufacturer Elisha Graves Otis (181161) who finally solved the problem of passenger elevators. In 1852, Otis pioneered the idea of a safety brake, and two years later he demonstrated it in spectacular fashion at the New York Crystal Palace Exhibition of Industry. Otis stood on the lifting platform, four storeys above an expectant crowd. The rope was cut, and after a small jolt, the platform came to a halt. Otis stunt increased peoples confidence in elevators and sales increased. The operating principle of the safety elevator was described and illustrated in its pattern documentation of 1861. The lifting platform was suspended between two vertical posts each lined with a toothed guide rail. A hook was set into the sides of the platform to engage with the teeth, allowing movement vertically upwards but not downwards. Descent of the elevator was possible only if the hooks were pulled in, which could only happen when the rope was in tension. If the rope were to break, the tension would be lost and the hooks would spring outwards to engage the teeth and stop the fall. Modern elevators incorporate similar safety mechanisms. Otis installed the first passenger elevator in a store in New York City in 1957. Following the success of the elevator, taller buildings were constructed, and sales increased once more as the business expanded into Europe. Englands first Otis passenger elevator (or lift as the British say) appeared four years later with the opening of Londons Grosvenor Hotel. Today, the Otis Elevator Company continues to be the worlds leading manufacturer of elevators, employing over 60,000 people with markets in 200 countries. More significantly perhaps, the advent of passenger lifts marked the birth of the modern skyscraper. Passenger elevators were powered by steam prior to 1902. A rope carrying the cab was wound round a revolving drum driven by a steam engine. The method was too slow for a tall building, which needed a large drum to hold a long coil of rope. By the following year, Otis had developed a compact electric traction elevator that used a cable but did away with the winding gear, allowing the passenger cab to be raised over 100 storeys both quickly and efficiently. In the electric elevator, the cable was routed from the top of the passenger cab to a pulley wheel at the head of the lift shaft and then back down to a weight acting as a counterbalance. A geared-down electric motor rotated the pulley wheel, which contained a groove to grip the cable and provide the traction. Following the success of the electric elevator, skyscraper buildings began to spring up in the major cities. The Woolworths building in New York, constructed in 1913, was a significant landmark, being the worlds tallest building for the next 27 years. It had 57 floors and the Otis high-speed electric elevators could reach the top floor in a little over one minute. Each elevator used several cables and pulley wheels, though one cable was enough to support the weight of the car. As a further safety feature, an oil-filled shock piston was mounted at the base of the lift shaft to act as a buffer, slowing the car down at a safe rate in the unlikely event of every cable failing as well as the safety brake.", "hypothesis": "The first passenger elevator was installed in a hotel.", "gold_label": "contradiction"}
{"uid": "id_300", "premise": "Vertical transport A DEATH DEFYING STUNT THAT SHAPED THE SKYLINE OF THE WORLD The raising of water from a well using a bucket suspended from a rope can be traced back to ancient times. If the rope was passed over a pulley wheel it made the lifting less strenuous. The method could be improved upon by attaching an empty bucket to the opposite end of the rope, then lowering it down the well as the full bucket came up, to counterbalance the weight. Some medieval monasteries were perched on the tops of cliffs that could not be readily scaled. To overcome the problem, a basket was lowered to the base of the cliff on the end of a rope coiled round a wooden rod, known as a windlass. It was possible to lift heavy weights with a windlass, especially if a small cog wheel on the cranking handle drove a larger cog wheel on a second rod. Materials and people were hoisted in this fashion, but it was a slow process and if the rope were to break the basket plummeted to the ground. In the middle of the nineteenth century the general public considered elevators supported by a rope to be too dangerous for personal use. Without an elevator, the height of a commercial building was limited by the number of steps people could be expected to climb within an economic time period. It was the American inventor and manufacturer Elisha Graves Otis (181161) who finally solved the problem of passenger elevators. In 1852, Otis pioneered the idea of a safety brake, and two years later he demonstrated it in spectacular fashion at the New York Crystal Palace Exhibition of Industry. Otis stood on the lifting platform, four storeys above an expectant crowd. The rope was cut, and after a small jolt, the platform came to a halt. Otis stunt increased peoples confidence in elevators and sales increased. The operating principle of the safety elevator was described and illustrated in its pattern documentation of 1861. The lifting platform was suspended between two vertical posts each lined with a toothed guide rail. A hook was set into the sides of the platform to engage with the teeth, allowing movement vertically upwards but not downwards. Descent of the elevator was possible only if the hooks were pulled in, which could only happen when the rope was in tension. If the rope were to break, the tension would be lost and the hooks would spring outwards to engage the teeth and stop the fall. Modern elevators incorporate similar safety mechanisms. Otis installed the first passenger elevator in a store in New York City in 1957. Following the success of the elevator, taller buildings were constructed, and sales increased once more as the business expanded into Europe. Englands first Otis passenger elevator (or lift as the British say) appeared four years later with the opening of Londons Grosvenor Hotel. Today, the Otis Elevator Company continues to be the worlds leading manufacturer of elevators, employing over 60,000 people with markets in 200 countries. More significantly perhaps, the advent of passenger lifts marked the birth of the modern skyscraper. Passenger elevators were powered by steam prior to 1902. A rope carrying the cab was wound round a revolving drum driven by a steam engine. The method was too slow for a tall building, which needed a large drum to hold a long coil of rope. By the following year, Otis had developed a compact electric traction elevator that used a cable but did away with the winding gear, allowing the passenger cab to be raised over 100 storeys both quickly and efficiently. In the electric elevator, the cable was routed from the top of the passenger cab to a pulley wheel at the head of the lift shaft and then back down to a weight acting as a counterbalance. A geared-down electric motor rotated the pulley wheel, which contained a groove to grip the cable and provide the traction. Following the success of the electric elevator, skyscraper buildings began to spring up in the major cities. The Woolworths building in New York, constructed in 1913, was a significant landmark, being the worlds tallest building for the next 27 years. It had 57 floors and the Otis high-speed electric elevators could reach the top floor in a little over one minute. Each elevator used several cables and pulley wheels, though one cable was enough to support the weight of the car. As a further safety feature, an oil-filled shock piston was mounted at the base of the lift shaft to act as a buffer, slowing the car down at a safe rate in the unlikely event of every cable failing as well as the safety brake.", "hypothesis": "Otis pattern documents contained a diagram.", "gold_label": "entailment"}
{"uid": "id_301", "premise": "Vertical transport A DEATH DEFYING STUNT THAT SHAPED THE SKYLINE OF THE WORLD The raising of water from a well using a bucket suspended from a rope can be traced back to ancient times. If the rope was passed over a pulley wheel it made the lifting less strenuous. The method could be improved upon by attaching an empty bucket to the opposite end of the rope, then lowering it down the well as the full bucket came up, to counterbalance the weight. Some medieval monasteries were perched on the tops of cliffs that could not be readily scaled. To overcome the problem, a basket was lowered to the base of the cliff on the end of a rope coiled round a wooden rod, known as a windlass. It was possible to lift heavy weights with a windlass, especially if a small cog wheel on the cranking handle drove a larger cog wheel on a second rod. Materials and people were hoisted in this fashion, but it was a slow process and if the rope were to break the basket plummeted to the ground. In the middle of the nineteenth century the general public considered elevators supported by a rope to be too dangerous for personal use. Without an elevator, the height of a commercial building was limited by the number of steps people could be expected to climb within an economic time period. It was the American inventor and manufacturer Elisha Graves Otis (181161) who finally solved the problem of passenger elevators. In 1852, Otis pioneered the idea of a safety brake, and two years later he demonstrated it in spectacular fashion at the New York Crystal Palace Exhibition of Industry. Otis stood on the lifting platform, four storeys above an expectant crowd. The rope was cut, and after a small jolt, the platform came to a halt. Otis stunt increased peoples confidence in elevators and sales increased. The operating principle of the safety elevator was described and illustrated in its pattern documentation of 1861. The lifting platform was suspended between two vertical posts each lined with a toothed guide rail. A hook was set into the sides of the platform to engage with the teeth, allowing movement vertically upwards but not downwards. Descent of the elevator was possible only if the hooks were pulled in, which could only happen when the rope was in tension. If the rope were to break, the tension would be lost and the hooks would spring outwards to engage the teeth and stop the fall. Modern elevators incorporate similar safety mechanisms. Otis installed the first passenger elevator in a store in New York City in 1957. Following the success of the elevator, taller buildings were constructed, and sales increased once more as the business expanded into Europe. Englands first Otis passenger elevator (or lift as the British say) appeared four years later with the opening of Londons Grosvenor Hotel. Today, the Otis Elevator Company continues to be the worlds leading manufacturer of elevators, employing over 60,000 people with markets in 200 countries. More significantly perhaps, the advent of passenger lifts marked the birth of the modern skyscraper. Passenger elevators were powered by steam prior to 1902. A rope carrying the cab was wound round a revolving drum driven by a steam engine. The method was too slow for a tall building, which needed a large drum to hold a long coil of rope. By the following year, Otis had developed a compact electric traction elevator that used a cable but did away with the winding gear, allowing the passenger cab to be raised over 100 storeys both quickly and efficiently. In the electric elevator, the cable was routed from the top of the passenger cab to a pulley wheel at the head of the lift shaft and then back down to a weight acting as a counterbalance. A geared-down electric motor rotated the pulley wheel, which contained a groove to grip the cable and provide the traction. Following the success of the electric elevator, skyscraper buildings began to spring up in the major cities. The Woolworths building in New York, constructed in 1913, was a significant landmark, being the worlds tallest building for the next 27 years. It had 57 floors and the Otis high-speed electric elevators could reach the top floor in a little over one minute. Each elevator used several cables and pulley wheels, though one cable was enough to support the weight of the car. As a further safety feature, an oil-filled shock piston was mounted at the base of the lift shaft to act as a buffer, slowing the car down at a safe rate in the unlikely event of every cable failing as well as the safety brake.", "hypothesis": "Tall commercial buildings were not economic without an elevator.", "gold_label": "entailment"}
{"uid": "id_302", "premise": "Video Games Unexpected Benefits to Human Brain A. James Paul Gee, professor of education at the University of Wisconsin- Madison, played his first video game years ago when his six-year-old son Sam was playing Pajama Sam: No Need to Hide When Its Dark Outside. He wanted to play the game so he could support Sams problem solving. Though Pajama Sam is not an educational game, it is replete with the types of problems psychologists study when they study thinking and learning. When he saw how well the game held Sams attention, he wondered what sort of beast a more mature video game might be. Video and computer games, like many other popular, entertaining and addicting kids activities, are looked down upon by many parents as time- wasters, and worse, parents think that these games rot the brain. Violent video games are readily blamed by the media and some experts as the reason why some youth become violent or commit extreme anti-social behavior. Recent content analyses of video games show that as many as 89% of games contain some violent content, but there is no form of aggressive content for 70% of popular games. Many scientists and psychologists, like James Paul Gee, find thatvideo games actually have many benefits - the main one being making kids smart. Video games may actually teach kids high-level thinking skills that they will need in the future. \"Video games change your brain, \" according to University of Wisconsin psychologist Shawn Green. Video games change the brains physical structure the same way as do learning to read, playing the piano, or navigating using a map. Much like exercise can build muscle, the powerful combination of concentration and rewarding surges of neurotransmitters like dopamine, which strengthens neural circuits, can build the players brain. Video games give your childs brain a real workout. In many video games, the skills requ u ed to win involve abstract and high level thinking. These skills are not even taught at school. Some of the mental skills trained by video games include: following instructions, problem solving, logic, hand-eye coordination, fine motor and spatial skills. Research also suggests that people can learn iconic, spatial, and visual attention skills from video games. There have been even studies with adults showing that experience with video games is related to better surgical skills. Jacob Benjamin, doctor from Beth Israel Medical Center NY, found a direct link between skill at video gaming and skill at keyhole or laparoscopic surgery. Also, a reason given by experts as to why fighter pilots of today are more skillful is that this generations pilots are being weaned on video games. The players learn to manage resources that are limited, and decide the best use of resources, the same way as in real life. In strategy games, for instance, while developing a city, an unexpected surprise like an enemy might emerge. This forces the player to be flexible and quickly change tactics. Sometimes the player does this almost every second of the game giving the brain a real workout. According to researchers at the University of Rochester, led by Daphne Bavelier, a cognitive scientist, games simulating stressful events such as those found in battle or action games could be a training tool for real-world situations. The study suggests that playing action video games primes the brain to make quick decisions. Video games can be used to train soldiers and surgeons, according to the study. Steven Johnson, author of Everything Bad isGood For You: How Today's Popular Culture, says gamers must deal with immediate problems while keeping their long-term goals on their horizon. Young gamers force themselves to read to get instructions, follow storylines of games, and get information from the game texts. James Paul Gee, professor of education at the University of Wisconsin- Madison, says that playing a video game is similar to working through a science problem. Like students in a laboratory, gamers must come up with a hypothesis. For example, players in some games constantly try out combinations of weapons and powers to use to defeat an enemy. If one does not work, they change hypothesis and try the next one. Video games are goal-driven experiences, says Gee, which are fundamental to learning. Also, using math skills is important to win in many games that involve quantitative analysis like managing resources. In higher levels of a game, players usually fail the first time around, but they keep on trying until they succeed and move on to the next level. Many games are played online and involve cooperation with other online players in order to win. Video and computer games also help children gain self-confidence and many games are based on history, city building, and governance and so on. Such games indirectly teach children about aspects of life on earth. H. In an upcoming study in the journal Current Biology, authors Daphne Bavelier, Alexandre Pouget, and C. Shawn Green report that video games could provide a potent training regimen for speeding up reactions in many types of real-life situations. The researchers tested dozens of 18-to 25-year-olds who were not ordinarily video game players. They split the subjects into two groups. One group played 50 hours of the fast-paced action video games \"Call of Duty 2\" and \"Unreal Tournament, \" and the other group played 50 hours of the slow- moving strategy game \"The Sims 2. \" After this training period, all of the subjects were asked to make quick decisions in several tasks designed by the researchers. The action game players were up to 25 percent faster at coming to a conclusion and answered just as many questions correctly as their strategy game playing peers.", "hypothesis": "The action game players minimized the percentage of making mistakes in the experiment.", "gold_label": "contradiction"}
{"uid": "id_303", "premise": "Video Games Unexpected Benefits to Human Brain A. James Paul Gee, professor of education at the University of Wisconsin- Madison, played his first video game years ago when his six-year-old son Sam was playing Pajama Sam: No Need to Hide When Its Dark Outside. He wanted to play the game so he could support Sams problem solving. Though Pajama Sam is not an educational game, it is replete with the types of problems psychologists study when they study thinking and learning. When he saw how well the game held Sams attention, he wondered what sort of beast a more mature video game might be. Video and computer games, like many other popular, entertaining and addicting kids activities, are looked down upon by many parents as time- wasters, and worse, parents think that these games rot the brain. Violent video games are readily blamed by the media and some experts as the reason why some youth become violent or commit extreme anti-social behavior. Recent content analyses of video games show that as many as 89% of games contain some violent content, but there is no form of aggressive content for 70% of popular games. Many scientists and psychologists, like James Paul Gee, find thatvideo games actually have many benefits - the main one being making kids smart. Video games may actually teach kids high-level thinking skills that they will need in the future. \"Video games change your brain, \" according to University of Wisconsin psychologist Shawn Green. Video games change the brains physical structure the same way as do learning to read, playing the piano, or navigating using a map. Much like exercise can build muscle, the powerful combination of concentration and rewarding surges of neurotransmitters like dopamine, which strengthens neural circuits, can build the players brain. Video games give your childs brain a real workout. In many video games, the skills requ u ed to win involve abstract and high level thinking. These skills are not even taught at school. Some of the mental skills trained by video games include: following instructions, problem solving, logic, hand-eye coordination, fine motor and spatial skills. Research also suggests that people can learn iconic, spatial, and visual attention skills from video games. There have been even studies with adults showing that experience with video games is related to better surgical skills. Jacob Benjamin, doctor from Beth Israel Medical Center NY, found a direct link between skill at video gaming and skill at keyhole or laparoscopic surgery. Also, a reason given by experts as to why fighter pilots of today are more skillful is that this generations pilots are being weaned on video games. The players learn to manage resources that are limited, and decide the best use of resources, the same way as in real life. In strategy games, for instance, while developing a city, an unexpected surprise like an enemy might emerge. This forces the player to be flexible and quickly change tactics. Sometimes the player does this almost every second of the game giving the brain a real workout. According to researchers at the University of Rochester, led by Daphne Bavelier, a cognitive scientist, games simulating stressful events such as those found in battle or action games could be a training tool for real-world situations. The study suggests that playing action video games primes the brain to make quick decisions. Video games can be used to train soldiers and surgeons, according to the study. Steven Johnson, author of Everything Bad isGood For You: How Today's Popular Culture, says gamers must deal with immediate problems while keeping their long-term goals on their horizon. Young gamers force themselves to read to get instructions, follow storylines of games, and get information from the game texts. James Paul Gee, professor of education at the University of Wisconsin- Madison, says that playing a video game is similar to working through a science problem. Like students in a laboratory, gamers must come up with a hypothesis. For example, players in some games constantly try out combinations of weapons and powers to use to defeat an enemy. If one does not work, they change hypothesis and try the next one. Video games are goal-driven experiences, says Gee, which are fundamental to learning. Also, using math skills is important to win in many games that involve quantitative analysis like managing resources. In higher levels of a game, players usually fail the first time around, but they keep on trying until they succeed and move on to the next level. Many games are played online and involve cooperation with other online players in order to win. Video and computer games also help children gain self-confidence and many games are based on history, city building, and governance and so on. Such games indirectly teach children about aspects of life on earth. H. In an upcoming study in the journal Current Biology, authors Daphne Bavelier, Alexandre Pouget, and C. Shawn Green report that video games could provide a potent training regimen for speeding up reactions in many types of real-life situations. The researchers tested dozens of 18-to 25-year-olds who were not ordinarily video game players. They split the subjects into two groups. One group played 50 hours of the fast-paced action video games \"Call of Duty 2\" and \"Unreal Tournament, \" and the other group played 50 hours of the slow- moving strategy game \"The Sims 2. \" After this training period, all of the subjects were asked to make quick decisions in several tasks designed by the researchers. The action game players were up to 25 percent faster at coming to a conclusion and answered just as many questions correctly as their strategy game playing peers.", "hypothesis": "It would be a good idea for schools to apply video games in their classrooms.", "gold_label": "neutral"}
{"uid": "id_304", "premise": "Video Games Unexpected Benefits to Human Brain A. James Paul Gee, professor of education at the University of Wisconsin- Madison, played his first video game years ago when his six-year-old son Sam was playing Pajama Sam: No Need to Hide When Its Dark Outside. He wanted to play the game so he could support Sams problem solving. Though Pajama Sam is not an educational game, it is replete with the types of problems psychologists study when they study thinking and learning. When he saw how well the game held Sams attention, he wondered what sort of beast a more mature video game might be. Video and computer games, like many other popular, entertaining and addicting kids activities, are looked down upon by many parents as time- wasters, and worse, parents think that these games rot the brain. Violent video games are readily blamed by the media and some experts as the reason why some youth become violent or commit extreme anti-social behavior. Recent content analyses of video games show that as many as 89% of games contain some violent content, but there is no form of aggressive content for 70% of popular games. Many scientists and psychologists, like James Paul Gee, find thatvideo games actually have many benefits - the main one being making kids smart. Video games may actually teach kids high-level thinking skills that they will need in the future. \"Video games change your brain, \" according to University of Wisconsin psychologist Shawn Green. Video games change the brains physical structure the same way as do learning to read, playing the piano, or navigating using a map. Much like exercise can build muscle, the powerful combination of concentration and rewarding surges of neurotransmitters like dopamine, which strengthens neural circuits, can build the players brain. Video games give your childs brain a real workout. In many video games, the skills requ u ed to win involve abstract and high level thinking. These skills are not even taught at school. Some of the mental skills trained by video games include: following instructions, problem solving, logic, hand-eye coordination, fine motor and spatial skills. Research also suggests that people can learn iconic, spatial, and visual attention skills from video games. There have been even studies with adults showing that experience with video games is related to better surgical skills. Jacob Benjamin, doctor from Beth Israel Medical Center NY, found a direct link between skill at video gaming and skill at keyhole or laparoscopic surgery. Also, a reason given by experts as to why fighter pilots of today are more skillful is that this generations pilots are being weaned on video games. The players learn to manage resources that are limited, and decide the best use of resources, the same way as in real life. In strategy games, for instance, while developing a city, an unexpected surprise like an enemy might emerge. This forces the player to be flexible and quickly change tactics. Sometimes the player does this almost every second of the game giving the brain a real workout. According to researchers at the University of Rochester, led by Daphne Bavelier, a cognitive scientist, games simulating stressful events such as those found in battle or action games could be a training tool for real-world situations. The study suggests that playing action video games primes the brain to make quick decisions. Video games can be used to train soldiers and surgeons, according to the study. Steven Johnson, author of Everything Bad isGood For You: How Today's Popular Culture, says gamers must deal with immediate problems while keeping their long-term goals on their horizon. Young gamers force themselves to read to get instructions, follow storylines of games, and get information from the game texts. James Paul Gee, professor of education at the University of Wisconsin- Madison, says that playing a video game is similar to working through a science problem. Like students in a laboratory, gamers must come up with a hypothesis. For example, players in some games constantly try out combinations of weapons and powers to use to defeat an enemy. If one does not work, they change hypothesis and try the next one. Video games are goal-driven experiences, says Gee, which are fundamental to learning. Also, using math skills is important to win in many games that involve quantitative analysis like managing resources. In higher levels of a game, players usually fail the first time around, but they keep on trying until they succeed and move on to the next level. Many games are played online and involve cooperation with other online players in order to win. Video and computer games also help children gain self-confidence and many games are based on history, city building, and governance and so on. Such games indirectly teach children about aspects of life on earth. H. In an upcoming study in the journal Current Biology, authors Daphne Bavelier, Alexandre Pouget, and C. Shawn Green report that video games could provide a potent training regimen for speeding up reactions in many types of real-life situations. The researchers tested dozens of 18-to 25-year-olds who were not ordinarily video game players. They split the subjects into two groups. One group played 50 hours of the fast-paced action video games \"Call of Duty 2\" and \"Unreal Tournament, \" and the other group played 50 hours of the slow- moving strategy game \"The Sims 2. \" After this training period, all of the subjects were asked to make quick decisions in several tasks designed by the researchers. The action game players were up to 25 percent faster at coming to a conclusion and answered just as many questions correctly as their strategy game playing peers.", "hypothesis": "Most video games are popular because of their violent content.", "gold_label": "neutral"}
{"uid": "id_305", "premise": "Video Games Unexpected Benefits to Human Brain A. James Paul Gee, professor of education at the University of Wisconsin- Madison, played his first video game years ago when his six-year-old son Sam was playing Pajama Sam: No Need to Hide When Its Dark Outside. He wanted to play the game so he could support Sams problem solving. Though Pajama Sam is not an educational game, it is replete with the types of problems psychologists study when they study thinking and learning. When he saw how well the game held Sams attention, he wondered what sort of beast a more mature video game might be. Video and computer games, like many other popular, entertaining and addicting kids activities, are looked down upon by many parents as time- wasters, and worse, parents think that these games rot the brain. Violent video games are readily blamed by the media and some experts as the reason why some youth become violent or commit extreme anti-social behavior. Recent content analyses of video games show that as many as 89% of games contain some violent content, but there is no form of aggressive content for 70% of popular games. Many scientists and psychologists, like James Paul Gee, find thatvideo games actually have many benefits - the main one being making kids smart. Video games may actually teach kids high-level thinking skills that they will need in the future. \"Video games change your brain, \" according to University of Wisconsin psychologist Shawn Green. Video games change the brains physical structure the same way as do learning to read, playing the piano, or navigating using a map. Much like exercise can build muscle, the powerful combination of concentration and rewarding surges of neurotransmitters like dopamine, which strengthens neural circuits, can build the players brain. Video games give your childs brain a real workout. In many video games, the skills requ u ed to win involve abstract and high level thinking. These skills are not even taught at school. Some of the mental skills trained by video games include: following instructions, problem solving, logic, hand-eye coordination, fine motor and spatial skills. Research also suggests that people can learn iconic, spatial, and visual attention skills from video games. There have been even studies with adults showing that experience with video games is related to better surgical skills. Jacob Benjamin, doctor from Beth Israel Medical Center NY, found a direct link between skill at video gaming and skill at keyhole or laparoscopic surgery. Also, a reason given by experts as to why fighter pilots of today are more skillful is that this generations pilots are being weaned on video games. The players learn to manage resources that are limited, and decide the best use of resources, the same way as in real life. In strategy games, for instance, while developing a city, an unexpected surprise like an enemy might emerge. This forces the player to be flexible and quickly change tactics. Sometimes the player does this almost every second of the game giving the brain a real workout. According to researchers at the University of Rochester, led by Daphne Bavelier, a cognitive scientist, games simulating stressful events such as those found in battle or action games could be a training tool for real-world situations. The study suggests that playing action video games primes the brain to make quick decisions. Video games can be used to train soldiers and surgeons, according to the study. Steven Johnson, author of Everything Bad isGood For You: How Today's Popular Culture, says gamers must deal with immediate problems while keeping their long-term goals on their horizon. Young gamers force themselves to read to get instructions, follow storylines of games, and get information from the game texts. James Paul Gee, professor of education at the University of Wisconsin- Madison, says that playing a video game is similar to working through a science problem. Like students in a laboratory, gamers must come up with a hypothesis. For example, players in some games constantly try out combinations of weapons and powers to use to defeat an enemy. If one does not work, they change hypothesis and try the next one. Video games are goal-driven experiences, says Gee, which are fundamental to learning. Also, using math skills is important to win in many games that involve quantitative analysis like managing resources. In higher levels of a game, players usually fail the first time around, but they keep on trying until they succeed and move on to the next level. Many games are played online and involve cooperation with other online players in order to win. Video and computer games also help children gain self-confidence and many games are based on history, city building, and governance and so on. Such games indirectly teach children about aspects of life on earth. H. In an upcoming study in the journal Current Biology, authors Daphne Bavelier, Alexandre Pouget, and C. Shawn Green report that video games could provide a potent training regimen for speeding up reactions in many types of real-life situations. The researchers tested dozens of 18-to 25-year-olds who were not ordinarily video game players. They split the subjects into two groups. One group played 50 hours of the fast-paced action video games \"Call of Duty 2\" and \"Unreal Tournament, \" and the other group played 50 hours of the slow- moving strategy game \"The Sims 2. \" After this training period, all of the subjects were asked to make quick decisions in several tasks designed by the researchers. The action game players were up to 25 percent faster at coming to a conclusion and answered just as many questions correctly as their strategy game playing peers.", "hypothesis": "Those people who are addicted to video games have lots of dopamine in their brains.", "gold_label": "entailment"}
{"uid": "id_306", "premise": "Video game research Although video games were first developed for adults, they are no longer exclusively reserved for the grown ups in the home. In 2006, Rideout and Hamel reported that as many as 29 percent of preschool children (children between two and six years old) in the United States had played console video games, and 18 percent had played hand-held ones. Given young childrens insatiable eagerness to learn, coupled with the fact that they are clearly surrounded by these media, we predict that preschoolers will both continue and increasingly begin to adopt video games for personal enjoyment. Although the majority of gaming equipment is still designed for a much older target audience, once a game system enters the household it is potentially available for all family members, including the youngest. Portable systems have done a particularly good job of penetrating the younger market. Research in the video game market is typically done at two stages: some time close to the end of the product cycle, in order to get feedback from consumers, so that a marketing strategy can be developed; and at the very end of the product cycle to fix bugs in the game. While both of those types of research are important, and may be appropriate for dealing with adult consumers, neither of them aids in designing better games, especially when it comes to designing for an audience that may have particular needs, such as preschoolers or senior citizens. Instead, exploratory and formative research has to be undertaken in order to truly understand those audiences, their abilities, their perspective, and their needs. In the spring of 2007, our preschool-game production team at Nickelodeon had a hunch that the Nintendo DS with its new features, such as the microphone, small size and portability, and its relatively low price point was a ripe gaming platform for preschoolers. There were a few games on the market at the time which had characters that appealed to the younger set, but our game producers did not think that the game mechanics or design were appropriate for preschoolers. What exactly preschoolers could do with the system, however, was a bit of a mystery. So we set about doing a study to answer the query: What could we expect preschoolers to be capable of in the context of hand-held game play, and how might the child development literature inform us as we proceeded with the creation of a new outlet for this age group? Our context in this case was the United States, although the games that resulted were also released in other regions, due to the broad international reach of the characters. In order to design the best possible DS product for a preschool audience we were fully committed to the ideals of a user-centered approach, which assumes that users will be at least considered, but ideally consulted during the development process. After all, when it comes to introducing a new interactive product to the child market, and particularly such a young age group within it, we believe it is crucial to assess the range of physical and cognitive abilities associated with their specific developmental stage. Revelle and Medoff (2002) review some of the basic reasons why home entertainment systems, computers, and other electronic gaming devices, are often difficult for preschoolers to use. In addition to their still developing motor skills (which make manipulating a controller with small buttons difficult), many of the major stumbling blocks are cognitive. Though preschoolers are learning to think symbolically, and understand that pictures can stand for real-life objects, the vast majority are still unable to read and write. Thus, using text-based menu selections is not viable. Mapping is yet another obstacle since preschoolers may be unable to understand that there is a direct link between how the controller is used and the activities that appear before them on screen. Though this aspect is changing, in traditional mapping systems real life movements do not usually translate into game-based activity. Over the course of our study, we gained many insights into how preschoolers interact with various platforms, including the DS. For instance, all instructions for preschoolers need to be in voice-over, and include visual representations, and this has been one of the most difficult areas for us to negotiate with respect to game design on the DS. Because the game cartridges have very limited memory capacity, particularly in comparison to console or computer games, the ability to capture large amounts of voice-over data via sound files or visual representations of instructions becomes limited. Text instructions take up minimal memory, so they are preferable from a technological perspective. Figuring out ways to maximise sound and graphics files, while retaining the clear visual and verbal cues that we know are critical for our youngest players, is a constant give and take. Another of our findings indicated that preschoolers may use either a stylus, or their fingers, or both although they are not very accurate with either. One of the very interesting aspects of the DS is that the interface, which is designed to respond to stylus interactions, can also effectively be used with the tip of the finger. This is particularly noteworthy in the context of preschoolers for two reasons. Firstly, as they have trouble with fine motor skills and their hand-eye coordination is still in development, they are less exact with their stylus movements; and secondly, their fingers are so small that they mimic the stylus very effectively, and therefore by using their fingers they can often be more accurate in their game interactions.", "hypothesis": "Video game use amongst preschool children is higher in the US than in other countries.", "gold_label": "neutral"}
{"uid": "id_307", "premise": "Video game research Although video games were first developed for adults, they are no longer exclusively reserved for the grown ups in the home. In 2006, Rideout and Hamel reported that as many as 29 percent of preschool children (children between two and six years old) in the United States had played console video games, and 18 percent had played hand-held ones. Given young childrens insatiable eagerness to learn, coupled with the fact that they are clearly surrounded by these media, we predict that preschoolers will both continue and increasingly begin to adopt video games for personal enjoyment. Although the majority of gaming equipment is still designed for a much older target audience, once a game system enters the household it is potentially available for all family members, including the youngest. Portable systems have done a particularly good job of penetrating the younger market. Research in the video game market is typically done at two stages: some time close to the end of the product cycle, in order to get feedback from consumers, so that a marketing strategy can be developed; and at the very end of the product cycle to fix bugs in the game. While both of those types of research are important, and may be appropriate for dealing with adult consumers, neither of them aids in designing better games, especially when it comes to designing for an audience that may have particular needs, such as preschoolers or senior citizens. Instead, exploratory and formative research has to be undertaken in order to truly understand those audiences, their abilities, their perspective, and their needs. In the spring of 2007, our preschool-game production team at Nickelodeon had a hunch that the Nintendo DS with its new features, such as the microphone, small size and portability, and its relatively low price point was a ripe gaming platform for preschoolers. There were a few games on the market at the time which had characters that appealed to the younger set, but our game producers did not think that the game mechanics or design were appropriate for preschoolers. What exactly preschoolers could do with the system, however, was a bit of a mystery. So we set about doing a study to answer the query: What could we expect preschoolers to be capable of in the context of hand-held game play, and how might the child development literature inform us as we proceeded with the creation of a new outlet for this age group? Our context in this case was the United States, although the games that resulted were also released in other regions, due to the broad international reach of the characters. In order to design the best possible DS product for a preschool audience we were fully committed to the ideals of a user-centered approach, which assumes that users will be at least considered, but ideally consulted during the development process. After all, when it comes to introducing a new interactive product to the child market, and particularly such a young age group within it, we believe it is crucial to assess the range of physical and cognitive abilities associated with their specific developmental stage. Revelle and Medoff (2002) review some of the basic reasons why home entertainment systems, computers, and other electronic gaming devices, are often difficult for preschoolers to use. In addition to their still developing motor skills (which make manipulating a controller with small buttons difficult), many of the major stumbling blocks are cognitive. Though preschoolers are learning to think symbolically, and understand that pictures can stand for real-life objects, the vast majority are still unable to read and write. Thus, using text-based menu selections is not viable. Mapping is yet another obstacle since preschoolers may be unable to understand that there is a direct link between how the controller is used and the activities that appear before them on screen. Though this aspect is changing, in traditional mapping systems real life movements do not usually translate into game-based activity. Over the course of our study, we gained many insights into how preschoolers interact with various platforms, including the DS. For instance, all instructions for preschoolers need to be in voice-over, and include visual representations, and this has been one of the most difficult areas for us to negotiate with respect to game design on the DS. Because the game cartridges have very limited memory capacity, particularly in comparison to console or computer games, the ability to capture large amounts of voice-over data via sound files or visual representations of instructions becomes limited. Text instructions take up minimal memory, so they are preferable from a technological perspective. Figuring out ways to maximise sound and graphics files, while retaining the clear visual and verbal cues that we know are critical for our youngest players, is a constant give and take. Another of our findings indicated that preschoolers may use either a stylus, or their fingers, or both although they are not very accurate with either. One of the very interesting aspects of the DS is that the interface, which is designed to respond to stylus interactions, can also effectively be used with the tip of the finger. This is particularly noteworthy in the context of preschoolers for two reasons. Firstly, as they have trouble with fine motor skills and their hand-eye coordination is still in development, they are less exact with their stylus movements; and secondly, their fingers are so small that they mimic the stylus very effectively, and therefore by using their fingers they can often be more accurate in their game interactions.", "hypothesis": "The proportion of preschool children using video games is likely to rise.", "gold_label": "entailment"}
{"uid": "id_308", "premise": "Video game research Although video games were first developed for adults, they are no longer exclusively reserved for the grown ups in the home. In 2006, Rideout and Hamel reported that as many as 29 percent of preschool children (children between two and six years old) in the United States had played console video games, and 18 percent had played hand-held ones. Given young childrens insatiable eagerness to learn, coupled with the fact that they are clearly surrounded by these media, we predict that preschoolers will both continue and increasingly begin to adopt video games for personal enjoyment. Although the majority of gaming equipment is still designed for a much older target audience, once a game system enters the household it is potentially available for all family members, including the youngest. Portable systems have done a particularly good job of penetrating the younger market. Research in the video game market is typically done at two stages: some time close to the end of the product cycle, in order to get feedback from consumers, so that a marketing strategy can be developed; and at the very end of the product cycle to fix bugs in the game. While both of those types of research are important, and may be appropriate for dealing with adult consumers, neither of them aids in designing better games, especially when it comes to designing for an audience that may have particular needs, such as preschoolers or senior citizens. Instead, exploratory and formative research has to be undertaken in order to truly understand those audiences, their abilities, their perspective, and their needs. In the spring of 2007, our preschool-game production team at Nickelodeon had a hunch that the Nintendo DS with its new features, such as the microphone, small size and portability, and its relatively low price point was a ripe gaming platform for preschoolers. There were a few games on the market at the time which had characters that appealed to the younger set, but our game producers did not think that the game mechanics or design were appropriate for preschoolers. What exactly preschoolers could do with the system, however, was a bit of a mystery. So we set about doing a study to answer the query: What could we expect preschoolers to be capable of in the context of hand-held game play, and how might the child development literature inform us as we proceeded with the creation of a new outlet for this age group? Our context in this case was the United States, although the games that resulted were also released in other regions, due to the broad international reach of the characters. In order to design the best possible DS product for a preschool audience we were fully committed to the ideals of a user-centered approach, which assumes that users will be at least considered, but ideally consulted during the development process. After all, when it comes to introducing a new interactive product to the child market, and particularly such a young age group within it, we believe it is crucial to assess the range of physical and cognitive abilities associated with their specific developmental stage. Revelle and Medoff (2002) review some of the basic reasons why home entertainment systems, computers, and other electronic gaming devices, are often difficult for preschoolers to use. In addition to their still developing motor skills (which make manipulating a controller with small buttons difficult), many of the major stumbling blocks are cognitive. Though preschoolers are learning to think symbolically, and understand that pictures can stand for real-life objects, the vast majority are still unable to read and write. Thus, using text-based menu selections is not viable. Mapping is yet another obstacle since preschoolers may be unable to understand that there is a direct link between how the controller is used and the activities that appear before them on screen. Though this aspect is changing, in traditional mapping systems real life movements do not usually translate into game-based activity. Over the course of our study, we gained many insights into how preschoolers interact with various platforms, including the DS. For instance, all instructions for preschoolers need to be in voice-over, and include visual representations, and this has been one of the most difficult areas for us to negotiate with respect to game design on the DS. Because the game cartridges have very limited memory capacity, particularly in comparison to console or computer games, the ability to capture large amounts of voice-over data via sound files or visual representations of instructions becomes limited. Text instructions take up minimal memory, so they are preferable from a technological perspective. Figuring out ways to maximise sound and graphics files, while retaining the clear visual and verbal cues that we know are critical for our youngest players, is a constant give and take. Another of our findings indicated that preschoolers may use either a stylus, or their fingers, or both although they are not very accurate with either. One of the very interesting aspects of the DS is that the interface, which is designed to respond to stylus interactions, can also effectively be used with the tip of the finger. This is particularly noteworthy in the context of preschoolers for two reasons. Firstly, as they have trouble with fine motor skills and their hand-eye coordination is still in development, they are less exact with their stylus movements; and secondly, their fingers are so small that they mimic the stylus very effectively, and therefore by using their fingers they can often be more accurate in their game interactions.", "hypothesis": "Parents in the US who own gaming equipment generally allow their children to play with it.", "gold_label": "neutral"}
{"uid": "id_309", "premise": "Video game research Although video games were first developed for adults, they are no longer exclusively reserved for the grown ups in the home. In 2006, Rideout and Hamel reported that as many as 29 percent of preschool children (children between two and six years old) in the United States had played console video games, and 18 percent had played hand-held ones. Given young childrens insatiable eagerness to learn, coupled with the fact that they are clearly surrounded by these media, we predict that preschoolers will both continue and increasingly begin to adopt video games for personal enjoyment. Although the majority of gaming equipment is still designed for a much older target audience, once a game system enters the household it is potentially available for all family members, including the youngest. Portable systems have done a particularly good job of penetrating the younger market. Research in the video game market is typically done at two stages: some time close to the end of the product cycle, in order to get feedback from consumers, so that a marketing strategy can be developed; and at the very end of the product cycle to fix bugs in the game. While both of those types of research are important, and may be appropriate for dealing with adult consumers, neither of them aids in designing better games, especially when it comes to designing for an audience that may have particular needs, such as preschoolers or senior citizens. Instead, exploratory and formative research has to be undertaken in order to truly understand those audiences, their abilities, their perspective, and their needs. In the spring of 2007, our preschool-game production team at Nickelodeon had a hunch that the Nintendo DS with its new features, such as the microphone, small size and portability, and its relatively low price point was a ripe gaming platform for preschoolers. There were a few games on the market at the time which had characters that appealed to the younger set, but our game producers did not think that the game mechanics or design were appropriate for preschoolers. What exactly preschoolers could do with the system, however, was a bit of a mystery. So we set about doing a study to answer the query: What could we expect preschoolers to be capable of in the context of hand-held game play, and how might the child development literature inform us as we proceeded with the creation of a new outlet for this age group? Our context in this case was the United States, although the games that resulted were also released in other regions, due to the broad international reach of the characters. In order to design the best possible DS product for a preschool audience we were fully committed to the ideals of a user-centered approach, which assumes that users will be at least considered, but ideally consulted during the development process. After all, when it comes to introducing a new interactive product to the child market, and particularly such a young age group within it, we believe it is crucial to assess the range of physical and cognitive abilities associated with their specific developmental stage. Revelle and Medoff (2002) review some of the basic reasons why home entertainment systems, computers, and other electronic gaming devices, are often difficult for preschoolers to use. In addition to their still developing motor skills (which make manipulating a controller with small buttons difficult), many of the major stumbling blocks are cognitive. Though preschoolers are learning to think symbolically, and understand that pictures can stand for real-life objects, the vast majority are still unable to read and write. Thus, using text-based menu selections is not viable. Mapping is yet another obstacle since preschoolers may be unable to understand that there is a direct link between how the controller is used and the activities that appear before them on screen. Though this aspect is changing, in traditional mapping systems real life movements do not usually translate into game-based activity. Over the course of our study, we gained many insights into how preschoolers interact with various platforms, including the DS. For instance, all instructions for preschoolers need to be in voice-over, and include visual representations, and this has been one of the most difficult areas for us to negotiate with respect to game design on the DS. Because the game cartridges have very limited memory capacity, particularly in comparison to console or computer games, the ability to capture large amounts of voice-over data via sound files or visual representations of instructions becomes limited. Text instructions take up minimal memory, so they are preferable from a technological perspective. Figuring out ways to maximise sound and graphics files, while retaining the clear visual and verbal cues that we know are critical for our youngest players, is a constant give and take. Another of our findings indicated that preschoolers may use either a stylus, or their fingers, or both although they are not very accurate with either. One of the very interesting aspects of the DS is that the interface, which is designed to respond to stylus interactions, can also effectively be used with the tip of the finger. This is particularly noteworthy in the context of preschoolers for two reasons. Firstly, as they have trouble with fine motor skills and their hand-eye coordination is still in development, they are less exact with their stylus movements; and secondly, their fingers are so small that they mimic the stylus very effectively, and therefore by using their fingers they can often be more accurate in their game interactions.", "hypothesis": "The type of research which manufacturers usually do is aimed at improving game design.", "gold_label": "contradiction"}
{"uid": "id_310", "premise": "Video game research Although video games were first developed for adults, they are no longer exclusively reserved for the grown ups in the home. In 2006, Rideout and Hamel reported that as many as 29 percent of preschool children (children between two and six years old) in the United States had played console video games, and 18 percent had played hand-held ones. Given young childrens insatiable eagerness to learn, coupled with the fact that they are clearly surrounded by these media, we predict that preschoolers will both continue and increasingly begin to adopt video games for personal enjoyment. Although the majority of gaming equipment is still designed for a much older target audience, once a game system enters the household it is potentially available for all family members, including the youngest. Portable systems have done a particularly good job of penetrating the younger market. Research in the video game market is typically done at two stages: some time close to the end of the product cycle, in order to get feedback from consumers, so that a marketing strategy can be developed; and at the very end of the product cycle to fix bugs in the game. While both of those types of research are important, and may be appropriate for dealing with adult consumers, neither of them aids in designing better games, especially when it comes to designing for an audience that may have particular needs, such as preschoolers or senior citizens. Instead, exploratory and formative research has to be undertaken in order to truly understand those audiences, their abilities, their perspective, and their needs. In the spring of 2007, our preschool-game production team at Nickelodeon had a hunch that the Nintendo DS with its new features, such as the microphone, small size and portability, and its relatively low price point was a ripe gaming platform for preschoolers. There were a few games on the market at the time which had characters that appealed to the younger set, but our game producers did not think that the game mechanics or design were appropriate for preschoolers. What exactly preschoolers could do with the system, however, was a bit of a mystery. So we set about doing a study to answer the query: What could we expect preschoolers to be capable of in the context of hand-held game play, and how might the child development literature inform us as we proceeded with the creation of a new outlet for this age group? Our context in this case was the United States, although the games that resulted were also released in other regions, due to the broad international reach of the characters. In order to design the best possible DS product for a preschool audience we were fully committed to the ideals of a user-centered approach, which assumes that users will be at least considered, but ideally consulted during the development process. After all, when it comes to introducing a new interactive product to the child market, and particularly such a young age group within it, we believe it is crucial to assess the range of physical and cognitive abilities associated with their specific developmental stage. Revelle and Medoff (2002) review some of the basic reasons why home entertainment systems, computers, and other electronic gaming devices, are often difficult for preschoolers to use. In addition to their still developing motor skills (which make manipulating a controller with small buttons difficult), many of the major stumbling blocks are cognitive. Though preschoolers are learning to think symbolically, and understand that pictures can stand for real-life objects, the vast majority are still unable to read and write. Thus, using text-based menu selections is not viable. Mapping is yet another obstacle since preschoolers may be unable to understand that there is a direct link between how the controller is used and the activities that appear before them on screen. Though this aspect is changing, in traditional mapping systems real life movements do not usually translate into game-based activity. Over the course of our study, we gained many insights into how preschoolers interact with various platforms, including the DS. For instance, all instructions for preschoolers need to be in voice-over, and include visual representations, and this has been one of the most difficult areas for us to negotiate with respect to game design on the DS. Because the game cartridges have very limited memory capacity, particularly in comparison to console or computer games, the ability to capture large amounts of voice-over data via sound files or visual representations of instructions becomes limited. Text instructions take up minimal memory, so they are preferable from a technological perspective. Figuring out ways to maximise sound and graphics files, while retaining the clear visual and verbal cues that we know are critical for our youngest players, is a constant give and take. Another of our findings indicated that preschoolers may use either a stylus, or their fingers, or both although they are not very accurate with either. One of the very interesting aspects of the DS is that the interface, which is designed to respond to stylus interactions, can also effectively be used with the tip of the finger. This is particularly noteworthy in the context of preschoolers for two reasons. Firstly, as they have trouble with fine motor skills and their hand-eye coordination is still in development, they are less exact with their stylus movements; and secondly, their fingers are so small that they mimic the stylus very effectively, and therefore by using their fingers they can often be more accurate in their game interactions.", "hypothesis": "Both old and young games consumers require research which is specifically targeted", "gold_label": "entailment"}
{"uid": "id_311", "premise": "Vincent has a paper route Each morning he delivers 37 newspapers to customers in his neighborhood. It takes Vincent 50 minutes to deliver all the papers. If Vincent is sick or has other plans, his friend Thomas, who lives on the same street, will sometimes deliver the papers for him.", "hypothesis": "It is dark outside when Vincent begins his deliveries.", "gold_label": "neutral"}
{"uid": "id_312", "premise": "Vincent has a paper route Each morning he delivers 37 newspapers to customers in his neighborhood. It takes Vincent 50 minutes to deliver all the papers. If Vincent is sick or has other plans, his friend Thomas, who lives on the same street, will sometimes deliver the papers for him.", "hypothesis": "Vincent and Thomas live in the same neighborhood.", "gold_label": "entailment"}
{"uid": "id_313", "premise": "Vincent has a paper route Each morning he delivers 37 newspapers to customers in his neighborhood. It takes Vincent 50 minutes to deliver all the papers. If Vincent is sick or has other plans, his friend Thomas, who lives on the same street, will sometimes deliver the papers for him.", "hypothesis": "It takes Thomas more than 50 minutes to deliver the papers.", "gold_label": "neutral"}
{"uid": "id_314", "premise": "Vincent has a paper route Each morning he delivers 37 newspapers to customers in his neighborhood. It takes Vincent 50 minutes to deliver all the papers. If Vincent is sick or has other plans, his friend Thomas, who lives on the same street, will sometimes deliver the papers for him.", "hypothesis": "Thomas would like to have his own paper route.", "gold_label": "neutral"}
{"uid": "id_315", "premise": "Vitamins To supplement or not? Mineral, vitamin, and antioxidant health supplements make up a multi-billion-dollar industry in the United States alone, but do they really work? Evidence suggests supplementation is clearly indicated in special circumstances, but can actually be harmful in others. For the general population, however, supplements have negligible or no impact on the prevention of common cancers, cardiovascular diseases, cognitive decline, mortality, or any other major indicators of health. In pursuit of a longer, happier and healthier life, there are certainly better investments for most people than a tube of vitamin supplements. Particular sub-groups of the population can gain a proven benefit from supplementation. Folic acid has long been indicated as a prenatal supplement due to its assistance in foetal cell division and corresponding ability to prevent neural tube birth defects. Since Canada and the United States decided to require white flour to be fortified with folic acid, spinal birth defects have plummeted by 75%, and rates of neuroblastoma (a ravaging form of infant cancer) are now 50% lower. In countries without such fortification, or for women on low-carbohydrate diets, a prenatal multivitamin could make the crucial difference. The United States Department of Health and Human Services has concluded that the elderly may also benefit from extra vitamin D; calcium can help prevent bone fractures; and zinc and antioxidants can maintain vision while deflecting macular degeneration in people who would otherwise be likely to develop this affliction. There is mounting evidence, however, for many people to steer clear of multivitamins. The National Institutes of Health has noted a disturbing evidence of risk in tobacco users: beta-carotene, a common ingredient in multivitamins, was found over a six-year study to significantly contribute to higher lung cancer and mortality rates in smokers. Meanwhile, excessive vitamin A (a supplement often taken to boost the immune system) has been proven to increase womens risk of a hip fracture, and vitamin E, thought to improve cardiovascular health, was contraindicated in a study that demonstrated higher rates of congestive heart failure among such vitamin users. Antioxidant supplementation has no purpose nor does it achieve anything, according to the Food and Nutrition Board of the National Academy of Sciences, and the Medical Letter Group has gone further in suggesting they may interfere with treatment and promote some cancers. Antioxidants are generally regarded as counteracting the destructive effect of free radicals in the body, but according to the Medical Letters theory, free radicals may also serve the purpose of sending a powerful signal to the bodys immune system to fix the damage. By taking supplements, we risk undermining that message and upsetting the balance of antioxidants and free radicals in the body. The supplements counteract the free radicals, the immune system is not placed on alert, and the disease could sneak through the gates. One problem with supplementation by tablet is the poor record on digestibility. These tablets are often stocked with metal-based minerals that are essentially miniature rocks, and our bodies are unable to digest them. Even the vitamin elements of these pills that are theoretically digestible are often unable to be effectively extracted by our bodies when they arrive in such a condensed form. In Salt Lake City, for example, over 150 gallons of vitamin and mineral pills are retrieved from the sewer filters each month. According to the physicians desk reference, only about 10% 20% of multivitamins are absorbed by the body. The National Advisory Board is even more damning, suggesting that every 100mg of tablet corresponds to about 8.3mg of blood concentration, although noting that this can still potentially perform a helpful role in some cases. In effect, for every $100 you spend on vitamin supplements, over $90 of that is quite literally flushed down the toilet. A final argument against multivitamins is the notion that they can lead people consciously or not to the conclusion that supplementation fills in the gaps of an unhealthy diet and mops up afterwards, leaving their bodies none the wiser that instead of preparing a breakfast of fresh fruit and muesli, they popped a tiny capsule with coffee and a chocolate bar. In a seven-year study, however, the Heart Protection study did not find any positive outcome whatsoever from multivitamins and concluded that while vitamins in the diet are important, multivitamin tablets are safe but completely useless. There is evidently no shortcut around the task of buying, preparing, and consuming fresh fruit and vegetables every day. Boosting, supplementing, and fortifying products alter peoples very perception of what healthy food is; instead of heading for the fresh produce aisle in the supermarket, they are likely to seek out sugary, processed foods with a handful of extra B vitamins as a healthy choice. We cannot supplement our way out of a bad diet.", "hypothesis": "Some multivitamin tablets have indigestible ingredients.", "gold_label": "entailment"}
{"uid": "id_316", "premise": "Vitamins To supplement or not? Mineral, vitamin, and antioxidant health supplements make up a multi-billion-dollar industry in the United States alone, but do they really work? Evidence suggests supplementation is clearly indicated in special circumstances, but can actually be harmful in others. For the general population, however, supplements have negligible or no impact on the prevention of common cancers, cardiovascular diseases, cognitive decline, mortality, or any other major indicators of health. In pursuit of a longer, happier and healthier life, there are certainly better investments for most people than a tube of vitamin supplements. Particular sub-groups of the population can gain a proven benefit from supplementation. Folic acid has long been indicated as a prenatal supplement due to its assistance in foetal cell division and corresponding ability to prevent neural tube birth defects. Since Canada and the United States decided to require white flour to be fortified with folic acid, spinal birth defects have plummeted by 75%, and rates of neuroblastoma (a ravaging form of infant cancer) are now 50% lower. In countries without such fortification, or for women on low-carbohydrate diets, a prenatal multivitamin could make the crucial difference. The United States Department of Health and Human Services has concluded that the elderly may also benefit from extra vitamin D; calcium can help prevent bone fractures; and zinc and antioxidants can maintain vision while deflecting macular degeneration in people who would otherwise be likely to develop this affliction. There is mounting evidence, however, for many people to steer clear of multivitamins. The National Institutes of Health has noted a disturbing evidence of risk in tobacco users: beta-carotene, a common ingredient in multivitamins, was found over a six-year study to significantly contribute to higher lung cancer and mortality rates in smokers. Meanwhile, excessive vitamin A (a supplement often taken to boost the immune system) has been proven to increase womens risk of a hip fracture, and vitamin E, thought to improve cardiovascular health, was contraindicated in a study that demonstrated higher rates of congestive heart failure among such vitamin users. Antioxidant supplementation has no purpose nor does it achieve anything, according to the Food and Nutrition Board of the National Academy of Sciences, and the Medical Letter Group has gone further in suggesting they may interfere with treatment and promote some cancers. Antioxidants are generally regarded as counteracting the destructive effect of free radicals in the body, but according to the Medical Letters theory, free radicals may also serve the purpose of sending a powerful signal to the bodys immune system to fix the damage. By taking supplements, we risk undermining that message and upsetting the balance of antioxidants and free radicals in the body. The supplements counteract the free radicals, the immune system is not placed on alert, and the disease could sneak through the gates. One problem with supplementation by tablet is the poor record on digestibility. These tablets are often stocked with metal-based minerals that are essentially miniature rocks, and our bodies are unable to digest them. Even the vitamin elements of these pills that are theoretically digestible are often unable to be effectively extracted by our bodies when they arrive in such a condensed form. In Salt Lake City, for example, over 150 gallons of vitamin and mineral pills are retrieved from the sewer filters each month. According to the physicians desk reference, only about 10% 20% of multivitamins are absorbed by the body. The National Advisory Board is even more damning, suggesting that every 100mg of tablet corresponds to about 8.3mg of blood concentration, although noting that this can still potentially perform a helpful role in some cases. In effect, for every $100 you spend on vitamin supplements, over $90 of that is quite literally flushed down the toilet. A final argument against multivitamins is the notion that they can lead people consciously or not to the conclusion that supplementation fills in the gaps of an unhealthy diet and mops up afterwards, leaving their bodies none the wiser that instead of preparing a breakfast of fresh fruit and muesli, they popped a tiny capsule with coffee and a chocolate bar. In a seven-year study, however, the Heart Protection study did not find any positive outcome whatsoever from multivitamins and concluded that while vitamins in the diet are important, multivitamin tablets are safe but completely useless. There is evidently no shortcut around the task of buying, preparing, and consuming fresh fruit and vegetables every day. Boosting, supplementing, and fortifying products alter peoples very perception of what healthy food is; instead of heading for the fresh produce aisle in the supermarket, they are likely to seek out sugary, processed foods with a handful of extra B vitamins as a healthy choice. We cannot supplement our way out of a bad diet.", "hypothesis": "Some individual vitamins are better absorbed than others in a tablet form.", "gold_label": "neutral"}
{"uid": "id_317", "premise": "Vitamins To supplement or not? Mineral, vitamin, and antioxidant health supplements make up a multi-billion-dollar industry in the United States alone, but do they really work? Evidence suggests supplementation is clearly indicated in special circumstances, but can actually be harmful in others. For the general population, however, supplements have negligible or no impact on the prevention of common cancers, cardiovascular diseases, cognitive decline, mortality, or any other major indicators of health. In pursuit of a longer, happier and healthier life, there are certainly better investments for most people than a tube of vitamin supplements. Particular sub-groups of the population can gain a proven benefit from supplementation. Folic acid has long been indicated as a prenatal supplement due to its assistance in foetal cell division and corresponding ability to prevent neural tube birth defects. Since Canada and the United States decided to require white flour to be fortified with folic acid, spinal birth defects have plummeted by 75%, and rates of neuroblastoma (a ravaging form of infant cancer) are now 50% lower. In countries without such fortification, or for women on low-carbohydrate diets, a prenatal multivitamin could make the crucial difference. The United States Department of Health and Human Services has concluded that the elderly may also benefit from extra vitamin D; calcium can help prevent bone fractures; and zinc and antioxidants can maintain vision while deflecting macular degeneration in people who would otherwise be likely to develop this affliction. There is mounting evidence, however, for many people to steer clear of multivitamins. The National Institutes of Health has noted a disturbing evidence of risk in tobacco users: beta-carotene, a common ingredient in multivitamins, was found over a six-year study to significantly contribute to higher lung cancer and mortality rates in smokers. Meanwhile, excessive vitamin A (a supplement often taken to boost the immune system) has been proven to increase womens risk of a hip fracture, and vitamin E, thought to improve cardiovascular health, was contraindicated in a study that demonstrated higher rates of congestive heart failure among such vitamin users. Antioxidant supplementation has no purpose nor does it achieve anything, according to the Food and Nutrition Board of the National Academy of Sciences, and the Medical Letter Group has gone further in suggesting they may interfere with treatment and promote some cancers. Antioxidants are generally regarded as counteracting the destructive effect of free radicals in the body, but according to the Medical Letters theory, free radicals may also serve the purpose of sending a powerful signal to the bodys immune system to fix the damage. By taking supplements, we risk undermining that message and upsetting the balance of antioxidants and free radicals in the body. The supplements counteract the free radicals, the immune system is not placed on alert, and the disease could sneak through the gates. One problem with supplementation by tablet is the poor record on digestibility. These tablets are often stocked with metal-based minerals that are essentially miniature rocks, and our bodies are unable to digest them. Even the vitamin elements of these pills that are theoretically digestible are often unable to be effectively extracted by our bodies when they arrive in such a condensed form. In Salt Lake City, for example, over 150 gallons of vitamin and mineral pills are retrieved from the sewer filters each month. According to the physicians desk reference, only about 10% 20% of multivitamins are absorbed by the body. The National Advisory Board is even more damning, suggesting that every 100mg of tablet corresponds to about 8.3mg of blood concentration, although noting that this can still potentially perform a helpful role in some cases. In effect, for every $100 you spend on vitamin supplements, over $90 of that is quite literally flushed down the toilet. A final argument against multivitamins is the notion that they can lead people consciously or not to the conclusion that supplementation fills in the gaps of an unhealthy diet and mops up afterwards, leaving their bodies none the wiser that instead of preparing a breakfast of fresh fruit and muesli, they popped a tiny capsule with coffee and a chocolate bar. In a seven-year study, however, the Heart Protection study did not find any positive outcome whatsoever from multivitamins and concluded that while vitamins in the diet are important, multivitamin tablets are safe but completely useless. There is evidently no shortcut around the task of buying, preparing, and consuming fresh fruit and vegetables every day. Boosting, supplementing, and fortifying products alter peoples very perception of what healthy food is; instead of heading for the fresh produce aisle in the supermarket, they are likely to seek out sugary, processed foods with a handful of extra B vitamins as a healthy choice. We cannot supplement our way out of a bad diet.", "hypothesis": "Our bodies cannot distinguish food-based from supplement-based vitamins.", "gold_label": "neutral"}
{"uid": "id_318", "premise": "Vitamins To supplement or not? Mineral, vitamin, and antioxidant health supplements make up a multi-billion-dollar industry in the United States alone, but do they really work? Evidence suggests supplementation is clearly indicated in special circumstances, but can actually be harmful in others. For the general population, however, supplements have negligible or no impact on the prevention of common cancers, cardiovascular diseases, cognitive decline, mortality, or any other major indicators of health. In pursuit of a longer, happier and healthier life, there are certainly better investments for most people than a tube of vitamin supplements. Particular sub-groups of the population can gain a proven benefit from supplementation. Folic acid has long been indicated as a prenatal supplement due to its assistance in foetal cell division and corresponding ability to prevent neural tube birth defects. Since Canada and the United States decided to require white flour to be fortified with folic acid, spinal birth defects have plummeted by 75%, and rates of neuroblastoma (a ravaging form of infant cancer) are now 50% lower. In countries without such fortification, or for women on low-carbohydrate diets, a prenatal multivitamin could make the crucial difference. The United States Department of Health and Human Services has concluded that the elderly may also benefit from extra vitamin D; calcium can help prevent bone fractures; and zinc and antioxidants can maintain vision while deflecting macular degeneration in people who would otherwise be likely to develop this affliction. There is mounting evidence, however, for many people to steer clear of multivitamins. The National Institutes of Health has noted a disturbing evidence of risk in tobacco users: beta-carotene, a common ingredient in multivitamins, was found over a six-year study to significantly contribute to higher lung cancer and mortality rates in smokers. Meanwhile, excessive vitamin A (a supplement often taken to boost the immune system) has been proven to increase womens risk of a hip fracture, and vitamin E, thought to improve cardiovascular health, was contraindicated in a study that demonstrated higher rates of congestive heart failure among such vitamin users. Antioxidant supplementation has no purpose nor does it achieve anything, according to the Food and Nutrition Board of the National Academy of Sciences, and the Medical Letter Group has gone further in suggesting they may interfere with treatment and promote some cancers. Antioxidants are generally regarded as counteracting the destructive effect of free radicals in the body, but according to the Medical Letters theory, free radicals may also serve the purpose of sending a powerful signal to the bodys immune system to fix the damage. By taking supplements, we risk undermining that message and upsetting the balance of antioxidants and free radicals in the body. The supplements counteract the free radicals, the immune system is not placed on alert, and the disease could sneak through the gates. One problem with supplementation by tablet is the poor record on digestibility. These tablets are often stocked with metal-based minerals that are essentially miniature rocks, and our bodies are unable to digest them. Even the vitamin elements of these pills that are theoretically digestible are often unable to be effectively extracted by our bodies when they arrive in such a condensed form. In Salt Lake City, for example, over 150 gallons of vitamin and mineral pills are retrieved from the sewer filters each month. According to the physicians desk reference, only about 10% 20% of multivitamins are absorbed by the body. The National Advisory Board is even more damning, suggesting that every 100mg of tablet corresponds to about 8.3mg of blood concentration, although noting that this can still potentially perform a helpful role in some cases. In effect, for every $100 you spend on vitamin supplements, over $90 of that is quite literally flushed down the toilet. A final argument against multivitamins is the notion that they can lead people consciously or not to the conclusion that supplementation fills in the gaps of an unhealthy diet and mops up afterwards, leaving their bodies none the wiser that instead of preparing a breakfast of fresh fruit and muesli, they popped a tiny capsule with coffee and a chocolate bar. In a seven-year study, however, the Heart Protection study did not find any positive outcome whatsoever from multivitamins and concluded that while vitamins in the diet are important, multivitamin tablets are safe but completely useless. There is evidently no shortcut around the task of buying, preparing, and consuming fresh fruit and vegetables every day. Boosting, supplementing, and fortifying products alter peoples very perception of what healthy food is; instead of heading for the fresh produce aisle in the supermarket, they are likely to seek out sugary, processed foods with a handful of extra B vitamins as a healthy choice. We cannot supplement our way out of a bad diet.", "hypothesis": "Multivitamins can lead to poorer overall eating habits in a persons life.", "gold_label": "entailment"}
{"uid": "id_319", "premise": "Vitamins To supplement or not? Mineral, vitamin, and antioxidant health supplements make up a multi-billion-dollar industry in the United States alone, but do they really work? Evidence suggests supplementation is clearly indicated in special circumstances, but can actually be harmful in others. For the general population, however, supplements have negligible or no impact on the prevention of common cancers, cardiovascular diseases, cognitive decline, mortality, or any other major indicators of health. In pursuit of a longer, happier and healthier life, there are certainly better investments for most people than a tube of vitamin supplements. Particular sub-groups of the population can gain a proven benefit from supplementation. Folic acid has long been indicated as a prenatal supplement due to its assistance in foetal cell division and corresponding ability to prevent neural tube birth defects. Since Canada and the United States decided to require white flour to be fortified with folic acid, spinal birth defects have plummeted by 75%, and rates of neuroblastoma (a ravaging form of infant cancer) are now 50% lower. In countries without such fortification, or for women on low-carbohydrate diets, a prenatal multivitamin could make the crucial difference. The United States Department of Health and Human Services has concluded that the elderly may also benefit from extra vitamin D; calcium can help prevent bone fractures; and zinc and antioxidants can maintain vision while deflecting macular degeneration in people who would otherwise be likely to develop this affliction. There is mounting evidence, however, for many people to steer clear of multivitamins. The National Institutes of Health has noted a disturbing evidence of risk in tobacco users: beta-carotene, a common ingredient in multivitamins, was found over a six-year study to significantly contribute to higher lung cancer and mortality rates in smokers. Meanwhile, excessive vitamin A (a supplement often taken to boost the immune system) has been proven to increase womens risk of a hip fracture, and vitamin E, thought to improve cardiovascular health, was contraindicated in a study that demonstrated higher rates of congestive heart failure among such vitamin users. Antioxidant supplementation has no purpose nor does it achieve anything, according to the Food and Nutrition Board of the National Academy of Sciences, and the Medical Letter Group has gone further in suggesting they may interfere with treatment and promote some cancers. Antioxidants are generally regarded as counteracting the destructive effect of free radicals in the body, but according to the Medical Letters theory, free radicals may also serve the purpose of sending a powerful signal to the bodys immune system to fix the damage. By taking supplements, we risk undermining that message and upsetting the balance of antioxidants and free radicals in the body. The supplements counteract the free radicals, the immune system is not placed on alert, and the disease could sneak through the gates. One problem with supplementation by tablet is the poor record on digestibility. These tablets are often stocked with metal-based minerals that are essentially miniature rocks, and our bodies are unable to digest them. Even the vitamin elements of these pills that are theoretically digestible are often unable to be effectively extracted by our bodies when they arrive in such a condensed form. In Salt Lake City, for example, over 150 gallons of vitamin and mineral pills are retrieved from the sewer filters each month. According to the physicians desk reference, only about 10% 20% of multivitamins are absorbed by the body. The National Advisory Board is even more damning, suggesting that every 100mg of tablet corresponds to about 8.3mg of blood concentration, although noting that this can still potentially perform a helpful role in some cases. In effect, for every $100 you spend on vitamin supplements, over $90 of that is quite literally flushed down the toilet. A final argument against multivitamins is the notion that they can lead people consciously or not to the conclusion that supplementation fills in the gaps of an unhealthy diet and mops up afterwards, leaving their bodies none the wiser that instead of preparing a breakfast of fresh fruit and muesli, they popped a tiny capsule with coffee and a chocolate bar. In a seven-year study, however, the Heart Protection study did not find any positive outcome whatsoever from multivitamins and concluded that while vitamins in the diet are important, multivitamin tablets are safe but completely useless. There is evidently no shortcut around the task of buying, preparing, and consuming fresh fruit and vegetables every day. Boosting, supplementing, and fortifying products alter peoples very perception of what healthy food is; instead of heading for the fresh produce aisle in the supermarket, they are likely to seek out sugary, processed foods with a handful of extra B vitamins as a healthy choice. We cannot supplement our way out of a bad diet.", "hypothesis": "People typically know that fortified processed foods are not good for them.", "gold_label": "contradiction"}
{"uid": "id_320", "premise": "Volunteers Thank you for volunteering to work one-on-one with some of the students at our school who need extra help. Smoking policy Smoking is prohibited by law in the classrooms and anywhere on the school grounds. Safety and Health Volunteers are responsible for their own personal safety and should notify the school of any pre-existing medical conditions. Prescription and any other medications that you normally carry with you must be handed in to the school nurse on arrival and collected on departure. If you require them, the nurse will dispense them to you in her office. Sign-in A sign-in book is located at office reception. Please sign this register every time you come to the school. This is important for insurance purposes and emergency situations. After signing the book, collect a Visitors badge from the office. This must be worn at all times when you are on school premises. Remember to return the badge afterwards. Messages Teachers will communicate with volunteers via telephone, email or messages left at the office. Always ask for messages. You may communicate with teachers in the same way the preferred method is to leave a memo in the relevant teachers pigeonhole. These can be found at the end of the corridor in the staffroom block. Work hours We understand that your time commitment is entirely voluntary and therefore flexible. If your personal schedule should change and this affects your availability, please contact the Co-ordinator for Volunteers at the school on extension 402: alternatively, you could drop in to her office situated in F block. Role of the Co-ordinator The Co-ordinator is responsible for matching volunteer tutors with students, organising tutorial rooms, ensuring student attendance and overseeing volunteer tutor training. If you encounter any problems, contact her as above.", "hypothesis": "If you forget to sign the register, you wont be insured for accidents.", "gold_label": "neutral"}
{"uid": "id_321", "premise": "Volunteers Thank you for volunteering to work one-on-one with some of the students at our school who need extra help. Smoking policy Smoking is prohibited by law in the classrooms and anywhere on the school grounds. Safety and Health Volunteers are responsible for their own personal safety and should notify the school of any pre-existing medical conditions. Prescription and any other medications that you normally carry with you must be handed in to the school nurse on arrival and collected on departure. If you require them, the nurse will dispense them to you in her office. Sign-in A sign-in book is located at office reception. Please sign this register every time you come to the school. This is important for insurance purposes and emergency situations. After signing the book, collect a Visitors badge from the office. This must be worn at all times when you are on school premises. Remember to return the badge afterwards. Messages Teachers will communicate with volunteers via telephone, email or messages left at the office. Always ask for messages. You may communicate with teachers in the same way the preferred method is to leave a memo in the relevant teachers pigeonhole. These can be found at the end of the corridor in the staffroom block. Work hours We understand that your time commitment is entirely voluntary and therefore flexible. If your personal schedule should change and this affects your availability, please contact the Co-ordinator for Volunteers at the school on extension 402: alternatively, you could drop in to her office situated in F block. Role of the Co-ordinator The Co-ordinator is responsible for matching volunteer tutors with students, organising tutorial rooms, ensuring student attendance and overseeing volunteer tutor training. If you encounter any problems, contact her as above.", "hypothesis": "As a volunteer, you will be helping students individually.", "gold_label": "entailment"}
{"uid": "id_322", "premise": "Volunteers Thank you for volunteering to work one-on-one with some of the students at our school who need extra help. Smoking policy Smoking is prohibited by law in the classrooms and anywhere on the school grounds. Safety and Health Volunteers are responsible for their own personal safety and should notify the school of any pre-existing medical conditions. Prescription and any other medications that you normally carry with you must be handed in to the school nurse on arrival and collected on departure. If you require them, the nurse will dispense them to you in her office. Sign-in A sign-in book is located at office reception. Please sign this register every time you come to the school. This is important for insurance purposes and emergency situations. After signing the book, collect a Visitors badge from the office. This must be worn at all times when you are on school premises. Remember to return the badge afterwards. Messages Teachers will communicate with volunteers via telephone, email or messages left at the office. Always ask for messages. You may communicate with teachers in the same way the preferred method is to leave a memo in the relevant teachers pigeonhole. These can be found at the end of the corridor in the staffroom block. Work hours We understand that your time commitment is entirely voluntary and therefore flexible. If your personal schedule should change and this affects your availability, please contact the Co-ordinator for Volunteers at the school on extension 402: alternatively, you could drop in to her office situated in F block. Role of the Co-ordinator The Co-ordinator is responsible for matching volunteer tutors with students, organising tutorial rooms, ensuring student attendance and overseeing volunteer tutor training. If you encounter any problems, contact her as above.", "hypothesis": "You may smoke in the playground.", "gold_label": "contradiction"}
{"uid": "id_323", "premise": "Volunteers Thank you for volunteering to work one-on-one with some of the students at our school who need extra help. Smoking policy Smoking is prohibited by law in the classrooms and anywhere on the school grounds. Safety and Health Volunteers are responsible for their own personal safety and should notify the school of any pre-existing medical conditions. Prescription and any other medications that you normally carry with you must be handed in to the school nurse on arrival and collected on departure. If you require them, the nurse will dispense them to you in her office. Sign-in A sign-in book is located at office reception. Please sign this register every time you come to the school. This is important for insurance purposes and emergency situations. After signing the book, collect a Visitors badge from the office. This must be worn at all times when you are on school premises. Remember to return the badge afterwards. Messages Teachers will communicate with volunteers via telephone, email or messages left at the office. Always ask for messages. You may communicate with teachers in the same way the preferred method is to leave a memo in the relevant teachers pigeonhole. These can be found at the end of the corridor in the staffroom block. Work hours We understand that your time commitment is entirely voluntary and therefore flexible. If your personal schedule should change and this affects your availability, please contact the Co-ordinator for Volunteers at the school on extension 402: alternatively, you could drop in to her office situated in F block. Role of the Co-ordinator The Co-ordinator is responsible for matching volunteer tutors with students, organising tutorial rooms, ensuring student attendance and overseeing volunteer tutor training. If you encounter any problems, contact her as above.", "hypothesis": "The co-ordinator keeps student attendance rolls.", "gold_label": "neutral"}
{"uid": "id_324", "premise": "Volunteers Thank you for volunteering to work one-on-one with some of the students at our school who need extra help. Smoking policy Smoking is prohibited by law in the classrooms and anywhere on the school grounds. Safety and Health Volunteers are responsible for their own personal safety and should notify the school of any pre-existing medical conditions. Prescription and any other medications that you normally carry with you must be handed in to the school nurse on arrival and collected on departure. If you require them, the nurse will dispense them to you in her office. Sign-in A sign-in book is located at office reception. Please sign this register every time you come to the school. This is important for insurance purposes and emergency situations. After signing the book, collect a Visitors badge from the office. This must be worn at all times when you are on school premises. Remember to return the badge afterwards. Messages Teachers will communicate with volunteers via telephone, email or messages left at the office. Always ask for messages. You may communicate with teachers in the same way the preferred method is to leave a memo in the relevant teachers pigeonhole. These can be found at the end of the corridor in the staffroom block. Work hours We understand that your time commitment is entirely voluntary and therefore flexible. If your personal schedule should change and this affects your availability, please contact the Co-ordinator for Volunteers at the school on extension 402: alternatively, you could drop in to her office situated in F block. Role of the Co-ordinator The Co-ordinator is responsible for matching volunteer tutors with students, organising tutorial rooms, ensuring student attendance and overseeing volunteer tutor training. If you encounter any problems, contact her as above.", "hypothesis": "You cannot take any medicine while at the school.", "gold_label": "contradiction"}
{"uid": "id_325", "premise": "Volunteers Thank you for volunteering to work one-on-one with some of the students at our school who need extra help. Smoking policy Smoking is prohibited by law in the classrooms and anywhere on the school grounds. Safety and Health Volunteers are responsible for their own personal safety and should notify the school of any pre-existing medical conditions. Prescription and any other medications that you normally carry with you must be handed in to the school nurse on arrival and collected on departure. If you require them, the nurse will dispense them to you in her office. Sign-in A sign-in book is located at office reception. Please sign this register every time you come to the school. This is important for insurance purposes and emergency situations. After signing the book, collect a Visitors badge from the office. This must be worn at all times when you are on school premises. Remember to return the badge afterwards. Messages Teachers will communicate with volunteers via telephone, email or messages left at the office. Always ask for messages. You may communicate with teachers in the same way the preferred method is to leave a memo in the relevant teachers pigeonhole. These can be found at the end of the corridor in the staffroom block. Work hours We understand that your time commitment is entirely voluntary and therefore flexible. If your personal schedule should change and this affects your availability, please contact the Co-ordinator for Volunteers at the school on extension 402: alternatively, you could drop in to her office situated in F block. Role of the Co-ordinator The Co-ordinator is responsible for matching volunteer tutors with students, organising tutorial rooms, ensuring student attendance and overseeing volunteer tutor training. If you encounter any problems, contact her as above.", "hypothesis": "The best way of communicating with teachers is in writing.", "gold_label": "entailment"}
{"uid": "id_326", "premise": "Volunteers Thank you for volunteering to work one-on-one with some of the students at our school who need extra help. Smoking policy Smoking is prohibited by law in the classrooms and anywhere on the school grounds. Safety and Health Volunteers are responsible for their own personal safety and should notify the school of any pre-existing medical conditions. Prescription and any other medications that you normally carry with you must be handed in to the school nurse on arrival and collected on departure. If you require them, the nurse will dispense them to you in her office. Sign-in A sign-in book is located at office reception. Please sign this register every time you come to the school. This is important for insurance purposes and emergency situations. After signing the book, collect a Visitors badge from the office. This must be worn at all times when you are on school premises. Remember to return the badge afterwards. Messages Teachers will communicate with volunteers via telephone, email or messages left at the office. Always ask for messages. You may communicate with teachers in the same way the preferred method is to leave a memo in the relevant teachers pigeonhole. These can be found at the end of the corridor in the staffroom block. Work hours We understand that your time commitment is entirely voluntary and therefore flexible. If your personal schedule should change and this affects your availability, please contact the Co-ordinator for Volunteers at the school on extension 402: alternatively, you could drop in to her office situated in F block. Role of the Co-ordinator The Co-ordinator is responsible for matching volunteer tutors with students, organising tutorial rooms, ensuring student attendance and overseeing volunteer tutor training. If you encounter any problems, contact her as above.", "hypothesis": "You can choose your own hours of work.", "gold_label": "entailment"}
{"uid": "id_327", "premise": "Votes count. The United Kingdom has had a full parliamentary democracy since 1928 when women were allowed to vote in general elections at age 21, the same as men. Women were first given the right to vote in 1918 after the First World War, but only if they were over the age of 30. In 1969 the voting age for men and women was reduced to 18. Today, no person can vote unless their name appears on the electoral register, and the earliest you can register is age 16. Citizens of the Commonwealth and those of the Irish Republic are eligible to vote in all public elections (general and local) as long as they are resident in the UK. British nationals who move abroad retain the right to vote in British and EU elections for a further 15 years. Some people are disenfranchised, including convicted prisoners (but not those on remand), non-UK EU citizens, Church of England archbishops and bishops, members of the House of Lords and people lacking the mental capacity to vote on polling day. However, all of the above people (convicted prisoners and those lacking mental capacity excepted) can vote in local elections, and all EU citizens can also vote in European elections, though only in one country and not two.", "hypothesis": "A 19-year-old female born in the Irish Republic is entitled to vote in a UK general election.", "gold_label": "neutral"}
{"uid": "id_328", "premise": "Votes count. The United Kingdom has had a full parliamentary democracy since 1928 when women were allowed to vote in general elections at age 21, the same as men. Women were first given the right to vote in 1918 after the First World War, but only if they were over the age of 30. In 1969 the voting age for men and women was reduced to 18. Today, no person can vote unless their name appears on the electoral register, and the earliest you can register is age 16. Citizens of the Commonwealth and those of the Irish Republic are eligible to vote in all public elections (general and local) as long as they are resident in the UK. British nationals who move abroad retain the right to vote in British and EU elections for a further 15 years. Some people are disenfranchised, including convicted prisoners (but not those on remand), non-UK EU citizens, Church of England archbishops and bishops, members of the House of Lords and people lacking the mental capacity to vote on polling day. However, all of the above people (convicted prisoners and those lacking mental capacity excepted) can vote in local elections, and all EU citizens can also vote in European elections, though only in one country and not two.", "hypothesis": "Non-UK EU citizens over age 18 with mental capacity who are not prisoners are entitled to vote in a UK general election.", "gold_label": "contradiction"}
{"uid": "id_329", "premise": "Votes count. The United Kingdom has had a full parliamentary democracy since 1928 when women were allowed to vote in general elections at age 21, the same as men. Women were first given the right to vote in 1918 after the First World War, but only if they were over the age of 30. In 1969 the voting age for men and women was reduced to 18. Today, no person can vote unless their name appears on the electoral register, and the earliest you can register is age 16. Citizens of the Commonwealth and those of the Irish Republic are eligible to vote in all public elections (general and local) as long as they are resident in the UK. British nationals who move abroad retain the right to vote in British and EU elections for a further 15 years. Some people are disenfranchised, including convicted prisoners (but not those on remand), non-UK EU citizens, Church of England archbishops and bishops, members of the House of Lords and people lacking the mental capacity to vote on polling day. However, all of the above people (convicted prisoners and those lacking mental capacity excepted) can vote in local elections, and all EU citizens can also vote in European elections, though only in one country and not two.", "hypothesis": "A woman born in 1889 would not have been allowed to vote in the 1918 UK general election.", "gold_label": "entailment"}
{"uid": "id_330", "premise": "Votes count. The United Kingdom has had a full parliamentary democracy since 1928 when women were allowed to vote in general elections at age 21, the same as men. Women were first given the right to vote in 1918 after the First World War, but only if they were over the age of 30. In 1969 the voting age for men and women was reduced to 18. Today, no person can vote unless their name appears on the electoral register, and the earliest you can register is age 16. Citizens of the Commonwealth and those of the Irish Republic are eligible to vote in all public elections (general and local) as long as they are resident in the UK. British nationals who move abroad retain the right to vote in British and EU elections for a further 15 years. Some people are disenfranchised, including convicted prisoners (but not those on remand), non-UK EU citizens, Church of England archbishops and bishops, members of the House of Lords and people lacking the mental capacity to vote on polling day. However, all of the above people (convicted prisoners and those lacking mental capacity excepted) can vote in local elections, and all EU citizens can also vote in European elections, though only in one country and not two.", "hypothesis": "A 55-year-old male born in Northern Ireland and domiciled in Spain five years ago is entitled to vote in a UK general election.", "gold_label": "entailment"}
{"uid": "id_331", "premise": "Voyage of going: beyond the blue line. One feels a certain sympathy for Captain James Cook on the day in 1778 that he \"discovered\" Hawaii. Then on his third expedition to the Pacific, the British navigator had explored scores of islands across the breadth of the sea, from lush New Zealand to the lonely wastes of Easter Island This latest voyage had taken him thousands of miles north from the Society Islands to an archipelago so remote that even the ok! Polynesians back on Tahiti knew nothing about it. Imagine Cook's surprise, then, when the natives of Hawaii came paddling out in their canoes and greeted him in a familiar tongue, one he had heard on virtually every mote of inhabited land he had visited Marveling at the ubiquity of this Pacific language and culture, he later wondered in his journal: \"How shall we account for this Nation spreading it self so far over this Vast ocean? \" B. Answers have been slow in coming. But now a startling archaeological find on the island of Efate, in the Pacific nation of Vanuatu, has revealed an ancient seafaring people, the distant ancestors of today's Polynesians, taking their first steps into the unknown. The discoveries there have also opened a window into the shadowy work! of those early voyagers. At the same time, other pieces of this human puzzle are turning up in unlikely places. Climate data gleaned from slow-growing corals around the Pacific and from sediments in alpine lakes in South America may help explain how, more than a thousand years later, a second wave of seafarers beat their way across the entire Pacific. C. What we have is a first-or second-generation site containing the graves of some of the Pacific's first explorers, \" says Spriggs, professor of archaeology at the Australian National University and co-leader of an international team excavating the site. It came to light only by luck A backhoe operator, digging up topsoil on the grounds of a derelict coconut plantation, scraped open a grave the first of dozens in a burial ground some 3,000 years old It is the oldest cemetery ever found in the Pacific islands, and it harbors the bones of an ancient people archaeologists call the Lapita, a label that derives from a beach in New Caledonia where a landmark cache of their pottery was found in the 1950s. They were daring blue-water adventurers who roved the sea not just as expbrers but also as pioneers, bringing abng everything they would need to build new lives their families and livestock, taro seedlings and stone tools. D. Within the span of a few centuries the Lapita stretched the boundaries of theirworld from the jungle-clad vokanoes of Papua New Guinea to the bneliest coral outliers of Tonga, at feast 2,000 miles eastward in the Pacific. Abng the way they expbred millions of square miles of unknown sea, discovering and cobnizing scores of tropical islands never before seen by human eyes: Vanuatu, New Caledonia, Fiji, Samoa. E. What little is known or surmised about them has been pieced together from fragments of pottery, animal bones, obsidian flakes, and such oblique sources as comparative linguistics and geochemistry. Although their voyages can be traced back to the northern islands of Papua New Guinea, their language variants of which are still spoken across the Pacific came from Taiwan. And their peculiar style of pottery decoration, created by pressing a carved stamp into the clay, probably had its roots in the northern Philippines. With the discovery of the Lapita cemetery on Efate, the volume of data available to researchers has expanded dramatically. The bones of at feast 62 individuals have been uncovered so far including old men, young women, even babiesand more skeletons are known to be in the ground Archaeobgists were also thrilled to discover six complete Lapita pots. It's an important find, Spriggs says, for it conclusively identifies the remains as Lapita. \"It would be hard for anyone to argue that these aren't Lapita when you have human bones enshrined inside what is unmistakably a Lapita urn. \" F. Several lines of evidence also undergird Spriggs's conclusion that this was a community of pioneers making their first voyages into the remote reaches of Oceania. For one thing, the radiocarbon dating of bones and charcoal places them early in the Lapita expansion. For another, the chemical makeup of the obsidian flakes littering the site indicates that the rock wasn't local; instead it was imported from a large island in Papua New Guinea's Bismarck Archipelago, the springboard for the Lapita's thrust into the Pacific. A particularly intriguing clue comes from chemical tests on the teeth of several skeletons. DNA teased from these ancient bones may also help answer one of the most puzzling questions in Pacific anthropobgy: Did all Pacific islanders spring from one source or many? Was there only one outward migration from a single point in Asia, or several from different points? \"This represents the best opportunity we've had yet, \" says Spriggs, \"to find out who the Lapita actually were, where they came from, and who their cbsest descendants are today. G. \"There is one stubborn question for which archaeobgy has yet to provide any answers: How did the Lapita accomplish the ancient equivalent of a moon landing, many times over? No one has found one of their canoes or any rigging, which could reveal how the canoes were sailed Nor do the oral histories andtraditions of later Polynesians offer any insights, for they segue into myth long before they reach as far back in time as the Lapita. \" All we can say for certain is that the Lapita had canoes that were capable of ocean voyages, and they had the ability to sail them, \" says Geoff Irwin, a professor of archaeology at the University of Auckland and an avid yachtsman. Those sailing skills, he says, were developed and passed down over thousands of years by earlier mariners who worked their way through the archipelagoes of the western Pacific making short crossings to islands within sight of each other. Reaching Fiji, as they did a century or so later, meant crossing more than 500 miles of ocean, pressing on day after day into the great blue void of the Pacific. What gave them the courage to launch out on such a risky voyage? H. The Lapita's thrust into the Pacific was eastward, against the prevailing trade winds, Irwin notes. Those nagging headwinds, he argues, may have been the key to their success. \"They could sail out for days into the unknown and reconnoiter, secure in the knowledge that if they didn't find anything, they could turn about and catch a swift ride home on the trade winds. It's what made the whole thing work. \" Once out there, skilled seafarers would detect abundant leads to follow to land: seabirds and turtles, coconuts and twigs carried out to sea by the tides, and the afternoon pileup of clouds on the horizon that often betokens an island in the distance. Some islands may have broadcast their presence with far less subtlety than a cloud bank. Some of the most violent eruptions anywhere on the planet during the past 10,000 years occurred in Melanesia, which sits nervously in one of the most explosive volcanic regions on Earth. Even less spectacular eruptions would have sent plumes of smoke bilbwing into the stratosphere and rained ash for hundreds of miles. It's possible that the Lapita saw these signs of distant islands and later sailed off in their direction, knowing they would find land For returning explorers, successful or not, the geography of their own archipelagoes provided a safety net to keep them from overshooting their home ports and sailing off into eternity. I. However they did it, the Lapita spread themselves a third of the way across the Pacific, then called it quits for reasons known only to them. Ahead lay the vast emptiness of the central Pacific, and perhaps they were too thinly stretched to venture farther. They probably never numbered more than a few thousand in total, and in their rapid migration eastward they encountered hundreds of islands more than 300 in Fiji alone. Still, more than a millennium would pass before the Lapita's descendants, a people we now call the Polynesians, struck out in search of new territory.", "hypothesis": "Professor Spriggs and his research team went to the Efate to try to find the site of ancient cemetery.", "gold_label": "contradiction"}
{"uid": "id_332", "premise": "Voyage of going: beyond the blue line. One feels a certain sympathy for Captain James Cook on the day in 1778 that he \"discovered\" Hawaii. Then on his third expedition to the Pacific, the British navigator had explored scores of islands across the breadth of the sea, from lush New Zealand to the lonely wastes of Easter Island This latest voyage had taken him thousands of miles north from the Society Islands to an archipelago so remote that even the ok! Polynesians back on Tahiti knew nothing about it. Imagine Cook's surprise, then, when the natives of Hawaii came paddling out in their canoes and greeted him in a familiar tongue, one he had heard on virtually every mote of inhabited land he had visited Marveling at the ubiquity of this Pacific language and culture, he later wondered in his journal: \"How shall we account for this Nation spreading it self so far over this Vast ocean? \" B. Answers have been slow in coming. But now a startling archaeological find on the island of Efate, in the Pacific nation of Vanuatu, has revealed an ancient seafaring people, the distant ancestors of today's Polynesians, taking their first steps into the unknown. The discoveries there have also opened a window into the shadowy work! of those early voyagers. At the same time, other pieces of this human puzzle are turning up in unlikely places. Climate data gleaned from slow-growing corals around the Pacific and from sediments in alpine lakes in South America may help explain how, more than a thousand years later, a second wave of seafarers beat their way across the entire Pacific. C. What we have is a first-or second-generation site containing the graves of some of the Pacific's first explorers, \" says Spriggs, professor of archaeology at the Australian National University and co-leader of an international team excavating the site. It came to light only by luck A backhoe operator, digging up topsoil on the grounds of a derelict coconut plantation, scraped open a grave the first of dozens in a burial ground some 3,000 years old It is the oldest cemetery ever found in the Pacific islands, and it harbors the bones of an ancient people archaeologists call the Lapita, a label that derives from a beach in New Caledonia where a landmark cache of their pottery was found in the 1950s. They were daring blue-water adventurers who roved the sea not just as expbrers but also as pioneers, bringing abng everything they would need to build new lives their families and livestock, taro seedlings and stone tools. D. Within the span of a few centuries the Lapita stretched the boundaries of theirworld from the jungle-clad vokanoes of Papua New Guinea to the bneliest coral outliers of Tonga, at feast 2,000 miles eastward in the Pacific. Abng the way they expbred millions of square miles of unknown sea, discovering and cobnizing scores of tropical islands never before seen by human eyes: Vanuatu, New Caledonia, Fiji, Samoa. E. What little is known or surmised about them has been pieced together from fragments of pottery, animal bones, obsidian flakes, and such oblique sources as comparative linguistics and geochemistry. Although their voyages can be traced back to the northern islands of Papua New Guinea, their language variants of which are still spoken across the Pacific came from Taiwan. And their peculiar style of pottery decoration, created by pressing a carved stamp into the clay, probably had its roots in the northern Philippines. With the discovery of the Lapita cemetery on Efate, the volume of data available to researchers has expanded dramatically. The bones of at feast 62 individuals have been uncovered so far including old men, young women, even babiesand more skeletons are known to be in the ground Archaeobgists were also thrilled to discover six complete Lapita pots. It's an important find, Spriggs says, for it conclusively identifies the remains as Lapita. \"It would be hard for anyone to argue that these aren't Lapita when you have human bones enshrined inside what is unmistakably a Lapita urn. \" F. Several lines of evidence also undergird Spriggs's conclusion that this was a community of pioneers making their first voyages into the remote reaches of Oceania. For one thing, the radiocarbon dating of bones and charcoal places them early in the Lapita expansion. For another, the chemical makeup of the obsidian flakes littering the site indicates that the rock wasn't local; instead it was imported from a large island in Papua New Guinea's Bismarck Archipelago, the springboard for the Lapita's thrust into the Pacific. A particularly intriguing clue comes from chemical tests on the teeth of several skeletons. DNA teased from these ancient bones may also help answer one of the most puzzling questions in Pacific anthropobgy: Did all Pacific islanders spring from one source or many? Was there only one outward migration from a single point in Asia, or several from different points? \"This represents the best opportunity we've had yet, \" says Spriggs, \"to find out who the Lapita actually were, where they came from, and who their cbsest descendants are today. G. \"There is one stubborn question for which archaeobgy has yet to provide any answers: How did the Lapita accomplish the ancient equivalent of a moon landing, many times over? No one has found one of their canoes or any rigging, which could reveal how the canoes were sailed Nor do the oral histories andtraditions of later Polynesians offer any insights, for they segue into myth long before they reach as far back in time as the Lapita. \" All we can say for certain is that the Lapita had canoes that were capable of ocean voyages, and they had the ability to sail them, \" says Geoff Irwin, a professor of archaeology at the University of Auckland and an avid yachtsman. Those sailing skills, he says, were developed and passed down over thousands of years by earlier mariners who worked their way through the archipelagoes of the western Pacific making short crossings to islands within sight of each other. Reaching Fiji, as they did a century or so later, meant crossing more than 500 miles of ocean, pressing on day after day into the great blue void of the Pacific. What gave them the courage to launch out on such a risky voyage? H. The Lapita's thrust into the Pacific was eastward, against the prevailing trade winds, Irwin notes. Those nagging headwinds, he argues, may have been the key to their success. \"They could sail out for days into the unknown and reconnoiter, secure in the knowledge that if they didn't find anything, they could turn about and catch a swift ride home on the trade winds. It's what made the whole thing work. \" Once out there, skilled seafarers would detect abundant leads to follow to land: seabirds and turtles, coconuts and twigs carried out to sea by the tides, and the afternoon pileup of clouds on the horizon that often betokens an island in the distance. Some islands may have broadcast their presence with far less subtlety than a cloud bank. Some of the most violent eruptions anywhere on the planet during the past 10,000 years occurred in Melanesia, which sits nervously in one of the most explosive volcanic regions on Earth. Even less spectacular eruptions would have sent plumes of smoke bilbwing into the stratosphere and rained ash for hundreds of miles. It's possible that the Lapita saw these signs of distant islands and later sailed off in their direction, knowing they would find land For returning explorers, successful or not, the geography of their own archipelagoes provided a safety net to keep them from overshooting their home ports and sailing off into eternity. I. However they did it, the Lapita spread themselves a third of the way across the Pacific, then called it quits for reasons known only to them. Ahead lay the vast emptiness of the central Pacific, and perhaps they were too thinly stretched to venture farther. They probably never numbered more than a few thousand in total, and in their rapid migration eastward they encountered hundreds of islands more than 300 in Fiji alone. Still, more than a millennium would pass before the Lapita's descendants, a people we now call the Polynesians, struck out in search of new territory.", "hypothesis": "Captain cook depicted number of cultural aspects of Polynesians in his journal.", "gold_label": "contradiction"}
{"uid": "id_333", "premise": "Voyage of going: beyond the blue line. One feels a certain sympathy for Captain James Cook on the day in 1778 that he \"discovered\" Hawaii. Then on his third expedition to the Pacific, the British navigator had explored scores of islands across the breadth of the sea, from lush New Zealand to the lonely wastes of Easter Island This latest voyage had taken him thousands of miles north from the Society Islands to an archipelago so remote that even the ok! Polynesians back on Tahiti knew nothing about it. Imagine Cook's surprise, then, when the natives of Hawaii came paddling out in their canoes and greeted him in a familiar tongue, one he had heard on virtually every mote of inhabited land he had visited Marveling at the ubiquity of this Pacific language and culture, he later wondered in his journal: \"How shall we account for this Nation spreading it self so far over this Vast ocean? \" B. Answers have been slow in coming. But now a startling archaeological find on the island of Efate, in the Pacific nation of Vanuatu, has revealed an ancient seafaring people, the distant ancestors of today's Polynesians, taking their first steps into the unknown. The discoveries there have also opened a window into the shadowy work! of those early voyagers. At the same time, other pieces of this human puzzle are turning up in unlikely places. Climate data gleaned from slow-growing corals around the Pacific and from sediments in alpine lakes in South America may help explain how, more than a thousand years later, a second wave of seafarers beat their way across the entire Pacific. C. What we have is a first-or second-generation site containing the graves of some of the Pacific's first explorers, \" says Spriggs, professor of archaeology at the Australian National University and co-leader of an international team excavating the site. It came to light only by luck A backhoe operator, digging up topsoil on the grounds of a derelict coconut plantation, scraped open a grave the first of dozens in a burial ground some 3,000 years old It is the oldest cemetery ever found in the Pacific islands, and it harbors the bones of an ancient people archaeologists call the Lapita, a label that derives from a beach in New Caledonia where a landmark cache of their pottery was found in the 1950s. They were daring blue-water adventurers who roved the sea not just as expbrers but also as pioneers, bringing abng everything they would need to build new lives their families and livestock, taro seedlings and stone tools. D. Within the span of a few centuries the Lapita stretched the boundaries of theirworld from the jungle-clad vokanoes of Papua New Guinea to the bneliest coral outliers of Tonga, at feast 2,000 miles eastward in the Pacific. Abng the way they expbred millions of square miles of unknown sea, discovering and cobnizing scores of tropical islands never before seen by human eyes: Vanuatu, New Caledonia, Fiji, Samoa. E. What little is known or surmised about them has been pieced together from fragments of pottery, animal bones, obsidian flakes, and such oblique sources as comparative linguistics and geochemistry. Although their voyages can be traced back to the northern islands of Papua New Guinea, their language variants of which are still spoken across the Pacific came from Taiwan. And their peculiar style of pottery decoration, created by pressing a carved stamp into the clay, probably had its roots in the northern Philippines. With the discovery of the Lapita cemetery on Efate, the volume of data available to researchers has expanded dramatically. The bones of at feast 62 individuals have been uncovered so far including old men, young women, even babiesand more skeletons are known to be in the ground Archaeobgists were also thrilled to discover six complete Lapita pots. It's an important find, Spriggs says, for it conclusively identifies the remains as Lapita. \"It would be hard for anyone to argue that these aren't Lapita when you have human bones enshrined inside what is unmistakably a Lapita urn. \" F. Several lines of evidence also undergird Spriggs's conclusion that this was a community of pioneers making their first voyages into the remote reaches of Oceania. For one thing, the radiocarbon dating of bones and charcoal places them early in the Lapita expansion. For another, the chemical makeup of the obsidian flakes littering the site indicates that the rock wasn't local; instead it was imported from a large island in Papua New Guinea's Bismarck Archipelago, the springboard for the Lapita's thrust into the Pacific. A particularly intriguing clue comes from chemical tests on the teeth of several skeletons. DNA teased from these ancient bones may also help answer one of the most puzzling questions in Pacific anthropobgy: Did all Pacific islanders spring from one source or many? Was there only one outward migration from a single point in Asia, or several from different points? \"This represents the best opportunity we've had yet, \" says Spriggs, \"to find out who the Lapita actually were, where they came from, and who their cbsest descendants are today. G. \"There is one stubborn question for which archaeobgy has yet to provide any answers: How did the Lapita accomplish the ancient equivalent of a moon landing, many times over? No one has found one of their canoes or any rigging, which could reveal how the canoes were sailed Nor do the oral histories andtraditions of later Polynesians offer any insights, for they segue into myth long before they reach as far back in time as the Lapita. \" All we can say for certain is that the Lapita had canoes that were capable of ocean voyages, and they had the ability to sail them, \" says Geoff Irwin, a professor of archaeology at the University of Auckland and an avid yachtsman. Those sailing skills, he says, were developed and passed down over thousands of years by earlier mariners who worked their way through the archipelagoes of the western Pacific making short crossings to islands within sight of each other. Reaching Fiji, as they did a century or so later, meant crossing more than 500 miles of ocean, pressing on day after day into the great blue void of the Pacific. What gave them the courage to launch out on such a risky voyage? H. The Lapita's thrust into the Pacific was eastward, against the prevailing trade winds, Irwin notes. Those nagging headwinds, he argues, may have been the key to their success. \"They could sail out for days into the unknown and reconnoiter, secure in the knowledge that if they didn't find anything, they could turn about and catch a swift ride home on the trade winds. It's what made the whole thing work. \" Once out there, skilled seafarers would detect abundant leads to follow to land: seabirds and turtles, coconuts and twigs carried out to sea by the tides, and the afternoon pileup of clouds on the horizon that often betokens an island in the distance. Some islands may have broadcast their presence with far less subtlety than a cloud bank. Some of the most violent eruptions anywhere on the planet during the past 10,000 years occurred in Melanesia, which sits nervously in one of the most explosive volcanic regions on Earth. Even less spectacular eruptions would have sent plumes of smoke bilbwing into the stratosphere and rained ash for hundreds of miles. It's possible that the Lapita saw these signs of distant islands and later sailed off in their direction, knowing they would find land For returning explorers, successful or not, the geography of their own archipelagoes provided a safety net to keep them from overshooting their home ports and sailing off into eternity. I. However they did it, the Lapita spread themselves a third of the way across the Pacific, then called it quits for reasons known only to them. Ahead lay the vast emptiness of the central Pacific, and perhaps they were too thinly stretched to venture farther. They probably never numbered more than a few thousand in total, and in their rapid migration eastward they encountered hundreds of islands more than 300 in Fiji alone. Still, more than a millennium would pass before the Lapita's descendants, a people we now call the Polynesians, struck out in search of new territory.", "hypothesis": "Captain cook once expected the Hawaii might speak another language of people from other pacific islands.", "gold_label": "entailment"}
{"uid": "id_334", "premise": "Voyage of going: beyond the blue line. One feels a certain sympathy for Captain James Cook on the day in 1778 that he \"discovered\" Hawaii. Then on his third expedition to the Pacific, the British navigator had explored scores of islands across the breadth of the sea, from lush New Zealand to the lonely wastes of Easter Island This latest voyage had taken him thousands of miles north from the Society Islands to an archipelago so remote that even the ok! Polynesians back on Tahiti knew nothing about it. Imagine Cook's surprise, then, when the natives of Hawaii came paddling out in their canoes and greeted him in a familiar tongue, one he had heard on virtually every mote of inhabited land he had visited Marveling at the ubiquity of this Pacific language and culture, he later wondered in his journal: \"How shall we account for this Nation spreading it self so far over this Vast ocean? \" B. Answers have been slow in coming. But now a startling archaeological find on the island of Efate, in the Pacific nation of Vanuatu, has revealed an ancient seafaring people, the distant ancestors of today's Polynesians, taking their first steps into the unknown. The discoveries there have also opened a window into the shadowy work! of those early voyagers. At the same time, other pieces of this human puzzle are turning up in unlikely places. Climate data gleaned from slow-growing corals around the Pacific and from sediments in alpine lakes in South America may help explain how, more than a thousand years later, a second wave of seafarers beat their way across the entire Pacific. C. What we have is a first-or second-generation site containing the graves of some of the Pacific's first explorers, \" says Spriggs, professor of archaeology at the Australian National University and co-leader of an international team excavating the site. It came to light only by luck A backhoe operator, digging up topsoil on the grounds of a derelict coconut plantation, scraped open a grave the first of dozens in a burial ground some 3,000 years old It is the oldest cemetery ever found in the Pacific islands, and it harbors the bones of an ancient people archaeologists call the Lapita, a label that derives from a beach in New Caledonia where a landmark cache of their pottery was found in the 1950s. They were daring blue-water adventurers who roved the sea not just as expbrers but also as pioneers, bringing abng everything they would need to build new lives their families and livestock, taro seedlings and stone tools. D. Within the span of a few centuries the Lapita stretched the boundaries of theirworld from the jungle-clad vokanoes of Papua New Guinea to the bneliest coral outliers of Tonga, at feast 2,000 miles eastward in the Pacific. Abng the way they expbred millions of square miles of unknown sea, discovering and cobnizing scores of tropical islands never before seen by human eyes: Vanuatu, New Caledonia, Fiji, Samoa. E. What little is known or surmised about them has been pieced together from fragments of pottery, animal bones, obsidian flakes, and such oblique sources as comparative linguistics and geochemistry. Although their voyages can be traced back to the northern islands of Papua New Guinea, their language variants of which are still spoken across the Pacific came from Taiwan. And their peculiar style of pottery decoration, created by pressing a carved stamp into the clay, probably had its roots in the northern Philippines. With the discovery of the Lapita cemetery on Efate, the volume of data available to researchers has expanded dramatically. The bones of at feast 62 individuals have been uncovered so far including old men, young women, even babiesand more skeletons are known to be in the ground Archaeobgists were also thrilled to discover six complete Lapita pots. It's an important find, Spriggs says, for it conclusively identifies the remains as Lapita. \"It would be hard for anyone to argue that these aren't Lapita when you have human bones enshrined inside what is unmistakably a Lapita urn. \" F. Several lines of evidence also undergird Spriggs's conclusion that this was a community of pioneers making their first voyages into the remote reaches of Oceania. For one thing, the radiocarbon dating of bones and charcoal places them early in the Lapita expansion. For another, the chemical makeup of the obsidian flakes littering the site indicates that the rock wasn't local; instead it was imported from a large island in Papua New Guinea's Bismarck Archipelago, the springboard for the Lapita's thrust into the Pacific. A particularly intriguing clue comes from chemical tests on the teeth of several skeletons. DNA teased from these ancient bones may also help answer one of the most puzzling questions in Pacific anthropobgy: Did all Pacific islanders spring from one source or many? Was there only one outward migration from a single point in Asia, or several from different points? \"This represents the best opportunity we've had yet, \" says Spriggs, \"to find out who the Lapita actually were, where they came from, and who their cbsest descendants are today. G. \"There is one stubborn question for which archaeobgy has yet to provide any answers: How did the Lapita accomplish the ancient equivalent of a moon landing, many times over? No one has found one of their canoes or any rigging, which could reveal how the canoes were sailed Nor do the oral histories andtraditions of later Polynesians offer any insights, for they segue into myth long before they reach as far back in time as the Lapita. \" All we can say for certain is that the Lapita had canoes that were capable of ocean voyages, and they had the ability to sail them, \" says Geoff Irwin, a professor of archaeology at the University of Auckland and an avid yachtsman. Those sailing skills, he says, were developed and passed down over thousands of years by earlier mariners who worked their way through the archipelagoes of the western Pacific making short crossings to islands within sight of each other. Reaching Fiji, as they did a century or so later, meant crossing more than 500 miles of ocean, pressing on day after day into the great blue void of the Pacific. What gave them the courage to launch out on such a risky voyage? H. The Lapita's thrust into the Pacific was eastward, against the prevailing trade winds, Irwin notes. Those nagging headwinds, he argues, may have been the key to their success. \"They could sail out for days into the unknown and reconnoiter, secure in the knowledge that if they didn't find anything, they could turn about and catch a swift ride home on the trade winds. It's what made the whole thing work. \" Once out there, skilled seafarers would detect abundant leads to follow to land: seabirds and turtles, coconuts and twigs carried out to sea by the tides, and the afternoon pileup of clouds on the horizon that often betokens an island in the distance. Some islands may have broadcast their presence with far less subtlety than a cloud bank. Some of the most violent eruptions anywhere on the planet during the past 10,000 years occurred in Melanesia, which sits nervously in one of the most explosive volcanic regions on Earth. Even less spectacular eruptions would have sent plumes of smoke bilbwing into the stratosphere and rained ash for hundreds of miles. It's possible that the Lapita saw these signs of distant islands and later sailed off in their direction, knowing they would find land For returning explorers, successful or not, the geography of their own archipelagoes provided a safety net to keep them from overshooting their home ports and sailing off into eternity. I. However they did it, the Lapita spread themselves a third of the way across the Pacific, then called it quits for reasons known only to them. Ahead lay the vast emptiness of the central Pacific, and perhaps they were too thinly stretched to venture farther. They probably never numbered more than a few thousand in total, and in their rapid migration eastward they encountered hundreds of islands more than 300 in Fiji alone. Still, more than a millennium would pass before the Lapita's descendants, a people we now call the Polynesians, struck out in search of new territory.", "hypothesis": "The Lapita were the first inhabitants in many pacific islands.", "gold_label": "entailment"}
{"uid": "id_335", "premise": "Voyage of going: beyond the blue line. One feels a certain sympathy for Captain James Cook on the day in 1778 that he \"discovered\" Hawaii. Then on his third expedition to the Pacific, the British navigator had explored scores of islands across the breadth of the sea, from lush New Zealand to the lonely wastes of Easter Island This latest voyage had taken him thousands of miles north from the Society Islands to an archipelago so remote that even the ok! Polynesians back on Tahiti knew nothing about it. Imagine Cook's surprise, then, when the natives of Hawaii came paddling out in their canoes and greeted him in a familiar tongue, one he had heard on virtually every mote of inhabited land he had visited Marveling at the ubiquity of this Pacific language and culture, he later wondered in his journal: \"How shall we account for this Nation spreading it self so far over this Vast ocean? \" B. Answers have been slow in coming. But now a startling archaeological find on the island of Efate, in the Pacific nation of Vanuatu, has revealed an ancient seafaring people, the distant ancestors of today's Polynesians, taking their first steps into the unknown. The discoveries there have also opened a window into the shadowy work! of those early voyagers. At the same time, other pieces of this human puzzle are turning up in unlikely places. Climate data gleaned from slow-growing corals around the Pacific and from sediments in alpine lakes in South America may help explain how, more than a thousand years later, a second wave of seafarers beat their way across the entire Pacific. C. What we have is a first-or second-generation site containing the graves of some of the Pacific's first explorers, \" says Spriggs, professor of archaeology at the Australian National University and co-leader of an international team excavating the site. It came to light only by luck A backhoe operator, digging up topsoil on the grounds of a derelict coconut plantation, scraped open a grave the first of dozens in a burial ground some 3,000 years old It is the oldest cemetery ever found in the Pacific islands, and it harbors the bones of an ancient people archaeologists call the Lapita, a label that derives from a beach in New Caledonia where a landmark cache of their pottery was found in the 1950s. They were daring blue-water adventurers who roved the sea not just as expbrers but also as pioneers, bringing abng everything they would need to build new lives their families and livestock, taro seedlings and stone tools. D. Within the span of a few centuries the Lapita stretched the boundaries of theirworld from the jungle-clad vokanoes of Papua New Guinea to the bneliest coral outliers of Tonga, at feast 2,000 miles eastward in the Pacific. Abng the way they expbred millions of square miles of unknown sea, discovering and cobnizing scores of tropical islands never before seen by human eyes: Vanuatu, New Caledonia, Fiji, Samoa. E. What little is known or surmised about them has been pieced together from fragments of pottery, animal bones, obsidian flakes, and such oblique sources as comparative linguistics and geochemistry. Although their voyages can be traced back to the northern islands of Papua New Guinea, their language variants of which are still spoken across the Pacific came from Taiwan. And their peculiar style of pottery decoration, created by pressing a carved stamp into the clay, probably had its roots in the northern Philippines. With the discovery of the Lapita cemetery on Efate, the volume of data available to researchers has expanded dramatically. The bones of at feast 62 individuals have been uncovered so far including old men, young women, even babiesand more skeletons are known to be in the ground Archaeobgists were also thrilled to discover six complete Lapita pots. It's an important find, Spriggs says, for it conclusively identifies the remains as Lapita. \"It would be hard for anyone to argue that these aren't Lapita when you have human bones enshrined inside what is unmistakably a Lapita urn. \" F. Several lines of evidence also undergird Spriggs's conclusion that this was a community of pioneers making their first voyages into the remote reaches of Oceania. For one thing, the radiocarbon dating of bones and charcoal places them early in the Lapita expansion. For another, the chemical makeup of the obsidian flakes littering the site indicates that the rock wasn't local; instead it was imported from a large island in Papua New Guinea's Bismarck Archipelago, the springboard for the Lapita's thrust into the Pacific. A particularly intriguing clue comes from chemical tests on the teeth of several skeletons. DNA teased from these ancient bones may also help answer one of the most puzzling questions in Pacific anthropobgy: Did all Pacific islanders spring from one source or many? Was there only one outward migration from a single point in Asia, or several from different points? \"This represents the best opportunity we've had yet, \" says Spriggs, \"to find out who the Lapita actually were, where they came from, and who their cbsest descendants are today. G. \"There is one stubborn question for which archaeobgy has yet to provide any answers: How did the Lapita accomplish the ancient equivalent of a moon landing, many times over? No one has found one of their canoes or any rigging, which could reveal how the canoes were sailed Nor do the oral histories andtraditions of later Polynesians offer any insights, for they segue into myth long before they reach as far back in time as the Lapita. \" All we can say for certain is that the Lapita had canoes that were capable of ocean voyages, and they had the ability to sail them, \" says Geoff Irwin, a professor of archaeology at the University of Auckland and an avid yachtsman. Those sailing skills, he says, were developed and passed down over thousands of years by earlier mariners who worked their way through the archipelagoes of the western Pacific making short crossings to islands within sight of each other. Reaching Fiji, as they did a century or so later, meant crossing more than 500 miles of ocean, pressing on day after day into the great blue void of the Pacific. What gave them the courage to launch out on such a risky voyage? H. The Lapita's thrust into the Pacific was eastward, against the prevailing trade winds, Irwin notes. Those nagging headwinds, he argues, may have been the key to their success. \"They could sail out for days into the unknown and reconnoiter, secure in the knowledge that if they didn't find anything, they could turn about and catch a swift ride home on the trade winds. It's what made the whole thing work. \" Once out there, skilled seafarers would detect abundant leads to follow to land: seabirds and turtles, coconuts and twigs carried out to sea by the tides, and the afternoon pileup of clouds on the horizon that often betokens an island in the distance. Some islands may have broadcast their presence with far less subtlety than a cloud bank. Some of the most violent eruptions anywhere on the planet during the past 10,000 years occurred in Melanesia, which sits nervously in one of the most explosive volcanic regions on Earth. Even less spectacular eruptions would have sent plumes of smoke bilbwing into the stratosphere and rained ash for hundreds of miles. It's possible that the Lapita saw these signs of distant islands and later sailed off in their direction, knowing they would find land For returning explorers, successful or not, the geography of their own archipelagoes provided a safety net to keep them from overshooting their home ports and sailing off into eternity. I. However they did it, the Lapita spread themselves a third of the way across the Pacific, then called it quits for reasons known only to them. Ahead lay the vast emptiness of the central Pacific, and perhaps they were too thinly stretched to venture farther. They probably never numbered more than a few thousand in total, and in their rapid migration eastward they encountered hundreds of islands more than 300 in Fiji alone. Still, more than a millennium would pass before the Lapita's descendants, a people we now call the Polynesians, struck out in search of new territory.", "hypothesis": "The unknown pots discovered in Efate had once been used for cooking.", "gold_label": "neutral"}
{"uid": "id_336", "premise": "Voyage of going: beyond the blue line. One feels a certain sympathy for Captain James Cook on the day in 1778 that he \"discovered\" Hawaii. Then on his third expedition to the Pacific, the British navigator had explored scores of islands across the breadth of the sea, from lush New Zealand to the lonely wastes of Easter Island This latest voyage had taken him thousands of miles north from the Society Islands to an archipelago so remote that even the ok! Polynesians back on Tahiti knew nothing about it. Imagine Cook's surprise, then, when the natives of Hawaii came paddling out in their canoes and greeted him in a familiar tongue, one he had heard on virtually every mote of inhabited land he had visited Marveling at the ubiquity of this Pacific language and culture, he later wondered in his journal: \"How shall we account for this Nation spreading it self so far over this Vast ocean? \" B. Answers have been slow in coming. But now a startling archaeological find on the island of Efate, in the Pacific nation of Vanuatu, has revealed an ancient seafaring people, the distant ancestors of today's Polynesians, taking their first steps into the unknown. The discoveries there have also opened a window into the shadowy work! of those early voyagers. At the same time, other pieces of this human puzzle are turning up in unlikely places. Climate data gleaned from slow-growing corals around the Pacific and from sediments in alpine lakes in South America may help explain how, more than a thousand years later, a second wave of seafarers beat their way across the entire Pacific. C. What we have is a first-or second-generation site containing the graves of some of the Pacific's first explorers, \" says Spriggs, professor of archaeology at the Australian National University and co-leader of an international team excavating the site. It came to light only by luck A backhoe operator, digging up topsoil on the grounds of a derelict coconut plantation, scraped open a grave the first of dozens in a burial ground some 3,000 years old It is the oldest cemetery ever found in the Pacific islands, and it harbors the bones of an ancient people archaeologists call the Lapita, a label that derives from a beach in New Caledonia where a landmark cache of their pottery was found in the 1950s. They were daring blue-water adventurers who roved the sea not just as expbrers but also as pioneers, bringing abng everything they would need to build new lives their families and livestock, taro seedlings and stone tools. D. Within the span of a few centuries the Lapita stretched the boundaries of theirworld from the jungle-clad vokanoes of Papua New Guinea to the bneliest coral outliers of Tonga, at feast 2,000 miles eastward in the Pacific. Abng the way they expbred millions of square miles of unknown sea, discovering and cobnizing scores of tropical islands never before seen by human eyes: Vanuatu, New Caledonia, Fiji, Samoa. E. What little is known or surmised about them has been pieced together from fragments of pottery, animal bones, obsidian flakes, and such oblique sources as comparative linguistics and geochemistry. Although their voyages can be traced back to the northern islands of Papua New Guinea, their language variants of which are still spoken across the Pacific came from Taiwan. And their peculiar style of pottery decoration, created by pressing a carved stamp into the clay, probably had its roots in the northern Philippines. With the discovery of the Lapita cemetery on Efate, the volume of data available to researchers has expanded dramatically. The bones of at feast 62 individuals have been uncovered so far including old men, young women, even babiesand more skeletons are known to be in the ground Archaeobgists were also thrilled to discover six complete Lapita pots. It's an important find, Spriggs says, for it conclusively identifies the remains as Lapita. \"It would be hard for anyone to argue that these aren't Lapita when you have human bones enshrined inside what is unmistakably a Lapita urn. \" F. Several lines of evidence also undergird Spriggs's conclusion that this was a community of pioneers making their first voyages into the remote reaches of Oceania. For one thing, the radiocarbon dating of bones and charcoal places them early in the Lapita expansion. For another, the chemical makeup of the obsidian flakes littering the site indicates that the rock wasn't local; instead it was imported from a large island in Papua New Guinea's Bismarck Archipelago, the springboard for the Lapita's thrust into the Pacific. A particularly intriguing clue comes from chemical tests on the teeth of several skeletons. DNA teased from these ancient bones may also help answer one of the most puzzling questions in Pacific anthropobgy: Did all Pacific islanders spring from one source or many? Was there only one outward migration from a single point in Asia, or several from different points? \"This represents the best opportunity we've had yet, \" says Spriggs, \"to find out who the Lapita actually were, where they came from, and who their cbsest descendants are today. G. \"There is one stubborn question for which archaeobgy has yet to provide any answers: How did the Lapita accomplish the ancient equivalent of a moon landing, many times over? No one has found one of their canoes or any rigging, which could reveal how the canoes were sailed Nor do the oral histories andtraditions of later Polynesians offer any insights, for they segue into myth long before they reach as far back in time as the Lapita. \" All we can say for certain is that the Lapita had canoes that were capable of ocean voyages, and they had the ability to sail them, \" says Geoff Irwin, a professor of archaeology at the University of Auckland and an avid yachtsman. Those sailing skills, he says, were developed and passed down over thousands of years by earlier mariners who worked their way through the archipelagoes of the western Pacific making short crossings to islands within sight of each other. Reaching Fiji, as they did a century or so later, meant crossing more than 500 miles of ocean, pressing on day after day into the great blue void of the Pacific. What gave them the courage to launch out on such a risky voyage? H. The Lapita's thrust into the Pacific was eastward, against the prevailing trade winds, Irwin notes. Those nagging headwinds, he argues, may have been the key to their success. \"They could sail out for days into the unknown and reconnoiter, secure in the knowledge that if they didn't find anything, they could turn about and catch a swift ride home on the trade winds. It's what made the whole thing work. \" Once out there, skilled seafarers would detect abundant leads to follow to land: seabirds and turtles, coconuts and twigs carried out to sea by the tides, and the afternoon pileup of clouds on the horizon that often betokens an island in the distance. Some islands may have broadcast their presence with far less subtlety than a cloud bank. Some of the most violent eruptions anywhere on the planet during the past 10,000 years occurred in Melanesia, which sits nervously in one of the most explosive volcanic regions on Earth. Even less spectacular eruptions would have sent plumes of smoke bilbwing into the stratosphere and rained ash for hundreds of miles. It's possible that the Lapita saw these signs of distant islands and later sailed off in their direction, knowing they would find land For returning explorers, successful or not, the geography of their own archipelagoes provided a safety net to keep them from overshooting their home ports and sailing off into eternity. I. However they did it, the Lapita spread themselves a third of the way across the Pacific, then called it quits for reasons known only to them. Ahead lay the vast emptiness of the central Pacific, and perhaps they were too thinly stretched to venture farther. They probably never numbered more than a few thousand in total, and in their rapid migration eastward they encountered hundreds of islands more than 300 in Fiji alone. Still, more than a millennium would pass before the Lapita's descendants, a people we now call the Polynesians, struck out in search of new territory.", "hypothesis": "The um buried in Efate site was plain as it was without any decoration.", "gold_label": "contradiction"}
{"uid": "id_337", "premise": "Voyage of going: beyond the blue line. One feels a certain sympathy for Captain James Cook on the day in 1778 that he \"discovered\" Hawaii. Then on his third expedition to the Pacific, the British navigator had explored scores of islands across the breadth of the sea, from lush New Zealand to the lonely wastes of Easter Island This latest voyage had taken him thousands of miles north from the Society Islands to an archipelago so remote that even the ok! Polynesians back on Tahiti knew nothing about it. Imagine Cook's surprise, then, when the natives of Hawaii came paddling out in their canoes and greeted him in a familiar tongue, one he had heard on virtually every mote of inhabited land he had visited Marveling at the ubiquity of this Pacific language and culture, he later wondered in his journal: \"How shall we account for this Nation spreading it self so far over this Vast ocean? \" B. Answers have been slow in coming. But now a startling archaeological find on the island of Efate, in the Pacific nation of Vanuatu, has revealed an ancient seafaring people, the distant ancestors of today's Polynesians, taking their first steps into the unknown. The discoveries there have also opened a window into the shadowy work! of those early voyagers. At the same time, other pieces of this human puzzle are turning up in unlikely places. Climate data gleaned from slow-growing corals around the Pacific and from sediments in alpine lakes in South America may help explain how, more than a thousand years later, a second wave of seafarers beat their way across the entire Pacific. C. What we have is a first-or second-generation site containing the graves of some of the Pacific's first explorers, \" says Spriggs, professor of archaeology at the Australian National University and co-leader of an international team excavating the site. It came to light only by luck A backhoe operator, digging up topsoil on the grounds of a derelict coconut plantation, scraped open a grave the first of dozens in a burial ground some 3,000 years old It is the oldest cemetery ever found in the Pacific islands, and it harbors the bones of an ancient people archaeologists call the Lapita, a label that derives from a beach in New Caledonia where a landmark cache of their pottery was found in the 1950s. They were daring blue-water adventurers who roved the sea not just as expbrers but also as pioneers, bringing abng everything they would need to build new lives their families and livestock, taro seedlings and stone tools. D. Within the span of a few centuries the Lapita stretched the boundaries of theirworld from the jungle-clad vokanoes of Papua New Guinea to the bneliest coral outliers of Tonga, at feast 2,000 miles eastward in the Pacific. Abng the way they expbred millions of square miles of unknown sea, discovering and cobnizing scores of tropical islands never before seen by human eyes: Vanuatu, New Caledonia, Fiji, Samoa. E. What little is known or surmised about them has been pieced together from fragments of pottery, animal bones, obsidian flakes, and such oblique sources as comparative linguistics and geochemistry. Although their voyages can be traced back to the northern islands of Papua New Guinea, their language variants of which are still spoken across the Pacific came from Taiwan. And their peculiar style of pottery decoration, created by pressing a carved stamp into the clay, probably had its roots in the northern Philippines. With the discovery of the Lapita cemetery on Efate, the volume of data available to researchers has expanded dramatically. The bones of at feast 62 individuals have been uncovered so far including old men, young women, even babiesand more skeletons are known to be in the ground Archaeobgists were also thrilled to discover six complete Lapita pots. It's an important find, Spriggs says, for it conclusively identifies the remains as Lapita. \"It would be hard for anyone to argue that these aren't Lapita when you have human bones enshrined inside what is unmistakably a Lapita urn. \" F. Several lines of evidence also undergird Spriggs's conclusion that this was a community of pioneers making their first voyages into the remote reaches of Oceania. For one thing, the radiocarbon dating of bones and charcoal places them early in the Lapita expansion. For another, the chemical makeup of the obsidian flakes littering the site indicates that the rock wasn't local; instead it was imported from a large island in Papua New Guinea's Bismarck Archipelago, the springboard for the Lapita's thrust into the Pacific. A particularly intriguing clue comes from chemical tests on the teeth of several skeletons. DNA teased from these ancient bones may also help answer one of the most puzzling questions in Pacific anthropobgy: Did all Pacific islanders spring from one source or many? Was there only one outward migration from a single point in Asia, or several from different points? \"This represents the best opportunity we've had yet, \" says Spriggs, \"to find out who the Lapita actually were, where they came from, and who their cbsest descendants are today. G. \"There is one stubborn question for which archaeobgy has yet to provide any answers: How did the Lapita accomplish the ancient equivalent of a moon landing, many times over? No one has found one of their canoes or any rigging, which could reveal how the canoes were sailed Nor do the oral histories andtraditions of later Polynesians offer any insights, for they segue into myth long before they reach as far back in time as the Lapita. \" All we can say for certain is that the Lapita had canoes that were capable of ocean voyages, and they had the ability to sail them, \" says Geoff Irwin, a professor of archaeology at the University of Auckland and an avid yachtsman. Those sailing skills, he says, were developed and passed down over thousands of years by earlier mariners who worked their way through the archipelagoes of the western Pacific making short crossings to islands within sight of each other. Reaching Fiji, as they did a century or so later, meant crossing more than 500 miles of ocean, pressing on day after day into the great blue void of the Pacific. What gave them the courage to launch out on such a risky voyage? H. The Lapita's thrust into the Pacific was eastward, against the prevailing trade winds, Irwin notes. Those nagging headwinds, he argues, may have been the key to their success. \"They could sail out for days into the unknown and reconnoiter, secure in the knowledge that if they didn't find anything, they could turn about and catch a swift ride home on the trade winds. It's what made the whole thing work. \" Once out there, skilled seafarers would detect abundant leads to follow to land: seabirds and turtles, coconuts and twigs carried out to sea by the tides, and the afternoon pileup of clouds on the horizon that often betokens an island in the distance. Some islands may have broadcast their presence with far less subtlety than a cloud bank. Some of the most violent eruptions anywhere on the planet during the past 10,000 years occurred in Melanesia, which sits nervously in one of the most explosive volcanic regions on Earth. Even less spectacular eruptions would have sent plumes of smoke bilbwing into the stratosphere and rained ash for hundreds of miles. It's possible that the Lapita saw these signs of distant islands and later sailed off in their direction, knowing they would find land For returning explorers, successful or not, the geography of their own archipelagoes provided a safety net to keep them from overshooting their home ports and sailing off into eternity. I. However they did it, the Lapita spread themselves a third of the way across the Pacific, then called it quits for reasons known only to them. Ahead lay the vast emptiness of the central Pacific, and perhaps they were too thinly stretched to venture farther. They probably never numbered more than a few thousand in total, and in their rapid migration eastward they encountered hundreds of islands more than 300 in Fiji alone. Still, more than a millennium would pass before the Lapita's descendants, a people we now call the Polynesians, struck out in search of new territory.", "hypothesis": "The Lapita completed a journey of around 2,000 miles in a period less than a centenary.", "gold_label": "neutral"}
{"uid": "id_338", "premise": "WATER HYACINTH: BEAUTIFUL YET DESTRUCTIVE Despite possessing vibrant purple flowers and being attractive to the eye, the water hyacinth has often been referred to as the most problematic aquatic plant in the worlds waters. Due to its aesthetic appeal, water hyacinth, which is native to South America, has been distributed to many different regions and now thrives in the southern states of the USA and many subtropical and tropical locations. It has also been observed to be relatively tolerant of cooler climates and is routinely sold as an ornamental plant for domestic use in a number of horticulture centres. Though the hyacinth species is distinctive in appearance, another aquatic floating plant water lettuce is sometimes mistakenly identified as water hyacinth. Water lettuce, however, does not have the same attractive flowers, has larger leaves and is less tolerant of cooler climates. Water hyacinth has rounded waxy, green leaves which grow up to around 6 inches in width and floating leaf stems which grow up to 12 inches in length. Flowers are typically between 2 to 3 inches in width and as many as 15 flowers, each purple on the outside and containing a yellow centre, may grow from each plant. Many of the problems associated with the water hyacinth are due to its incredible growth and reproduction capabilities, which have made it difficult to control and allow it to quickly dominate the environment in which it grows and spreads. Its growth patterns are characterised by a rapid formation of an impenetrable vegetation mass; botanists say that one plant can produce around 5000 seeds and in one study two plants were observed to produce 1200 plants in as little as 4 months. Following natures usual pattern, water hyacinth seeds are distributed outside of the immediate area by birds, fauna, wind and water currents, facilitating growth in surrounding areas previously free of the plant. Domination of environments by water hyacinth populations has a number of negative implications. For humans, difficulties may be faced in getting boats through areas of rivers and lakes where the plant is present and fishing and swimming opportunities may be limited. However, the implications for the ecosystem of the immediate environment may be of even greater concern. The density of the mass of water hyacinth populations can prevent adequate amounts of sunlight and oxygen reaching the water: as a result, significant numbers of fish may die, other species of plant growing below water level are compromised and the ecosystem of the immediate area can therefore become unbalanced. Furthermore, the conditions created by the presence of water hyacinth, while detrimental to most forms of life, are perfect for encouraging growth of deadly bacteria often found in poorly oxygenated areas of water. In the southern states of the USA, in Florida in particular, water hyacinth is now under maintenance control. The plant population can be limited in a number of ways: including use of herbicides, clearance equipment and bio-control insects. However, efforts to minimise the population of water hyacinth need to be continual and consistent; experts warning that unless control methods are upheld, the problem can easily reoccur. Some say inattention for as little as a twelve month period would allow numbers to quickly return to infestation level; hardly surprising given that the species is known to be able to double in as little as 12 days. Water hyacinth is thought to have been introduced into Africa in the 1800s; its presence at Lake Kyoga was first identified in 1988 and at Lake Victoria in 1989. In the mid 1990s, water hyacinth was estimated to dominate 10% of the latter lakes waters. However, by 1998, the plant was almost completely eliminated from East African waters; this being achieved predominantly by the use of bio-control insects, in this case snout beetles, a type of weevil which feeds only on the water hyacinth species of plant. Tens of thousands of the weevils were distributed throughout the lake areas of East Africa, their habit of feeding on the leaves and laying their eggs in the plants stalks eventually causing the plants to die and sink to the bottom of the lake. In addition, the plant population was removed using mechanical clearing equipment and by hand with the help of a machete. Despite earlier success, however, negative repercussions of human activity have caused the return of water hyacinth to East African waters. Ugandas Lake Kyoga, has recently once again experienced problems with infestation. Sewage and agricultural waste making their way into the waterways and thereby creating an excess of nutrients in the water have been the main contributing factors to the re-emergence of water hyacinth. In addition, high levels of nitrogen in rainfall, which enters the water cycle from the smoke created by wood burning cooking fires used in the region, also serves as nutrition to the increasing plant population. Restriction of human activity on lakes such as this, caused by the infestation of water hyacinth has enormous implications; villages such as Kayago, which is in close proximity to the lake, are often almost completely dependent on fishing activity for their economy and food source. While the infestation of water hyacinth in Lake Victoria at the time of writing stands at 0.5%, far below the 10% level experienced in the middle of the 1990s, experts fear that growth could once again become out of control. The main concern is that, as a result of changing weather conditions, the activity of the snout beetle weevils may be less effective than in the past. The region around Lake Victoria has experienced an extended period of drought and while the water hyacinth is capable of living and reproducing both in lakes and surrounding dry land, its predator, the snout beetle can only survive on water. Plant populations growing in lakeside locations are therefore under limited threat from the insect brought in to control them and are consequently able to reproduce in relative freedom.", "hypothesis": "The current problem of dominance of water hyacinth on Lake Kyoga is less serious than in the 1980s and early 1990s.", "gold_label": "neutral"}
{"uid": "id_339", "premise": "WATER HYACINTH: BEAUTIFUL YET DESTRUCTIVE Despite possessing vibrant purple flowers and being attractive to the eye, the water hyacinth has often been referred to as the most problematic aquatic plant in the worlds waters. Due to its aesthetic appeal, water hyacinth, which is native to South America, has been distributed to many different regions and now thrives in the southern states of the USA and many subtropical and tropical locations. It has also been observed to be relatively tolerant of cooler climates and is routinely sold as an ornamental plant for domestic use in a number of horticulture centres. Though the hyacinth species is distinctive in appearance, another aquatic floating plant water lettuce is sometimes mistakenly identified as water hyacinth. Water lettuce, however, does not have the same attractive flowers, has larger leaves and is less tolerant of cooler climates. Water hyacinth has rounded waxy, green leaves which grow up to around 6 inches in width and floating leaf stems which grow up to 12 inches in length. Flowers are typically between 2 to 3 inches in width and as many as 15 flowers, each purple on the outside and containing a yellow centre, may grow from each plant. Many of the problems associated with the water hyacinth are due to its incredible growth and reproduction capabilities, which have made it difficult to control and allow it to quickly dominate the environment in which it grows and spreads. Its growth patterns are characterised by a rapid formation of an impenetrable vegetation mass; botanists say that one plant can produce around 5000 seeds and in one study two plants were observed to produce 1200 plants in as little as 4 months. Following natures usual pattern, water hyacinth seeds are distributed outside of the immediate area by birds, fauna, wind and water currents, facilitating growth in surrounding areas previously free of the plant. Domination of environments by water hyacinth populations has a number of negative implications. For humans, difficulties may be faced in getting boats through areas of rivers and lakes where the plant is present and fishing and swimming opportunities may be limited. However, the implications for the ecosystem of the immediate environment may be of even greater concern. The density of the mass of water hyacinth populations can prevent adequate amounts of sunlight and oxygen reaching the water: as a result, significant numbers of fish may die, other species of plant growing below water level are compromised and the ecosystem of the immediate area can therefore become unbalanced. Furthermore, the conditions created by the presence of water hyacinth, while detrimental to most forms of life, are perfect for encouraging growth of deadly bacteria often found in poorly oxygenated areas of water. In the southern states of the USA, in Florida in particular, water hyacinth is now under maintenance control. The plant population can be limited in a number of ways: including use of herbicides, clearance equipment and bio-control insects. However, efforts to minimise the population of water hyacinth need to be continual and consistent; experts warning that unless control methods are upheld, the problem can easily reoccur. Some say inattention for as little as a twelve month period would allow numbers to quickly return to infestation level; hardly surprising given that the species is known to be able to double in as little as 12 days. Water hyacinth is thought to have been introduced into Africa in the 1800s; its presence at Lake Kyoga was first identified in 1988 and at Lake Victoria in 1989. In the mid 1990s, water hyacinth was estimated to dominate 10% of the latter lakes waters. However, by 1998, the plant was almost completely eliminated from East African waters; this being achieved predominantly by the use of bio-control insects, in this case snout beetles, a type of weevil which feeds only on the water hyacinth species of plant. Tens of thousands of the weevils were distributed throughout the lake areas of East Africa, their habit of feeding on the leaves and laying their eggs in the plants stalks eventually causing the plants to die and sink to the bottom of the lake. In addition, the plant population was removed using mechanical clearing equipment and by hand with the help of a machete. Despite earlier success, however, negative repercussions of human activity have caused the return of water hyacinth to East African waters. Ugandas Lake Kyoga, has recently once again experienced problems with infestation. Sewage and agricultural waste making their way into the waterways and thereby creating an excess of nutrients in the water have been the main contributing factors to the re-emergence of water hyacinth. In addition, high levels of nitrogen in rainfall, which enters the water cycle from the smoke created by wood burning cooking fires used in the region, also serves as nutrition to the increasing plant population. Restriction of human activity on lakes such as this, caused by the infestation of water hyacinth has enormous implications; villages such as Kayago, which is in close proximity to the lake, are often almost completely dependent on fishing activity for their economy and food source. While the infestation of water hyacinth in Lake Victoria at the time of writing stands at 0.5%, far below the 10% level experienced in the middle of the 1990s, experts fear that growth could once again become out of control. The main concern is that, as a result of changing weather conditions, the activity of the snout beetle weevils may be less effective than in the past. The region around Lake Victoria has experienced an extended period of drought and while the water hyacinth is capable of living and reproducing both in lakes and surrounding dry land, its predator, the snout beetle can only survive on water. Plant populations growing in lakeside locations are therefore under limited threat from the insect brought in to control them and are consequently able to reproduce in relative freedom.", "hypothesis": "Presence of dense water hyacinth populations can encourage the development of certain harmful forms of life.", "gold_label": "entailment"}
{"uid": "id_340", "premise": "WATER HYACINTH: BEAUTIFUL YET DESTRUCTIVE Despite possessing vibrant purple flowers and being attractive to the eye, the water hyacinth has often been referred to as the most problematic aquatic plant in the worlds waters. Due to its aesthetic appeal, water hyacinth, which is native to South America, has been distributed to many different regions and now thrives in the southern states of the USA and many subtropical and tropical locations. It has also been observed to be relatively tolerant of cooler climates and is routinely sold as an ornamental plant for domestic use in a number of horticulture centres. Though the hyacinth species is distinctive in appearance, another aquatic floating plant water lettuce is sometimes mistakenly identified as water hyacinth. Water lettuce, however, does not have the same attractive flowers, has larger leaves and is less tolerant of cooler climates. Water hyacinth has rounded waxy, green leaves which grow up to around 6 inches in width and floating leaf stems which grow up to 12 inches in length. Flowers are typically between 2 to 3 inches in width and as many as 15 flowers, each purple on the outside and containing a yellow centre, may grow from each plant. Many of the problems associated with the water hyacinth are due to its incredible growth and reproduction capabilities, which have made it difficult to control and allow it to quickly dominate the environment in which it grows and spreads. Its growth patterns are characterised by a rapid formation of an impenetrable vegetation mass; botanists say that one plant can produce around 5000 seeds and in one study two plants were observed to produce 1200 plants in as little as 4 months. Following natures usual pattern, water hyacinth seeds are distributed outside of the immediate area by birds, fauna, wind and water currents, facilitating growth in surrounding areas previously free of the plant. Domination of environments by water hyacinth populations has a number of negative implications. For humans, difficulties may be faced in getting boats through areas of rivers and lakes where the plant is present and fishing and swimming opportunities may be limited. However, the implications for the ecosystem of the immediate environment may be of even greater concern. The density of the mass of water hyacinth populations can prevent adequate amounts of sunlight and oxygen reaching the water: as a result, significant numbers of fish may die, other species of plant growing below water level are compromised and the ecosystem of the immediate area can therefore become unbalanced. Furthermore, the conditions created by the presence of water hyacinth, while detrimental to most forms of life, are perfect for encouraging growth of deadly bacteria often found in poorly oxygenated areas of water. In the southern states of the USA, in Florida in particular, water hyacinth is now under maintenance control. The plant population can be limited in a number of ways: including use of herbicides, clearance equipment and bio-control insects. However, efforts to minimise the population of water hyacinth need to be continual and consistent; experts warning that unless control methods are upheld, the problem can easily reoccur. Some say inattention for as little as a twelve month period would allow numbers to quickly return to infestation level; hardly surprising given that the species is known to be able to double in as little as 12 days. Water hyacinth is thought to have been introduced into Africa in the 1800s; its presence at Lake Kyoga was first identified in 1988 and at Lake Victoria in 1989. In the mid 1990s, water hyacinth was estimated to dominate 10% of the latter lakes waters. However, by 1998, the plant was almost completely eliminated from East African waters; this being achieved predominantly by the use of bio-control insects, in this case snout beetles, a type of weevil which feeds only on the water hyacinth species of plant. Tens of thousands of the weevils were distributed throughout the lake areas of East Africa, their habit of feeding on the leaves and laying their eggs in the plants stalks eventually causing the plants to die and sink to the bottom of the lake. In addition, the plant population was removed using mechanical clearing equipment and by hand with the help of a machete. Despite earlier success, however, negative repercussions of human activity have caused the return of water hyacinth to East African waters. Ugandas Lake Kyoga, has recently once again experienced problems with infestation. Sewage and agricultural waste making their way into the waterways and thereby creating an excess of nutrients in the water have been the main contributing factors to the re-emergence of water hyacinth. In addition, high levels of nitrogen in rainfall, which enters the water cycle from the smoke created by wood burning cooking fires used in the region, also serves as nutrition to the increasing plant population. Restriction of human activity on lakes such as this, caused by the infestation of water hyacinth has enormous implications; villages such as Kayago, which is in close proximity to the lake, are often almost completely dependent on fishing activity for their economy and food source. While the infestation of water hyacinth in Lake Victoria at the time of writing stands at 0.5%, far below the 10% level experienced in the middle of the 1990s, experts fear that growth could once again become out of control. The main concern is that, as a result of changing weather conditions, the activity of the snout beetle weevils may be less effective than in the past. The region around Lake Victoria has experienced an extended period of drought and while the water hyacinth is capable of living and reproducing both in lakes and surrounding dry land, its predator, the snout beetle can only survive on water. Plant populations growing in lakeside locations are therefore under limited threat from the insect brought in to control them and are consequently able to reproduce in relative freedom.", "hypothesis": "Sewage and waste created by farming have had more of an impact on the return of the water hyacinth population in Uganda than nitrogen- rich air.", "gold_label": "entailment"}
{"uid": "id_341", "premise": "WEATHERING IN THE DESERT In the deserts, as elsewhere, rocks at the earths surface are changed by weathering, which may be defined as the disintegration of rocks where they lie. Weathering processes are either chemical, when alteration of some of the constituent particles is involved; or mechanical, when there is merely the physical breaking apart and fragmentation of rocks. Which process will dominate depends primarily on the mineralogy and texture of the rock and the local climate, but several individual processes usually work together to the common end of rock disintegration. The great daily changes in temperature of deserts have long been supposed to be responsible for the disintegration of rocks, either by the differential heating of the various rock-forming minerals or by differential heating between the outer and inner parts of rock masses. However, both field observations and laboratory experiments have led to a reassessment of the importance of exposure to the suns rays in desert weathering. Almost half a century ago Barton remarked that the buried parts of some of the ancient monuments in Egypt were more weathered than were those parts fully exposed to the suns rays, and attributed this to the effects of water absorption below the ground surface. Laboratory experiments have shown that rocks subjected to many cycles of large temperature oscillations (larger than those experienced in nature) display no evidence of fissuring or fragmentation, as a result. However, when marked fluctuations of temperature occur in moist conditions small rock fragments quickly form. The expansive action of crystallising salts is often alleged to exert sufficient force to disintegrate rocks. Few would dispute that this mechanism is capable of disrupting fissile or well-cleaved rocks or rocks already weakened by other weathering agencies; wood is splintered, terracotta tiles disintegrated and clays disturbed by the mechanism, but its importance when acting upon fresh and cohesive crystalline rocks remains uncertain. Weathering achieves more than the disintegration of rocks, though this is its most important geomorphic effect. It causes specific landforms to develop. Many boulders possess a superficial hard layer of iron oxide and/or silica, substances which have migrated in solution from the inside of the block towards the surface. Not only is the exterior thus case-hardened but the depleted interior disintegrates easily. When weathering penetrates the shell the inside is rapidly attacked and only the hard outer layer remains to give hollowed or tortoiseshell rocks. Another superficial layer, the precise nature of which is little understood, is the well-known desert varnish or patina, a shiny coat on the surface of rocks and pebbles and characteristic of arid environments. Some varnishes are colourless, others light brown, yet others so dark a brown as to be virtually black. Its origin is unknown but is significant, for it has been suggested that the varnish grows darker with the passage of time; obviously before such a criterion could be used with confidence as a chronological tool its origin must be known with precision. Its formation is so slow that in Egypt, for example, it has been estimated that a light brown coating requires between 2,000 and 5,000 years to develop, a fully formed blackish veneer between 20,000 and 50,000 years. The development of relatively impermeable soil horizons that are subsequently exposed at the surface because of erosion of once overlying, easily eroded materials, and which thus become surface crusts, is widespread in arid regions, although it is also known outside the deserts, and indeed many of the examples in arid lands probably originated in former periods of humid climate. The crusts prevent the waters of occasional torrential downpours from penetrating deeply into the soil, and thus they contribute to the rapid run-off associated with desert storms. Also, after erosion has cut through the crust and exposed underlying soil layers, the hard layer forms a resistant capping (duricrust) on plateaux and mesas, such as are common in many parts of arid and semi-arid Australia. Some duricrust layers have been used as time markers for landforms and geological formations. The necessary conditions for this are that the crust forms fairly rapidly, and that it is sufficiently distinct in appearance to preclude the possibility of confusion with other crusts formed at other times. The Barrilaco calcrete of Mexico for instance is believed to date from about 7,000 B. C. The main silcrete of the northern districts of South Australia is believed to date from the Lower Miocene, the laterite of northern Australia to be of the Lower or Middle Miocene age.", "hypothesis": "It is estimated that dark patina originated between 2,000 and 5,000 years ago.", "gold_label": "contradiction"}
{"uid": "id_342", "premise": "WEATHERING IN THE DESERT In the deserts, as elsewhere, rocks at the earths surface are changed by weathering, which may be defined as the disintegration of rocks where they lie. Weathering processes are either chemical, when alteration of some of the constituent particles is involved; or mechanical, when there is merely the physical breaking apart and fragmentation of rocks. Which process will dominate depends primarily on the mineralogy and texture of the rock and the local climate, but several individual processes usually work together to the common end of rock disintegration. The great daily changes in temperature of deserts have long been supposed to be responsible for the disintegration of rocks, either by the differential heating of the various rock-forming minerals or by differential heating between the outer and inner parts of rock masses. However, both field observations and laboratory experiments have led to a reassessment of the importance of exposure to the suns rays in desert weathering. Almost half a century ago Barton remarked that the buried parts of some of the ancient monuments in Egypt were more weathered than were those parts fully exposed to the suns rays, and attributed this to the effects of water absorption below the ground surface. Laboratory experiments have shown that rocks subjected to many cycles of large temperature oscillations (larger than those experienced in nature) display no evidence of fissuring or fragmentation, as a result. However, when marked fluctuations of temperature occur in moist conditions small rock fragments quickly form. The expansive action of crystallising salts is often alleged to exert sufficient force to disintegrate rocks. Few would dispute that this mechanism is capable of disrupting fissile or well-cleaved rocks or rocks already weakened by other weathering agencies; wood is splintered, terracotta tiles disintegrated and clays disturbed by the mechanism, but its importance when acting upon fresh and cohesive crystalline rocks remains uncertain. Weathering achieves more than the disintegration of rocks, though this is its most important geomorphic effect. It causes specific landforms to develop. Many boulders possess a superficial hard layer of iron oxide and/or silica, substances which have migrated in solution from the inside of the block towards the surface. Not only is the exterior thus case-hardened but the depleted interior disintegrates easily. When weathering penetrates the shell the inside is rapidly attacked and only the hard outer layer remains to give hollowed or tortoiseshell rocks. Another superficial layer, the precise nature of which is little understood, is the well-known desert varnish or patina, a shiny coat on the surface of rocks and pebbles and characteristic of arid environments. Some varnishes are colourless, others light brown, yet others so dark a brown as to be virtually black. Its origin is unknown but is significant, for it has been suggested that the varnish grows darker with the passage of time; obviously before such a criterion could be used with confidence as a chronological tool its origin must be known with precision. Its formation is so slow that in Egypt, for example, it has been estimated that a light brown coating requires between 2,000 and 5,000 years to develop, a fully formed blackish veneer between 20,000 and 50,000 years. The development of relatively impermeable soil horizons that are subsequently exposed at the surface because of erosion of once overlying, easily eroded materials, and which thus become surface crusts, is widespread in arid regions, although it is also known outside the deserts, and indeed many of the examples in arid lands probably originated in former periods of humid climate. The crusts prevent the waters of occasional torrential downpours from penetrating deeply into the soil, and thus they contribute to the rapid run-off associated with desert storms. Also, after erosion has cut through the crust and exposed underlying soil layers, the hard layer forms a resistant capping (duricrust) on plateaux and mesas, such as are common in many parts of arid and semi-arid Australia. Some duricrust layers have been used as time markers for landforms and geological formations. The necessary conditions for this are that the crust forms fairly rapidly, and that it is sufficiently distinct in appearance to preclude the possibility of confusion with other crusts formed at other times. The Barrilaco calcrete of Mexico for instance is believed to date from about 7,000 B. C. The main silcrete of the northern districts of South Australia is believed to date from the Lower Miocene, the laterite of northern Australia to be of the Lower or Middle Miocene age.", "hypothesis": "Desert rocks can become weathered when there is a chemical reaction within the rock.", "gold_label": "entailment"}
{"uid": "id_343", "premise": "WEATHERING IN THE DESERT In the deserts, as elsewhere, rocks at the earths surface are changed by weathering, which may be defined as the disintegration of rocks where they lie. Weathering processes are either chemical, when alteration of some of the constituent particles is involved; or mechanical, when there is merely the physical breaking apart and fragmentation of rocks. Which process will dominate depends primarily on the mineralogy and texture of the rock and the local climate, but several individual processes usually work together to the common end of rock disintegration. The great daily changes in temperature of deserts have long been supposed to be responsible for the disintegration of rocks, either by the differential heating of the various rock-forming minerals or by differential heating between the outer and inner parts of rock masses. However, both field observations and laboratory experiments have led to a reassessment of the importance of exposure to the suns rays in desert weathering. Almost half a century ago Barton remarked that the buried parts of some of the ancient monuments in Egypt were more weathered than were those parts fully exposed to the suns rays, and attributed this to the effects of water absorption below the ground surface. Laboratory experiments have shown that rocks subjected to many cycles of large temperature oscillations (larger than those experienced in nature) display no evidence of fissuring or fragmentation, as a result. However, when marked fluctuations of temperature occur in moist conditions small rock fragments quickly form. The expansive action of crystallising salts is often alleged to exert sufficient force to disintegrate rocks. Few would dispute that this mechanism is capable of disrupting fissile or well-cleaved rocks or rocks already weakened by other weathering agencies; wood is splintered, terracotta tiles disintegrated and clays disturbed by the mechanism, but its importance when acting upon fresh and cohesive crystalline rocks remains uncertain. Weathering achieves more than the disintegration of rocks, though this is its most important geomorphic effect. It causes specific landforms to develop. Many boulders possess a superficial hard layer of iron oxide and/or silica, substances which have migrated in solution from the inside of the block towards the surface. Not only is the exterior thus case-hardened but the depleted interior disintegrates easily. When weathering penetrates the shell the inside is rapidly attacked and only the hard outer layer remains to give hollowed or tortoiseshell rocks. Another superficial layer, the precise nature of which is little understood, is the well-known desert varnish or patina, a shiny coat on the surface of rocks and pebbles and characteristic of arid environments. Some varnishes are colourless, others light brown, yet others so dark a brown as to be virtually black. Its origin is unknown but is significant, for it has been suggested that the varnish grows darker with the passage of time; obviously before such a criterion could be used with confidence as a chronological tool its origin must be known with precision. Its formation is so slow that in Egypt, for example, it has been estimated that a light brown coating requires between 2,000 and 5,000 years to develop, a fully formed blackish veneer between 20,000 and 50,000 years. The development of relatively impermeable soil horizons that are subsequently exposed at the surface because of erosion of once overlying, easily eroded materials, and which thus become surface crusts, is widespread in arid regions, although it is also known outside the deserts, and indeed many of the examples in arid lands probably originated in former periods of humid climate. The crusts prevent the waters of occasional torrential downpours from penetrating deeply into the soil, and thus they contribute to the rapid run-off associated with desert storms. Also, after erosion has cut through the crust and exposed underlying soil layers, the hard layer forms a resistant capping (duricrust) on plateaux and mesas, such as are common in many parts of arid and semi-arid Australia. Some duricrust layers have been used as time markers for landforms and geological formations. The necessary conditions for this are that the crust forms fairly rapidly, and that it is sufficiently distinct in appearance to preclude the possibility of confusion with other crusts formed at other times. The Barrilaco calcrete of Mexico for instance is believed to date from about 7,000 B. C. The main silcrete of the northern districts of South Australia is believed to date from the Lower Miocene, the laterite of northern Australia to be of the Lower or Middle Miocene age.", "hypothesis": "The parts of Egyptian monuments exposed to sunlight were found to be affected by the weather more than those below the ground.", "gold_label": "contradiction"}
{"uid": "id_344", "premise": "WEATHERING IN THE DESERT In the deserts, as elsewhere, rocks at the earths surface are changed by weathering, which may be defined as the disintegration of rocks where they lie. Weathering processes are either chemical, when alteration of some of the constituent particles is involved; or mechanical, when there is merely the physical breaking apart and fragmentation of rocks. Which process will dominate depends primarily on the mineralogy and texture of the rock and the local climate, but several individual processes usually work together to the common end of rock disintegration. The great daily changes in temperature of deserts have long been supposed to be responsible for the disintegration of rocks, either by the differential heating of the various rock-forming minerals or by differential heating between the outer and inner parts of rock masses. However, both field observations and laboratory experiments have led to a reassessment of the importance of exposure to the suns rays in desert weathering. Almost half a century ago Barton remarked that the buried parts of some of the ancient monuments in Egypt were more weathered than were those parts fully exposed to the suns rays, and attributed this to the effects of water absorption below the ground surface. Laboratory experiments have shown that rocks subjected to many cycles of large temperature oscillations (larger than those experienced in nature) display no evidence of fissuring or fragmentation, as a result. However, when marked fluctuations of temperature occur in moist conditions small rock fragments quickly form. The expansive action of crystallising salts is often alleged to exert sufficient force to disintegrate rocks. Few would dispute that this mechanism is capable of disrupting fissile or well-cleaved rocks or rocks already weakened by other weathering agencies; wood is splintered, terracotta tiles disintegrated and clays disturbed by the mechanism, but its importance when acting upon fresh and cohesive crystalline rocks remains uncertain. Weathering achieves more than the disintegration of rocks, though this is its most important geomorphic effect. It causes specific landforms to develop. Many boulders possess a superficial hard layer of iron oxide and/or silica, substances which have migrated in solution from the inside of the block towards the surface. Not only is the exterior thus case-hardened but the depleted interior disintegrates easily. When weathering penetrates the shell the inside is rapidly attacked and only the hard outer layer remains to give hollowed or tortoiseshell rocks. Another superficial layer, the precise nature of which is little understood, is the well-known desert varnish or patina, a shiny coat on the surface of rocks and pebbles and characteristic of arid environments. Some varnishes are colourless, others light brown, yet others so dark a brown as to be virtually black. Its origin is unknown but is significant, for it has been suggested that the varnish grows darker with the passage of time; obviously before such a criterion could be used with confidence as a chronological tool its origin must be known with precision. Its formation is so slow that in Egypt, for example, it has been estimated that a light brown coating requires between 2,000 and 5,000 years to develop, a fully formed blackish veneer between 20,000 and 50,000 years. The development of relatively impermeable soil horizons that are subsequently exposed at the surface because of erosion of once overlying, easily eroded materials, and which thus become surface crusts, is widespread in arid regions, although it is also known outside the deserts, and indeed many of the examples in arid lands probably originated in former periods of humid climate. The crusts prevent the waters of occasional torrential downpours from penetrating deeply into the soil, and thus they contribute to the rapid run-off associated with desert storms. Also, after erosion has cut through the crust and exposed underlying soil layers, the hard layer forms a resistant capping (duricrust) on plateaux and mesas, such as are common in many parts of arid and semi-arid Australia. Some duricrust layers have been used as time markers for landforms and geological formations. The necessary conditions for this are that the crust forms fairly rapidly, and that it is sufficiently distinct in appearance to preclude the possibility of confusion with other crusts formed at other times. The Barrilaco calcrete of Mexico for instance is believed to date from about 7,000 B. C. The main silcrete of the northern districts of South Australia is believed to date from the Lower Miocene, the laterite of northern Australia to be of the Lower or Middle Miocene age.", "hypothesis": "Duricrust layering is no longer used as an indicator of time because of the confusion with similar crusts.", "gold_label": "neutral"}
{"uid": "id_345", "premise": "WEATHERING IN THE DESERT In the deserts, as elsewhere, rocks at the earths surface are changed by weathering, which may be defined as the disintegration of rocks where they lie. Weathering processes are either chemical, when alteration of some of the constituent particles is involved; or mechanical, when there is merely the physical breaking apart and fragmentation of rocks. Which process will dominate depends primarily on the mineralogy and texture of the rock and the local climate, but several individual processes usually work together to the common end of rock disintegration. The great daily changes in temperature of deserts have long been supposed to be responsible for the disintegration of rocks, either by the differential heating of the various rock-forming minerals or by differential heating between the outer and inner parts of rock masses. However, both field observations and laboratory experiments have led to a reassessment of the importance of exposure to the suns rays in desert weathering. Almost half a century ago Barton remarked that the buried parts of some of the ancient monuments in Egypt were more weathered than were those parts fully exposed to the suns rays, and attributed this to the effects of water absorption below the ground surface. Laboratory experiments have shown that rocks subjected to many cycles of large temperature oscillations (larger than those experienced in nature) display no evidence of fissuring or fragmentation, as a result. However, when marked fluctuations of temperature occur in moist conditions small rock fragments quickly form. The expansive action of crystallising salts is often alleged to exert sufficient force to disintegrate rocks. Few would dispute that this mechanism is capable of disrupting fissile or well-cleaved rocks or rocks already weakened by other weathering agencies; wood is splintered, terracotta tiles disintegrated and clays disturbed by the mechanism, but its importance when acting upon fresh and cohesive crystalline rocks remains uncertain. Weathering achieves more than the disintegration of rocks, though this is its most important geomorphic effect. It causes specific landforms to develop. Many boulders possess a superficial hard layer of iron oxide and/or silica, substances which have migrated in solution from the inside of the block towards the surface. Not only is the exterior thus case-hardened but the depleted interior disintegrates easily. When weathering penetrates the shell the inside is rapidly attacked and only the hard outer layer remains to give hollowed or tortoiseshell rocks. Another superficial layer, the precise nature of which is little understood, is the well-known desert varnish or patina, a shiny coat on the surface of rocks and pebbles and characteristic of arid environments. Some varnishes are colourless, others light brown, yet others so dark a brown as to be virtually black. Its origin is unknown but is significant, for it has been suggested that the varnish grows darker with the passage of time; obviously before such a criterion could be used with confidence as a chronological tool its origin must be known with precision. Its formation is so slow that in Egypt, for example, it has been estimated that a light brown coating requires between 2,000 and 5,000 years to develop, a fully formed blackish veneer between 20,000 and 50,000 years. The development of relatively impermeable soil horizons that are subsequently exposed at the surface because of erosion of once overlying, easily eroded materials, and which thus become surface crusts, is widespread in arid regions, although it is also known outside the deserts, and indeed many of the examples in arid lands probably originated in former periods of humid climate. The crusts prevent the waters of occasional torrential downpours from penetrating deeply into the soil, and thus they contribute to the rapid run-off associated with desert storms. Also, after erosion has cut through the crust and exposed underlying soil layers, the hard layer forms a resistant capping (duricrust) on plateaux and mesas, such as are common in many parts of arid and semi-arid Australia. Some duricrust layers have been used as time markers for landforms and geological formations. The necessary conditions for this are that the crust forms fairly rapidly, and that it is sufficiently distinct in appearance to preclude the possibility of confusion with other crusts formed at other times. The Barrilaco calcrete of Mexico for instance is believed to date from about 7,000 B. C. The main silcrete of the northern districts of South Australia is believed to date from the Lower Miocene, the laterite of northern Australia to be of the Lower or Middle Miocene age.", "hypothesis": "Because of surface crusts, water from torrential rains cannot be fully absorbed into the ground and as a result causes run offs in arid regions.", "gold_label": "entailment"}
{"uid": "id_346", "premise": "WEATHERING IN THE DESERT In the deserts, as elsewhere, rocks at the earths surface are changed by weathering, which may be defined as the disintegration of rocks where they lie. Weathering processes are either chemical, when alteration of some of the constituent particles is involved; or mechanical, when there is merely the physical breaking apart and fragmentation of rocks. Which process will dominate depends primarily on the mineralogy and texture of the rock and the local climate, but several individual processes usually work together to the common end of rock disintegration. The great daily changes in temperature of deserts have long been supposed to be responsible for the disintegration of rocks, either by the differential heating of the various rock-forming minerals or by differential heating between the outer and inner parts of rock masses. However, both field observations and laboratory experiments have led to a reassessment of the importance of exposure to the suns rays in desert weathering. Almost half a century ago Barton remarked that the buried parts of some of the ancient monuments in Egypt were more weathered than were those parts fully exposed to the suns rays, and attributed this to the effects of water absorption below the ground surface. Laboratory experiments have shown that rocks subjected to many cycles of large temperature oscillations (larger than those experienced in nature) display no evidence of fissuring or fragmentation, as a result. However, when marked fluctuations of temperature occur in moist conditions small rock fragments quickly form. The expansive action of crystallising salts is often alleged to exert sufficient force to disintegrate rocks. Few would dispute that this mechanism is capable of disrupting fissile or well-cleaved rocks or rocks already weakened by other weathering agencies; wood is splintered, terracotta tiles disintegrated and clays disturbed by the mechanism, but its importance when acting upon fresh and cohesive crystalline rocks remains uncertain. Weathering achieves more than the disintegration of rocks, though this is its most important geomorphic effect. It causes specific landforms to develop. Many boulders possess a superficial hard layer of iron oxide and/or silica, substances which have migrated in solution from the inside of the block towards the surface. Not only is the exterior thus case-hardened but the depleted interior disintegrates easily. When weathering penetrates the shell the inside is rapidly attacked and only the hard outer layer remains to give hollowed or tortoiseshell rocks. Another superficial layer, the precise nature of which is little understood, is the well-known desert varnish or patina, a shiny coat on the surface of rocks and pebbles and characteristic of arid environments. Some varnishes are colourless, others light brown, yet others so dark a brown as to be virtually black. Its origin is unknown but is significant, for it has been suggested that the varnish grows darker with the passage of time; obviously before such a criterion could be used with confidence as a chronological tool its origin must be known with precision. Its formation is so slow that in Egypt, for example, it has been estimated that a light brown coating requires between 2,000 and 5,000 years to develop, a fully formed blackish veneer between 20,000 and 50,000 years. The development of relatively impermeable soil horizons that are subsequently exposed at the surface because of erosion of once overlying, easily eroded materials, and which thus become surface crusts, is widespread in arid regions, although it is also known outside the deserts, and indeed many of the examples in arid lands probably originated in former periods of humid climate. The crusts prevent the waters of occasional torrential downpours from penetrating deeply into the soil, and thus they contribute to the rapid run-off associated with desert storms. Also, after erosion has cut through the crust and exposed underlying soil layers, the hard layer forms a resistant capping (duricrust) on plateaux and mesas, such as are common in many parts of arid and semi-arid Australia. Some duricrust layers have been used as time markers for landforms and geological formations. The necessary conditions for this are that the crust forms fairly rapidly, and that it is sufficiently distinct in appearance to preclude the possibility of confusion with other crusts formed at other times. The Barrilaco calcrete of Mexico for instance is believed to date from about 7,000 B. C. The main silcrete of the northern districts of South Australia is believed to date from the Lower Miocene, the laterite of northern Australia to be of the Lower or Middle Miocene age.", "hypothesis": "Granite which has been subjected to huge temperature swings tends not to exhibit any signs of disintegration as a result.", "gold_label": "neutral"}
{"uid": "id_347", "premise": "WEST THAMES COLLEGE BACKGROUND INFORMATION FOR CANDIDATES West Thames College (initially known as Hounslow Borough College) came into existence in 1976 following the merger of Isleworth Polytechnic with part of Chiswick Polytechnic. Both parent colleges, in various guises, enjoyed a long tradition of service to the community dating back to the 1890s. The college is located at London Road, Isleworth, on a site occupied by the Victorian house of the Pears family, Spring Grove House. An earlier house of the same name on this site had been the home of Sir Joseph Banks, the botanist who named Botany Bay with Captain Cook in 1770. Later he founded Kew Gardens. Situated at the heart of West London, West Thames College is ideally placed to serve the training and education needs of local industry and local people. But its influence reaches much further than the immediate locality. Under its former name, Hounslow Borough College, it had already established a regional, national and international reputation for excellence. In fact, about eight per cent of its students come from continental Europe and further afield, whilst a further 52 per cent are from outside the immediate area. Since 1 April 1993, when it became independent of the local authority and adopted its new title, West Thames College has continued to build on that first class reputation. These days there is no such thing as a typical student. More than half of West Thames colleges 6000 students are over 19 years old. Some of these will be attending college part-time under their employers training schemes. Others will want to learn new skills purely out of interest, or out of a desire to improve their promotion chances, or they may want a change in career. The college is also very popular with 16-18 year olds, who see it as a practical alternative to a further two years at school. They want to study in the more adult atmosphere the college provides. They can choose from a far wider range of subjects than it would be practical for a sixth form to offer. If they want to go straight into employment they can still study at college to gain qualifications relevant to the job, either on a day-release basis or through Network or the Modern Apprenticeship Scheme.", "hypothesis": "Chiswick Polytechnic was closed at the same time West Thames College was opened.", "gold_label": "neutral"}
{"uid": "id_348", "premise": "WEST THAMES COLLEGE BACKGROUND INFORMATION FOR CANDIDATES West Thames College (initially known as Hounslow Borough College) came into existence in 1976 following the merger of Isleworth Polytechnic with part of Chiswick Polytechnic. Both parent colleges, in various guises, enjoyed a long tradition of service to the community dating back to the 1890s. The college is located at London Road, Isleworth, on a site occupied by the Victorian house of the Pears family, Spring Grove House. An earlier house of the same name on this site had been the home of Sir Joseph Banks, the botanist who named Botany Bay with Captain Cook in 1770. Later he founded Kew Gardens. Situated at the heart of West London, West Thames College is ideally placed to serve the training and education needs of local industry and local people. But its influence reaches much further than the immediate locality. Under its former name, Hounslow Borough College, it had already established a regional, national and international reputation for excellence. In fact, about eight per cent of its students come from continental Europe and further afield, whilst a further 52 per cent are from outside the immediate area. Since 1 April 1993, when it became independent of the local authority and adopted its new title, West Thames College has continued to build on that first class reputation. These days there is no such thing as a typical student. More than half of West Thames colleges 6000 students are over 19 years old. Some of these will be attending college part-time under their employers training schemes. Others will want to learn new skills purely out of interest, or out of a desire to improve their promotion chances, or they may want a change in career. The college is also very popular with 16-18 year olds, who see it as a practical alternative to a further two years at school. They want to study in the more adult atmosphere the college provides. They can choose from a far wider range of subjects than it would be practical for a sixth form to offer. If they want to go straight into employment they can still study at college to gain qualifications relevant to the job, either on a day-release basis or through Network or the Modern Apprenticeship Scheme.", "hypothesis": "Students under the age of 16 cannot attend any of the courses offered by the college.", "gold_label": "neutral"}
{"uid": "id_349", "premise": "WEST THAMES COLLEGE BACKGROUND INFORMATION FOR CANDIDATES West Thames College (initially known as Hounslow Borough College) came into existence in 1976 following the merger of Isleworth Polytechnic with part of Chiswick Polytechnic. Both parent colleges, in various guises, enjoyed a long tradition of service to the community dating back to the 1890s. The college is located at London Road, Isleworth, on a site occupied by the Victorian house of the Pears family, Spring Grove House. An earlier house of the same name on this site had been the home of Sir Joseph Banks, the botanist who named Botany Bay with Captain Cook in 1770. Later he founded Kew Gardens. Situated at the heart of West London, West Thames College is ideally placed to serve the training and education needs of local industry and local people. But its influence reaches much further than the immediate locality. Under its former name, Hounslow Borough College, it had already established a regional, national and international reputation for excellence. In fact, about eight per cent of its students come from continental Europe and further afield, whilst a further 52 per cent are from outside the immediate area. Since 1 April 1993, when it became independent of the local authority and adopted its new title, West Thames College has continued to build on that first class reputation. These days there is no such thing as a typical student. More than half of West Thames colleges 6000 students are over 19 years old. Some of these will be attending college part-time under their employers training schemes. Others will want to learn new skills purely out of interest, or out of a desire to improve their promotion chances, or they may want a change in career. The college is also very popular with 16-18 year olds, who see it as a practical alternative to a further two years at school. They want to study in the more adult atmosphere the college provides. They can choose from a far wider range of subjects than it would be practical for a sixth form to offer. If they want to go straight into employment they can still study at college to gain qualifications relevant to the job, either on a day-release basis or through Network or the Modern Apprenticeship Scheme.", "hypothesis": "There are fewer subjects to study in the sixth form of a school than at the college.", "gold_label": "entailment"}
{"uid": "id_350", "premise": "WEST THAMES COLLEGE BACKGROUND INFORMATION FOR CANDIDATES West Thames College (initially known as Hounslow Borough College) came into existence in 1976 following the merger of Isleworth Polytechnic with part of Chiswick Polytechnic. Both parent colleges, in various guises, enjoyed a long tradition of service to the community dating back to the 1890s. The college is located at London Road, Isleworth, on a site occupied by the Victorian house of the Pears family, Spring Grove House. An earlier house of the same name on this site had been the home of Sir Joseph Banks, the botanist who named Botany Bay with Captain Cook in 1770. Later he founded Kew Gardens. Situated at the heart of West London, West Thames College is ideally placed to serve the training and education needs of local industry and local people. But its influence reaches much further than the immediate locality. Under its former name, Hounslow Borough College, it had already established a regional, national and international reputation for excellence. In fact, about eight per cent of its students come from continental Europe and further afield, whilst a further 52 per cent are from outside the immediate area. Since 1 April 1993, when it became independent of the local authority and adopted its new title, West Thames College has continued to build on that first class reputation. These days there is no such thing as a typical student. More than half of West Thames colleges 6000 students are over 19 years old. Some of these will be attending college part-time under their employers training schemes. Others will want to learn new skills purely out of interest, or out of a desire to improve their promotion chances, or they may want a change in career. The college is also very popular with 16-18 year olds, who see it as a practical alternative to a further two years at school. They want to study in the more adult atmosphere the college provides. They can choose from a far wider range of subjects than it would be practical for a sixth form to offer. If they want to go straight into employment they can still study at college to gain qualifications relevant to the job, either on a day-release basis or through Network or the Modern Apprenticeship Scheme.", "hypothesis": "There are currently 6000 students over the age of 19 attending the college.", "gold_label": "contradiction"}
{"uid": "id_351", "premise": "WEST THAMES COLLEGE BACKGROUND INFORMATION FOR CANDIDATES West Thames College (initially known as Hounslow Borough College) came into existence in 1976 following the merger of Isleworth Polytechnic with part of Chiswick Polytechnic. Both parent colleges, in various guises, enjoyed a long tradition of service to the community dating back to the 1890s. The college is located at London Road, Isleworth, on a site occupied by the Victorian house of the Pears family, Spring Grove House. An earlier house of the same name on this site had been the home of Sir Joseph Banks, the botanist who named Botany Bay with Captain Cook in 1770. Later he founded Kew Gardens. Situated at the heart of West London, West Thames College is ideally placed to serve the training and education needs of local industry and local people. But its influence reaches much further than the immediate locality. Under its former name, Hounslow Borough College, it had already established a regional, national and international reputation for excellence. In fact, about eight per cent of its students come from continental Europe and further afield, whilst a further 52 per cent are from outside the immediate area. Since 1 April 1993, when it became independent of the local authority and adopted its new title, West Thames College has continued to build on that first class reputation. These days there is no such thing as a typical student. More than half of West Thames colleges 6000 students are over 19 years old. Some of these will be attending college part-time under their employers training schemes. Others will want to learn new skills purely out of interest, or out of a desire to improve their promotion chances, or they may want a change in career. The college is also very popular with 16-18 year olds, who see it as a practical alternative to a further two years at school. They want to study in the more adult atmosphere the college provides. They can choose from a far wider range of subjects than it would be practical for a sixth form to offer. If they want to go straight into employment they can still study at college to gain qualifications relevant to the job, either on a day-release basis or through Network or the Modern Apprenticeship Scheme.", "hypothesis": "The college offers a more mature environment in which to learn than a school.", "gold_label": "entailment"}
{"uid": "id_352", "premise": "WEST THAMES COLLEGE BACKGROUND INFORMATION FOR CANDIDATES West Thames College (initially known as Hounslow Borough College) came into existence in 1976 following the merger of Isleworth Polytechnic with part of Chiswick Polytechnic. Both parent colleges, in various guises, enjoyed a long tradition of service to the community dating back to the 1890s. The college is located at London Road, Isleworth, on a site occupied by the Victorian house of the Pears family, Spring Grove House. An earlier house of the same name on this site had been the home of Sir Joseph Banks, the botanist who named Botany Bay with Captain Cook in 1770. Later he founded Kew Gardens. Situated at the heart of West London, West Thames College is ideally placed to serve the training and education needs of local industry and local people. But its influence reaches much further than the immediate locality. Under its former name, Hounslow Borough College, it had already established a regional, national and international reputation for excellence. In fact, about eight per cent of its students come from continental Europe and further afield, whilst a further 52 per cent are from outside the immediate area. Since 1 April 1993, when it became independent of the local authority and adopted its new title, West Thames College has continued to build on that first class reputation. These days there is no such thing as a typical student. More than half of West Thames colleges 6000 students are over 19 years old. Some of these will be attending college part-time under their employers training schemes. Others will want to learn new skills purely out of interest, or out of a desire to improve their promotion chances, or they may want a change in career. The college is also very popular with 16-18 year olds, who see it as a practical alternative to a further two years at school. They want to study in the more adult atmosphere the college provides. They can choose from a far wider range of subjects than it would be practical for a sixth form to offer. If they want to go straight into employment they can still study at college to gain qualifications relevant to the job, either on a day-release basis or through Network or the Modern Apprenticeship Scheme.", "hypothesis": "The college changed its name to West Thames College in 1993.", "gold_label": "entailment"}
{"uid": "id_353", "premise": "WEST THAMES COLLEGE BACKGROUND INFORMATION FOR CANDIDATES West Thames College (initially known as Hounslow Borough College) came into existence in 1976 following the merger of Isleworth Polytechnic with part of Chiswick Polytechnic. Both parent colleges, in various guises, enjoyed a long tradition of service to the community dating back to the 1890s. The college is located at London Road, Isleworth, on a site occupied by the Victorian house of the Pears family, Spring Grove House. An earlier house of the same name on this site had been the home of Sir Joseph Banks, the botanist who named Botany Bay with Captain Cook in 1770. Later he founded Kew Gardens. Situated at the heart of West London, West Thames College is ideally placed to serve the training and education needs of local industry and local people. But its influence reaches much further than the immediate locality. Under its former name, Hounslow Borough College, it had already established a regional, national and international reputation for excellence. In fact, about eight per cent of its students come from continental Europe and further afield, whilst a further 52 per cent are from outside the immediate area. Since 1 April 1993, when it became independent of the local authority and adopted its new title, West Thames College has continued to build on that first class reputation. These days there is no such thing as a typical student. More than half of West Thames colleges 6000 students are over 19 years old. Some of these will be attending college part-time under their employers training schemes. Others will want to learn new skills purely out of interest, or out of a desire to improve their promotion chances, or they may want a change in career. The college is also very popular with 16-18 year olds, who see it as a practical alternative to a further two years at school. They want to study in the more adult atmosphere the college provides. They can choose from a far wider range of subjects than it would be practical for a sixth form to offer. If they want to go straight into employment they can still study at college to gain qualifications relevant to the job, either on a day-release basis or through Network or the Modern Apprenticeship Scheme.", "hypothesis": "Most of the students at the college come from outside the local area.", "gold_label": "entailment"}
{"uid": "id_354", "premise": "WESTLEY GENERAL HOSPITAL GUIDE FOR PATIENTS When you come to hospital for a planned stay, please remember that space is limited. We also advise you to bring an overnight bag even if you are only expecting to spend a day in hospital. A Clothing Please bring a selection of light clothing and personal belongings that may include: night clothes, a track suit, a sweater or fleece, a bathrobe, slippers or socks, glasses, contact lenses, dentures, a hearing aid, bottled drinks (plastic only), tissues, books and magazines, contact details of friends, cash to purchase items during your stay. B Toiletries Please bring a selection with you including a shaving kit if you are male. The hospital also runs a shop and trolley service from which extra items (additional toiletries, magazines, stamps, newspapers etc. ) can be purchased. C Valuables We strongly advise you not to bring any valuables with you as their security cannot be guaranteed. A closet is provided for some personal items. D Electrical appliances We ask that you do not bring electrical appliances with you. TV, radio and payphones are provided. E Medicines Please bring all your current medication with you, preferably in their original containers. On arrival the nursing staff will ask about your history and allergies. F Maternity Please bring the appropriate baby clothes and feeding equipment. For further information, please contact the Maternity Unit on 740648. G What Not to Bring Please do not bring any valuables (jewellery), personal computers, radios, TVs. The hospital cannot be held responsible for the loss of any items during your stay. Please note that the hospital does not allow the use of mobile telephones due to possible interference with patient monitoring equipment. H Smoking and Drinking Policy Smoking and alcohol are strictly prohibited in Westley Hospital. Patients wishing to smoke must do so outdoors. No alcohol is allowed on the premises. I Visiting Hours For details about when your friends and family can visit, see the list in your room or ward or check our website.", "hypothesis": "Dont bring any money to the hospital.", "gold_label": "contradiction"}
{"uid": "id_355", "premise": "WESTLEY GENERAL HOSPITAL GUIDE FOR PATIENTS When you come to hospital for a planned stay, please remember that space is limited. We also advise you to bring an overnight bag even if you are only expecting to spend a day in hospital. A Clothing Please bring a selection of light clothing and personal belongings that may include: night clothes, a track suit, a sweater or fleece, a bathrobe, slippers or socks, glasses, contact lenses, dentures, a hearing aid, bottled drinks (plastic only), tissues, books and magazines, contact details of friends, cash to purchase items during your stay. B Toiletries Please bring a selection with you including a shaving kit if you are male. The hospital also runs a shop and trolley service from which extra items (additional toiletries, magazines, stamps, newspapers etc. ) can be purchased. C Valuables We strongly advise you not to bring any valuables with you as their security cannot be guaranteed. A closet is provided for some personal items. D Electrical appliances We ask that you do not bring electrical appliances with you. TV, radio and payphones are provided. E Medicines Please bring all your current medication with you, preferably in their original containers. On arrival the nursing staff will ask about your history and allergies. F Maternity Please bring the appropriate baby clothes and feeding equipment. For further information, please contact the Maternity Unit on 740648. G What Not to Bring Please do not bring any valuables (jewellery), personal computers, radios, TVs. The hospital cannot be held responsible for the loss of any items during your stay. Please note that the hospital does not allow the use of mobile telephones due to possible interference with patient monitoring equipment. H Smoking and Drinking Policy Smoking and alcohol are strictly prohibited in Westley Hospital. Patients wishing to smoke must do so outdoors. No alcohol is allowed on the premises. I Visiting Hours For details about when your friends and family can visit, see the list in your room or ward or check our website.", "hypothesis": "Radios can interfere with hospital electronic equipment.", "gold_label": "neutral"}
{"uid": "id_356", "premise": "WESTLEY GENERAL HOSPITAL GUIDE FOR PATIENTS When you come to hospital for a planned stay, please remember that space is limited. We also advise you to bring an overnight bag even if you are only expecting to spend a day in hospital. A Clothing Please bring a selection of light clothing and personal belongings that may include: night clothes, a track suit, a sweater or fleece, a bathrobe, slippers or socks, glasses, contact lenses, dentures, a hearing aid, bottled drinks (plastic only), tissues, books and magazines, contact details of friends, cash to purchase items during your stay. B Toiletries Please bring a selection with you including a shaving kit if you are male. The hospital also runs a shop and trolley service from which extra items (additional toiletries, magazines, stamps, newspapers etc. ) can be purchased. C Valuables We strongly advise you not to bring any valuables with you as their security cannot be guaranteed. A closet is provided for some personal items. D Electrical appliances We ask that you do not bring electrical appliances with you. TV, radio and payphones are provided. E Medicines Please bring all your current medication with you, preferably in their original containers. On arrival the nursing staff will ask about your history and allergies. F Maternity Please bring the appropriate baby clothes and feeding equipment. For further information, please contact the Maternity Unit on 740648. G What Not to Bring Please do not bring any valuables (jewellery), personal computers, radios, TVs. The hospital cannot be held responsible for the loss of any items during your stay. Please note that the hospital does not allow the use of mobile telephones due to possible interference with patient monitoring equipment. H Smoking and Drinking Policy Smoking and alcohol are strictly prohibited in Westley Hospital. Patients wishing to smoke must do so outdoors. No alcohol is allowed on the premises. I Visiting Hours For details about when your friends and family can visit, see the list in your room or ward or check our website.", "hypothesis": "Leave any false teeth at home.", "gold_label": "contradiction"}
{"uid": "id_357", "premise": "WESTLEY GENERAL HOSPITAL GUIDE FOR PATIENTS When you come to hospital for a planned stay, please remember that space is limited. We also advise you to bring an overnight bag even if you are only expecting to spend a day in hospital. A Clothing Please bring a selection of light clothing and personal belongings that may include: night clothes, a track suit, a sweater or fleece, a bathrobe, slippers or socks, glasses, contact lenses, dentures, a hearing aid, bottled drinks (plastic only), tissues, books and magazines, contact details of friends, cash to purchase items during your stay. B Toiletries Please bring a selection with you including a shaving kit if you are male. The hospital also runs a shop and trolley service from which extra items (additional toiletries, magazines, stamps, newspapers etc. ) can be purchased. C Valuables We strongly advise you not to bring any valuables with you as their security cannot be guaranteed. A closet is provided for some personal items. D Electrical appliances We ask that you do not bring electrical appliances with you. TV, radio and payphones are provided. E Medicines Please bring all your current medication with you, preferably in their original containers. On arrival the nursing staff will ask about your history and allergies. F Maternity Please bring the appropriate baby clothes and feeding equipment. For further information, please contact the Maternity Unit on 740648. G What Not to Bring Please do not bring any valuables (jewellery), personal computers, radios, TVs. The hospital cannot be held responsible for the loss of any items during your stay. Please note that the hospital does not allow the use of mobile telephones due to possible interference with patient monitoring equipment. H Smoking and Drinking Policy Smoking and alcohol are strictly prohibited in Westley Hospital. Patients wishing to smoke must do so outdoors. No alcohol is allowed on the premises. I Visiting Hours For details about when your friends and family can visit, see the list in your room or ward or check our website.", "hypothesis": "Telephone services are provided through coin or card operated telephones.", "gold_label": "entailment"}
{"uid": "id_358", "premise": "WESTLEY GENERAL HOSPITAL GUIDE FOR PATIENTS When you come to hospital for a planned stay, please remember that space is limited. We also advise you to bring an overnight bag even if you are only expecting to spend a day in hospital. A Clothing Please bring a selection of light clothing and personal belongings that may include: night clothes, a track suit, a sweater or fleece, a bathrobe, slippers or socks, glasses, contact lenses, dentures, a hearing aid, bottled drinks (plastic only), tissues, books and magazines, contact details of friends, cash to purchase items during your stay. B Toiletries Please bring a selection with you including a shaving kit if you are male. The hospital also runs a shop and trolley service from which extra items (additional toiletries, magazines, stamps, newspapers etc. ) can be purchased. C Valuables We strongly advise you not to bring any valuables with you as their security cannot be guaranteed. A closet is provided for some personal items. D Electrical appliances We ask that you do not bring electrical appliances with you. TV, radio and payphones are provided. E Medicines Please bring all your current medication with you, preferably in their original containers. On arrival the nursing staff will ask about your history and allergies. F Maternity Please bring the appropriate baby clothes and feeding equipment. For further information, please contact the Maternity Unit on 740648. G What Not to Bring Please do not bring any valuables (jewellery), personal computers, radios, TVs. The hospital cannot be held responsible for the loss of any items during your stay. Please note that the hospital does not allow the use of mobile telephones due to possible interference with patient monitoring equipment. H Smoking and Drinking Policy Smoking and alcohol are strictly prohibited in Westley Hospital. Patients wishing to smoke must do so outdoors. No alcohol is allowed on the premises. I Visiting Hours For details about when your friends and family can visit, see the list in your room or ward or check our website.", "hypothesis": "You should pack a bag to stay for the night even if you intend only to be a day patient.", "gold_label": "entailment"}
{"uid": "id_359", "premise": "WESTLEY SCHOOL OF ENGLISH Information for Students Timings The school is open Mon Fri from 7.30 am to 9.00 pm and on Saturday from 9.00 am to 12.30 pm. CLASS TIMINGS (Mon Fri) Lesson 1 8.45 am 10.15 am Lesson 2 10.45 am 12.15 pm Lesson 3 2.00 pm 3.30 pm Computer Room The school has a fully equipped computer lab with a free 24-hour internet connection. Students may use the computers at any time during school opening hours unless any class or activity is scheduled. In the evenings there is a booking system for the computers. Please read the rules for this in the computer room. Be advised that, due to the risk of viruses, students are not allowed to bring in and use their own disks or CDs. Self Access and Language Lab The lab is open and available for all students during school opening hours. There are tapes and self-study materials available for all levels. In the break times and the evenings there is a teacher on duty who can assist students with accessing material. Cafeteria The school cafeteria is open from 8.15 am to 5.00 pm. The cafeteria only sells hot food at lunchtime. A selection of sandwiches, snacks and hot or cold drinks are available at other times during the rest of the day. Attendance All students who come to the UK on student visas are required by law to attend a minimum of 85% of their scheduled courses. The school is required to inform the Department of Immigration of any student not fulfilling his visa obligations. A minimum attendance of 85% is also required for students to receive their course certificate. Fees All fees must be paid in full before the start of any course. A non-returnable deposit of 10% will secure a reservation on a course but the balance must be paid before classes begin.", "hypothesis": "The police will visit any student not completing the required attendance levels", "gold_label": "neutral"}
{"uid": "id_360", "premise": "WESTLEY SCHOOL OF ENGLISH Information for Students Timings The school is open Mon Fri from 7.30 am to 9.00 pm and on Saturday from 9.00 am to 12.30 pm. CLASS TIMINGS (Mon Fri) Lesson 1 8.45 am 10.15 am Lesson 2 10.45 am 12.15 pm Lesson 3 2.00 pm 3.30 pm Computer Room The school has a fully equipped computer lab with a free 24-hour internet connection. Students may use the computers at any time during school opening hours unless any class or activity is scheduled. In the evenings there is a booking system for the computers. Please read the rules for this in the computer room. Be advised that, due to the risk of viruses, students are not allowed to bring in and use their own disks or CDs. Self Access and Language Lab The lab is open and available for all students during school opening hours. There are tapes and self-study materials available for all levels. In the break times and the evenings there is a teacher on duty who can assist students with accessing material. Cafeteria The school cafeteria is open from 8.15 am to 5.00 pm. The cafeteria only sells hot food at lunchtime. A selection of sandwiches, snacks and hot or cold drinks are available at other times during the rest of the day. Attendance All students who come to the UK on student visas are required by law to attend a minimum of 85% of their scheduled courses. The school is required to inform the Department of Immigration of any student not fulfilling his visa obligations. A minimum attendance of 85% is also required for students to receive their course certificate. Fees All fees must be paid in full before the start of any course. A non-returnable deposit of 10% will secure a reservation on a course but the balance must be paid before classes begin.", "hypothesis": "Students can go into the Language Lab at 8.30 on Thursday mornings.", "gold_label": "entailment"}
{"uid": "id_361", "premise": "WESTLEY SCHOOL OF ENGLISH Information for Students Timings The school is open Mon Fri from 7.30 am to 9.00 pm and on Saturday from 9.00 am to 12.30 pm. CLASS TIMINGS (Mon Fri) Lesson 1 8.45 am 10.15 am Lesson 2 10.45 am 12.15 pm Lesson 3 2.00 pm 3.30 pm Computer Room The school has a fully equipped computer lab with a free 24-hour internet connection. Students may use the computers at any time during school opening hours unless any class or activity is scheduled. In the evenings there is a booking system for the computers. Please read the rules for this in the computer room. Be advised that, due to the risk of viruses, students are not allowed to bring in and use their own disks or CDs. Self Access and Language Lab The lab is open and available for all students during school opening hours. There are tapes and self-study materials available for all levels. In the break times and the evenings there is a teacher on duty who can assist students with accessing material. Cafeteria The school cafeteria is open from 8.15 am to 5.00 pm. The cafeteria only sells hot food at lunchtime. A selection of sandwiches, snacks and hot or cold drinks are available at other times during the rest of the day. Attendance All students who come to the UK on student visas are required by law to attend a minimum of 85% of their scheduled courses. The school is required to inform the Department of Immigration of any student not fulfilling his visa obligations. A minimum attendance of 85% is also required for students to receive their course certificate. Fees All fees must be paid in full before the start of any course. A non-returnable deposit of 10% will secure a reservation on a course but the balance must be paid before classes begin.", "hypothesis": "Students may not use their own floppy discs in the schools computers.", "gold_label": "entailment"}
{"uid": "id_362", "premise": "WESTLEY SCHOOL OF ENGLISH Information for Students Timings The school is open Mon Fri from 7.30 am to 9.00 pm and on Saturday from 9.00 am to 12.30 pm. CLASS TIMINGS (Mon Fri) Lesson 1 8.45 am 10.15 am Lesson 2 10.45 am 12.15 pm Lesson 3 2.00 pm 3.30 pm Computer Room The school has a fully equipped computer lab with a free 24-hour internet connection. Students may use the computers at any time during school opening hours unless any class or activity is scheduled. In the evenings there is a booking system for the computers. Please read the rules for this in the computer room. Be advised that, due to the risk of viruses, students are not allowed to bring in and use their own disks or CDs. Self Access and Language Lab The lab is open and available for all students during school opening hours. There are tapes and self-study materials available for all levels. In the break times and the evenings there is a teacher on duty who can assist students with accessing material. Cafeteria The school cafeteria is open from 8.15 am to 5.00 pm. The cafeteria only sells hot food at lunchtime. A selection of sandwiches, snacks and hot or cold drinks are available at other times during the rest of the day. Attendance All students who come to the UK on student visas are required by law to attend a minimum of 85% of their scheduled courses. The school is required to inform the Department of Immigration of any student not fulfilling his visa obligations. A minimum attendance of 85% is also required for students to receive their course certificate. Fees All fees must be paid in full before the start of any course. A non-returnable deposit of 10% will secure a reservation on a course but the balance must be paid before classes begin.", "hypothesis": "Students can have a cooked breakfast in the cafe before their morning classes.", "gold_label": "contradiction"}
{"uid": "id_363", "premise": "WESTWINDS FARM CAMPSITE Open April September (Booking is advised for holidays in July and August to guarantee a place. ) Jim and Meg Oaks welcome you to the campsite. We hope you will enjoy your stay here. We ask all campers to show due care and consideration whilst staying here and to observe the following camp rules. Keep the campsite clean and tidy: dispose of litter in the bins provided; leave the showers, toilets and washing area in the same state as you found them; ensure your site is clear of all litter when you leave it. Dont obstruct rights of way. Keep cars, bikes, etc. off the road. Let sleeping campers have some peace. Dont make any noise after 10 oclock at night or before 7.30 in the morning. Dogs must be kept on a lead. Owners of dogs that disturb other campers by barking through the night will be asked to leave. Disorderly behaviour will not be tolerated. The lighting of fires is strictly prohibited. Ball games are not allowed on the campsite. There is plenty of room for ball games in the park opposite the campsite. Radios, portable music equipment, etc. must not be played at high volume. The management reserves the right to refuse admittance.", "hypothesis": "You should book ahead for the busier times of the year.", "gold_label": "entailment"}
{"uid": "id_364", "premise": "WESTWINDS FARM CAMPSITE Open April September (Booking is advised for holidays in July and August to guarantee a place. ) Jim and Meg Oaks welcome you to the campsite. We hope you will enjoy your stay here. We ask all campers to show due care and consideration whilst staying here and to observe the following camp rules. Keep the campsite clean and tidy: dispose of litter in the bins provided; leave the showers, toilets and washing area in the same state as you found them; ensure your site is clear of all litter when you leave it. Dont obstruct rights of way. Keep cars, bikes, etc. off the road. Let sleeping campers have some peace. Dont make any noise after 10 oclock at night or before 7.30 in the morning. Dogs must be kept on a lead. Owners of dogs that disturb other campers by barking through the night will be asked to leave. Disorderly behaviour will not be tolerated. The lighting of fires is strictly prohibited. Ball games are not allowed on the campsite. There is plenty of room for ball games in the park opposite the campsite. Radios, portable music equipment, etc. must not be played at high volume. The management reserves the right to refuse admittance.", "hypothesis": "The owners of the campsite may not allow you to camp there.", "gold_label": "entailment"}
{"uid": "id_365", "premise": "WESTWINDS FARM CAMPSITE Open April September (Booking is advised for holidays in July and August to guarantee a place. ) Jim and Meg Oaks welcome you to the campsite. We hope you will enjoy your stay here. We ask all campers to show due care and consideration whilst staying here and to observe the following camp rules. Keep the campsite clean and tidy: dispose of litter in the bins provided; leave the showers, toilets and washing area in the same state as you found them; ensure your site is clear of all litter when you leave it. Dont obstruct rights of way. Keep cars, bikes, etc. off the road. Let sleeping campers have some peace. Dont make any noise after 10 oclock at night or before 7.30 in the morning. Dogs must be kept on a lead. Owners of dogs that disturb other campers by barking through the night will be asked to leave. Disorderly behaviour will not be tolerated. The lighting of fires is strictly prohibited. Ball games are not allowed on the campsite. There is plenty of room for ball games in the park opposite the campsite. Radios, portable music equipment, etc. must not be played at high volume. The management reserves the right to refuse admittance.", "hypothesis": "You are not allowed to cook food on open fires.", "gold_label": "entailment"}
{"uid": "id_366", "premise": "WESTWINDS FARM CAMPSITE Open April September (Booking is advised for holidays in July and August to guarantee a place. ) Jim and Meg Oaks welcome you to the campsite. We hope you will enjoy your stay here. We ask all campers to show due care and consideration whilst staying here and to observe the following camp rules. Keep the campsite clean and tidy: dispose of litter in the bins provided; leave the showers, toilets and washing area in the same state as you found them; ensure your site is clear of all litter when you leave it. Dont obstruct rights of way. Keep cars, bikes, etc. off the road. Let sleeping campers have some peace. Dont make any noise after 10 oclock at night or before 7.30 in the morning. Dogs must be kept on a lead. Owners of dogs that disturb other campers by barking through the night will be asked to leave. Disorderly behaviour will not be tolerated. The lighting of fires is strictly prohibited. Ball games are not allowed on the campsite. There is plenty of room for ball games in the park opposite the campsite. Radios, portable music equipment, etc. must not be played at high volume. The management reserves the right to refuse admittance.", "hypothesis": "No dogs are allowed on the campsite.", "gold_label": "contradiction"}
{"uid": "id_367", "premise": "WESTWINDS FARM CAMPSITE Open April September (Booking is advised for holidays in July and August to guarantee a place. ) Jim and Meg Oaks welcome you to the campsite. We hope you will enjoy your stay here. We ask all campers to show due care and consideration whilst staying here and to observe the following camp rules. Keep the campsite clean and tidy: dispose of litter in the bins provided; leave the showers, toilets and washing area in the same state as you found them; ensure your site is clear of all litter when you leave it. Dont obstruct rights of way. Keep cars, bikes, etc. off the road. Let sleeping campers have some peace. Dont make any noise after 10 oclock at night or before 7.30 in the morning. Dogs must be kept on a lead. Owners of dogs that disturb other campers by barking through the night will be asked to leave. Disorderly behaviour will not be tolerated. The lighting of fires is strictly prohibited. Ball games are not allowed on the campsite. There is plenty of room for ball games in the park opposite the campsite. Radios, portable music equipment, etc. must not be played at high volume. The management reserves the right to refuse admittance.", "hypothesis": "The campsite is open all year round.", "gold_label": "contradiction"}
{"uid": "id_368", "premise": "WESTWINDS FARM CAMPSITE Open April September (Booking is advised for holidays in July and August to guarantee a place. ) Jim and Meg Oaks welcome you to the campsite. We hope you will enjoy your stay here. We ask all campers to show due care and consideration whilst staying here and to observe the following camp rules. Keep the campsite clean and tidy: dispose of litter in the bins provided; leave the showers, toilets and washing area in the same state as you found them; ensure your site is clear of all litter when you leave it. Dont obstruct rights of way. Keep cars, bikes, etc. off the road. Let sleeping campers have some peace. Dont make any noise after 10 oclock at night or before 7.30 in the morning. Dogs must be kept on a lead. Owners of dogs that disturb other campers by barking through the night will be asked to leave. Disorderly behaviour will not be tolerated. The lighting of fires is strictly prohibited. Ball games are not allowed on the campsite. There is plenty of room for ball games in the park opposite the campsite. Radios, portable music equipment, etc. must not be played at high volume. The management reserves the right to refuse admittance.", "hypothesis": "The minimum stay at the campsite is two nights.", "gold_label": "neutral"}
{"uid": "id_369", "premise": "WESTWINDS FARM CAMPSITE Open April September (Booking is advised for holidays in July and August to guarantee a place. ) Jim and Meg Oaks welcome you to the campsite. We hope you will enjoy your stay here. We ask all campers to show due care and consideration whilst staying here and to observe the following camp rules. Keep the campsite clean and tidy: dispose of litter in the bins provided; leave the showers, toilets and washing area in the same state as you found them; ensure your site is clear of all litter when you leave it. Dont obstruct rights of way. Keep cars, bikes, etc. off the road. Let sleeping campers have some peace. Dont make any noise after 10 oclock at night or before 7.30 in the morning. Dogs must be kept on a lead. Owners of dogs that disturb other campers by barking through the night will be asked to leave. Disorderly behaviour will not be tolerated. The lighting of fires is strictly prohibited. Ball games are not allowed on the campsite. There is plenty of room for ball games in the park opposite the campsite. Radios, portable music equipment, etc. must not be played at high volume. The management reserves the right to refuse admittance.", "hypothesis": "The entrance to the campsite is locked after 10 p. m.", "gold_label": "neutral"}
{"uid": "id_370", "premise": "WHATS ON IN WINTER The Great Outdoors Sundays, June and July ORIENTEERING Where: various bush and farm locations Orienteering is an outdoor activity that combines adventure and sport with navigational skills through the bush. Take a hike or mountain-bike ride through a set course in a different bush or farm location on each excursion with guidance from a compass and a map. Each course is within an hours drive of the CBD. This is a fun, easy way to enhance fitness for the whole family, ages 7-70. To learn more about orienteering or sign up for a course, visit wa. orienteering. asn. au or call 9215 0700. Mountain Designs Adventure Race Australia 4 July Where: bush camp and forest retreat Adventure Race Australia heightens the thrill of adventure racing, combining biking, running, trekking, kayaking, rock climbing and other adventure sports to test physical strength, endurance and willpower. The race caters to both inexperienced and seasoned racers with a Raw course for beginners and a Hardcore course for racers who want an extra challenge. To get involved go to adventureaustralia. com. au Film Frenzy 21 June & 19 July MEMORABLE MOVIES IN MIDLAND Where: Town Hall Take a trip down memory lane at the Memorable Movies gathering, held once a month. This June the memorable movie is Roman Holiday, the 1953 classic starring Gregory Peck and Audrey Hepburn. Then in July there is a school holiday special presentation of The Worlds Fastest Indian, a true-life story of motorcycle enthusiast and world-record breaker Burt Munro, starring Anthony Hopkins. Festivals and Fairs 17 to 19 June HILLARYS ANTIQUE AND VINTAGE FAIR Where: Hillarys Boat Harbour The Antique and Vintage Fair will showcase hidden treasures from the past, including fascinating items from antique furniture to retro fashion. Antique valuers will also be on the premises to give expert advice on buying and selling as attendees peruse the various stalls underneath one giant tent. Music Magic 29 to 30 July A TRIBUTE TO LOUIS ARMSTRONG Where: Concert Hall Louis Armstrong revolutionised American jazz and dominated the scene for more than 60 years. He defines the jazz style and is a legendary figure in music history. Conductor Benjamin Northey will accompany trumpeter James Morrison to pay tribute to the famous musician by playing some of his most well-known and beloved hits. Go to waso. com. au for more details. All the Rest Until 18 October WHODUNNIT? EXHIBITION Where: Scitech Become a detective for a day at the Whodunnit? Exhibition. The exhibition is a fabricated crime scene in a zoo: someone has shot and killed a security guard, and a famous white rhino is missing. Guests use forensic science to obtain evidence and solve the crimes.", "hypothesis": "The motorcyclist was wearing a helmet when he crashed and died.", "gold_label": "contradiction"}
{"uid": "id_371", "premise": "WHATS ON IN WINTER The Great Outdoors Sundays, June and July ORIENTEERING Where: various bush and farm locations Orienteering is an outdoor activity that combines adventure and sport with navigational skills through the bush. Take a hike or mountain-bike ride through a set course in a different bush or farm location on each excursion with guidance from a compass and a map. Each course is within an hours drive of the CBD. This is a fun, easy way to enhance fitness for the whole family, ages 7-70. To learn more about orienteering or sign up for a course, visit wa. orienteering. asn. au or call 9215 0700. Mountain Designs Adventure Race Australia 4 July Where: bush camp and forest retreat Adventure Race Australia heightens the thrill of adventure racing, combining biking, running, trekking, kayaking, rock climbing and other adventure sports to test physical strength, endurance and willpower. The race caters to both inexperienced and seasoned racers with a Raw course for beginners and a Hardcore course for racers who want an extra challenge. To get involved go to adventureaustralia. com. au Film Frenzy 21 June & 19 July MEMORABLE MOVIES IN MIDLAND Where: Town Hall Take a trip down memory lane at the Memorable Movies gathering, held once a month. This June the memorable movie is Roman Holiday, the 1953 classic starring Gregory Peck and Audrey Hepburn. Then in July there is a school holiday special presentation of The Worlds Fastest Indian, a true-life story of motorcycle enthusiast and world-record breaker Burt Munro, starring Anthony Hopkins. Festivals and Fairs 17 to 19 June HILLARYS ANTIQUE AND VINTAGE FAIR Where: Hillarys Boat Harbour The Antique and Vintage Fair will showcase hidden treasures from the past, including fascinating items from antique furniture to retro fashion. Antique valuers will also be on the premises to give expert advice on buying and selling as attendees peruse the various stalls underneath one giant tent. Music Magic 29 to 30 July A TRIBUTE TO LOUIS ARMSTRONG Where: Concert Hall Louis Armstrong revolutionised American jazz and dominated the scene for more than 60 years. He defines the jazz style and is a legendary figure in music history. Conductor Benjamin Northey will accompany trumpeter James Morrison to pay tribute to the famous musician by playing some of his most well-known and beloved hits. Go to waso. com. au for more details. All the Rest Until 18 October WHODUNNIT? EXHIBITION Where: Scitech Become a detective for a day at the Whodunnit? Exhibition. The exhibition is a fabricated crime scene in a zoo: someone has shot and killed a security guard, and a famous white rhino is missing. Guests use forensic science to obtain evidence and solve the crimes.", "hypothesis": "This incident took place in Onondaga, New York.", "gold_label": "entailment"}
{"uid": "id_372", "premise": "WHATS ON IN WINTER The Great Outdoors Sundays, June and July ORIENTEERING Where: various bush and farm locations Orienteering is an outdoor activity that combines adventure and sport with navigational skills through the bush. Take a hike or mountain-bike ride through a set course in a different bush or farm location on each excursion with guidance from a compass and a map. Each course is within an hours drive of the CBD. This is a fun, easy way to enhance fitness for the whole family, ages 7-70. To learn more about orienteering or sign up for a course, visit wa. orienteering. asn. au or call 9215 0700. Mountain Designs Adventure Race Australia 4 July Where: bush camp and forest retreat Adventure Race Australia heightens the thrill of adventure racing, combining biking, running, trekking, kayaking, rock climbing and other adventure sports to test physical strength, endurance and willpower. The race caters to both inexperienced and seasoned racers with a Raw course for beginners and a Hardcore course for racers who want an extra challenge. To get involved go to adventureaustralia. com. au Film Frenzy 21 June & 19 July MEMORABLE MOVIES IN MIDLAND Where: Town Hall Take a trip down memory lane at the Memorable Movies gathering, held once a month. This June the memorable movie is Roman Holiday, the 1953 classic starring Gregory Peck and Audrey Hepburn. Then in July there is a school holiday special presentation of The Worlds Fastest Indian, a true-life story of motorcycle enthusiast and world-record breaker Burt Munro, starring Anthony Hopkins. Festivals and Fairs 17 to 19 June HILLARYS ANTIQUE AND VINTAGE FAIR Where: Hillarys Boat Harbour The Antique and Vintage Fair will showcase hidden treasures from the past, including fascinating items from antique furniture to retro fashion. Antique valuers will also be on the premises to give expert advice on buying and selling as attendees peruse the various stalls underneath one giant tent. Music Magic 29 to 30 July A TRIBUTE TO LOUIS ARMSTRONG Where: Concert Hall Louis Armstrong revolutionised American jazz and dominated the scene for more than 60 years. He defines the jazz style and is a legendary figure in music history. Conductor Benjamin Northey will accompany trumpeter James Morrison to pay tribute to the famous musician by playing some of his most well-known and beloved hits. Go to waso. com. au for more details. All the Rest Until 18 October WHODUNNIT? EXHIBITION Where: Scitech Become a detective for a day at the Whodunnit? Exhibition. The exhibition is a fabricated crime scene in a zoo: someone has shot and killed a security guard, and a famous white rhino is missing. Guests use forensic science to obtain evidence and solve the crimes.", "hypothesis": "New York State requires motorcyclists to wear helmets.", "gold_label": "entailment"}
{"uid": "id_373", "premise": "WHATS ON IN WINTER The Great Outdoors Sundays, June and July ORIENTEERING Where: various bush and farm locations Orienteering is an outdoor activity that combines adventure and sport with navigational skills through the bush. Take a hike or mountain-bike ride through a set course in a different bush or farm location on each excursion with guidance from a compass and a map. Each course is within an hours drive of the CBD. This is a fun, easy way to enhance fitness for the whole family, ages 7-70. To learn more about orienteering or sign up for a course, visit wa. orienteering. asn. au or call 9215 0700. Mountain Designs Adventure Race Australia 4 July Where: bush camp and forest retreat Adventure Race Australia heightens the thrill of adventure racing, combining biking, running, trekking, kayaking, rock climbing and other adventure sports to test physical strength, endurance and willpower. The race caters to both inexperienced and seasoned racers with a Raw course for beginners and a Hardcore course for racers who want an extra challenge. To get involved go to adventureaustralia. com. au Film Frenzy 21 June & 19 July MEMORABLE MOVIES IN MIDLAND Where: Town Hall Take a trip down memory lane at the Memorable Movies gathering, held once a month. This June the memorable movie is Roman Holiday, the 1953 classic starring Gregory Peck and Audrey Hepburn. Then in July there is a school holiday special presentation of The Worlds Fastest Indian, a true-life story of motorcycle enthusiast and world-record breaker Burt Munro, starring Anthony Hopkins. Festivals and Fairs 17 to 19 June HILLARYS ANTIQUE AND VINTAGE FAIR Where: Hillarys Boat Harbour The Antique and Vintage Fair will showcase hidden treasures from the past, including fascinating items from antique furniture to retro fashion. Antique valuers will also be on the premises to give expert advice on buying and selling as attendees peruse the various stalls underneath one giant tent. Music Magic 29 to 30 July A TRIBUTE TO LOUIS ARMSTRONG Where: Concert Hall Louis Armstrong revolutionised American jazz and dominated the scene for more than 60 years. He defines the jazz style and is a legendary figure in music history. Conductor Benjamin Northey will accompany trumpeter James Morrison to pay tribute to the famous musician by playing some of his most well-known and beloved hits. Go to waso. com. au for more details. All the Rest Until 18 October WHODUNNIT? EXHIBITION Where: Scitech Become a detective for a day at the Whodunnit? Exhibition. The exhibition is a fabricated crime scene in a zoo: someone has shot and killed a security guard, and a famous white rhino is missing. Guests use forensic science to obtain evidence and solve the crimes.", "hypothesis": "More than a hundred motorcyclists were taking part in this protest ride.", "gold_label": "neutral"}
{"uid": "id_374", "premise": "WHATS ON IN WINTER The Great Outdoors Sundays, June and July ORIENTEERING Where: various bush and farm locations Orienteering is an outdoor activity that combines adventure and sport with navigational skills through the bush. Take a hike or mountain-bike ride through a set course in a different bush or farm location on each excursion with guidance from a compass and a map. Each course is within an hours drive of the CBD. This is a fun, easy way to enhance fitness for the whole family, ages 7-70. To learn more about orienteering or sign up for a course, visit wa. orienteering. asn. au or call 9215 0700. Mountain Designs Adventure Race Australia 4 July Where: bush camp and forest retreat Adventure Race Australia heightens the thrill of adventure racing, combining biking, running, trekking, kayaking, rock climbing and other adventure sports to test physical strength, endurance and willpower. The race caters to both inexperienced and seasoned racers with a Raw course for beginners and a Hardcore course for racers who want an extra challenge. To get involved go to adventureaustralia. com. au Film Frenzy 21 June & 19 July MEMORABLE MOVIES IN MIDLAND Where: Town Hall Take a trip down memory lane at the Memorable Movies gathering, held once a month. This June the memorable movie is Roman Holiday, the 1953 classic starring Gregory Peck and Audrey Hepburn. Then in July there is a school holiday special presentation of The Worlds Fastest Indian, a true-life story of motorcycle enthusiast and world-record breaker Burt Munro, starring Anthony Hopkins. Festivals and Fairs 17 to 19 June HILLARYS ANTIQUE AND VINTAGE FAIR Where: Hillarys Boat Harbour The Antique and Vintage Fair will showcase hidden treasures from the past, including fascinating items from antique furniture to retro fashion. Antique valuers will also be on the premises to give expert advice on buying and selling as attendees peruse the various stalls underneath one giant tent. Music Magic 29 to 30 July A TRIBUTE TO LOUIS ARMSTRONG Where: Concert Hall Louis Armstrong revolutionised American jazz and dominated the scene for more than 60 years. He defines the jazz style and is a legendary figure in music history. Conductor Benjamin Northey will accompany trumpeter James Morrison to pay tribute to the famous musician by playing some of his most well-known and beloved hits. Go to waso. com. au for more details. All the Rest Until 18 October WHODUNNIT? EXHIBITION Where: Scitech Become a detective for a day at the Whodunnit? Exhibition. The exhibition is a fabricated crime scene in a zoo: someone has shot and killed a security guard, and a famous white rhino is missing. Guests use forensic science to obtain evidence and solve the crimes.", "hypothesis": "Protests in the USA against compulsory use of motorcycle helmets have at times been successful.", "gold_label": "entailment"}
{"uid": "id_375", "premise": "WHATS ON IN WINTER The Great Outdoors Sundays, June and July ORIENTEERING Where: various bush and farm locations Orienteering is an outdoor activity that combines adventure and sport with navigational skills through the bush. Take a hike or mountain-bike ride through a set course in a different bush or farm location on each excursion with guidance from a compass and a map. Each course is within an hours drive of the CBD. This is a fun, easy way to enhance fitness for the whole family, ages 7-70. To learn more about orienteering or sign up for a course, visit wa. orienteering. asn. au or call 9215 0700. Mountain Designs Adventure Race Australia 4 July Where: bush camp and forest retreat Adventure Race Australia heightens the thrill of adventure racing, combining biking, running, trekking, kayaking, rock climbing and other adventure sports to test physical strength, endurance and willpower. The race caters to both inexperienced and seasoned racers with a Raw course for beginners and a Hardcore course for racers who want an extra challenge. To get involved go to adventureaustralia. com. au Film Frenzy 21 June & 19 July MEMORABLE MOVIES IN MIDLAND Where: Town Hall Take a trip down memory lane at the Memorable Movies gathering, held once a month. This June the memorable movie is Roman Holiday, the 1953 classic starring Gregory Peck and Audrey Hepburn. Then in July there is a school holiday special presentation of The Worlds Fastest Indian, a true-life story of motorcycle enthusiast and world-record breaker Burt Munro, starring Anthony Hopkins. Festivals and Fairs 17 to 19 June HILLARYS ANTIQUE AND VINTAGE FAIR Where: Hillarys Boat Harbour The Antique and Vintage Fair will showcase hidden treasures from the past, including fascinating items from antique furniture to retro fashion. Antique valuers will also be on the premises to give expert advice on buying and selling as attendees peruse the various stalls underneath one giant tent. Music Magic 29 to 30 July A TRIBUTE TO LOUIS ARMSTRONG Where: Concert Hall Louis Armstrong revolutionised American jazz and dominated the scene for more than 60 years. He defines the jazz style and is a legendary figure in music history. Conductor Benjamin Northey will accompany trumpeter James Morrison to pay tribute to the famous musician by playing some of his most well-known and beloved hits. Go to waso. com. au for more details. All the Rest Until 18 October WHODUNNIT? EXHIBITION Where: Scitech Become a detective for a day at the Whodunnit? Exhibition. The exhibition is a fabricated crime scene in a zoo: someone has shot and killed a security guard, and a famous white rhino is missing. Guests use forensic science to obtain evidence and solve the crimes.", "hypothesis": "All states in the USA require motorcyclists to wear helmets.", "gold_label": "contradiction"}
{"uid": "id_376", "premise": "WHEN the subject is global warming, the villain is usually America . Although it produces a quarter of the greenhouse gases that are heating up the planet, it refuses to regulate them. When other countries agreed on an international treaty to do so he Kyoto protocolAmerica failed to ratify it. But not all American officialdom is happy with the federal government's stance. In fact,12 states disagree so fiercely that they are suing to force it to curb emissions of carbon dioxide, the most common greenhouse gas. The Supreme Court heard argument in the case on November 29th. The outcome will not be known for months, but the political wind seems to be shifting in favour of firmer action to counter climate change. The Clean Air Act charges the Environmental Protection Agency (EPA) with regulating air pollution from vehicles. But the EPA argues that Congress did not intend to include CO2 under that heading, and that to do so would extend the EPA's authority to an unreasonable extent. Furthermore, it contends that regulating emissions would not do good unless all or most other countries did the same. That is in keeping with the policies of President George Bush, who opposes mandatory curbs on emissions and believes that any international accord on global warming should apply to all countries unlike the Kyoto protocol, which exempts poor ones, including big polluters such as China and India . Ten states, among them gas-guzzling Texas and car-making Michigan, also back the EPA. The plaintiffs comprise 12 states, three cities, various NGOs, and American Samoa, a Pacific territory in danger of vanishing beneath the rising ocean. They are supported by a further six states, two power companies, a ski resort, and assorted clergymen, Indian tribes and agitated grandees such as Madeleine Albright, a former secretary of state. They point out that under the administration of Bill Clinton, the EPA decided that it did have the authority to regulate CO2. The act, they note, says the EPA should regulate any air pollutant that \"may reasonably be interpreted to endanger public health or welfare\". It goes on to define public welfare to include \"effects on soils, water, crops, vegetation, manmade materials, animals, wildlife, weather, visibility, and climate\". The Supreme Court may give a mixed ruling, decreeing that carbon dioxide is indeed a pollutant, but one the EPA is free to ignore or regulate as it pleases. Or it might dismiss the complaint on the grounds that the plaintiffs did not have the right to lodge it in the first place. In theory, they must prove that the EPA's foot-dragging has caused them some specific harm that regulation might remedy a tall order in a field as fraught with uncertainty as climatology. Even if the court found in the plaintiffs' favour, rapid change is unlikely. By the time the EPA had implemented such a ruling, Congress would probably have superseded it with a new law. That is the point, environmental groups say. They want Congress to pass a law tackling global warming, and hope that a favourable court ruling will jolly the politicians along. Moreover, the case has a bearing on several other bitterly-contested lawsuits. Carmakers, for example, are trying to get the courts to strike down a Californian state law based on certain provisions of the Clean Air Act that require them to reduce their vehicles' CO2 emissions. If the Supreme Court decides that the act does not apply to CO2, then the Californian law would also be in jeopardy. That, in turn, would scupper the decision of ten other states to adopt the same standard. However the Supreme Court rules, many state governments are determined to tackle climate change. California is in the vanguard. Its legislature has passed a law that will cap and then reduce industrial emissions of greenhouse gases. Seven eastern states have formed the Regional Greenhouse Gas Initiative, which will treat emissions from power plants the same way. Almost 400 mayors have signed an agreement to cut their cities' emissions in line with Kyoto . Many businesses, even some power companies, would rather see regulation now than prolonged uncertainty. And several of the leading contenders for 2008's presidential election are much keener on emissions caps than Mr Bush. Change is in the air.", "hypothesis": "An American island is in danger of disappearing beneath the rising ocean.", "gold_label": "neutral"}
{"uid": "id_377", "premise": "WHEN the subject is global warming, the villain is usually America . Although it produces a quarter of the greenhouse gases that are heating up the planet, it refuses to regulate them. When other countries agreed on an international treaty to do so he Kyoto protocolAmerica failed to ratify it. But not all American officialdom is happy with the federal government's stance. In fact,12 states disagree so fiercely that they are suing to force it to curb emissions of carbon dioxide, the most common greenhouse gas. The Supreme Court heard argument in the case on November 29th. The outcome will not be known for months, but the political wind seems to be shifting in favour of firmer action to counter climate change. The Clean Air Act charges the Environmental Protection Agency (EPA) with regulating air pollution from vehicles. But the EPA argues that Congress did not intend to include CO2 under that heading, and that to do so would extend the EPA's authority to an unreasonable extent. Furthermore, it contends that regulating emissions would not do good unless all or most other countries did the same. That is in keeping with the policies of President George Bush, who opposes mandatory curbs on emissions and believes that any international accord on global warming should apply to all countries unlike the Kyoto protocol, which exempts poor ones, including big polluters such as China and India . Ten states, among them gas-guzzling Texas and car-making Michigan, also back the EPA. The plaintiffs comprise 12 states, three cities, various NGOs, and American Samoa, a Pacific territory in danger of vanishing beneath the rising ocean. They are supported by a further six states, two power companies, a ski resort, and assorted clergymen, Indian tribes and agitated grandees such as Madeleine Albright, a former secretary of state. They point out that under the administration of Bill Clinton, the EPA decided that it did have the authority to regulate CO2. The act, they note, says the EPA should regulate any air pollutant that \"may reasonably be interpreted to endanger public health or welfare\". It goes on to define public welfare to include \"effects on soils, water, crops, vegetation, manmade materials, animals, wildlife, weather, visibility, and climate\". The Supreme Court may give a mixed ruling, decreeing that carbon dioxide is indeed a pollutant, but one the EPA is free to ignore or regulate as it pleases. Or it might dismiss the complaint on the grounds that the plaintiffs did not have the right to lodge it in the first place. In theory, they must prove that the EPA's foot-dragging has caused them some specific harm that regulation might remedy a tall order in a field as fraught with uncertainty as climatology. Even if the court found in the plaintiffs' favour, rapid change is unlikely. By the time the EPA had implemented such a ruling, Congress would probably have superseded it with a new law. That is the point, environmental groups say. They want Congress to pass a law tackling global warming, and hope that a favourable court ruling will jolly the politicians along. Moreover, the case has a bearing on several other bitterly-contested lawsuits. Carmakers, for example, are trying to get the courts to strike down a Californian state law based on certain provisions of the Clean Air Act that require them to reduce their vehicles' CO2 emissions. If the Supreme Court decides that the act does not apply to CO2, then the Californian law would also be in jeopardy. That, in turn, would scupper the decision of ten other states to adopt the same standard. However the Supreme Court rules, many state governments are determined to tackle climate change. California is in the vanguard. Its legislature has passed a law that will cap and then reduce industrial emissions of greenhouse gases. Seven eastern states have formed the Regional Greenhouse Gas Initiative, which will treat emissions from power plants the same way. Almost 400 mayors have signed an agreement to cut their cities' emissions in line with Kyoto . Many businesses, even some power companies, would rather see regulation now than prolonged uncertainty. And several of the leading contenders for 2008's presidential election are much keener on emissions caps than Mr Bush. Change is in the air.", "hypothesis": "Texas and Michigan are among the 12 states which call for regulating air pollution.", "gold_label": "contradiction"}
{"uid": "id_378", "premise": "WHEN the subject is global warming, the villain is usually America . Although it produces a quarter of the greenhouse gases that are heating up the planet, it refuses to regulate them. When other countries agreed on an international treaty to do so he Kyoto protocolAmerica failed to ratify it. But not all American officialdom is happy with the federal government's stance. In fact,12 states disagree so fiercely that they are suing to force it to curb emissions of carbon dioxide, the most common greenhouse gas. The Supreme Court heard argument in the case on November 29th. The outcome will not be known for months, but the political wind seems to be shifting in favour of firmer action to counter climate change. The Clean Air Act charges the Environmental Protection Agency (EPA) with regulating air pollution from vehicles. But the EPA argues that Congress did not intend to include CO2 under that heading, and that to do so would extend the EPA's authority to an unreasonable extent. Furthermore, it contends that regulating emissions would not do good unless all or most other countries did the same. That is in keeping with the policies of President George Bush, who opposes mandatory curbs on emissions and believes that any international accord on global warming should apply to all countries unlike the Kyoto protocol, which exempts poor ones, including big polluters such as China and India . Ten states, among them gas-guzzling Texas and car-making Michigan, also back the EPA. The plaintiffs comprise 12 states, three cities, various NGOs, and American Samoa, a Pacific territory in danger of vanishing beneath the rising ocean. They are supported by a further six states, two power companies, a ski resort, and assorted clergymen, Indian tribes and agitated grandees such as Madeleine Albright, a former secretary of state. They point out that under the administration of Bill Clinton, the EPA decided that it did have the authority to regulate CO2. The act, they note, says the EPA should regulate any air pollutant that \"may reasonably be interpreted to endanger public health or welfare\". It goes on to define public welfare to include \"effects on soils, water, crops, vegetation, manmade materials, animals, wildlife, weather, visibility, and climate\". The Supreme Court may give a mixed ruling, decreeing that carbon dioxide is indeed a pollutant, but one the EPA is free to ignore or regulate as it pleases. Or it might dismiss the complaint on the grounds that the plaintiffs did not have the right to lodge it in the first place. In theory, they must prove that the EPA's foot-dragging has caused them some specific harm that regulation might remedy a tall order in a field as fraught with uncertainty as climatology. Even if the court found in the plaintiffs' favour, rapid change is unlikely. By the time the EPA had implemented such a ruling, Congress would probably have superseded it with a new law. That is the point, environmental groups say. They want Congress to pass a law tackling global warming, and hope that a favourable court ruling will jolly the politicians along. Moreover, the case has a bearing on several other bitterly-contested lawsuits. Carmakers, for example, are trying to get the courts to strike down a Californian state law based on certain provisions of the Clean Air Act that require them to reduce their vehicles' CO2 emissions. If the Supreme Court decides that the act does not apply to CO2, then the Californian law would also be in jeopardy. That, in turn, would scupper the decision of ten other states to adopt the same standard. However the Supreme Court rules, many state governments are determined to tackle climate change. California is in the vanguard. Its legislature has passed a law that will cap and then reduce industrial emissions of greenhouse gases. Seven eastern states have formed the Regional Greenhouse Gas Initiative, which will treat emissions from power plants the same way. Almost 400 mayors have signed an agreement to cut their cities' emissions in line with Kyoto . Many businesses, even some power companies, would rather see regulation now than prolonged uncertainty. And several of the leading contenders for 2008's presidential election are much keener on emissions caps than Mr Bush. Change is in the air.", "hypothesis": "The Supreme Court's ruling may influence the results of other lawsuits.", "gold_label": "entailment"}
{"uid": "id_379", "premise": "WHEN the subject is global warming, the villain is usually America . Although it produces a quarter of the greenhouse gases that are heating up the planet, it refuses to regulate them. When other countries agreed on an international treaty to do so he Kyoto protocolAmerica failed to ratify it. But not all American officialdom is happy with the federal government's stance. In fact,12 states disagree so fiercely that they are suing to force it to curb emissions of carbon dioxide, the most common greenhouse gas. The Supreme Court heard argument in the case on November 29th. The outcome will not be known for months, but the political wind seems to be shifting in favour of firmer action to counter climate change. The Clean Air Act charges the Environmental Protection Agency (EPA) with regulating air pollution from vehicles. But the EPA argues that Congress did not intend to include CO2 under that heading, and that to do so would extend the EPA's authority to an unreasonable extent. Furthermore, it contends that regulating emissions would not do good unless all or most other countries did the same. That is in keeping with the policies of President George Bush, who opposes mandatory curbs on emissions and believes that any international accord on global warming should apply to all countries unlike the Kyoto protocol, which exempts poor ones, including big polluters such as China and India . Ten states, among them gas-guzzling Texas and car-making Michigan, also back the EPA. The plaintiffs comprise 12 states, three cities, various NGOs, and American Samoa, a Pacific territory in danger of vanishing beneath the rising ocean. They are supported by a further six states, two power companies, a ski resort, and assorted clergymen, Indian tribes and agitated grandees such as Madeleine Albright, a former secretary of state. They point out that under the administration of Bill Clinton, the EPA decided that it did have the authority to regulate CO2. The act, they note, says the EPA should regulate any air pollutant that \"may reasonably be interpreted to endanger public health or welfare\". It goes on to define public welfare to include \"effects on soils, water, crops, vegetation, manmade materials, animals, wildlife, weather, visibility, and climate\". The Supreme Court may give a mixed ruling, decreeing that carbon dioxide is indeed a pollutant, but one the EPA is free to ignore or regulate as it pleases. Or it might dismiss the complaint on the grounds that the plaintiffs did not have the right to lodge it in the first place. In theory, they must prove that the EPA's foot-dragging has caused them some specific harm that regulation might remedy a tall order in a field as fraught with uncertainty as climatology. Even if the court found in the plaintiffs' favour, rapid change is unlikely. By the time the EPA had implemented such a ruling, Congress would probably have superseded it with a new law. That is the point, environmental groups say. They want Congress to pass a law tackling global warming, and hope that a favourable court ruling will jolly the politicians along. Moreover, the case has a bearing on several other bitterly-contested lawsuits. Carmakers, for example, are trying to get the courts to strike down a Californian state law based on certain provisions of the Clean Air Act that require them to reduce their vehicles' CO2 emissions. If the Supreme Court decides that the act does not apply to CO2, then the Californian law would also be in jeopardy. That, in turn, would scupper the decision of ten other states to adopt the same standard. However the Supreme Court rules, many state governments are determined to tackle climate change. California is in the vanguard. Its legislature has passed a law that will cap and then reduce industrial emissions of greenhouse gases. Seven eastern states have formed the Regional Greenhouse Gas Initiative, which will treat emissions from power plants the same way. Almost 400 mayors have signed an agreement to cut their cities' emissions in line with Kyoto . Many businesses, even some power companies, would rather see regulation now than prolonged uncertainty. And several of the leading contenders for 2008's presidential election are much keener on emissions caps than Mr Bush. Change is in the air.", "hypothesis": "The plaintiffs can prove that the EPA foot-dragging has caused them harm that the regulation might remedy.", "gold_label": "entailment"}
{"uid": "id_380", "premise": "Walking on water The availability of groundwater has always been taken for granted by Australians. Groundwater supplies have in prior times been perceived as a resource of infinite bounds the prevailing mindset was out of sight out of mind. This has all changed with the modern epoch. Persistent neglect has resulted in numerous complications for groundwater users and many interest groups have great stake in its management and allocation. Over-allocation of surface water and persistent water shortages mean that reliance of groundwater supplies is expected to swell. The main point of concern now is whether or not a groundwater source can deliver a sustainable yield. This relies on a proper management of discharge (outflow) and recharge (inflow) rates. Discharge occurs when humans extract water as well as through vegetation and evaporation into the atmosphere. Sustainable use therefore depends on more than keeping within the recharge rate: if humans use water at precisely the recharge rate, discharge through other ways can be adversely affected. Queensland has been one of the most active states in managing groundwater supplies. This is because the territory sits atop the Great Artesian Basin (GAB) an expansive underwater aquifer that covers nearly one-fifth of the Australian continent. This resource has long been used by indigenous people and outback communities, particularly in times of drought (when surface water could dry up for hundreds of kilometres on end). Since farmers at Kerribee pioneered the use of bores in the country, the number has spiralled beyond sustainable levels and caused water pressure and flow rates across the region to decline. Furthermore, estimates indicate that 80% of GAB outflow is wasted because of inefficient and out-dated delivery systems. Open drains used to keep livestock hydrated are a particular scourge much water is lost due to seepage and evaporation. A number of initiatives have been undertaken to help stem this problem. The Queensland government declared in 2005 a moratorium on issuing new licences for water extraction from GAB. A strategy group known as the Great Artesian Basin Consultative Council has also published a management plan that involved capping some bores (to prevent further declines in pressure) and rehabilitating hundreds of other bores and bore drains with troughs and polyester piping (to prevent water seeping into the earth). It is now also apparent that corruption of groundwater supplies by humans is going to be an issue to contend with. In 2006, thousands of Sydney residents had their groundwater usage curtailed due to industrial pollution of the Botany Stands aquifer. Bore water for any domestic purposes has since been off limits due to chemical seepage from an estimated 8 industrial sites. Nevertheless, groundwater plans continue apace. Development of a controversial desalination plant has been postponed indefinitely while the feasibility of exploiting two aquifers near Sydney is explored. Authorities intend to use the aquifers to provide up to 30 gigalitres of water a year during dry spells and then leave them alone to replenish during higher rainfall years. But the proposed scheme it riddled with difficulties: low flow rates are hampering extraction: replenishment rates are lower than expected, and salinity imbalances caused by the procedure could wreak havoc on efforts to preserve wetland flora and fauna ecosystems that rely on a plentiful, clean and steady supply of water from the aquifers. It is not too late to turn groundwater into a sustainable resource. Groundwater is renewable through surface run off (and, a much slower rate, in organic springs where it is literally drip fed through rock on its way to aquifers). At present however, experts believe excessive amounts of groundwater are being squandered on aesthetic projects such as keeping parks, gardens and golf courses green. Aside from more judicious use of groundwater, many experts also believe that we need to look at harnessing other potential sources in order to meet our water needs. During rainy seasons for example urban areas are inundated with storm water and flash flooding that can bring cities to a standstill. Better storm water control mechanisms could potentially capture and preserve this rainwater for use at a later date.", "hypothesis": "Australians have always seen groundwater as a precious resource.", "gold_label": "contradiction"}
{"uid": "id_381", "premise": "Walking on water The availability of groundwater has always been taken for granted by Australians. Groundwater supplies have in prior times been perceived as a resource of infinite bounds the prevailing mindset was out of sight out of mind. This has all changed with the modern epoch. Persistent neglect has resulted in numerous complications for groundwater users and many interest groups have great stake in its management and allocation. Over-allocation of surface water and persistent water shortages mean that reliance of groundwater supplies is expected to swell. The main point of concern now is whether or not a groundwater source can deliver a sustainable yield. This relies on a proper management of discharge (outflow) and recharge (inflow) rates. Discharge occurs when humans extract water as well as through vegetation and evaporation into the atmosphere. Sustainable use therefore depends on more than keeping within the recharge rate: if humans use water at precisely the recharge rate, discharge through other ways can be adversely affected. Queensland has been one of the most active states in managing groundwater supplies. This is because the territory sits atop the Great Artesian Basin (GAB) an expansive underwater aquifer that covers nearly one-fifth of the Australian continent. This resource has long been used by indigenous people and outback communities, particularly in times of drought (when surface water could dry up for hundreds of kilometres on end). Since farmers at Kerribee pioneered the use of bores in the country, the number has spiralled beyond sustainable levels and caused water pressure and flow rates across the region to decline. Furthermore, estimates indicate that 80% of GAB outflow is wasted because of inefficient and out-dated delivery systems. Open drains used to keep livestock hydrated are a particular scourge much water is lost due to seepage and evaporation. A number of initiatives have been undertaken to help stem this problem. The Queensland government declared in 2005 a moratorium on issuing new licences for water extraction from GAB. A strategy group known as the Great Artesian Basin Consultative Council has also published a management plan that involved capping some bores (to prevent further declines in pressure) and rehabilitating hundreds of other bores and bore drains with troughs and polyester piping (to prevent water seeping into the earth). It is now also apparent that corruption of groundwater supplies by humans is going to be an issue to contend with. In 2006, thousands of Sydney residents had their groundwater usage curtailed due to industrial pollution of the Botany Stands aquifer. Bore water for any domestic purposes has since been off limits due to chemical seepage from an estimated 8 industrial sites. Nevertheless, groundwater plans continue apace. Development of a controversial desalination plant has been postponed indefinitely while the feasibility of exploiting two aquifers near Sydney is explored. Authorities intend to use the aquifers to provide up to 30 gigalitres of water a year during dry spells and then leave them alone to replenish during higher rainfall years. But the proposed scheme it riddled with difficulties: low flow rates are hampering extraction: replenishment rates are lower than expected, and salinity imbalances caused by the procedure could wreak havoc on efforts to preserve wetland flora and fauna ecosystems that rely on a plentiful, clean and steady supply of water from the aquifers. It is not too late to turn groundwater into a sustainable resource. Groundwater is renewable through surface run off (and, a much slower rate, in organic springs where it is literally drip fed through rock on its way to aquifers). At present however, experts believe excessive amounts of groundwater are being squandered on aesthetic projects such as keeping parks, gardens and golf courses green. Aside from more judicious use of groundwater, many experts also believe that we need to look at harnessing other potential sources in order to meet our water needs. During rainy seasons for example urban areas are inundated with storm water and flash flooding that can bring cities to a standstill. Better storm water control mechanisms could potentially capture and preserve this rainwater for use at a later date.", "hypothesis": "Using water at the recharge rate or lower will ensure sustainable use.", "gold_label": "contradiction"}
{"uid": "id_382", "premise": "Walking on water The availability of groundwater has always been taken for granted by Australians. Groundwater supplies have in prior times been perceived as a resource of infinite bounds the prevailing mindset was out of sight out of mind. This has all changed with the modern epoch. Persistent neglect has resulted in numerous complications for groundwater users and many interest groups have great stake in its management and allocation. Over-allocation of surface water and persistent water shortages mean that reliance of groundwater supplies is expected to swell. The main point of concern now is whether or not a groundwater source can deliver a sustainable yield. This relies on a proper management of discharge (outflow) and recharge (inflow) rates. Discharge occurs when humans extract water as well as through vegetation and evaporation into the atmosphere. Sustainable use therefore depends on more than keeping within the recharge rate: if humans use water at precisely the recharge rate, discharge through other ways can be adversely affected. Queensland has been one of the most active states in managing groundwater supplies. This is because the territory sits atop the Great Artesian Basin (GAB) an expansive underwater aquifer that covers nearly one-fifth of the Australian continent. This resource has long been used by indigenous people and outback communities, particularly in times of drought (when surface water could dry up for hundreds of kilometres on end). Since farmers at Kerribee pioneered the use of bores in the country, the number has spiralled beyond sustainable levels and caused water pressure and flow rates across the region to decline. Furthermore, estimates indicate that 80% of GAB outflow is wasted because of inefficient and out-dated delivery systems. Open drains used to keep livestock hydrated are a particular scourge much water is lost due to seepage and evaporation. A number of initiatives have been undertaken to help stem this problem. The Queensland government declared in 2005 a moratorium on issuing new licences for water extraction from GAB. A strategy group known as the Great Artesian Basin Consultative Council has also published a management plan that involved capping some bores (to prevent further declines in pressure) and rehabilitating hundreds of other bores and bore drains with troughs and polyester piping (to prevent water seeping into the earth). It is now also apparent that corruption of groundwater supplies by humans is going to be an issue to contend with. In 2006, thousands of Sydney residents had their groundwater usage curtailed due to industrial pollution of the Botany Stands aquifer. Bore water for any domestic purposes has since been off limits due to chemical seepage from an estimated 8 industrial sites. Nevertheless, groundwater plans continue apace. Development of a controversial desalination plant has been postponed indefinitely while the feasibility of exploiting two aquifers near Sydney is explored. Authorities intend to use the aquifers to provide up to 30 gigalitres of water a year during dry spells and then leave them alone to replenish during higher rainfall years. But the proposed scheme it riddled with difficulties: low flow rates are hampering extraction: replenishment rates are lower than expected, and salinity imbalances caused by the procedure could wreak havoc on efforts to preserve wetland flora and fauna ecosystems that rely on a plentiful, clean and steady supply of water from the aquifers. It is not too late to turn groundwater into a sustainable resource. Groundwater is renewable through surface run off (and, a much slower rate, in organic springs where it is literally drip fed through rock on its way to aquifers). At present however, experts believe excessive amounts of groundwater are being squandered on aesthetic projects such as keeping parks, gardens and golf courses green. Aside from more judicious use of groundwater, many experts also believe that we need to look at harnessing other potential sources in order to meet our water needs. During rainy seasons for example urban areas are inundated with storm water and flash flooding that can bring cities to a standstill. Better storm water control mechanisms could potentially capture and preserve this rainwater for use at a later date.", "hypothesis": "Use of groundwater is predicted to increase.", "gold_label": "entailment"}
{"uid": "id_383", "premise": "Walking on water The availability of groundwater has always been taken for granted by Australians. Groundwater supplies have in prior times been perceived as a resource of infinite bounds the prevailing mindset was out of sight out of mind. This has all changed with the modern epoch. Persistent neglect has resulted in numerous complications for groundwater users and many interest groups have great stake in its management and allocation. Over-allocation of surface water and persistent water shortages mean that reliance of groundwater supplies is expected to swell. The main point of concern now is whether or not a groundwater source can deliver a sustainable yield. This relies on a proper management of discharge (outflow) and recharge (inflow) rates. Discharge occurs when humans extract water as well as through vegetation and evaporation into the atmosphere. Sustainable use therefore depends on more than keeping within the recharge rate: if humans use water at precisely the recharge rate, discharge through other ways can be adversely affected. Queensland has been one of the most active states in managing groundwater supplies. This is because the territory sits atop the Great Artesian Basin (GAB) an expansive underwater aquifer that covers nearly one-fifth of the Australian continent. This resource has long been used by indigenous people and outback communities, particularly in times of drought (when surface water could dry up for hundreds of kilometres on end). Since farmers at Kerribee pioneered the use of bores in the country, the number has spiralled beyond sustainable levels and caused water pressure and flow rates across the region to decline. Furthermore, estimates indicate that 80% of GAB outflow is wasted because of inefficient and out-dated delivery systems. Open drains used to keep livestock hydrated are a particular scourge much water is lost due to seepage and evaporation. A number of initiatives have been undertaken to help stem this problem. The Queensland government declared in 2005 a moratorium on issuing new licences for water extraction from GAB. A strategy group known as the Great Artesian Basin Consultative Council has also published a management plan that involved capping some bores (to prevent further declines in pressure) and rehabilitating hundreds of other bores and bore drains with troughs and polyester piping (to prevent water seeping into the earth). It is now also apparent that corruption of groundwater supplies by humans is going to be an issue to contend with. In 2006, thousands of Sydney residents had their groundwater usage curtailed due to industrial pollution of the Botany Stands aquifer. Bore water for any domestic purposes has since been off limits due to chemical seepage from an estimated 8 industrial sites. Nevertheless, groundwater plans continue apace. Development of a controversial desalination plant has been postponed indefinitely while the feasibility of exploiting two aquifers near Sydney is explored. Authorities intend to use the aquifers to provide up to 30 gigalitres of water a year during dry spells and then leave them alone to replenish during higher rainfall years. But the proposed scheme it riddled with difficulties: low flow rates are hampering extraction: replenishment rates are lower than expected, and salinity imbalances caused by the procedure could wreak havoc on efforts to preserve wetland flora and fauna ecosystems that rely on a plentiful, clean and steady supply of water from the aquifers. It is not too late to turn groundwater into a sustainable resource. Groundwater is renewable through surface run off (and, a much slower rate, in organic springs where it is literally drip fed through rock on its way to aquifers). At present however, experts believe excessive amounts of groundwater are being squandered on aesthetic projects such as keeping parks, gardens and golf courses green. Aside from more judicious use of groundwater, many experts also believe that we need to look at harnessing other potential sources in order to meet our water needs. During rainy seasons for example urban areas are inundated with storm water and flash flooding that can bring cities to a standstill. Better storm water control mechanisms could potentially capture and preserve this rainwater for use at a later date.", "hypothesis": "Humans cannot alter the recharge rate of groundwater.", "gold_label": "neutral"}
{"uid": "id_384", "premise": "Walking with dinosaurs Peter L. Falkingham and his colleagues at Manchester University are developing techniques which look set to revolutionize our understanding of how dinosaurs and other extinct animals behaved. The media image of palaeontologists who study prehistoric life is often of field workers camped in the desert in the hot sun, carefully picking away at the rock surrounding a large dinosaur bone. But Peter Falkingham has done little of that for a while now. Instead, he devotes himself to his computer. Not because he has become inundated with paperwork, but because he is a new kind of palaeontologist: a computational palaeontologist. What few people may consider is that uncovering a skeleton, or discovering a new species, is where the research begins, not where it ends. What we really want to understand is how the extinct animals and plants behaved in their natural habitats. Drs Bill Sellers and Phil Manning from the University of Manchester use a genetic algorithm a kind of computer code that can change itself and evolve to explore how extinct animals like dinosaurs, and our own early ancestors, walked and stalked. The fossilized bones of a complete dinosaur skeleton can tell scientists a lot about the animal, but they do not make up the complete picture and the computer can try to fill the gap. The computer model is given a digitized skeleton, and the locations of known muscles. The model then randomly activates the muscles. This, perhaps unsurprisingly, results almost without fail in the animal falling on its face. So the computer alters the activation pattern and tries again ... usually to similar effect. The modeled dinosaurs quickly evolve. If there is any improvement, the computer discards the old pattern and adopts the new one as the base for alteration. Eventually, the muscle activation pattern evolves a stable way of moving, the best possible solution is reached, and the dinosaur can walk, run, chase or graze. Assuming natural selection evolves the best possible solution too, the modeled animal should be moving in a manner similar to its now-extinct counterpart. And indeed, using the same method for living animals (humans, emu and ostriches) similar top speeds were achieved on the computer as in reality. By comparing their cyberspace results with real measurements of living species, the Manchester team of palaeontologists can be confident in the results computed showing how extinct prehistoric animals such as dinosaurs moved. The Manchester University team have used the computer simulations to produce a model of a giant meat-eating dinosaur. lt is called an acrocanthosaurus which literally means high spined lizard because of the spines which run along its backbone. It is not really known why they are there but scientists have speculated they could have supported a hump that stored fat and water reserves. There are also those who believe that the spines acted as a support for a sail. Of these, one half think it was used as a display and could be flushed with blood and the other half think it was used as a temperature-regulating device. It may have been a mixture of the two. The skull seems out of proportion with its thick, heavy body because it is so narrow and the jaws are delicate and fine. The feet are also worthy of note as they look surprisingly small in contrast to the animal as a whole. It has a deep broad tail and powerful leg muscles to aid locomotion. It walked on its back legs and its front legs were much shorter with powerful claws. Falkingham himself is investigating fossilized tracks, or footprints, using computer simulations to help analyze how extinct animals moved. Modern-day trackers who study the habitats of wild animals can tell you what animal made a track, whether that animal was walking or running, sometimes even the sex of the animal. But a fossil track poses a more considerable challenge to interpret in the same way. A crucial consideration is knowing what the environment including the mud, or sediment, upon which the animal walked was like millions of years ago when the track was made. Experiments can answer these questions but the number of variables is staggering. To physically recreate each scenario with a box of mud is extremely time-consuming and difficult to repeat accurately. This is where computer simulation comes in. Falkingham uses computational techniques to model a volume of mud and control the moisture content, consistency, and other conditions to simulate the mud of prehistoric times. A footprint is then made in the digital mud by a virtual foot. This footprint can be chopped up and viewed from any angle and stress values can be extracted and calculated from inside it. By running hundreds of these simulations simultaneously on supercomputers, Falkingham can start to understand what types of footprint would be expected if an animal moved in a certain way over a given kind of ground. Looking at the variation in the virtual tracks, researchers can make sense of fossil tracks with greater confidence. The application of computational techniques in palaeontology is becoming more prevalent every year. As computer power continues to increase, the range of problems that can be tackled and questions that can be answered will only expand.", "hypothesis": "Research carried out into the composition of prehistoric mud has been found to be inaccurate.", "gold_label": "neutral"}
{"uid": "id_385", "premise": "Walking with dinosaurs Peter L. Falkingham and his colleagues at Manchester University are developing techniques which look set to revolutionize our understanding of how dinosaurs and other extinct animals behaved. The media image of palaeontologists who study prehistoric life is often of field workers camped in the desert in the hot sun, carefully picking away at the rock surrounding a large dinosaur bone. But Peter Falkingham has done little of that for a while now. Instead, he devotes himself to his computer. Not because he has become inundated with paperwork, but because he is a new kind of palaeontologist: a computational palaeontologist. What few people may consider is that uncovering a skeleton, or discovering a new species, is where the research begins, not where it ends. What we really want to understand is how the extinct animals and plants behaved in their natural habitats. Drs Bill Sellers and Phil Manning from the University of Manchester use a genetic algorithm a kind of computer code that can change itself and evolve to explore how extinct animals like dinosaurs, and our own early ancestors, walked and stalked. The fossilized bones of a complete dinosaur skeleton can tell scientists a lot about the animal, but they do not make up the complete picture and the computer can try to fill the gap. The computer model is given a digitized skeleton, and the locations of known muscles. The model then randomly activates the muscles. This, perhaps unsurprisingly, results almost without fail in the animal falling on its face. So the computer alters the activation pattern and tries again ... usually to similar effect. The modeled dinosaurs quickly evolve. If there is any improvement, the computer discards the old pattern and adopts the new one as the base for alteration. Eventually, the muscle activation pattern evolves a stable way of moving, the best possible solution is reached, and the dinosaur can walk, run, chase or graze. Assuming natural selection evolves the best possible solution too, the modeled animal should be moving in a manner similar to its now-extinct counterpart. And indeed, using the same method for living animals (humans, emu and ostriches) similar top speeds were achieved on the computer as in reality. By comparing their cyberspace results with real measurements of living species, the Manchester team of palaeontologists can be confident in the results computed showing how extinct prehistoric animals such as dinosaurs moved. The Manchester University team have used the computer simulations to produce a model of a giant meat-eating dinosaur. lt is called an acrocanthosaurus which literally means high spined lizard because of the spines which run along its backbone. It is not really known why they are there but scientists have speculated they could have supported a hump that stored fat and water reserves. There are also those who believe that the spines acted as a support for a sail. Of these, one half think it was used as a display and could be flushed with blood and the other half think it was used as a temperature-regulating device. It may have been a mixture of the two. The skull seems out of proportion with its thick, heavy body because it is so narrow and the jaws are delicate and fine. The feet are also worthy of note as they look surprisingly small in contrast to the animal as a whole. It has a deep broad tail and powerful leg muscles to aid locomotion. It walked on its back legs and its front legs were much shorter with powerful claws. Falkingham himself is investigating fossilized tracks, or footprints, using computer simulations to help analyze how extinct animals moved. Modern-day trackers who study the habitats of wild animals can tell you what animal made a track, whether that animal was walking or running, sometimes even the sex of the animal. But a fossil track poses a more considerable challenge to interpret in the same way. A crucial consideration is knowing what the environment including the mud, or sediment, upon which the animal walked was like millions of years ago when the track was made. Experiments can answer these questions but the number of variables is staggering. To physically recreate each scenario with a box of mud is extremely time-consuming and difficult to repeat accurately. This is where computer simulation comes in. Falkingham uses computational techniques to model a volume of mud and control the moisture content, consistency, and other conditions to simulate the mud of prehistoric times. A footprint is then made in the digital mud by a virtual foot. This footprint can be chopped up and viewed from any angle and stress values can be extracted and calculated from inside it. By running hundreds of these simulations simultaneously on supercomputers, Falkingham can start to understand what types of footprint would be expected if an animal moved in a certain way over a given kind of ground. Looking at the variation in the virtual tracks, researchers can make sense of fossil tracks with greater confidence. The application of computational techniques in palaeontology is becoming more prevalent every year. As computer power continues to increase, the range of problems that can be tackled and questions that can be answered will only expand.", "hypothesis": "When the Sellers and Manning computer model was used for people, it showed them moving faster than they are physically able to.", "gold_label": "contradiction"}
{"uid": "id_386", "premise": "Walking with dinosaurs Peter L. Falkingham and his colleagues at Manchester University are developing techniques which look set to revolutionize our understanding of how dinosaurs and other extinct animals behaved. The media image of palaeontologists who study prehistoric life is often of field workers camped in the desert in the hot sun, carefully picking away at the rock surrounding a large dinosaur bone. But Peter Falkingham has done little of that for a while now. Instead, he devotes himself to his computer. Not because he has become inundated with paperwork, but because he is a new kind of palaeontologist: a computational palaeontologist. What few people may consider is that uncovering a skeleton, or discovering a new species, is where the research begins, not where it ends. What we really want to understand is how the extinct animals and plants behaved in their natural habitats. Drs Bill Sellers and Phil Manning from the University of Manchester use a genetic algorithm a kind of computer code that can change itself and evolve to explore how extinct animals like dinosaurs, and our own early ancestors, walked and stalked. The fossilized bones of a complete dinosaur skeleton can tell scientists a lot about the animal, but they do not make up the complete picture and the computer can try to fill the gap. The computer model is given a digitized skeleton, and the locations of known muscles. The model then randomly activates the muscles. This, perhaps unsurprisingly, results almost without fail in the animal falling on its face. So the computer alters the activation pattern and tries again ... usually to similar effect. The modeled dinosaurs quickly evolve. If there is any improvement, the computer discards the old pattern and adopts the new one as the base for alteration. Eventually, the muscle activation pattern evolves a stable way of moving, the best possible solution is reached, and the dinosaur can walk, run, chase or graze. Assuming natural selection evolves the best possible solution too, the modeled animal should be moving in a manner similar to its now-extinct counterpart. And indeed, using the same method for living animals (humans, emu and ostriches) similar top speeds were achieved on the computer as in reality. By comparing their cyberspace results with real measurements of living species, the Manchester team of palaeontologists can be confident in the results computed showing how extinct prehistoric animals such as dinosaurs moved. The Manchester University team have used the computer simulations to produce a model of a giant meat-eating dinosaur. lt is called an acrocanthosaurus which literally means high spined lizard because of the spines which run along its backbone. It is not really known why they are there but scientists have speculated they could have supported a hump that stored fat and water reserves. There are also those who believe that the spines acted as a support for a sail. Of these, one half think it was used as a display and could be flushed with blood and the other half think it was used as a temperature-regulating device. It may have been a mixture of the two. The skull seems out of proportion with its thick, heavy body because it is so narrow and the jaws are delicate and fine. The feet are also worthy of note as they look surprisingly small in contrast to the animal as a whole. It has a deep broad tail and powerful leg muscles to aid locomotion. It walked on its back legs and its front legs were much shorter with powerful claws. Falkingham himself is investigating fossilized tracks, or footprints, using computer simulations to help analyze how extinct animals moved. Modern-day trackers who study the habitats of wild animals can tell you what animal made a track, whether that animal was walking or running, sometimes even the sex of the animal. But a fossil track poses a more considerable challenge to interpret in the same way. A crucial consideration is knowing what the environment including the mud, or sediment, upon which the animal walked was like millions of years ago when the track was made. Experiments can answer these questions but the number of variables is staggering. To physically recreate each scenario with a box of mud is extremely time-consuming and difficult to repeat accurately. This is where computer simulation comes in. Falkingham uses computational techniques to model a volume of mud and control the moisture content, consistency, and other conditions to simulate the mud of prehistoric times. A footprint is then made in the digital mud by a virtual foot. This footprint can be chopped up and viewed from any angle and stress values can be extracted and calculated from inside it. By running hundreds of these simulations simultaneously on supercomputers, Falkingham can start to understand what types of footprint would be expected if an animal moved in a certain way over a given kind of ground. Looking at the variation in the virtual tracks, researchers can make sense of fossil tracks with greater confidence. The application of computational techniques in palaeontology is becoming more prevalent every year. As computer power continues to increase, the range of problems that can be tackled and questions that can be answered will only expand.", "hypothesis": "Some palaeontologists have expressed reservations about the conclusions reached by the Manchester team concerning the movement of dinosaurs.", "gold_label": "neutral"}
{"uid": "id_387", "premise": "Walking with dinosaurs Peter L. Falkingham and his colleagues at Manchester University are developing techniques which look set to revolutionize our understanding of how dinosaurs and other extinct animals behaved. The media image of palaeontologists who study prehistoric life is often of field workers camped in the desert in the hot sun, carefully picking away at the rock surrounding a large dinosaur bone. But Peter Falkingham has done little of that for a while now. Instead, he devotes himself to his computer. Not because he has become inundated with paperwork, but because he is a new kind of palaeontologist: a computational palaeontologist. What few people may consider is that uncovering a skeleton, or discovering a new species, is where the research begins, not where it ends. What we really want to understand is how the extinct animals and plants behaved in their natural habitats. Drs Bill Sellers and Phil Manning from the University of Manchester use a genetic algorithm a kind of computer code that can change itself and evolve to explore how extinct animals like dinosaurs, and our own early ancestors, walked and stalked. The fossilized bones of a complete dinosaur skeleton can tell scientists a lot about the animal, but they do not make up the complete picture and the computer can try to fill the gap. The computer model is given a digitized skeleton, and the locations of known muscles. The model then randomly activates the muscles. This, perhaps unsurprisingly, results almost without fail in the animal falling on its face. So the computer alters the activation pattern and tries again ... usually to similar effect. The modeled dinosaurs quickly evolve. If there is any improvement, the computer discards the old pattern and adopts the new one as the base for alteration. Eventually, the muscle activation pattern evolves a stable way of moving, the best possible solution is reached, and the dinosaur can walk, run, chase or graze. Assuming natural selection evolves the best possible solution too, the modeled animal should be moving in a manner similar to its now-extinct counterpart. And indeed, using the same method for living animals (humans, emu and ostriches) similar top speeds were achieved on the computer as in reality. By comparing their cyberspace results with real measurements of living species, the Manchester team of palaeontologists can be confident in the results computed showing how extinct prehistoric animals such as dinosaurs moved. The Manchester University team have used the computer simulations to produce a model of a giant meat-eating dinosaur. lt is called an acrocanthosaurus which literally means high spined lizard because of the spines which run along its backbone. It is not really known why they are there but scientists have speculated they could have supported a hump that stored fat and water reserves. There are also those who believe that the spines acted as a support for a sail. Of these, one half think it was used as a display and could be flushed with blood and the other half think it was used as a temperature-regulating device. It may have been a mixture of the two. The skull seems out of proportion with its thick, heavy body because it is so narrow and the jaws are delicate and fine. The feet are also worthy of note as they look surprisingly small in contrast to the animal as a whole. It has a deep broad tail and powerful leg muscles to aid locomotion. It walked on its back legs and its front legs were much shorter with powerful claws. Falkingham himself is investigating fossilized tracks, or footprints, using computer simulations to help analyze how extinct animals moved. Modern-day trackers who study the habitats of wild animals can tell you what animal made a track, whether that animal was walking or running, sometimes even the sex of the animal. But a fossil track poses a more considerable challenge to interpret in the same way. A crucial consideration is knowing what the environment including the mud, or sediment, upon which the animal walked was like millions of years ago when the track was made. Experiments can answer these questions but the number of variables is staggering. To physically recreate each scenario with a box of mud is extremely time-consuming and difficult to repeat accurately. This is where computer simulation comes in. Falkingham uses computational techniques to model a volume of mud and control the moisture content, consistency, and other conditions to simulate the mud of prehistoric times. A footprint is then made in the digital mud by a virtual foot. This footprint can be chopped up and viewed from any angle and stress values can be extracted and calculated from inside it. By running hundreds of these simulations simultaneously on supercomputers, Falkingham can start to understand what types of footprint would be expected if an animal moved in a certain way over a given kind of ground. Looking at the variation in the virtual tracks, researchers can make sense of fossil tracks with greater confidence. The application of computational techniques in palaeontology is becoming more prevalent every year. As computer power continues to increase, the range of problems that can be tackled and questions that can be answered will only expand.", "hypothesis": "An experienced tracker can analyse fossil footprints as easily as those made by live animals.", "gold_label": "contradiction"}
{"uid": "id_388", "premise": "Walking with dinosaurs Peter L. Falkingham and his colleagues at Manchester University are developing techniques which look set to revolutionize our understanding of how dinosaurs and other extinct animals behaved. The media image of palaeontologists who study prehistoric life is often of field workers camped in the desert in the hot sun, carefully picking away at the rock surrounding a large dinosaur bone. But Peter Falkingham has done little of that for a while now. Instead, he devotes himself to his computer. Not because he has become inundated with paperwork, but because he is a new kind of palaeontologist: a computational palaeontologist. What few people may consider is that uncovering a skeleton, or discovering a new species, is where the research begins, not where it ends. What we really want to understand is how the extinct animals and plants behaved in their natural habitats. Drs Bill Sellers and Phil Manning from the University of Manchester use a genetic algorithm a kind of computer code that can change itself and evolve to explore how extinct animals like dinosaurs, and our own early ancestors, walked and stalked. The fossilized bones of a complete dinosaur skeleton can tell scientists a lot about the animal, but they do not make up the complete picture and the computer can try to fill the gap. The computer model is given a digitized skeleton, and the locations of known muscles. The model then randomly activates the muscles. This, perhaps unsurprisingly, results almost without fail in the animal falling on its face. So the computer alters the activation pattern and tries again ... usually to similar effect. The modeled dinosaurs quickly evolve. If there is any improvement, the computer discards the old pattern and adopts the new one as the base for alteration. Eventually, the muscle activation pattern evolves a stable way of moving, the best possible solution is reached, and the dinosaur can walk, run, chase or graze. Assuming natural selection evolves the best possible solution too, the modeled animal should be moving in a manner similar to its now-extinct counterpart. And indeed, using the same method for living animals (humans, emu and ostriches) similar top speeds were achieved on the computer as in reality. By comparing their cyberspace results with real measurements of living species, the Manchester team of palaeontologists can be confident in the results computed showing how extinct prehistoric animals such as dinosaurs moved. The Manchester University team have used the computer simulations to produce a model of a giant meat-eating dinosaur. lt is called an acrocanthosaurus which literally means high spined lizard because of the spines which run along its backbone. It is not really known why they are there but scientists have speculated they could have supported a hump that stored fat and water reserves. There are also those who believe that the spines acted as a support for a sail. Of these, one half think it was used as a display and could be flushed with blood and the other half think it was used as a temperature-regulating device. It may have been a mixture of the two. The skull seems out of proportion with its thick, heavy body because it is so narrow and the jaws are delicate and fine. The feet are also worthy of note as they look surprisingly small in contrast to the animal as a whole. It has a deep broad tail and powerful leg muscles to aid locomotion. It walked on its back legs and its front legs were much shorter with powerful claws. Falkingham himself is investigating fossilized tracks, or footprints, using computer simulations to help analyze how extinct animals moved. Modern-day trackers who study the habitats of wild animals can tell you what animal made a track, whether that animal was walking or running, sometimes even the sex of the animal. But a fossil track poses a more considerable challenge to interpret in the same way. A crucial consideration is knowing what the environment including the mud, or sediment, upon which the animal walked was like millions of years ago when the track was made. Experiments can answer these questions but the number of variables is staggering. To physically recreate each scenario with a box of mud is extremely time-consuming and difficult to repeat accurately. This is where computer simulation comes in. Falkingham uses computational techniques to model a volume of mud and control the moisture content, consistency, and other conditions to simulate the mud of prehistoric times. A footprint is then made in the digital mud by a virtual foot. This footprint can be chopped up and viewed from any angle and stress values can be extracted and calculated from inside it. By running hundreds of these simulations simultaneously on supercomputers, Falkingham can start to understand what types of footprint would be expected if an animal moved in a certain way over a given kind of ground. Looking at the variation in the virtual tracks, researchers can make sense of fossil tracks with greater confidence. The application of computational techniques in palaeontology is becoming more prevalent every year. As computer power continues to increase, the range of problems that can be tackled and questions that can be answered will only expand.", "hypothesis": "In his study of prehistoric life, Peter Falkinghom rarely spends time on outdoor research.", "gold_label": "entailment"}
{"uid": "id_389", "premise": "Walking with dinosaurs Peter L. Falkingham and his colleagues at Manchester University are developing techniques which look set to revolutionize our understanding of how dinosaurs and other extinct animals behaved. The media image of palaeontologists who study prehistoric life is often of field workers camped in the desert in the hot sun, carefully picking away at the rock surrounding a large dinosaur bone. But Peter Falkingham has done little of that for a while now. Instead, he devotes himself to his computer. Not because he has become inundated with paperwork, but because he is a new kind of palaeontologist: a computational palaeontologist. What few people may consider is that uncovering a skeleton, or discovering a new species, is where the research begins, not where it ends. What we really want to understand is how the extinct animals and plants behaved in their natural habitats. Drs Bill Sellers and Phil Manning from the University of Manchester use a genetic algorithm a kind of computer code that can change itself and evolve to explore how extinct animals like dinosaurs, and our own early ancestors, walked and stalked. The fossilized bones of a complete dinosaur skeleton can tell scientists a lot about the animal, but they do not make up the complete picture and the computer can try to fill the gap. The computer model is given a digitized skeleton, and the locations of known muscles. The model then randomly activates the muscles. This, perhaps unsurprisingly, results almost without fail in the animal falling on its face. So the computer alters the activation pattern and tries again ... usually to similar effect. The modeled dinosaurs quickly evolve. If there is any improvement, the computer discards the old pattern and adopts the new one as the base for alteration. Eventually, the muscle activation pattern evolves a stable way of moving, the best possible solution is reached, and the dinosaur can walk, run, chase or graze. Assuming natural selection evolves the best possible solution too, the modeled animal should be moving in a manner similar to its now-extinct counterpart. And indeed, using the same method for living animals (humans, emu and ostriches) similar top speeds were achieved on the computer as in reality. By comparing their cyberspace results with real measurements of living species, the Manchester team of palaeontologists can be confident in the results computed showing how extinct prehistoric animals such as dinosaurs moved. The Manchester University team have used the computer simulations to produce a model of a giant meat-eating dinosaur. lt is called an acrocanthosaurus which literally means high spined lizard because of the spines which run along its backbone. It is not really known why they are there but scientists have speculated they could have supported a hump that stored fat and water reserves. There are also those who believe that the spines acted as a support for a sail. Of these, one half think it was used as a display and could be flushed with blood and the other half think it was used as a temperature-regulating device. It may have been a mixture of the two. The skull seems out of proportion with its thick, heavy body because it is so narrow and the jaws are delicate and fine. The feet are also worthy of note as they look surprisingly small in contrast to the animal as a whole. It has a deep broad tail and powerful leg muscles to aid locomotion. It walked on its back legs and its front legs were much shorter with powerful claws. Falkingham himself is investigating fossilized tracks, or footprints, using computer simulations to help analyze how extinct animals moved. Modern-day trackers who study the habitats of wild animals can tell you what animal made a track, whether that animal was walking or running, sometimes even the sex of the animal. But a fossil track poses a more considerable challenge to interpret in the same way. A crucial consideration is knowing what the environment including the mud, or sediment, upon which the animal walked was like millions of years ago when the track was made. Experiments can answer these questions but the number of variables is staggering. To physically recreate each scenario with a box of mud is extremely time-consuming and difficult to repeat accurately. This is where computer simulation comes in. Falkingham uses computational techniques to model a volume of mud and control the moisture content, consistency, and other conditions to simulate the mud of prehistoric times. A footprint is then made in the digital mud by a virtual foot. This footprint can be chopped up and viewed from any angle and stress values can be extracted and calculated from inside it. By running hundreds of these simulations simultaneously on supercomputers, Falkingham can start to understand what types of footprint would be expected if an animal moved in a certain way over a given kind of ground. Looking at the variation in the virtual tracks, researchers can make sense of fossil tracks with greater confidence. The application of computational techniques in palaeontology is becoming more prevalent every year. As computer power continues to increase, the range of problems that can be tackled and questions that can be answered will only expand.", "hypothesis": "Several attempts are usually needed before the computer model of a dinosaur used by Sellers and Manning manages to stay upright.", "gold_label": "entailment"}
{"uid": "id_390", "premise": "Walnuts cost more than peanuts. Walnuts cost less than pistachios.", "hypothesis": "Pistachios cost more than both peanuts and walnuts.", "gold_label": "entailment"}
{"uid": "id_391", "premise": "Water Filter. An ingenious invention is set to bring clean water to the third world, and while the science may be cutting edge, the materials are extremely down to earth. A handful of clay yesterdays coffee grounds and some cow manure are the ingredients that could bring clean, safe drinking water to much of the third world. B. The simple new technology, developed by ANU materials scientist Mr. Tony Flynn, allows water filters to be made from commonly available materials and fired on the ground using cow manure as the source of heat, without the need for a kiln. The filters have been tested and shown to remove common pathogens (disease-producing organisms) including E-coli. Unlike other water filtering devices, the filters are simple and inexpensive to make. They are very simple to explain and demonstrate and can be made by anyone, anywhere, says Mr. Flynn. They dont require any western technology. All you need is terracotta clay, a compliant cow and a match. C. The production of the filters is extremely simple. Take a handful of dry, crushed clay, mix it with a handful of organic material, such as used tea leaves, coffee grounds or rice hulls, add enough water to make a stiff biscuit-like mixture and form a cylindrical pot that has one end closed, then dry it in the sun. According to Mr. Flynn, used coffee grounds have given the best results to date. Next, surround the pots with straw; put them in a mound of cow manure, light the straw and then top up the burning manure as required. In less than 60 minutes the filters are finished. The walls of the finished pot should be about as thick as an adults index. The properties of cow manure are vital as the fuel can reach a temperature of 700 degrees in half an hour and will be up to 950 degrees after another 20 to 30 minutes. The manure makes a good fuel because itis very high in organic material that bums readily and quickly; the manure has to be dry and is best used exactly as found in the field, there is no need to break it up or process it any further. D. A potters din is an expensive item and can could take up to four or five hours to get upto 800 degrees. It needs expensive or scarce fuel, such as gas or wood to heat it and experience to run it. With no technology, no insulation and nothing other than a pile of cow manure and a match, none of these restrictions apply, Mr. Flynn says. E. It is also helpful that, like terracotta clay and organic material, cow dung is freely available across the developing world. A cow is a natural fuel factory. My understanding is that cow dung as a fuel would be pretty much the same wherever you would find it. Just as using manure as a fuel for domestic uses is not a new idea, the porosity of clay is something that potters have known about for years, and something that as a former ceramics lecturer in the ANU School of Art, Mr. Flynn is well aware of. The difference is that rather than viewing the porous nature of the material as a problem after all not many people want a pot that wont hold water his filters capitalize on this property. F. Other commercial ceramic filters do exist, but, even if available, with prices starting at US$5 each, they are often outside the budgets of most people in the developing world. The filtration process is simple, but effective. The basic principle is that there are passages through the filter that are wide enough for water droplets to pass through, but too narrow for pathogens. Tests with the deadly E-coli bacterium have seen the filters remove 96.4 to 99.8 per cent of the pathogen well within safe levels. Using only one filter it takes two hours to filter a litre of water. The use of organic material, which burns away after firing, helps produce the structure in which pathogens will become trapped. It overcomes the potential problems of finer clays that may not let water through and also means that cracks are soon halted. And like clay and cow dung, it is universally available. G. The invention was born out of a World Vision project involving the Manatuto community in East Timor The charity wanted to help set up a small industry manufacturing water filters, but initial research found the local clay to be too fine a problem solved by the addition of organic material. While the AF problems of producing a working ceramic filter in East Timor were overcome, the solution was kiln-based and particular to that communitys materials and couldnt be applied elsewhere. Manure firing, with no requirement for a kiln, has made this zero technology approach available anywhere it is needed. With all the components being widely available, Mr. Flynn says there is no reason the technology couldnt be applied throughout the developing world, and with no plans to patent his idea, there will be no legal obstacles to it being adopted in any community that needs it. Everyone has a right to clean water, these filters have the potential to enable anyone in the world to drink water safely, says Mr. Flynn.", "hypothesis": "E-coli is the most difficult bacteria to combat.", "gold_label": "neutral"}
{"uid": "id_392", "premise": "Water Filter. An ingenious invention is set to bring clean water to the third world, and while the science may be cutting edge, the materials are extremely down to earth. A handful of clay yesterdays coffee grounds and some cow manure are the ingredients that could bring clean, safe drinking water to much of the third world. B. The simple new technology, developed by ANU materials scientist Mr. Tony Flynn, allows water filters to be made from commonly available materials and fired on the ground using cow manure as the source of heat, without the need for a kiln. The filters have been tested and shown to remove common pathogens (disease-producing organisms) including E-coli. Unlike other water filtering devices, the filters are simple and inexpensive to make. They are very simple to explain and demonstrate and can be made by anyone, anywhere, says Mr. Flynn. They dont require any western technology. All you need is terracotta clay, a compliant cow and a match. C. The production of the filters is extremely simple. Take a handful of dry, crushed clay, mix it with a handful of organic material, such as used tea leaves, coffee grounds or rice hulls, add enough water to make a stiff biscuit-like mixture and form a cylindrical pot that has one end closed, then dry it in the sun. According to Mr. Flynn, used coffee grounds have given the best results to date. Next, surround the pots with straw; put them in a mound of cow manure, light the straw and then top up the burning manure as required. In less than 60 minutes the filters are finished. The walls of the finished pot should be about as thick as an adults index. The properties of cow manure are vital as the fuel can reach a temperature of 700 degrees in half an hour and will be up to 950 degrees after another 20 to 30 minutes. The manure makes a good fuel because itis very high in organic material that bums readily and quickly; the manure has to be dry and is best used exactly as found in the field, there is no need to break it up or process it any further. D. A potters din is an expensive item and can could take up to four or five hours to get upto 800 degrees. It needs expensive or scarce fuel, such as gas or wood to heat it and experience to run it. With no technology, no insulation and nothing other than a pile of cow manure and a match, none of these restrictions apply, Mr. Flynn says. E. It is also helpful that, like terracotta clay and organic material, cow dung is freely available across the developing world. A cow is a natural fuel factory. My understanding is that cow dung as a fuel would be pretty much the same wherever you would find it. Just as using manure as a fuel for domestic uses is not a new idea, the porosity of clay is something that potters have known about for years, and something that as a former ceramics lecturer in the ANU School of Art, Mr. Flynn is well aware of. The difference is that rather than viewing the porous nature of the material as a problem after all not many people want a pot that wont hold water his filters capitalize on this property. F. Other commercial ceramic filters do exist, but, even if available, with prices starting at US$5 each, they are often outside the budgets of most people in the developing world. The filtration process is simple, but effective. The basic principle is that there are passages through the filter that are wide enough for water droplets to pass through, but too narrow for pathogens. Tests with the deadly E-coli bacterium have seen the filters remove 96.4 to 99.8 per cent of the pathogen well within safe levels. Using only one filter it takes two hours to filter a litre of water. The use of organic material, which burns away after firing, helps produce the structure in which pathogens will become trapped. It overcomes the potential problems of finer clays that may not let water through and also means that cracks are soon halted. And like clay and cow dung, it is universally available. G. The invention was born out of a World Vision project involving the Manatuto community in East Timor The charity wanted to help set up a small industry manufacturing water filters, but initial research found the local clay to be too fine a problem solved by the addition of organic material. While the AF problems of producing a working ceramic filter in East Timor were overcome, the solution was kiln-based and particular to that communitys materials and couldnt be applied elsewhere. Manure firing, with no requirement for a kiln, has made this zero technology approach available anywhere it is needed. With all the components being widely available, Mr. Flynn says there is no reason the technology couldnt be applied throughout the developing world, and with no plans to patent his idea, there will be no legal obstacles to it being adopted in any community that needs it. Everyone has a right to clean water, these filters have the potential to enable anyone in the world to drink water safely, says Mr. Flynn.", "hypothesis": "Clay was initially found to be unsuitable for pot making.", "gold_label": "entailment"}
{"uid": "id_393", "premise": "Water Filter. An ingenious invention is set to bring clean water to the third world, and while the science may be cutting edge, the materials are extremely down to earth. A handful of clay yesterdays coffee grounds and some cow manure are the ingredients that could bring clean, safe drinking water to much of the third world. B. The simple new technology, developed by ANU materials scientist Mr. Tony Flynn, allows water filters to be made from commonly available materials and fired on the ground using cow manure as the source of heat, without the need for a kiln. The filters have been tested and shown to remove common pathogens (disease-producing organisms) including E-coli. Unlike other water filtering devices, the filters are simple and inexpensive to make. They are very simple to explain and demonstrate and can be made by anyone, anywhere, says Mr. Flynn. They dont require any western technology. All you need is terracotta clay, a compliant cow and a match. C. The production of the filters is extremely simple. Take a handful of dry, crushed clay, mix it with a handful of organic material, such as used tea leaves, coffee grounds or rice hulls, add enough water to make a stiff biscuit-like mixture and form a cylindrical pot that has one end closed, then dry it in the sun. According to Mr. Flynn, used coffee grounds have given the best results to date. Next, surround the pots with straw; put them in a mound of cow manure, light the straw and then top up the burning manure as required. In less than 60 minutes the filters are finished. The walls of the finished pot should be about as thick as an adults index. The properties of cow manure are vital as the fuel can reach a temperature of 700 degrees in half an hour and will be up to 950 degrees after another 20 to 30 minutes. The manure makes a good fuel because itis very high in organic material that bums readily and quickly; the manure has to be dry and is best used exactly as found in the field, there is no need to break it up or process it any further. D. A potters din is an expensive item and can could take up to four or five hours to get upto 800 degrees. It needs expensive or scarce fuel, such as gas or wood to heat it and experience to run it. With no technology, no insulation and nothing other than a pile of cow manure and a match, none of these restrictions apply, Mr. Flynn says. E. It is also helpful that, like terracotta clay and organic material, cow dung is freely available across the developing world. A cow is a natural fuel factory. My understanding is that cow dung as a fuel would be pretty much the same wherever you would find it. Just as using manure as a fuel for domestic uses is not a new idea, the porosity of clay is something that potters have known about for years, and something that as a former ceramics lecturer in the ANU School of Art, Mr. Flynn is well aware of. The difference is that rather than viewing the porous nature of the material as a problem after all not many people want a pot that wont hold water his filters capitalize on this property. F. Other commercial ceramic filters do exist, but, even if available, with prices starting at US$5 each, they are often outside the budgets of most people in the developing world. The filtration process is simple, but effective. The basic principle is that there are passages through the filter that are wide enough for water droplets to pass through, but too narrow for pathogens. Tests with the deadly E-coli bacterium have seen the filters remove 96.4 to 99.8 per cent of the pathogen well within safe levels. Using only one filter it takes two hours to filter a litre of water. The use of organic material, which burns away after firing, helps produce the structure in which pathogens will become trapped. It overcomes the potential problems of finer clays that may not let water through and also means that cracks are soon halted. And like clay and cow dung, it is universally available. G. The invention was born out of a World Vision project involving the Manatuto community in East Timor The charity wanted to help set up a small industry manufacturing water filters, but initial research found the local clay to be too fine a problem solved by the addition of organic material. While the AF problems of producing a working ceramic filter in East Timor were overcome, the solution was kiln-based and particular to that communitys materials and couldnt be applied elsewhere. Manure firing, with no requirement for a kiln, has made this zero technology approach available anywhere it is needed. With all the components being widely available, Mr. Flynn says there is no reason the technology couldnt be applied throughout the developing world, and with no plans to patent his idea, there will be no legal obstacles to it being adopted in any community that needs it. Everyone has a right to clean water, these filters have the potential to enable anyone in the world to drink water safely, says Mr. Flynn.", "hypothesis": "Coffee grounds are twice as effective as other materials.", "gold_label": "neutral"}
{"uid": "id_394", "premise": "Water Filter. An ingenious invention is set to bring clean water to the third world, and while the science may be cutting edge, the materials are extremely down to earth. A handful of clay yesterdays coffee grounds and some cow manure are the ingredients that could bring clean, safe drinking water to much of the third world. B. The simple new technology, developed by ANU materials scientist Mr. Tony Flynn, allows water filters to be made from commonly available materials and fired on the ground using cow manure as the source of heat, without the need for a kiln. The filters have been tested and shown to remove common pathogens (disease-producing organisms) including E-coli. Unlike other water filtering devices, the filters are simple and inexpensive to make. They are very simple to explain and demonstrate and can be made by anyone, anywhere, says Mr. Flynn. They dont require any western technology. All you need is terracotta clay, a compliant cow and a match. C. The production of the filters is extremely simple. Take a handful of dry, crushed clay, mix it with a handful of organic material, such as used tea leaves, coffee grounds or rice hulls, add enough water to make a stiff biscuit-like mixture and form a cylindrical pot that has one end closed, then dry it in the sun. According to Mr. Flynn, used coffee grounds have given the best results to date. Next, surround the pots with straw; put them in a mound of cow manure, light the straw and then top up the burning manure as required. In less than 60 minutes the filters are finished. The walls of the finished pot should be about as thick as an adults index. The properties of cow manure are vital as the fuel can reach a temperature of 700 degrees in half an hour and will be up to 950 degrees after another 20 to 30 minutes. The manure makes a good fuel because itis very high in organic material that bums readily and quickly; the manure has to be dry and is best used exactly as found in the field, there is no need to break it up or process it any further. D. A potters din is an expensive item and can could take up to four or five hours to get upto 800 degrees. It needs expensive or scarce fuel, such as gas or wood to heat it and experience to run it. With no technology, no insulation and nothing other than a pile of cow manure and a match, none of these restrictions apply, Mr. Flynn says. E. It is also helpful that, like terracotta clay and organic material, cow dung is freely available across the developing world. A cow is a natural fuel factory. My understanding is that cow dung as a fuel would be pretty much the same wherever you would find it. Just as using manure as a fuel for domestic uses is not a new idea, the porosity of clay is something that potters have known about for years, and something that as a former ceramics lecturer in the ANU School of Art, Mr. Flynn is well aware of. The difference is that rather than viewing the porous nature of the material as a problem after all not many people want a pot that wont hold water his filters capitalize on this property. F. Other commercial ceramic filters do exist, but, even if available, with prices starting at US$5 each, they are often outside the budgets of most people in the developing world. The filtration process is simple, but effective. The basic principle is that there are passages through the filter that are wide enough for water droplets to pass through, but too narrow for pathogens. Tests with the deadly E-coli bacterium have seen the filters remove 96.4 to 99.8 per cent of the pathogen well within safe levels. Using only one filter it takes two hours to filter a litre of water. The use of organic material, which burns away after firing, helps produce the structure in which pathogens will become trapped. It overcomes the potential problems of finer clays that may not let water through and also means that cracks are soon halted. And like clay and cow dung, it is universally available. G. The invention was born out of a World Vision project involving the Manatuto community in East Timor The charity wanted to help set up a small industry manufacturing water filters, but initial research found the local clay to be too fine a problem solved by the addition of organic material. While the AF problems of producing a working ceramic filter in East Timor were overcome, the solution was kiln-based and particular to that communitys materials and couldnt be applied elsewhere. Manure firing, with no requirement for a kiln, has made this zero technology approach available anywhere it is needed. With all the components being widely available, Mr. Flynn says there is no reason the technology couldnt be applied throughout the developing world, and with no plans to patent his idea, there will be no legal obstacles to it being adopted in any community that needs it. Everyone has a right to clean water, these filters have the potential to enable anyone in the world to drink water safely, says Mr. Flynn.", "hypothesis": "It takes half an hour for the manure to reach 950 degrees.", "gold_label": "contradiction"}
{"uid": "id_395", "premise": "Water and chips break new ground Computers have been shrinking ever since their conception almost two centuries ago, and the trend is set to continue with the latest developments in microchip manufacturing. The earliest prototype of a mechanical computer was called the Difference Engine, and was invented by an eccentric Victorian called Charles Babbage. It weighed over 15 tons and had 26,000 parts. Colossus, the first electronic computer, did not appear until the end of WWTI, and with its 1,500 vacuum tubes was even more complex and much heavier than its mechanical predecessor. It was only when the silicon-based microchip was invented in the early 1950s that computers started to become more compact. The first microchip computers were very complex and had more than 100,000 transistors, or electronic switches; however, they were still rather bulky and measured several metres across. Nowadays microchips are measured in nanometres (nm)that is, in billionths of a metreand the search for even smaller microchips continues as scientists work on new methods of microchip production. Today, most microchips are shaped by a process called lithographic etching, which uses ultraviolet (UV) light. A beam of UV light with a wavelength of only 193 nm is projected through a lens on to an etching mask, a micro device with slits, or long narrow cuts. When the UV light hits the surface of silicon chips, it removes microscopic layers of silicon to create patterns for the microchips circuits. Microchips with features as small as 65 nm can be created with this wavelength. However, lithographic etching is unable to make chips much smaller than 65 nm due to the fundamental properties of light. If the slit in the mask were made narrower, the air and nitrogen used in the space between the lens and the etching mask would diffuse the light, causing a blurred image. This means that 193-nm UV light cannot be used to produce microchips with features smaller than 65 nm. Manufacturers know that they need to go even smaller for the technological demands of this century, and they are looking for new methods of making microchips. One approach to solving the problem is to use microscopic mirrors to focus X-rays rather than ultraviolet light. X-rays with a wavelength of less than 25 nm can be created, allowing engineers to make components smaller than 15 nm. The process is known as X-ray lithography etching. However, this technology is extremely expensive, so manufacturers are continuing to search for a cheaper alternative. A technology called immersion lithography might be the solution. Although liquids are not commonly associated with computers, a tiny drop of water may be all it takes to make microprocessors smaller and more powerful. Intel and IBM, who made the first microprocessors, have recently developed a unique method of microchip production, which uses water droplets to enable manufacturers to shrink the chipsand at a reasonable price! The new microchip is produced by using a drop of water to narrow the gap between the light source and the etching mask, and shorten the wavelength of the UV light to less than 34 nm. This process can be used to manufacture microchips as small as 45 nm, or possibly even smaller. Initially, engineers feared that air bubbles and other contaminants in water drops would distort the light and ruin the microchip etching process, and the first experiments proved these fears to be well-founded. The problem was overcome by using high-purity water, free of air and other substances. Scientists are also experimenting with liquids other than waterdenser liquids such as hydrofluoric acidwhich may allow the wavelength to be shrunk still further, thus producing even smaller chips. IBM have already successfully implemented immersion lithography on some of their production lines and created a fully-functioning microprocessor. IBM also claim that they are able to produce microchips with very few defects. Although immersion lithography is very new, it is highly promising as it will make the production of 45 nm and 32 nm chips commercially viable. It is a significant milestone in chip manufacturing and will help to bring the costs of the chip down without fundamentally changing the microchip production processes. In the near future, the ground-breaking technology of immersion lithography will enable computer manufacturers to make powerful microchips that will be used in electronic devices smaller than a coin. This will open up new opportunities in the ever-shrinking world of digital technology.", "hypothesis": "The first electronic computer weighed more than the first mechanical prototype.", "gold_label": "entailment"}
{"uid": "id_396", "premise": "Water and chips break new ground Computers have been shrinking ever since their conception almost two centuries ago, and the trend is set to continue with the latest developments in microchip manufacturing. The earliest prototype of a mechanical computer was called the Difference Engine, and was invented by an eccentric Victorian called Charles Babbage. It weighed over 15 tons and had 26,000 parts. Colossus, the first electronic computer, did not appear until the end of WWTI, and with its 1,500 vacuum tubes was even more complex and much heavier than its mechanical predecessor. It was only when the silicon-based microchip was invented in the early 1950s that computers started to become more compact. The first microchip computers were very complex and had more than 100,000 transistors, or electronic switches; however, they were still rather bulky and measured several metres across. Nowadays microchips are measured in nanometres (nm)that is, in billionths of a metreand the search for even smaller microchips continues as scientists work on new methods of microchip production. Today, most microchips are shaped by a process called lithographic etching, which uses ultraviolet (UV) light. A beam of UV light with a wavelength of only 193 nm is projected through a lens on to an etching mask, a micro device with slits, or long narrow cuts. When the UV light hits the surface of silicon chips, it removes microscopic layers of silicon to create patterns for the microchips circuits. Microchips with features as small as 65 nm can be created with this wavelength. However, lithographic etching is unable to make chips much smaller than 65 nm due to the fundamental properties of light. If the slit in the mask were made narrower, the air and nitrogen used in the space between the lens and the etching mask would diffuse the light, causing a blurred image. This means that 193-nm UV light cannot be used to produce microchips with features smaller than 65 nm. Manufacturers know that they need to go even smaller for the technological demands of this century, and they are looking for new methods of making microchips. One approach to solving the problem is to use microscopic mirrors to focus X-rays rather than ultraviolet light. X-rays with a wavelength of less than 25 nm can be created, allowing engineers to make components smaller than 15 nm. The process is known as X-ray lithography etching. However, this technology is extremely expensive, so manufacturers are continuing to search for a cheaper alternative. A technology called immersion lithography might be the solution. Although liquids are not commonly associated with computers, a tiny drop of water may be all it takes to make microprocessors smaller and more powerful. Intel and IBM, who made the first microprocessors, have recently developed a unique method of microchip production, which uses water droplets to enable manufacturers to shrink the chipsand at a reasonable price! The new microchip is produced by using a drop of water to narrow the gap between the light source and the etching mask, and shorten the wavelength of the UV light to less than 34 nm. This process can be used to manufacture microchips as small as 45 nm, or possibly even smaller. Initially, engineers feared that air bubbles and other contaminants in water drops would distort the light and ruin the microchip etching process, and the first experiments proved these fears to be well-founded. The problem was overcome by using high-purity water, free of air and other substances. Scientists are also experimenting with liquids other than waterdenser liquids such as hydrofluoric acidwhich may allow the wavelength to be shrunk still further, thus producing even smaller chips. IBM have already successfully implemented immersion lithography on some of their production lines and created a fully-functioning microprocessor. IBM also claim that they are able to produce microchips with very few defects. Although immersion lithography is very new, it is highly promising as it will make the production of 45 nm and 32 nm chips commercially viable. It is a significant milestone in chip manufacturing and will help to bring the costs of the chip down without fundamentally changing the microchip production processes. In the near future, the ground-breaking technology of immersion lithography will enable computer manufacturers to make powerful microchips that will be used in electronic devices smaller than a coin. This will open up new opportunities in the ever-shrinking world of digital technology.", "hypothesis": "Computers started to shrink with the invention of the microchip.", "gold_label": "entailment"}
{"uid": "id_397", "premise": "Water and chips break new ground Computers have been shrinking ever since their conception almost two centuries ago, and the trend is set to continue with the latest developments in microchip manufacturing. The earliest prototype of a mechanical computer was called the Difference Engine, and was invented by an eccentric Victorian called Charles Babbage. It weighed over 15 tons and had 26,000 parts. Colossus, the first electronic computer, did not appear until the end of WWTI, and with its 1,500 vacuum tubes was even more complex and much heavier than its mechanical predecessor. It was only when the silicon-based microchip was invented in the early 1950s that computers started to become more compact. The first microchip computers were very complex and had more than 100,000 transistors, or electronic switches; however, they were still rather bulky and measured several metres across. Nowadays microchips are measured in nanometres (nm)that is, in billionths of a metreand the search for even smaller microchips continues as scientists work on new methods of microchip production. Today, most microchips are shaped by a process called lithographic etching, which uses ultraviolet (UV) light. A beam of UV light with a wavelength of only 193 nm is projected through a lens on to an etching mask, a micro device with slits, or long narrow cuts. When the UV light hits the surface of silicon chips, it removes microscopic layers of silicon to create patterns for the microchips circuits. Microchips with features as small as 65 nm can be created with this wavelength. However, lithographic etching is unable to make chips much smaller than 65 nm due to the fundamental properties of light. If the slit in the mask were made narrower, the air and nitrogen used in the space between the lens and the etching mask would diffuse the light, causing a blurred image. This means that 193-nm UV light cannot be used to produce microchips with features smaller than 65 nm. Manufacturers know that they need to go even smaller for the technological demands of this century, and they are looking for new methods of making microchips. One approach to solving the problem is to use microscopic mirrors to focus X-rays rather than ultraviolet light. X-rays with a wavelength of less than 25 nm can be created, allowing engineers to make components smaller than 15 nm. The process is known as X-ray lithography etching. However, this technology is extremely expensive, so manufacturers are continuing to search for a cheaper alternative. A technology called immersion lithography might be the solution. Although liquids are not commonly associated with computers, a tiny drop of water may be all it takes to make microprocessors smaller and more powerful. Intel and IBM, who made the first microprocessors, have recently developed a unique method of microchip production, which uses water droplets to enable manufacturers to shrink the chipsand at a reasonable price! The new microchip is produced by using a drop of water to narrow the gap between the light source and the etching mask, and shorten the wavelength of the UV light to less than 34 nm. This process can be used to manufacture microchips as small as 45 nm, or possibly even smaller. Initially, engineers feared that air bubbles and other contaminants in water drops would distort the light and ruin the microchip etching process, and the first experiments proved these fears to be well-founded. The problem was overcome by using high-purity water, free of air and other substances. Scientists are also experimenting with liquids other than waterdenser liquids such as hydrofluoric acidwhich may allow the wavelength to be shrunk still further, thus producing even smaller chips. IBM have already successfully implemented immersion lithography on some of their production lines and created a fully-functioning microprocessor. IBM also claim that they are able to produce microchips with very few defects. Although immersion lithography is very new, it is highly promising as it will make the production of 45 nm and 32 nm chips commercially viable. It is a significant milestone in chip manufacturing and will help to bring the costs of the chip down without fundamentally changing the microchip production processes. In the near future, the ground-breaking technology of immersion lithography will enable computer manufacturers to make powerful microchips that will be used in electronic devices smaller than a coin. This will open up new opportunities in the ever-shrinking world of digital technology.", "hypothesis": "In early 1950s engineers used ultraviolet rays to build the first microchip.", "gold_label": "neutral"}
{"uid": "id_398", "premise": "Water and chips break new ground Computers have been shrinking ever since their conception almost two centuries ago, and the trend is set to continue with the latest developments in microchip manufacturing. The earliest prototype of a mechanical computer was called the Difference Engine, and was invented by an eccentric Victorian called Charles Babbage. It weighed over 15 tons and had 26,000 parts. Colossus, the first electronic computer, did not appear until the end of WWTI, and with its 1,500 vacuum tubes was even more complex and much heavier than its mechanical predecessor. It was only when the silicon-based microchip was invented in the early 1950s that computers started to become more compact. The first microchip computers were very complex and had more than 100,000 transistors, or electronic switches; however, they were still rather bulky and measured several metres across. Nowadays microchips are measured in nanometres (nm)that is, in billionths of a metreand the search for even smaller microchips continues as scientists work on new methods of microchip production. Today, most microchips are shaped by a process called lithographic etching, which uses ultraviolet (UV) light. A beam of UV light with a wavelength of only 193 nm is projected through a lens on to an etching mask, a micro device with slits, or long narrow cuts. When the UV light hits the surface of silicon chips, it removes microscopic layers of silicon to create patterns for the microchips circuits. Microchips with features as small as 65 nm can be created with this wavelength. However, lithographic etching is unable to make chips much smaller than 65 nm due to the fundamental properties of light. If the slit in the mask were made narrower, the air and nitrogen used in the space between the lens and the etching mask would diffuse the light, causing a blurred image. This means that 193-nm UV light cannot be used to produce microchips with features smaller than 65 nm. Manufacturers know that they need to go even smaller for the technological demands of this century, and they are looking for new methods of making microchips. One approach to solving the problem is to use microscopic mirrors to focus X-rays rather than ultraviolet light. X-rays with a wavelength of less than 25 nm can be created, allowing engineers to make components smaller than 15 nm. The process is known as X-ray lithography etching. However, this technology is extremely expensive, so manufacturers are continuing to search for a cheaper alternative. A technology called immersion lithography might be the solution. Although liquids are not commonly associated with computers, a tiny drop of water may be all it takes to make microprocessors smaller and more powerful. Intel and IBM, who made the first microprocessors, have recently developed a unique method of microchip production, which uses water droplets to enable manufacturers to shrink the chipsand at a reasonable price! The new microchip is produced by using a drop of water to narrow the gap between the light source and the etching mask, and shorten the wavelength of the UV light to less than 34 nm. This process can be used to manufacture microchips as small as 45 nm, or possibly even smaller. Initially, engineers feared that air bubbles and other contaminants in water drops would distort the light and ruin the microchip etching process, and the first experiments proved these fears to be well-founded. The problem was overcome by using high-purity water, free of air and other substances. Scientists are also experimenting with liquids other than waterdenser liquids such as hydrofluoric acidwhich may allow the wavelength to be shrunk still further, thus producing even smaller chips. IBM have already successfully implemented immersion lithography on some of their production lines and created a fully-functioning microprocessor. IBM also claim that they are able to produce microchips with very few defects. Although immersion lithography is very new, it is highly promising as it will make the production of 45 nm and 32 nm chips commercially viable. It is a significant milestone in chip manufacturing and will help to bring the costs of the chip down without fundamentally changing the microchip production processes. In the near future, the ground-breaking technology of immersion lithography will enable computer manufacturers to make powerful microchips that will be used in electronic devices smaller than a coin. This will open up new opportunities in the ever-shrinking world of digital technology.", "hypothesis": "X-ray lithography is an inexpensive alternative technology to lithographic etching.", "gold_label": "contradiction"}
{"uid": "id_399", "premise": "Water and chips break new ground Computers have been shrinking ever since their conception almost two centuries ago, and the trend is set to continue with the latest developments in microchip manufacturing. The earliest prototype of a mechanical computer was called the Difference Engine, and was invented by an eccentric Victorian called Charles Babbage. It weighed over 15 tons and had 26,000 parts. Colossus, the first electronic computer, did not appear until the end of WWTI, and with its 1,500 vacuum tubes was even more complex and much heavier than its mechanical predecessor. It was only when the silicon-based microchip was invented in the early 1950s that computers started to become more compact. The first microchip computers were very complex and had more than 100,000 transistors, or electronic switches; however, they were still rather bulky and measured several metres across. Nowadays microchips are measured in nanometres (nm)that is, in billionths of a metreand the search for even smaller microchips continues as scientists work on new methods of microchip production. Today, most microchips are shaped by a process called lithographic etching, which uses ultraviolet (UV) light. A beam of UV light with a wavelength of only 193 nm is projected through a lens on to an etching mask, a micro device with slits, or long narrow cuts. When the UV light hits the surface of silicon chips, it removes microscopic layers of silicon to create patterns for the microchips circuits. Microchips with features as small as 65 nm can be created with this wavelength. However, lithographic etching is unable to make chips much smaller than 65 nm due to the fundamental properties of light. If the slit in the mask were made narrower, the air and nitrogen used in the space between the lens and the etching mask would diffuse the light, causing a blurred image. This means that 193-nm UV light cannot be used to produce microchips with features smaller than 65 nm. Manufacturers know that they need to go even smaller for the technological demands of this century, and they are looking for new methods of making microchips. One approach to solving the problem is to use microscopic mirrors to focus X-rays rather than ultraviolet light. X-rays with a wavelength of less than 25 nm can be created, allowing engineers to make components smaller than 15 nm. The process is known as X-ray lithography etching. However, this technology is extremely expensive, so manufacturers are continuing to search for a cheaper alternative. A technology called immersion lithography might be the solution. Although liquids are not commonly associated with computers, a tiny drop of water may be all it takes to make microprocessors smaller and more powerful. Intel and IBM, who made the first microprocessors, have recently developed a unique method of microchip production, which uses water droplets to enable manufacturers to shrink the chipsand at a reasonable price! The new microchip is produced by using a drop of water to narrow the gap between the light source and the etching mask, and shorten the wavelength of the UV light to less than 34 nm. This process can be used to manufacture microchips as small as 45 nm, or possibly even smaller. Initially, engineers feared that air bubbles and other contaminants in water drops would distort the light and ruin the microchip etching process, and the first experiments proved these fears to be well-founded. The problem was overcome by using high-purity water, free of air and other substances. Scientists are also experimenting with liquids other than waterdenser liquids such as hydrofluoric acidwhich may allow the wavelength to be shrunk still further, thus producing even smaller chips. IBM have already successfully implemented immersion lithography on some of their production lines and created a fully-functioning microprocessor. IBM also claim that they are able to produce microchips with very few defects. Although immersion lithography is very new, it is highly promising as it will make the production of 45 nm and 32 nm chips commercially viable. It is a significant milestone in chip manufacturing and will help to bring the costs of the chip down without fundamentally changing the microchip production processes. In the near future, the ground-breaking technology of immersion lithography will enable computer manufacturers to make powerful microchips that will be used in electronic devices smaller than a coin. This will open up new opportunities in the ever-shrinking world of digital technology.", "hypothesis": "Immersion lithography has enabled microchip manufacturers to produce higher quality computer chips.", "gold_label": "entailment"}
{"uid": "id_400", "premise": "Water occupies 71% of our planet. About 96.5% of the water found on Earth is not readily available for human consumption, and resides in the oceans and seas. Out of the remaining 3.5%, 1.7% can be found in groundwater, 1.7% in glaciers and ice caps in Antarctica and Greenland and 0.001% in the air as vapour and clouds. Water moves continually through the water cycle of evaporation and transpiration, condensation, precipitation and runoff, usually reaching the sea. Whereas evaporation refers to the phase shift of any liquid to gas, transpiration is the process of water movement through a plant. Runoff is the flow of water over the Earth's surface. It's created when too much rain falls, and there is no more room in the soil to absorb more water. One of the reasons seas are salty is because they contain large amounts of highly soluble salts (such as sodium and chloride) which were washed away by runoff water on its way to the sea.", "hypothesis": "Taking into account the water found in ice caps in Greenland and Antarctica, water constitutes over 71% of our planet.", "gold_label": "contradiction"}
{"uid": "id_401", "premise": "Water occupies 71% of our planet. About 96.5% of the water found on Earth is not readily available for human consumption, and resides in the oceans and seas. Out of the remaining 3.5%, 1.7% can be found in groundwater, 1.7% in glaciers and ice caps in Antarctica and Greenland and 0.001% in the air as vapour and clouds. Water moves continually through the water cycle of evaporation and transpiration, condensation, precipitation and runoff, usually reaching the sea. Whereas evaporation refers to the phase shift of any liquid to gas, transpiration is the process of water movement through a plant. Runoff is the flow of water over the Earth's surface. It's created when too much rain falls, and there is no more room in the soil to absorb more water. One of the reasons seas are salty is because they contain large amounts of highly soluble salts (such as sodium and chloride) which were washed away by runoff water on its way to the sea.", "hypothesis": "Water content in glaciers is not considered to be groundwater.", "gold_label": "entailment"}
{"uid": "id_402", "premise": "Water occupies 71% of our planet. About 96.5% of the water found on Earth is not readily available for human consumption, and resides in the oceans and seas. Out of the remaining 3.5%, 1.7% can be found in groundwater, 1.7% in glaciers and ice caps in Antarctica and Greenland and 0.001% in the air as vapour and clouds. Water moves continually through the water cycle of evaporation and transpiration, condensation, precipitation and runoff, usually reaching the sea. Whereas evaporation refers to the phase shift of any liquid to gas, transpiration is the process of water movement through a plant. Runoff is the flow of water over the Earth's surface. It's created when too much rain falls, and there is no more room in the soil to absorb more water. One of the reasons seas are salty is because they contain large amounts of highly soluble salts (such as sodium and chloride) which were washed away by runoff water on its way to the sea.", "hypothesis": "The runoff stage in the water cycle takes the longest amount of time.", "gold_label": "neutral"}
{"uid": "id_403", "premise": "Water stress and scarcity Water stress and scarcity occur when there is an imbalance between the availability of water and the demand for water. When we hear people talking about water stress and scarcity, we often think of drought but this is only one of several causes. Alex Karpov, a representative from the WHO explains some of the other issues that also impact the availability of fresh water, The deterioration of ground water and surface water quality, competition for water between different segments of society, for example, between agricultural, industrial, and domestic users, and even social and financial barriers, are all causes of water stress and scarcity today. While approximately three quarters of the earth are covered with water only a small proportion of it is available as fresh water. Of the available fresh water supplies, nearly 70% is withdrawn and used for irrigation to produce food, and the demand just keep growing. Although there is currently no global scarcity of water, more and more regions of the world are chronically short of water. At present, 1.1 billion people have little choice but to use potentially harmful sources of water, and 2.6 billion people, which is around half the developing world, lack access to adequate sanitation. As Kathie Coles, an executive from the charity World of Water, describes, the situation will deteriorate. Over the next 20 years, an estimated 1.8 billion people will be living in countries or regions with an absolute water scarcity, and two-thirds of the world population may be under pressure conditions. This situation will only worsen, as rapidly growing urban areas place heavy pressure on water supplies. Of course, there have been different initiatives put into place around the world to help with water stress and scarcity. With larger scale projects, such as the construction of piper water systems, remain important objectives of many development agencies, a shortage of time and finances will leave hundreds of millions of people without access to safe water in the foreseeable future. Georgina Ronaldson, a spokesperson for the World Bank, recently announced a way to deal with the current difficulties. To help developing countries, various concerned organisations have developed the Safe Water System (SWS), which is an adaptable and flexible intervention that employs scientific methods appropriate for the developing world. The SWS has been criticised in various corners as being too amateurish, but Ronaldson continues to justify the approach. The use of relevant technologies is important, an in many places around the world, water provision efforts suffer from a lack of technical knowledge to effectively manage or adapt a system to a communitys changing needs. The SWS is a community-based, integrative approach to improving health and quality of life through increased access to improve water, sanitation and hygiene. Darren Stanford, a water quality engineer, explains the important three step methodology. The first is an assessment of water delivery system from catchment to consumer. The second is implementing appropriate interventions, which can include protection of source waters, improvements to the water deliver systems, introduction of SWS, improved sanitation and hygiene education. The third is the evaluation of the impact of the intervention of the health and quality of life of the consumers. One example of how poor water access can affect local populations is the problems of guinea worms in remote parts of Africa. This is a preventable parasitic infection that affects poor communities that lack safe drinking water. The infection is transmitted to people who drink water containing copepods (tiny water fleas) that are infected with the larvae of guinea worms. Once ingested these larvae take up to one year to grow into adult worms; the female worms then emerge from the skin anywhere on the body. Will Goodman, a doctor with WHO, says that this can affect communities in different ways. The emergence of the adult female worm can be very painful, slow and disabling and prevents people from working in their fields, tending their animals, going to school, and caring for their families. Currently many organisations are helping the last nine endemic countries (all in Sub-Saharan Africa) to eradicate guinea worm. Since the Guinea Worm Eradication programme began, the incidence of guinea worm has declined from 1.5 million cases per year in 20 endemic countries to 25,018 reported cases in 2008 from the nine remaining endemic countries. The eradication efforts make use of simple intervention for providing safe drinking water including using cloth filters and pipe filters to strain the infected copepods from water, applying chemicals to the water supplies to kill the larvae, and preventing infected people from entering and contaminating the water supplies, as the worms emerge from their skins. Providing borehole wells and other supplies of water in endemic village is another important component of the eradication efforts. The provision of borehole well is one of the principal aims of SWS. Many existing dug wells in communities only pierce the topsoil, do not reach deep enough and are therefore readily affected by drought or by the natural declines from summer to autumn in the water table. SWS borehole wells can pierce the bedrock and access a deeper aquifer with water that is not affected by surface drought. These are also unaffected by guinea worm infestation and water is much safer for human consumption.", "hypothesis": "Majority of water available on earth is drinkable.", "gold_label": "contradiction"}
{"uid": "id_404", "premise": "Water stress and scarcity Water stress and scarcity occur when there is an imbalance between the availability of water and the demand for water. When we hear people talking about water stress and scarcity, we often think of drought but this is only one of several causes. Alex Karpov, a representative from the WHO explains some of the other issues that also impact the availability of fresh water, The deterioration of ground water and surface water quality, competition for water between different segments of society, for example, between agricultural, industrial, and domestic users, and even social and financial barriers, are all causes of water stress and scarcity today. While approximately three quarters of the earth are covered with water only a small proportion of it is available as fresh water. Of the available fresh water supplies, nearly 70% is withdrawn and used for irrigation to produce food, and the demand just keep growing. Although there is currently no global scarcity of water, more and more regions of the world are chronically short of water. At present, 1.1 billion people have little choice but to use potentially harmful sources of water, and 2.6 billion people, which is around half the developing world, lack access to adequate sanitation. As Kathie Coles, an executive from the charity World of Water, describes, the situation will deteriorate. Over the next 20 years, an estimated 1.8 billion people will be living in countries or regions with an absolute water scarcity, and two-thirds of the world population may be under pressure conditions. This situation will only worsen, as rapidly growing urban areas place heavy pressure on water supplies. Of course, there have been different initiatives put into place around the world to help with water stress and scarcity. With larger scale projects, such as the construction of piper water systems, remain important objectives of many development agencies, a shortage of time and finances will leave hundreds of millions of people without access to safe water in the foreseeable future. Georgina Ronaldson, a spokesperson for the World Bank, recently announced a way to deal with the current difficulties. To help developing countries, various concerned organisations have developed the Safe Water System (SWS), which is an adaptable and flexible intervention that employs scientific methods appropriate for the developing world. The SWS has been criticised in various corners as being too amateurish, but Ronaldson continues to justify the approach. The use of relevant technologies is important, an in many places around the world, water provision efforts suffer from a lack of technical knowledge to effectively manage or adapt a system to a communitys changing needs. The SWS is a community-based, integrative approach to improving health and quality of life through increased access to improve water, sanitation and hygiene. Darren Stanford, a water quality engineer, explains the important three step methodology. The first is an assessment of water delivery system from catchment to consumer. The second is implementing appropriate interventions, which can include protection of source waters, improvements to the water deliver systems, introduction of SWS, improved sanitation and hygiene education. The third is the evaluation of the impact of the intervention of the health and quality of life of the consumers. One example of how poor water access can affect local populations is the problems of guinea worms in remote parts of Africa. This is a preventable parasitic infection that affects poor communities that lack safe drinking water. The infection is transmitted to people who drink water containing copepods (tiny water fleas) that are infected with the larvae of guinea worms. Once ingested these larvae take up to one year to grow into adult worms; the female worms then emerge from the skin anywhere on the body. Will Goodman, a doctor with WHO, says that this can affect communities in different ways. The emergence of the adult female worm can be very painful, slow and disabling and prevents people from working in their fields, tending their animals, going to school, and caring for their families. Currently many organisations are helping the last nine endemic countries (all in Sub-Saharan Africa) to eradicate guinea worm. Since the Guinea Worm Eradication programme began, the incidence of guinea worm has declined from 1.5 million cases per year in 20 endemic countries to 25,018 reported cases in 2008 from the nine remaining endemic countries. The eradication efforts make use of simple intervention for providing safe drinking water including using cloth filters and pipe filters to strain the infected copepods from water, applying chemicals to the water supplies to kill the larvae, and preventing infected people from entering and contaminating the water supplies, as the worms emerge from their skins. Providing borehole wells and other supplies of water in endemic village is another important component of the eradication efforts. The provision of borehole well is one of the principal aims of SWS. Many existing dug wells in communities only pierce the topsoil, do not reach deep enough and are therefore readily affected by drought or by the natural declines from summer to autumn in the water table. SWS borehole wells can pierce the bedrock and access a deeper aquifer with water that is not affected by surface drought. These are also unaffected by guinea worm infestation and water is much safer for human consumption.", "hypothesis": "SWS focuses on providing boreholes to eradicate the problem of guinea worms.", "gold_label": "entailment"}
{"uid": "id_405", "premise": "Water stress and scarcity Water stress and scarcity occur when there is an imbalance between the availability of water and the demand for water. When we hear people talking about water stress and scarcity, we often think of drought but this is only one of several causes. Alex Karpov, a representative from the WHO explains some of the other issues that also impact the availability of fresh water, The deterioration of ground water and surface water quality, competition for water between different segments of society, for example, between agricultural, industrial, and domestic users, and even social and financial barriers, are all causes of water stress and scarcity today. While approximately three quarters of the earth are covered with water only a small proportion of it is available as fresh water. Of the available fresh water supplies, nearly 70% is withdrawn and used for irrigation to produce food, and the demand just keep growing. Although there is currently no global scarcity of water, more and more regions of the world are chronically short of water. At present, 1.1 billion people have little choice but to use potentially harmful sources of water, and 2.6 billion people, which is around half the developing world, lack access to adequate sanitation. As Kathie Coles, an executive from the charity World of Water, describes, the situation will deteriorate. Over the next 20 years, an estimated 1.8 billion people will be living in countries or regions with an absolute water scarcity, and two-thirds of the world population may be under pressure conditions. This situation will only worsen, as rapidly growing urban areas place heavy pressure on water supplies. Of course, there have been different initiatives put into place around the world to help with water stress and scarcity. With larger scale projects, such as the construction of piper water systems, remain important objectives of many development agencies, a shortage of time and finances will leave hundreds of millions of people without access to safe water in the foreseeable future. Georgina Ronaldson, a spokesperson for the World Bank, recently announced a way to deal with the current difficulties. To help developing countries, various concerned organisations have developed the Safe Water System (SWS), which is an adaptable and flexible intervention that employs scientific methods appropriate for the developing world. The SWS has been criticised in various corners as being too amateurish, but Ronaldson continues to justify the approach. The use of relevant technologies is important, an in many places around the world, water provision efforts suffer from a lack of technical knowledge to effectively manage or adapt a system to a communitys changing needs. The SWS is a community-based, integrative approach to improving health and quality of life through increased access to improve water, sanitation and hygiene. Darren Stanford, a water quality engineer, explains the important three step methodology. The first is an assessment of water delivery system from catchment to consumer. The second is implementing appropriate interventions, which can include protection of source waters, improvements to the water deliver systems, introduction of SWS, improved sanitation and hygiene education. The third is the evaluation of the impact of the intervention of the health and quality of life of the consumers. One example of how poor water access can affect local populations is the problems of guinea worms in remote parts of Africa. This is a preventable parasitic infection that affects poor communities that lack safe drinking water. The infection is transmitted to people who drink water containing copepods (tiny water fleas) that are infected with the larvae of guinea worms. Once ingested these larvae take up to one year to grow into adult worms; the female worms then emerge from the skin anywhere on the body. Will Goodman, a doctor with WHO, says that this can affect communities in different ways. The emergence of the adult female worm can be very painful, slow and disabling and prevents people from working in their fields, tending their animals, going to school, and caring for their families. Currently many organisations are helping the last nine endemic countries (all in Sub-Saharan Africa) to eradicate guinea worm. Since the Guinea Worm Eradication programme began, the incidence of guinea worm has declined from 1.5 million cases per year in 20 endemic countries to 25,018 reported cases in 2008 from the nine remaining endemic countries. The eradication efforts make use of simple intervention for providing safe drinking water including using cloth filters and pipe filters to strain the infected copepods from water, applying chemicals to the water supplies to kill the larvae, and preventing infected people from entering and contaminating the water supplies, as the worms emerge from their skins. Providing borehole wells and other supplies of water in endemic village is another important component of the eradication efforts. The provision of borehole well is one of the principal aims of SWS. Many existing dug wells in communities only pierce the topsoil, do not reach deep enough and are therefore readily affected by drought or by the natural declines from summer to autumn in the water table. SWS borehole wells can pierce the bedrock and access a deeper aquifer with water that is not affected by surface drought. These are also unaffected by guinea worm infestation and water is much safer for human consumption.", "hypothesis": "Guinea worms in only found in Arica.", "gold_label": "neutral"}
{"uid": "id_406", "premise": "Water stress and scarcity Water stress and scarcity occur when there is an imbalance between the availability of water and the demand for water. When we hear people talking about water stress and scarcity, we often think of drought but this is only one of several causes. Alex Karpov, a representative from the WHO explains some of the other issues that also impact the availability of fresh water, The deterioration of ground water and surface water quality, competition for water between different segments of society, for example, between agricultural, industrial, and domestic users, and even social and financial barriers, are all causes of water stress and scarcity today. While approximately three quarters of the earth are covered with water only a small proportion of it is available as fresh water. Of the available fresh water supplies, nearly 70% is withdrawn and used for irrigation to produce food, and the demand just keep growing. Although there is currently no global scarcity of water, more and more regions of the world are chronically short of water. At present, 1.1 billion people have little choice but to use potentially harmful sources of water, and 2.6 billion people, which is around half the developing world, lack access to adequate sanitation. As Kathie Coles, an executive from the charity World of Water, describes, the situation will deteriorate. Over the next 20 years, an estimated 1.8 billion people will be living in countries or regions with an absolute water scarcity, and two-thirds of the world population may be under pressure conditions. This situation will only worsen, as rapidly growing urban areas place heavy pressure on water supplies. Of course, there have been different initiatives put into place around the world to help with water stress and scarcity. With larger scale projects, such as the construction of piper water systems, remain important objectives of many development agencies, a shortage of time and finances will leave hundreds of millions of people without access to safe water in the foreseeable future. Georgina Ronaldson, a spokesperson for the World Bank, recently announced a way to deal with the current difficulties. To help developing countries, various concerned organisations have developed the Safe Water System (SWS), which is an adaptable and flexible intervention that employs scientific methods appropriate for the developing world. The SWS has been criticised in various corners as being too amateurish, but Ronaldson continues to justify the approach. The use of relevant technologies is important, an in many places around the world, water provision efforts suffer from a lack of technical knowledge to effectively manage or adapt a system to a communitys changing needs. The SWS is a community-based, integrative approach to improving health and quality of life through increased access to improve water, sanitation and hygiene. Darren Stanford, a water quality engineer, explains the important three step methodology. The first is an assessment of water delivery system from catchment to consumer. The second is implementing appropriate interventions, which can include protection of source waters, improvements to the water deliver systems, introduction of SWS, improved sanitation and hygiene education. The third is the evaluation of the impact of the intervention of the health and quality of life of the consumers. One example of how poor water access can affect local populations is the problems of guinea worms in remote parts of Africa. This is a preventable parasitic infection that affects poor communities that lack safe drinking water. The infection is transmitted to people who drink water containing copepods (tiny water fleas) that are infected with the larvae of guinea worms. Once ingested these larvae take up to one year to grow into adult worms; the female worms then emerge from the skin anywhere on the body. Will Goodman, a doctor with WHO, says that this can affect communities in different ways. The emergence of the adult female worm can be very painful, slow and disabling and prevents people from working in their fields, tending their animals, going to school, and caring for their families. Currently many organisations are helping the last nine endemic countries (all in Sub-Saharan Africa) to eradicate guinea worm. Since the Guinea Worm Eradication programme began, the incidence of guinea worm has declined from 1.5 million cases per year in 20 endemic countries to 25,018 reported cases in 2008 from the nine remaining endemic countries. The eradication efforts make use of simple intervention for providing safe drinking water including using cloth filters and pipe filters to strain the infected copepods from water, applying chemicals to the water supplies to kill the larvae, and preventing infected people from entering and contaminating the water supplies, as the worms emerge from their skins. Providing borehole wells and other supplies of water in endemic village is another important component of the eradication efforts. The provision of borehole well is one of the principal aims of SWS. Many existing dug wells in communities only pierce the topsoil, do not reach deep enough and are therefore readily affected by drought or by the natural declines from summer to autumn in the water table. SWS borehole wells can pierce the bedrock and access a deeper aquifer with water that is not affected by surface drought. These are also unaffected by guinea worm infestation and water is much safer for human consumption.", "hypothesis": "One of main reasons behind declining availability of water is demand from different working segments of society.", "gold_label": "entailment"}
{"uid": "id_407", "premise": "Water stress and scarcity Water stress and scarcity occur when there is an imbalance between the availability of water and the demand for water. When we hear people talking about water stress and scarcity, we often think of drought but this is only one of several causes. Alex Karpov, a representative from the WHO explains some of the other issues that also impact the availability of fresh water, The deterioration of ground water and surface water quality, competition for water between different segments of society, for example, between agricultural, industrial, and domestic users, and even social and financial barriers, are all causes of water stress and scarcity today. While approximately three quarters of the earth are covered with water only a small proportion of it is available as fresh water. Of the available fresh water supplies, nearly 70% is withdrawn and used for irrigation to produce food, and the demand just keep growing. Although there is currently no global scarcity of water, more and more regions of the world are chronically short of water. At present, 1.1 billion people have little choice but to use potentially harmful sources of water, and 2.6 billion people, which is around half the developing world, lack access to adequate sanitation. As Kathie Coles, an executive from the charity World of Water, describes, the situation will deteriorate. Over the next 20 years, an estimated 1.8 billion people will be living in countries or regions with an absolute water scarcity, and two-thirds of the world population may be under pressure conditions. This situation will only worsen, as rapidly growing urban areas place heavy pressure on water supplies. Of course, there have been different initiatives put into place around the world to help with water stress and scarcity. With larger scale projects, such as the construction of piper water systems, remain important objectives of many development agencies, a shortage of time and finances will leave hundreds of millions of people without access to safe water in the foreseeable future. Georgina Ronaldson, a spokesperson for the World Bank, recently announced a way to deal with the current difficulties. To help developing countries, various concerned organisations have developed the Safe Water System (SWS), which is an adaptable and flexible intervention that employs scientific methods appropriate for the developing world. The SWS has been criticised in various corners as being too amateurish, but Ronaldson continues to justify the approach. The use of relevant technologies is important, an in many places around the world, water provision efforts suffer from a lack of technical knowledge to effectively manage or adapt a system to a communitys changing needs. The SWS is a community-based, integrative approach to improving health and quality of life through increased access to improve water, sanitation and hygiene. Darren Stanford, a water quality engineer, explains the important three step methodology. The first is an assessment of water delivery system from catchment to consumer. The second is implementing appropriate interventions, which can include protection of source waters, improvements to the water deliver systems, introduction of SWS, improved sanitation and hygiene education. The third is the evaluation of the impact of the intervention of the health and quality of life of the consumers. One example of how poor water access can affect local populations is the problems of guinea worms in remote parts of Africa. This is a preventable parasitic infection that affects poor communities that lack safe drinking water. The infection is transmitted to people who drink water containing copepods (tiny water fleas) that are infected with the larvae of guinea worms. Once ingested these larvae take up to one year to grow into adult worms; the female worms then emerge from the skin anywhere on the body. Will Goodman, a doctor with WHO, says that this can affect communities in different ways. The emergence of the adult female worm can be very painful, slow and disabling and prevents people from working in their fields, tending their animals, going to school, and caring for their families. Currently many organisations are helping the last nine endemic countries (all in Sub-Saharan Africa) to eradicate guinea worm. Since the Guinea Worm Eradication programme began, the incidence of guinea worm has declined from 1.5 million cases per year in 20 endemic countries to 25,018 reported cases in 2008 from the nine remaining endemic countries. The eradication efforts make use of simple intervention for providing safe drinking water including using cloth filters and pipe filters to strain the infected copepods from water, applying chemicals to the water supplies to kill the larvae, and preventing infected people from entering and contaminating the water supplies, as the worms emerge from their skins. Providing borehole wells and other supplies of water in endemic village is another important component of the eradication efforts. The provision of borehole well is one of the principal aims of SWS. Many existing dug wells in communities only pierce the topsoil, do not reach deep enough and are therefore readily affected by drought or by the natural declines from summer to autumn in the water table. SWS borehole wells can pierce the bedrock and access a deeper aquifer with water that is not affected by surface drought. These are also unaffected by guinea worm infestation and water is much safer for human consumption.", "hypothesis": "The SWS has been appreciated worldwide.", "gold_label": "contradiction"}
{"uid": "id_408", "premise": "Water stress and scarcity Water stress and scarcity occur when there is an imbalance between the availability of water and the demand for water. When we hear people talking about water stress and scarcity, we often think of drought but this is only one of several causes. Alex Karpov, a representative from the WHO explains some of the other issues that also impact the availability of fresh water, The deterioration of ground water and surface water quality, competition for water between different segments of society, for example, between agricultural, industrial, and domestic users, and even social and financial barriers, are all causes of water stress and scarcity today. While approximately three quarters of the earth are covered with water only a small proportion of it is available as fresh water. Of the available fresh water supplies, nearly 70% is withdrawn and used for irrigation to produce food, and the demand just keep growing. Although there is currently no global scarcity of water, more and more regions of the world are chronically short of water. At present, 1.1 billion people have little choice but to use potentially harmful sources of water, and 2.6 billion people, which is around half the developing world, lack access to adequate sanitation. As Kathie Coles, an executive from the charity World of Water, describes, the situation will deteriorate. Over the next 20 years, an estimated 1.8 billion people will be living in countries or regions with an absolute water scarcity, and two-thirds of the world population may be under pressure conditions. This situation will only worsen, as rapidly growing urban areas place heavy pressure on water supplies. Of course, there have been different initiatives put into place around the world to help with water stress and scarcity. With larger scale projects, such as the construction of piper water systems, remain important objectives of many development agencies, a shortage of time and finances will leave hundreds of millions of people without access to safe water in the foreseeable future. Georgina Ronaldson, a spokesperson for the World Bank, recently announced a way to deal with the current difficulties. To help developing countries, various concerned organisations have developed the Safe Water System (SWS), which is an adaptable and flexible intervention that employs scientific methods appropriate for the developing world. The SWS has been criticised in various corners as being too amateurish, but Ronaldson continues to justify the approach. The use of relevant technologies is important, an in many places around the world, water provision efforts suffer from a lack of technical knowledge to effectively manage or adapt a system to a communitys changing needs. The SWS is a community-based, integrative approach to improving health and quality of life through increased access to improve water, sanitation and hygiene. Darren Stanford, a water quality engineer, explains the important three step methodology. The first is an assessment of water delivery system from catchment to consumer. The second is implementing appropriate interventions, which can include protection of source waters, improvements to the water deliver systems, introduction of SWS, improved sanitation and hygiene education. The third is the evaluation of the impact of the intervention of the health and quality of life of the consumers. One example of how poor water access can affect local populations is the problems of guinea worms in remote parts of Africa. This is a preventable parasitic infection that affects poor communities that lack safe drinking water. The infection is transmitted to people who drink water containing copepods (tiny water fleas) that are infected with the larvae of guinea worms. Once ingested these larvae take up to one year to grow into adult worms; the female worms then emerge from the skin anywhere on the body. Will Goodman, a doctor with WHO, says that this can affect communities in different ways. The emergence of the adult female worm can be very painful, slow and disabling and prevents people from working in their fields, tending their animals, going to school, and caring for their families. Currently many organisations are helping the last nine endemic countries (all in Sub-Saharan Africa) to eradicate guinea worm. Since the Guinea Worm Eradication programme began, the incidence of guinea worm has declined from 1.5 million cases per year in 20 endemic countries to 25,018 reported cases in 2008 from the nine remaining endemic countries. The eradication efforts make use of simple intervention for providing safe drinking water including using cloth filters and pipe filters to strain the infected copepods from water, applying chemicals to the water supplies to kill the larvae, and preventing infected people from entering and contaminating the water supplies, as the worms emerge from their skins. Providing borehole wells and other supplies of water in endemic village is another important component of the eradication efforts. The provision of borehole well is one of the principal aims of SWS. Many existing dug wells in communities only pierce the topsoil, do not reach deep enough and are therefore readily affected by drought or by the natural declines from summer to autumn in the water table. SWS borehole wells can pierce the bedrock and access a deeper aquifer with water that is not affected by surface drought. These are also unaffected by guinea worm infestation and water is much safer for human consumption.", "hypothesis": "SWS has been implemented in more than 30 countries.", "gold_label": "neutral"}
{"uid": "id_409", "premise": "Water, the most common liquid used for cleaning, has a property called surface tension. Molecules in the body of the water are surrounded by other molecules, but at the surface a tension is created as molecules are only surrounded by other molecules on the waterside. This tension inhibits the cleaning process, as it slows the wetting of surface due to tension causing the water to bead up. This is where water droplets hold their shape and do not spread. For effective cleaning to take place surface tension must be reduced so that water can spread. Surface active agents, or surfactants, are chemicals, which are able to do this effectively.", "hypothesis": "The molecules on the waterside hinder the cleaning process.", "gold_label": "contradiction"}
{"uid": "id_410", "premise": "Water, the most common liquid used for cleaning, has a property called surface tension. Molecules in the body of the water are surrounded by other molecules, but at the surface a tension is created as molecules are only surrounded by other molecules on the waterside. This tension inhibits the cleaning process, as it slows the wetting of surface due to tension causing the water to bead up. This is where water droplets hold their shape and do not spread. For effective cleaning to take place surface tension must be reduced so that water can spread. Surface active agents, or surfactants, are chemicals, which are able to do this effectively.", "hypothesis": "Surface-active agents, or surfactants, are only used for cleaning.", "gold_label": "neutral"}
{"uid": "id_411", "premise": "Water, the most common liquid used for cleaning, has a property called surface tension. Molecules in the body of the water are surrounded by other molecules, but at the surface a tension is created as molecules are only surrounded by other molecules on the waterside. This tension inhibits the cleaning process, as it slows the wetting of surface due to tension causing the water to bead up. This is where water droplets hold their shape and do not spread. For effective cleaning to take place surface tension must be reduced so that water can spread. Surface active agents, or surfactants, are chemicals, which are able to do this effectively.", "hypothesis": "Water is the only known liquid used for cleaning.", "gold_label": "contradiction"}
{"uid": "id_412", "premise": "Water, the most common liquid used for cleaning, has a property called surface tension. Molecules in the body of the water are surrounded by other molecules, but at the surface a tension is created as molecules are only surrounded by other molecules on the waterside. This tension inhibits the cleaning process, as it slows the wetting of surface due to tension causing the water to bead up. This is where water droplets hold their shape and do not spread. For effective cleaning to take place surface tension must be reduced so that water can spread. Surface active agents, or surfactants, are chemicals, which are able to do this effectively.", "hypothesis": "If surfactant chemicals are added to water when cleaning a surface, surface tension will occur.", "gold_label": "contradiction"}
{"uid": "id_413", "premise": "Water, the most common liquid used for cleaning, has a property called surface tension. Molecules in the body of the water are surrounded by other molecules, but at the surface a tension is created as molecules are only surrounded by other molecules on the waterside. This tension inhibits the cleaning process, as it slows the wetting of surface due to tension causing the water to bead up. This is where water droplets hold their shape and do not spread. For effective cleaning to take place surface tension must be reduced so that water can spread. Surface-active agents, or surfactants, are chemicals, which are able to do this effectively.", "hypothesis": "Surface-active agents, or surfactants, are only used for cleaning.", "gold_label": "neutral"}
{"uid": "id_414", "premise": "Water, the most common liquid used for cleaning, has a property called surface tension. Molecules in the body of the water are surrounded by other molecules, but at the surface a tension is created as molecules are only surrounded by other molecules on the waterside. This tension inhibits the cleaning process, as it slows the wetting of surface due to tension causing the water to bead up. This is where water droplets hold their shape and do not spread. For effective cleaning to take place surface tension must be reduced so that water can spread. Surface-active agents, or surfactants, are chemicals, which are able to do this effectively.", "hypothesis": "Water is the only known liquid used for cleaning.", "gold_label": "contradiction"}
{"uid": "id_415", "premise": "Water, the most common liquid used for cleaning, has a property called surface tension. Molecules in the body of the water are surrounded by other molecules, but at the surface a tension is created as molecules are only surrounded by other molecules on the waterside. This tension inhibits the cleaning process, as it slows the wetting of surface due to tension causing the water to bead up. This is where water droplets hold their shape and do not spread. For effective cleaning to take place surface tension must be reduced so that water can spread. Surface-active agents, or surfactants, are chemicals, which are able to do this effectively.", "hypothesis": "If surfactant chemicals are added to water when cleaning a surface, surface tension will occur.", "gold_label": "contradiction"}
{"uid": "id_416", "premise": "Water, the most common liquid used for cleaning, has a property called surface tension. Molecules in the body of the water are surrounded by other molecules, but at the surface a tension is created as molecules are only surrounded by other molecules on the waterside. This tension inhibits the cleaning process, as it slows the wetting of surface due to tension causing the water to bead up. This is where water droplets hold their shape and do not spread. For effective cleaning to take place surface tension must be reduced so that water can spread. Surface-active agents, or surfactants, are chemicals, which are able to do this effectively.", "hypothesis": "The molecules on the waterside hinder the cleaning process.", "gold_label": "entailment"}
{"uid": "id_417", "premise": "Water, the most common liquid used for cleaning, has a property called surface tension. Molecules in the body of the water are surrounded by other molecules, but at the surface a tension is created as molecules are only surrounded by other molecules on the waterside. This tension inhibits the cleaning process, as it slows the wetting of surfaces due to tension causing the water to bead up. This is where water droplets hold their shape and do not spread. For effective cleaning to take place surface tension must be reduced so that water can spread. Surface-active agents, or surfactants, are chemicals which are able to do this effectively.", "hypothesis": "Water is the only known liquid used for cleaning.", "gold_label": "contradiction"}
{"uid": "id_418", "premise": "Water, the most common liquid used for cleaning, has a property called surface tension. Molecules in the body of the water are surrounded by other molecules, but at the surface a tension is created as molecules are only surrounded by other molecules on the waterside. This tension inhibits the cleaning process, as it slows the wetting of surfaces due to tension causing the water to bead up. This is where water droplets hold their shape and do not spread. For effective cleaning to take place surface tension must be reduced so that water can spread. Surface-active agents, or surfactants, are chemicals which are able to do this effectively.", "hypothesis": "the molecules on the waterside hinder the cleaning process.", "gold_label": "entailment"}
{"uid": "id_419", "premise": "Water, the most common liquid used for cleaning, has a property called surface tension. Molecules in the body of the water are surrounded by other molecules, but at the surface a tension is created as molecules are only surrounded by other molecules on the waterside. This tension inhibits the cleaning process, as it slows the wetting of surfaces due to tension causing the water to bead up. This is where water droplets hold their shape and do not spread. For effective cleaning to take place surface tension must be reduced so that water can spread. Surface-active agents, or surfactants, are chemicals which are able to do this effectively.", "hypothesis": "surface active agents, or surfactants, are only used for cleaning.", "gold_label": "neutral"}
{"uid": "id_420", "premise": "Waterfalls Waterfalls are places where rivers or streams direct their flow over vertical drops. They have always been a lure for their scenic beauty or, in the case of the biggest, their ability to showcase natures might and majesty. Niagara Falls, on the border of Canada and America (discharging the most water of all), is a magnet for visitors, as is Victoria Falls, also straddling an international boundary between Zimbabwe and Zambia, and presenting the single largest sheet of falling water in the world. Similarly, the remoteness and inaccessibility of the highest waterfall, Angel Falls, located deep in the middle of the Venezuelan jungle, has not stopped it from becoming one of the countrys top tourist attractions. There are many possible causes of waterfalls, but a common one is differences in rock type. When a river flows over a resistant rock bed, erosion is slow, but with the complex geological faulting of the Earths surface, softer patches of rock can be exposed. The water cuts into this, resulting in a minor turbulence at the boundary, stirring up pebbles and grit from the riverbed, which increases the erosive capacity of the current. And so a process begins whereby the river takes on two tiers, or levels, and a waterfall is born. Other more abrupt causes of waterfalls are earthquakes or landslides, which create fault lines in the land, or divert watercourses, respectively. Additionally, during past ice ages, glaciers scoured out many deep basins. These glaciers may have disappeared, but their feeder rivers can continue to flow as waterfalls into the remaining depressions. Obviously then, waterfalls come in a variety of shapes and sizes, as different as the local geology in which they are found, and this has resulted in an abundance of descriptive terms. The word cataract refers simply to a large powerful waterfall, while a cascade descends a series of rock steps. If these steps are very distinct, it is a tiered waterfall, and if each step is larger still, of approximately the same size, and with a significant pool of water at each base, it is known as a multi-step waterfall. If the falling water engages with the rock face, it often widens, to be called a horsetail waterfall, while if it does not touch the rock face at all, it is a plunge waterfall often the most picturesque. Regardless of such differences, all waterfalls have in common a vertical height and average flow of water. These features, taken together, are a measure of the waterfalls power, quantified using a ten-point logarithmic scale. Giant falls, such as Niagara, are graded at the very top of this scale, find smaller falls, which may occur in town creeks, at the bottom. Another common feature of larger falls is a plunge pool. This is caused by the rubble at the base of the falls, which is stirred and broken into smaller pieces. In the never-ending eddies and whirlpools, these pieces scour out a deep underwater basin. An interesting consequence is that such falls are in the process of retreat, since the softer material at the lower face suffers undercutting. This gives rise to rock shelters behind the falling water, which steadily become larger until the roof collapses, and the waterfall retreats significantly backward into the Earth. Of course, to people at large, a waterfall seems fixed and forever. Erosion is indeed a slow process; however, given a sufficiently powerful waterfall and the right sort of rock, the retreat can be over a meter a year. This would be clearly observable over a persons life time, and a fast-motion view, spanning several decades, would see an essentially unchanged height of falling water burrowing backwards with surprising evenness. Since this motion is towards higher elevations or through more hilly terrain, a host of geological features can be laid in the waterfalls retreating path. Victoria Falls are a prime example, with its lower reaches characterised by spectacular islands, gorges, and rock formations. This retreat occasionally causes problems, as can be seen with Niagara Falls. In just over ten millennia, the falls have moved almost 11 kilometres upstream. Since the Niagara river marks the border of Canada and America, as agreed in 1819, the detectable retreat of these falls since that time technically means that the Canadian frontier has advanced forward at the expense of America, although this argument has obviously caused dispute. More practically, with so much infrastructure, such as hotels, roads, bridges, and scenic viewpoints, all rigidly established, it remains important to limit the erosion. For this reason, the exposed ridges of the falls have been extensively strengthened, and underwater barriers installed to divert the more erosive of river currents. The most ambitious erosion-control measure took place in 1969 on Niagaras American Falls, whose retreat was nibbling away at American territory. The branch of the Niagara river which feeds these subsidiary falls was dammed, allowing the main Horseshoe Falls to absorb the excess flow. The then-completely-dry-and-exposed river bottom and cliff face allowed a team of US-army engineers to use bolts, cement, and brackets, to strengthen any unstable rock. Five months later, the temporary dam was destroyed with explosives, returning water to the falls, but with the inexorable erosion process having been slowed considerably.", "hypothesis": "Glaciers have produced the most waterfalls.", "gold_label": "neutral"}
{"uid": "id_421", "premise": "Waterfalls Waterfalls are places where rivers or streams direct their flow over vertical drops. They have always been a lure for their scenic beauty or, in the case of the biggest, their ability to showcase natures might and majesty. Niagara Falls, on the border of Canada and America (discharging the most water of all), is a magnet for visitors, as is Victoria Falls, also straddling an international boundary between Zimbabwe and Zambia, and presenting the single largest sheet of falling water in the world. Similarly, the remoteness and inaccessibility of the highest waterfall, Angel Falls, located deep in the middle of the Venezuelan jungle, has not stopped it from becoming one of the countrys top tourist attractions. There are many possible causes of waterfalls, but a common one is differences in rock type. When a river flows over a resistant rock bed, erosion is slow, but with the complex geological faulting of the Earths surface, softer patches of rock can be exposed. The water cuts into this, resulting in a minor turbulence at the boundary, stirring up pebbles and grit from the riverbed, which increases the erosive capacity of the current. And so a process begins whereby the river takes on two tiers, or levels, and a waterfall is born. Other more abrupt causes of waterfalls are earthquakes or landslides, which create fault lines in the land, or divert watercourses, respectively. Additionally, during past ice ages, glaciers scoured out many deep basins. These glaciers may have disappeared, but their feeder rivers can continue to flow as waterfalls into the remaining depressions. Obviously then, waterfalls come in a variety of shapes and sizes, as different as the local geology in which they are found, and this has resulted in an abundance of descriptive terms. The word cataract refers simply to a large powerful waterfall, while a cascade descends a series of rock steps. If these steps are very distinct, it is a tiered waterfall, and if each step is larger still, of approximately the same size, and with a significant pool of water at each base, it is known as a multi-step waterfall. If the falling water engages with the rock face, it often widens, to be called a horsetail waterfall, while if it does not touch the rock face at all, it is a plunge waterfall often the most picturesque. Regardless of such differences, all waterfalls have in common a vertical height and average flow of water. These features, taken together, are a measure of the waterfalls power, quantified using a ten-point logarithmic scale. Giant falls, such as Niagara, are graded at the very top of this scale, find smaller falls, which may occur in town creeks, at the bottom. Another common feature of larger falls is a plunge pool. This is caused by the rubble at the base of the falls, which is stirred and broken into smaller pieces. In the never-ending eddies and whirlpools, these pieces scour out a deep underwater basin. An interesting consequence is that such falls are in the process of retreat, since the softer material at the lower face suffers undercutting. This gives rise to rock shelters behind the falling water, which steadily become larger until the roof collapses, and the waterfall retreats significantly backward into the Earth. Of course, to people at large, a waterfall seems fixed and forever. Erosion is indeed a slow process; however, given a sufficiently powerful waterfall and the right sort of rock, the retreat can be over a meter a year. This would be clearly observable over a persons life time, and a fast-motion view, spanning several decades, would see an essentially unchanged height of falling water burrowing backwards with surprising evenness. Since this motion is towards higher elevations or through more hilly terrain, a host of geological features can be laid in the waterfalls retreating path. Victoria Falls are a prime example, with its lower reaches characterised by spectacular islands, gorges, and rock formations. This retreat occasionally causes problems, as can be seen with Niagara Falls. In just over ten millennia, the falls have moved almost 11 kilometres upstream. Since the Niagara river marks the border of Canada and America, as agreed in 1819, the detectable retreat of these falls since that time technically means that the Canadian frontier has advanced forward at the expense of America, although this argument has obviously caused dispute. More practically, with so much infrastructure, such as hotels, roads, bridges, and scenic viewpoints, all rigidly established, it remains important to limit the erosion. For this reason, the exposed ridges of the falls have been extensively strengthened, and underwater barriers installed to divert the more erosive of river currents. The most ambitious erosion-control measure took place in 1969 on Niagaras American Falls, whose retreat was nibbling away at American territory. The branch of the Niagara river which feeds these subsidiary falls was dammed, allowing the main Horseshoe Falls to absorb the excess flow. The then-completely-dry-and-exposed river bottom and cliff face allowed a team of US-army engineers to use bolts, cement, and brackets, to strengthen any unstable rock. Five months later, the temporary dam was destroyed with explosives, returning water to the falls, but with the inexorable erosion process having been slowed considerably.", "hypothesis": "Landslides can create waterfalls faster than erosion.", "gold_label": "entailment"}
{"uid": "id_422", "premise": "Waterfalls Waterfalls are places where rivers or streams direct their flow over vertical drops. They have always been a lure for their scenic beauty or, in the case of the biggest, their ability to showcase natures might and majesty. Niagara Falls, on the border of Canada and America (discharging the most water of all), is a magnet for visitors, as is Victoria Falls, also straddling an international boundary between Zimbabwe and Zambia, and presenting the single largest sheet of falling water in the world. Similarly, the remoteness and inaccessibility of the highest waterfall, Angel Falls, located deep in the middle of the Venezuelan jungle, has not stopped it from becoming one of the countrys top tourist attractions. There are many possible causes of waterfalls, but a common one is differences in rock type. When a river flows over a resistant rock bed, erosion is slow, but with the complex geological faulting of the Earths surface, softer patches of rock can be exposed. The water cuts into this, resulting in a minor turbulence at the boundary, stirring up pebbles and grit from the riverbed, which increases the erosive capacity of the current. And so a process begins whereby the river takes on two tiers, or levels, and a waterfall is born. Other more abrupt causes of waterfalls are earthquakes or landslides, which create fault lines in the land, or divert watercourses, respectively. Additionally, during past ice ages, glaciers scoured out many deep basins. These glaciers may have disappeared, but their feeder rivers can continue to flow as waterfalls into the remaining depressions. Obviously then, waterfalls come in a variety of shapes and sizes, as different as the local geology in which they are found, and this has resulted in an abundance of descriptive terms. The word cataract refers simply to a large powerful waterfall, while a cascade descends a series of rock steps. If these steps are very distinct, it is a tiered waterfall, and if each step is larger still, of approximately the same size, and with a significant pool of water at each base, it is known as a multi-step waterfall. If the falling water engages with the rock face, it often widens, to be called a horsetail waterfall, while if it does not touch the rock face at all, it is a plunge waterfall often the most picturesque. Regardless of such differences, all waterfalls have in common a vertical height and average flow of water. These features, taken together, are a measure of the waterfalls power, quantified using a ten-point logarithmic scale. Giant falls, such as Niagara, are graded at the very top of this scale, find smaller falls, which may occur in town creeks, at the bottom. Another common feature of larger falls is a plunge pool. This is caused by the rubble at the base of the falls, which is stirred and broken into smaller pieces. In the never-ending eddies and whirlpools, these pieces scour out a deep underwater basin. An interesting consequence is that such falls are in the process of retreat, since the softer material at the lower face suffers undercutting. This gives rise to rock shelters behind the falling water, which steadily become larger until the roof collapses, and the waterfall retreats significantly backward into the Earth. Of course, to people at large, a waterfall seems fixed and forever. Erosion is indeed a slow process; however, given a sufficiently powerful waterfall and the right sort of rock, the retreat can be over a meter a year. This would be clearly observable over a persons life time, and a fast-motion view, spanning several decades, would see an essentially unchanged height of falling water burrowing backwards with surprising evenness. Since this motion is towards higher elevations or through more hilly terrain, a host of geological features can be laid in the waterfalls retreating path. Victoria Falls are a prime example, with its lower reaches characterised by spectacular islands, gorges, and rock formations. This retreat occasionally causes problems, as can be seen with Niagara Falls. In just over ten millennia, the falls have moved almost 11 kilometres upstream. Since the Niagara river marks the border of Canada and America, as agreed in 1819, the detectable retreat of these falls since that time technically means that the Canadian frontier has advanced forward at the expense of America, although this argument has obviously caused dispute. More practically, with so much infrastructure, such as hotels, roads, bridges, and scenic viewpoints, all rigidly established, it remains important to limit the erosion. For this reason, the exposed ridges of the falls have been extensively strengthened, and underwater barriers installed to divert the more erosive of river currents. The most ambitious erosion-control measure took place in 1969 on Niagaras American Falls, whose retreat was nibbling away at American territory. The branch of the Niagara river which feeds these subsidiary falls was dammed, allowing the main Horseshoe Falls to absorb the excess flow. The then-completely-dry-and-exposed river bottom and cliff face allowed a team of US-army engineers to use bolts, cement, and brackets, to strengthen any unstable rock. Five months later, the temporary dam was destroyed with explosives, returning water to the falls, but with the inexorable erosion process having been slowed considerably.", "hypothesis": "Niagara, Victoria, and Angel Falls are on international boundaries.", "gold_label": "contradiction"}
{"uid": "id_423", "premise": "Waterfalls Waterfalls are places where rivers or streams direct their flow over vertical drops. They have always been a lure for their scenic beauty or, in the case of the biggest, their ability to showcase natures might and majesty. Niagara Falls, on the border of Canada and America (discharging the most water of all), is a magnet for visitors, as is Victoria Falls, also straddling an international boundary between Zimbabwe and Zambia, and presenting the single largest sheet of falling water in the world. Similarly, the remoteness and inaccessibility of the highest waterfall, Angel Falls, located deep in the middle of the Venezuelan jungle, has not stopped it from becoming one of the countrys top tourist attractions. There are many possible causes of waterfalls, but a common one is differences in rock type. When a river flows over a resistant rock bed, erosion is slow, but with the complex geological faulting of the Earths surface, softer patches of rock can be exposed. The water cuts into this, resulting in a minor turbulence at the boundary, stirring up pebbles and grit from the riverbed, which increases the erosive capacity of the current. And so a process begins whereby the river takes on two tiers, or levels, and a waterfall is born. Other more abrupt causes of waterfalls are earthquakes or landslides, which create fault lines in the land, or divert watercourses, respectively. Additionally, during past ice ages, glaciers scoured out many deep basins. These glaciers may have disappeared, but their feeder rivers can continue to flow as waterfalls into the remaining depressions. Obviously then, waterfalls come in a variety of shapes and sizes, as different as the local geology in which they are found, and this has resulted in an abundance of descriptive terms. The word cataract refers simply to a large powerful waterfall, while a cascade descends a series of rock steps. If these steps are very distinct, it is a tiered waterfall, and if each step is larger still, of approximately the same size, and with a significant pool of water at each base, it is known as a multi-step waterfall. If the falling water engages with the rock face, it often widens, to be called a horsetail waterfall, while if it does not touch the rock face at all, it is a plunge waterfall often the most picturesque. Regardless of such differences, all waterfalls have in common a vertical height and average flow of water. These features, taken together, are a measure of the waterfalls power, quantified using a ten-point logarithmic scale. Giant falls, such as Niagara, are graded at the very top of this scale, find smaller falls, which may occur in town creeks, at the bottom. Another common feature of larger falls is a plunge pool. This is caused by the rubble at the base of the falls, which is stirred and broken into smaller pieces. In the never-ending eddies and whirlpools, these pieces scour out a deep underwater basin. An interesting consequence is that such falls are in the process of retreat, since the softer material at the lower face suffers undercutting. This gives rise to rock shelters behind the falling water, which steadily become larger until the roof collapses, and the waterfall retreats significantly backward into the Earth. Of course, to people at large, a waterfall seems fixed and forever. Erosion is indeed a slow process; however, given a sufficiently powerful waterfall and the right sort of rock, the retreat can be over a meter a year. This would be clearly observable over a persons life time, and a fast-motion view, spanning several decades, would see an essentially unchanged height of falling water burrowing backwards with surprising evenness. Since this motion is towards higher elevations or through more hilly terrain, a host of geological features can be laid in the waterfalls retreating path. Victoria Falls are a prime example, with its lower reaches characterised by spectacular islands, gorges, and rock formations. This retreat occasionally causes problems, as can be seen with Niagara Falls. In just over ten millennia, the falls have moved almost 11 kilometres upstream. Since the Niagara river marks the border of Canada and America, as agreed in 1819, the detectable retreat of these falls since that time technically means that the Canadian frontier has advanced forward at the expense of America, although this argument has obviously caused dispute. More practically, with so much infrastructure, such as hotels, roads, bridges, and scenic viewpoints, all rigidly established, it remains important to limit the erosion. For this reason, the exposed ridges of the falls have been extensively strengthened, and underwater barriers installed to divert the more erosive of river currents. The most ambitious erosion-control measure took place in 1969 on Niagaras American Falls, whose retreat was nibbling away at American territory. The branch of the Niagara river which feeds these subsidiary falls was dammed, allowing the main Horseshoe Falls to absorb the excess flow. The then-completely-dry-and-exposed river bottom and cliff face allowed a team of US-army engineers to use bolts, cement, and brackets, to strengthen any unstable rock. Five months later, the temporary dam was destroyed with explosives, returning water to the falls, but with the inexorable erosion process having been slowed considerably.", "hypothesis": "Niagara is a Grade Ten waterfall.", "gold_label": "entailment"}
{"uid": "id_424", "premise": "Waterfalls Waterfalls are places where rivers or streams direct their flow over vertical drops. They have always been a lure for their scenic beauty or, in the case of the biggest, their ability to showcase natures might and majesty. Niagara Falls, on the border of Canada and America (discharging the most water of all), is a magnet for visitors, as is Victoria Falls, also straddling an international boundary between Zimbabwe and Zambia, and presenting the single largest sheet of falling water in the world. Similarly, the remoteness and inaccessibility of the highest waterfall, Angel Falls, located deep in the middle of the Venezuelan jungle, has not stopped it from becoming one of the countrys top tourist attractions. There are many possible causes of waterfalls, but a common one is differences in rock type. When a river flows over a resistant rock bed, erosion is slow, but with the complex geological faulting of the Earths surface, softer patches of rock can be exposed. The water cuts into this, resulting in a minor turbulence at the boundary, stirring up pebbles and grit from the riverbed, which increases the erosive capacity of the current. And so a process begins whereby the river takes on two tiers, or levels, and a waterfall is born. Other more abrupt causes of waterfalls are earthquakes or landslides, which create fault lines in the land, or divert watercourses, respectively. Additionally, during past ice ages, glaciers scoured out many deep basins. These glaciers may have disappeared, but their feeder rivers can continue to flow as waterfalls into the remaining depressions. Obviously then, waterfalls come in a variety of shapes and sizes, as different as the local geology in which they are found, and this has resulted in an abundance of descriptive terms. The word cataract refers simply to a large powerful waterfall, while a cascade descends a series of rock steps. If these steps are very distinct, it is a tiered waterfall, and if each step is larger still, of approximately the same size, and with a significant pool of water at each base, it is known as a multi-step waterfall. If the falling water engages with the rock face, it often widens, to be called a horsetail waterfall, while if it does not touch the rock face at all, it is a plunge waterfall often the most picturesque. Regardless of such differences, all waterfalls have in common a vertical height and average flow of water. These features, taken together, are a measure of the waterfalls power, quantified using a ten-point logarithmic scale. Giant falls, such as Niagara, are graded at the very top of this scale, find smaller falls, which may occur in town creeks, at the bottom. Another common feature of larger falls is a plunge pool. This is caused by the rubble at the base of the falls, which is stirred and broken into smaller pieces. In the never-ending eddies and whirlpools, these pieces scour out a deep underwater basin. An interesting consequence is that such falls are in the process of retreat, since the softer material at the lower face suffers undercutting. This gives rise to rock shelters behind the falling water, which steadily become larger until the roof collapses, and the waterfall retreats significantly backward into the Earth. Of course, to people at large, a waterfall seems fixed and forever. Erosion is indeed a slow process; however, given a sufficiently powerful waterfall and the right sort of rock, the retreat can be over a meter a year. This would be clearly observable over a persons life time, and a fast-motion view, spanning several decades, would see an essentially unchanged height of falling water burrowing backwards with surprising evenness. Since this motion is towards higher elevations or through more hilly terrain, a host of geological features can be laid in the waterfalls retreating path. Victoria Falls are a prime example, with its lower reaches characterised by spectacular islands, gorges, and rock formations. This retreat occasionally causes problems, as can be seen with Niagara Falls. In just over ten millennia, the falls have moved almost 11 kilometres upstream. Since the Niagara river marks the border of Canada and America, as agreed in 1819, the detectable retreat of these falls since that time technically means that the Canadian frontier has advanced forward at the expense of America, although this argument has obviously caused dispute. More practically, with so much infrastructure, such as hotels, roads, bridges, and scenic viewpoints, all rigidly established, it remains important to limit the erosion. For this reason, the exposed ridges of the falls have been extensively strengthened, and underwater barriers installed to divert the more erosive of river currents. The most ambitious erosion-control measure took place in 1969 on Niagaras American Falls, whose retreat was nibbling away at American territory. The branch of the Niagara river which feeds these subsidiary falls was dammed, allowing the main Horseshoe Falls to absorb the excess flow. The then-completely-dry-and-exposed river bottom and cliff face allowed a team of US-army engineers to use bolts, cement, and brackets, to strengthen any unstable rock. Five months later, the temporary dam was destroyed with explosives, returning water to the falls, but with the inexorable erosion process having been slowed considerably.", "hypothesis": "A tiered waterfall has the largest steps.", "gold_label": "contradiction"}
{"uid": "id_425", "premise": "Waterways. At the height of the Industrial Revolution in the mid-19th century, huge quantities of coal had to be transported from the pithead for iron smelting, manufacturing and domestic use. Coastal shipping, navigable rivers and horse-drawn carts were either slow or restrictive in comparison to the new purpose-built canals. A horse could pull a narrowboat weighing 50 times as much as a cart. The UK soon developed a national network of canals and by the middle of the 19th century almost all major towns and cities had a canal. At the same time, there was controversy as to the rival merits of transporting coal by canal or by railway. Stephensons locomotive could transport vast quantities of coal and other goods more quickly than by canal and also offered a new means of passenger transport. The canal network was doomed, and investment was redirected into railways, with local lines laid down in the coal districts developed into a national system for the whole of the country. Road haulage in the 20th century brought more competition for canals, and only a few remained open until the Second World War. Further declines were inevitable, and the use of canals for industrial purposes was minimal in the 1960s. However, interest in canals for leisure purposes had begun to grow, and some were restored and reopened by volun- teers in the 1970s. This trend has continued, with canals attracting government funding for restoration projects. Canals are now a major tourist industry, with more than 10 million visitors per year and 30,000 craft. Today there are more boats on the canals than at the height of the Industrial Revolution.", "hypothesis": "There are more narrowboats on the canals today than at the height of the Industrial Revolution.", "gold_label": "neutral"}
{"uid": "id_426", "premise": "Waterways. At the height of the Industrial Revolution in the mid-19th century, huge quantities of coal had to be transported from the pithead for iron smelting, manufacturing and domestic use. Coastal shipping, navigable rivers and horse-drawn carts were either slow or restrictive in comparison to the new purpose-built canals. A horse could pull a narrowboat weighing 50 times as much as a cart. The UK soon developed a national network of canals and by the middle of the 19th century almost all major towns and cities had a canal. At the same time, there was controversy as to the rival merits of transporting coal by canal or by railway. Stephensons locomotive could transport vast quantities of coal and other goods more quickly than by canal and also offered a new means of passenger transport. The canal network was doomed, and investment was redirected into railways, with local lines laid down in the coal districts developed into a national system for the whole of the country. Road haulage in the 20th century brought more competition for canals, and only a few remained open until the Second World War. Further declines were inevitable, and the use of canals for industrial purposes was minimal in the 1960s. However, interest in canals for leisure purposes had begun to grow, and some were restored and reopened by volun- teers in the 1970s. This trend has continued, with canals attracting government funding for restoration projects. Canals are now a major tourist industry, with more than 10 million visitors per year and 30,000 craft. Today there are more boats on the canals than at the height of the Industrial Revolution.", "hypothesis": "A network of canals was in place before a national system of railways.", "gold_label": "entailment"}
{"uid": "id_427", "premise": "Waterways. At the height of the Industrial Revolution in the mid-19th century, huge quantities of coal had to be transported from the pithead for iron smelting, manufacturing and domestic use. Coastal shipping, navigable rivers and horse-drawn carts were either slow or restrictive in comparison to the new purpose-built canals. A horse could pull a narrowboat weighing 50 times as much as a cart. The UK soon developed a national network of canals and by the middle of the 19th century almost all major towns and cities had a canal. At the same time, there was controversy as to the rival merits of transporting coal by canal or by railway. Stephensons locomotive could transport vast quantities of coal and other goods more quickly than by canal and also offered a new means of passenger transport. The canal network was doomed, and investment was redirected into railways, with local lines laid down in the coal districts developed into a national system for the whole of the country. Road haulage in the 20th century brought more competition for canals, and only a few remained open until the Second World War. Further declines were inevitable, and the use of canals for industrial purposes was minimal in the 1960s. However, interest in canals for leisure purposes had begun to grow, and some were restored and reopened by volun- teers in the 1970s. This trend has continued, with canals attracting government funding for restoration projects. Canals are now a major tourist industry, with more than 10 million visitors per year and 30,000 craft. Today there are more boats on the canals than at the height of the Industrial Revolution.", "hypothesis": "The 1960s saw more interest in canals for leisure than for industry.", "gold_label": "neutral"}
{"uid": "id_428", "premise": "Waterways. At the height of the Industrial Revolution in the mid-19th century, huge quantities of coal had to be transported from the pithead for iron smelting, manufacturing and domestic use. Coastal shipping, navigable rivers and horse-drawn carts were either slow or restrictive in comparison to the new purpose-built canals. A horse could pull a narrowboat weighing 50 times as much as a cart. The UK soon developed a national network of canals and by the middle of the 19th century almost all major towns and cities had a canal. At the same time, there was controversy as to the rival merits of transporting coal by canal or by railway. Stephensons locomotive could transport vast quantities of coal and other goods more quickly than by canal and also offered a new means of passenger transport. The canal network was doomed, and investment was redirected into railways, with local lines laid down in the coal districts developed into a national system for the whole of the country. Road haulage in the 20th century brought more competition for canals, and only a few remained open until the Second World War. Further declines were inevitable, and the use of canals for industrial purposes was minimal in the 1960s. However, interest in canals for leisure purposes had begun to grow, and some were restored and reopened by volun- teers in the 1970s. This trend has continued, with canals attracting government funding for restoration projects. Canals are now a major tourist industry, with more than 10 million visitors per year and 30,000 craft. Today there are more boats on the canals than at the height of the Industrial Revolution.", "hypothesis": "Stephensons locomotive succeeded because it could transport vast quantities of coal.", "gold_label": "contradiction"}
{"uid": "id_429", "premise": "Waves become swell when they leave the area of wind in which they were generated. Long after the wind that created it has stopped blowing, swell can continue to travel for thousands of miles and have a life span dependent on its wave length and the extent of ocean. The longer the wave the faster it travels and given sufficient sea room the longer it continues to travel. Wind can generate waves that travel faster than the wind itself and after a few hours of blowing the wave can be a long way ahead of the wind. At sea the arrival of a swell can be an indication of bad weather to come. If a long low swell arrives and it steadily increases in height then you should prepare for an approaching gale. If the swell remains long and low then it is likely that the wind that generated it is a long way away and you will escape it. Sometimes a swell generated far away crosses the waves generated by another wind. This can lead to a confused and in the extreme a dangerous sea state.", "hypothesis": "The sentence wind can generate waves that travel faster than the wind itself and after a few hours of blowing the wave can be a long way ahead of the wind would be more correct if it read Wind can generate waves that travel faster than the wind itself and after a few hours of blowing the swell can be a long way ahead of the wind.", "gold_label": "entailment"}
{"uid": "id_430", "premise": "Waves become swell when they leave the area of wind in which they were generated. Long after the wind that created it has stopped blowing, swell can continue to travel for thousands of miles and have a life span dependent on its wave length and the extent of ocean. The longer the wave the faster it travels and given sufficient sea room the longer it continues to travel. Wind can generate waves that travel faster than the wind itself and after a few hours of blowing the wave can be a long way ahead of the wind. At sea the arrival of a swell can be an indication of bad weather to come. If a long low swell arrives and it steadily increases in height then you should prepare for an approaching gale. If the swell remains long and low then it is likely that the wind that generated it is a long way away and you will escape it. Sometimes a swell generated far away crosses the waves generated by another wind. This can lead to a confused and in the extreme a dangerous sea state.", "hypothesis": "The views expressed in the passage are a statement of the findings of experimental investigations.", "gold_label": "neutral"}
{"uid": "id_431", "premise": "We are such optimists and opportunists that we find it hard not to adopt every new technology as soon as it comes along. As a result, we tend to discover the adverse consequences of these new practices the hard way. When problems emerge, as they inevitably seem to do, we set about a search for a better technology to help solve or alleviate the problems created by the first. However, some commentators argue that the debate over the introduction of new technology to genetically modify crops was not about an existing technology but about a proposed one, and for once they claim we tried to identify the benefits and risks before running blindly into them. The example is held up as a new way of assessing technologies before adopting them, and governments are urged to require companies to test and environmentally model new technologies before they are introduced. The difficulty with such a recommendation to governments is that not all will adopt them and most new technologies are introduced by multinational companies that exist beyond the control of one or a few governments. These companies therefore can choose to avoid new controls over their commercial activities by simply taking their developmental work elsewhere.", "hypothesis": "Some governments are already requiring companies to test and environmentally model the impact of new technologies before introducing them.", "gold_label": "neutral"}
{"uid": "id_432", "premise": "We are such optimists and opportunists that we find it hard not to adopt every new technology as soon as it comes along. As a result, we tend to discover the adverse consequences of these new practices the hard way. When problems emerge, as they inevitably seem to do, we set about a search for a better technology to help solve or alleviate the problems created by the first. However, some commentators argue that the debate over the introduction of new technology to genetically modify crops was not about an existing technology but about a proposed one, and for once they claim we tried to identify the benefits and risks before running blindly into them. The example is held up as a new way of assessing technologies before adopting them, and governments are urged to require companies to test and environmentally model new technologies before they are introduced. The difficulty with such a recommendation to governments is that not all will adopt them and most new technologies are introduced by multinational companies that exist beyond the control of one or a few governments. These companies therefore can choose to avoid new controls over their commercial activities by simply taking their developmental work elsewhere.", "hypothesis": "If our government were to adopt the recommendation then we could look forward to no longer lurching from one failed technology to the next.", "gold_label": "contradiction"}
{"uid": "id_433", "premise": "We are such optimists and opportunists that we find it hard not to adopt every new technology as soon as it comes along. As a result, we tend to discover the adverse consequences of these new practices the hard way. When problems emerge, as they inevitably seem to do, we set about a search for a better technology to help solve or alleviate the problems created by the first. However, some commentators argue that the debate over the introduction of new technology to genetically modify crops was not about an existing technology but about a proposed one, and for once they claim we tried to identify the benefits and risks before running blindly into them. The example is held up as a new way of assessing technologies before adopting them, and governments are urged to require companies to test and environmentally model new technologies before they are introduced. The difficulty with such a recommendation to governments is that not all will adopt them and most new technologies are introduced by multinational companies that exist beyond the control of one or a few governments. These companies therefore can choose to avoid new controls over their commercial activities by simply taking their developmental work elsewhere.", "hypothesis": "Environmental problems such as acid rain or ozone depletion might have been avoided had the new approach been adopted in the past.", "gold_label": "entailment"}
{"uid": "id_434", "premise": "We freeze some moments in time. Every culture has its frozen moments, events so important and personal that they transcend the normal flow of news. Americans of a certain age, for example, know precisely where they were and what they were doing when they learned that President Franklin D. Roosevelt had died. Another generation has absolute clarity of John F. Kennedys assassination. And no one who was older than a baby on 11 th September, 2001, will ever forget hearing about, or seeing, aeroplanes flying into skyscrapers. In 1945, people gathered around radios for the immediate news and stayed with the radio to hear more about their fallen leader and about the man who took his place. Newspapers printed extra editions and filled their columns with detail for days and weeks afterward. Magazines stepped back from the breaking news and offered perspective. 11 th September, 2001, followed a similarly grim pattern. We watched again and again the awful events. Consumers of news learned about the attacks, thanks to the television networks that showed the horror so graphically. Then we learned some of the hows and whys, as print publications and thoughtful broadcasters worked to bring depth to events that defied mere words. Journalists did some of their finest work and made me proud to be one of them. But something else, something profound, was happening this time around: news was being produced by regular people who had something to say and show, and not solely by the official news organisations that had traditionally decided how the first draft of history would look. This time, the first draft of history was being written in part, by the former audience. It was possible, it was inevitable, because of new publishing tools available on the Internet.", "hypothesis": "The author of this passage is a journalist.", "gold_label": "entailment"}
{"uid": "id_435", "premise": "We have all heard about bullying in schools, but bullying in the workplace is a huge problem in the UK which results in nearly 19 million days of lost output per year and costs the country 6 billion pounds annually. Workplace bullying is the abuse of a position of power by one individual over another. Otherwise known as harassment, intimidation, aggression, coercive management and by other euphemisms, bullying in the workplace can take many forms involving gender, race or age. In a nutshell, workplace bullying means behaviour that is humiliating or offensive towards some individual. This kind of bullying ranges from violence to less obvious actions like deliberately ignoring a fellow worker.", "hypothesis": "Deliberately ignoring a colleague is a form of bullying.", "gold_label": "entailment"}
{"uid": "id_436", "premise": "We have all heard about bullying in schools, but bullying in the workplace is a huge problem in the UK which results in nearly 19 million days of lost output per year and costs the country 6 billion pounds annually. Workplace bullying is the abuse of a position of power by one individual over another. Otherwise known as harassment, intimidation, aggression, coercive management and by other euphemisms, bullying in the workplace can take many forms involving gender, race or age. In a nutshell, workplace bullying means behaviour that is humiliating or offensive towards some individual. This kind of bullying ranges from violence to less obvious actions like deliberately ignoring a fellow worker.", "hypothesis": "Bullying in the workplace hinders UK economic output.", "gold_label": "entailment"}
{"uid": "id_437", "premise": "We have all heard about bullying in schools, but bullying in the workplace is a huge problem in the UK which results in nearly 19 million days of lost output per year and costs the country 6 billion pounds annually. Workplace bullying is the abuse of a position of power by one individual over another. Otherwise known as harassment, intimidation, aggression, coercive management and by other euphemisms, bullying in the workplace can take many forms involving gender, race or age. In a nutshell, workplace bullying means behaviour that is humiliating or offensive towards some individual. This kind of bullying ranges from violence to less obvious actions like deliberately ignoring a fellow worker.", "hypothesis": "Another name for workplace bullying is coercive management.", "gold_label": "entailment"}
{"uid": "id_438", "premise": "We have all heard about bullying in schools, but bullying in the workplace is a huge problem in the UK which results in nearly 19 million days of lost output per year and costs the country 6 billion pounds annually. Workplace bullying is the abuse of a position of power by one individual over another. Otherwise known as harassment, intimidation, aggression, coercive management and by other euphemisms, bullying in the workplace can take many forms involving gender, race or age. In a nutshell, workplace bullying means behaviour that is humiliating or offensive towards some individual. This kind of bullying ranges from violence to less obvious actions like deliberately ignoring a fellow worker.", "hypothesis": "Bullying in the workplace is sometimes caused by religious intolerance.", "gold_label": "neutral"}
{"uid": "id_439", "premise": "We know the city where HIV first emerged It is easy to see why AIDS seemed so mysterious and frightening when US medics first encountered it 35 years ago. The condition robbed young, healthy people of their strong immune system, leaving them weak and vulnerable. And it seemed to come out of nowhere. Today we know much more how and why HIV the virus that leads to AIDS has become a global pandemic. Unsurprisingly, sex workers unwittingly played a part. But no less important were the roles of trade, the collapse of colonialism, and 20th Century sociopolitical reform. HIV did not really appear out of nowhere, of course. It probably began as a virus affecting monkeys and apes in west central Africa. From there it jumped species into humans on several occasions, perhaps because people ate infected bushmeat. Some people carry a version of HIV closely related to that seen in sooty mangabey monkeys, for instance. But HIV that came from monkeys has not become a global problem. We are more closely related to apes, like gorillas and chimpanzees, than we are to monkeys. But even when HIV has passed into human populations from these apes, it has not necessarily turned into a widespread health issue. HIV originating from apes typically belongs to a type of virus called HIV-1. One is called HIV-1 group O, and human cases are largely confined to west Africa. In fact, only one form of HIV has spread far and wide after jumping to humans. This version, which probably originated from chimpanzees, is called HIV-1 group M (for major). More than 90% of HIV infections belong in group M. Which raises an obvious question: whats so special about HIV-1 group M? A study published in 2014 suggests a surprising answer: there might be nothing particularly special about group M. It is not especially infectious, as you might expect. Instead, it seems that this form of HIV simply took advantage of events. Ecological rather than evolutionary factors drove its rapid spread, says Nuno Faria at the University of Oxford in the UK. Faria and his colleagues built a family tree of HIV, by looking at a diverse array of HIV genomes collected from about 800 infected people from central Africa. Genomes pick up new mutations at a fairly steady rate, so by comparing two genome sequences and counting the differences they could work out when the two last shared a common ancestor. This technique is widely used, for example to establish that our common ancestor with chimpanzees lived at least 7 million years ago. RNA viruses such as HIV evolve approximately 1 million times faster than human DNA, says Faria. This means the HIV molecular clock ticks very fast indeed. It ticks so fast, Faria and his colleagues found that the HIV genomes all shared a common ancestor that existed no more than 100 years ago. The HIV-1 group M pandemic probably first began in the 1920s. Then the team went further. Because they knew where each of the HIV samples had been collected, they could place the origin of the pandemic in a specific city: Kinshasa, now the capital of the Democratic Republic of Congo. At this point, the researchers changed tack. They turned to historical records to work out why HIV infections in an African city in the 1920s could ultimately spark a pandemic. A likely sequence of events quickly became obvious. In the 1920s, DR Congo was a Belgian colony and Kinshasa then known as Leopoldville had just been made the capital. The city became a very attractive destination for young working men seeking their fortunes, and for sex workers only too willing to help them spend their earnings. The virus spread quickly through the population. It did not remain confined to the city. The researchers discovered that the capital of the Belgian Congo was, in the 1920s, one of the best connected cities in Africa. Taking full advantage of an extensive rail network used by hundreds of thousands of people each year, the virus spread to cities 900 miles (1500km) away in just 20 years. Everything was in place for an explosion in infection rates in the 1960s. The beginning of that decade brought another change. Belgian Congo gained its independence, and became an attractive source of employment to French speakers elsewhere in the world, including Haiti. When these young Haitians returned home a few years later they took a particular form of HIV-1 group M, called subtype B, to the western side of the Atlantic. It arrived in the US in the 1970s, just as sexual liberation and homophobic attitudes were leading to concentrations of gay men in cosmopolitan cities like New York and San Francisco. Once more, HIV took advantage of the sociopolitical situation to spread quickly through the US and Europe. There is no reason to believe that other subtypes would not have spread as quickly as subtype B, given similar ecological circumstances, says Faria. The story of the spread of HIV is not over yet. For instance, in 2015 there was an outbreak in the US state of Indiana, associated with drug injecting. The US Centers for Disease Control and Prevention has been analyzing the HIV genome sequences and data about location and time of infection, says Yonatan Grad at the Harvard School of Public Health in Boston, Massachusetts. These data help to understand the extent of the outbreak, and will further help to understand when public health interventions have worked. This approach can work for other pathogens. In 2014, Grad and his colleague Marc Lipsitch published an investigation into the spread of drug-resistant gonorrhoea across the US. Because we had representative sequences from individuals in different cities at different times and with different sexual orientations, we could show the spread was from the west of the country to the east, says Lipsitch. Whats more, they could confirm that the drug-resistant form of gonorrhoea appeared to have circulated predominantly in men who have sex with men. That could prompt increased screening in these at-risk populations, in an effort to reduce further spread. In other words, there is real power to studying pathogens like HIV and gonorrhoea through the prism of human society.", "hypothesis": "Humans are not closely related to monkey.", "gold_label": "neutral"}
{"uid": "id_440", "premise": "We know the city where HIV first emerged It is easy to see why AIDS seemed so mysterious and frightening when US medics first encountered it 35 years ago. The condition robbed young, healthy people of their strong immune system, leaving them weak and vulnerable. And it seemed to come out of nowhere. Today we know much more how and why HIV the virus that leads to AIDS has become a global pandemic. Unsurprisingly, sex workers unwittingly played a part. But no less important were the roles of trade, the collapse of colonialism, and 20th Century sociopolitical reform. HIV did not really appear out of nowhere, of course. It probably began as a virus affecting monkeys and apes in west central Africa. From there it jumped species into humans on several occasions, perhaps because people ate infected bushmeat. Some people carry a version of HIV closely related to that seen in sooty mangabey monkeys, for instance. But HIV that came from monkeys has not become a global problem. We are more closely related to apes, like gorillas and chimpanzees, than we are to monkeys. But even when HIV has passed into human populations from these apes, it has not necessarily turned into a widespread health issue. HIV originating from apes typically belongs to a type of virus called HIV-1. One is called HIV-1 group O, and human cases are largely confined to west Africa. In fact, only one form of HIV has spread far and wide after jumping to humans. This version, which probably originated from chimpanzees, is called HIV-1 group M (for major). More than 90% of HIV infections belong in group M. Which raises an obvious question: whats so special about HIV-1 group M? A study published in 2014 suggests a surprising answer: there might be nothing particularly special about group M. It is not especially infectious, as you might expect. Instead, it seems that this form of HIV simply took advantage of events. Ecological rather than evolutionary factors drove its rapid spread, says Nuno Faria at the University of Oxford in the UK. Faria and his colleagues built a family tree of HIV, by looking at a diverse array of HIV genomes collected from about 800 infected people from central Africa. Genomes pick up new mutations at a fairly steady rate, so by comparing two genome sequences and counting the differences they could work out when the two last shared a common ancestor. This technique is widely used, for example to establish that our common ancestor with chimpanzees lived at least 7 million years ago. RNA viruses such as HIV evolve approximately 1 million times faster than human DNA, says Faria. This means the HIV molecular clock ticks very fast indeed. It ticks so fast, Faria and his colleagues found that the HIV genomes all shared a common ancestor that existed no more than 100 years ago. The HIV-1 group M pandemic probably first began in the 1920s. Then the team went further. Because they knew where each of the HIV samples had been collected, they could place the origin of the pandemic in a specific city: Kinshasa, now the capital of the Democratic Republic of Congo. At this point, the researchers changed tack. They turned to historical records to work out why HIV infections in an African city in the 1920s could ultimately spark a pandemic. A likely sequence of events quickly became obvious. In the 1920s, DR Congo was a Belgian colony and Kinshasa then known as Leopoldville had just been made the capital. The city became a very attractive destination for young working men seeking their fortunes, and for sex workers only too willing to help them spend their earnings. The virus spread quickly through the population. It did not remain confined to the city. The researchers discovered that the capital of the Belgian Congo was, in the 1920s, one of the best connected cities in Africa. Taking full advantage of an extensive rail network used by hundreds of thousands of people each year, the virus spread to cities 900 miles (1500km) away in just 20 years. Everything was in place for an explosion in infection rates in the 1960s. The beginning of that decade brought another change. Belgian Congo gained its independence, and became an attractive source of employment to French speakers elsewhere in the world, including Haiti. When these young Haitians returned home a few years later they took a particular form of HIV-1 group M, called subtype B, to the western side of the Atlantic. It arrived in the US in the 1970s, just as sexual liberation and homophobic attitudes were leading to concentrations of gay men in cosmopolitan cities like New York and San Francisco. Once more, HIV took advantage of the sociopolitical situation to spread quickly through the US and Europe. There is no reason to believe that other subtypes would not have spread as quickly as subtype B, given similar ecological circumstances, says Faria. The story of the spread of HIV is not over yet. For instance, in 2015 there was an outbreak in the US state of Indiana, associated with drug injecting. The US Centers for Disease Control and Prevention has been analyzing the HIV genome sequences and data about location and time of infection, says Yonatan Grad at the Harvard School of Public Health in Boston, Massachusetts. These data help to understand the extent of the outbreak, and will further help to understand when public health interventions have worked. This approach can work for other pathogens. In 2014, Grad and his colleague Marc Lipsitch published an investigation into the spread of drug-resistant gonorrhoea across the US. Because we had representative sequences from individuals in different cities at different times and with different sexual orientations, we could show the spread was from the west of the country to the east, says Lipsitch. Whats more, they could confirm that the drug-resistant form of gonorrhoea appeared to have circulated predominantly in men who have sex with men. That could prompt increased screening in these at-risk populations, in an effort to reduce further spread. In other words, there is real power to studying pathogens like HIV and gonorrhoea through the prism of human society.", "hypothesis": "It is believed that HIV appeared out of nowhere.", "gold_label": "contradiction"}
{"uid": "id_441", "premise": "We know the city where HIV first emerged It is easy to see why AIDS seemed so mysterious and frightening when US medics first encountered it 35 years ago. The condition robbed young, healthy people of their strong immune system, leaving them weak and vulnerable. And it seemed to come out of nowhere. Today we know much more how and why HIV the virus that leads to AIDS has become a global pandemic. Unsurprisingly, sex workers unwittingly played a part. But no less important were the roles of trade, the collapse of colonialism, and 20th Century sociopolitical reform. HIV did not really appear out of nowhere, of course. It probably began as a virus affecting monkeys and apes in west central Africa. From there it jumped species into humans on several occasions, perhaps because people ate infected bushmeat. Some people carry a version of HIV closely related to that seen in sooty mangabey monkeys, for instance. But HIV that came from monkeys has not become a global problem. We are more closely related to apes, like gorillas and chimpanzees, than we are to monkeys. But even when HIV has passed into human populations from these apes, it has not necessarily turned into a widespread health issue. HIV originating from apes typically belongs to a type of virus called HIV-1. One is called HIV-1 group O, and human cases are largely confined to west Africa. In fact, only one form of HIV has spread far and wide after jumping to humans. This version, which probably originated from chimpanzees, is called HIV-1 group M (for major). More than 90% of HIV infections belong in group M. Which raises an obvious question: whats so special about HIV-1 group M? A study published in 2014 suggests a surprising answer: there might be nothing particularly special about group M. It is not especially infectious, as you might expect. Instead, it seems that this form of HIV simply took advantage of events. Ecological rather than evolutionary factors drove its rapid spread, says Nuno Faria at the University of Oxford in the UK. Faria and his colleagues built a family tree of HIV, by looking at a diverse array of HIV genomes collected from about 800 infected people from central Africa. Genomes pick up new mutations at a fairly steady rate, so by comparing two genome sequences and counting the differences they could work out when the two last shared a common ancestor. This technique is widely used, for example to establish that our common ancestor with chimpanzees lived at least 7 million years ago. RNA viruses such as HIV evolve approximately 1 million times faster than human DNA, says Faria. This means the HIV molecular clock ticks very fast indeed. It ticks so fast, Faria and his colleagues found that the HIV genomes all shared a common ancestor that existed no more than 100 years ago. The HIV-1 group M pandemic probably first began in the 1920s. Then the team went further. Because they knew where each of the HIV samples had been collected, they could place the origin of the pandemic in a specific city: Kinshasa, now the capital of the Democratic Republic of Congo. At this point, the researchers changed tack. They turned to historical records to work out why HIV infections in an African city in the 1920s could ultimately spark a pandemic. A likely sequence of events quickly became obvious. In the 1920s, DR Congo was a Belgian colony and Kinshasa then known as Leopoldville had just been made the capital. The city became a very attractive destination for young working men seeking their fortunes, and for sex workers only too willing to help them spend their earnings. The virus spread quickly through the population. It did not remain confined to the city. The researchers discovered that the capital of the Belgian Congo was, in the 1920s, one of the best connected cities in Africa. Taking full advantage of an extensive rail network used by hundreds of thousands of people each year, the virus spread to cities 900 miles (1500km) away in just 20 years. Everything was in place for an explosion in infection rates in the 1960s. The beginning of that decade brought another change. Belgian Congo gained its independence, and became an attractive source of employment to French speakers elsewhere in the world, including Haiti. When these young Haitians returned home a few years later they took a particular form of HIV-1 group M, called subtype B, to the western side of the Atlantic. It arrived in the US in the 1970s, just as sexual liberation and homophobic attitudes were leading to concentrations of gay men in cosmopolitan cities like New York and San Francisco. Once more, HIV took advantage of the sociopolitical situation to spread quickly through the US and Europe. There is no reason to believe that other subtypes would not have spread as quickly as subtype B, given similar ecological circumstances, says Faria. The story of the spread of HIV is not over yet. For instance, in 2015 there was an outbreak in the US state of Indiana, associated with drug injecting. The US Centers for Disease Control and Prevention has been analyzing the HIV genome sequences and data about location and time of infection, says Yonatan Grad at the Harvard School of Public Health in Boston, Massachusetts. These data help to understand the extent of the outbreak, and will further help to understand when public health interventions have worked. This approach can work for other pathogens. In 2014, Grad and his colleague Marc Lipsitch published an investigation into the spread of drug-resistant gonorrhoea across the US. Because we had representative sequences from individuals in different cities at different times and with different sexual orientations, we could show the spread was from the west of the country to the east, says Lipsitch. Whats more, they could confirm that the drug-resistant form of gonorrhoea appeared to have circulated predominantly in men who have sex with men. That could prompt increased screening in these at-risk populations, in an effort to reduce further spread. In other words, there is real power to studying pathogens like HIV and gonorrhoea through the prism of human society.", "hypothesis": "HIV-1 group O originated in 1920s.", "gold_label": "neutral"}
{"uid": "id_442", "premise": "We know the city where HIV first emerged It is easy to see why AIDS seemed so mysterious and frightening when US medics first encountered it 35 years ago. The condition robbed young, healthy people of their strong immune system, leaving them weak and vulnerable. And it seemed to come out of nowhere. Today we know much more how and why HIV the virus that leads to AIDS has become a global pandemic. Unsurprisingly, sex workers unwittingly played a part. But no less important were the roles of trade, the collapse of colonialism, and 20th Century sociopolitical reform. HIV did not really appear out of nowhere, of course. It probably began as a virus affecting monkeys and apes in west central Africa. From there it jumped species into humans on several occasions, perhaps because people ate infected bushmeat. Some people carry a version of HIV closely related to that seen in sooty mangabey monkeys, for instance. But HIV that came from monkeys has not become a global problem. We are more closely related to apes, like gorillas and chimpanzees, than we are to monkeys. But even when HIV has passed into human populations from these apes, it has not necessarily turned into a widespread health issue. HIV originating from apes typically belongs to a type of virus called HIV-1. One is called HIV-1 group O, and human cases are largely confined to west Africa. In fact, only one form of HIV has spread far and wide after jumping to humans. This version, which probably originated from chimpanzees, is called HIV-1 group M (for major). More than 90% of HIV infections belong in group M. Which raises an obvious question: whats so special about HIV-1 group M? A study published in 2014 suggests a surprising answer: there might be nothing particularly special about group M. It is not especially infectious, as you might expect. Instead, it seems that this form of HIV simply took advantage of events. Ecological rather than evolutionary factors drove its rapid spread, says Nuno Faria at the University of Oxford in the UK. Faria and his colleagues built a family tree of HIV, by looking at a diverse array of HIV genomes collected from about 800 infected people from central Africa. Genomes pick up new mutations at a fairly steady rate, so by comparing two genome sequences and counting the differences they could work out when the two last shared a common ancestor. This technique is widely used, for example to establish that our common ancestor with chimpanzees lived at least 7 million years ago. RNA viruses such as HIV evolve approximately 1 million times faster than human DNA, says Faria. This means the HIV molecular clock ticks very fast indeed. It ticks so fast, Faria and his colleagues found that the HIV genomes all shared a common ancestor that existed no more than 100 years ago. The HIV-1 group M pandemic probably first began in the 1920s. Then the team went further. Because they knew where each of the HIV samples had been collected, they could place the origin of the pandemic in a specific city: Kinshasa, now the capital of the Democratic Republic of Congo. At this point, the researchers changed tack. They turned to historical records to work out why HIV infections in an African city in the 1920s could ultimately spark a pandemic. A likely sequence of events quickly became obvious. In the 1920s, DR Congo was a Belgian colony and Kinshasa then known as Leopoldville had just been made the capital. The city became a very attractive destination for young working men seeking their fortunes, and for sex workers only too willing to help them spend their earnings. The virus spread quickly through the population. It did not remain confined to the city. The researchers discovered that the capital of the Belgian Congo was, in the 1920s, one of the best connected cities in Africa. Taking full advantage of an extensive rail network used by hundreds of thousands of people each year, the virus spread to cities 900 miles (1500km) away in just 20 years. Everything was in place for an explosion in infection rates in the 1960s. The beginning of that decade brought another change. Belgian Congo gained its independence, and became an attractive source of employment to French speakers elsewhere in the world, including Haiti. When these young Haitians returned home a few years later they took a particular form of HIV-1 group M, called subtype B, to the western side of the Atlantic. It arrived in the US in the 1970s, just as sexual liberation and homophobic attitudes were leading to concentrations of gay men in cosmopolitan cities like New York and San Francisco. Once more, HIV took advantage of the sociopolitical situation to spread quickly through the US and Europe. There is no reason to believe that other subtypes would not have spread as quickly as subtype B, given similar ecological circumstances, says Faria. The story of the spread of HIV is not over yet. For instance, in 2015 there was an outbreak in the US state of Indiana, associated with drug injecting. The US Centers for Disease Control and Prevention has been analyzing the HIV genome sequences and data about location and time of infection, says Yonatan Grad at the Harvard School of Public Health in Boston, Massachusetts. These data help to understand the extent of the outbreak, and will further help to understand when public health interventions have worked. This approach can work for other pathogens. In 2014, Grad and his colleague Marc Lipsitch published an investigation into the spread of drug-resistant gonorrhoea across the US. Because we had representative sequences from individuals in different cities at different times and with different sexual orientations, we could show the spread was from the west of the country to the east, says Lipsitch. Whats more, they could confirm that the drug-resistant form of gonorrhoea appeared to have circulated predominantly in men who have sex with men. That could prompt increased screening in these at-risk populations, in an effort to reduce further spread. In other words, there is real power to studying pathogens like HIV and gonorrhoea through the prism of human society.", "hypothesis": "HIV-1 group M has something special.", "gold_label": "contradiction"}
{"uid": "id_443", "premise": "We know the city where HIV first emerged It is easy to see why AIDS seemed so mysterious and frightening when US medics first encountered it 35 years ago. The condition robbed young, healthy people of their strong immune system, leaving them weak and vulnerable. And it seemed to come out of nowhere. Today we know much more how and why HIV the virus that leads to AIDS has become a global pandemic. Unsurprisingly, sex workers unwittingly played a part. But no less important were the roles of trade, the collapse of colonialism, and 20th Century sociopolitical reform. HIV did not really appear out of nowhere, of course. It probably began as a virus affecting monkeys and apes in west central Africa. From there it jumped species into humans on several occasions, perhaps because people ate infected bushmeat. Some people carry a version of HIV closely related to that seen in sooty mangabey monkeys, for instance. But HIV that came from monkeys has not become a global problem. We are more closely related to apes, like gorillas and chimpanzees, than we are to monkeys. But even when HIV has passed into human populations from these apes, it has not necessarily turned into a widespread health issue. HIV originating from apes typically belongs to a type of virus called HIV-1. One is called HIV-1 group O, and human cases are largely confined to west Africa. In fact, only one form of HIV has spread far and wide after jumping to humans. This version, which probably originated from chimpanzees, is called HIV-1 group M (for major). More than 90% of HIV infections belong in group M. Which raises an obvious question: whats so special about HIV-1 group M? A study published in 2014 suggests a surprising answer: there might be nothing particularly special about group M. It is not especially infectious, as you might expect. Instead, it seems that this form of HIV simply took advantage of events. Ecological rather than evolutionary factors drove its rapid spread, says Nuno Faria at the University of Oxford in the UK. Faria and his colleagues built a family tree of HIV, by looking at a diverse array of HIV genomes collected from about 800 infected people from central Africa. Genomes pick up new mutations at a fairly steady rate, so by comparing two genome sequences and counting the differences they could work out when the two last shared a common ancestor. This technique is widely used, for example to establish that our common ancestor with chimpanzees lived at least 7 million years ago. RNA viruses such as HIV evolve approximately 1 million times faster than human DNA, says Faria. This means the HIV molecular clock ticks very fast indeed. It ticks so fast, Faria and his colleagues found that the HIV genomes all shared a common ancestor that existed no more than 100 years ago. The HIV-1 group M pandemic probably first began in the 1920s. Then the team went further. Because they knew where each of the HIV samples had been collected, they could place the origin of the pandemic in a specific city: Kinshasa, now the capital of the Democratic Republic of Congo. At this point, the researchers changed tack. They turned to historical records to work out why HIV infections in an African city in the 1920s could ultimately spark a pandemic. A likely sequence of events quickly became obvious. In the 1920s, DR Congo was a Belgian colony and Kinshasa then known as Leopoldville had just been made the capital. The city became a very attractive destination for young working men seeking their fortunes, and for sex workers only too willing to help them spend their earnings. The virus spread quickly through the population. It did not remain confined to the city. The researchers discovered that the capital of the Belgian Congo was, in the 1920s, one of the best connected cities in Africa. Taking full advantage of an extensive rail network used by hundreds of thousands of people each year, the virus spread to cities 900 miles (1500km) away in just 20 years. Everything was in place for an explosion in infection rates in the 1960s. The beginning of that decade brought another change. Belgian Congo gained its independence, and became an attractive source of employment to French speakers elsewhere in the world, including Haiti. When these young Haitians returned home a few years later they took a particular form of HIV-1 group M, called subtype B, to the western side of the Atlantic. It arrived in the US in the 1970s, just as sexual liberation and homophobic attitudes were leading to concentrations of gay men in cosmopolitan cities like New York and San Francisco. Once more, HIV took advantage of the sociopolitical situation to spread quickly through the US and Europe. There is no reason to believe that other subtypes would not have spread as quickly as subtype B, given similar ecological circumstances, says Faria. The story of the spread of HIV is not over yet. For instance, in 2015 there was an outbreak in the US state of Indiana, associated with drug injecting. The US Centers for Disease Control and Prevention has been analyzing the HIV genome sequences and data about location and time of infection, says Yonatan Grad at the Harvard School of Public Health in Boston, Massachusetts. These data help to understand the extent of the outbreak, and will further help to understand when public health interventions have worked. This approach can work for other pathogens. In 2014, Grad and his colleague Marc Lipsitch published an investigation into the spread of drug-resistant gonorrhoea across the US. Because we had representative sequences from individuals in different cities at different times and with different sexual orientations, we could show the spread was from the west of the country to the east, says Lipsitch. Whats more, they could confirm that the drug-resistant form of gonorrhoea appeared to have circulated predominantly in men who have sex with men. That could prompt increased screening in these at-risk populations, in an effort to reduce further spread. In other words, there is real power to studying pathogens like HIV and gonorrhoea through the prism of human society.", "hypothesis": "Human DNA evolves approximately 1 million times slower than HIV.", "gold_label": "entailment"}
{"uid": "id_444", "premise": "We know the city where HIV first emerged It is easy to see why AIDS seemed so mysterious and frightening when US medics first encountered it 35 years ago. The condition robbed young, healthy people of their strong immune system, leaving them weak and vulnerable. And it seemed to come out of nowhere. Today we know much more how and why HIV the virus that leads to AIDS has become a global pandemic. Unsurprisingly, sex workers unwittingly played a part. But no less important were the roles of trade, the collapse of colonialism, and 20th Century sociopolitical reform. HIV did not really appear out of nowhere, of course. It probably began as a virus affecting monkeys and apes in west central Africa. From there it jumped species into humans on several occasions, perhaps because people ate infected bushmeat. Some people carry a version of HIV closely related to that seen in sooty mangabey monkeys, for instance. But HIV that came from monkeys has not become a global problem. We are more closely related to apes, like gorillas and chimpanzees, than we are to monkeys. But even when HIV has passed into human populations from these apes, it has not necessarily turned into a widespread health issue. HIV originating from apes typically belongs to a type of virus called HIV-1. One is called HIV-1 group O, and human cases are largely confined to west Africa. In fact, only one form of HIV has spread far and wide after jumping to humans. This version, which probably originated from chimpanzees, is called HIV-1 group M (for major). More than 90% of HIV infections belong in group M. Which raises an obvious question: whats so special about HIV-1 group M? A study published in 2014 suggests a surprising answer: there might be nothing particularly special about group M. It is not especially infectious, as you might expect. Instead, it seems that this form of HIV simply took advantage of events. Ecological rather than evolutionary factors drove its rapid spread, says Nuno Faria at the University of Oxford in the UK. Faria and his colleagues built a family tree of HIV, by looking at a diverse array of HIV genomes collected from about 800 infected people from central Africa. Genomes pick up new mutations at a fairly steady rate, so by comparing two genome sequences and counting the differences they could work out when the two last shared a common ancestor. This technique is widely used, for example to establish that our common ancestor with chimpanzees lived at least 7 million years ago. RNA viruses such as HIV evolve approximately 1 million times faster than human DNA, says Faria. This means the HIV molecular clock ticks very fast indeed. It ticks so fast, Faria and his colleagues found that the HIV genomes all shared a common ancestor that existed no more than 100 years ago. The HIV-1 group M pandemic probably first began in the 1920s. Then the team went further. Because they knew where each of the HIV samples had been collected, they could place the origin of the pandemic in a specific city: Kinshasa, now the capital of the Democratic Republic of Congo. At this point, the researchers changed tack. They turned to historical records to work out why HIV infections in an African city in the 1920s could ultimately spark a pandemic. A likely sequence of events quickly became obvious. In the 1920s, DR Congo was a Belgian colony and Kinshasa then known as Leopoldville had just been made the capital. The city became a very attractive destination for young working men seeking their fortunes, and for sex workers only too willing to help them spend their earnings. The virus spread quickly through the population. It did not remain confined to the city. The researchers discovered that the capital of the Belgian Congo was, in the 1920s, one of the best connected cities in Africa. Taking full advantage of an extensive rail network used by hundreds of thousands of people each year, the virus spread to cities 900 miles (1500km) away in just 20 years. Everything was in place for an explosion in infection rates in the 1960s. The beginning of that decade brought another change. Belgian Congo gained its independence, and became an attractive source of employment to French speakers elsewhere in the world, including Haiti. When these young Haitians returned home a few years later they took a particular form of HIV-1 group M, called subtype B, to the western side of the Atlantic. It arrived in the US in the 1970s, just as sexual liberation and homophobic attitudes were leading to concentrations of gay men in cosmopolitan cities like New York and San Francisco. Once more, HIV took advantage of the sociopolitical situation to spread quickly through the US and Europe. There is no reason to believe that other subtypes would not have spread as quickly as subtype B, given similar ecological circumstances, says Faria. The story of the spread of HIV is not over yet. For instance, in 2015 there was an outbreak in the US state of Indiana, associated with drug injecting. The US Centers for Disease Control and Prevention has been analyzing the HIV genome sequences and data about location and time of infection, says Yonatan Grad at the Harvard School of Public Health in Boston, Massachusetts. These data help to understand the extent of the outbreak, and will further help to understand when public health interventions have worked. This approach can work for other pathogens. In 2014, Grad and his colleague Marc Lipsitch published an investigation into the spread of drug-resistant gonorrhoea across the US. Because we had representative sequences from individuals in different cities at different times and with different sexual orientations, we could show the spread was from the west of the country to the east, says Lipsitch. Whats more, they could confirm that the drug-resistant form of gonorrhoea appeared to have circulated predominantly in men who have sex with men. That could prompt increased screening in these at-risk populations, in an effort to reduce further spread. In other words, there is real power to studying pathogens like HIV and gonorrhoea through the prism of human society.", "hypothesis": "The most important role in developing AIDS as a pandemia was played by sex workers.", "gold_label": "contradiction"}
{"uid": "id_445", "premise": "We know the city where HIV first emerged It is easy to see why AIDS seemed so mysterious and frightening when US medics first encountered it 35 years ago. The condition robbed young, healthy people of their strong immune system, leaving them weak and vulnerable. And it seemed to come out of nowhere. Today we know much more how and why HIV the virus that leads to AIDS has become a global pandemic. Unsurprisingly, sex workers unwittingly played a part. But no less important were the roles of trade, the collapse of colonialism, and 20th Century sociopolitical reform. HIV did not really appear out of nowhere, of course. It probably began as a virus affecting monkeys and apes in west central Africa. From there it jumped species into humans on several occasions, perhaps because people ate infected bushmeat. Some people carry a version of HIV closely related to that seen in sooty mangabey monkeys, for instance. But HIV that came from monkeys has not become a global problem. We are more closely related to apes, like gorillas and chimpanzees, than we are to monkeys. But even when HIV has passed into human populations from these apes, it has not necessarily turned into a widespread health issue. HIV originating from apes typically belongs to a type of virus called HIV-1. One is called HIV-1 group O, and human cases are largely confined to west Africa. In fact, only one form of HIV has spread far and wide after jumping to humans. This version, which probably originated from chimpanzees, is called HIV-1 group M (for major). More than 90% of HIV infections belong in group M. Which raises an obvious question: whats so special about HIV-1 group M? A study published in 2014 suggests a surprising answer: there might be nothing particularly special about group M. It is not especially infectious, as you might expect. Instead, it seems that this form of HIV simply took advantage of events. Ecological rather than evolutionary factors drove its rapid spread, says Nuno Faria at the University of Oxford in the UK. Faria and his colleagues built a family tree of HIV, by looking at a diverse array of HIV genomes collected from about 800 infected people from central Africa. Genomes pick up new mutations at a fairly steady rate, so by comparing two genome sequences and counting the differences they could work out when the two last shared a common ancestor. This technique is widely used, for example to establish that our common ancestor with chimpanzees lived at least 7 million years ago. RNA viruses such as HIV evolve approximately 1 million times faster than human DNA, says Faria. This means the HIV molecular clock ticks very fast indeed. It ticks so fast, Faria and his colleagues found that the HIV genomes all shared a common ancestor that existed no more than 100 years ago. The HIV-1 group M pandemic probably first began in the 1920s. Then the team went further. Because they knew where each of the HIV samples had been collected, they could place the origin of the pandemic in a specific city: Kinshasa, now the capital of the Democratic Republic of Congo. At this point, the researchers changed tack. They turned to historical records to work out why HIV infections in an African city in the 1920s could ultimately spark a pandemic. A likely sequence of events quickly became obvious. In the 1920s, DR Congo was a Belgian colony and Kinshasa then known as Leopoldville had just been made the capital. The city became a very attractive destination for young working men seeking their fortunes, and for sex workers only too willing to help them spend their earnings. The virus spread quickly through the population. It did not remain confined to the city. The researchers discovered that the capital of the Belgian Congo was, in the 1920s, one of the best connected cities in Africa. Taking full advantage of an extensive rail network used by hundreds of thousands of people each year, the virus spread to cities 900 miles (1500km) away in just 20 years. Everything was in place for an explosion in infection rates in the 1960s. The beginning of that decade brought another change. Belgian Congo gained its independence, and became an attractive source of employment to French speakers elsewhere in the world, including Haiti. When these young Haitians returned home a few years later they took a particular form of HIV-1 group M, called subtype B, to the western side of the Atlantic. It arrived in the US in the 1970s, just as sexual liberation and homophobic attitudes were leading to concentrations of gay men in cosmopolitan cities like New York and San Francisco. Once more, HIV took advantage of the sociopolitical situation to spread quickly through the US and Europe. There is no reason to believe that other subtypes would not have spread as quickly as subtype B, given similar ecological circumstances, says Faria. The story of the spread of HIV is not over yet. For instance, in 2015 there was an outbreak in the US state of Indiana, associated with drug injecting. The US Centers for Disease Control and Prevention has been analyzing the HIV genome sequences and data about location and time of infection, says Yonatan Grad at the Harvard School of Public Health in Boston, Massachusetts. These data help to understand the extent of the outbreak, and will further help to understand when public health interventions have worked. This approach can work for other pathogens. In 2014, Grad and his colleague Marc Lipsitch published an investigation into the spread of drug-resistant gonorrhoea across the US. Because we had representative sequences from individuals in different cities at different times and with different sexual orientations, we could show the spread was from the west of the country to the east, says Lipsitch. Whats more, they could confirm that the drug-resistant form of gonorrhoea appeared to have circulated predominantly in men who have sex with men. That could prompt increased screening in these at-risk populations, in an effort to reduce further spread. In other words, there is real power to studying pathogens like HIV and gonorrhoea through the prism of human society.", "hypothesis": "Scientists believe that HIV already existed in 1920s.", "gold_label": "entailment"}
{"uid": "id_446", "premise": "We know the city where HIV first emerged It is easy to see why AIDS seemed so mysterious and frightening when US medics first encountered it 35 years ago. The condition robbed young, healthy people of their strong immune system, leaving them weak and vulnerable. And it seemed to come out of nowhere. Today we know much more how and why HIV the virus that leads to AIDS has become a global pandemic. Unsurprisingly, sex workers unwittingly played a part. But no less important were the roles of trade, the collapse of colonialism, and 20th Century sociopolitical reform. HIV did not really appear out of nowhere, of course. It probably began as a virus affecting monkeys and apes in west central Africa. From there it jumped species into humans on several occasions, perhaps because people ate infected bushmeat. Some people carry a version of HIV closely related to that seen in sooty mangabey monkeys, for instance. But HIV that came from monkeys has not become a global problem. We are more closely related to apes, like gorillas and chimpanzees, than we are to monkeys. But even when HIV has passed into human populations from these apes, it has not necessarily turned into a widespread health issue. HIV originating from apes typically belongs to a type of virus called HIV-1. One is called HIV-1 group O, and human cases are largely confined to west Africa. In fact, only one form of HIV has spread far and wide after jumping to humans. This version, which probably originated from chimpanzees, is called HIV-1 group M (for major). More than 90% of HIV infections belong in group M. Which raises an obvious question: whats so special about HIV-1 group M? A study published in 2014 suggests a surprising answer: there might be nothing particularly special about group M. It is not especially infectious, as you might expect. Instead, it seems that this form of HIV simply took advantage of events. Ecological rather than evolutionary factors drove its rapid spread, says Nuno Faria at the University of Oxford in the UK. Faria and his colleagues built a family tree of HIV, by looking at a diverse array of HIV genomes collected from about 800 infected people from central Africa. Genomes pick up new mutations at a fairly steady rate, so by comparing two genome sequences and counting the differences they could work out when the two last shared a common ancestor. This technique is widely used, for example to establish that our common ancestor with chimpanzees lived at least 7 million years ago. RNA viruses such as HIV evolve approximately 1 million times faster than human DNA, says Faria. This means the HIV molecular clock ticks very fast indeed. It ticks so fast, Faria and his colleagues found that the HIV genomes all shared a common ancestor that existed no more than 100 years ago. The HIV-1 group M pandemic probably first began in the 1920s. Then the team went further. Because they knew where each of the HIV samples had been collected, they could place the origin of the pandemic in a specific city: Kinshasa, now the capital of the Democratic Republic of Congo. At this point, the researchers changed tack. They turned to historical records to work out why HIV infections in an African city in the 1920s could ultimately spark a pandemic. A likely sequence of events quickly became obvious. In the 1920s, DR Congo was a Belgian colony and Kinshasa then known as Leopoldville had just been made the capital. The city became a very attractive destination for young working men seeking their fortunes, and for sex workers only too willing to help them spend their earnings. The virus spread quickly through the population. It did not remain confined to the city. The researchers discovered that the capital of the Belgian Congo was, in the 1920s, one of the best connected cities in Africa. Taking full advantage of an extensive rail network used by hundreds of thousands of people each year, the virus spread to cities 900 miles (1500km) away in just 20 years. Everything was in place for an explosion in infection rates in the 1960s. The beginning of that decade brought another change. Belgian Congo gained its independence, and became an attractive source of employment to French speakers elsewhere in the world, including Haiti. When these young Haitians returned home a few years later they took a particular form of HIV-1 group M, called subtype B, to the western side of the Atlantic. It arrived in the US in the 1970s, just as sexual liberation and homophobic attitudes were leading to concentrations of gay men in cosmopolitan cities like New York and San Francisco. Once more, HIV took advantage of the sociopolitical situation to spread quickly through the US and Europe. There is no reason to believe that other subtypes would not have spread as quickly as subtype B, given similar ecological circumstances, says Faria. The story of the spread of HIV is not over yet. For instance, in 2015 there was an outbreak in the US state of Indiana, associated with drug injecting. The US Centers for Disease Control and Prevention has been analyzing the HIV genome sequences and data about location and time of infection, says Yonatan Grad at the Harvard School of Public Health in Boston, Massachusetts. These data help to understand the extent of the outbreak, and will further help to understand when public health interventions have worked. This approach can work for other pathogens. In 2014, Grad and his colleague Marc Lipsitch published an investigation into the spread of drug-resistant gonorrhoea across the US. Because we had representative sequences from individuals in different cities at different times and with different sexual orientations, we could show the spread was from the west of the country to the east, says Lipsitch. Whats more, they could confirm that the drug-resistant form of gonorrhoea appeared to have circulated predominantly in men who have sex with men. That could prompt increased screening in these at-risk populations, in an effort to reduce further spread. In other words, there is real power to studying pathogens like HIV and gonorrhoea through the prism of human society.", "hypothesis": "AIDS were first encountered 35 years ago.", "gold_label": "entailment"}
{"uid": "id_447", "premise": "We like to think of ourselves as unique but we are in fact 99.9 per cent genetically identical. DNA, which comprises the chemical code, governs the construction and function of every cell in our body. The Human Genome Project mapped the sequence for human DNA and provided a blueprint of the DNA shared by every person. But what of the 0.1 per cent that is not common to all mankind and was left out of the Human Genome Project blueprint? It is responsible for all individual idiosyncrasies and the differences between racial and ethnic groups. If it were not for this minute percentage there would be no individual differences. We would be clones. Individual differences could be greatly increased if we were to think the unthinkable and allow genetic engineering of the human DNA. This would involve inserting genes from one cell into another and changing that cells DNA and its characteristics. In theory it would be possible to take the DNA from an entirely different species and insert it into human cells. Such radical modifications could certainly make us much more unique.", "hypothesis": "A word that means the same as blueprint is design.", "gold_label": "entailment"}
{"uid": "id_448", "premise": "We like to think of ourselves as unique but we are in fact 99.9 per cent genetically identical. DNA, which comprises the chemical code, governs the construction and function of every cell in our body. The Human Genome Project mapped the sequence for human DNA and provided a blueprint of the DNA shared by every person. But what of the 0.1 per cent that is not common to all mankind and was left out of the Human Genome Project blueprint? It is responsible for all individual idiosyncrasies and the differences between racial and ethnic groups. If it were not for this minute percentage there would be no individual differences. We would be clones. Individual differences could be greatly increased if we were to think the unthinkable and allow genetic engineering of the human DNA. This would involve inserting genes from one cell into another and changing that cells DNA and its characteristics. In theory it would be possible to take the DNA from an entirely different species and insert it into human cells. Such radical modifications could certainly make us much more unique.", "hypothesis": "It can be inferred from the passage that a DNA molecule is contained in the nucleus of every cell in our body.", "gold_label": "contradiction"}
{"uid": "id_449", "premise": "We like to think of ourselves as unique but we are in fact 99.9 per cent genetically identical. DNA, which comprises the chemical code, governs the construction and function of every cell in our body. The Human Genome Project mapped the sequence for human DNA and provided a blueprint of the DNA shared by every person. But what of the 0.1 per cent that is not common to all mankind and was left out of the Human Genome Project blueprint? It is responsible for all individual idiosyncrasies and the differences between racial and ethnic groups. If it were not for this minute percentage there would be no individual differences. We would be clones. Individual differences could be greatly increased if we were to think the unthinkable and allow genetic engineering of the human DNA. This would involve inserting genes from one cell into another and changing that cells DNA and its characteristics. In theory it would be possible to take the DNA from an entirely different species and insert it into human cells. Such radical modifications could certainly make us much more unique.", "hypothesis": "The Human Genome Project is mentioned in the project in relation to cloning.", "gold_label": "contradiction"}
{"uid": "id_450", "premise": "We like to think of ourselves as unique but we are in fact 99.9 per cent genetically identical. DNA, which comprises the chemical code, governs the construction and function of every cell in our body. The Human Genome Project mapped the sequence for human DNA and provided a blueprint of the DNA shared by every person. But what of the 0.1 per cent that is not common to all mankind and was left out of the Human Genome Project blueprint? It is responsible for all individual idiosyncrasies and the differences between racial and ethnic groups. If it were not for this minute percentage there would be no individual differences. We would be clones. Individual differences could be greatly increased if we were to think the unthinkable and allow genetic engineering of the human DNA. This would involve inserting genes from one cell into another and changing that cells DNA and its characteristics. In theory it would be possible to take the DNA from an entirely different species and insert it into human cells. Such radical modifications could certainly make us much more unique.", "hypothesis": "It can be inferred from the passage that the author does not approve of the genetic engineering of human DNA.", "gold_label": "neutral"}
{"uid": "id_451", "premise": "We like to think of ourselves as unique but we are in fact 99.9 per cent genetically identical. DNA, which comprises the chemical code, governs the construction and function of every cell in our body. The Human Genome Project mapped the sequence for human DNA and provided a blueprint of the DNA shared by every person. But what of the 0.1 per cent that is not common to all mankind and was left out of the Human Genome Project blueprint? It is responsible for all individual idiosyncrasies and the differences between racial and ethnic groups. If it were not for this minute percentage there would be no individual differences. We would be clones. Individual differences could be greatly increased if we were to think the unthinkable and allow genetic engineering of the human DNA. This would involve inserting genes from one cell into another and changing that cells DNA and its characteristics. In theory it would be possible to take the DNA from an entirely different species and insert it into human cells. Such radical modifications could certainly make us much more unique.", "hypothesis": "In the context of the passage idiosyncrasies means unconventional behaviour.", "gold_label": "contradiction"}
{"uid": "id_452", "premise": "We suffer a suspension of judgement when we hand over a card to purchase something and spend funds that we intended to use for something essential or unintentionally create an unauthorized overdraft. These spur-of-the-moment lapses are more likely to occur when we pay for something electronically or with credit than with hard cash. This is because of a widely held perception that electronic money and credit are somehow not as real or valuable as notes and coins. Retailers play on this emotional weakness with offers of in- store cards and buy now play later deals. But, nowhere is our Achilles heel exploited more than on the internet where it is impossible to pay with ready money and perhaps the sites that have perfected this form of exploitation are those that offer gambling. The sites regulated by the Gaming Commission have safeguards but the unregulated sites set out to encourage people to stake more to recover their losses and do not provide facilities to allow the gambler to set limits on how much they will fritter.", "hypothesis": "Sites unregulated by the Gaming Commission are unlicensed.", "gold_label": "neutral"}
{"uid": "id_453", "premise": "We suffer a suspension of judgement when we hand over a card to purchase something and spend funds that we intended to use for something essential or unintentionally create an unauthorized overdraft. These spur-of-the-moment lapses are more likely to occur when we pay for something electronically or with credit than with hard cash. This is because of a widely held perception that electronic money and credit are somehow not as real or valuable as notes and coins. Retailers play on this emotional weakness with offers of in- store cards and buy now play later deals. But, nowhere is our Achilles heel exploited more than on the internet where it is impossible to pay with ready money and perhaps the sites that have perfected this form of exploitation are those that offer gambling. The sites regulated by the Gaming Commission have safeguards but the unregulated sites set out to encourage people to stake more to recover their losses and do not provide facilities to allow the gambler to set limits on how much they will fritter.", "hypothesis": "We suffer a suspension of judgement when we hand over a card to purchase something.", "gold_label": "contradiction"}
{"uid": "id_454", "premise": "We suffer a suspension of judgement when we hand over a card to purchase something and spend funds that we intended to use for something essential or unintentionally create an unauthorized overdraft. These spur-of-the-moment lapses are more likely to occur when we pay for something electronically or with credit than with hard cash. This is because of a widely held perception that electronic money and credit are somehow not as real or valuable as notes and coins. Retailers play on this emotional weakness with offers of in- store cards and buy now play later deals. But, nowhere is our Achilles heel exploited more than on the internet where it is impossible to pay with ready money and perhaps the sites that have perfected this form of exploitation are those that offer gambling. The sites regulated by the Gaming Commission have safeguards but the unregulated sites set out to encourage people to stake more to recover their losses and do not provide facilities to allow the gambler to set limits on how much they will fritter.", "hypothesis": "Electronic money and credit have a lower psychological value than cash in your hand.", "gold_label": "entailment"}
{"uid": "id_455", "premise": "Weather forecast sometimes has a better history record than economists. They make a great contribution to the revenue. For example, a recent weather forecast said there would be a storm in a resort resulting thousand dollars books decrease that day while actually the resort enjoyed a sunny day. Weather forecast would bring marketing mix alteration to various super market or retail shops when they review the forecast", "hypothesis": "Economists forecasts are prone to some biggest errors.", "gold_label": "neutral"}
{"uid": "id_456", "premise": "Weather forecast sometimes has a better history record than economists. They make a great contribution to the revenue. For example, a recent weather forecast said there would be a storm in a resort resulting thousand dollars books decrease that day while actually the resort enjoyed a sunny day. Weather forecast would bring marketing mix alteration to various super market or retail shops when they review the forecast", "hypothesis": "Travellers or people having holidays pay little attention to the weather.", "gold_label": "neutral"}
{"uid": "id_457", "premise": "Weather forecast sometimes has a better history record than economists. They make a great contribution to the revenue. For example, a recent weather forecast said there would be a storm in a resort resulting thousand dollars books decrease that day while actually the resort enjoyed a sunny day. Weather forecast would bring marketing mix alteration to various super market or retail shops when they review the forecast", "hypothesis": "It would be very beneficial for super markets and retailers to be informed of the weather forecast.", "gold_label": "entailment"}
{"uid": "id_458", "premise": "Weighty problem. The World Health Organization (WHO) reports that obesity has reached epidemic proportions worldwide, with three times as many overweight adults as there were 20 years ago. Almost one-quarter of the adult population of the UK are now classed as obese, and they are over-represented in their use of NHS services. The most widely used tool to assess obesity is body mass index (BMI), which divides 2 weight in kilograms by height in metres squared to give the units kg/m . A BMI of 25 or above is defined as overweight or pre-obese, and a BMI of 30 or more is defined as obese. People with a BMI of 40 or above are morbidly obese; they are at severe risk of developing co-morbidities like cardiovascular disease and type 2 diabetes, which reduce life expectancy and increase hospital stay. Patients weighing more than 20 stone are described as bariatric the word originated from the Greek word baros meaning heavy and iatrics meaning medical treatment. The large size of bariatric patients often leads to poor mobility, with implications for manual handling, equipment, beds, chairs and space. Most bariatric patients will have a BMI in excess of 40, though not all bariatric people will be morbidly obese nor will every person with a BMI over 30 be obese. For example, a six-foot-five rugby player weighing 21 stone (BMI = 35) with a muscular build and a good weight distribution might be athletic. In these larger people the waist-to-hip ratio can serve as a more reliable indicator of a weight problem. A ratio of 1.0 or more is consistent with an excess of fat around the waist and the need to lose weight. From a health perspective, maximum safe waist measurements are reported as 40 inches (102 cm) for men and 35 inches (89 cm) for women irrespective of fat distribution.", "hypothesis": "A patient with a waist-to-hip ratio of 1.1 is obese.", "gold_label": "neutral"}
{"uid": "id_459", "premise": "Weighty problem. The World Health Organization (WHO) reports that obesity has reached epidemic proportions worldwide, with three times as many overweight adults as there were 20 years ago. Almost one-quarter of the adult population of the UK are now classed as obese, and they are over-represented in their use of NHS services. The most widely used tool to assess obesity is body mass index (BMI), which divides 2 weight in kilograms by height in metres squared to give the units kg/m . A BMI of 25 or above is defined as overweight or pre-obese, and a BMI of 30 or more is defined as obese. People with a BMI of 40 or above are morbidly obese; they are at severe risk of developing co-morbidities like cardiovascular disease and type 2 diabetes, which reduce life expectancy and increase hospital stay. Patients weighing more than 20 stone are described as bariatric the word originated from the Greek word baros meaning heavy and iatrics meaning medical treatment. The large size of bariatric patients often leads to poor mobility, with implications for manual handling, equipment, beds, chairs and space. Most bariatric patients will have a BMI in excess of 40, though not all bariatric people will be morbidly obese nor will every person with a BMI over 30 be obese. For example, a six-foot-five rugby player weighing 21 stone (BMI = 35) with a muscular build and a good weight distribution might be athletic. In these larger people the waist-to-hip ratio can serve as a more reliable indicator of a weight problem. A ratio of 1.0 or more is consistent with an excess of fat around the waist and the need to lose weight. From a health perspective, maximum safe waist measurements are reported as 40 inches (102 cm) for men and 35 inches (89 cm) for women irrespective of fat distribution.", "hypothesis": "A patient with a waist measurement over 40 inches is obese.", "gold_label": "neutral"}
{"uid": "id_460", "premise": "Weighty problem. The World Health Organization (WHO) reports that obesity has reached epidemic proportions worldwide, with three times as many overweight adults as there were 20 years ago. Almost one-quarter of the adult population of the UK are now classed as obese, and they are over-represented in their use of NHS services. The most widely used tool to assess obesity is body mass index (BMI), which divides 2 weight in kilograms by height in metres squared to give the units kg/m . A BMI of 25 or above is defined as overweight or pre-obese, and a BMI of 30 or more is defined as obese. People with a BMI of 40 or above are morbidly obese; they are at severe risk of developing co-morbidities like cardiovascular disease and type 2 diabetes, which reduce life expectancy and increase hospital stay. Patients weighing more than 20 stone are described as bariatric the word originated from the Greek word baros meaning heavy and iatrics meaning medical treatment. The large size of bariatric patients often leads to poor mobility, with implications for manual handling, equipment, beds, chairs and space. Most bariatric patients will have a BMI in excess of 40, though not all bariatric people will be morbidly obese nor will every person with a BMI over 30 be obese. For example, a six-foot-five rugby player weighing 21 stone (BMI = 35) with a muscular build and a good weight distribution might be athletic. In these larger people the waist-to-hip ratio can serve as a more reliable indicator of a weight problem. A ratio of 1.0 or more is consistent with an excess of fat around the waist and the need to lose weight. From a health perspective, maximum safe waist measurements are reported as 40 inches (102 cm) for men and 35 inches (89 cm) for women irrespective of fat distribution.", "hypothesis": "A patient with a BMI of between 25.0 and 29.9 is pre-obese.", "gold_label": "entailment"}
{"uid": "id_461", "premise": "Weighty problem. The World Health Organization (WHO) reports that obesity has reached epidemic proportions worldwide, with three times as many overweight adults as there were 20 years ago. Almost one-quarter of the adult population of the UK are now classed as obese, and they are over-represented in their use of NHS services. The most widely used tool to assess obesity is body mass index (BMI), which divides 2 weight in kilograms by height in metres squared to give the units kg/m . A BMI of 25 or above is defined as overweight or pre-obese, and a BMI of 30 or more is defined as obese. People with a BMI of 40 or above are morbidly obese; they are at severe risk of developing co-morbidities like cardiovascular disease and type 2 diabetes, which reduce life expectancy and increase hospital stay. Patients weighing more than 20 stone are described as bariatric the word originated from the Greek word baros meaning heavy and iatrics meaning medical treatment. The large size of bariatric patients often leads to poor mobility, with implications for manual handling, equipment, beds, chairs and space. Most bariatric patients will have a BMI in excess of 40, though not all bariatric people will be morbidly obese nor will every person with a BMI over 30 be obese. For example, a six-foot-five rugby player weighing 21 stone (BMI = 35) with a muscular build and a good weight distribution might be athletic. In these larger people the waist-to-hip ratio can serve as a more reliable indicator of a weight problem. A ratio of 1.0 or more is consistent with an excess of fat around the waist and the need to lose weight. From a health perspective, maximum safe waist measurements are reported as 40 inches (102 cm) for men and 35 inches (89 cm) for women irrespective of fat distribution.", "hypothesis": "At least one-quarter of obese adults use NHS services.", "gold_label": "contradiction"}
{"uid": "id_462", "premise": "Well-regulated, ethical practices should always be an area of primary concern for any business. In an environment where multinational conglomerates predominate, owners of small businesses may feel anonymous enough to become flexible about their code of ethics. However, the increasingly inescapable attention of the media allows an unprecedented number of individuals to access news and information with greater speed than ever before unethical practices can become a matter of public knowledge overnight, with devastating consequences. Codes of ethical practice should apply not only to clients, but to employees, who are just as able to draw inappropriate behaviour on the part of their employers to the public's attention. In today's society, businesses of any size must be able to demonstrate transparency and accountability in their dealings with employees, clients, and the public alike.", "hypothesis": "Employees of a company should be subject to ethical codes of practice.", "gold_label": "entailment"}
{"uid": "id_463", "premise": "Well-regulated, ethical practices should always be an area of primary concern for any business. In an environment where multinational conglomerates predominate, owners of small businesses may feel anonymous enough to become flexible about their code of ethics. However, the increasingly inescapable attention of the media allows an unprecedented number of individuals to access news and information with greater speed than ever before unethical practices can become a matter of public knowledge overnight, with devastating consequences. Codes of ethical practice should apply not only to clients, but to employees, who are just as able to draw inappropriate behaviour on the part of their employers to the public's attention. In today's society, businesses of any size must be able to demonstrate transparency and accountability in their dealings with employees, clients, and the public alike.", "hypothesis": "Unethical practices are only a problem if the public becomes aware of them.", "gold_label": "neutral"}
{"uid": "id_464", "premise": "Well-regulated, ethical practices should always be an area of primary concern for any business. In an environment where multinational conglomerates predominate, owners of small businesses may feel anonymous enough to become flexible about their code of ethics. However, the increasingly inescapable attention of the media allows an unprecedented number of individuals to access news and information with greater speed than ever before unethical practices can become a matter of public knowledge overnight, with devastating consequences. Codes of ethical practice should apply not only to clients, but to employees, who are just as able to draw inappropriate behaviour on the part of their employers to the public's attention. In today's society, businesses of any size must be able to demonstrate transparency and accountability in their dealings with employees, clients, and the public alike.", "hypothesis": "More people than ever before have access to information about companies' ethical practices.", "gold_label": "entailment"}
{"uid": "id_465", "premise": "Westley Business School Preparation Courses for Students 80% of the students who take our courses are mature students who have not done any formal study for several years. Many of the courses at the Westley Business School require a good knowledge of various skills. If you feel you need some extra preparation before your course, look below and see if any of our preparation courses suit your needs. All courses take place in August, and for enrolled students all the courses listed below are free. Course 1 STATISTICS A grounding in statistics is a must for any prospective business student. This is a one week course (Mon Fri) consisting of one lecture every night. The tutor will ensure that by the end of the course, you will have had a thorough introduction to all the statistical skills that you will need to start your course at Westley Business School. Each lecture runs from 6pm to 9pm. Course 2 ESSAY WRITING This is a self-study pack containing guidance, practice and tests. At the end of the course (it should take about 10 hours of self-study) you will receive a 1 hour tutorial with the essay writing tutor who will go over your work with you. Course 3 BASIC MATHS This is a one-off lecture of 3 hours aimed at reviewing all the basic maths that you will vaguely remember from school! This course is run on a first come, first served basis and there are only 20 places (every Monday in August from 5.45pm 8.45pm) so dont be late. Course 4 COMPUTING This 2 week course (Mon Fri 6.30pm 8.30pm) will give students all the basic computer skills that they will need for their courses at Westley Business School. There are two courses running concurrently with only 10 PLACES in each so book early! NB UNLESS OTHERWISE STATED, YOU MUST BOOK IN ADVANCE FOR THESE COURSES AT THE MAIN WESTLEY BUSINESS SCHOOL RECEPTION", "hypothesis": "Students registered at Westley Business College dont have to pay for the preparation course.", "gold_label": "entailment"}
{"uid": "id_466", "premise": "Westley Business School Preparation Courses for Students 80% of the students who take our courses are mature students who have not done any formal study for several years. Many of the courses at the Westley Business School require a good knowledge of various skills. If you feel you need some extra preparation before your course, look below and see if any of our preparation courses suit your needs. All courses take place in August, and for enrolled students all the courses listed below are free. Course 1 STATISTICS A grounding in statistics is a must for any prospective business student. This is a one week course (Mon Fri) consisting of one lecture every night. The tutor will ensure that by the end of the course, you will have had a thorough introduction to all the statistical skills that you will need to start your course at Westley Business School. Each lecture runs from 6pm to 9pm. Course 2 ESSAY WRITING This is a self-study pack containing guidance, practice and tests. At the end of the course (it should take about 10 hours of self-study) you will receive a 1 hour tutorial with the essay writing tutor who will go over your work with you. Course 3 BASIC MATHS This is a one-off lecture of 3 hours aimed at reviewing all the basic maths that you will vaguely remember from school! This course is run on a first come, first served basis and there are only 20 places (every Monday in August from 5.45pm 8.45pm) so dont be late. Course 4 COMPUTING This 2 week course (Mon Fri 6.30pm 8.30pm) will give students all the basic computer skills that they will need for their courses at Westley Business School. There are two courses running concurrently with only 10 PLACES in each so book early! NB UNLESS OTHERWISE STATED, YOU MUST BOOK IN ADVANCE FOR THESE COURSES AT THE MAIN WESTLEY BUSINESS SCHOOL RECEPTION", "hypothesis": "Most students at Westley Business School are older than the average college student.", "gold_label": "entailment"}
{"uid": "id_467", "premise": "Westley Business School Preparation Courses for Students 80% of the students who take our courses are mature students who have not done any formal study for several years. Many of the courses at the Westley Business School require a good knowledge of various skills. If you feel you need some extra preparation before your course, look below and see if any of our preparation courses suit your needs. All courses take place in August, and for enrolled students all the courses listed below are free. Course 1 STATISTICS A grounding in statistics is a must for any prospective business student. This is a one week course (Mon Fri) consisting of one lecture every night. The tutor will ensure that by the end of the course, you will have had a thorough introduction to all the statistical skills that you will need to start your course at Westley Business School. Each lecture runs from 6pm to 9pm. Course 2 ESSAY WRITING This is a self-study pack containing guidance, practice and tests. At the end of the course (it should take about 10 hours of self-study) you will receive a 1 hour tutorial with the essay writing tutor who will go over your work with you. Course 3 BASIC MATHS This is a one-off lecture of 3 hours aimed at reviewing all the basic maths that you will vaguely remember from school! This course is run on a first come, first served basis and there are only 20 places (every Monday in August from 5.45pm 8.45pm) so dont be late. Course 4 COMPUTING This 2 week course (Mon Fri 6.30pm 8.30pm) will give students all the basic computer skills that they will need for their courses at Westley Business School. There are two courses running concurrently with only 10 PLACES in each so book early! NB UNLESS OTHERWISE STATED, YOU MUST BOOK IN ADVANCE FOR THESE COURSES AT THE MAIN WESTLEY BUSINESS SCHOOL RECEPTION", "hypothesis": "All taught courses are held in the Westley Business School main building.", "gold_label": "neutral"}
{"uid": "id_468", "premise": "Westley Central Surgery Information Opening Hours Monday to Friday 8.30 am 6.00 pm Saturday 9.00 am 10.00 am (emergencies only) Surgeries Ten-minute appointments are given, although longer periods can be allocated on request. Morning surgery is between 8.30 am and 11.00 am, and afternoon surgery between 3.00 pm and 5.30 pm. These times may change during holiday periods and for staff training. We will always see you the same day for an urgent problem, although we cannot guarantee that this will be with the doctor of your choice. An urgent appointment is intended for matters that cannot wait until the next available routine appointment. Giving our staff an outline of the nature of the problem may help them organize the most appropriate response. We will often ask the doctor to ring you back to help decide the most appropriate way to deal with your problem. If you are unable to attend an appointment, please let us know so that we can offer the appointment to someone else. Results of Tests If you are asked to phone for results, please ring between 11.30 and 12.30. Please allow at least three working days for the results to be available. X-ray results take two weeks to arrive back at the surgery. Prescriptions Please allow at least two full days notice of your prescription requirements. With every prescription issued a printed sheet is given showing details of all your medicines. Please retain this. When you require a further prescription, please use this sheet as a tick list to request the medicines you require or obtain a request slip from reception. You can come in to order your prescription or post or fax your request. If you would like us to post your prescription to you, please include a stamped, self-addressed envelope. We do not accept telephone requests for repeat prescriptions as this can result in errors. Home Visits If you require a doctor to visit you at home, please ring the surgery before 10.00 am if possible. The doctors usually visit patients between 12.00 pm and 3.00 pm. New Patients To register with the Practice, please attend reception with your medical card if you have it, as well as the details of your previous doctor. You will be encouraged to attend a New Patients Health Check with one of our practice nurses. Emergency calls To speak to the doctor urgently you can ring the main surgery telephone number or ring the emergency mobile phone. For the mobile, please allow 25 seconds for connection. If the mobile phone is in use, or the doctor is in an area of poor reception, your call will be transferred to an answer phone. The emergency doctor will be alerted and will call you back. Practice Area Unfortunately we can only accept registration from patients who live within our practice area. If you move outside this area, you will be asked to register with another doctor. If you are in any doubt as to whether you are in our area, please speak to the reception staff. Charges There is a charge for some medical services that fall outside those provided by the NHS. These services include private sick notes, passport forms, holiday cancellation forms, insurance reports and employment medicals. Some travel vaccinations are also charged for and we charge for issuing a private prescription.", "hypothesis": "Ten minutes is the maximum available length for an appointment.", "gold_label": "contradiction"}
{"uid": "id_469", "premise": "Westley Central Surgery Information Opening Hours Monday to Friday 8.30 am 6.00 pm Saturday 9.00 am 10.00 am (emergencies only) Surgeries Ten-minute appointments are given, although longer periods can be allocated on request. Morning surgery is between 8.30 am and 11.00 am, and afternoon surgery between 3.00 pm and 5.30 pm. These times may change during holiday periods and for staff training. We will always see you the same day for an urgent problem, although we cannot guarantee that this will be with the doctor of your choice. An urgent appointment is intended for matters that cannot wait until the next available routine appointment. Giving our staff an outline of the nature of the problem may help them organize the most appropriate response. We will often ask the doctor to ring you back to help decide the most appropriate way to deal with your problem. If you are unable to attend an appointment, please let us know so that we can offer the appointment to someone else. Results of Tests If you are asked to phone for results, please ring between 11.30 and 12.30. Please allow at least three working days for the results to be available. X-ray results take two weeks to arrive back at the surgery. Prescriptions Please allow at least two full days notice of your prescription requirements. With every prescription issued a printed sheet is given showing details of all your medicines. Please retain this. When you require a further prescription, please use this sheet as a tick list to request the medicines you require or obtain a request slip from reception. You can come in to order your prescription or post or fax your request. If you would like us to post your prescription to you, please include a stamped, self-addressed envelope. We do not accept telephone requests for repeat prescriptions as this can result in errors. Home Visits If you require a doctor to visit you at home, please ring the surgery before 10.00 am if possible. The doctors usually visit patients between 12.00 pm and 3.00 pm. New Patients To register with the Practice, please attend reception with your medical card if you have it, as well as the details of your previous doctor. You will be encouraged to attend a New Patients Health Check with one of our practice nurses. Emergency calls To speak to the doctor urgently you can ring the main surgery telephone number or ring the emergency mobile phone. For the mobile, please allow 25 seconds for connection. If the mobile phone is in use, or the doctor is in an area of poor reception, your call will be transferred to an answer phone. The emergency doctor will be alerted and will call you back. Practice Area Unfortunately we can only accept registration from patients who live within our practice area. If you move outside this area, you will be asked to register with another doctor. If you are in any doubt as to whether you are in our area, please speak to the reception staff. Charges There is a charge for some medical services that fall outside those provided by the NHS. These services include private sick notes, passport forms, holiday cancellation forms, insurance reports and employment medicals. Some travel vaccinations are also charged for and we charge for issuing a private prescription.", "hypothesis": "You cannot order a repeat prescription over the phone.", "gold_label": "entailment"}
{"uid": "id_470", "premise": "Westley Central Surgery Information Opening Hours Monday to Friday 8.30 am 6.00 pm Saturday 9.00 am 10.00 am (emergencies only) Surgeries Ten-minute appointments are given, although longer periods can be allocated on request. Morning surgery is between 8.30 am and 11.00 am, and afternoon surgery between 3.00 pm and 5.30 pm. These times may change during holiday periods and for staff training. We will always see you the same day for an urgent problem, although we cannot guarantee that this will be with the doctor of your choice. An urgent appointment is intended for matters that cannot wait until the next available routine appointment. Giving our staff an outline of the nature of the problem may help them organize the most appropriate response. We will often ask the doctor to ring you back to help decide the most appropriate way to deal with your problem. If you are unable to attend an appointment, please let us know so that we can offer the appointment to someone else. Results of Tests If you are asked to phone for results, please ring between 11.30 and 12.30. Please allow at least three working days for the results to be available. X-ray results take two weeks to arrive back at the surgery. Prescriptions Please allow at least two full days notice of your prescription requirements. With every prescription issued a printed sheet is given showing details of all your medicines. Please retain this. When you require a further prescription, please use this sheet as a tick list to request the medicines you require or obtain a request slip from reception. You can come in to order your prescription or post or fax your request. If you would like us to post your prescription to you, please include a stamped, self-addressed envelope. We do not accept telephone requests for repeat prescriptions as this can result in errors. Home Visits If you require a doctor to visit you at home, please ring the surgery before 10.00 am if possible. The doctors usually visit patients between 12.00 pm and 3.00 pm. New Patients To register with the Practice, please attend reception with your medical card if you have it, as well as the details of your previous doctor. You will be encouraged to attend a New Patients Health Check with one of our practice nurses. Emergency calls To speak to the doctor urgently you can ring the main surgery telephone number or ring the emergency mobile phone. For the mobile, please allow 25 seconds for connection. If the mobile phone is in use, or the doctor is in an area of poor reception, your call will be transferred to an answer phone. The emergency doctor will be alerted and will call you back. Practice Area Unfortunately we can only accept registration from patients who live within our practice area. If you move outside this area, you will be asked to register with another doctor. If you are in any doubt as to whether you are in our area, please speak to the reception staff. Charges There is a charge for some medical services that fall outside those provided by the NHS. These services include private sick notes, passport forms, holiday cancellation forms, insurance reports and employment medicals. Some travel vaccinations are also charged for and we charge for issuing a private prescription.", "hypothesis": "If you have had an x-ray, call the surgery no earlier than one week following the date of the x-ray for the result.", "gold_label": "contradiction"}
{"uid": "id_471", "premise": "Westley Central Surgery Information Opening Hours Monday to Friday 8.30 am 6.00 pm Saturday 9.00 am 10.00 am (emergencies only) Surgeries Ten-minute appointments are given, although longer periods can be allocated on request. Morning surgery is between 8.30 am and 11.00 am, and afternoon surgery between 3.00 pm and 5.30 pm. These times may change during holiday periods and for staff training. We will always see you the same day for an urgent problem, although we cannot guarantee that this will be with the doctor of your choice. An urgent appointment is intended for matters that cannot wait until the next available routine appointment. Giving our staff an outline of the nature of the problem may help them organize the most appropriate response. We will often ask the doctor to ring you back to help decide the most appropriate way to deal with your problem. If you are unable to attend an appointment, please let us know so that we can offer the appointment to someone else. Results of Tests If you are asked to phone for results, please ring between 11.30 and 12.30. Please allow at least three working days for the results to be available. X-ray results take two weeks to arrive back at the surgery. Prescriptions Please allow at least two full days notice of your prescription requirements. With every prescription issued a printed sheet is given showing details of all your medicines. Please retain this. When you require a further prescription, please use this sheet as a tick list to request the medicines you require or obtain a request slip from reception. You can come in to order your prescription or post or fax your request. If you would like us to post your prescription to you, please include a stamped, self-addressed envelope. We do not accept telephone requests for repeat prescriptions as this can result in errors. Home Visits If you require a doctor to visit you at home, please ring the surgery before 10.00 am if possible. The doctors usually visit patients between 12.00 pm and 3.00 pm. New Patients To register with the Practice, please attend reception with your medical card if you have it, as well as the details of your previous doctor. You will be encouraged to attend a New Patients Health Check with one of our practice nurses. Emergency calls To speak to the doctor urgently you can ring the main surgery telephone number or ring the emergency mobile phone. For the mobile, please allow 25 seconds for connection. If the mobile phone is in use, or the doctor is in an area of poor reception, your call will be transferred to an answer phone. The emergency doctor will be alerted and will call you back. Practice Area Unfortunately we can only accept registration from patients who live within our practice area. If you move outside this area, you will be asked to register with another doctor. If you are in any doubt as to whether you are in our area, please speak to the reception staff. Charges There is a charge for some medical services that fall outside those provided by the NHS. These services include private sick notes, passport forms, holiday cancellation forms, insurance reports and employment medicals. Some travel vaccinations are also charged for and we charge for issuing a private prescription.", "hypothesis": "One of the practices four doctors will conduct a New Patients Health Check with any new patients to the practice.", "gold_label": "contradiction"}
{"uid": "id_472", "premise": "Whale Strandings When the last stranded whale of a group eventually dies, the story does not end there. A team of researchers begins to investigate, collecting skin samples for instance, recording anything that could help them answer the crucial question: why? Theories abound, some more convincing than others. In recent years, navy sonar has been accused of causing certain whales to strand. It is known that noise pollution from offshore industry, shipping and sonar can impair underwater communication, but can it really drive whales onto our beaches? In 1998, researchers at the Pelagos Cetacean Research Institute, a Greek non-profit scientific group, linked whale strandings with low- frequency sonar tests being carried out by the North Atlantic Treaty Organisation (NATO). They recorded the stranding of 12 Cuviers beaked whales over 38.2 kilometres of coastline. NATO later admitted it had been testing new sonar technology in the same area at the time as the strandings had occurred. Mass whale strandings involve four or more animals. Typically they all wash ashore together, but in mass atypical strandings (such as the one in Greece), the whales dont strand as a group; they are scattered over a larger area. For humans, hearing a sudden loud noise might prove frightening, but it does not induce mass fatality. For whales, on the other hand, there is a theory on how sonar can kill. The noise can surprise the animal, causing it to swim too quickly to the surface. The result is decompression sickness, a hazard human divers know all too well. If a diver ascends too quickly from a high-pressure underwater environment to a lower-pressure one, gases dissolved in blood and tissue expand and form bubbles. The bubbles block the flow of blood to vital organs, and can ultimately lead to death. Plausible as this seems, it is still a theory and based on our more comprehensive knowledge of land-based animals. For this reason, some scientists are wary. Whale expert Karen Evans is one such scientist. Another is Rosemary Gales, a leading expert on whale strandings. She says sonar technology cannot always be blamed for mass strandings. Its a case-by-case situation. Whales have been stranding for a very long time pre-sonar. And when 80% of all Australian whale strandings occur around Tasmania, Gales and her team must continue in the search for answers. When animals beach next to each other at the same time, the most common cause has nothing to do with humans at all. Theyre highly social creatures, says Gales. When they mass strand its complete panic and chaos. If one of the group strands and sounds the alarm, others will try to swim to its aid, and become stuck themselves. Activities such as sonar testing can hint at when a stranding may occur, but if conservationists are to reduce the number of strandings, or improve rescue operations, they need information on where strandings are likely to occur as well. With this in mind, Ralph James, physicist at the University of Western Australia in Perth, thinks he may have discovered why whales turn up only on some beaches. In 1986 he went to Augusta, Western Australia, where more than 100 false killer whales had beached. I found out from chatting to the locals that whales had been stranding there for decades. So I asked myself, what is it about this beach? From this question that James pondered over 20 years ago, grew the universitys Whale Stranding Analysis Project. Data has since revealed that all mass strandings around Australia occur on gently sloping sandy beaches, some with inclines of less than 0.5%. For whale species that depend on an echolocation system to navigate, this kind of beach spells disaster. Usually, as they swim, they make clicking noises, and the resulting sound waves are reflected in an echo and travel back to them. However, these just fade out on shallow beaches, so the whale doesnt hear an echo and it crashes onto the shore. But that is not all. Physics, it appears, can help with the when as well as the where. The ocean is full of bubbles. Larger ones rise quickly to the surface and disappear, whilst smaller ones called microbubbles can last for days. It is these that absorb whale clicks! Rough weather generates more bubbles than usual, James adds. So, during and after a storm, echolocating whales are essentially swimming blind. Last year was a bad one for strandings in Australia. Can we predict if this or any other year will be any better? Some scientists believe we can. They have found trends which could be used to forecast bad years for strandings in the future. In 2005, a survey by Klaus Vanselow and Klaus Ricklefs of sperm whale strandings in the North Sea even found a correlation between these and the sunspot cycle, and suggested that changes in the Earths magnetic field might be involved. But others are sceptical. Their study was interesting ... but the analyses they used were flawed on a number of levels, says Evans. In the same year, she co-authored a study on Australian strandings that uncovered a completely different trend. We analysed data from 1920 to 2002 ... and observed a clear periodicity in the number of whales stranded each year that coincides with a major climatic cycle. To put it more simply, she says, in the years when strong westerly and southerly winds bring cool water rich in nutrients closer to the Australia coast, there is an increase in the number of fish. The whales follow. So what causes mass strandings? Its probably many different components, says James. And he is probably right. But the point is we now know what many of those components are.", "hypothesis": "There is now agreement amongst scientists that changes in the Earths magnetic fields contribute to whale strandings.", "gold_label": "contradiction"}
{"uid": "id_473", "premise": "Whale Strandings When the last stranded whale of a group eventually dies, the story does not end there. A team of researchers begins to investigate, collecting skin samples for instance, recording anything that could help them answer the crucial question: why? Theories abound, some more convincing than others. In recent years, navy sonar has been accused of causing certain whales to strand. It is known that noise pollution from offshore industry, shipping and sonar can impair underwater communication, but can it really drive whales onto our beaches? In 1998, researchers at the Pelagos Cetacean Research Institute, a Greek non-profit scientific group, linked whale strandings with low- frequency sonar tests being carried out by the North Atlantic Treaty Organisation (NATO). They recorded the stranding of 12 Cuviers beaked whales over 38.2 kilometres of coastline. NATO later admitted it had been testing new sonar technology in the same area at the time as the strandings had occurred. Mass whale strandings involve four or more animals. Typically they all wash ashore together, but in mass atypical strandings (such as the one in Greece), the whales dont strand as a group; they are scattered over a larger area. For humans, hearing a sudden loud noise might prove frightening, but it does not induce mass fatality. For whales, on the other hand, there is a theory on how sonar can kill. The noise can surprise the animal, causing it to swim too quickly to the surface. The result is decompression sickness, a hazard human divers know all too well. If a diver ascends too quickly from a high-pressure underwater environment to a lower-pressure one, gases dissolved in blood and tissue expand and form bubbles. The bubbles block the flow of blood to vital organs, and can ultimately lead to death. Plausible as this seems, it is still a theory and based on our more comprehensive knowledge of land-based animals. For this reason, some scientists are wary. Whale expert Karen Evans is one such scientist. Another is Rosemary Gales, a leading expert on whale strandings. She says sonar technology cannot always be blamed for mass strandings. Its a case-by-case situation. Whales have been stranding for a very long time pre-sonar. And when 80% of all Australian whale strandings occur around Tasmania, Gales and her team must continue in the search for answers. When animals beach next to each other at the same time, the most common cause has nothing to do with humans at all. Theyre highly social creatures, says Gales. When they mass strand its complete panic and chaos. If one of the group strands and sounds the alarm, others will try to swim to its aid, and become stuck themselves. Activities such as sonar testing can hint at when a stranding may occur, but if conservationists are to reduce the number of strandings, or improve rescue operations, they need information on where strandings are likely to occur as well. With this in mind, Ralph James, physicist at the University of Western Australia in Perth, thinks he may have discovered why whales turn up only on some beaches. In 1986 he went to Augusta, Western Australia, where more than 100 false killer whales had beached. I found out from chatting to the locals that whales had been stranding there for decades. So I asked myself, what is it about this beach? From this question that James pondered over 20 years ago, grew the universitys Whale Stranding Analysis Project. Data has since revealed that all mass strandings around Australia occur on gently sloping sandy beaches, some with inclines of less than 0.5%. For whale species that depend on an echolocation system to navigate, this kind of beach spells disaster. Usually, as they swim, they make clicking noises, and the resulting sound waves are reflected in an echo and travel back to them. However, these just fade out on shallow beaches, so the whale doesnt hear an echo and it crashes onto the shore. But that is not all. Physics, it appears, can help with the when as well as the where. The ocean is full of bubbles. Larger ones rise quickly to the surface and disappear, whilst smaller ones called microbubbles can last for days. It is these that absorb whale clicks! Rough weather generates more bubbles than usual, James adds. So, during and after a storm, echolocating whales are essentially swimming blind. Last year was a bad one for strandings in Australia. Can we predict if this or any other year will be any better? Some scientists believe we can. They have found trends which could be used to forecast bad years for strandings in the future. In 2005, a survey by Klaus Vanselow and Klaus Ricklefs of sperm whale strandings in the North Sea even found a correlation between these and the sunspot cycle, and suggested that changes in the Earths magnetic field might be involved. But others are sceptical. Their study was interesting ... but the analyses they used were flawed on a number of levels, says Evans. In the same year, she co-authored a study on Australian strandings that uncovered a completely different trend. We analysed data from 1920 to 2002 ... and observed a clear periodicity in the number of whales stranded each year that coincides with a major climatic cycle. To put it more simply, she says, in the years when strong westerly and southerly winds bring cool water rich in nutrients closer to the Australia coast, there is an increase in the number of fish. The whales follow. So what causes mass strandings? Its probably many different components, says James. And he is probably right. But the point is we now know what many of those components are.", "hypothesis": "The whales stranded in Greece were found at different points along the coast.", "gold_label": "entailment"}
{"uid": "id_474", "premise": "Whale Strandings When the last stranded whale of a group eventually dies, the story does not end there. A team of researchers begins to investigate, collecting skin samples for instance, recording anything that could help them answer the crucial question: why? Theories abound, some more convincing than others. In recent years, navy sonar has been accused of causing certain whales to strand. It is known that noise pollution from offshore industry, shipping and sonar can impair underwater communication, but can it really drive whales onto our beaches? In 1998, researchers at the Pelagos Cetacean Research Institute, a Greek non-profit scientific group, linked whale strandings with low- frequency sonar tests being carried out by the North Atlantic Treaty Organisation (NATO). They recorded the stranding of 12 Cuviers beaked whales over 38.2 kilometres of coastline. NATO later admitted it had been testing new sonar technology in the same area at the time as the strandings had occurred. Mass whale strandings involve four or more animals. Typically they all wash ashore together, but in mass atypical strandings (such as the one in Greece), the whales dont strand as a group; they are scattered over a larger area. For humans, hearing a sudden loud noise might prove frightening, but it does not induce mass fatality. For whales, on the other hand, there is a theory on how sonar can kill. The noise can surprise the animal, causing it to swim too quickly to the surface. The result is decompression sickness, a hazard human divers know all too well. If a diver ascends too quickly from a high-pressure underwater environment to a lower-pressure one, gases dissolved in blood and tissue expand and form bubbles. The bubbles block the flow of blood to vital organs, and can ultimately lead to death. Plausible as this seems, it is still a theory and based on our more comprehensive knowledge of land-based animals. For this reason, some scientists are wary. Whale expert Karen Evans is one such scientist. Another is Rosemary Gales, a leading expert on whale strandings. She says sonar technology cannot always be blamed for mass strandings. Its a case-by-case situation. Whales have been stranding for a very long time pre-sonar. And when 80% of all Australian whale strandings occur around Tasmania, Gales and her team must continue in the search for answers. When animals beach next to each other at the same time, the most common cause has nothing to do with humans at all. Theyre highly social creatures, says Gales. When they mass strand its complete panic and chaos. If one of the group strands and sounds the alarm, others will try to swim to its aid, and become stuck themselves. Activities such as sonar testing can hint at when a stranding may occur, but if conservationists are to reduce the number of strandings, or improve rescue operations, they need information on where strandings are likely to occur as well. With this in mind, Ralph James, physicist at the University of Western Australia in Perth, thinks he may have discovered why whales turn up only on some beaches. In 1986 he went to Augusta, Western Australia, where more than 100 false killer whales had beached. I found out from chatting to the locals that whales had been stranding there for decades. So I asked myself, what is it about this beach? From this question that James pondered over 20 years ago, grew the universitys Whale Stranding Analysis Project. Data has since revealed that all mass strandings around Australia occur on gently sloping sandy beaches, some with inclines of less than 0.5%. For whale species that depend on an echolocation system to navigate, this kind of beach spells disaster. Usually, as they swim, they make clicking noises, and the resulting sound waves are reflected in an echo and travel back to them. However, these just fade out on shallow beaches, so the whale doesnt hear an echo and it crashes onto the shore. But that is not all. Physics, it appears, can help with the when as well as the where. The ocean is full of bubbles. Larger ones rise quickly to the surface and disappear, whilst smaller ones called microbubbles can last for days. It is these that absorb whale clicks! Rough weather generates more bubbles than usual, James adds. So, during and after a storm, echolocating whales are essentially swimming blind. Last year was a bad one for strandings in Australia. Can we predict if this or any other year will be any better? Some scientists believe we can. They have found trends which could be used to forecast bad years for strandings in the future. In 2005, a survey by Klaus Vanselow and Klaus Ricklefs of sperm whale strandings in the North Sea even found a correlation between these and the sunspot cycle, and suggested that changes in the Earths magnetic field might be involved. But others are sceptical. Their study was interesting ... but the analyses they used were flawed on a number of levels, says Evans. In the same year, she co-authored a study on Australian strandings that uncovered a completely different trend. We analysed data from 1920 to 2002 ... and observed a clear periodicity in the number of whales stranded each year that coincides with a major climatic cycle. To put it more simply, she says, in the years when strong westerly and southerly winds bring cool water rich in nutrients closer to the Australia coast, there is an increase in the number of fish. The whales follow. So what causes mass strandings? Its probably many different components, says James. And he is probably right. But the point is we now know what many of those components are.", "hypothesis": "The aim of the research by the Pelagos Institute in 1998 was to prove that navy sonar was responsible for whale strandings.", "gold_label": "neutral"}
{"uid": "id_475", "premise": "Whale Strandings When the last stranded whale of a group eventually dies, the story does not end there. A team of researchers begins to investigate, collecting skin samples for instance, recording anything that could help them answer the crucial question: why? Theories abound, some more convincing than others. In recent years, navy sonar has been accused of causing certain whales to strand. It is known that noise pollution from offshore industry, shipping and sonar can impair underwater communication, but can it really drive whales onto our beaches? In 1998, researchers at the Pelagos Cetacean Research Institute, a Greek non-profit scientific group, linked whale strandings with low- frequency sonar tests being carried out by the North Atlantic Treaty Organisation (NATO). They recorded the stranding of 12 Cuviers beaked whales over 38.2 kilometres of coastline. NATO later admitted it had been testing new sonar technology in the same area at the time as the strandings had occurred. Mass whale strandings involve four or more animals. Typically they all wash ashore together, but in mass atypical strandings (such as the one in Greece), the whales dont strand as a group; they are scattered over a larger area. For humans, hearing a sudden loud noise might prove frightening, but it does not induce mass fatality. For whales, on the other hand, there is a theory on how sonar can kill. The noise can surprise the animal, causing it to swim too quickly to the surface. The result is decompression sickness, a hazard human divers know all too well. If a diver ascends too quickly from a high-pressure underwater environment to a lower-pressure one, gases dissolved in blood and tissue expand and form bubbles. The bubbles block the flow of blood to vital organs, and can ultimately lead to death. Plausible as this seems, it is still a theory and based on our more comprehensive knowledge of land-based animals. For this reason, some scientists are wary. Whale expert Karen Evans is one such scientist. Another is Rosemary Gales, a leading expert on whale strandings. She says sonar technology cannot always be blamed for mass strandings. Its a case-by-case situation. Whales have been stranding for a very long time pre-sonar. And when 80% of all Australian whale strandings occur around Tasmania, Gales and her team must continue in the search for answers. When animals beach next to each other at the same time, the most common cause has nothing to do with humans at all. Theyre highly social creatures, says Gales. When they mass strand its complete panic and chaos. If one of the group strands and sounds the alarm, others will try to swim to its aid, and become stuck themselves. Activities such as sonar testing can hint at when a stranding may occur, but if conservationists are to reduce the number of strandings, or improve rescue operations, they need information on where strandings are likely to occur as well. With this in mind, Ralph James, physicist at the University of Western Australia in Perth, thinks he may have discovered why whales turn up only on some beaches. In 1986 he went to Augusta, Western Australia, where more than 100 false killer whales had beached. I found out from chatting to the locals that whales had been stranding there for decades. So I asked myself, what is it about this beach? From this question that James pondered over 20 years ago, grew the universitys Whale Stranding Analysis Project. Data has since revealed that all mass strandings around Australia occur on gently sloping sandy beaches, some with inclines of less than 0.5%. For whale species that depend on an echolocation system to navigate, this kind of beach spells disaster. Usually, as they swim, they make clicking noises, and the resulting sound waves are reflected in an echo and travel back to them. However, these just fade out on shallow beaches, so the whale doesnt hear an echo and it crashes onto the shore. But that is not all. Physics, it appears, can help with the when as well as the where. The ocean is full of bubbles. Larger ones rise quickly to the surface and disappear, whilst smaller ones called microbubbles can last for days. It is these that absorb whale clicks! Rough weather generates more bubbles than usual, James adds. So, during and after a storm, echolocating whales are essentially swimming blind. Last year was a bad one for strandings in Australia. Can we predict if this or any other year will be any better? Some scientists believe we can. They have found trends which could be used to forecast bad years for strandings in the future. In 2005, a survey by Klaus Vanselow and Klaus Ricklefs of sperm whale strandings in the North Sea even found a correlation between these and the sunspot cycle, and suggested that changes in the Earths magnetic field might be involved. But others are sceptical. Their study was interesting ... but the analyses they used were flawed on a number of levels, says Evans. In the same year, she co-authored a study on Australian strandings that uncovered a completely different trend. We analysed data from 1920 to 2002 ... and observed a clear periodicity in the number of whales stranded each year that coincides with a major climatic cycle. To put it more simply, she says, in the years when strong westerly and southerly winds bring cool water rich in nutrients closer to the Australia coast, there is an increase in the number of fish. The whales follow. So what causes mass strandings? Its probably many different components, says James. And he is probably right. But the point is we now know what many of those components are.", "hypothesis": "Rosemary Gales has questioned the research techniques used by the Greek scientists.", "gold_label": "neutral"}
{"uid": "id_476", "premise": "Whale Strandings When the last stranded whale of a group eventually dies, the story does not end there. A team of researchers begins to investigate, collecting skin samples for instance, recording anything that could help them answer the crucial question: why? Theories abound, some more convincing than others. In recent years, navy sonar has been accused of causing certain whales to strand. It is known that noise pollution from offshore industry, shipping and sonar can impair underwater communication, but can it really drive whales onto our beaches? In 1998, researchers at the Pelagos Cetacean Research Institute, a Greek non-profit scientific group, linked whale strandings with low- frequency sonar tests being carried out by the North Atlantic Treaty Organisation (NATO). They recorded the stranding of 12 Cuviers beaked whales over 38.2 kilometres of coastline. NATO later admitted it had been testing new sonar technology in the same area at the time as the strandings had occurred. Mass whale strandings involve four or more animals. Typically they all wash ashore together, but in mass atypical strandings (such as the one in Greece), the whales dont strand as a group; they are scattered over a larger area. For humans, hearing a sudden loud noise might prove frightening, but it does not induce mass fatality. For whales, on the other hand, there is a theory on how sonar can kill. The noise can surprise the animal, causing it to swim too quickly to the surface. The result is decompression sickness, a hazard human divers know all too well. If a diver ascends too quickly from a high-pressure underwater environment to a lower-pressure one, gases dissolved in blood and tissue expand and form bubbles. The bubbles block the flow of blood to vital organs, and can ultimately lead to death. Plausible as this seems, it is still a theory and based on our more comprehensive knowledge of land-based animals. For this reason, some scientists are wary. Whale expert Karen Evans is one such scientist. Another is Rosemary Gales, a leading expert on whale strandings. She says sonar technology cannot always be blamed for mass strandings. Its a case-by-case situation. Whales have been stranding for a very long time pre-sonar. And when 80% of all Australian whale strandings occur around Tasmania, Gales and her team must continue in the search for answers. When animals beach next to each other at the same time, the most common cause has nothing to do with humans at all. Theyre highly social creatures, says Gales. When they mass strand its complete panic and chaos. If one of the group strands and sounds the alarm, others will try to swim to its aid, and become stuck themselves. Activities such as sonar testing can hint at when a stranding may occur, but if conservationists are to reduce the number of strandings, or improve rescue operations, they need information on where strandings are likely to occur as well. With this in mind, Ralph James, physicist at the University of Western Australia in Perth, thinks he may have discovered why whales turn up only on some beaches. In 1986 he went to Augusta, Western Australia, where more than 100 false killer whales had beached. I found out from chatting to the locals that whales had been stranding there for decades. So I asked myself, what is it about this beach? From this question that James pondered over 20 years ago, grew the universitys Whale Stranding Analysis Project. Data has since revealed that all mass strandings around Australia occur on gently sloping sandy beaches, some with inclines of less than 0.5%. For whale species that depend on an echolocation system to navigate, this kind of beach spells disaster. Usually, as they swim, they make clicking noises, and the resulting sound waves are reflected in an echo and travel back to them. However, these just fade out on shallow beaches, so the whale doesnt hear an echo and it crashes onto the shore. But that is not all. Physics, it appears, can help with the when as well as the where. The ocean is full of bubbles. Larger ones rise quickly to the surface and disappear, whilst smaller ones called microbubbles can last for days. It is these that absorb whale clicks! Rough weather generates more bubbles than usual, James adds. So, during and after a storm, echolocating whales are essentially swimming blind. Last year was a bad one for strandings in Australia. Can we predict if this or any other year will be any better? Some scientists believe we can. They have found trends which could be used to forecast bad years for strandings in the future. In 2005, a survey by Klaus Vanselow and Klaus Ricklefs of sperm whale strandings in the North Sea even found a correlation between these and the sunspot cycle, and suggested that changes in the Earths magnetic field might be involved. But others are sceptical. Their study was interesting ... but the analyses they used were flawed on a number of levels, says Evans. In the same year, she co-authored a study on Australian strandings that uncovered a completely different trend. We analysed data from 1920 to 2002 ... and observed a clear periodicity in the number of whales stranded each year that coincides with a major climatic cycle. To put it more simply, she says, in the years when strong westerly and southerly winds bring cool water rich in nutrients closer to the Australia coast, there is an increase in the number of fish. The whales follow. So what causes mass strandings? Its probably many different components, says James. And he is probably right. But the point is we now know what many of those components are.", "hypothesis": "According to Gales, whales are likely to try to help another whale in trouble.", "gold_label": "entailment"}
{"uid": "id_477", "premise": "What are you laughing at? We like to think that laughing is the height of human sophistication. Our big brains let us see the humour in a strategically positioned pun, an unexpected plot twist or a clever piece of wordplay. But while joking and wit are uniquely human inventions, laughter certainly is not. Other creatures, including chimpanzees, gorillas, and even rats, chuckle. Obviously, they dont crack up at Homer Simpson or titter at the bosss dreadful jokes, but the fact that they laugh in the first place suggests that sniggers and chortles have been around for a lot longer than we have. It points the way to the origins of laughter, suggesting a much more practical purpose than you might think. There is no doubt that laughing typically involves groups of people. Laughter evolved as a signal to others it almost disappears when we are alone, says Robert Provine, a neuroscientist at the University of Maryland. Provine found that most laughter comes as a polite reaction to everyday remarks such as see you later, rather than anything particularly funny. And the way we laugh depends on the company were keeping. Men tend to laugh longer and harder when they are with other men, perhaps as a way of bonding. Women tend to laugh more and at a higher pitch when men are present, possibly indicating flirtation or even submission. To find the origins of laughter, Provine believes we need to look at the play. He points out that the masters of laughing are children, and nowhere is their talent more obvious than in the boisterous antics, and the original context plays, he says. Well-known primate watchers, including Dian Fossey and Jane Goodall, have long argued that chimps laugh while at play. The sound they produce is known as a panting laugh. It seems obvious when you watch their behaviour they even have the same ticklish spots as we do. But remove the context, and the parallel between human laughter and a chimps characteristic pant laugh is not so clear. When Provine played a tape of the pant laughs to 119 of his students, for example, only two guessed correctly what it was. These findings underline how chimp and human laughter vary. When we laugh the sound is usually produced by chopping up a single exhalation into a series of shorter with one sound produced on each inward and outward breath. The question is: does this pant laughter have the same source as our own laughter? New research lends weight to the idea that it does. The findings come from Elke Zimmerman, head of the Institute for Zoology in Germany, who compared the sounds made by babies and chimpanzees in response to tickling during the first year of their life. Using sound spectrographs to reveal the pitch and intensity of vocalizations, she discovered that chimp and human baby laughter follow broadly the same pattern. Zimmerman believes the closeness of baby laughter to chimp laughter supports the idea that laughter was around long before humans arrived on the scene. What started simply as a modification of breathing associated with enjoyable and playful interactions has acquired a symbolic meaning as an indicator of pleasure. Pinpointing when laughter developed is another matter. Humans and chimps share a common ancestor that lived perhaps 8 million years ago, but animals might have been laughing long before that. More distantly related primates, including gorillas, laugh, and anecdotal evidence suggests that other social mammals may do too. Scientists are currently testing such stories with a comparative analysis of just how common, laughter is, among animals. So far, though, the most compelling evidence for laughter beyond primates comes from research done by Jaak Panksepp from Bowling Green State University, Ohio, into the ultrasonic chirps produced by rats during play and in response to tickling. All this still doesnt answer the question of why we laugh at all. One idea is that if laughter and tickling originated as a way of sealing the relationship between mother and child. Another is that the reflex response to tickling is protective, alerting us to the presence of crawling creatures that might harm us or compelling us to defend the parts of our bodies that are most vulnerable in hand-to-hand combat. But the idea that has gained most popular in recent years is that laughter in response to tickling is a way for two individuals to signal and test their trust in one another. This hypothesis starts from the observation that although a little tickle can be enjoyable if it goes on too long it can be torture. By engaging in a bout of tickling, we put ourselves at the mercy of another individual, and laughing is a signal that our laughter is what makes it a reliable signal of trust according to Tom Flamson, a laughter researcher at the University of California, Los Angeles. Even in rats, laughter, tickle, play, and trust are linked. Rats chirp a lot when they play, says Flamson. These chirps can be aroused by tickling. And they get bonded to us as a result, which certainly seems like a show of trust. Well never know which animal laughed the first laugh, or why. But we can be sure it wasnt in response to a prehistoric joke. The funny thing is that while the origins of laughter are probably quite serious, we owe human laughter and our language-based humour to the same unique skill. While other animals pant, we alone can control our breath well enough to produce the sound of laughter. Without that control, there would also be no speech and no jokes to endure.", "hypothesis": "Primates lack sufficient breath control to be able to produce laughs the way humans do.", "gold_label": "entailment"}
{"uid": "id_478", "premise": "What are you laughing at? We like to think that laughing is the height of human sophistication. Our big brains let us see the humour in a strategically positioned pun, an unexpected plot twist or a clever piece of wordplay. But while joking and wit are uniquely human inventions, laughter certainly is not. Other creatures, including chimpanzees, gorillas, and even rats, chuckle. Obviously, they dont crack up at Homer Simpson or titter at the bosss dreadful jokes, but the fact that they laugh in the first place suggests that sniggers and chortles have been around for a lot longer than we have. It points the way to the origins of laughter, suggesting a much more practical purpose than you might think. There is no doubt that laughing typically involves groups of people. Laughter evolved as a signal to others it almost disappears when we are alone, says Robert Provine, a neuroscientist at the University of Maryland. Provine found that most laughter comes as a polite reaction to everyday remarks such as see you later, rather than anything particularly funny. And the way we laugh depends on the company were keeping. Men tend to laugh longer and harder when they are with other men, perhaps as a way of bonding. Women tend to laugh more and at a higher pitch when men are present, possibly indicating flirtation or even submission. To find the origins of laughter, Provine believes we need to look at the play. He points out that the masters of laughing are children, and nowhere is their talent more obvious than in the boisterous antics, and the original context plays, he says. Well-known primate watchers, including Dian Fossey and Jane Goodall, have long argued that chimps laugh while at play. The sound they produce is known as a panting laugh. It seems obvious when you watch their behaviour they even have the same ticklish spots as we do. But remove the context, and the parallel between human laughter and a chimps characteristic pant laugh is not so clear. When Provine played a tape of the pant laughs to 119 of his students, for example, only two guessed correctly what it was. These findings underline how chimp and human laughter vary. When we laugh the sound is usually produced by chopping up a single exhalation into a series of shorter with one sound produced on each inward and outward breath. The question is: does this pant laughter have the same source as our own laughter? New research lends weight to the idea that it does. The findings come from Elke Zimmerman, head of the Institute for Zoology in Germany, who compared the sounds made by babies and chimpanzees in response to tickling during the first year of their life. Using sound spectrographs to reveal the pitch and intensity of vocalizations, she discovered that chimp and human baby laughter follow broadly the same pattern. Zimmerman believes the closeness of baby laughter to chimp laughter supports the idea that laughter was around long before humans arrived on the scene. What started simply as a modification of breathing associated with enjoyable and playful interactions has acquired a symbolic meaning as an indicator of pleasure. Pinpointing when laughter developed is another matter. Humans and chimps share a common ancestor that lived perhaps 8 million years ago, but animals might have been laughing long before that. More distantly related primates, including gorillas, laugh, and anecdotal evidence suggests that other social mammals may do too. Scientists are currently testing such stories with a comparative analysis of just how common, laughter is, among animals. So far, though, the most compelling evidence for laughter beyond primates comes from research done by Jaak Panksepp from Bowling Green State University, Ohio, into the ultrasonic chirps produced by rats during play and in response to tickling. All this still doesnt answer the question of why we laugh at all. One idea is that if laughter and tickling originated as a way of sealing the relationship between mother and child. Another is that the reflex response to tickling is protective, alerting us to the presence of crawling creatures that might harm us or compelling us to defend the parts of our bodies that are most vulnerable in hand-to-hand combat. But the idea that has gained most popular in recent years is that laughter in response to tickling is a way for two individuals to signal and test their trust in one another. This hypothesis starts from the observation that although a little tickle can be enjoyable if it goes on too long it can be torture. By engaging in a bout of tickling, we put ourselves at the mercy of another individual, and laughing is a signal that our laughter is what makes it a reliable signal of trust according to Tom Flamson, a laughter researcher at the University of California, Los Angeles. Even in rats, laughter, tickle, play, and trust are linked. Rats chirp a lot when they play, says Flamson. These chirps can be aroused by tickling. And they get bonded to us as a result, which certainly seems like a show of trust. Well never know which animal laughed the first laugh, or why. But we can be sure it wasnt in response to a prehistoric joke. The funny thing is that while the origins of laughter are probably quite serious, we owe human laughter and our language-based humour to the same unique skill. While other animals pant, we alone can control our breath well enough to produce the sound of laughter. Without that control, there would also be no speech and no jokes to endure.", "hypothesis": "Chimpanzees produce laughter in a wider range of situations than rats do", "gold_label": "neutral"}
{"uid": "id_479", "premise": "What are you laughing at? We like to think that laughing is the height of human sophistication. Our big brains let us see the humour in a strategically positioned pun, an unexpected plot twist or a clever piece of wordplay. But while joking and wit are uniquely human inventions, laughter certainly is not. Other creatures, including chimpanzees, gorillas, and even rats, chuckle. Obviously, they dont crack up at Homer Simpson or titter at the bosss dreadful jokes, but the fact that they laugh in the first place suggests that sniggers and chortles have been around for a lot longer than we have. It points the way to the origins of laughter, suggesting a much more practical purpose than you might think. There is no doubt that laughing typically involves groups of people. Laughter evolved as a signal to others it almost disappears when we are alone, says Robert Provine, a neuroscientist at the University of Maryland. Provine found that most laughter comes as a polite reaction to everyday remarks such as see you later, rather than anything particularly funny. And the way we laugh depends on the company were keeping. Men tend to laugh longer and harder when they are with other men, perhaps as a way of bonding. Women tend to laugh more and at a higher pitch when men are present, possibly indicating flirtation or even submission. To find the origins of laughter, Provine believes we need to look at the play. He points out that the masters of laughing are children, and nowhere is their talent more obvious than in the boisterous antics, and the original context plays, he says. Well-known primate watchers, including Dian Fossey and Jane Goodall, have long argued that chimps laugh while at play. The sound they produce is known as a panting laugh. It seems obvious when you watch their behaviour they even have the same ticklish spots as we do. But remove the context, and the parallel between human laughter and a chimps characteristic pant laugh is not so clear. When Provine played a tape of the pant laughs to 119 of his students, for example, only two guessed correctly what it was. These findings underline how chimp and human laughter vary. When we laugh the sound is usually produced by chopping up a single exhalation into a series of shorter with one sound produced on each inward and outward breath. The question is: does this pant laughter have the same source as our own laughter? New research lends weight to the idea that it does. The findings come from Elke Zimmerman, head of the Institute for Zoology in Germany, who compared the sounds made by babies and chimpanzees in response to tickling during the first year of their life. Using sound spectrographs to reveal the pitch and intensity of vocalizations, she discovered that chimp and human baby laughter follow broadly the same pattern. Zimmerman believes the closeness of baby laughter to chimp laughter supports the idea that laughter was around long before humans arrived on the scene. What started simply as a modification of breathing associated with enjoyable and playful interactions has acquired a symbolic meaning as an indicator of pleasure. Pinpointing when laughter developed is another matter. Humans and chimps share a common ancestor that lived perhaps 8 million years ago, but animals might have been laughing long before that. More distantly related primates, including gorillas, laugh, and anecdotal evidence suggests that other social mammals may do too. Scientists are currently testing such stories with a comparative analysis of just how common, laughter is, among animals. So far, though, the most compelling evidence for laughter beyond primates comes from research done by Jaak Panksepp from Bowling Green State University, Ohio, into the ultrasonic chirps produced by rats during play and in response to tickling. All this still doesnt answer the question of why we laugh at all. One idea is that if laughter and tickling originated as a way of sealing the relationship between mother and child. Another is that the reflex response to tickling is protective, alerting us to the presence of crawling creatures that might harm us or compelling us to defend the parts of our bodies that are most vulnerable in hand-to-hand combat. But the idea that has gained most popular in recent years is that laughter in response to tickling is a way for two individuals to signal and test their trust in one another. This hypothesis starts from the observation that although a little tickle can be enjoyable if it goes on too long it can be torture. By engaging in a bout of tickling, we put ourselves at the mercy of another individual, and laughing is a signal that our laughter is what makes it a reliable signal of trust according to Tom Flamson, a laughter researcher at the University of California, Los Angeles. Even in rats, laughter, tickle, play, and trust are linked. Rats chirp a lot when they play, says Flamson. These chirps can be aroused by tickling. And they get bonded to us as a result, which certainly seems like a show of trust. Well never know which animal laughed the first laugh, or why. But we can be sure it wasnt in response to a prehistoric joke. The funny thing is that while the origins of laughter are probably quite serious, we owe human laughter and our language-based humour to the same unique skill. While other animals pant, we alone can control our breath well enough to produce the sound of laughter. Without that control, there would also be no speech and no jokes to endure.", "hypothesis": "Both men and women laugh more when they are with members of the same sex.", "gold_label": "neutral"}
{"uid": "id_480", "premise": "What determines whether a product will succeed or fail? In 1990, six out of ten new products lasted for less than three months in the marketplace. In 2007, two out of ten succeeded. These products are all promoted and great emphasis is placed on brand and logo. Still, most fail and manufacturers must go a bit further if they are to improve the prospects of their products success. Your iPod (you almost certainly have one) does not have a logo on it but it is instantly recognizable from its shape and feel. What about your mobile phone? There is a good chance it is a Nokia, and when it rings you immediately recognize the tone, which is a part of the Nokia brand. An incredible 60 per cent of people recognize it.", "hypothesis": "Given that the worlds population is around 8 billion people, the passage suggests that approaching 5 billion people will recognize the Nokia ring tone.", "gold_label": "contradiction"}
{"uid": "id_481", "premise": "What determines whether a product will succeed or fail? In 1990, six out of ten new products lasted for less than three months in the marketplace. In 2007, two out of ten succeeded. These products are all promoted and great emphasis is placed on brand and logo. Still, most fail and manufacturers must go a bit further if they are to improve the prospects of their products success. Your iPod (you almost certainly have one) does not have a logo on it but it is instantly recognizable from its shape and feel. What about your mobile phone? There is a good chance it is a Nokia, and when it rings you immediately recognize the tone, which is a part of the Nokia brand. An incredible 60 per cent of people recognize it.", "hypothesis": "The authors strategy is to look at success stories.", "gold_label": "entailment"}
{"uid": "id_482", "premise": "What determines whether a product will succeed or fail? In 1990, six out of ten new products lasted for less than three months in the marketplace. In 2007, two out of ten succeeded. These products are all promoted and great emphasis is placed on brand and logo. Still, most fail and manufacturers must go a bit further if they are to improve the prospects of their products success. Your iPod (you almost certainly have one) does not have a logo on it but it is instantly recognizable from its shape and feel. What about your mobile phone? There is a good chance it is a Nokia, and when it rings you immediately recognize the tone, which is a part of the Nokia brand. An incredible 60 per cent of people recognize it.", "hypothesis": "The passage is making the point that product success depends on more than a catchy brand name and a memorable logo.", "gold_label": "entailment"}
{"uid": "id_483", "premise": "What do we mean by being talented or gifted? The most obvious way is to look at the work someone does and if they are capable of significant success, label them as talented. The purely quantitative route percentage definition looks not at individuals, but at simple percentages, such as the top five per cent of the population, and labels them by definition as gifted. This definition has fallen from favour, eclipsed by the advent of IQ tests, favoured by luminaries such as Professor Hans Eysenck, where a series of written or verbal tests of general intelligence leads to a score of intelligence. The IQ test has been eclipsed in turn. Most people studying intelligence and creativity in the new millennium now prefer a broader definition, using a multifaceted approach where talents in many areas are recognised rather than purely concentrating on academic achievement. If we are therefore assuming that talented, creative or gifted individuals may need to be assessed across a range of abilities, does this mean intelligence can run in families as a genetic or inherited tendency? Mental dysfunction such as schizophrenia can, so is an efficient mental capacity passed on from parent to child? Animal experiments throw some light on this question, and on the whole area of whether it is genetics, the environment or a combination of the two that allows for intelligence and creative ability. Different strains of rats show great differences in intelligence or rat reasoning. If these are brought up in normal conditions and then through a maze to reach a food goal, the bright strain make far fewer wrong turns that the dull ones. But if the environment is made dull and boring the number of errors becomes equal. Return the rats to an exciting maze and the discrepancy returns as before but is much smaller. In other words, a dull rat in a stimulating environment will almost do as well as a bright rat who is bored in a normal one. This principle applies to humans too someone may be born with innate intelligence, but their environment probably has the final say over whether they become creative or even a genius. Evidence now exists that most young children, if given enough opportunities and encouragement, are able to achieve significant and sustainable levels of academic or sporting prowess. Bright or creative children are often physically very active at the same time, and so may receive more parental attention as a result almost by default in order to ensure their safety. They may also talk earlier, and this, in turn, breeds parental interest. This can sometimes cause problems with other siblings who may feel jealous even though they themselves may be bright. Their creative talents may be undervalued and so never come to fruition. Two themes seem to run through famously creative families as a result. The first is that the parents were able to identify the talents of each child, and nurture and encourage these accordingly but in an even-handed manner. Individual differences were encouraged, and friendly sibling rivalry was not seen as a particular problem. If the father is, say, a famous actor, there is no undue pressure for his children to follow him onto the boards, but instead their chosen interests are encouraged. There need not even by any obvious talent in such a family since there always needs to be someone who sets the family career in motion, as in the case of the Sheen acting dynasty. Martin Sheen was the seventh of ten children born to a Spanish immigrant father and an Irish mother. Despite intense parental disapproval he turned his back on entrance exams to university and borrowed cash from a local priest to start a fledgling acting career. His acting successes in films such as Badlands and Apocalypse Now made him one of the most highly-regarded actors of the 1970s. Three sons Emilio Estevez, Ramon Estevez and Charlie Sheen have followed him into the profession as a consequence of being inspired by his motivation and enthusiasm. A stream seems to run through creative families. Such children are not necessarily smothered with love by their parents. They feel loved and wanted, and are secure in their home, but are often more surrounded by an atmosphere of work and where following a calling appears to be important. They may see from their parents that it takes time and dedication to be master of a craft, and so are in less of a hurry to achieve for themselves once they start to work. The generation of creativity is complex: it is a mixture of genetics, the environment, parental teaching and luck that determines how successful or talented family members are. This last point luck is often not mentioned where talent is concerned but plays an undoubted part. Mozart, considered by many to be the finest composer of all time, was lucky to be living in an age that encouraged the writing of music. He was brought up surrounded by it, his father was a musician who encouraged him to the point of giving up his job to promote his child genius, and he learnt musical composition with frightening speed the speed of a genius. Mozart himself simply wanted to create the finest music ever written but did not necessarily view himself as a genius he could write sublime music at will, and so often preferred to lead a hedonistic lifestyle that he found more exciting than writing music to order. Albert Einstein and Bill Gates are two more examples of people whose talents have blossomed by virtue of the times they were living in. Einstein was a solitary, somewhat slow child who had affection at home but whose phenomenal intelligence emerged without any obvious parental input. This may have been partly due to the fact that at the start of the 20th Century a lot of the Newtonian laws of physics were being questioned, leaving a fertile ground for ideas such as his to be developed. Bill Gates may have had the creative vision to develop Microsoft, but without the new computer age dawning at the same time he may never have achieved the position on the world stage he now occupies.", "hypothesis": "The importance of luck in the genius equation tends to be ignored.", "gold_label": "entailment"}
{"uid": "id_484", "premise": "What do we mean by being talented or gifted? The most obvious way is to look at the work someone does and if they are capable of significant success, label them as talented. The purely quantitative route percentage definition looks not at individuals, but at simple percentages, such as the top five per cent of the population, and labels them by definition as gifted. This definition has fallen from favour, eclipsed by the advent of IQ tests, favoured by luminaries such as Professor Hans Eysenck, where a series of written or verbal tests of general intelligence leads to a score of intelligence. The IQ test has been eclipsed in turn. Most people studying intelligence and creativity in the new millennium now prefer a broader definition, using a multifaceted approach where talents in many areas are recognised rather than purely concentrating on academic achievement. If we are therefore assuming that talented, creative or gifted individuals may need to be assessed across a range of abilities, does this mean intelligence can run in families as a genetic or inherited tendency? Mental dysfunction such as schizophrenia can, so is an efficient mental capacity passed on from parent to child? Animal experiments throw some light on this question, and on the whole area of whether it is genetics, the environment or a combination of the two that allows for intelligence and creative ability. Different strains of rats show great differences in intelligence or rat reasoning. If these are brought up in normal conditions and then through a maze to reach a food goal, the bright strain make far fewer wrong turns that the dull ones. But if the environment is made dull and boring the number of errors becomes equal. Return the rats to an exciting maze and the discrepancy returns as before but is much smaller. In other words, a dull rat in a stimulating environment will almost do as well as a bright rat who is bored in a normal one. This principle applies to humans too someone may be born with innate intelligence, but their environment probably has the final say over whether they become creative or even a genius. Evidence now exists that most young children, if given enough opportunities and encouragement, are able to achieve significant and sustainable levels of academic or sporting prowess. Bright or creative children are often physically very active at the same time, and so may receive more parental attention as a result almost by default in order to ensure their safety. They may also talk earlier, and this, in turn, breeds parental interest. This can sometimes cause problems with other siblings who may feel jealous even though they themselves may be bright. Their creative talents may be undervalued and so never come to fruition. Two themes seem to run through famously creative families as a result. The first is that the parents were able to identify the talents of each child, and nurture and encourage these accordingly but in an even-handed manner. Individual differences were encouraged, and friendly sibling rivalry was not seen as a particular problem. If the father is, say, a famous actor, there is no undue pressure for his children to follow him onto the boards, but instead their chosen interests are encouraged. There need not even by any obvious talent in such a family since there always needs to be someone who sets the family career in motion, as in the case of the Sheen acting dynasty. Martin Sheen was the seventh of ten children born to a Spanish immigrant father and an Irish mother. Despite intense parental disapproval he turned his back on entrance exams to university and borrowed cash from a local priest to start a fledgling acting career. His acting successes in films such as Badlands and Apocalypse Now made him one of the most highly-regarded actors of the 1970s. Three sons Emilio Estevez, Ramon Estevez and Charlie Sheen have followed him into the profession as a consequence of being inspired by his motivation and enthusiasm. A stream seems to run through creative families. Such children are not necessarily smothered with love by their parents. They feel loved and wanted, and are secure in their home, but are often more surrounded by an atmosphere of work and where following a calling appears to be important. They may see from their parents that it takes time and dedication to be master of a craft, and so are in less of a hurry to achieve for themselves once they start to work. The generation of creativity is complex: it is a mixture of genetics, the environment, parental teaching and luck that determines how successful or talented family members are. This last point luck is often not mentioned where talent is concerned but plays an undoubted part. Mozart, considered by many to be the finest composer of all time, was lucky to be living in an age that encouraged the writing of music. He was brought up surrounded by it, his father was a musician who encouraged him to the point of giving up his job to promote his child genius, and he learnt musical composition with frightening speed the speed of a genius. Mozart himself simply wanted to create the finest music ever written but did not necessarily view himself as a genius he could write sublime music at will, and so often preferred to lead a hedonistic lifestyle that he found more exciting than writing music to order. Albert Einstein and Bill Gates are two more examples of people whose talents have blossomed by virtue of the times they were living in. Einstein was a solitary, somewhat slow child who had affection at home but whose phenomenal intelligence emerged without any obvious parental input. This may have been partly due to the fact that at the start of the 20th Century a lot of the Newtonian laws of physics were being questioned, leaving a fertile ground for ideas such as his to be developed. Bill Gates may have had the creative vision to develop Microsoft, but without the new computer age dawning at the same time he may never have achieved the position on the world stage he now occupies.", "hypothesis": "Einstein and Gates would have achieved success in any era.", "gold_label": "contradiction"}
{"uid": "id_485", "premise": "What do we mean by being talented or gifted? The most obvious way is to look at the work someone does and if they are capable of significant success, label them as talented. The purely quantitative route percentage definition looks not at individuals, but at simple percentages, such as the top five per cent of the population, and labels them by definition as gifted. This definition has fallen from favour, eclipsed by the advent of IQ tests, favoured by luminaries such as Professor Hans Eysenck, where a series of written or verbal tests of general intelligence leads to a score of intelligence. The IQ test has been eclipsed in turn. Most people studying intelligence and creativity in the new millennium now prefer a broader definition, using a multifaceted approach where talents in many areas are recognised rather than purely concentrating on academic achievement. If we are therefore assuming that talented, creative or gifted individuals may need to be assessed across a range of abilities, does this mean intelligence can run in families as a genetic or inherited tendency? Mental dysfunction such as schizophrenia can, so is an efficient mental capacity passed on from parent to child? Animal experiments throw some light on this question, and on the whole area of whether it is genetics, the environment or a combination of the two that allows for intelligence and creative ability. Different strains of rats show great differences in intelligence or rat reasoning. If these are brought up in normal conditions and then through a maze to reach a food goal, the bright strain make far fewer wrong turns that the dull ones. But if the environment is made dull and boring the number of errors becomes equal. Return the rats to an exciting maze and the discrepancy returns as before but is much smaller. In other words, a dull rat in a stimulating environment will almost do as well as a bright rat who is bored in a normal one. This principle applies to humans too someone may be born with innate intelligence, but their environment probably has the final say over whether they become creative or even a genius. Evidence now exists that most young children, if given enough opportunities and encouragement, are able to achieve significant and sustainable levels of academic or sporting prowess. Bright or creative children are often physically very active at the same time, and so may receive more parental attention as a result almost by default in order to ensure their safety. They may also talk earlier, and this, in turn, breeds parental interest. This can sometimes cause problems with other siblings who may feel jealous even though they themselves may be bright. Their creative talents may be undervalued and so never come to fruition. Two themes seem to run through famously creative families as a result. The first is that the parents were able to identify the talents of each child, and nurture and encourage these accordingly but in an even-handed manner. Individual differences were encouraged, and friendly sibling rivalry was not seen as a particular problem. If the father is, say, a famous actor, there is no undue pressure for his children to follow him onto the boards, but instead their chosen interests are encouraged. There need not even by any obvious talent in such a family since there always needs to be someone who sets the family career in motion, as in the case of the Sheen acting dynasty. Martin Sheen was the seventh of ten children born to a Spanish immigrant father and an Irish mother. Despite intense parental disapproval he turned his back on entrance exams to university and borrowed cash from a local priest to start a fledgling acting career. His acting successes in films such as Badlands and Apocalypse Now made him one of the most highly-regarded actors of the 1970s. Three sons Emilio Estevez, Ramon Estevez and Charlie Sheen have followed him into the profession as a consequence of being inspired by his motivation and enthusiasm. A stream seems to run through creative families. Such children are not necessarily smothered with love by their parents. They feel loved and wanted, and are secure in their home, but are often more surrounded by an atmosphere of work and where following a calling appears to be important. They may see from their parents that it takes time and dedication to be master of a craft, and so are in less of a hurry to achieve for themselves once they start to work. The generation of creativity is complex: it is a mixture of genetics, the environment, parental teaching and luck that determines how successful or talented family members are. This last point luck is often not mentioned where talent is concerned but plays an undoubted part. Mozart, considered by many to be the finest composer of all time, was lucky to be living in an age that encouraged the writing of music. He was brought up surrounded by it, his father was a musician who encouraged him to the point of giving up his job to promote his child genius, and he learnt musical composition with frightening speed the speed of a genius. Mozart himself simply wanted to create the finest music ever written but did not necessarily view himself as a genius he could write sublime music at will, and so often preferred to lead a hedonistic lifestyle that he found more exciting than writing music to order. Albert Einstein and Bill Gates are two more examples of people whose talents have blossomed by virtue of the times they were living in. Einstein was a solitary, somewhat slow child who had affection at home but whose phenomenal intelligence emerged without any obvious parental input. This may have been partly due to the fact that at the start of the 20th Century a lot of the Newtonian laws of physics were being questioned, leaving a fertile ground for ideas such as his to be developed. Bill Gates may have had the creative vision to develop Microsoft, but without the new computer age dawning at the same time he may never have achieved the position on the world stage he now occupies.", "hypothesis": "Intelligence tests have now been proved to be unreliable.", "gold_label": "neutral"}
{"uid": "id_486", "premise": "What do we mean by being talented or gifted? The most obvious way is to look at the work someone does and if they are capable of significant success, label them as talented. The purely quantitative route percentage definition looks not at individuals, but at simple percentages, such as the top five per cent of the population, and labels them by definition as gifted. This definition has fallen from favour, eclipsed by the advent of IQ tests, favoured by luminaries such as Professor Hans Eysenck, where a series of written or verbal tests of general intelligence leads to a score of intelligence. The IQ test has been eclipsed in turn. Most people studying intelligence and creativity in the new millennium now prefer a broader definition, using a multifaceted approach where talents in many areas are recognised rather than purely concentrating on academic achievement. If we are therefore assuming that talented, creative or gifted individuals may need to be assessed across a range of abilities, does this mean intelligence can run in families as a genetic or inherited tendency? Mental dysfunction such as schizophrenia can, so is an efficient mental capacity passed on from parent to child? Animal experiments throw some light on this question, and on the whole area of whether it is genetics, the environment or a combination of the two that allows for intelligence and creative ability. Different strains of rats show great differences in intelligence or rat reasoning. If these are brought up in normal conditions and then through a maze to reach a food goal, the bright strain make far fewer wrong turns that the dull ones. But if the environment is made dull and boring the number of errors becomes equal. Return the rats to an exciting maze and the discrepancy returns as before but is much smaller. In other words, a dull rat in a stimulating environment will almost do as well as a bright rat who is bored in a normal one. This principle applies to humans too someone may be born with innate intelligence, but their environment probably has the final say over whether they become creative or even a genius. Evidence now exists that most young children, if given enough opportunities and encouragement, are able to achieve significant and sustainable levels of academic or sporting prowess. Bright or creative children are often physically very active at the same time, and so may receive more parental attention as a result almost by default in order to ensure their safety. They may also talk earlier, and this, in turn, breeds parental interest. This can sometimes cause problems with other siblings who may feel jealous even though they themselves may be bright. Their creative talents may be undervalued and so never come to fruition. Two themes seem to run through famously creative families as a result. The first is that the parents were able to identify the talents of each child, and nurture and encourage these accordingly but in an even-handed manner. Individual differences were encouraged, and friendly sibling rivalry was not seen as a particular problem. If the father is, say, a famous actor, there is no undue pressure for his children to follow him onto the boards, but instead their chosen interests are encouraged. There need not even by any obvious talent in such a family since there always needs to be someone who sets the family career in motion, as in the case of the Sheen acting dynasty. Martin Sheen was the seventh of ten children born to a Spanish immigrant father and an Irish mother. Despite intense parental disapproval he turned his back on entrance exams to university and borrowed cash from a local priest to start a fledgling acting career. His acting successes in films such as Badlands and Apocalypse Now made him one of the most highly-regarded actors of the 1970s. Three sons Emilio Estevez, Ramon Estevez and Charlie Sheen have followed him into the profession as a consequence of being inspired by his motivation and enthusiasm. A stream seems to run through creative families. Such children are not necessarily smothered with love by their parents. They feel loved and wanted, and are secure in their home, but are often more surrounded by an atmosphere of work and where following a calling appears to be important. They may see from their parents that it takes time and dedication to be master of a craft, and so are in less of a hurry to achieve for themselves once they start to work. The generation of creativity is complex: it is a mixture of genetics, the environment, parental teaching and luck that determines how successful or talented family members are. This last point luck is often not mentioned where talent is concerned but plays an undoubted part. Mozart, considered by many to be the finest composer of all time, was lucky to be living in an age that encouraged the writing of music. He was brought up surrounded by it, his father was a musician who encouraged him to the point of giving up his job to promote his child genius, and he learnt musical composition with frightening speed the speed of a genius. Mozart himself simply wanted to create the finest music ever written but did not necessarily view himself as a genius he could write sublime music at will, and so often preferred to lead a hedonistic lifestyle that he found more exciting than writing music to order. Albert Einstein and Bill Gates are two more examples of people whose talents have blossomed by virtue of the times they were living in. Einstein was a solitary, somewhat slow child who had affection at home but whose phenomenal intelligence emerged without any obvious parental input. This may have been partly due to the fact that at the start of the 20th Century a lot of the Newtonian laws of physics were being questioned, leaving a fertile ground for ideas such as his to be developed. Bill Gates may have had the creative vision to develop Microsoft, but without the new computer age dawning at the same time he may never have achieved the position on the world stage he now occupies.", "hypothesis": "The brother or sister of a gifted older child may fail to fulfil their own potential.", "gold_label": "entailment"}
{"uid": "id_487", "premise": "What do we mean by being talented or gifted? The most obvious way is to look at the work someone does and if they are capable of significant success, label them as talented. The purely quantitative route percentage definition looks not at individuals, but at simple percentages, such as the top five per cent of the population, and labels them by definition as gifted. This definition has fallen from favour, eclipsed by the advent of IQ tests, favoured by luminaries such as Professor Hans Eysenck, where a series of written or verbal tests of general intelligence leads to a score of intelligence. The IQ test has been eclipsed in turn. Most people studying intelligence and creativity in the new millennium now prefer a broader definition, using a multifaceted approach where talents in many areas are recognised rather than purely concentrating on academic achievement. If we are therefore assuming that talented, creative or gifted individuals may need to be assessed across a range of abilities, does this mean intelligence can run in families as a genetic or inherited tendency? Mental dysfunction such as schizophrenia can, so is an efficient mental capacity passed on from parent to child? Animal experiments throw some light on this question, and on the whole area of whether it is genetics, the environment or a combination of the two that allows for intelligence and creative ability. Different strains of rats show great differences in intelligence or rat reasoning. If these are brought up in normal conditions and then through a maze to reach a food goal, the bright strain make far fewer wrong turns that the dull ones. But if the environment is made dull and boring the number of errors becomes equal. Return the rats to an exciting maze and the discrepancy returns as before but is much smaller. In other words, a dull rat in a stimulating environment will almost do as well as a bright rat who is bored in a normal one. This principle applies to humans too someone may be born with innate intelligence, but their environment probably has the final say over whether they become creative or even a genius. Evidence now exists that most young children, if given enough opportunities and encouragement, are able to achieve significant and sustainable levels of academic or sporting prowess. Bright or creative children are often physically very active at the same time, and so may receive more parental attention as a result almost by default in order to ensure their safety. They may also talk earlier, and this, in turn, breeds parental interest. This can sometimes cause problems with other siblings who may feel jealous even though they themselves may be bright. Their creative talents may be undervalued and so never come to fruition. Two themes seem to run through famously creative families as a result. The first is that the parents were able to identify the talents of each child, and nurture and encourage these accordingly but in an even-handed manner. Individual differences were encouraged, and friendly sibling rivalry was not seen as a particular problem. If the father is, say, a famous actor, there is no undue pressure for his children to follow him onto the boards, but instead their chosen interests are encouraged. There need not even by any obvious talent in such a family since there always needs to be someone who sets the family career in motion, as in the case of the Sheen acting dynasty. Martin Sheen was the seventh of ten children born to a Spanish immigrant father and an Irish mother. Despite intense parental disapproval he turned his back on entrance exams to university and borrowed cash from a local priest to start a fledgling acting career. His acting successes in films such as Badlands and Apocalypse Now made him one of the most highly-regarded actors of the 1970s. Three sons Emilio Estevez, Ramon Estevez and Charlie Sheen have followed him into the profession as a consequence of being inspired by his motivation and enthusiasm. A stream seems to run through creative families. Such children are not necessarily smothered with love by their parents. They feel loved and wanted, and are secure in their home, but are often more surrounded by an atmosphere of work and where following a calling appears to be important. They may see from their parents that it takes time and dedication to be master of a craft, and so are in less of a hurry to achieve for themselves once they start to work. The generation of creativity is complex: it is a mixture of genetics, the environment, parental teaching and luck that determines how successful or talented family members are. This last point luck is often not mentioned where talent is concerned but plays an undoubted part. Mozart, considered by many to be the finest composer of all time, was lucky to be living in an age that encouraged the writing of music. He was brought up surrounded by it, his father was a musician who encouraged him to the point of giving up his job to promote his child genius, and he learnt musical composition with frightening speed the speed of a genius. Mozart himself simply wanted to create the finest music ever written but did not necessarily view himself as a genius he could write sublime music at will, and so often preferred to lead a hedonistic lifestyle that he found more exciting than writing music to order. Albert Einstein and Bill Gates are two more examples of people whose talents have blossomed by virtue of the times they were living in. Einstein was a solitary, somewhat slow child who had affection at home but whose phenomenal intelligence emerged without any obvious parental input. This may have been partly due to the fact that at the start of the 20th Century a lot of the Newtonian laws of physics were being questioned, leaving a fertile ground for ideas such as his to be developed. Bill Gates may have had the creative vision to develop Microsoft, but without the new computer age dawning at the same time he may never have achieved the position on the world stage he now occupies.", "hypothesis": "Mozart was acutely aware of his own remarkable talent.", "gold_label": "contradiction"}
{"uid": "id_488", "premise": "What is Meaning The end, product of education, yours and mine and everybodys, is the total pattern of reactions and possible reactions we have inside ourselves. If you did not have within you at this moment the pattern of reactions that we call the ability to read. you would see here only meaningless black marks on paper. Because of the trained patterns of response, you are (or are not) stirred to patriotism by martial music, your feelings of reverence are aroused by symbols of your religion, you listen more respectfully to the health advice of someone who has MD after his name than to that of someone who hasnt. What I call here a pattern of reactions, then, is the sum total of the ways we act in response to events, to words, and to symbols. Our reaction patterns or our semantic habits, are the internal and most important residue of whatever years of education or miseducation we may have received from our parents conduct toward us in childhood as well as their teachings, from the formal education we may have had, from all the lectures we have listened to, from the radio programs and the movies and television shows we have experienced, from all the books and newspapers and comic strips we have read, from the conversations we have had with friends and associates, and from all our experiences. If, as the result of all these influences that make us what we are, our semantic habits are reasonably similar to those of most people around us, we are regarded as normal, or perhaps dull. If our semantic habits are noticeably different from those of others, we are regarded as individualistic or original. or, if the differences are disapproved of or viewed with alarm, as crazy. Semantics is sometimes defined in dictionaries as the science of the meaning of words which would not be a bad definition if people didnt assume that the search for the meanings of words begins and ends with looking them up in a dictionary. If one stops to think for a moment, it is clear that to define a word, as a dictionary does, is simply to explain the word with more words. To be thorough about defining, we should next have to define the words used in the definition, then define the words used in defining the words used in the definition and so on. Defining words with more words, in short, gets us at once into what mathematicians call an infinite regress. Alternatively, it can get us into the kind of run-around we sometimes encounter when we look up impertinence and find it defined as impudence, so we look up impudence and find it defined as impertinence. Yetand here we come to another common reaction patternpeople often act as if words can be explained fully with more words. To a person who asked for a definition of jazz, Louis Armstrong is said to have replied, Man. when you got to ask what it is, youll never get to know, proving himself to be an intuitive semanticist as well as a great trumpet player. Semantics, then, does not deal with the meaning of words as that expression is commonly understood. P. W. Bridgman, the Nobel Prize winner and physicist, once wrote, The true meaning of a term is to be found by observing what a man does with it, not by what he says about it. He made an enormous contribution to science by showing that the meaning of a scientific term lies in the operations, the things done, that establish its validity, rather than in verbal definitions. Here is a simple, everyday kind of example of operational definition. If you say, This table measures six feet in length, you could prove it by taking a foot rule, performing the operation of laying it end to end while counting, One... two... three... four... But if you sayand revolutionists have started uprisings with just this statement Man is born free, but everywhere he is in chains! what operations could you perform to demonstrate its accuracy or inaccuracy? But let us carry this suggestion of operationalism outside the physical sciences where Bridgman applied it, and observe what operations people perform as the result of both the language they use and the language other people use in communicating to them. Here is a personnel manager studying an application blank. He comes to the words Education: Harvard University, and drops the application blank in the wastebasket (thats the operation) because, as he would say if you asked him, I dont like Harvard men. This is an instance of meaning at workbut it is not a meaning that can be found in dictionaries. If I seem to be taking a long time to explain what semantics is about, it is because I am trying, in the course of explanation, to introduce the reader to a certain way of looking at human behavior. I say human responses because, so far as we know, human beings are the only creatures that have, over and above that biological equipment which we have in common with other creatures, the additional capacity for manufacturing symbols and systems of symbols. When we react to a flag, we are not reacting simply to a piece of cloth, but to the meaning with which it has been symbolically endowed. When we react to a word, we are not reacting to a set of sounds, but to the meaning with which that set of sounds has been symbolically endowed. A basic idea in general semantics, therefore, is that the meaning of words (or other symbols) is not in the words, but in our own semantic reactions. If I were to tell a shockingly obscene story in Arabic or Hindustani or Swahili before an audience that understood only English, no one would blush or be angry; the story would be neither shocking nor obscene-induced, it would not even be a story. Likewise, the value of a dollar bill is not in the bill, but in our social agreement to accept it as a symbol of value. If that agreement were to break down through the collapse of our government, the dollar bill would become only a scrap of paper. We do not understand a dollar bill by staring at it long and hard. We understand it by observing how people act with respect to it. We understand it by understanding the social mechanisms and the loyalties that keep it meaningful. Semantics is therefore a social study, basic to all other social studies.", "hypothesis": "Some statements are incapable of being proved or disproved.", "gold_label": "entailment"}
{"uid": "id_489", "premise": "What is Meaning The end, product of education, yours and mine and everybodys, is the total pattern of reactions and possible reactions we have inside ourselves. If you did not have within you at this moment the pattern of reactions that we call the ability to read. you would see here only meaningless black marks on paper. Because of the trained patterns of response, you are (or are not) stirred to patriotism by martial music, your feelings of reverence are aroused by symbols of your religion, you listen more respectfully to the health advice of someone who has MD after his name than to that of someone who hasnt. What I call here a pattern of reactions, then, is the sum total of the ways we act in response to events, to words, and to symbols. Our reaction patterns or our semantic habits, are the internal and most important residue of whatever years of education or miseducation we may have received from our parents conduct toward us in childhood as well as their teachings, from the formal education we may have had, from all the lectures we have listened to, from the radio programs and the movies and television shows we have experienced, from all the books and newspapers and comic strips we have read, from the conversations we have had with friends and associates, and from all our experiences. If, as the result of all these influences that make us what we are, our semantic habits are reasonably similar to those of most people around us, we are regarded as normal, or perhaps dull. If our semantic habits are noticeably different from those of others, we are regarded as individualistic or original. or, if the differences are disapproved of or viewed with alarm, as crazy. Semantics is sometimes defined in dictionaries as the science of the meaning of words which would not be a bad definition if people didnt assume that the search for the meanings of words begins and ends with looking them up in a dictionary. If one stops to think for a moment, it is clear that to define a word, as a dictionary does, is simply to explain the word with more words. To be thorough about defining, we should next have to define the words used in the definition, then define the words used in defining the words used in the definition and so on. Defining words with more words, in short, gets us at once into what mathematicians call an infinite regress. Alternatively, it can get us into the kind of run-around we sometimes encounter when we look up impertinence and find it defined as impudence, so we look up impudence and find it defined as impertinence. Yetand here we come to another common reaction patternpeople often act as if words can be explained fully with more words. To a person who asked for a definition of jazz, Louis Armstrong is said to have replied, Man. when you got to ask what it is, youll never get to know, proving himself to be an intuitive semanticist as well as a great trumpet player. Semantics, then, does not deal with the meaning of words as that expression is commonly understood. P. W. Bridgman, the Nobel Prize winner and physicist, once wrote, The true meaning of a term is to be found by observing what a man does with it, not by what he says about it. He made an enormous contribution to science by showing that the meaning of a scientific term lies in the operations, the things done, that establish its validity, rather than in verbal definitions. Here is a simple, everyday kind of example of operational definition. If you say, This table measures six feet in length, you could prove it by taking a foot rule, performing the operation of laying it end to end while counting, One... two... three... four... But if you sayand revolutionists have started uprisings with just this statement Man is born free, but everywhere he is in chains! what operations could you perform to demonstrate its accuracy or inaccuracy? But let us carry this suggestion of operationalism outside the physical sciences where Bridgman applied it, and observe what operations people perform as the result of both the language they use and the language other people use in communicating to them. Here is a personnel manager studying an application blank. He comes to the words Education: Harvard University, and drops the application blank in the wastebasket (thats the operation) because, as he would say if you asked him, I dont like Harvard men. This is an instance of meaning at workbut it is not a meaning that can be found in dictionaries. If I seem to be taking a long time to explain what semantics is about, it is because I am trying, in the course of explanation, to introduce the reader to a certain way of looking at human behavior. I say human responses because, so far as we know, human beings are the only creatures that have, over and above that biological equipment which we have in common with other creatures, the additional capacity for manufacturing symbols and systems of symbols. When we react to a flag, we are not reacting simply to a piece of cloth, but to the meaning with which it has been symbolically endowed. When we react to a word, we are not reacting to a set of sounds, but to the meaning with which that set of sounds has been symbolically endowed. A basic idea in general semantics, therefore, is that the meaning of words (or other symbols) is not in the words, but in our own semantic reactions. If I were to tell a shockingly obscene story in Arabic or Hindustani or Swahili before an audience that understood only English, no one would blush or be angry; the story would be neither shocking nor obscene-induced, it would not even be a story. Likewise, the value of a dollar bill is not in the bill, but in our social agreement to accept it as a symbol of value. If that agreement were to break down through the collapse of our government, the dollar bill would become only a scrap of paper. We do not understand a dollar bill by staring at it long and hard. We understand it by observing how people act with respect to it. We understand it by understanding the social mechanisms and the loyalties that keep it meaningful. Semantics is therefore a social study, basic to all other social studies.", "hypothesis": "Flags and words are eliciting responses of the same reason.", "gold_label": "entailment"}
{"uid": "id_490", "premise": "What is Meaning The end, product of education, yours and mine and everybodys, is the total pattern of reactions and possible reactions we have inside ourselves. If you did not have within you at this moment the pattern of reactions that we call the ability to read. you would see here only meaningless black marks on paper. Because of the trained patterns of response, you are (or are not) stirred to patriotism by martial music, your feelings of reverence are aroused by symbols of your religion, you listen more respectfully to the health advice of someone who has MD after his name than to that of someone who hasnt. What I call here a pattern of reactions, then, is the sum total of the ways we act in response to events, to words, and to symbols. Our reaction patterns or our semantic habits, are the internal and most important residue of whatever years of education or miseducation we may have received from our parents conduct toward us in childhood as well as their teachings, from the formal education we may have had, from all the lectures we have listened to, from the radio programs and the movies and television shows we have experienced, from all the books and newspapers and comic strips we have read, from the conversations we have had with friends and associates, and from all our experiences. If, as the result of all these influences that make us what we are, our semantic habits are reasonably similar to those of most people around us, we are regarded as normal, or perhaps dull. If our semantic habits are noticeably different from those of others, we are regarded as individualistic or original. or, if the differences are disapproved of or viewed with alarm, as crazy. Semantics is sometimes defined in dictionaries as the science of the meaning of words which would not be a bad definition if people didnt assume that the search for the meanings of words begins and ends with looking them up in a dictionary. If one stops to think for a moment, it is clear that to define a word, as a dictionary does, is simply to explain the word with more words. To be thorough about defining, we should next have to define the words used in the definition, then define the words used in defining the words used in the definition and so on. Defining words with more words, in short, gets us at once into what mathematicians call an infinite regress. Alternatively, it can get us into the kind of run-around we sometimes encounter when we look up impertinence and find it defined as impudence, so we look up impudence and find it defined as impertinence. Yetand here we come to another common reaction patternpeople often act as if words can be explained fully with more words. To a person who asked for a definition of jazz, Louis Armstrong is said to have replied, Man. when you got to ask what it is, youll never get to know, proving himself to be an intuitive semanticist as well as a great trumpet player. Semantics, then, does not deal with the meaning of words as that expression is commonly understood. P. W. Bridgman, the Nobel Prize winner and physicist, once wrote, The true meaning of a term is to be found by observing what a man does with it, not by what he says about it. He made an enormous contribution to science by showing that the meaning of a scientific term lies in the operations, the things done, that establish its validity, rather than in verbal definitions. Here is a simple, everyday kind of example of operational definition. If you say, This table measures six feet in length, you could prove it by taking a foot rule, performing the operation of laying it end to end while counting, One... two... three... four... But if you sayand revolutionists have started uprisings with just this statement Man is born free, but everywhere he is in chains! what operations could you perform to demonstrate its accuracy or inaccuracy? But let us carry this suggestion of operationalism outside the physical sciences where Bridgman applied it, and observe what operations people perform as the result of both the language they use and the language other people use in communicating to them. Here is a personnel manager studying an application blank. He comes to the words Education: Harvard University, and drops the application blank in the wastebasket (thats the operation) because, as he would say if you asked him, I dont like Harvard men. This is an instance of meaning at workbut it is not a meaning that can be found in dictionaries. If I seem to be taking a long time to explain what semantics is about, it is because I am trying, in the course of explanation, to introduce the reader to a certain way of looking at human behavior. I say human responses because, so far as we know, human beings are the only creatures that have, over and above that biological equipment which we have in common with other creatures, the additional capacity for manufacturing symbols and systems of symbols. When we react to a flag, we are not reacting simply to a piece of cloth, but to the meaning with which it has been symbolically endowed. When we react to a word, we are not reacting to a set of sounds, but to the meaning with which that set of sounds has been symbolically endowed. A basic idea in general semantics, therefore, is that the meaning of words (or other symbols) is not in the words, but in our own semantic reactions. If I were to tell a shockingly obscene story in Arabic or Hindustani or Swahili before an audience that understood only English, no one would blush or be angry; the story would be neither shocking nor obscene-induced, it would not even be a story. Likewise, the value of a dollar bill is not in the bill, but in our social agreement to accept it as a symbol of value. If that agreement were to break down through the collapse of our government, the dollar bill would become only a scrap of paper. We do not understand a dollar bill by staring at it long and hard. We understand it by observing how people act with respect to it. We understand it by understanding the social mechanisms and the loyalties that keep it meaningful. Semantics is therefore a social study, basic to all other social studies.", "hypothesis": "A story can be entertaining without being understood.", "gold_label": "contradiction"}
{"uid": "id_491", "premise": "What is Meaning The end, product of education, yours and mine and everybodys, is the total pattern of reactions and possible reactions we have inside ourselves. If you did not have within you at this moment the pattern of reactions that we call the ability to read. you would see here only meaningless black marks on paper. Because of the trained patterns of response, you are (or are not) stirred to patriotism by martial music, your feelings of reverence are aroused by symbols of your religion, you listen more respectfully to the health advice of someone who has MD after his name than to that of someone who hasnt. What I call here a pattern of reactions, then, is the sum total of the ways we act in response to events, to words, and to symbols. Our reaction patterns or our semantic habits, are the internal and most important residue of whatever years of education or miseducation we may have received from our parents conduct toward us in childhood as well as their teachings, from the formal education we may have had, from all the lectures we have listened to, from the radio programs and the movies and television shows we have experienced, from all the books and newspapers and comic strips we have read, from the conversations we have had with friends and associates, and from all our experiences. If, as the result of all these influences that make us what we are, our semantic habits are reasonably similar to those of most people around us, we are regarded as normal, or perhaps dull. If our semantic habits are noticeably different from those of others, we are regarded as individualistic or original. or, if the differences are disapproved of or viewed with alarm, as crazy. Semantics is sometimes defined in dictionaries as the science of the meaning of words which would not be a bad definition if people didnt assume that the search for the meanings of words begins and ends with looking them up in a dictionary. If one stops to think for a moment, it is clear that to define a word, as a dictionary does, is simply to explain the word with more words. To be thorough about defining, we should next have to define the words used in the definition, then define the words used in defining the words used in the definition and so on. Defining words with more words, in short, gets us at once into what mathematicians call an infinite regress. Alternatively, it can get us into the kind of run-around we sometimes encounter when we look up impertinence and find it defined as impudence, so we look up impudence and find it defined as impertinence. Yetand here we come to another common reaction patternpeople often act as if words can be explained fully with more words. To a person who asked for a definition of jazz, Louis Armstrong is said to have replied, Man. when you got to ask what it is, youll never get to know, proving himself to be an intuitive semanticist as well as a great trumpet player. Semantics, then, does not deal with the meaning of words as that expression is commonly understood. P. W. Bridgman, the Nobel Prize winner and physicist, once wrote, The true meaning of a term is to be found by observing what a man does with it, not by what he says about it. He made an enormous contribution to science by showing that the meaning of a scientific term lies in the operations, the things done, that establish its validity, rather than in verbal definitions. Here is a simple, everyday kind of example of operational definition. If you say, This table measures six feet in length, you could prove it by taking a foot rule, performing the operation of laying it end to end while counting, One... two... three... four... But if you sayand revolutionists have started uprisings with just this statement Man is born free, but everywhere he is in chains! what operations could you perform to demonstrate its accuracy or inaccuracy? But let us carry this suggestion of operationalism outside the physical sciences where Bridgman applied it, and observe what operations people perform as the result of both the language they use and the language other people use in communicating to them. Here is a personnel manager studying an application blank. He comes to the words Education: Harvard University, and drops the application blank in the wastebasket (thats the operation) because, as he would say if you asked him, I dont like Harvard men. This is an instance of meaning at workbut it is not a meaning that can be found in dictionaries. If I seem to be taking a long time to explain what semantics is about, it is because I am trying, in the course of explanation, to introduce the reader to a certain way of looking at human behavior. I say human responses because, so far as we know, human beings are the only creatures that have, over and above that biological equipment which we have in common with other creatures, the additional capacity for manufacturing symbols and systems of symbols. When we react to a flag, we are not reacting simply to a piece of cloth, but to the meaning with which it has been symbolically endowed. When we react to a word, we are not reacting to a set of sounds, but to the meaning with which that set of sounds has been symbolically endowed. A basic idea in general semantics, therefore, is that the meaning of words (or other symbols) is not in the words, but in our own semantic reactions. If I were to tell a shockingly obscene story in Arabic or Hindustani or Swahili before an audience that understood only English, no one would blush or be angry; the story would be neither shocking nor obscene-induced, it would not even be a story. Likewise, the value of a dollar bill is not in the bill, but in our social agreement to accept it as a symbol of value. If that agreement were to break down through the collapse of our government, the dollar bill would become only a scrap of paper. We do not understand a dollar bill by staring at it long and hard. We understand it by observing how people act with respect to it. We understand it by understanding the social mechanisms and the loyalties that keep it meaningful. Semantics is therefore a social study, basic to all other social studies.", "hypothesis": "Meaning that is personal to individuals is less worthy to study than shared meanings.", "gold_label": "neutral"}
{"uid": "id_492", "premise": "What is a novel? A novel is a marketable commodity, of the class collectively termed luxuries, as not contributing directly to the support of life or the maintenance of health. The novel, therefore, is an intellectual artistic luxury in that it can be of no use to a man when he is at work, but may conduce to peace of mind and delectation during his hours of idleness. Probably, no one denies that the first object of the novel is to amuse and interest the reader. But it is often said that the novel should instruct as well as afford amusement, and the novel-with-a-purpose is the realisation of this idea. The purpose-novel, then, proposes to serve two masters, besides procuring a reasonable amount of bread and butter for its writer and publisher, it proposes to escape from my definition of the novel in general and make itself an intellectual moral lesson instead of an intellectual artistic luxury. It constitutes a violation of the unwritten contract tacitly existing between writer and reader. A man buys what purports to be a work of fiction, a romance, a novel, a story of adventure, pays his money, takes his book home, prepares to enjoy it at his ease, and discovers that he has paid a dollar for somebodys views on socialism, religion, or the divorce laws.", "hypothesis": "According to the author, a writer should write a novel with the sole purpose of amusement", "gold_label": "entailment"}
{"uid": "id_493", "premise": "What is a novel? A novel is a marketable commodity, of the class collectively termed luxuries, as not contributing directly to the support of life or the maintenance of health. The novel, therefore, is an intellectual artistic luxury in that it can be of no use to a man when he is at work, but may conduce to peace of mind and delectation during his hours of idleness. Probably, no one denies that the first object of the novel is to amuse and interest the reader. But it is often said that the novel should instruct as well as afford amusement, and the novel-with-a-purpose is the realisation of this idea. The purpose-novel, then, proposes to serve two masters, besides procuring a reasonable amount of bread and butter for its writer and publisher, it proposes to escape from my definition of the novel in general and make itself an intellectual moral lesson instead of an intellectual artistic luxury. It constitutes a violation of the unwritten contract tacitly existing between writer and reader. A man buys what purports to be a work of fiction, a romance, a novel, a story of adventure, pays his money, takes his book home, prepares to enjoy it at his ease, and discovers that he has paid a dollar for somebodys views on socialism, religion, or the divorce laws.", "hypothesis": "The writer of the passage regards a novel which has a strong view on socialism as their biggest hate.", "gold_label": "neutral"}
{"uid": "id_494", "premise": "What is it like to run a large supermarket? Jill Insley finds out You cant beat really good service. Ive been shopping in the Thamesmead branch of supermarket chain Morrisons, in south-east London, and Ive experienced at first hand, the stores latest maxim for improving the shopping experience help, offer, thank. This involves identifying customers who might need help, greeting them, asking what they need, providing it, thanking them and leaving them in peace. If they dont look like they want help, theyll be left alone. But if theyre standing looking lost and perplexed, a member of staff will approach them. Staff are expected to be friendly to everyone. My checkout assistant has certainly said something to amuse the woman in front of me, shes smiling as she leaves. Adrian Perriss, manager of the branch, has discussed the approach with each of his 387 staff. He says its about recognising that someone needs help, not being a nuisance to them. When hes in another store, hes irritated by someone saying, Can I help you? when hes only just walked in to have a quick look at the products. How anyone can be friendly and enthusiastic when they start work at dawn beats me. The store opens at 7 am, Monday to Saturday, meaning that some staff, including Perriss, have to be here at 6 am to make sure its clean, safe and stocked up for the morning rush. Sometimes he walks in at 6 am and thinks theyre never going to be ready on time but they always are. Theres so much going on overnight 20 people working on unloading three enormous trailers full of groceries. Perriss has worked in supermarkets since 1982, when he became a trolley boy on a weekly salary of 76. It was less money than my previous job, but I loved it. It was different and diverse. I was doing trolleys, portering, bread, cakes, dairy and general maintenance. After a period in the produce department, looking after the fruit and vegetables, he was made produce manager, then assistant store manager, before reaching the top job in 1998. This involved intensive training and assessment through the companys future store manager programme, learning how to analyse and prioritise sales. wastage, recruitment and many other issues. Perriss first stop as store manager was at a store which was closed soon afterwards though he was not to blame. Despite the disappointing start, his career went from strength to strength and he was put in charge of launching new stores and heading up a concept store, where the then new ideas of preparing and cooking pizzas in store, and having a proper florist, and fruit and vegetable markets were Mailed. All Morrisons managers from the whole country spent three days there to see the new concept. That was hard work, he says, long days, seven days a week, for about a year. Although he oversees a store with a large turnover, there is a strongly practical aspect to Perrisss job. As we walk around, he chats to all the staff while checking the layout of their counters and the quality of the produce. He examines the baking potato shelf and rejects three, one that has split virtually in half and two that are beginning to go green. He then pulls out a lemon that looks fine to me. When I ask why, he picks up a second lemon and says: Close your eyes and just feel and tell me which you would keep. I do and realise that while one is firm and hard, the other is going a bit squashy. Despite eagle-eyed Perriss pulling out fruit and veg that most of us would buy without a second thought, the wastage each week is tiny: produce worth 4,200 is marked down for a quick sale, and only 400-worth is scrapped. This, he explains, is down to Morrisons method of ordering, still done manually rather than by computer. Department heads know exactly how much theyve sold that day and how much theyre likely to sell the next, based on sales records and allowing for influences such as the weather. Perriss is in charge of 1,000 man-hours a week across the store. To help him, he has a key team of four, who each have direct responsibility for different departments. He is keen to hear what staff think. He recently held a talent day, inviting employees interested in moving to a new job within the store to come and talk to him about why they thought they should be promoted, and discuss how to go about it. We had twenty-three people come through the door, people wanting to talk about progression, he says. What do they need to do to become a supervisor? Twenty-three people will be better members of staff as a result of that talk. His favourite department is fish, which has a 4 m-long counter run by Debbie and Angela, who are busy having a discussion about how to cook a particular fish with a customer. But it is one of just 20 or so departments around the store and Perriss admits the pressure of making sure he knows whats happening on them all can be intense. You have to do so much and there could be something wrong with every single one, every day, he says. Youve got to minimise those things and shrink them into perspective. Youve got to love the job. And Perriss certainly does.", "hypothesis": "Perriss was surprised how many staff asked about promotion on the talent day.", "gold_label": "neutral"}
{"uid": "id_495", "premise": "What is it like to run a large supermarket? Jill Insley finds out You cant beat really good service. Ive been shopping in the Thamesmead branch of supermarket chain Morrisons, in south-east London, and Ive experienced at first hand, the stores latest maxim for improving the shopping experience help, offer, thank. This involves identifying customers who might need help, greeting them, asking what they need, providing it, thanking them and leaving them in peace. If they dont look like they want help, theyll be left alone. But if theyre standing looking lost and perplexed, a member of staff will approach them. Staff are expected to be friendly to everyone. My checkout assistant has certainly said something to amuse the woman in front of me, shes smiling as she leaves. Adrian Perriss, manager of the branch, has discussed the approach with each of his 387 staff. He says its about recognising that someone needs help, not being a nuisance to them. When hes in another store, hes irritated by someone saying, Can I help you? when hes only just walked in to have a quick look at the products. How anyone can be friendly and enthusiastic when they start work at dawn beats me. The store opens at 7 am, Monday to Saturday, meaning that some staff, including Perriss, have to be here at 6 am to make sure its clean, safe and stocked up for the morning rush. Sometimes he walks in at 6 am and thinks theyre never going to be ready on time but they always are. Theres so much going on overnight 20 people working on unloading three enormous trailers full of groceries. Perriss has worked in supermarkets since 1982, when he became a trolley boy on a weekly salary of 76. It was less money than my previous job, but I loved it. It was different and diverse. I was doing trolleys, portering, bread, cakes, dairy and general maintenance. After a period in the produce department, looking after the fruit and vegetables, he was made produce manager, then assistant store manager, before reaching the top job in 1998. This involved intensive training and assessment through the companys future store manager programme, learning how to analyse and prioritise sales. wastage, recruitment and many other issues. Perriss first stop as store manager was at a store which was closed soon afterwards though he was not to blame. Despite the disappointing start, his career went from strength to strength and he was put in charge of launching new stores and heading up a concept store, where the then new ideas of preparing and cooking pizzas in store, and having a proper florist, and fruit and vegetable markets were Mailed. All Morrisons managers from the whole country spent three days there to see the new concept. That was hard work, he says, long days, seven days a week, for about a year. Although he oversees a store with a large turnover, there is a strongly practical aspect to Perrisss job. As we walk around, he chats to all the staff while checking the layout of their counters and the quality of the produce. He examines the baking potato shelf and rejects three, one that has split virtually in half and two that are beginning to go green. He then pulls out a lemon that looks fine to me. When I ask why, he picks up a second lemon and says: Close your eyes and just feel and tell me which you would keep. I do and realise that while one is firm and hard, the other is going a bit squashy. Despite eagle-eyed Perriss pulling out fruit and veg that most of us would buy without a second thought, the wastage each week is tiny: produce worth 4,200 is marked down for a quick sale, and only 400-worth is scrapped. This, he explains, is down to Morrisons method of ordering, still done manually rather than by computer. Department heads know exactly how much theyve sold that day and how much theyre likely to sell the next, based on sales records and allowing for influences such as the weather. Perriss is in charge of 1,000 man-hours a week across the store. To help him, he has a key team of four, who each have direct responsibility for different departments. He is keen to hear what staff think. He recently held a talent day, inviting employees interested in moving to a new job within the store to come and talk to him about why they thought they should be promoted, and discuss how to go about it. We had twenty-three people come through the door, people wanting to talk about progression, he says. What do they need to do to become a supervisor? Twenty-three people will be better members of staff as a result of that talk. His favourite department is fish, which has a 4 m-long counter run by Debbie and Angela, who are busy having a discussion about how to cook a particular fish with a customer. But it is one of just 20 or so departments around the store and Perriss admits the pressure of making sure he knows whats happening on them all can be intense. You have to do so much and there could be something wrong with every single one, every day, he says. Youve got to minimise those things and shrink them into perspective. Youve got to love the job. And Perriss certainly does.", "hypothesis": "Perriss encourages staff to offer help to all customers.", "gold_label": "contradiction"}
{"uid": "id_496", "premise": "What is it like to run a large supermarket? Jill Insley finds out You cant beat really good service. Ive been shopping in the Thamesmead branch of supermarket chain Morrisons, in south-east London, and Ive experienced at first hand, the stores latest maxim for improving the shopping experience help, offer, thank. This involves identifying customers who might need help, greeting them, asking what they need, providing it, thanking them and leaving them in peace. If they dont look like they want help, theyll be left alone. But if theyre standing looking lost and perplexed, a member of staff will approach them. Staff are expected to be friendly to everyone. My checkout assistant has certainly said something to amuse the woman in front of me, shes smiling as she leaves. Adrian Perriss, manager of the branch, has discussed the approach with each of his 387 staff. He says its about recognising that someone needs help, not being a nuisance to them. When hes in another store, hes irritated by someone saying, Can I help you? when hes only just walked in to have a quick look at the products. How anyone can be friendly and enthusiastic when they start work at dawn beats me. The store opens at 7 am, Monday to Saturday, meaning that some staff, including Perriss, have to be here at 6 am to make sure its clean, safe and stocked up for the morning rush. Sometimes he walks in at 6 am and thinks theyre never going to be ready on time but they always are. Theres so much going on overnight 20 people working on unloading three enormous trailers full of groceries. Perriss has worked in supermarkets since 1982, when he became a trolley boy on a weekly salary of 76. It was less money than my previous job, but I loved it. It was different and diverse. I was doing trolleys, portering, bread, cakes, dairy and general maintenance. After a period in the produce department, looking after the fruit and vegetables, he was made produce manager, then assistant store manager, before reaching the top job in 1998. This involved intensive training and assessment through the companys future store manager programme, learning how to analyse and prioritise sales. wastage, recruitment and many other issues. Perriss first stop as store manager was at a store which was closed soon afterwards though he was not to blame. Despite the disappointing start, his career went from strength to strength and he was put in charge of launching new stores and heading up a concept store, where the then new ideas of preparing and cooking pizzas in store, and having a proper florist, and fruit and vegetable markets were Mailed. All Morrisons managers from the whole country spent three days there to see the new concept. That was hard work, he says, long days, seven days a week, for about a year. Although he oversees a store with a large turnover, there is a strongly practical aspect to Perrisss job. As we walk around, he chats to all the staff while checking the layout of their counters and the quality of the produce. He examines the baking potato shelf and rejects three, one that has split virtually in half and two that are beginning to go green. He then pulls out a lemon that looks fine to me. When I ask why, he picks up a second lemon and says: Close your eyes and just feel and tell me which you would keep. I do and realise that while one is firm and hard, the other is going a bit squashy. Despite eagle-eyed Perriss pulling out fruit and veg that most of us would buy without a second thought, the wastage each week is tiny: produce worth 4,200 is marked down for a quick sale, and only 400-worth is scrapped. This, he explains, is down to Morrisons method of ordering, still done manually rather than by computer. Department heads know exactly how much theyve sold that day and how much theyre likely to sell the next, based on sales records and allowing for influences such as the weather. Perriss is in charge of 1,000 man-hours a week across the store. To help him, he has a key team of four, who each have direct responsibility for different departments. He is keen to hear what staff think. He recently held a talent day, inviting employees interested in moving to a new job within the store to come and talk to him about why they thought they should be promoted, and discuss how to go about it. We had twenty-three people come through the door, people wanting to talk about progression, he says. What do they need to do to become a supervisor? Twenty-three people will be better members of staff as a result of that talk. His favourite department is fish, which has a 4 m-long counter run by Debbie and Angela, who are busy having a discussion about how to cook a particular fish with a customer. But it is one of just 20 or so departments around the store and Perriss admits the pressure of making sure he knows whats happening on them all can be intense. You have to do so much and there could be something wrong with every single one, every day, he says. Youve got to minimise those things and shrink them into perspective. Youve got to love the job. And Perriss certainly does.", "hypothesis": "Perriss is sometimes worried that customers will arrive before the store is ready for them.", "gold_label": "entailment"}
{"uid": "id_497", "premise": "What is it like to run a large supermarket? Jill Insley finds out You cant beat really good service. Ive been shopping in the Thamesmead branch of supermarket chain Morrisons, in south-east London, and Ive experienced at first hand, the stores latest maxim for improving the shopping experience help, offer, thank. This involves identifying customers who might need help, greeting them, asking what they need, providing it, thanking them and leaving them in peace. If they dont look like they want help, theyll be left alone. But if theyre standing looking lost and perplexed, a member of staff will approach them. Staff are expected to be friendly to everyone. My checkout assistant has certainly said something to amuse the woman in front of me, shes smiling as she leaves. Adrian Perriss, manager of the branch, has discussed the approach with each of his 387 staff. He says its about recognising that someone needs help, not being a nuisance to them. When hes in another store, hes irritated by someone saying, Can I help you? when hes only just walked in to have a quick look at the products. How anyone can be friendly and enthusiastic when they start work at dawn beats me. The store opens at 7 am, Monday to Saturday, meaning that some staff, including Perriss, have to be here at 6 am to make sure its clean, safe and stocked up for the morning rush. Sometimes he walks in at 6 am and thinks theyre never going to be ready on time but they always are. Theres so much going on overnight 20 people working on unloading three enormous trailers full of groceries. Perriss has worked in supermarkets since 1982, when he became a trolley boy on a weekly salary of 76. It was less money than my previous job, but I loved it. It was different and diverse. I was doing trolleys, portering, bread, cakes, dairy and general maintenance. After a period in the produce department, looking after the fruit and vegetables, he was made produce manager, then assistant store manager, before reaching the top job in 1998. This involved intensive training and assessment through the companys future store manager programme, learning how to analyse and prioritise sales. wastage, recruitment and many other issues. Perriss first stop as store manager was at a store which was closed soon afterwards though he was not to blame. Despite the disappointing start, his career went from strength to strength and he was put in charge of launching new stores and heading up a concept store, where the then new ideas of preparing and cooking pizzas in store, and having a proper florist, and fruit and vegetable markets were Mailed. All Morrisons managers from the whole country spent three days there to see the new concept. That was hard work, he says, long days, seven days a week, for about a year. Although he oversees a store with a large turnover, there is a strongly practical aspect to Perrisss job. As we walk around, he chats to all the staff while checking the layout of their counters and the quality of the produce. He examines the baking potato shelf and rejects three, one that has split virtually in half and two that are beginning to go green. He then pulls out a lemon that looks fine to me. When I ask why, he picks up a second lemon and says: Close your eyes and just feel and tell me which you would keep. I do and realise that while one is firm and hard, the other is going a bit squashy. Despite eagle-eyed Perriss pulling out fruit and veg that most of us would buy without a second thought, the wastage each week is tiny: produce worth 4,200 is marked down for a quick sale, and only 400-worth is scrapped. This, he explains, is down to Morrisons method of ordering, still done manually rather than by computer. Department heads know exactly how much theyve sold that day and how much theyre likely to sell the next, based on sales records and allowing for influences such as the weather. Perriss is in charge of 1,000 man-hours a week across the store. To help him, he has a key team of four, who each have direct responsibility for different departments. He is keen to hear what staff think. He recently held a talent day, inviting employees interested in moving to a new job within the store to come and talk to him about why they thought they should be promoted, and discuss how to go about it. We had twenty-three people come through the door, people wanting to talk about progression, he says. What do they need to do to become a supervisor? Twenty-three people will be better members of staff as a result of that talk. His favourite department is fish, which has a 4 m-long counter run by Debbie and Angela, who are busy having a discussion about how to cook a particular fish with a customer. But it is one of just 20 or so departments around the store and Perriss admits the pressure of making sure he knows whats happening on them all can be intense. You have to do so much and there could be something wrong with every single one, every day, he says. Youve got to minimise those things and shrink them into perspective. Youve got to love the job. And Perriss certainly does.", "hypothesis": "When Perriss first became a store manager, he knew the store was going to close.", "gold_label": "neutral"}
{"uid": "id_498", "premise": "What is it like to run a large supermarket? Jill Insley finds out You cant beat really good service. Ive been shopping in the Thamesmead branch of supermarket chain Morrisons, in south-east London, and Ive experienced at first hand, the stores latest maxim for improving the shopping experience help, offer, thank. This involves identifying customers who might need help, greeting them, asking what they need, providing it, thanking them and leaving them in peace. If they dont look like they want help, theyll be left alone. But if theyre standing looking lost and perplexed, a member of staff will approach them. Staff are expected to be friendly to everyone. My checkout assistant has certainly said something to amuse the woman in front of me, shes smiling as she leaves. Adrian Perriss, manager of the branch, has discussed the approach with each of his 387 staff. He says its about recognising that someone needs help, not being a nuisance to them. When hes in another store, hes irritated by someone saying, Can I help you? when hes only just walked in to have a quick look at the products. How anyone can be friendly and enthusiastic when they start work at dawn beats me. The store opens at 7 am, Monday to Saturday, meaning that some staff, including Perriss, have to be here at 6 am to make sure its clean, safe and stocked up for the morning rush. Sometimes he walks in at 6 am and thinks theyre never going to be ready on time but they always are. Theres so much going on overnight 20 people working on unloading three enormous trailers full of groceries. Perriss has worked in supermarkets since 1982, when he became a trolley boy on a weekly salary of 76. It was less money than my previous job, but I loved it. It was different and diverse. I was doing trolleys, portering, bread, cakes, dairy and general maintenance. After a period in the produce department, looking after the fruit and vegetables, he was made produce manager, then assistant store manager, before reaching the top job in 1998. This involved intensive training and assessment through the companys future store manager programme, learning how to analyse and prioritise sales. wastage, recruitment and many other issues. Perriss first stop as store manager was at a store which was closed soon afterwards though he was not to blame. Despite the disappointing start, his career went from strength to strength and he was put in charge of launching new stores and heading up a concept store, where the then new ideas of preparing and cooking pizzas in store, and having a proper florist, and fruit and vegetable markets were Mailed. All Morrisons managers from the whole country spent three days there to see the new concept. That was hard work, he says, long days, seven days a week, for about a year. Although he oversees a store with a large turnover, there is a strongly practical aspect to Perrisss job. As we walk around, he chats to all the staff while checking the layout of their counters and the quality of the produce. He examines the baking potato shelf and rejects three, one that has split virtually in half and two that are beginning to go green. He then pulls out a lemon that looks fine to me. When I ask why, he picks up a second lemon and says: Close your eyes and just feel and tell me which you would keep. I do and realise that while one is firm and hard, the other is going a bit squashy. Despite eagle-eyed Perriss pulling out fruit and veg that most of us would buy without a second thought, the wastage each week is tiny: produce worth 4,200 is marked down for a quick sale, and only 400-worth is scrapped. This, he explains, is down to Morrisons method of ordering, still done manually rather than by computer. Department heads know exactly how much theyve sold that day and how much theyre likely to sell the next, based on sales records and allowing for influences such as the weather. Perriss is in charge of 1,000 man-hours a week across the store. To help him, he has a key team of four, who each have direct responsibility for different departments. He is keen to hear what staff think. He recently held a talent day, inviting employees interested in moving to a new job within the store to come and talk to him about why they thought they should be promoted, and discuss how to go about it. We had twenty-three people come through the door, people wanting to talk about progression, he says. What do they need to do to become a supervisor? Twenty-three people will be better members of staff as a result of that talk. His favourite department is fish, which has a 4 m-long counter run by Debbie and Angela, who are busy having a discussion about how to cook a particular fish with a customer. But it is one of just 20 or so departments around the store and Perriss admits the pressure of making sure he knows whats happening on them all can be intense. You have to do so much and there could be something wrong with every single one, every day, he says. Youve got to minimise those things and shrink them into perspective. Youve got to love the job. And Perriss certainly does.", "hypothesis": "On average, produce worth 4,200 is thrown away every week.", "gold_label": "contradiction"}
{"uid": "id_499", "premise": "What is it that draws us to these creatures? This inhuman place makes human monsters, wrote Stephen King in his novel The Shining. Many academics agree that monsters lurk in the deepest recesses, they prowl through our ancestral minds appearing in the half-light, under the bed or at the bottom of the sea. They dont really exist, but they play a huge role in our mindscapes, in our dreams, stories, nightmares, myths and so on, says Matthias Classen, assistant professor of literature and media at Aarhus University in Denmark, who studies monsters in literature. Monsters say something about human psychology, not the world. One Norse legend talks of the Kraken, a deep sea creature that was the curse of fishermen. If sailors found a place with many fish, most likely it was the monster that was driving them to the surface. If it saw the ship it would pluck the hapless sailors from the boat and drag them to a watery grave. This terrifying legend occupied the mind and pen of the poet Alfred Lord Tennyson too. In his short 1830 poem The Kraken he wrote: Below the thunders of the upper deep, / Far far beneath in the abysmal sea, / His ancient, dreamless, uninvaded sleep / The Kraken sleepeth. The deeper we travel into the ocean, the deeper we delve into our own psyche. And when we can go no further there lurks the Kraken. Most likely the Kraken is based on a real creature the giant squid. The huge mollusc takes pride of place as the personification of the terrors of the deep sea. Sailors would have encountered it at the surface, dying, and probably thrashing about. It would have made a weird sight, about the most alien thing you can imagine, says Edith Widder, CEO at the Ocean Research and Conservation Association. It has eight lashing arms and two slashing tentacles growing straight out of its head and its got serrated suckers that can latch on to the slimiest of prey and its got a parrot beak that can rip flesh. Its got an eye the size of your head, its got a jet propulsion system and three hearts that pump blue blood. The giant squid continued to dominate stories of sea monsters with the famous 1870 novel, Twenty Thousand Leagues Under the Sea, by Jules Verne. Vernes submarine fantasy is a classic story of puny man against a gigantic squid. The monster needed no embellishment this creature was scary enough, and Verne incorporated as much fact as possible into the story, says Emily Alder from Edinburgh Napier University. Twenty Thousand Leagues Under the Sea and another contemporaneous book, Victor Hugos Toilers of the Sea, both tried to represent the giant squid as they might have been actual zoological animals, much more taking the squid as a biological creature than a mythical creature. It was a given that the squid was vicious and would readily attack humans given the chance. That myth wasnt busted until 2012, when Edith Widder and her colleagues were the first people to successfully film giant squid under water and see first-hand the true character of the monster of the deep. They realised previous attempts to film squid had failed because the bright lights and noisy thrusters on submersibles had frightened them away. By quietening down the engines and using bioluminescence to attract it, they managed to see this most extraordinary animal in its natural habitat. It serenely glided into view, its body rippled with metallic colours of bronze and silver. Its huge, intelligent eye watched the submarine warily as it delicately picked at the bait with its beak. It was balletic and mesmeric. It could not have been further from the gnashing, human-destroying creature of myth and literature. In reality this is a gentle giant that is easily scared and pecks at its food. Another giant squid lies peacefully in the Natural History Museum in London, in the Spirit Room, where it is preserved in a huge glass case. In 2004 it was caught in a fishing net off the Falkland Islands and died at the surface. The crew immediately froze its body and it was sent to be preserved in the museum by the Curator of Molluscs, Jon Ablett. It is called Archie, an affectionate short version of its Latin name Architeuthis dux. It is the longest preserved specimen of a giant squid in the world. It really has brought science to life for many people, says Ablett. Sometimes I feel a bit overshadowed by Archie, most of my work is on slugs and snails but unfortunately most people dont want to talk about that! And so today we can watch Archies graceful relative on film and stare Archie herself (she is a female) eye-to-eye in a museum. But have we finally slain the monster of the deep? Now we know there is nothing to be afraid of, can the Kraken finally be laid to rest? Probably not says Classen. We humans are afraid of the strangest things. They dont need to be realistic. Theres no indication that enlightenment and scientific progress has banished the monsters from the shadows of our imaginations. We will continue to be afraid of very strange things, including probably sea monsters. Indeed we are. The Kraken made a fearsome appearance in the blockbuster series Pirates of the Caribbean. It forced Captain Jack Sparrow to face his demons in a terrifying face-to-face encounter. Pirates needed the monstrous Kraken, nothing else would do. Or, as the German film director Werner Herzog put it, What would an ocean be without a monster lurking in the dark? It would be like sleep without dreams.", "hypothesis": "Werner Herzog suggests that Kraken is essential to the ocean.", "gold_label": "neutral"}
{"uid": "id_500", "premise": "What is it that draws us to these creatures? This inhuman place makes human monsters, wrote Stephen King in his novel The Shining. Many academics agree that monsters lurk in the deepest recesses, they prowl through our ancestral minds appearing in the half-light, under the bed or at the bottom of the sea. They dont really exist, but they play a huge role in our mindscapes, in our dreams, stories, nightmares, myths and so on, says Matthias Classen, assistant professor of literature and media at Aarhus University in Denmark, who studies monsters in literature. Monsters say something about human psychology, not the world. One Norse legend talks of the Kraken, a deep sea creature that was the curse of fishermen. If sailors found a place with many fish, most likely it was the monster that was driving them to the surface. If it saw the ship it would pluck the hapless sailors from the boat and drag them to a watery grave. This terrifying legend occupied the mind and pen of the poet Alfred Lord Tennyson too. In his short 1830 poem The Kraken he wrote: Below the thunders of the upper deep, / Far far beneath in the abysmal sea, / His ancient, dreamless, uninvaded sleep / The Kraken sleepeth. The deeper we travel into the ocean, the deeper we delve into our own psyche. And when we can go no further there lurks the Kraken. Most likely the Kraken is based on a real creature the giant squid. The huge mollusc takes pride of place as the personification of the terrors of the deep sea. Sailors would have encountered it at the surface, dying, and probably thrashing about. It would have made a weird sight, about the most alien thing you can imagine, says Edith Widder, CEO at the Ocean Research and Conservation Association. It has eight lashing arms and two slashing tentacles growing straight out of its head and its got serrated suckers that can latch on to the slimiest of prey and its got a parrot beak that can rip flesh. Its got an eye the size of your head, its got a jet propulsion system and three hearts that pump blue blood. The giant squid continued to dominate stories of sea monsters with the famous 1870 novel, Twenty Thousand Leagues Under the Sea, by Jules Verne. Vernes submarine fantasy is a classic story of puny man against a gigantic squid. The monster needed no embellishment this creature was scary enough, and Verne incorporated as much fact as possible into the story, says Emily Alder from Edinburgh Napier University. Twenty Thousand Leagues Under the Sea and another contemporaneous book, Victor Hugos Toilers of the Sea, both tried to represent the giant squid as they might have been actual zoological animals, much more taking the squid as a biological creature than a mythical creature. It was a given that the squid was vicious and would readily attack humans given the chance. That myth wasnt busted until 2012, when Edith Widder and her colleagues were the first people to successfully film giant squid under water and see first-hand the true character of the monster of the deep. They realised previous attempts to film squid had failed because the bright lights and noisy thrusters on submersibles had frightened them away. By quietening down the engines and using bioluminescence to attract it, they managed to see this most extraordinary animal in its natural habitat. It serenely glided into view, its body rippled with metallic colours of bronze and silver. Its huge, intelligent eye watched the submarine warily as it delicately picked at the bait with its beak. It was balletic and mesmeric. It could not have been further from the gnashing, human-destroying creature of myth and literature. In reality this is a gentle giant that is easily scared and pecks at its food. Another giant squid lies peacefully in the Natural History Museum in London, in the Spirit Room, where it is preserved in a huge glass case. In 2004 it was caught in a fishing net off the Falkland Islands and died at the surface. The crew immediately froze its body and it was sent to be preserved in the museum by the Curator of Molluscs, Jon Ablett. It is called Archie, an affectionate short version of its Latin name Architeuthis dux. It is the longest preserved specimen of a giant squid in the world. It really has brought science to life for many people, says Ablett. Sometimes I feel a bit overshadowed by Archie, most of my work is on slugs and snails but unfortunately most people dont want to talk about that! And so today we can watch Archies graceful relative on film and stare Archie herself (she is a female) eye-to-eye in a museum. But have we finally slain the monster of the deep? Now we know there is nothing to be afraid of, can the Kraken finally be laid to rest? Probably not says Classen. We humans are afraid of the strangest things. They dont need to be realistic. Theres no indication that enlightenment and scientific progress has banished the monsters from the shadows of our imaginations. We will continue to be afraid of very strange things, including probably sea monsters. Indeed we are. The Kraken made a fearsome appearance in the blockbuster series Pirates of the Caribbean. It forced Captain Jack Sparrow to face his demons in a terrifying face-to-face encounter. Pirates needed the monstrous Kraken, nothing else would do. Or, as the German film director Werner Herzog put it, What would an ocean be without a monster lurking in the dark? It would be like sleep without dreams.", "hypothesis": "According to Classen, people can be scared both by imaginary and real monsters.", "gold_label": "entailment"}
{"uid": "id_501", "premise": "What is it that draws us to these creatures? This inhuman place makes human monsters, wrote Stephen King in his novel The Shining. Many academics agree that monsters lurk in the deepest recesses, they prowl through our ancestral minds appearing in the half-light, under the bed or at the bottom of the sea. They dont really exist, but they play a huge role in our mindscapes, in our dreams, stories, nightmares, myths and so on, says Matthias Classen, assistant professor of literature and media at Aarhus University in Denmark, who studies monsters in literature. Monsters say something about human psychology, not the world. One Norse legend talks of the Kraken, a deep sea creature that was the curse of fishermen. If sailors found a place with many fish, most likely it was the monster that was driving them to the surface. If it saw the ship it would pluck the hapless sailors from the boat and drag them to a watery grave. This terrifying legend occupied the mind and pen of the poet Alfred Lord Tennyson too. In his short 1830 poem The Kraken he wrote: Below the thunders of the upper deep, / Far far beneath in the abysmal sea, / His ancient, dreamless, uninvaded sleep / The Kraken sleepeth. The deeper we travel into the ocean, the deeper we delve into our own psyche. And when we can go no further there lurks the Kraken. Most likely the Kraken is based on a real creature the giant squid. The huge mollusc takes pride of place as the personification of the terrors of the deep sea. Sailors would have encountered it at the surface, dying, and probably thrashing about. It would have made a weird sight, about the most alien thing you can imagine, says Edith Widder, CEO at the Ocean Research and Conservation Association. It has eight lashing arms and two slashing tentacles growing straight out of its head and its got serrated suckers that can latch on to the slimiest of prey and its got a parrot beak that can rip flesh. Its got an eye the size of your head, its got a jet propulsion system and three hearts that pump blue blood. The giant squid continued to dominate stories of sea monsters with the famous 1870 novel, Twenty Thousand Leagues Under the Sea, by Jules Verne. Vernes submarine fantasy is a classic story of puny man against a gigantic squid. The monster needed no embellishment this creature was scary enough, and Verne incorporated as much fact as possible into the story, says Emily Alder from Edinburgh Napier University. Twenty Thousand Leagues Under the Sea and another contemporaneous book, Victor Hugos Toilers of the Sea, both tried to represent the giant squid as they might have been actual zoological animals, much more taking the squid as a biological creature than a mythical creature. It was a given that the squid was vicious and would readily attack humans given the chance. That myth wasnt busted until 2012, when Edith Widder and her colleagues were the first people to successfully film giant squid under water and see first-hand the true character of the monster of the deep. They realised previous attempts to film squid had failed because the bright lights and noisy thrusters on submersibles had frightened them away. By quietening down the engines and using bioluminescence to attract it, they managed to see this most extraordinary animal in its natural habitat. It serenely glided into view, its body rippled with metallic colours of bronze and silver. Its huge, intelligent eye watched the submarine warily as it delicately picked at the bait with its beak. It was balletic and mesmeric. It could not have been further from the gnashing, human-destroying creature of myth and literature. In reality this is a gentle giant that is easily scared and pecks at its food. Another giant squid lies peacefully in the Natural History Museum in London, in the Spirit Room, where it is preserved in a huge glass case. In 2004 it was caught in a fishing net off the Falkland Islands and died at the surface. The crew immediately froze its body and it was sent to be preserved in the museum by the Curator of Molluscs, Jon Ablett. It is called Archie, an affectionate short version of its Latin name Architeuthis dux. It is the longest preserved specimen of a giant squid in the world. It really has brought science to life for many people, says Ablett. Sometimes I feel a bit overshadowed by Archie, most of my work is on slugs and snails but unfortunately most people dont want to talk about that! And so today we can watch Archies graceful relative on film and stare Archie herself (she is a female) eye-to-eye in a museum. But have we finally slain the monster of the deep? Now we know there is nothing to be afraid of, can the Kraken finally be laid to rest? Probably not says Classen. We humans are afraid of the strangest things. They dont need to be realistic. Theres no indication that enlightenment and scientific progress has banished the monsters from the shadows of our imaginations. We will continue to be afraid of very strange things, including probably sea monsters. Indeed we are. The Kraken made a fearsome appearance in the blockbuster series Pirates of the Caribbean. It forced Captain Jack Sparrow to face his demons in a terrifying face-to-face encounter. Pirates needed the monstrous Kraken, nothing else would do. Or, as the German film director Werner Herzog put it, What would an ocean be without a monster lurking in the dark? It would be like sleep without dreams.", "hypothesis": "Giant squid was caught alive in 2004 and brought to the museum.", "gold_label": "contradiction"}
{"uid": "id_502", "premise": "What is it that draws us to these creatures? This inhuman place makes human monsters, wrote Stephen King in his novel The Shining. Many academics agree that monsters lurk in the deepest recesses, they prowl through our ancestral minds appearing in the half-light, under the bed or at the bottom of the sea. They dont really exist, but they play a huge role in our mindscapes, in our dreams, stories, nightmares, myths and so on, says Matthias Classen, assistant professor of literature and media at Aarhus University in Denmark, who studies monsters in literature. Monsters say something about human psychology, not the world. One Norse legend talks of the Kraken, a deep sea creature that was the curse of fishermen. If sailors found a place with many fish, most likely it was the monster that was driving them to the surface. If it saw the ship it would pluck the hapless sailors from the boat and drag them to a watery grave. This terrifying legend occupied the mind and pen of the poet Alfred Lord Tennyson too. In his short 1830 poem The Kraken he wrote: Below the thunders of the upper deep, / Far far beneath in the abysmal sea, / His ancient, dreamless, uninvaded sleep / The Kraken sleepeth. The deeper we travel into the ocean, the deeper we delve into our own psyche. And when we can go no further there lurks the Kraken. Most likely the Kraken is based on a real creature the giant squid. The huge mollusc takes pride of place as the personification of the terrors of the deep sea. Sailors would have encountered it at the surface, dying, and probably thrashing about. It would have made a weird sight, about the most alien thing you can imagine, says Edith Widder, CEO at the Ocean Research and Conservation Association. It has eight lashing arms and two slashing tentacles growing straight out of its head and its got serrated suckers that can latch on to the slimiest of prey and its got a parrot beak that can rip flesh. Its got an eye the size of your head, its got a jet propulsion system and three hearts that pump blue blood. The giant squid continued to dominate stories of sea monsters with the famous 1870 novel, Twenty Thousand Leagues Under the Sea, by Jules Verne. Vernes submarine fantasy is a classic story of puny man against a gigantic squid. The monster needed no embellishment this creature was scary enough, and Verne incorporated as much fact as possible into the story, says Emily Alder from Edinburgh Napier University. Twenty Thousand Leagues Under the Sea and another contemporaneous book, Victor Hugos Toilers of the Sea, both tried to represent the giant squid as they might have been actual zoological animals, much more taking the squid as a biological creature than a mythical creature. It was a given that the squid was vicious and would readily attack humans given the chance. That myth wasnt busted until 2012, when Edith Widder and her colleagues were the first people to successfully film giant squid under water and see first-hand the true character of the monster of the deep. They realised previous attempts to film squid had failed because the bright lights and noisy thrusters on submersibles had frightened them away. By quietening down the engines and using bioluminescence to attract it, they managed to see this most extraordinary animal in its natural habitat. It serenely glided into view, its body rippled with metallic colours of bronze and silver. Its huge, intelligent eye watched the submarine warily as it delicately picked at the bait with its beak. It was balletic and mesmeric. It could not have been further from the gnashing, human-destroying creature of myth and literature. In reality this is a gentle giant that is easily scared and pecks at its food. Another giant squid lies peacefully in the Natural History Museum in London, in the Spirit Room, where it is preserved in a huge glass case. In 2004 it was caught in a fishing net off the Falkland Islands and died at the surface. The crew immediately froze its body and it was sent to be preserved in the museum by the Curator of Molluscs, Jon Ablett. It is called Archie, an affectionate short version of its Latin name Architeuthis dux. It is the longest preserved specimen of a giant squid in the world. It really has brought science to life for many people, says Ablett. Sometimes I feel a bit overshadowed by Archie, most of my work is on slugs and snails but unfortunately most people dont want to talk about that! And so today we can watch Archies graceful relative on film and stare Archie herself (she is a female) eye-to-eye in a museum. But have we finally slain the monster of the deep? Now we know there is nothing to be afraid of, can the Kraken finally be laid to rest? Probably not says Classen. We humans are afraid of the strangest things. They dont need to be realistic. Theres no indication that enlightenment and scientific progress has banished the monsters from the shadows of our imaginations. We will continue to be afraid of very strange things, including probably sea monsters. Indeed we are. The Kraken made a fearsome appearance in the blockbuster series Pirates of the Caribbean. It forced Captain Jack Sparrow to face his demons in a terrifying face-to-face encounter. Pirates needed the monstrous Kraken, nothing else would do. Or, as the German film director Werner Herzog put it, What would an ocean be without a monster lurking in the dark? It would be like sleep without dreams.", "hypothesis": "Previous attempts on filming the squid had failed due to the fact that the creature was scared.", "gold_label": "entailment"}
{"uid": "id_503", "premise": "What is it that draws us to these creatures? This inhuman place makes human monsters, wrote Stephen King in his novel The Shining. Many academics agree that monsters lurk in the deepest recesses, they prowl through our ancestral minds appearing in the half-light, under the bed or at the bottom of the sea. They dont really exist, but they play a huge role in our mindscapes, in our dreams, stories, nightmares, myths and so on, says Matthias Classen, assistant professor of literature and media at Aarhus University in Denmark, who studies monsters in literature. Monsters say something about human psychology, not the world. One Norse legend talks of the Kraken, a deep sea creature that was the curse of fishermen. If sailors found a place with many fish, most likely it was the monster that was driving them to the surface. If it saw the ship it would pluck the hapless sailors from the boat and drag them to a watery grave. This terrifying legend occupied the mind and pen of the poet Alfred Lord Tennyson too. In his short 1830 poem The Kraken he wrote: Below the thunders of the upper deep, / Far far beneath in the abysmal sea, / His ancient, dreamless, uninvaded sleep / The Kraken sleepeth. The deeper we travel into the ocean, the deeper we delve into our own psyche. And when we can go no further there lurks the Kraken. Most likely the Kraken is based on a real creature the giant squid. The huge mollusc takes pride of place as the personification of the terrors of the deep sea. Sailors would have encountered it at the surface, dying, and probably thrashing about. It would have made a weird sight, about the most alien thing you can imagine, says Edith Widder, CEO at the Ocean Research and Conservation Association. It has eight lashing arms and two slashing tentacles growing straight out of its head and its got serrated suckers that can latch on to the slimiest of prey and its got a parrot beak that can rip flesh. Its got an eye the size of your head, its got a jet propulsion system and three hearts that pump blue blood. The giant squid continued to dominate stories of sea monsters with the famous 1870 novel, Twenty Thousand Leagues Under the Sea, by Jules Verne. Vernes submarine fantasy is a classic story of puny man against a gigantic squid. The monster needed no embellishment this creature was scary enough, and Verne incorporated as much fact as possible into the story, says Emily Alder from Edinburgh Napier University. Twenty Thousand Leagues Under the Sea and another contemporaneous book, Victor Hugos Toilers of the Sea, both tried to represent the giant squid as they might have been actual zoological animals, much more taking the squid as a biological creature than a mythical creature. It was a given that the squid was vicious and would readily attack humans given the chance. That myth wasnt busted until 2012, when Edith Widder and her colleagues were the first people to successfully film giant squid under water and see first-hand the true character of the monster of the deep. They realised previous attempts to film squid had failed because the bright lights and noisy thrusters on submersibles had frightened them away. By quietening down the engines and using bioluminescence to attract it, they managed to see this most extraordinary animal in its natural habitat. It serenely glided into view, its body rippled with metallic colours of bronze and silver. Its huge, intelligent eye watched the submarine warily as it delicately picked at the bait with its beak. It was balletic and mesmeric. It could not have been further from the gnashing, human-destroying creature of myth and literature. In reality this is a gentle giant that is easily scared and pecks at its food. Another giant squid lies peacefully in the Natural History Museum in London, in the Spirit Room, where it is preserved in a huge glass case. In 2004 it was caught in a fishing net off the Falkland Islands and died at the surface. The crew immediately froze its body and it was sent to be preserved in the museum by the Curator of Molluscs, Jon Ablett. It is called Archie, an affectionate short version of its Latin name Architeuthis dux. It is the longest preserved specimen of a giant squid in the world. It really has brought science to life for many people, says Ablett. Sometimes I feel a bit overshadowed by Archie, most of my work is on slugs and snails but unfortunately most people dont want to talk about that! And so today we can watch Archies graceful relative on film and stare Archie herself (she is a female) eye-to-eye in a museum. But have we finally slain the monster of the deep? Now we know there is nothing to be afraid of, can the Kraken finally be laid to rest? Probably not says Classen. We humans are afraid of the strangest things. They dont need to be realistic. Theres no indication that enlightenment and scientific progress has banished the monsters from the shadows of our imaginations. We will continue to be afraid of very strange things, including probably sea monsters. Indeed we are. The Kraken made a fearsome appearance in the blockbuster series Pirates of the Caribbean. It forced Captain Jack Sparrow to face his demons in a terrifying face-to-face encounter. Pirates needed the monstrous Kraken, nothing else would do. Or, as the German film director Werner Herzog put it, What would an ocean be without a monster lurking in the dark? It would be like sleep without dreams.", "hypothesis": "Jon Ablett admits that he likes Archie.", "gold_label": "neutral"}
{"uid": "id_504", "premise": "What is it that draws us to these creatures? This inhuman place makes human monsters, wrote Stephen King in his novel The Shining. Many academics agree that monsters lurk in the deepest recesses, they prowl through our ancestral minds appearing in the half-light, under the bed or at the bottom of the sea. They dont really exist, but they play a huge role in our mindscapes, in our dreams, stories, nightmares, myths and so on, says Matthias Classen, assistant professor of literature and media at Aarhus University in Denmark, who studies monsters in literature. Monsters say something about human psychology, not the world. One Norse legend talks of the Kraken, a deep sea creature that was the curse of fishermen. If sailors found a place with many fish, most likely it was the monster that was driving them to the surface. If it saw the ship it would pluck the hapless sailors from the boat and drag them to a watery grave. This terrifying legend occupied the mind and pen of the poet Alfred Lord Tennyson too. In his short 1830 poem The Kraken he wrote: Below the thunders of the upper deep, / Far far beneath in the abysmal sea, / His ancient, dreamless, uninvaded sleep / The Kraken sleepeth. The deeper we travel into the ocean, the deeper we delve into our own psyche. And when we can go no further there lurks the Kraken. Most likely the Kraken is based on a real creature the giant squid. The huge mollusc takes pride of place as the personification of the terrors of the deep sea. Sailors would have encountered it at the surface, dying, and probably thrashing about. It would have made a weird sight, about the most alien thing you can imagine, says Edith Widder, CEO at the Ocean Research and Conservation Association. It has eight lashing arms and two slashing tentacles growing straight out of its head and its got serrated suckers that can latch on to the slimiest of prey and its got a parrot beak that can rip flesh. Its got an eye the size of your head, its got a jet propulsion system and three hearts that pump blue blood. The giant squid continued to dominate stories of sea monsters with the famous 1870 novel, Twenty Thousand Leagues Under the Sea, by Jules Verne. Vernes submarine fantasy is a classic story of puny man against a gigantic squid. The monster needed no embellishment this creature was scary enough, and Verne incorporated as much fact as possible into the story, says Emily Alder from Edinburgh Napier University. Twenty Thousand Leagues Under the Sea and another contemporaneous book, Victor Hugos Toilers of the Sea, both tried to represent the giant squid as they might have been actual zoological animals, much more taking the squid as a biological creature than a mythical creature. It was a given that the squid was vicious and would readily attack humans given the chance. That myth wasnt busted until 2012, when Edith Widder and her colleagues were the first people to successfully film giant squid under water and see first-hand the true character of the monster of the deep. They realised previous attempts to film squid had failed because the bright lights and noisy thrusters on submersibles had frightened them away. By quietening down the engines and using bioluminescence to attract it, they managed to see this most extraordinary animal in its natural habitat. It serenely glided into view, its body rippled with metallic colours of bronze and silver. Its huge, intelligent eye watched the submarine warily as it delicately picked at the bait with its beak. It was balletic and mesmeric. It could not have been further from the gnashing, human-destroying creature of myth and literature. In reality this is a gentle giant that is easily scared and pecks at its food. Another giant squid lies peacefully in the Natural History Museum in London, in the Spirit Room, where it is preserved in a huge glass case. In 2004 it was caught in a fishing net off the Falkland Islands and died at the surface. The crew immediately froze its body and it was sent to be preserved in the museum by the Curator of Molluscs, Jon Ablett. It is called Archie, an affectionate short version of its Latin name Architeuthis dux. It is the longest preserved specimen of a giant squid in the world. It really has brought science to life for many people, says Ablett. Sometimes I feel a bit overshadowed by Archie, most of my work is on slugs and snails but unfortunately most people dont want to talk about that! And so today we can watch Archies graceful relative on film and stare Archie herself (she is a female) eye-to-eye in a museum. But have we finally slain the monster of the deep? Now we know there is nothing to be afraid of, can the Kraken finally be laid to rest? Probably not says Classen. We humans are afraid of the strangest things. They dont need to be realistic. Theres no indication that enlightenment and scientific progress has banished the monsters from the shadows of our imaginations. We will continue to be afraid of very strange things, including probably sea monsters. Indeed we are. The Kraken made a fearsome appearance in the blockbuster series Pirates of the Caribbean. It forced Captain Jack Sparrow to face his demons in a terrifying face-to-face encounter. Pirates needed the monstrous Kraken, nothing else would do. Or, as the German film director Werner Herzog put it, What would an ocean be without a monster lurking in the dark? It would be like sleep without dreams.", "hypothesis": "Matthias Classen is unsure about the possibility of monsters existence.", "gold_label": "contradiction"}
{"uid": "id_505", "premise": "What is it that draws us to these creatures? This inhuman place makes human monsters, wrote Stephen King in his novel The Shining. Many academics agree that monsters lurk in the deepest recesses, they prowl through our ancestral minds appearing in the half-light, under the bed or at the bottom of the sea. They dont really exist, but they play a huge role in our mindscapes, in our dreams, stories, nightmares, myths and so on, says Matthias Classen, assistant professor of literature and media at Aarhus University in Denmark, who studies monsters in literature. Monsters say something about human psychology, not the world. One Norse legend talks of the Kraken, a deep sea creature that was the curse of fishermen. If sailors found a place with many fish, most likely it was the monster that was driving them to the surface. If it saw the ship it would pluck the hapless sailors from the boat and drag them to a watery grave. This terrifying legend occupied the mind and pen of the poet Alfred Lord Tennyson too. In his short 1830 poem The Kraken he wrote: Below the thunders of the upper deep, / Far far beneath in the abysmal sea, / His ancient, dreamless, uninvaded sleep / The Kraken sleepeth. The deeper we travel into the ocean, the deeper we delve into our own psyche. And when we can go no further there lurks the Kraken. Most likely the Kraken is based on a real creature the giant squid. The huge mollusc takes pride of place as the personification of the terrors of the deep sea. Sailors would have encountered it at the surface, dying, and probably thrashing about. It would have made a weird sight, about the most alien thing you can imagine, says Edith Widder, CEO at the Ocean Research and Conservation Association. It has eight lashing arms and two slashing tentacles growing straight out of its head and its got serrated suckers that can latch on to the slimiest of prey and its got a parrot beak that can rip flesh. Its got an eye the size of your head, its got a jet propulsion system and three hearts that pump blue blood. The giant squid continued to dominate stories of sea monsters with the famous 1870 novel, Twenty Thousand Leagues Under the Sea, by Jules Verne. Vernes submarine fantasy is a classic story of puny man against a gigantic squid. The monster needed no embellishment this creature was scary enough, and Verne incorporated as much fact as possible into the story, says Emily Alder from Edinburgh Napier University. Twenty Thousand Leagues Under the Sea and another contemporaneous book, Victor Hugos Toilers of the Sea, both tried to represent the giant squid as they might have been actual zoological animals, much more taking the squid as a biological creature than a mythical creature. It was a given that the squid was vicious and would readily attack humans given the chance. That myth wasnt busted until 2012, when Edith Widder and her colleagues were the first people to successfully film giant squid under water and see first-hand the true character of the monster of the deep. They realised previous attempts to film squid had failed because the bright lights and noisy thrusters on submersibles had frightened them away. By quietening down the engines and using bioluminescence to attract it, they managed to see this most extraordinary animal in its natural habitat. It serenely glided into view, its body rippled with metallic colours of bronze and silver. Its huge, intelligent eye watched the submarine warily as it delicately picked at the bait with its beak. It was balletic and mesmeric. It could not have been further from the gnashing, human-destroying creature of myth and literature. In reality this is a gentle giant that is easily scared and pecks at its food. Another giant squid lies peacefully in the Natural History Museum in London, in the Spirit Room, where it is preserved in a huge glass case. In 2004 it was caught in a fishing net off the Falkland Islands and died at the surface. The crew immediately froze its body and it was sent to be preserved in the museum by the Curator of Molluscs, Jon Ablett. It is called Archie, an affectionate short version of its Latin name Architeuthis dux. It is the longest preserved specimen of a giant squid in the world. It really has brought science to life for many people, says Ablett. Sometimes I feel a bit overshadowed by Archie, most of my work is on slugs and snails but unfortunately most people dont want to talk about that! And so today we can watch Archies graceful relative on film and stare Archie herself (she is a female) eye-to-eye in a museum. But have we finally slain the monster of the deep? Now we know there is nothing to be afraid of, can the Kraken finally be laid to rest? Probably not says Classen. We humans are afraid of the strangest things. They dont need to be realistic. Theres no indication that enlightenment and scientific progress has banished the monsters from the shadows of our imaginations. We will continue to be afraid of very strange things, including probably sea monsters. Indeed we are. The Kraken made a fearsome appearance in the blockbuster series Pirates of the Caribbean. It forced Captain Jack Sparrow to face his demons in a terrifying face-to-face encounter. Pirates needed the monstrous Kraken, nothing else would do. Or, as the German film director Werner Herzog put it, What would an ocean be without a monster lurking in the dark? It would be like sleep without dreams.", "hypothesis": "Kraken is probably based on an imaginary animal.", "gold_label": "contradiction"}
{"uid": "id_506", "premise": "What is patriotism? Is it love of ones birthplace, the place of childhoods recollections and hopes, dreams and aspirations? Is it the place where, in child- like naivety, we would watch the fleeting clouds and wonder why we too could not run so swiftly? The place where we would count the milliard glittering stars, terror-stricken lest each one an eye should be, piercing the very depths of our little souls? Is it the place where we would listen to the music of the birds and long to have wings to fly, even as they, to distant lands? Or the place where wewould sit at mothers knee, enraptured by wonderful tales of great deeds and conquests? In short, is it love for the spot, every inch representing dear and precious recollections of a happy, joyous, and playful childhood? If that were patriotism, few American men of today could be called upon to be patriotic, since the place of play has been turned into a factory, mill, and mine, while deafening sounds of machinery have replaced the music of the birds. Nor can we still hear the tales of great deeds, for the stories our mothers tell today are but those of sorrow, tears and grief. What, then, is patriotism? Patriotism, sir, is the last resort of scoundrels, said Dr. Johnson. Leo Tolstoy, the greatest anti-patriot of our times, defines patriotism as the principle that will justify the training of wholesale murderers; a trade that requires better equipment for the exercise of man-killing than the making of such necessities of life as shoes, clothing, and houses; a trade that guarantees better returns and greater glory than that of the average workingman.", "hypothesis": "The author believes patriotism as being the love for the spot where one grew up and had many happy memories.", "gold_label": "neutral"}
{"uid": "id_507", "premise": "What is patriotism? Is it love of ones birthplace, the place of childhoods recollections and hopes, dreams and aspirations? Is it the place where, in child- like naivety, we would watch the fleeting clouds and wonder why we too could not run so swiftly? The place where we would count the milliard glittering stars, terror-stricken lest each one an eye should be, piercing the very depths of our little souls? Is it the place where we would listen to the music of the birds and long to have wings to fly, even as they, to distant lands? Or the place where wewould sit at mothers knee, enraptured by wonderful tales of great deeds and conquests? In short, is it love for the spot, every inch representing dear and precious recollections of a happy, joyous, and playful childhood? If that were patriotism, few American men of today could be called upon to be patriotic, since the place of play has been turned into a factory, mill, and mine, while deafening sounds of machinery have replaced the music of the birds. Nor can we still hear the tales of great deeds, for the stories our mothers tell today are but those of sorrow, tears and grief. What, then, is patriotism? Patriotism, sir, is the last resort of scoundrels, said Dr. Johnson. Leo Tolstoy, the greatest anti-patriot of our times, defines patriotism as the principle that will justify the training of wholesale murderers; a trade that requires better equipment for the exercise of man-killing than the making of such necessities of life as shoes, clothing, and houses; a trade that guarantees better returns and greater glory than that of the average workingman.", "hypothesis": "Few Americans of today are patriotic", "gold_label": "contradiction"}
{"uid": "id_508", "premise": "What qualities and attributes make a political leader successful? A recent poll asked voters what they looked for in the ideal political leader; a good economic strategy perhaps, a willingness to admit the past mistakes of ones party or the ability to be likeable as a person. The popular answer seems to be credibility; voters want someone they can trust. How does this translate into a political strategy? To begin with, the poll suggests confusion surrounds the very basics of politics; what do the parties stand for anymore? The past few years has seen such a convergence in political ideals that the once clear blue conservative and red labour lines are now somewhat purple. To be credible, to be a successful political leader, you mustnt be afraid of hanging the banners and stating your policy. By this, and not doing a political 180 after the election, is the key to number 10.", "hypothesis": "Conservative and Labour parties have become more distinct.", "gold_label": "contradiction"}
{"uid": "id_509", "premise": "What qualities and attributes make a political leader successful? A recent poll asked voters what they looked for in the ideal political leader; a good economic strategy perhaps, a willingness to admit the past mistakes of ones party or the ability to be likeable as a person. The popular answer seems to be credibility; voters want someone they can trust. How does this translate into a political strategy? To begin with, the poll suggests confusion surrounds the very basics of politics; what do the parties stand for anymore? The past few years has seen such a convergence in political ideals that the once clear blue conservative and red labour lines are now somewhat purple. To be credible, to be a successful political leader, you mustnt be afraid of hanging the banners and stating your policy. By this, and not doing a political 180 after the election, is the key to number 10.", "hypothesis": "conservative and Labour parties have become similar", "gold_label": "entailment"}
{"uid": "id_510", "premise": "What qualities and attributes make a political leader successful? A recent poll asked voters what they looked for in the ideal political leader; a good economic strategy perhaps, a willingness to admit the past mistakes of ones party or the ability to be likeable as a person. The popular answer seems to be credibility; voters want someone they can trust. How does this translate into a political strategy? To begin with, the poll suggests confusion surrounds the very basics of politics; what do the parties stand for anymore? The past few years has seen such a convergence in political ideals that the once clear blue conservative and red labour lines are now somewhat purple. To be credible, to be a successful political leader, you mustnt be afraid of hanging the banners and stating your policy. By this, and not doing a political 180 after the election, is the key to number 10.", "hypothesis": "Conservative and Labour party are currently merging", "gold_label": "neutral"}
{"uid": "id_511", "premise": "What qualities and attributes make a political leader successful? A recent poll asked voters what they looked for in the ideal political leader; a good economic strategy perhaps, a willingness to admit the past mistakes of ones party or the ability to be likeable as a person. The popular answer seems to be credibility; voters want someone they can trust. How does this translate into a political strategy? To begin with, the poll suggests confusion surrounds the very basics of politics; what do the parties stand for anymore? The past few years has seen such a convergence in political ideals that the once clear blue conservative and red labour lines are now somewhat purple. To be credible, to be a successful political leader, you mustnt be afraid of hanging the banners and stating your policy. By this, and not doing a political 180 after the election, is the key to number 10.", "hypothesis": "Conservative and Labour MPs have become geographically closer.", "gold_label": "neutral"}
{"uid": "id_512", "premise": "What the Managers Really Do? When students graduate and first enter the workforce, the most common choice is to find an entry-level position. This can be a job such as an unpaid internship, an assistant, a secretary, or a junior partner position. Traditionally, we start with simpler jobs and work our way up. Young professionals start out with a plan to become senior partners, associates, or even managers of a workplace. However, these promotions can be few and far between, leaving many young professionals unfamiliar with management experience. An important step is understanding the role and responsibilities of a person in a managing position. Managers are organisational members who are responsible for the work performance of other organisational members. Managers have formal authority to use organisational resources and to make decisions. Managers at different levels of the organisation engage in different amounts of time on the four managerial functions of planning, organising, leading, and controlling. However, as many professionals already know, managing styles can be very different depending on where you work. Some managing styles are strictly hierarchical. Other managing styles can be more casual and relaxed, where the manager may act more like a team member rather than a strict boss. Many researchers have created a more scientific approach in studying these different approaches to managing. In the 1960s, researcher Henry Mintzberg created a seminal organisational model using three categories. These categories represent three major functional approaches, which are designated as interpersonal, informational and decisional. Introduced Category 1: INTERPERSONAL ROLES. Interpersonal roles require managers to direct and supervise employees and the organisation. The figurehead is typically a top of middle manager. This manager may communicate future organisational goals or ethical guidelines to employees at company meetings. They also attend ribbon-cutting ceremonies, host receptions, presentations and other activities associated with the figurehead role. A leader acts as an example for other employees to follow, gives commands and directions to subordinates, makes decisions, and mobilises employee support. They are also responsible for the selection and training of employees. Managers must be leaders at all levels of the organisation; often lower-level managers look to top management for this leadership example. In the role of liaison, a manager must coordinate the work of others in different work units, establish alliances between others, and work to share resources. This role is particularly critical for middle managers, who must often compete with other managers for important resources, yet must maintain successful working relationships with them for long time periods. Introduced Category 2: INFORMATIONAL ROLES. Informational roles are those in which managers obtain and transmit information. These roles have changed dramatically as technology has improved. The monitor evaluates the performance of others and takes corrective action to improve that performance. Monitors also watch for changes in the environment and within the company that may affect individual and organisational performance. Monitoring occurs at all levels of management. The role of disseminator requires that managers inform employees of changes that affect them and the organisation. They also communicate the companys vision and purpose. Introduced Category 3: DECISIONAL ROLES. Decisional roles require managers to plan strategy and utilise resources. There are four specific roles that are decisional. The entrepreneur role requires the manager to assign resources to develop innovative goods and services, or to expand a business. The disturbance handler corrects unanticipated problems facing the organisation from the internal or external environment. The third decisional role, that of resource allocator, involves determining which work units will get which resources. Top managers are likely to make large, overall budget decisions, while middle managers may make more specific allocations. Finally, the negotiator works with others, such as suppliers, distributors, or labor unions, to reach agreements regarding products and services. Although Mintzbergs initial research in 1960s helped categorise manager approaches, Mintzberg was still concerned about research involving other roles in the workplace. Minstzberg considered expanding his research to other roles, such as the role of disseminator, figurehead, liaison and spokesperson. Each role would have different special characteristics, and a new categorisation system would have to be made for each role to understand it properly. While Mintzbergs initial research was helpful in starting the conversation, there has since been criticism of his methods from other researchers. Some criticisms of the work were that even though there were multiple categories, the role of manager is still more complex. There are still many manager roles that are not as traditional and are not captured in Mintzbergs original three categories. In addition, sometimes, Mintzbergs research was not always effective. The research, when applied to real-life situations, did not always improve the management process in real-life practice. These two criticisms against Mintzbergs research method raised some questions about whether or not the research was useful to how we understand managers in todays world. However, even if the criticisms against Mintzbergs work are true, it does not mean that the original research from the 1960s is completely useless. Those researchers did not say Mintzbergs research is invalid. His research has two positive functions to the further research. The first positive function is Mintzberg provided a useful functional approach to analyse management. And he used this approach to provide a clear concept of the role of manager to the researcher. When researching human behavior, it is important to be concise about the subject of the research. Mintzbergs research has helped other researchers clearly define what a manager is, because in real-life situations, the manager is not always the same position title. Mintzbergs definitions added clarity and precision to future research on the topic. The second positive function is Mintzbergs research could be regarded as a good beginning to give a new insight to further research on this field in the future. Scientific research is always a gradual process. Just because Mintzbergs initial research had certain flaws, does not mean it is useless to other researchers. Researchers who are interested in studying the workplace in a systematic way have older research to look back on. A researcher doesnt have to start from the very beginning older research like Mintzbergs have shown what methods work well and what methods are not as appropriate for workplace dynamics. As more young professionals enter the job market, this research will continue to study and change the way we think about the modern workplace.", "hypothesis": "Young professionals can easily know management experience in the workplace.", "gold_label": "contradiction"}
{"uid": "id_513", "premise": "What the Managers Really Do? When students graduate and first enter the workforce, the most common choice is to find an entry-level position. This can be a job such as an unpaid internship, an assistant, a secretary, or a junior partner position. Traditionally, we start with simpler jobs and work our way up. Young professionals start out with a plan to become senior partners, associates, or even managers of a workplace. However, these promotions can be few and far between, leaving many young professionals unfamiliar with management experience. An important step is understanding the role and responsibilities of a person in a managing position. Managers are organisational members who are responsible for the work performance of other organisational members. Managers have formal authority to use organisational resources and to make decisions. Managers at different levels of the organisation engage in different amounts of time on the four managerial functions of planning, organising, leading, and controlling. However, as many professionals already know, managing styles can be very different depending on where you work. Some managing styles are strictly hierarchical. Other managing styles can be more casual and relaxed, where the manager may act more like a team member rather than a strict boss. Many researchers have created a more scientific approach in studying these different approaches to managing. In the 1960s, researcher Henry Mintzberg created a seminal organisational model using three categories. These categories represent three major functional approaches, which are designated as interpersonal, informational and decisional. Introduced Category 1: INTERPERSONAL ROLES. Interpersonal roles require managers to direct and supervise employees and the organisation. The figurehead is typically a top of middle manager. This manager may communicate future organisational goals or ethical guidelines to employees at company meetings. They also attend ribbon-cutting ceremonies, host receptions, presentations and other activities associated with the figurehead role. A leader acts as an example for other employees to follow, gives commands and directions to subordinates, makes decisions, and mobilises employee support. They are also responsible for the selection and training of employees. Managers must be leaders at all levels of the organisation; often lower-level managers look to top management for this leadership example. In the role of liaison, a manager must coordinate the work of others in different work units, establish alliances between others, and work to share resources. This role is particularly critical for middle managers, who must often compete with other managers for important resources, yet must maintain successful working relationships with them for long time periods. Introduced Category 2: INFORMATIONAL ROLES. Informational roles are those in which managers obtain and transmit information. These roles have changed dramatically as technology has improved. The monitor evaluates the performance of others and takes corrective action to improve that performance. Monitors also watch for changes in the environment and within the company that may affect individual and organisational performance. Monitoring occurs at all levels of management. The role of disseminator requires that managers inform employees of changes that affect them and the organisation. They also communicate the companys vision and purpose. Introduced Category 3: DECISIONAL ROLES. Decisional roles require managers to plan strategy and utilise resources. There are four specific roles that are decisional. The entrepreneur role requires the manager to assign resources to develop innovative goods and services, or to expand a business. The disturbance handler corrects unanticipated problems facing the organisation from the internal or external environment. The third decisional role, that of resource allocator, involves determining which work units will get which resources. Top managers are likely to make large, overall budget decisions, while middle managers may make more specific allocations. Finally, the negotiator works with others, such as suppliers, distributors, or labor unions, to reach agreements regarding products and services. Although Mintzbergs initial research in 1960s helped categorise manager approaches, Mintzberg was still concerned about research involving other roles in the workplace. Minstzberg considered expanding his research to other roles, such as the role of disseminator, figurehead, liaison and spokesperson. Each role would have different special characteristics, and a new categorisation system would have to be made for each role to understand it properly. While Mintzbergs initial research was helpful in starting the conversation, there has since been criticism of his methods from other researchers. Some criticisms of the work were that even though there were multiple categories, the role of manager is still more complex. There are still many manager roles that are not as traditional and are not captured in Mintzbergs original three categories. In addition, sometimes, Mintzbergs research was not always effective. The research, when applied to real-life situations, did not always improve the management process in real-life practice. These two criticisms against Mintzbergs research method raised some questions about whether or not the research was useful to how we understand managers in todays world. However, even if the criticisms against Mintzbergs work are true, it does not mean that the original research from the 1960s is completely useless. Those researchers did not say Mintzbergs research is invalid. His research has two positive functions to the further research. The first positive function is Mintzberg provided a useful functional approach to analyse management. And he used this approach to provide a clear concept of the role of manager to the researcher. When researching human behavior, it is important to be concise about the subject of the research. Mintzbergs research has helped other researchers clearly define what a manager is, because in real-life situations, the manager is not always the same position title. Mintzbergs definitions added clarity and precision to future research on the topic. The second positive function is Mintzbergs research could be regarded as a good beginning to give a new insight to further research on this field in the future. Scientific research is always a gradual process. Just because Mintzbergs initial research had certain flaws, does not mean it is useless to other researchers. Researchers who are interested in studying the workplace in a systematic way have older research to look back on. A researcher doesnt have to start from the very beginning older research like Mintzbergs have shown what methods work well and what methods are not as appropriate for workplace dynamics. As more young professionals enter the job market, this research will continue to study and change the way we think about the modern workplace.", "hypothesis": "Mintzbergs theory is valuable for future studies.", "gold_label": "entailment"}
{"uid": "id_514", "premise": "What the Managers Really Do? When students graduate and first enter the workforce, the most common choice is to find an entry-level position. This can be a job such as an unpaid internship, an assistant, a secretary, or a junior partner position. Traditionally, we start with simpler jobs and work our way up. Young professionals start out with a plan to become senior partners, associates, or even managers of a workplace. However, these promotions can be few and far between, leaving many young professionals unfamiliar with management experience. An important step is understanding the role and responsibilities of a person in a managing position. Managers are organisational members who are responsible for the work performance of other organisational members. Managers have formal authority to use organisational resources and to make decisions. Managers at different levels of the organisation engage in different amounts of time on the four managerial functions of planning, organising, leading, and controlling. However, as many professionals already know, managing styles can be very different depending on where you work. Some managing styles are strictly hierarchical. Other managing styles can be more casual and relaxed, where the manager may act more like a team member rather than a strict boss. Many researchers have created a more scientific approach in studying these different approaches to managing. In the 1960s, researcher Henry Mintzberg created a seminal organisational model using three categories. These categories represent three major functional approaches, which are designated as interpersonal, informational and decisional. Introduced Category 1: INTERPERSONAL ROLES. Interpersonal roles require managers to direct and supervise employees and the organisation. The figurehead is typically a top of middle manager. This manager may communicate future organisational goals or ethical guidelines to employees at company meetings. They also attend ribbon-cutting ceremonies, host receptions, presentations and other activities associated with the figurehead role. A leader acts as an example for other employees to follow, gives commands and directions to subordinates, makes decisions, and mobilises employee support. They are also responsible for the selection and training of employees. Managers must be leaders at all levels of the organisation; often lower-level managers look to top management for this leadership example. In the role of liaison, a manager must coordinate the work of others in different work units, establish alliances between others, and work to share resources. This role is particularly critical for middle managers, who must often compete with other managers for important resources, yet must maintain successful working relationships with them for long time periods. Introduced Category 2: INFORMATIONAL ROLES. Informational roles are those in which managers obtain and transmit information. These roles have changed dramatically as technology has improved. The monitor evaluates the performance of others and takes corrective action to improve that performance. Monitors also watch for changes in the environment and within the company that may affect individual and organisational performance. Monitoring occurs at all levels of management. The role of disseminator requires that managers inform employees of changes that affect them and the organisation. They also communicate the companys vision and purpose. Introduced Category 3: DECISIONAL ROLES. Decisional roles require managers to plan strategy and utilise resources. There are four specific roles that are decisional. The entrepreneur role requires the manager to assign resources to develop innovative goods and services, or to expand a business. The disturbance handler corrects unanticipated problems facing the organisation from the internal or external environment. The third decisional role, that of resource allocator, involves determining which work units will get which resources. Top managers are likely to make large, overall budget decisions, while middle managers may make more specific allocations. Finally, the negotiator works with others, such as suppliers, distributors, or labor unions, to reach agreements regarding products and services. Although Mintzbergs initial research in 1960s helped categorise manager approaches, Mintzberg was still concerned about research involving other roles in the workplace. Minstzberg considered expanding his research to other roles, such as the role of disseminator, figurehead, liaison and spokesperson. Each role would have different special characteristics, and a new categorisation system would have to be made for each role to understand it properly. While Mintzbergs initial research was helpful in starting the conversation, there has since been criticism of his methods from other researchers. Some criticisms of the work were that even though there were multiple categories, the role of manager is still more complex. There are still many manager roles that are not as traditional and are not captured in Mintzbergs original three categories. In addition, sometimes, Mintzbergs research was not always effective. The research, when applied to real-life situations, did not always improve the management process in real-life practice. These two criticisms against Mintzbergs research method raised some questions about whether or not the research was useful to how we understand managers in todays world. However, even if the criticisms against Mintzbergs work are true, it does not mean that the original research from the 1960s is completely useless. Those researchers did not say Mintzbergs research is invalid. His research has two positive functions to the further research. The first positive function is Mintzberg provided a useful functional approach to analyse management. And he used this approach to provide a clear concept of the role of manager to the researcher. When researching human behavior, it is important to be concise about the subject of the research. Mintzbergs research has helped other researchers clearly define what a manager is, because in real-life situations, the manager is not always the same position title. Mintzbergs definitions added clarity and precision to future research on the topic. The second positive function is Mintzbergs research could be regarded as a good beginning to give a new insight to further research on this field in the future. Scientific research is always a gradual process. Just because Mintzbergs initial research had certain flaws, does not mean it is useless to other researchers. Researchers who are interested in studying the workplace in a systematic way have older research to look back on. A researcher doesnt have to start from the very beginning older research like Mintzbergs have shown what methods work well and what methods are not as appropriate for workplace dynamics. As more young professionals enter the job market, this research will continue to study and change the way we think about the modern workplace.", "hypothesis": "All managers do the same work.", "gold_label": "contradiction"}
{"uid": "id_515", "premise": "What the Managers Really Do? When students graduate and first enter the workforce, the most common choice is to find an entry-level position. This can be a job such as an unpaid internship, an assistant, a secretary, or a junior partner position. Traditionally, we start with simpler jobs and work our way up. Young professionals start out with a plan to become senior partners, associates, or even managers of a workplace. However, these promotions can be few and far between, leaving many young professionals unfamiliar with management experience. An important step is understanding the role and responsibilities of a person in a managing position. Managers are organisational members who are responsible for the work performance of other organisational members. Managers have formal authority to use organisational resources and to make decisions. Managers at different levels of the organisation engage in different amounts of time on the four managerial functions of planning, organising, leading, and controlling. However, as many professionals already know, managing styles can be very different depending on where you work. Some managing styles are strictly hierarchical. Other managing styles can be more casual and relaxed, where the manager may act more like a team member rather than a strict boss. Many researchers have created a more scientific approach in studying these different approaches to managing. In the 1960s, researcher Henry Mintzberg created a seminal organisational model using three categories. These categories represent three major functional approaches, which are designated as interpersonal, informational and decisional. Introduced Category 1: INTERPERSONAL ROLES. Interpersonal roles require managers to direct and supervise employees and the organisation. The figurehead is typically a top of middle manager. This manager may communicate future organisational goals or ethical guidelines to employees at company meetings. They also attend ribbon-cutting ceremonies, host receptions, presentations and other activities associated with the figurehead role. A leader acts as an example for other employees to follow, gives commands and directions to subordinates, makes decisions, and mobilises employee support. They are also responsible for the selection and training of employees. Managers must be leaders at all levels of the organisation; often lower-level managers look to top management for this leadership example. In the role of liaison, a manager must coordinate the work of others in different work units, establish alliances between others, and work to share resources. This role is particularly critical for middle managers, who must often compete with other managers for important resources, yet must maintain successful working relationships with them for long time periods. Introduced Category 2: INFORMATIONAL ROLES. Informational roles are those in which managers obtain and transmit information. These roles have changed dramatically as technology has improved. The monitor evaluates the performance of others and takes corrective action to improve that performance. Monitors also watch for changes in the environment and within the company that may affect individual and organisational performance. Monitoring occurs at all levels of management. The role of disseminator requires that managers inform employees of changes that affect them and the organisation. They also communicate the companys vision and purpose. Introduced Category 3: DECISIONAL ROLES. Decisional roles require managers to plan strategy and utilise resources. There are four specific roles that are decisional. The entrepreneur role requires the manager to assign resources to develop innovative goods and services, or to expand a business. The disturbance handler corrects unanticipated problems facing the organisation from the internal or external environment. The third decisional role, that of resource allocator, involves determining which work units will get which resources. Top managers are likely to make large, overall budget decisions, while middle managers may make more specific allocations. Finally, the negotiator works with others, such as suppliers, distributors, or labor unions, to reach agreements regarding products and services. Although Mintzbergs initial research in 1960s helped categorise manager approaches, Mintzberg was still concerned about research involving other roles in the workplace. Minstzberg considered expanding his research to other roles, such as the role of disseminator, figurehead, liaison and spokesperson. Each role would have different special characteristics, and a new categorisation system would have to be made for each role to understand it properly. While Mintzbergs initial research was helpful in starting the conversation, there has since been criticism of his methods from other researchers. Some criticisms of the work were that even though there were multiple categories, the role of manager is still more complex. There are still many manager roles that are not as traditional and are not captured in Mintzbergs original three categories. In addition, sometimes, Mintzbergs research was not always effective. The research, when applied to real-life situations, did not always improve the management process in real-life practice. These two criticisms against Mintzbergs research method raised some questions about whether or not the research was useful to how we understand managers in todays world. However, even if the criticisms against Mintzbergs work are true, it does not mean that the original research from the 1960s is completely useless. Those researchers did not say Mintzbergs research is invalid. His research has two positive functions to the further research. The first positive function is Mintzberg provided a useful functional approach to analyse management. And he used this approach to provide a clear concept of the role of manager to the researcher. When researching human behavior, it is important to be concise about the subject of the research. Mintzbergs research has helped other researchers clearly define what a manager is, because in real-life situations, the manager is not always the same position title. Mintzbergs definitions added clarity and precision to future research on the topic. The second positive function is Mintzbergs research could be regarded as a good beginning to give a new insight to further research on this field in the future. Scientific research is always a gradual process. Just because Mintzbergs initial research had certain flaws, does not mean it is useless to other researchers. Researchers who are interested in studying the workplace in a systematic way have older research to look back on. A researcher doesnt have to start from the very beginning older research like Mintzbergs have shown what methods work well and what methods are not as appropriate for workplace dynamics. As more young professionals enter the job market, this research will continue to study and change the way we think about the modern workplace.", "hypothesis": "Mintzbergs theory broke well-established notions about managing styles.", "gold_label": "neutral"}
{"uid": "id_516", "premise": "What the Managers Really Do? When students graduate and first enter the workforce, the most common choice is to find an entry-level position. This can be a job such as an unpaid internship, an assistant, a secretary, or a junior partner position. Traditionally, we start with simpler jobs and work our way up. Young professionals start out with a plan to become senior partners, associates, or even managers of a workplace. However, these promotions can be few and far between, leaving many young professionals unfamiliar with management experience. An important step is understanding the role and responsibilities of a person in a managing position. Managers are organisational members who are responsible for the work performance of other organisational members. Managers have formal authority to use organisational resources and to make decisions. Managers at different levels of the organisation engage in different amounts of time on the four managerial functions of planning, organising, leading, and controlling. However, as many professionals already know, managing styles can be very different depending on where you work. Some managing styles are strictly hierarchical. Other managing styles can be more casual and relaxed, where the manager may act more like a team member rather than a strict boss. Many researchers have created a more scientific approach in studying these different approaches to managing. In the 1960s, researcher Henry Mintzberg created a seminal organisational model using three categories. These categories represent three major functional approaches, which are designated as interpersonal, informational and decisional. Introduced Category 1: INTERPERSONAL ROLES. Interpersonal roles require managers to direct and supervise employees and the organisation. The figurehead is typically a top of middle manager. This manager may communicate future organisational goals or ethical guidelines to employees at company meetings. They also attend ribbon-cutting ceremonies, host receptions, presentations and other activities associated with the figurehead role. A leader acts as an example for other employees to follow, gives commands and directions to subordinates, makes decisions, and mobilises employee support. They are also responsible for the selection and training of employees. Managers must be leaders at all levels of the organisation; often lower-level managers look to top management for this leadership example. In the role of liaison, a manager must coordinate the work of others in different work units, establish alliances between others, and work to share resources. This role is particularly critical for middle managers, who must often compete with other managers for important resources, yet must maintain successful working relationships with them for long time periods. Introduced Category 2: INFORMATIONAL ROLES. Informational roles are those in which managers obtain and transmit information. These roles have changed dramatically as technology has improved. The monitor evaluates the performance of others and takes corrective action to improve that performance. Monitors also watch for changes in the environment and within the company that may affect individual and organisational performance. Monitoring occurs at all levels of management. The role of disseminator requires that managers inform employees of changes that affect them and the organisation. They also communicate the companys vision and purpose. Introduced Category 3: DECISIONAL ROLES. Decisional roles require managers to plan strategy and utilise resources. There are four specific roles that are decisional. The entrepreneur role requires the manager to assign resources to develop innovative goods and services, or to expand a business. The disturbance handler corrects unanticipated problems facing the organisation from the internal or external environment. The third decisional role, that of resource allocator, involves determining which work units will get which resources. Top managers are likely to make large, overall budget decisions, while middle managers may make more specific allocations. Finally, the negotiator works with others, such as suppliers, distributors, or labor unions, to reach agreements regarding products and services. Although Mintzbergs initial research in 1960s helped categorise manager approaches, Mintzberg was still concerned about research involving other roles in the workplace. Minstzberg considered expanding his research to other roles, such as the role of disseminator, figurehead, liaison and spokesperson. Each role would have different special characteristics, and a new categorisation system would have to be made for each role to understand it properly. While Mintzbergs initial research was helpful in starting the conversation, there has since been criticism of his methods from other researchers. Some criticisms of the work were that even though there were multiple categories, the role of manager is still more complex. There are still many manager roles that are not as traditional and are not captured in Mintzbergs original three categories. In addition, sometimes, Mintzbergs research was not always effective. The research, when applied to real-life situations, did not always improve the management process in real-life practice. These two criticisms against Mintzbergs research method raised some questions about whether or not the research was useful to how we understand managers in todays world. However, even if the criticisms against Mintzbergs work are true, it does not mean that the original research from the 1960s is completely useless. Those researchers did not say Mintzbergs research is invalid. His research has two positive functions to the further research. The first positive function is Mintzberg provided a useful functional approach to analyse management. And he used this approach to provide a clear concept of the role of manager to the researcher. When researching human behavior, it is important to be concise about the subject of the research. Mintzbergs research has helped other researchers clearly define what a manager is, because in real-life situations, the manager is not always the same position title. Mintzbergs definitions added clarity and precision to future research on the topic. The second positive function is Mintzbergs research could be regarded as a good beginning to give a new insight to further research on this field in the future. Scientific research is always a gradual process. Just because Mintzbergs initial research had certain flaws, does not mean it is useless to other researchers. Researchers who are interested in studying the workplace in a systematic way have older research to look back on. A researcher doesnt have to start from the very beginning older research like Mintzbergs have shown what methods work well and what methods are not as appropriate for workplace dynamics. As more young professionals enter the job market, this research will continue to study and change the way we think about the modern workplace.", "hypothesis": "Mintzberg got a large amount of research funds for his contribution.", "gold_label": "neutral"}
{"uid": "id_517", "premise": "What to do in a fire? Fire drills are a big part of being safe in school: They prepare you for what you need to do in case of a fire. But what if there was a fire where you live? Would you know what to do? Talking about fires can be scary because no one likes to think about people getting hurt or their things getting burned. But you can feel less worried if you are prepared. Its a good idea for families to talk about what they would do to escape a fire. Different families will have different strategies. Some kids live in one-story houses and other kids live in tall buildings. Youll want to talk about escape plans and escape routes, so lets start there. Know Your Way Out An escape plan can help every member of a family get out of a burning house. The idea is to get outside quickly and safely. Smoke from a fire can make it hard to see where things are, so its important to learn and remember the different ways out of your home. How many exits are there? How do you get to them from your room? Its a good idea to have your family draw a map of the escape plan. Its possible one way out could be blocked by fire or smoke, so youll want to know where other ones are. And if you live in an apartment building, youll want to know the best way to the stairwell or other emergency exits. Safety Steps If youre in a room with the door closed when the fire breaks out, you need to take a few extra steps: Check to see if theres heat or smoke coming in the cracks around the door. (Youre checking to see if theres fire on the other side. ) If you see smoke coming under the door dont open the door! If you dont see smoke touch the door. If the door is hot or very warm dont open the door! If you dont see smoke and the door is not hot then use your fingers to lightly touch the doorknob. If the doorknob is hot or very warm dont open the door! If the doorknob feels cool, and you cant see any smoke around the door, you can open the door very carefully and slowly. When you open the door, if you feel a burst of heat or smoke pours into the room, quickly shut the door and make sure it is really closed. If theres no smoke or heat when you open the door, go toward your escape route exit.", "hypothesis": "If you open the door and everything seems fine, go straight to the exit.", "gold_label": "entailment"}
{"uid": "id_518", "premise": "What to do in a fire? Fire drills are a big part of being safe in school: They prepare you for what you need to do in case of a fire. But what if there was a fire where you live? Would you know what to do? Talking about fires can be scary because no one likes to think about people getting hurt or their things getting burned. But you can feel less worried if you are prepared. Its a good idea for families to talk about what they would do to escape a fire. Different families will have different strategies. Some kids live in one-story houses and other kids live in tall buildings. Youll want to talk about escape plans and escape routes, so lets start there. Know Your Way Out An escape plan can help every member of a family get out of a burning house. The idea is to get outside quickly and safely. Smoke from a fire can make it hard to see where things are, so its important to learn and remember the different ways out of your home. How many exits are there? How do you get to them from your room? Its a good idea to have your family draw a map of the escape plan. Its possible one way out could be blocked by fire or smoke, so youll want to know where other ones are. And if you live in an apartment building, youll want to know the best way to the stairwell or other emergency exits. Safety Steps If youre in a room with the door closed when the fire breaks out, you need to take a few extra steps: Check to see if theres heat or smoke coming in the cracks around the door. (Youre checking to see if theres fire on the other side. ) If you see smoke coming under the door dont open the door! If you dont see smoke touch the door. If the door is hot or very warm dont open the door! If you dont see smoke and the door is not hot then use your fingers to lightly touch the doorknob. If the doorknob is hot or very warm dont open the door! If the doorknob feels cool, and you cant see any smoke around the door, you can open the door very carefully and slowly. When you open the door, if you feel a burst of heat or smoke pours into the room, quickly shut the door and make sure it is really closed. If theres no smoke or heat when you open the door, go toward your escape route exit.", "hypothesis": "Hot door means you shouldnt open it to escape.", "gold_label": "entailment"}
{"uid": "id_519", "premise": "What to do in a fire? Fire drills are a big part of being safe in school: They prepare you for what you need to do in case of a fire. But what if there was a fire where you live? Would you know what to do? Talking about fires can be scary because no one likes to think about people getting hurt or their things getting burned. But you can feel less worried if you are prepared. Its a good idea for families to talk about what they would do to escape a fire. Different families will have different strategies. Some kids live in one-story houses and other kids live in tall buildings. Youll want to talk about escape plans and escape routes, so lets start there. Know Your Way Out An escape plan can help every member of a family get out of a burning house. The idea is to get outside quickly and safely. Smoke from a fire can make it hard to see where things are, so its important to learn and remember the different ways out of your home. How many exits are there? How do you get to them from your room? Its a good idea to have your family draw a map of the escape plan. Its possible one way out could be blocked by fire or smoke, so youll want to know where other ones are. And if you live in an apartment building, youll want to know the best way to the stairwell or other emergency exits. Safety Steps If youre in a room with the door closed when the fire breaks out, you need to take a few extra steps: Check to see if theres heat or smoke coming in the cracks around the door. (Youre checking to see if theres fire on the other side. ) If you see smoke coming under the door dont open the door! If you dont see smoke touch the door. If the door is hot or very warm dont open the door! If you dont see smoke and the door is not hot then use your fingers to lightly touch the doorknob. If the doorknob is hot or very warm dont open the door! If the doorknob feels cool, and you cant see any smoke around the door, you can open the door very carefully and slowly. When you open the door, if you feel a burst of heat or smoke pours into the room, quickly shut the door and make sure it is really closed. If theres no smoke or heat when you open the door, go toward your escape route exit.", "hypothesis": "If youre stuck in a room, and see smoke coming into your room, you should open the door and ran to the exit.", "gold_label": "contradiction"}
{"uid": "id_520", "premise": "What to do in a fire? Fire drills are a big part of being safe in school: They prepare you for what you need to do in case of a fire. But what if there was a fire where you live? Would you know what to do? Talking about fires can be scary because no one likes to think about people getting hurt or their things getting burned. But you can feel less worried if you are prepared. Its a good idea for families to talk about what they would do to escape a fire. Different families will have different strategies. Some kids live in one-story houses and other kids live in tall buildings. Youll want to talk about escape plans and escape routes, so lets start there. Know Your Way Out An escape plan can help every member of a family get out of a burning house. The idea is to get outside quickly and safely. Smoke from a fire can make it hard to see where things are, so its important to learn and remember the different ways out of your home. How many exits are there? How do you get to them from your room? Its a good idea to have your family draw a map of the escape plan. Its possible one way out could be blocked by fire or smoke, so youll want to know where other ones are. And if you live in an apartment building, youll want to know the best way to the stairwell or other emergency exits. Safety Steps If youre in a room with the door closed when the fire breaks out, you need to take a few extra steps: Check to see if theres heat or smoke coming in the cracks around the door. (Youre checking to see if theres fire on the other side. ) If you see smoke coming under the door dont open the door! If you dont see smoke touch the door. If the door is hot or very warm dont open the door! If you dont see smoke and the door is not hot then use your fingers to lightly touch the doorknob. If the doorknob is hot or very warm dont open the door! If the doorknob feels cool, and you cant see any smoke around the door, you can open the door very carefully and slowly. When you open the door, if you feel a burst of heat or smoke pours into the room, quickly shut the door and make sure it is really closed. If theres no smoke or heat when you open the door, go toward your escape route exit.", "hypothesis": "You should mark different ways out of your home on the map.", "gold_label": "neutral"}
{"uid": "id_521", "premise": "What to do in a fire? Fire drills are a big part of being safe in school: They prepare you for what you need to do in case of a fire. But what if there was a fire where you live? Would you know what to do? Talking about fires can be scary because no one likes to think about people getting hurt or their things getting burned. But you can feel less worried if you are prepared. Its a good idea for families to talk about what they would do to escape a fire. Different families will have different strategies. Some kids live in one-story houses and other kids live in tall buildings. Youll want to talk about escape plans and escape routes, so lets start there. Know Your Way Out An escape plan can help every member of a family get out of a burning house. The idea is to get outside quickly and safely. Smoke from a fire can make it hard to see where things are, so its important to learn and remember the different ways out of your home. How many exits are there? How do you get to them from your room? Its a good idea to have your family draw a map of the escape plan. Its possible one way out could be blocked by fire or smoke, so youll want to know where other ones are. And if you live in an apartment building, youll want to know the best way to the stairwell or other emergency exits. Safety Steps If youre in a room with the door closed when the fire breaks out, you need to take a few extra steps: Check to see if theres heat or smoke coming in the cracks around the door. (Youre checking to see if theres fire on the other side. ) If you see smoke coming under the door dont open the door! If you dont see smoke touch the door. If the door is hot or very warm dont open the door! If you dont see smoke and the door is not hot then use your fingers to lightly touch the doorknob. If the doorknob is hot or very warm dont open the door! If the doorknob feels cool, and you cant see any smoke around the door, you can open the door very carefully and slowly. When you open the door, if you feel a burst of heat or smoke pours into the room, quickly shut the door and make sure it is really closed. If theres no smoke or heat when you open the door, go toward your escape route exit.", "hypothesis": "It is important to have a strategy before escaping the fire.", "gold_label": "entailment"}
{"uid": "id_522", "premise": "What you need to know about Culture Shock Most people who move to a foreign country or culture may experience a period of time when they feel very homesick and have a lot of stress and difficulty functioning in the new culture. This feeling is often called culture shock and it is important to understand and learn how to cope with culture shock if you are to adapt successfully to your new homes culture. First of all, its important to know that culture shock is normal. Everyone in a new situation will go through some form of culture shock, and the extent of which they do is determined by factors such as the difference between cultures, the degree to which someone is anxious to adapt to a new culture and the familiarity that person has to the new culture. If you go, for example, to a culture that is far different from your own, youre likely to experience culture shock more sharply than those who move to a new culture knowing the language and the behavioural norms of the new culture. There are four general stages of cultural adjustment, and it is important that you are aware of these stages and can recognise which stage you are in and when so that you will understand why you feel the way you do and that any difficulties you are experience are temporary, a process you are going through rather than a constant situation. The first stage is usually referred to as the excitement stage or the honeymoon stage. Upon arriving in a new environment, youll be interested in the new culture, everything will seem exciting, everyone will seem friendly and helpful and youll be overwhelmed with impressions. During this stage you are merely soaking up the new landscape, taking in these impressions passively, and at this stage you have little meaningful experience of the culture. But it isnt long before the honeymoon stage dissolves into the second stage sometimes called the withdrawal stage. The excitement you felt before changes to frustration as you find it difficult to cope with the problems that arise. It seems that everything is difficult, the language is hard to learn, people are unusual and unpredictable, friends are hard to make, and simple things like shopping and going to the bank are challenges. It is at this stage that you are likely to feel anxious and homesick, and you will probably find yourself complaining about the new culture or country. This is the stage which is referred to as culture shock. Culture shock is only temporary, and at some point, if you are one of those who manage to stick it out, youll transition into the third stage of cultural adjustment, the recovery stage. At this point, youll have a routine, and youll feel more confident functioning in the new culture. Youll start to feel less isolated as you start to understand and accept the way things are done and the way people behave in your new environment. Customs and traditions are clearer and easier to understand. At this stage, youll deal with new challenges with humour rather than anxiety. The last stage is the home or stability stage this is the point when people start to feel at home in the new culture. At this stage, youll function well in the new culture, adopt certain features and behaviours from your new home, and prefer certain aspects of the new culture to your own culture. There is, in a sense, a fifth stage to this process. If you decide to return home after a long period in a new culture, you may experience what is called reverse culture shock. This means that you may find aspects of your own culture foreign because you are so used to the new culture that you have spent so long adjusting to. Reverse culture shock is usually pretty mild you may notice things about your home culture that you had never noticed before, and some of the ways people do things may seem odd. Reverse culture shock rarely lasts for very long.", "hypothesis": "Some people will find the process of adapting to a new country easier than others.", "gold_label": "entailment"}
{"uid": "id_523", "premise": "What you need to know about Culture Shock Most people who move to a foreign country or culture may experience a period of time when they feel very homesick and have a lot of stress and difficulty functioning in the new culture. This feeling is often called culture shock and it is important to understand and learn how to cope with culture shock if you are to adapt successfully to your new homes culture. First of all, its important to know that culture shock is normal. Everyone in a new situation will go through some form of culture shock, and the extent of which they do is determined by factors such as the difference between cultures, the degree to which someone is anxious to adapt to a new culture and the familiarity that person has to the new culture. If you go, for example, to a culture that is far different from your own, youre likely to experience culture shock more sharply than those who move to a new culture knowing the language and the behavioural norms of the new culture. There are four general stages of cultural adjustment, and it is important that you are aware of these stages and can recognise which stage you are in and when so that you will understand why you feel the way you do and that any difficulties you are experience are temporary, a process you are going through rather than a constant situation. The first stage is usually referred to as the excitement stage or the honeymoon stage. Upon arriving in a new environment, youll be interested in the new culture, everything will seem exciting, everyone will seem friendly and helpful and youll be overwhelmed with impressions. During this stage you are merely soaking up the new landscape, taking in these impressions passively, and at this stage you have little meaningful experience of the culture. But it isnt long before the honeymoon stage dissolves into the second stage sometimes called the withdrawal stage. The excitement you felt before changes to frustration as you find it difficult to cope with the problems that arise. It seems that everything is difficult, the language is hard to learn, people are unusual and unpredictable, friends are hard to make, and simple things like shopping and going to the bank are challenges. It is at this stage that you are likely to feel anxious and homesick, and you will probably find yourself complaining about the new culture or country. This is the stage which is referred to as culture shock. Culture shock is only temporary, and at some point, if you are one of those who manage to stick it out, youll transition into the third stage of cultural adjustment, the recovery stage. At this point, youll have a routine, and youll feel more confident functioning in the new culture. Youll start to feel less isolated as you start to understand and accept the way things are done and the way people behave in your new environment. Customs and traditions are clearer and easier to understand. At this stage, youll deal with new challenges with humour rather than anxiety. The last stage is the home or stability stage this is the point when people start to feel at home in the new culture. At this stage, youll function well in the new culture, adopt certain features and behaviours from your new home, and prefer certain aspects of the new culture to your own culture. There is, in a sense, a fifth stage to this process. If you decide to return home after a long period in a new culture, you may experience what is called reverse culture shock. This means that you may find aspects of your own culture foreign because you are so used to the new culture that you have spent so long adjusting to. Reverse culture shock is usually pretty mild you may notice things about your home culture that you had never noticed before, and some of the ways people do things may seem odd. Reverse culture shock rarely lasts for very long.", "hypothesis": "By the third stage, people do not experience any more problems with the new culture.", "gold_label": "contradiction"}
{"uid": "id_524", "premise": "What you need to know about Culture Shock Most people who move to a foreign country or culture may experience a period of time when they feel very homesick and have a lot of stress and difficulty functioning in the new culture. This feeling is often called culture shock and it is important to understand and learn how to cope with culture shock if you are to adapt successfully to your new homes culture. First of all, its important to know that culture shock is normal. Everyone in a new situation will go through some form of culture shock, and the extent of which they do is determined by factors such as the difference between cultures, the degree to which someone is anxious to adapt to a new culture and the familiarity that person has to the new culture. If you go, for example, to a culture that is far different from your own, youre likely to experience culture shock more sharply than those who move to a new culture knowing the language and the behavioural norms of the new culture. There are four general stages of cultural adjustment, and it is important that you are aware of these stages and can recognise which stage you are in and when so that you will understand why you feel the way you do and that any difficulties you are experience are temporary, a process you are going through rather than a constant situation. The first stage is usually referred to as the excitement stage or the honeymoon stage. Upon arriving in a new environment, youll be interested in the new culture, everything will seem exciting, everyone will seem friendly and helpful and youll be overwhelmed with impressions. During this stage you are merely soaking up the new landscape, taking in these impressions passively, and at this stage you have little meaningful experience of the culture. But it isnt long before the honeymoon stage dissolves into the second stage sometimes called the withdrawal stage. The excitement you felt before changes to frustration as you find it difficult to cope with the problems that arise. It seems that everything is difficult, the language is hard to learn, people are unusual and unpredictable, friends are hard to make, and simple things like shopping and going to the bank are challenges. It is at this stage that you are likely to feel anxious and homesick, and you will probably find yourself complaining about the new culture or country. This is the stage which is referred to as culture shock. Culture shock is only temporary, and at some point, if you are one of those who manage to stick it out, youll transition into the third stage of cultural adjustment, the recovery stage. At this point, youll have a routine, and youll feel more confident functioning in the new culture. Youll start to feel less isolated as you start to understand and accept the way things are done and the way people behave in your new environment. Customs and traditions are clearer and easier to understand. At this stage, youll deal with new challenges with humour rather than anxiety. The last stage is the home or stability stage this is the point when people start to feel at home in the new culture. At this stage, youll function well in the new culture, adopt certain features and behaviours from your new home, and prefer certain aspects of the new culture to your own culture. There is, in a sense, a fifth stage to this process. If you decide to return home after a long period in a new culture, you may experience what is called reverse culture shock. This means that you may find aspects of your own culture foreign because you are so used to the new culture that you have spent so long adjusting to. Reverse culture shock is usually pretty mild you may notice things about your home culture that you had never noticed before, and some of the ways people do things may seem odd. Reverse culture shock rarely lasts for very long.", "hypothesis": "In the fourth stage, people speak new language fluently.", "gold_label": "neutral"}
{"uid": "id_525", "premise": "What you need to know about Culture Shock Most people who move to a foreign country or culture may experience a period of time when they feel very homesick and have a lot of stress and difficulty functioning in the new culture. This feeling is often called culture shock and it is important to understand and learn how to cope with culture shock if you are to adapt successfully to your new homes culture. First of all, its important to know that culture shock is normal. Everyone in a new situation will go through some form of culture shock, and the extent of which they do is determined by factors such as the difference between cultures, the degree to which someone is anxious to adapt to a new culture and the familiarity that person has to the new culture. If you go, for example, to a culture that is far different from your own, youre likely to experience culture shock more sharply than those who move to a new culture knowing the language and the behavioural norms of the new culture. There are four general stages of cultural adjustment, and it is important that you are aware of these stages and can recognise which stage you are in and when so that you will understand why you feel the way you do and that any difficulties you are experience are temporary, a process you are going through rather than a constant situation. The first stage is usually referred to as the excitement stage or the honeymoon stage. Upon arriving in a new environment, youll be interested in the new culture, everything will seem exciting, everyone will seem friendly and helpful and youll be overwhelmed with impressions. During this stage you are merely soaking up the new landscape, taking in these impressions passively, and at this stage you have little meaningful experience of the culture. But it isnt long before the honeymoon stage dissolves into the second stage sometimes called the withdrawal stage. The excitement you felt before changes to frustration as you find it difficult to cope with the problems that arise. It seems that everything is difficult, the language is hard to learn, people are unusual and unpredictable, friends are hard to make, and simple things like shopping and going to the bank are challenges. It is at this stage that you are likely to feel anxious and homesick, and you will probably find yourself complaining about the new culture or country. This is the stage which is referred to as culture shock. Culture shock is only temporary, and at some point, if you are one of those who manage to stick it out, youll transition into the third stage of cultural adjustment, the recovery stage. At this point, youll have a routine, and youll feel more confident functioning in the new culture. Youll start to feel less isolated as you start to understand and accept the way things are done and the way people behave in your new environment. Customs and traditions are clearer and easier to understand. At this stage, youll deal with new challenges with humour rather than anxiety. The last stage is the home or stability stage this is the point when people start to feel at home in the new culture. At this stage, youll function well in the new culture, adopt certain features and behaviours from your new home, and prefer certain aspects of the new culture to your own culture. There is, in a sense, a fifth stage to this process. If you decide to return home after a long period in a new culture, you may experience what is called reverse culture shock. This means that you may find aspects of your own culture foreign because you are so used to the new culture that you have spent so long adjusting to. Reverse culture shock is usually pretty mild you may notice things about your home culture that you had never noticed before, and some of the ways people do things may seem odd. Reverse culture shock rarely lasts for very long.", "hypothesis": "People can ease culture shock by learning about the language and customs before they go to the new culture.", "gold_label": "entailment"}
{"uid": "id_526", "premise": "What you need to know about Culture Shock Most people who move to a foreign country or culture may experience a period of time when they feel very homesick and have a lot of stress and difficulty functioning in the new culture. This feeling is often called culture shock and it is important to understand and learn how to cope with culture shock if you are to adapt successfully to your new homes culture. First of all, its important to know that culture shock is normal. Everyone in a new situation will go through some form of culture shock, and the extent of which they do is determined by factors such as the difference between cultures, the degree to which someone is anxious to adapt to a new culture and the familiarity that person has to the new culture. If you go, for example, to a culture that is far different from your own, youre likely to experience culture shock more sharply than those who move to a new culture knowing the language and the behavioural norms of the new culture. There are four general stages of cultural adjustment, and it is important that you are aware of these stages and can recognise which stage you are in and when so that you will understand why you feel the way you do and that any difficulties you are experience are temporary, a process you are going through rather than a constant situation. The first stage is usually referred to as the excitement stage or the honeymoon stage. Upon arriving in a new environment, youll be interested in the new culture, everything will seem exciting, everyone will seem friendly and helpful and youll be overwhelmed with impressions. During this stage you are merely soaking up the new landscape, taking in these impressions passively, and at this stage you have little meaningful experience of the culture. But it isnt long before the honeymoon stage dissolves into the second stage sometimes called the withdrawal stage. The excitement you felt before changes to frustration as you find it difficult to cope with the problems that arise. It seems that everything is difficult, the language is hard to learn, people are unusual and unpredictable, friends are hard to make, and simple things like shopping and going to the bank are challenges. It is at this stage that you are likely to feel anxious and homesick, and you will probably find yourself complaining about the new culture or country. This is the stage which is referred to as culture shock. Culture shock is only temporary, and at some point, if you are one of those who manage to stick it out, youll transition into the third stage of cultural adjustment, the recovery stage. At this point, youll have a routine, and youll feel more confident functioning in the new culture. Youll start to feel less isolated as you start to understand and accept the way things are done and the way people behave in your new environment. Customs and traditions are clearer and easier to understand. At this stage, youll deal with new challenges with humour rather than anxiety. The last stage is the home or stability stage this is the point when people start to feel at home in the new culture. At this stage, youll function well in the new culture, adopt certain features and behaviours from your new home, and prefer certain aspects of the new culture to your own culture. There is, in a sense, a fifth stage to this process. If you decide to return home after a long period in a new culture, you may experience what is called reverse culture shock. This means that you may find aspects of your own culture foreign because you are so used to the new culture that you have spent so long adjusting to. Reverse culture shock is usually pretty mild you may notice things about your home culture that you had never noticed before, and some of the ways people do things may seem odd. Reverse culture shock rarely lasts for very long.", "hypothesis": "In the first stage, people will have a very positive impression of the new culture.", "gold_label": "entailment"}
{"uid": "id_527", "premise": "What you need to know about Culture Shock Most people who move to a foreign country or culture may experience a period of time when they feel very homesick and have a lot of stress and difficulty functioning in the new culture. This feeling is often called culture shock and it is important to understand and learn how to cope with culture shock if you are to adapt successfully to your new homes culture. First of all, its important to know that culture shock is normal. Everyone in a new situation will go through some form of culture shock, and the extent of which they do is determined by factors such as the difference between cultures, the degree to which someone is anxious to adapt to a new culture and the familiarity that person has to the new culture. If you go, for example, to a culture that is far different from your own, youre likely to experience culture shock more sharply than those who move to a new culture knowing the language and the behavioural norms of the new culture. There are four general stages of cultural adjustment, and it is important that you are aware of these stages and can recognise which stage you are in and when so that you will understand why you feel the way you do and that any difficulties you are experience are temporary, a process you are going through rather than a constant situation. The first stage is usually referred to as the excitement stage or the honeymoon stage. Upon arriving in a new environment, youll be interested in the new culture, everything will seem exciting, everyone will seem friendly and helpful and youll be overwhelmed with impressions. During this stage you are merely soaking up the new landscape, taking in these impressions passively, and at this stage you have little meaningful experience of the culture. But it isnt long before the honeymoon stage dissolves into the second stage sometimes called the withdrawal stage. The excitement you felt before changes to frustration as you find it difficult to cope with the problems that arise. It seems that everything is difficult, the language is hard to learn, people are unusual and unpredictable, friends are hard to make, and simple things like shopping and going to the bank are challenges. It is at this stage that you are likely to feel anxious and homesick, and you will probably find yourself complaining about the new culture or country. This is the stage which is referred to as culture shock. Culture shock is only temporary, and at some point, if you are one of those who manage to stick it out, youll transition into the third stage of cultural adjustment, the recovery stage. At this point, youll have a routine, and youll feel more confident functioning in the new culture. Youll start to feel less isolated as you start to understand and accept the way things are done and the way people behave in your new environment. Customs and traditions are clearer and easier to understand. At this stage, youll deal with new challenges with humour rather than anxiety. The last stage is the home or stability stage this is the point when people start to feel at home in the new culture. At this stage, youll function well in the new culture, adopt certain features and behaviours from your new home, and prefer certain aspects of the new culture to your own culture. There is, in a sense, a fifth stage to this process. If you decide to return home after a long period in a new culture, you may experience what is called reverse culture shock. This means that you may find aspects of your own culture foreign because you are so used to the new culture that you have spent so long adjusting to. Reverse culture shock is usually pretty mild you may notice things about your home culture that you had never noticed before, and some of the ways people do things may seem odd. Reverse culture shock rarely lasts for very long.", "hypothesis": "Many people will leave the new culture while they are in the second stage.", "gold_label": "neutral"}
{"uid": "id_528", "premise": "What you need to know about Culture Shock Most people who move to a foreign country or culture may experience a period of time when they feel very homesick and have a lot of stress and difficulty functioning in the new culture. This feeling is often called culture shock and it is important to understand and learn how to cope with culture shock if you are to adapt successfully to your new homes culture. First of all, its important to know that culture shock is normal. Everyone in a new situation will go through some form of culture shock, and the extent of which they do is determined by factors such as the difference between cultures, the degree to which someone is anxious to adapt to a new culture and the familiarity that person has to the new culture. If you go, for example, to a culture that is far different from your own, youre likely to experience culture shock more sharply than those who move to a new culture knowing the language and the behavioural norms of the new culture. There are four general stages of cultural adjustment, and it is important that you are aware of these stages and can recognise which stage you are in and when so that you will understand why you feel the way you do and that any difficulties you are experience are temporary, a process you are going through rather than a constant situation. The first stage is usually referred to as the excitement stage or the honeymoon stage. Upon arriving in a new environment, youll be interested in the new culture, everything will seem exciting, everyone will seem friendly and helpful and youll be overwhelmed with impressions. During this stage you are merely soaking up the new landscape, taking in these impressions passively, and at this stage you have little meaningful experience of the culture. But it isnt long before the honeymoon stage dissolves into the second stage sometimes called the withdrawal stage. The excitement you felt before changes to frustration as you find it difficult to cope with the problems that arise. It seems that everything is difficult, the language is hard to learn, people are unusual and unpredictable, friends are hard to make, and simple things like shopping and going to the bank are challenges. It is at this stage that you are likely to feel anxious and homesick, and you will probably find yourself complaining about the new culture or country. This is the stage which is referred to as culture shock. Culture shock is only temporary, and at some point, if you are one of those who manage to stick it out, youll transition into the third stage of cultural adjustment, the recovery stage. At this point, youll have a routine, and youll feel more confident functioning in the new culture. Youll start to feel less isolated as you start to understand and accept the way things are done and the way people behave in your new environment. Customs and traditions are clearer and easier to understand. At this stage, youll deal with new challenges with humour rather than anxiety. The last stage is the home or stability stage this is the point when people start to feel at home in the new culture. At this stage, youll function well in the new culture, adopt certain features and behaviours from your new home, and prefer certain aspects of the new culture to your own culture. There is, in a sense, a fifth stage to this process. If you decide to return home after a long period in a new culture, you may experience what is called reverse culture shock. This means that you may find aspects of your own culture foreign because you are so used to the new culture that you have spent so long adjusting to. Reverse culture shock is usually pretty mild you may notice things about your home culture that you had never noticed before, and some of the ways people do things may seem odd. Reverse culture shock rarely lasts for very long.", "hypothesis": "Reverse culture shock is as difficult to deal with as culture shock.", "gold_label": "contradiction"}
{"uid": "id_529", "premise": "What you need to know about Culture Shock Most people who move to a foreign country or culture may experience a period of time when they feel very homesick and have a lot of stress and difficulty functioning in the new culture. This feeling is often called culture shock and it is important to understand and learn how to cope with culture shock if you are to adapt successfully to your new homes culture. First of all, its important to know that culture shock is normal. Everyone in a new situation will go through some form of culture shock, and the extent of which they do is determined by factors such as the difference between cultures, the degree to which someone is anxious to adapt to a new culture and the familiarity that person has to the new culture. If you go, for example, to a culture that is far different from your own, youre likely to experience culture shock more sharply than those who move to a new culture knowing the language and the behavioural norms of the new culture. There are four general stages of cultural adjustment, and it is important that you are aware of these stages and can recognise which stage you are in and when so that you will understand why you feel the way you do and that any difficulties you are experience are temporary, a process you are going through rather than a constant situation. The first stage is usually referred to as the excitement stage or the honeymoon stage. Upon arriving in a new environment, youll be interested in the new culture, everything will seem exciting, everyone will seem friendly and helpful and youll be overwhelmed with impressions. During this stage you are merely soaking up the new landscape, taking in these impressions passively, and at this stage you have little meaningful experience of the culture. But it isnt long before the honeymoon stage dissolves into the second stage sometimes called the withdrawal stage. The excitement you felt before changes to frustration as you find it difficult to cope with the problems that arise. It seems that everything is difficult, the language is hard to learn, people are unusual and unpredictable, friends are hard to make, and simple things like shopping and going to the bank are challenges. It is at this stage that you are likely to feel anxious and homesick, and you will probably find yourself complaining about the new culture or country. This is the stage which is referred to as culture shock. Culture shock is only temporary, and at some point, if you are one of those who manage to stick it out, youll transition into the third stage of cultural adjustment, the recovery stage. At this point, youll have a routine, and youll feel more confident functioning in the new culture. Youll start to feel less isolated as you start to understand and accept the way things are done and the way people behave in your new environment. Customs and traditions are clearer and easier to understand. At this stage, youll deal with new challenges with humour rather than anxiety. The last stage is the home or stability stage this is the point when people start to feel at home in the new culture. At this stage, youll function well in the new culture, adopt certain features and behaviours from your new home, and prefer certain aspects of the new culture to your own culture. There is, in a sense, a fifth stage to this process. If you decide to return home after a long period in a new culture, you may experience what is called reverse culture shock. This means that you may find aspects of your own culture foreign because you are so used to the new culture that you have spent so long adjusting to. Reverse culture shock is usually pretty mild you may notice things about your home culture that you had never noticed before, and some of the ways people do things may seem odd. Reverse culture shock rarely lasts for very long.", "hypothesis": "Knowing about these four stages will help people adjust to a new culture more quickly.", "gold_label": "neutral"}
{"uid": "id_530", "premise": "What you need to know about Culture Shock Most people who move to a foreign country or culture may experience a period of time when they feel very homesick and have a lot of stress and difficulty functioning in the new culture. This feeling is often called culture shock and it is important to understand and learn how to cope with culture shock if you are to adapt successfully to your new homes culture. First of all, its important to know that culture shock is normal. Everyone in a new situation will go through some form of culture shock, and the extent of which they do is determined by factors such as the difference between cultures, the degree to which someone is anxious to adapt to a new culture and the familiarity that person has to the new culture. If you go, for example, to a culture that is far different from your own, youre likely to experience culture shock more sharply than those who move to a new culture knowing the language and the behavioural norms of the new culture. There are four general stages of cultural adjustment, and it is important that you are aware of these stages and can recognise which stage you are in and when so that you will understand why you feel the way you do and that any difficulties you are experience are temporary, a process you are going through rather than a constant situation. The first stage is usually referred to as the excitement stage or the honeymoon stage. Upon arriving in a new environment, youll be interested in the new culture, everything will seem exciting, everyone will seem friendly and helpful and youll be overwhelmed with impressions. During this stage you are merely soaking up the new landscape, taking in these impressions passively, and at this stage you have little meaningful experience of the culture. But it isnt long before the honeymoon stage dissolves into the second stage sometimes called the withdrawal stage. The excitement you felt before changes to frustration as you find it difficult to cope with the problems that arise. It seems that everything is difficult, the language is hard to learn, people are unusual and unpredictable, friends are hard to make, and simple things like shopping and going to the bank are challenges. It is at this stage that you are likely to feel anxious and homesick, and you will probably find yourself complaining about the new culture or country. This is the stage which is referred to as culture shock. Culture shock is only temporary, and at some point, if you are one of those who manage to stick it out, youll transition into the third stage of cultural adjustment, the recovery stage. At this point, youll have a routine, and youll feel more confident functioning in the new culture. Youll start to feel less isolated as you start to understand and accept the way things are done and the way people behave in your new environment. Customs and traditions are clearer and easier to understand. At this stage, youll deal with new challenges with humour rather than anxiety. The last stage is the home or stability stage this is the point when people start to feel at home in the new culture. At this stage, youll function well in the new culture, adopt certain features and behaviours from your new home, and prefer certain aspects of the new culture to your own culture. There is, in a sense, a fifth stage to this process. If you decide to return home after a long period in a new culture, you may experience what is called reverse culture shock. This means that you may find aspects of your own culture foreign because you are so used to the new culture that you have spent so long adjusting to. Reverse culture shock is usually pretty mild you may notice things about your home culture that you had never noticed before, and some of the ways people do things may seem odd. Reverse culture shock rarely lasts for very long.", "hypothesis": "Culture shock is another name for cultural adjustment.", "gold_label": "contradiction"}
{"uid": "id_531", "premise": "What you need to know about Culture Shock Most people who move to a foreign country or culture may experience a period of time when they feel very homesick and have a lot of stress and difficulty functioning in the new culture. This feeling is often called culture shock and it is important to understand and learn how to cope with culture shock if you are to adapt successfully to your new homes culture. First of all, its important to know that culture shock is normal. Everyone in a new situation will go through some form of culture shock, and the extent of which they do is determined by factors such as the difference between cultures, the degree to which someone is anxious to adapt to a new culture and the familiarity that person has to the new culture. If you go, for example, to a culture that is far different from your own, youre likely to experience culture shock more sharply than those who move to a new culture knowing the language and the behavioural norms of the new culture. There are four general stages of cultural adjustment, and it is important that you are aware of these stages and can recognise which stage you are in and when so that you will understand why you feel the way you do and that any difficulties you are experience are temporary, a process you are going through rather than a constant situation. The first stage is usually referred to as the excitement stage or the honeymoon stage. Upon arriving in a new environment, youll be interested in the new culture, everything will seem exciting, everyone will seem friendly and helpful and youll be overwhelmed with impressions. During this stage you are merely soaking up the new landscape, taking in these impressions passively, and at this stage you have little meaningful experience of the culture. But it isnt long before the honeymoon stage dissolves into the second stage sometimes called the withdrawal stage. The excitement you felt before changes to frustration as you find it difficult to cope with the problems that arise. It seems that everything is difficult, the language is hard to learn, people are unusual and unpredictable, friends are hard to make, and simple things like shopping and going to the bank are challenges. It is at this stage that you are likely to feel anxious and homesick, and you will probably find yourself complaining about the new culture or country. This is the stage which is referred to as culture shock. Culture shock is only temporary, and at some point, if you are one of those who manage to stick it out, youll transition into the third stage of cultural adjustment, the recovery stage. At this point, youll have a routine, and youll feel more confident functioning in the new culture. Youll start to feel less isolated as you start to understand and accept the way things are done and the way people behave in your new environment. Customs and traditions are clearer and easier to understand. At this stage, youll deal with new challenges with humour rather than anxiety. The last stage is the home or stability stage this is the point when people start to feel at home in the new culture. At this stage, youll function well in the new culture, adopt certain features and behaviours from your new home, and prefer certain aspects of the new culture to your own culture. There is, in a sense, a fifth stage to this process. If you decide to return home after a long period in a new culture, you may experience what is called reverse culture shock. This means that you may find aspects of your own culture foreign because you are so used to the new culture that you have spent so long adjusting to. Reverse culture shock is usually pretty mild you may notice things about your home culture that you had never noticed before, and some of the ways people do things may seem odd. Reverse culture shock rarely lasts for very long.", "hypothesis": "The first stage is usually the shortest.", "gold_label": "neutral"}
{"uid": "id_532", "premise": "What's so funny? John McCrone reviews recent research on humor The joke comes over the headphones: 'Which side of a dog has the most hair? The left. ' No, not funny. Try again. 'Which side of a dog has the most hair? The outside. ' Hah! The punchline is silly yet fitting, tempting a smile, even a laugh. Laughter has always struck people as deeply mysterious, perhaps pointless. The writer Arthur Koestler dubbed it the luxury reflex: 'unique in that it serves no apparent biological purpose. ' Theories about humour have an ancient pedigree. Plato expressed the idea that humor is simply a delighted feeling of superiority over others. Kant and Freud felt that joke-telling relies on building up a psychic tension which is safely punctured by the ludicrousness of the punchline. But most modern humor theorists have settled on some version of Aristotle's belief that jokes are based on a reaction to or resolution of incongruity, when the punchline is either a nonsense or, though appearing silly, has a clever second meaning. Graeme Ritchie, a computational linguist in Edinburgh, studies the linguistic structure of jokes in order to understand not only humor but language understanding and reasoning in machines. He says that while there is no single format for jokes, many revolve around a sudden and surprising conceptual shift. A comedian will present a situation followed by an unexpected interpretation that is also apt. So even if a punchline sounds silly, the listener can see there is a clever semantic fit and that sudden mental 'Aha! ' is the buzz that makes us laugh. Viewed from this angle, humor is just a form of creative insight, a sudden leap to a new perspective. However, there is another type of laughter, the laughter of social appeasement and it is important to understand this too. Play is a crucial part of development in most young mammals. Rats produce ultrasonic squeaks to prevent their scuffles turning nasty. Chimpanzees have a 'play-face' a gaping expression accompanied by a panting 'ah ah' noise. In humans, these signals have mutated into smiles and laughs. Researchers believe social situations, rather than cognitive events such as jokes, trigger these instinctual markers of play or appeasement. People laugh on fairground rides or when tickled to flag a play situation, whether they feel amused or not. Both social and cognitive types of laughter tap into the same expressive machinery in our brains, the emotion and motor circuits that produce smiles and excited vocalisations. However, if cognitive laughter is the product of more general thought processes, it should result from more expansive brain activity. Psychologist Vinod Goel investigated humour using the new technique of 'single event' functional magnetic resonance imaging (fMRI). An MRI scanner uses magnetic fields and radio waves to track the changes in oxygenated blood that accompany mental activity. Until recently, MRI scanners needed several minutes of activity and so could not be used to track rapid thought processes such as comprehending a joke. New developments now allow half-second 'snapshots' of all sorts of reasoning and problem-solving activities. Although Goel felt being inside a brain scanner was hardly the ideal place for appreciating a joke, he found evidence that understanding a joke involves a widespread mental shift. His scans showed that at the beginning of a joke the listener's prefrontal cortex lit up, particularly the right prefrontal believed to be critical for problem solving. But there was also activity in the temporal lobes at the side of the head (consistent with attempts to rouse stored knowledge) and in many other brain areas. Then when the punchline arrived, a new area sprang to life the orbital prefrontal cortex. This patch of brain tucked behind the orbits of the eyes is associated with evaluating information. Making a rapid emotional assessment of the events of the moment is an extremely demanding job for the brain, animal or human. Energy and arousal levels may need to be retuned in the blink of an eye. These abrupt changes will produce either positive or negative feelings. The orbital cortex, the region that becomes active in Goel's experiment, seems the best candidate for the site that feeds such feelings into higher-level thought processes, with its close connections to the brain's sub-cortical arousal apparatus and centres of metabolic control. All warm-blooded animals make constant tiny adjustments in arousal in response to external events, but humans, who have developed a much more complicated internal life as a result of language, respond emotionally not only to their surroundings, but to their own thoughts. Whenever a sought-for answer snaps into place, there is a shudder of pleased recognition. Creative discovery being pleasurable, humans have learned to find ways of milking this natural response. The fact that jokes tap into our general evaluative machinery explains why the line between funny and disgusting, or funny and frightening, can be so fine. Whether a joke gives pleasure or pain depends on a person's outlook. Humor may be a luxury, but the mechanism behind it is no evolutionary accident. As Peter Derks, a psychologist at William and Mary College in Virginia, says: 'I like to think of humour as the distorted mirror of the mind. It's creative, perceptual, analytical and lingual. If we can figure out how the mind processes humor, then we'll have a pretty good handle on how it works in general. '", "hypothesis": "Current thinking on humour has largely ignored Aristotle's view on the subject.", "gold_label": "contradiction"}
{"uid": "id_533", "premise": "What's so funny? John McCrone reviews recent research on humor The joke comes over the headphones: 'Which side of a dog has the most hair? The left. ' No, not funny. Try again. 'Which side of a dog has the most hair? The outside. ' Hah! The punchline is silly yet fitting, tempting a smile, even a laugh. Laughter has always struck people as deeply mysterious, perhaps pointless. The writer Arthur Koestler dubbed it the luxury reflex: 'unique in that it serves no apparent biological purpose. ' Theories about humour have an ancient pedigree. Plato expressed the idea that humor is simply a delighted feeling of superiority over others. Kant and Freud felt that joke-telling relies on building up a psychic tension which is safely punctured by the ludicrousness of the punchline. But most modern humor theorists have settled on some version of Aristotle's belief that jokes are based on a reaction to or resolution of incongruity, when the punchline is either a nonsense or, though appearing silly, has a clever second meaning. Graeme Ritchie, a computational linguist in Edinburgh, studies the linguistic structure of jokes in order to understand not only humor but language understanding and reasoning in machines. He says that while there is no single format for jokes, many revolve around a sudden and surprising conceptual shift. A comedian will present a situation followed by an unexpected interpretation that is also apt. So even if a punchline sounds silly, the listener can see there is a clever semantic fit and that sudden mental 'Aha! ' is the buzz that makes us laugh. Viewed from this angle, humor is just a form of creative insight, a sudden leap to a new perspective. However, there is another type of laughter, the laughter of social appeasement and it is important to understand this too. Play is a crucial part of development in most young mammals. Rats produce ultrasonic squeaks to prevent their scuffles turning nasty. Chimpanzees have a 'play-face' a gaping expression accompanied by a panting 'ah ah' noise. In humans, these signals have mutated into smiles and laughs. Researchers believe social situations, rather than cognitive events such as jokes, trigger these instinctual markers of play or appeasement. People laugh on fairground rides or when tickled to flag a play situation, whether they feel amused or not. Both social and cognitive types of laughter tap into the same expressive machinery in our brains, the emotion and motor circuits that produce smiles and excited vocalisations. However, if cognitive laughter is the product of more general thought processes, it should result from more expansive brain activity. Psychologist Vinod Goel investigated humour using the new technique of 'single event' functional magnetic resonance imaging (fMRI). An MRI scanner uses magnetic fields and radio waves to track the changes in oxygenated blood that accompany mental activity. Until recently, MRI scanners needed several minutes of activity and so could not be used to track rapid thought processes such as comprehending a joke. New developments now allow half-second 'snapshots' of all sorts of reasoning and problem-solving activities. Although Goel felt being inside a brain scanner was hardly the ideal place for appreciating a joke, he found evidence that understanding a joke involves a widespread mental shift. His scans showed that at the beginning of a joke the listener's prefrontal cortex lit up, particularly the right prefrontal believed to be critical for problem solving. But there was also activity in the temporal lobes at the side of the head (consistent with attempts to rouse stored knowledge) and in many other brain areas. Then when the punchline arrived, a new area sprang to life the orbital prefrontal cortex. This patch of brain tucked behind the orbits of the eyes is associated with evaluating information. Making a rapid emotional assessment of the events of the moment is an extremely demanding job for the brain, animal or human. Energy and arousal levels may need to be retuned in the blink of an eye. These abrupt changes will produce either positive or negative feelings. The orbital cortex, the region that becomes active in Goel's experiment, seems the best candidate for the site that feeds such feelings into higher-level thought processes, with its close connections to the brain's sub-cortical arousal apparatus and centres of metabolic control. All warm-blooded animals make constant tiny adjustments in arousal in response to external events, but humans, who have developed a much more complicated internal life as a result of language, respond emotionally not only to their surroundings, but to their own thoughts. Whenever a sought-for answer snaps into place, there is a shudder of pleased recognition. Creative discovery being pleasurable, humans have learned to find ways of milking this natural response. The fact that jokes tap into our general evaluative machinery explains why the line between funny and disgusting, or funny and frightening, can be so fine. Whether a joke gives pleasure or pain depends on a person's outlook. Humor may be a luxury, but the mechanism behind it is no evolutionary accident. As Peter Derks, a psychologist at William and Mary College in Virginia, says: 'I like to think of humour as the distorted mirror of the mind. It's creative, perceptual, analytical and lingual. If we can figure out how the mind processes humor, then we'll have a pretty good handle on how it works in general. '", "hypothesis": "Graeme Ritchie's work links jokes to artificial intelligence.", "gold_label": "entailment"}
{"uid": "id_534", "premise": "What's so funny? John McCrone reviews recent research on humor The joke comes over the headphones: 'Which side of a dog has the most hair? The left. ' No, not funny. Try again. 'Which side of a dog has the most hair? The outside. ' Hah! The punchline is silly yet fitting, tempting a smile, even a laugh. Laughter has always struck people as deeply mysterious, perhaps pointless. The writer Arthur Koestler dubbed it the luxury reflex: 'unique in that it serves no apparent biological purpose. ' Theories about humour have an ancient pedigree. Plato expressed the idea that humor is simply a delighted feeling of superiority over others. Kant and Freud felt that joke-telling relies on building up a psychic tension which is safely punctured by the ludicrousness of the punchline. But most modern humor theorists have settled on some version of Aristotle's belief that jokes are based on a reaction to or resolution of incongruity, when the punchline is either a nonsense or, though appearing silly, has a clever second meaning. Graeme Ritchie, a computational linguist in Edinburgh, studies the linguistic structure of jokes in order to understand not only humor but language understanding and reasoning in machines. He says that while there is no single format for jokes, many revolve around a sudden and surprising conceptual shift. A comedian will present a situation followed by an unexpected interpretation that is also apt. So even if a punchline sounds silly, the listener can see there is a clever semantic fit and that sudden mental 'Aha! ' is the buzz that makes us laugh. Viewed from this angle, humor is just a form of creative insight, a sudden leap to a new perspective. However, there is another type of laughter, the laughter of social appeasement and it is important to understand this too. Play is a crucial part of development in most young mammals. Rats produce ultrasonic squeaks to prevent their scuffles turning nasty. Chimpanzees have a 'play-face' a gaping expression accompanied by a panting 'ah ah' noise. In humans, these signals have mutated into smiles and laughs. Researchers believe social situations, rather than cognitive events such as jokes, trigger these instinctual markers of play or appeasement. People laugh on fairground rides or when tickled to flag a play situation, whether they feel amused or not. Both social and cognitive types of laughter tap into the same expressive machinery in our brains, the emotion and motor circuits that produce smiles and excited vocalisations. However, if cognitive laughter is the product of more general thought processes, it should result from more expansive brain activity. Psychologist Vinod Goel investigated humour using the new technique of 'single event' functional magnetic resonance imaging (fMRI). An MRI scanner uses magnetic fields and radio waves to track the changes in oxygenated blood that accompany mental activity. Until recently, MRI scanners needed several minutes of activity and so could not be used to track rapid thought processes such as comprehending a joke. New developments now allow half-second 'snapshots' of all sorts of reasoning and problem-solving activities. Although Goel felt being inside a brain scanner was hardly the ideal place for appreciating a joke, he found evidence that understanding a joke involves a widespread mental shift. His scans showed that at the beginning of a joke the listener's prefrontal cortex lit up, particularly the right prefrontal believed to be critical for problem solving. But there was also activity in the temporal lobes at the side of the head (consistent with attempts to rouse stored knowledge) and in many other brain areas. Then when the punchline arrived, a new area sprang to life the orbital prefrontal cortex. This patch of brain tucked behind the orbits of the eyes is associated with evaluating information. Making a rapid emotional assessment of the events of the moment is an extremely demanding job for the brain, animal or human. Energy and arousal levels may need to be retuned in the blink of an eye. These abrupt changes will produce either positive or negative feelings. The orbital cortex, the region that becomes active in Goel's experiment, seems the best candidate for the site that feeds such feelings into higher-level thought processes, with its close connections to the brain's sub-cortical arousal apparatus and centres of metabolic control. All warm-blooded animals make constant tiny adjustments in arousal in response to external events, but humans, who have developed a much more complicated internal life as a result of language, respond emotionally not only to their surroundings, but to their own thoughts. Whenever a sought-for answer snaps into place, there is a shudder of pleased recognition. Creative discovery being pleasurable, humans have learned to find ways of milking this natural response. The fact that jokes tap into our general evaluative machinery explains why the line between funny and disgusting, or funny and frightening, can be so fine. Whether a joke gives pleasure or pain depends on a person's outlook. Humor may be a luxury, but the mechanism behind it is no evolutionary accident. As Peter Derks, a psychologist at William and Mary College in Virginia, says: 'I like to think of humour as the distorted mirror of the mind. It's creative, perceptual, analytical and lingual. If we can figure out how the mind processes humor, then we'll have a pretty good handle on how it works in general. '", "hypothesis": "Plato believed humour to be a sign of above-average intelligence.", "gold_label": "neutral"}
{"uid": "id_535", "premise": "What's so funny? John McCrone reviews recent research on humor The joke comes over the headphones: 'Which side of a dog has the most hair? The left. ' No, not funny. Try again. 'Which side of a dog has the most hair? The outside. ' Hah! The punchline is silly yet fitting, tempting a smile, even a laugh. Laughter has always struck people as deeply mysterious, perhaps pointless. The writer Arthur Koestler dubbed it the luxury reflex: 'unique in that it serves no apparent biological purpose. ' Theories about humour have an ancient pedigree. Plato expressed the idea that humor is simply a delighted feeling of superiority over others. Kant and Freud felt that joke-telling relies on building up a psychic tension which is safely punctured by the ludicrousness of the punchline. But most modern humor theorists have settled on some version of Aristotle's belief that jokes are based on a reaction to or resolution of incongruity, when the punchline is either a nonsense or, though appearing silly, has a clever second meaning. Graeme Ritchie, a computational linguist in Edinburgh, studies the linguistic structure of jokes in order to understand not only humor but language understanding and reasoning in machines. He says that while there is no single format for jokes, many revolve around a sudden and surprising conceptual shift. A comedian will present a situation followed by an unexpected interpretation that is also apt. So even if a punchline sounds silly, the listener can see there is a clever semantic fit and that sudden mental 'Aha! ' is the buzz that makes us laugh. Viewed from this angle, humor is just a form of creative insight, a sudden leap to a new perspective. However, there is another type of laughter, the laughter of social appeasement and it is important to understand this too. Play is a crucial part of development in most young mammals. Rats produce ultrasonic squeaks to prevent their scuffles turning nasty. Chimpanzees have a 'play-face' a gaping expression accompanied by a panting 'ah ah' noise. In humans, these signals have mutated into smiles and laughs. Researchers believe social situations, rather than cognitive events such as jokes, trigger these instinctual markers of play or appeasement. People laugh on fairground rides or when tickled to flag a play situation, whether they feel amused or not. Both social and cognitive types of laughter tap into the same expressive machinery in our brains, the emotion and motor circuits that produce smiles and excited vocalisations. However, if cognitive laughter is the product of more general thought processes, it should result from more expansive brain activity. Psychologist Vinod Goel investigated humour using the new technique of 'single event' functional magnetic resonance imaging (fMRI). An MRI scanner uses magnetic fields and radio waves to track the changes in oxygenated blood that accompany mental activity. Until recently, MRI scanners needed several minutes of activity and so could not be used to track rapid thought processes such as comprehending a joke. New developments now allow half-second 'snapshots' of all sorts of reasoning and problem-solving activities. Although Goel felt being inside a brain scanner was hardly the ideal place for appreciating a joke, he found evidence that understanding a joke involves a widespread mental shift. His scans showed that at the beginning of a joke the listener's prefrontal cortex lit up, particularly the right prefrontal believed to be critical for problem solving. But there was also activity in the temporal lobes at the side of the head (consistent with attempts to rouse stored knowledge) and in many other brain areas. Then when the punchline arrived, a new area sprang to life the orbital prefrontal cortex. This patch of brain tucked behind the orbits of the eyes is associated with evaluating information. Making a rapid emotional assessment of the events of the moment is an extremely demanding job for the brain, animal or human. Energy and arousal levels may need to be retuned in the blink of an eye. These abrupt changes will produce either positive or negative feelings. The orbital cortex, the region that becomes active in Goel's experiment, seems the best candidate for the site that feeds such feelings into higher-level thought processes, with its close connections to the brain's sub-cortical arousal apparatus and centres of metabolic control. All warm-blooded animals make constant tiny adjustments in arousal in response to external events, but humans, who have developed a much more complicated internal life as a result of language, respond emotionally not only to their surroundings, but to their own thoughts. Whenever a sought-for answer snaps into place, there is a shudder of pleased recognition. Creative discovery being pleasurable, humans have learned to find ways of milking this natural response. The fact that jokes tap into our general evaluative machinery explains why the line between funny and disgusting, or funny and frightening, can be so fine. Whether a joke gives pleasure or pain depends on a person's outlook. Humor may be a luxury, but the mechanism behind it is no evolutionary accident. As Peter Derks, a psychologist at William and Mary College in Virginia, says: 'I like to think of humour as the distorted mirror of the mind. It's creative, perceptual, analytical and lingual. If we can figure out how the mind processes humor, then we'll have a pretty good handle on how it works in general. '", "hypothesis": "Kant believed that a successful joke involves the controlled release of nervous energy.", "gold_label": "entailment"}
{"uid": "id_536", "premise": "What's so funny? John McCrone reviews recent research on humor The joke comes over the headphones: 'Which side of a dog has the most hair? The left. ' No, not funny. Try again. 'Which side of a dog has the most hair? The outside. ' Hah! The punchline is silly yet fitting, tempting a smile, even a laugh. Laughter has always struck people as deeply mysterious, perhaps pointless. The writer Arthur Koestler dubbed it the luxury reflex: 'unique in that it serves no apparent biological purpose. ' Theories about humour have an ancient pedigree. Plato expressed the idea that humor is simply a delighted feeling of superiority over others. Kant and Freud felt that joke-telling relies on building up a psychic tension which is safely punctured by the ludicrousness of the punchline. But most modern humor theorists have settled on some version of Aristotle's belief that jokes are based on a reaction to or resolution of incongruity, when the punchline is either a nonsense or, though appearing silly, has a clever second meaning. Graeme Ritchie, a computational linguist in Edinburgh, studies the linguistic structure of jokes in order to understand not only humor but language understanding and reasoning in machines. He says that while there is no single format for jokes, many revolve around a sudden and surprising conceptual shift. A comedian will present a situation followed by an unexpected interpretation that is also apt. So even if a punchline sounds silly, the listener can see there is a clever semantic fit and that sudden mental 'Aha! ' is the buzz that makes us laugh. Viewed from this angle, humor is just a form of creative insight, a sudden leap to a new perspective. However, there is another type of laughter, the laughter of social appeasement and it is important to understand this too. Play is a crucial part of development in most young mammals. Rats produce ultrasonic squeaks to prevent their scuffles turning nasty. Chimpanzees have a 'play-face' a gaping expression accompanied by a panting 'ah ah' noise. In humans, these signals have mutated into smiles and laughs. Researchers believe social situations, rather than cognitive events such as jokes, trigger these instinctual markers of play or appeasement. People laugh on fairground rides or when tickled to flag a play situation, whether they feel amused or not. Both social and cognitive types of laughter tap into the same expressive machinery in our brains, the emotion and motor circuits that produce smiles and excited vocalisations. However, if cognitive laughter is the product of more general thought processes, it should result from more expansive brain activity. Psychologist Vinod Goel investigated humour using the new technique of 'single event' functional magnetic resonance imaging (fMRI). An MRI scanner uses magnetic fields and radio waves to track the changes in oxygenated blood that accompany mental activity. Until recently, MRI scanners needed several minutes of activity and so could not be used to track rapid thought processes such as comprehending a joke. New developments now allow half-second 'snapshots' of all sorts of reasoning and problem-solving activities. Although Goel felt being inside a brain scanner was hardly the ideal place for appreciating a joke, he found evidence that understanding a joke involves a widespread mental shift. His scans showed that at the beginning of a joke the listener's prefrontal cortex lit up, particularly the right prefrontal believed to be critical for problem solving. But there was also activity in the temporal lobes at the side of the head (consistent with attempts to rouse stored knowledge) and in many other brain areas. Then when the punchline arrived, a new area sprang to life the orbital prefrontal cortex. This patch of brain tucked behind the orbits of the eyes is associated with evaluating information. Making a rapid emotional assessment of the events of the moment is an extremely demanding job for the brain, animal or human. Energy and arousal levels may need to be retuned in the blink of an eye. These abrupt changes will produce either positive or negative feelings. The orbital cortex, the region that becomes active in Goel's experiment, seems the best candidate for the site that feeds such feelings into higher-level thought processes, with its close connections to the brain's sub-cortical arousal apparatus and centres of metabolic control. All warm-blooded animals make constant tiny adjustments in arousal in response to external events, but humans, who have developed a much more complicated internal life as a result of language, respond emotionally not only to their surroundings, but to their own thoughts. Whenever a sought-for answer snaps into place, there is a shudder of pleased recognition. Creative discovery being pleasurable, humans have learned to find ways of milking this natural response. The fact that jokes tap into our general evaluative machinery explains why the line between funny and disgusting, or funny and frightening, can be so fine. Whether a joke gives pleasure or pain depends on a person's outlook. Humor may be a luxury, but the mechanism behind it is no evolutionary accident. As Peter Derks, a psychologist at William and Mary College in Virginia, says: 'I like to think of humour as the distorted mirror of the mind. It's creative, perceptual, analytical and lingual. If we can figure out how the mind processes humor, then we'll have a pretty good handle on how it works in general. '", "hypothesis": "Arthur Koestler considered laughter biologically important in several ways.", "gold_label": "contradiction"}
{"uid": "id_537", "premise": "What's so funny? John McCrone reviews recent research on humor The joke comes over the headphones: 'Which side of a dog has the most hair? The left. ' No, not funny. Try again. 'Which side of a dog has the most hair? The outside. ' Hah! The punchline is silly yet fitting, tempting a smile, even a laugh. Laughter has always struck people as deeply mysterious, perhaps pointless. The writer Arthur Koestler dubbed it the luxury reflex: 'unique in that it serves no apparent biological purpose. ' Theories about humour have an ancient pedigree. Plato expressed the idea that humor is simply a delighted feeling of superiority over others. Kant and Freud felt that joke-telling relies on building up a psychic tension which is safely punctured by the ludicrousness of the punchline. But most modern humor theorists have settled on some version of Aristotle's belief that jokes are based on a reaction to or resolution of incongruity, when the punchline is either a nonsense or, though appearing silly, has a clever second meaning. Graeme Ritchie, a computational linguist in Edinburgh, studies the linguistic structure of jokes in order to understand not only humor but language understanding and reasoning in machines. He says that while there is no single format for jokes, many revolve around a sudden and surprising conceptual shift. A comedian will present a situation followed by an unexpected interpretation that is also apt. So even if a punchline sounds silly, the listener can see there is a clever semantic fit and that sudden mental 'Aha! ' is the buzz that makes us laugh. Viewed from this angle, humor is just a form of creative insight, a sudden leap to a new perspective. However, there is another type of laughter, the laughter of social appeasement and it is important to understand this too. Play is a crucial part of development in most young mammals. Rats produce ultrasonic squeaks to prevent their scuffles turning nasty. Chimpanzees have a 'play-face' a gaping expression accompanied by a panting 'ah ah' noise. In humans, these signals have mutated into smiles and laughs. Researchers believe social situations, rather than cognitive events such as jokes, trigger these instinctual markers of play or appeasement. People laugh on fairground rides or when tickled to flag a play situation, whether they feel amused or not. Both social and cognitive types of laughter tap into the same expressive machinery in our brains, the emotion and motor circuits that produce smiles and excited vocalisations. However, if cognitive laughter is the product of more general thought processes, it should result from more expansive brain activity. Psychologist Vinod Goel investigated humour using the new technique of 'single event' functional magnetic resonance imaging (fMRI). An MRI scanner uses magnetic fields and radio waves to track the changes in oxygenated blood that accompany mental activity. Until recently, MRI scanners needed several minutes of activity and so could not be used to track rapid thought processes such as comprehending a joke. New developments now allow half-second 'snapshots' of all sorts of reasoning and problem-solving activities. Although Goel felt being inside a brain scanner was hardly the ideal place for appreciating a joke, he found evidence that understanding a joke involves a widespread mental shift. His scans showed that at the beginning of a joke the listener's prefrontal cortex lit up, particularly the right prefrontal believed to be critical for problem solving. But there was also activity in the temporal lobes at the side of the head (consistent with attempts to rouse stored knowledge) and in many other brain areas. Then when the punchline arrived, a new area sprang to life the orbital prefrontal cortex. This patch of brain tucked behind the orbits of the eyes is associated with evaluating information. Making a rapid emotional assessment of the events of the moment is an extremely demanding job for the brain, animal or human. Energy and arousal levels may need to be retuned in the blink of an eye. These abrupt changes will produce either positive or negative feelings. The orbital cortex, the region that becomes active in Goel's experiment, seems the best candidate for the site that feeds such feelings into higher-level thought processes, with its close connections to the brain's sub-cortical arousal apparatus and centres of metabolic control. All warm-blooded animals make constant tiny adjustments in arousal in response to external events, but humans, who have developed a much more complicated internal life as a result of language, respond emotionally not only to their surroundings, but to their own thoughts. Whenever a sought-for answer snaps into place, there is a shudder of pleased recognition. Creative discovery being pleasurable, humans have learned to find ways of milking this natural response. The fact that jokes tap into our general evaluative machinery explains why the line between funny and disgusting, or funny and frightening, can be so fine. Whether a joke gives pleasure or pain depends on a person's outlook. Humor may be a luxury, but the mechanism behind it is no evolutionary accident. As Peter Derks, a psychologist at William and Mary College in Virginia, says: 'I like to think of humour as the distorted mirror of the mind. It's creative, perceptual, analytical and lingual. If we can figure out how the mind processes humor, then we'll have a pretty good handle on how it works in general. '", "hypothesis": "Most comedians use personal situations as a source of humour.", "gold_label": "neutral"}
{"uid": "id_538", "premise": "What's so funny? John McCrone reviews recent research on humor The joke comes over the headphones: 'Which side of a dog has the most hair? The left. ' No, not funny. Try again. 'Which side of a dog has the most hair? The outside. ' Hah! The punchline is silly yet fitting, tempting a smile, even a laugh. Laughter has always struck people as deeply mysterious, perhaps pointless. The writer Arthur Koestler dubbed it the luxury reflex: 'unique in that it serves no apparent biological purpose. ' Theories about humour have an ancient pedigree. Plato expressed the idea that humor is simply a delighted feeling of superiority over others. Kant and Freud felt that joke-telling relies on building up a psychic tension which is safely punctured by the ludicrousness of the punchline. But most modern humor theorists have settled on some version of Aristotle's belief that jokes are based on a reaction to or resolution of incongruity, when the punchline is either a nonsense or, though appearing silly, has a clever second meaning. Graeme Ritchie, a computational linguist in Edinburgh, studies the linguistic structure of jokes in order to understand not only humor but language understanding and reasoning in machines. He says that while there is no single format for jokes, many revolve around a sudden and surprising conceptual shift. A comedian will present a situation followed by an unexpected interpretation that is also apt. So even if a punchline sounds silly, the listener can see there is a clever semantic fit and that sudden mental 'Aha! ' is the buzz that makes us laugh. Viewed from this angle, humor is just a form of creative insight, a sudden leap to a new perspective. However, there is another type of laughter, the laughter of social appeasement and it is important to understand this too. Play is a crucial part of development in most young mammals. Rats produce ultrasonic squeaks to prevent their scuffles turning nasty. Chimpanzees have a 'play-face' a gaping expression accompanied by a panting 'ah ah' noise. In humans, these signals have mutated into smiles and laughs. Researchers believe social situations, rather than cognitive events such as jokes, trigger these instinctual markers of play or appeasement. People laugh on fairground rides or when tickled to flag a play situation, whether they feel amused or not. Both social and cognitive types of laughter tap into the same expressive machinery in our brains, the emotion and motor circuits that produce smiles and excited vocalisations. However, if cognitive laughter is the product of more general thought processes, it should result from more expansive brain activity. Psychologist Vinod Goel investigated humour using the new technique of 'single event' functional magnetic resonance imaging (fMRI). An MRI scanner uses magnetic fields and radio waves to track the changes in oxygenated blood that accompany mental activity. Until recently, MRI scanners needed several minutes of activity and so could not be used to track rapid thought processes such as comprehending a joke. New developments now allow half-second 'snapshots' of all sorts of reasoning and problem-solving activities. Although Goel felt being inside a brain scanner was hardly the ideal place for appreciating a joke, he found evidence that understanding a joke involves a widespread mental shift. His scans showed that at the beginning of a joke the listener's prefrontal cortex lit up, particularly the right prefrontal believed to be critical for problem solving. But there was also activity in the temporal lobes at the side of the head (consistent with attempts to rouse stored knowledge) and in many other brain areas. Then when the punchline arrived, a new area sprang to life the orbital prefrontal cortex. This patch of brain tucked behind the orbits of the eyes is associated with evaluating information. Making a rapid emotional assessment of the events of the moment is an extremely demanding job for the brain, animal or human. Energy and arousal levels may need to be retuned in the blink of an eye. These abrupt changes will produce either positive or negative feelings. The orbital cortex, the region that becomes active in Goel's experiment, seems the best candidate for the site that feeds such feelings into higher-level thought processes, with its close connections to the brain's sub-cortical arousal apparatus and centres of metabolic control. All warm-blooded animals make constant tiny adjustments in arousal in response to external events, but humans, who have developed a much more complicated internal life as a result of language, respond emotionally not only to their surroundings, but to their own thoughts. Whenever a sought-for answer snaps into place, there is a shudder of pleased recognition. Creative discovery being pleasurable, humans have learned to find ways of milking this natural response. The fact that jokes tap into our general evaluative machinery explains why the line between funny and disgusting, or funny and frightening, can be so fine. Whether a joke gives pleasure or pain depends on a person's outlook. Humor may be a luxury, but the mechanism behind it is no evolutionary accident. As Peter Derks, a psychologist at William and Mary College in Virginia, says: 'I like to think of humour as the distorted mirror of the mind. It's creative, perceptual, analytical and lingual. If we can figure out how the mind processes humor, then we'll have a pretty good handle on how it works in general. '", "hypothesis": "Chimpanzees make particular noises when they are playing.", "gold_label": "entailment"}
{"uid": "id_539", "premise": "What's the purpose of gaining knowledge? 'I would found an institution where any person can find instruction in any subject. ' That was the founder's motto for Cornell University, and it seems an apt characterization of the different university, also in the USA, where I currently teach philosophy. A student can prepare for a career in resort management, engineering, interior design, accounting, music, law enforcement, you name it. But what would the founders of these two institutions have thought of a course called Arson for Profit ? I kid you not: we have it on the books. Any undergraduates who have met the academic requirements can sign up for the course in our program in 'fire science'. Naturally, the course is intended for prospective arson investigators, who can learn all the tricks of the trade for detecting whether a fire was deliberately set, discovering who did it, and establishing a chain of evidence for effective prosecution in a court of law. But wouldn't this also be the perfect course for prospective arsonists to sign up for? My point is not to criticize academic programs in fire science: they are highly welcome as part of the increasing professionalization of this and many other occupations. However, it's not unknown for a firefighter to torch a building. This example suggests how dishonest and illegal behavior, with the help of higher education, can creep into every aspect of public and business life. I realized this anew when I was invited to speak before a class in marketing, which is another of our degree programs. The regular instructor is a colleague who appreciates the kind of ethical perspective I can bring as a philosopher. There are endless ways I could have approached this assignment, but I took my cue from the title of the course: 'Principles of Marketing'. It made me think to ask the students, 'Is marketing principled? ' After all, a subject matter can have principles in the sense of being codified, having rules, as with football or chess, without being principled in the sense of being ethical. Many of the students immediately assumed that the answer to my question about marketing principles was obvious: no. Just look at the ways in which everything under the sun has been marketed; obviously it need not be done in a principled (=ethical) fashion. Is that obvious? I made the suggestion, which may sound downright crazy in light of the evidence, that perhaps marketing is by definition principled. My inspiration for this judgement is the philosopher Immanuel Kant, who argued that any body of knowledge consists of an end (or purpose) and a means. Let us apply both the terms 'means' and 'end' to marketing. The students have signed up for a course in order to learn how to market effectively. But to what end? There seem to be two main attitudes toward that question. One is that the answer is obvious: the purpose of marketing is to sell things and to make money. The other attitude is that the purpose of marketing is irrelevant: Each person comes to the program and course with his or her own plans, and these need not even concern the acquisition of marketing expertise as such. My proposal, which I believe would also be Kant's, is that neither of these attitudes captures the significance of the end to the means for marketing. A field of knowledge or a professional endeavor is defined by both the means and the end; hence both deserve scrutiny. Students need to study both how to achieve X, and also what X is. It is at this point that 'Arson for Profit' becomes supremely relevant. That course is presumably all about means: how to detect and prosecute criminal activity. It is therefore assumed that the end is good in an ethical sense. When I ask fire science students to articulate the end, or purpose, of their field, they eventually generalize to something like, 'The safety and welfare of society, ' which seems right. As we have seen, someone could use the very same knowledge of means to achieve a much less noble end, such as personal profit via destructive, dangerous, reckless activity. But we would not call that firefighting. We have a separate word for it: arson. Similarly, if you employed the 'principles of marketing' in an unprincipled way, you would not be doing marketing. We have another term for it: fraud. Kant gives the example of a doctor and a poisoner, who use the identical knowledge to achieve their divergent ends. We would say that one is practicing medicine, the other, murder.", "hypothesis": "The 'Arson for Profit' course would be useful for people intending to set fire to buildings.", "gold_label": "entailment"}
{"uid": "id_540", "premise": "What's the purpose of gaining knowledge? 'I would found an institution where any person can find instruction in any subject. ' That was the founder's motto for Cornell University, and it seems an apt characterization of the different university, also in the USA, where I currently teach philosophy. A student can prepare for a career in resort management, engineering, interior design, accounting, music, law enforcement, you name it. But what would the founders of these two institutions have thought of a course called Arson for Profit ? I kid you not: we have it on the books. Any undergraduates who have met the academic requirements can sign up for the course in our program in 'fire science'. Naturally, the course is intended for prospective arson investigators, who can learn all the tricks of the trade for detecting whether a fire was deliberately set, discovering who did it, and establishing a chain of evidence for effective prosecution in a court of law. But wouldn't this also be the perfect course for prospective arsonists to sign up for? My point is not to criticize academic programs in fire science: they are highly welcome as part of the increasing professionalization of this and many other occupations. However, it's not unknown for a firefighter to torch a building. This example suggests how dishonest and illegal behavior, with the help of higher education, can creep into every aspect of public and business life. I realized this anew when I was invited to speak before a class in marketing, which is another of our degree programs. The regular instructor is a colleague who appreciates the kind of ethical perspective I can bring as a philosopher. There are endless ways I could have approached this assignment, but I took my cue from the title of the course: 'Principles of Marketing'. It made me think to ask the students, 'Is marketing principled? ' After all, a subject matter can have principles in the sense of being codified, having rules, as with football or chess, without being principled in the sense of being ethical. Many of the students immediately assumed that the answer to my question about marketing principles was obvious: no. Just look at the ways in which everything under the sun has been marketed; obviously it need not be done in a principled (=ethical) fashion. Is that obvious? I made the suggestion, which may sound downright crazy in light of the evidence, that perhaps marketing is by definition principled. My inspiration for this judgement is the philosopher Immanuel Kant, who argued that any body of knowledge consists of an end (or purpose) and a means. Let us apply both the terms 'means' and 'end' to marketing. The students have signed up for a course in order to learn how to market effectively. But to what end? There seem to be two main attitudes toward that question. One is that the answer is obvious: the purpose of marketing is to sell things and to make money. The other attitude is that the purpose of marketing is irrelevant: Each person comes to the program and course with his or her own plans, and these need not even concern the acquisition of marketing expertise as such. My proposal, which I believe would also be Kant's, is that neither of these attitudes captures the significance of the end to the means for marketing. A field of knowledge or a professional endeavor is defined by both the means and the end; hence both deserve scrutiny. Students need to study both how to achieve X, and also what X is. It is at this point that 'Arson for Profit' becomes supremely relevant. That course is presumably all about means: how to detect and prosecute criminal activity. It is therefore assumed that the end is good in an ethical sense. When I ask fire science students to articulate the end, or purpose, of their field, they eventually generalize to something like, 'The safety and welfare of society, ' which seems right. As we have seen, someone could use the very same knowledge of means to achieve a much less noble end, such as personal profit via destructive, dangerous, reckless activity. But we would not call that firefighting. We have a separate word for it: arson. Similarly, if you employed the 'principles of marketing' in an unprincipled way, you would not be doing marketing. We have another term for it: fraud. Kant gives the example of a doctor and a poisoner, who use the identical knowledge to achieve their divergent ends. We would say that one is practicing medicine, the other, murder.", "hypothesis": "It is difficult to attract students onto courses that do not focus on a career.", "gold_label": "neutral"}
{"uid": "id_541", "premise": "What's the purpose of gaining knowledge? 'I would found an institution where any person can find instruction in any subject. ' That was the founder's motto for Cornell University, and it seems an apt characterization of the different university, also in the USA, where I currently teach philosophy. A student can prepare for a career in resort management, engineering, interior design, accounting, music, law enforcement, you name it. But what would the founders of these two institutions have thought of a course called Arson for Profit ? I kid you not: we have it on the books. Any undergraduates who have met the academic requirements can sign up for the course in our program in 'fire science'. Naturally, the course is intended for prospective arson investigators, who can learn all the tricks of the trade for detecting whether a fire was deliberately set, discovering who did it, and establishing a chain of evidence for effective prosecution in a court of law. But wouldn't this also be the perfect course for prospective arsonists to sign up for? My point is not to criticize academic programs in fire science: they are highly welcome as part of the increasing professionalization of this and many other occupations. However, it's not unknown for a firefighter to torch a building. This example suggests how dishonest and illegal behavior, with the help of higher education, can creep into every aspect of public and business life. I realized this anew when I was invited to speak before a class in marketing, which is another of our degree programs. The regular instructor is a colleague who appreciates the kind of ethical perspective I can bring as a philosopher. There are endless ways I could have approached this assignment, but I took my cue from the title of the course: 'Principles of Marketing'. It made me think to ask the students, 'Is marketing principled? ' After all, a subject matter can have principles in the sense of being codified, having rules, as with football or chess, without being principled in the sense of being ethical. Many of the students immediately assumed that the answer to my question about marketing principles was obvious: no. Just look at the ways in which everything under the sun has been marketed; obviously it need not be done in a principled (=ethical) fashion. Is that obvious? I made the suggestion, which may sound downright crazy in light of the evidence, that perhaps marketing is by definition principled. My inspiration for this judgement is the philosopher Immanuel Kant, who argued that any body of knowledge consists of an end (or purpose) and a means. Let us apply both the terms 'means' and 'end' to marketing. The students have signed up for a course in order to learn how to market effectively. But to what end? There seem to be two main attitudes toward that question. One is that the answer is obvious: the purpose of marketing is to sell things and to make money. The other attitude is that the purpose of marketing is irrelevant: Each person comes to the program and course with his or her own plans, and these need not even concern the acquisition of marketing expertise as such. My proposal, which I believe would also be Kant's, is that neither of these attitudes captures the significance of the end to the means for marketing. A field of knowledge or a professional endeavor is defined by both the means and the end; hence both deserve scrutiny. Students need to study both how to achieve X, and also what X is. It is at this point that 'Arson for Profit' becomes supremely relevant. That course is presumably all about means: how to detect and prosecute criminal activity. It is therefore assumed that the end is good in an ethical sense. When I ask fire science students to articulate the end, or purpose, of their field, they eventually generalize to something like, 'The safety and welfare of society, ' which seems right. As we have seen, someone could use the very same knowledge of means to achieve a much less noble end, such as personal profit via destructive, dangerous, reckless activity. But we would not call that firefighting. We have a separate word for it: arson. Similarly, if you employed the 'principles of marketing' in an unprincipled way, you would not be doing marketing. We have another term for it: fraud. Kant gives the example of a doctor and a poisoner, who use the identical knowledge to achieve their divergent ends. We would say that one is practicing medicine, the other, murder.", "hypothesis": "Fire science courses are too academic to help people to be good at the job of firefighting.", "gold_label": "contradiction"}
{"uid": "id_542", "premise": "What's the purpose of gaining knowledge? 'I would found an institution where any person can find instruction in any subject. ' That was the founder's motto for Cornell University, and it seems an apt characterization of the different university, also in the USA, where I currently teach philosophy. A student can prepare for a career in resort management, engineering, interior design, accounting, music, law enforcement, you name it. But what would the founders of these two institutions have thought of a course called Arson for Profit ? I kid you not: we have it on the books. Any undergraduates who have met the academic requirements can sign up for the course in our program in 'fire science'. Naturally, the course is intended for prospective arson investigators, who can learn all the tricks of the trade for detecting whether a fire was deliberately set, discovering who did it, and establishing a chain of evidence for effective prosecution in a court of law. But wouldn't this also be the perfect course for prospective arsonists to sign up for? My point is not to criticize academic programs in fire science: they are highly welcome as part of the increasing professionalization of this and many other occupations. However, it's not unknown for a firefighter to torch a building. This example suggests how dishonest and illegal behavior, with the help of higher education, can creep into every aspect of public and business life. I realized this anew when I was invited to speak before a class in marketing, which is another of our degree programs. The regular instructor is a colleague who appreciates the kind of ethical perspective I can bring as a philosopher. There are endless ways I could have approached this assignment, but I took my cue from the title of the course: 'Principles of Marketing'. It made me think to ask the students, 'Is marketing principled? ' After all, a subject matter can have principles in the sense of being codified, having rules, as with football or chess, without being principled in the sense of being ethical. Many of the students immediately assumed that the answer to my question about marketing principles was obvious: no. Just look at the ways in which everything under the sun has been marketed; obviously it need not be done in a principled (=ethical) fashion. Is that obvious? I made the suggestion, which may sound downright crazy in light of the evidence, that perhaps marketing is by definition principled. My inspiration for this judgement is the philosopher Immanuel Kant, who argued that any body of knowledge consists of an end (or purpose) and a means. Let us apply both the terms 'means' and 'end' to marketing. The students have signed up for a course in order to learn how to market effectively. But to what end? There seem to be two main attitudes toward that question. One is that the answer is obvious: the purpose of marketing is to sell things and to make money. The other attitude is that the purpose of marketing is irrelevant: Each person comes to the program and course with his or her own plans, and these need not even concern the acquisition of marketing expertise as such. My proposal, which I believe would also be Kant's, is that neither of these attitudes captures the significance of the end to the means for marketing. A field of knowledge or a professional endeavor is defined by both the means and the end; hence both deserve scrutiny. Students need to study both how to achieve X, and also what X is. It is at this point that 'Arson for Profit' becomes supremely relevant. That course is presumably all about means: how to detect and prosecute criminal activity. It is therefore assumed that the end is good in an ethical sense. When I ask fire science students to articulate the end, or purpose, of their field, they eventually generalize to something like, 'The safety and welfare of society, ' which seems right. As we have seen, someone could use the very same knowledge of means to achieve a much less noble end, such as personal profit via destructive, dangerous, reckless activity. But we would not call that firefighting. We have a separate word for it: arson. Similarly, if you employed the 'principles of marketing' in an unprincipled way, you would not be doing marketing. We have another term for it: fraud. Kant gives the example of a doctor and a poisoner, who use the identical knowledge to achieve their divergent ends. We would say that one is practicing medicine, the other, murder.", "hypothesis": "The writer's fire science students provided a detailed definition of the purpose of their studies.", "gold_label": "contradiction"}
{"uid": "id_543", "premise": "Whats in Blood? Blood is the most specialised fluid within living animals, playing an absolutely critical role. It symbolises life (new blood), health (get your blood running), personality (good or bad blood), and family (your bloodline). This red fluid itself is something which most people would rather not see, yet it contains such a complex soup of proteins, sugars, ions, hormones, gases, and basic cellular components that it is certainly worth considering in some detail. By volume, half of blood is the liquid part, called plasma. The rest comprises specialised components, the main one being red blood cells (technically known as erythrocytes). These transport oxygen molecules throughout the body, and also give blood its colour (from the hemoglobin protein within, which turns red when combined with oxygen). Red blood cells, as with all cells in the human body, have a limited operating life. They are produced within the marrow of bones, principally the larger ones, and live for about four months before they fall inactive, to be then reabsorbed by the spleen and liver, with waste products absorbed into the urine. This contrasts with the other main cells of human blood: the white blood cells, technically known as leukocytes. Similarly produced in the bone marrow, they are active only for three or four days, yet they are essential in defending the body against infections. White blood cells come in many different types, each designed to deal with a different sort of invader bacteria, virus, fungus, or parasite. When one of these enters the body, the white blood cells quickly determine its nature, then, after mustering sufficient numbers of a specific type (the period in which you are sick), they launch themselves into the fight, enveloping each individual invasive cell, and breaking it down (leading to recovery). That leaves the last main component of blood: platelets. Their technical name is thrombocytes, and they are much smaller than red and white blood cells. Also circulating freely, they are responsible for clotting the blood, and this is necessary to heal both external and internal injuries. Again, they are produced in the bone marrow, and have the interesting ability to change shape. There are several diseases related to the breakdown in the regulation of their numbers. If too low, excessive bleeding can occur, yet if too high, internal clotting may result, causing potentially catastrophic blockages in parts of the body and medical ailments we know as strokes, heart attacks, and embolisms. Bloods complexity presents particular difficulties in the advent of emergency transfusions. These are avoided whenever possible in order to lower the risk of reactions due to blood incompatibility. Unexpected antigens can trigger antibodies to attack blood components, with potentially lethal results. Thus, if transfusions are to take place, a thorough knowledge and classification of blood is essential, yet with 30 recognised blood-group systems, containing hundreds of antigens, this presents quite a challenge. The ABO system is the most important. On top of this is the Rhesus factor, which is not as simple as positive or negative (as most people think), but comprises scores of antigens. These can, however, be clustered together into groups which cause similar responses, creating some order. Of course, the simplest system to avoid adverse transfusion reactions is for patients to receive their own blood for example, in a series of blood donations in anticipation of an operation scheduled some months in advance. The second best system is to undertake cross-matching, which involves simply mixing samples of the patients blood with the donors, then checking microscopically for clumping a key sign of incompatibility. Both of these systems are obviously impractical in an emergency situation, which is why meticulous testing, documentation, and labeling of blood are necessary. In a true emergency, a blood bank is needed, with an array of various types of blood on hand. Hence, blood donations must be a regular occurrence among a significant segment of the population. In the developed world, unpaid volunteers provide most of the blood for the community, whereas in less developed nations, families or friends are mostly involved. In the era of HIV and other insidious blood-borne diseases, potential donors are carefully screened and tested, and a period of about two months is recommended before successive whole blood donations. Given the vital role which blood plays, it is strange to think that for almost 2000 years bloodletting was a widespread medical practice. It was based on the belief that blood carried humours, whose imbalances resulted in medical illnesses. Bleeding a patient was supposed to remove an undesirable excess of one of these. Furthermore, the fact that blood circulated around the body was unknown. It was instead assumed to be quickly created, and equally quickly exhausted of its value, after which it could stagnant unhealthily in the bodily extremities. Although the logic was there, it goes without saying that very few patients responded positively to such treatment.", "hypothesis": "Bleeding people was a painful process.", "gold_label": "neutral"}
{"uid": "id_544", "premise": "Whats in Blood? Blood is the most specialised fluid within living animals, playing an absolutely critical role. It symbolises life (new blood), health (get your blood running), personality (good or bad blood), and family (your bloodline). This red fluid itself is something which most people would rather not see, yet it contains such a complex soup of proteins, sugars, ions, hormones, gases, and basic cellular components that it is certainly worth considering in some detail. By volume, half of blood is the liquid part, called plasma. The rest comprises specialised components, the main one being red blood cells (technically known as erythrocytes). These transport oxygen molecules throughout the body, and also give blood its colour (from the hemoglobin protein within, which turns red when combined with oxygen). Red blood cells, as with all cells in the human body, have a limited operating life. They are produced within the marrow of bones, principally the larger ones, and live for about four months before they fall inactive, to be then reabsorbed by the spleen and liver, with waste products absorbed into the urine. This contrasts with the other main cells of human blood: the white blood cells, technically known as leukocytes. Similarly produced in the bone marrow, they are active only for three or four days, yet they are essential in defending the body against infections. White blood cells come in many different types, each designed to deal with a different sort of invader bacteria, virus, fungus, or parasite. When one of these enters the body, the white blood cells quickly determine its nature, then, after mustering sufficient numbers of a specific type (the period in which you are sick), they launch themselves into the fight, enveloping each individual invasive cell, and breaking it down (leading to recovery). That leaves the last main component of blood: platelets. Their technical name is thrombocytes, and they are much smaller than red and white blood cells. Also circulating freely, they are responsible for clotting the blood, and this is necessary to heal both external and internal injuries. Again, they are produced in the bone marrow, and have the interesting ability to change shape. There are several diseases related to the breakdown in the regulation of their numbers. If too low, excessive bleeding can occur, yet if too high, internal clotting may result, causing potentially catastrophic blockages in parts of the body and medical ailments we know as strokes, heart attacks, and embolisms. Bloods complexity presents particular difficulties in the advent of emergency transfusions. These are avoided whenever possible in order to lower the risk of reactions due to blood incompatibility. Unexpected antigens can trigger antibodies to attack blood components, with potentially lethal results. Thus, if transfusions are to take place, a thorough knowledge and classification of blood is essential, yet with 30 recognised blood-group systems, containing hundreds of antigens, this presents quite a challenge. The ABO system is the most important. On top of this is the Rhesus factor, which is not as simple as positive or negative (as most people think), but comprises scores of antigens. These can, however, be clustered together into groups which cause similar responses, creating some order. Of course, the simplest system to avoid adverse transfusion reactions is for patients to receive their own blood for example, in a series of blood donations in anticipation of an operation scheduled some months in advance. The second best system is to undertake cross-matching, which involves simply mixing samples of the patients blood with the donors, then checking microscopically for clumping a key sign of incompatibility. Both of these systems are obviously impractical in an emergency situation, which is why meticulous testing, documentation, and labeling of blood are necessary. In a true emergency, a blood bank is needed, with an array of various types of blood on hand. Hence, blood donations must be a regular occurrence among a significant segment of the population. In the developed world, unpaid volunteers provide most of the blood for the community, whereas in less developed nations, families or friends are mostly involved. In the era of HIV and other insidious blood-borne diseases, potential donors are carefully screened and tested, and a period of about two months is recommended before successive whole blood donations. Given the vital role which blood plays, it is strange to think that for almost 2000 years bloodletting was a widespread medical practice. It was based on the belief that blood carried humours, whose imbalances resulted in medical illnesses. Bleeding a patient was supposed to remove an undesirable excess of one of these. Furthermore, the fact that blood circulated around the body was unknown. It was instead assumed to be quickly created, and equally quickly exhausted of its value, after which it could stagnant unhealthily in the bodily extremities. Although the logic was there, it goes without saying that very few patients responded positively to such treatment.", "hypothesis": "In poorer countries, family members often donate blood.", "gold_label": "entailment"}
{"uid": "id_545", "premise": "Whats in Blood? Blood is the most specialised fluid within living animals, playing an absolutely critical role. It symbolises life (new blood), health (get your blood running), personality (good or bad blood), and family (your bloodline). This red fluid itself is something which most people would rather not see, yet it contains such a complex soup of proteins, sugars, ions, hormones, gases, and basic cellular components that it is certainly worth considering in some detail. By volume, half of blood is the liquid part, called plasma. The rest comprises specialised components, the main one being red blood cells (technically known as erythrocytes). These transport oxygen molecules throughout the body, and also give blood its colour (from the hemoglobin protein within, which turns red when combined with oxygen). Red blood cells, as with all cells in the human body, have a limited operating life. They are produced within the marrow of bones, principally the larger ones, and live for about four months before they fall inactive, to be then reabsorbed by the spleen and liver, with waste products absorbed into the urine. This contrasts with the other main cells of human blood: the white blood cells, technically known as leukocytes. Similarly produced in the bone marrow, they are active only for three or four days, yet they are essential in defending the body against infections. White blood cells come in many different types, each designed to deal with a different sort of invader bacteria, virus, fungus, or parasite. When one of these enters the body, the white blood cells quickly determine its nature, then, after mustering sufficient numbers of a specific type (the period in which you are sick), they launch themselves into the fight, enveloping each individual invasive cell, and breaking it down (leading to recovery). That leaves the last main component of blood: platelets. Their technical name is thrombocytes, and they are much smaller than red and white blood cells. Also circulating freely, they are responsible for clotting the blood, and this is necessary to heal both external and internal injuries. Again, they are produced in the bone marrow, and have the interesting ability to change shape. There are several diseases related to the breakdown in the regulation of their numbers. If too low, excessive bleeding can occur, yet if too high, internal clotting may result, causing potentially catastrophic blockages in parts of the body and medical ailments we know as strokes, heart attacks, and embolisms. Bloods complexity presents particular difficulties in the advent of emergency transfusions. These are avoided whenever possible in order to lower the risk of reactions due to blood incompatibility. Unexpected antigens can trigger antibodies to attack blood components, with potentially lethal results. Thus, if transfusions are to take place, a thorough knowledge and classification of blood is essential, yet with 30 recognised blood-group systems, containing hundreds of antigens, this presents quite a challenge. The ABO system is the most important. On top of this is the Rhesus factor, which is not as simple as positive or negative (as most people think), but comprises scores of antigens. These can, however, be clustered together into groups which cause similar responses, creating some order. Of course, the simplest system to avoid adverse transfusion reactions is for patients to receive their own blood for example, in a series of blood donations in anticipation of an operation scheduled some months in advance. The second best system is to undertake cross-matching, which involves simply mixing samples of the patients blood with the donors, then checking microscopically for clumping a key sign of incompatibility. Both of these systems are obviously impractical in an emergency situation, which is why meticulous testing, documentation, and labeling of blood are necessary. In a true emergency, a blood bank is needed, with an array of various types of blood on hand. Hence, blood donations must be a regular occurrence among a significant segment of the population. In the developed world, unpaid volunteers provide most of the blood for the community, whereas in less developed nations, families or friends are mostly involved. In the era of HIV and other insidious blood-borne diseases, potential donors are carefully screened and tested, and a period of about two months is recommended before successive whole blood donations. Given the vital role which blood plays, it is strange to think that for almost 2000 years bloodletting was a widespread medical practice. It was based on the belief that blood carried humours, whose imbalances resulted in medical illnesses. Bleeding a patient was supposed to remove an undesirable excess of one of these. Furthermore, the fact that blood circulated around the body was unknown. It was instead assumed to be quickly created, and equally quickly exhausted of its value, after which it could stagnant unhealthily in the bodily extremities. Although the logic was there, it goes without saying that very few patients responded positively to such treatment.", "hypothesis": "Blood cross-matching can be done without special equipment.", "gold_label": "contradiction"}
{"uid": "id_546", "premise": "Whats the purpose of gaining knowledge? I would found an institution where any person can find instruction in any subject That was the founders motto for Cornell University, and it seems an apt characterization of the different university, also in the USA, where I currently teach philosophy. A student can prepare for a career in resort management, engineering, interior design, accounting, music, law enforcement, you name it. But what would the founders of these two institutions have thought of a course called Arson for Profit? I kid you not: we have it on the books. Any undergraduates who have met the academic requirements can sign up for the course in our program in fire science. Naturally, the course is intended for prospective arson investigators, who can learn all the tricks of the trade for detecting whether a fire was deliberately set, discovering who did it, and establishing a chain of evidence for effective prosecution in a court of law. But wouldnt this also be the perfect course for prospective arsonists to sign up for? My point is not to criticize academic programs in fire science: they are highly welcome as part of the increasing professionalization of this and many other occupations. However, its not unknown for a firefighter to torch a building. This example suggests how dishonest and illegal behavior, with the help of higher education, can creep into every aspect of public and business life. I realized this anew when I was invited to speak before a class in marketing, which is another of our degree programs. The regular instructor is a colleague who appreciates the kind of ethical perspective I can bring as a philosopher. There are endless ways I could have approached this assignment, but I took my cue from the title of the course: Principles of Marketing. It made me think to ask the students, Is marketing principled? After all, a subject matter can have principles in the sense of being codified, having rules, as with football or chess, without being principled in the sense of being ethical. Many of the students immediately assumed that the answer to my question about marketing principles was obvious: no. Just look at the ways in which everything under the sun has been marketed; obviously it need not be done in a principled (=ethical) fashion. Is that obvious? I made the suggestion, which may sound downright crazy in light of the evidence, that perhaps marketing is by definition principled. My inspiration for this judgement is the philosopher Immanuel Kant, who argued that any body of knowledge consists of an end (or purpose) and a means. Let us apply both the terms means and end to marketing. The students have signed up for a course in order to learn how to market effectively. But to what end? There seem to be two main attitudes toward that question. One is that the answer is obvious: the purpose of marketing is to sell things and to make money. The other attitude is that the purpose of marketing is irrelevant: Each person comes to the program and course with his or her own plans, and these need not even concern the acquisition of marketing expertise as such. My proposal, which I believe would also be Kants, is that neither of these attitudes captures the significance of the end to the means for marketing. A field of knowledge or a professional endeavor is defined by both the means and the end; hence both deserve scrutiny. Students need to study both how to achieve X, and also what X is. It is at this point that Arson for Profit becomes supremely relevant. That course is presumably all about means: how to detect and prosecute criminal activity. It is therefore assumed that the end is good in an ethical sense. When I ask fire science students to articulate the end, or purpose, of their field, they eventually generalize to something like, The safety and welfare of society, which seems right. As we have seen, someone could use the very same knowledge of means to achieve a much less noble end, such as personal profit via destructive, dangerous, reckless activity. But we would not call that firefighting. We have a separate word for it: arson. Similarly, if you employed the principles of marketing in an unprincipled way, you would not be doing marketing. We have another term for it: fraud. Kant gives the example of a doctor and a poisoner, who use the identical knowledge to achieve their divergent ends. We would say that one is practicing medicine, the other, murder.", "hypothesis": "The writers fire science students provided a detailed definition of the purpose of their studies.", "gold_label": "contradiction"}
{"uid": "id_547", "premise": "Whats the purpose of gaining knowledge? I would found an institution where any person can find instruction in any subject That was the founders motto for Cornell University, and it seems an apt characterization of the different university, also in the USA, where I currently teach philosophy. A student can prepare for a career in resort management, engineering, interior design, accounting, music, law enforcement, you name it. But what would the founders of these two institutions have thought of a course called Arson for Profit? I kid you not: we have it on the books. Any undergraduates who have met the academic requirements can sign up for the course in our program in fire science. Naturally, the course is intended for prospective arson investigators, who can learn all the tricks of the trade for detecting whether a fire was deliberately set, discovering who did it, and establishing a chain of evidence for effective prosecution in a court of law. But wouldnt this also be the perfect course for prospective arsonists to sign up for? My point is not to criticize academic programs in fire science: they are highly welcome as part of the increasing professionalization of this and many other occupations. However, its not unknown for a firefighter to torch a building. This example suggests how dishonest and illegal behavior, with the help of higher education, can creep into every aspect of public and business life. I realized this anew when I was invited to speak before a class in marketing, which is another of our degree programs. The regular instructor is a colleague who appreciates the kind of ethical perspective I can bring as a philosopher. There are endless ways I could have approached this assignment, but I took my cue from the title of the course: Principles of Marketing. It made me think to ask the students, Is marketing principled? After all, a subject matter can have principles in the sense of being codified, having rules, as with football or chess, without being principled in the sense of being ethical. Many of the students immediately assumed that the answer to my question about marketing principles was obvious: no. Just look at the ways in which everything under the sun has been marketed; obviously it need not be done in a principled (=ethical) fashion. Is that obvious? I made the suggestion, which may sound downright crazy in light of the evidence, that perhaps marketing is by definition principled. My inspiration for this judgement is the philosopher Immanuel Kant, who argued that any body of knowledge consists of an end (or purpose) and a means. Let us apply both the terms means and end to marketing. The students have signed up for a course in order to learn how to market effectively. But to what end? There seem to be two main attitudes toward that question. One is that the answer is obvious: the purpose of marketing is to sell things and to make money. The other attitude is that the purpose of marketing is irrelevant: Each person comes to the program and course with his or her own plans, and these need not even concern the acquisition of marketing expertise as such. My proposal, which I believe would also be Kants, is that neither of these attitudes captures the significance of the end to the means for marketing. A field of knowledge or a professional endeavor is defined by both the means and the end; hence both deserve scrutiny. Students need to study both how to achieve X, and also what X is. It is at this point that Arson for Profit becomes supremely relevant. That course is presumably all about means: how to detect and prosecute criminal activity. It is therefore assumed that the end is good in an ethical sense. When I ask fire science students to articulate the end, or purpose, of their field, they eventually generalize to something like, The safety and welfare of society, which seems right. As we have seen, someone could use the very same knowledge of means to achieve a much less noble end, such as personal profit via destructive, dangerous, reckless activity. But we would not call that firefighting. We have a separate word for it: arson. Similarly, if you employed the principles of marketing in an unprincipled way, you would not be doing marketing. We have another term for it: fraud. Kant gives the example of a doctor and a poisoner, who use the identical knowledge to achieve their divergent ends. We would say that one is practicing medicine, the other, murder.", "hypothesis": "Fire science are too academic to help people to be good at the job of firefighting.", "gold_label": "neutral"}
{"uid": "id_548", "premise": "Whats the purpose of gaining knowledge? I would found an institution where any person can find instruction in any subject That was the founders motto for Cornell University, and it seems an apt characterization of the different university, also in the USA, where I currently teach philosophy. A student can prepare for a career in resort management, engineering, interior design, accounting, music, law enforcement, you name it. But what would the founders of these two institutions have thought of a course called Arson for Profit? I kid you not: we have it on the books. Any undergraduates who have met the academic requirements can sign up for the course in our program in fire science. Naturally, the course is intended for prospective arson investigators, who can learn all the tricks of the trade for detecting whether a fire was deliberately set, discovering who did it, and establishing a chain of evidence for effective prosecution in a court of law. But wouldnt this also be the perfect course for prospective arsonists to sign up for? My point is not to criticize academic programs in fire science: they are highly welcome as part of the increasing professionalization of this and many other occupations. However, its not unknown for a firefighter to torch a building. This example suggests how dishonest and illegal behavior, with the help of higher education, can creep into every aspect of public and business life. I realized this anew when I was invited to speak before a class in marketing, which is another of our degree programs. The regular instructor is a colleague who appreciates the kind of ethical perspective I can bring as a philosopher. There are endless ways I could have approached this assignment, but I took my cue from the title of the course: Principles of Marketing. It made me think to ask the students, Is marketing principled? After all, a subject matter can have principles in the sense of being codified, having rules, as with football or chess, without being principled in the sense of being ethical. Many of the students immediately assumed that the answer to my question about marketing principles was obvious: no. Just look at the ways in which everything under the sun has been marketed; obviously it need not be done in a principled (=ethical) fashion. Is that obvious? I made the suggestion, which may sound downright crazy in light of the evidence, that perhaps marketing is by definition principled. My inspiration for this judgement is the philosopher Immanuel Kant, who argued that any body of knowledge consists of an end (or purpose) and a means. Let us apply both the terms means and end to marketing. The students have signed up for a course in order to learn how to market effectively. But to what end? There seem to be two main attitudes toward that question. One is that the answer is obvious: the purpose of marketing is to sell things and to make money. The other attitude is that the purpose of marketing is irrelevant: Each person comes to the program and course with his or her own plans, and these need not even concern the acquisition of marketing expertise as such. My proposal, which I believe would also be Kants, is that neither of these attitudes captures the significance of the end to the means for marketing. A field of knowledge or a professional endeavor is defined by both the means and the end; hence both deserve scrutiny. Students need to study both how to achieve X, and also what X is. It is at this point that Arson for Profit becomes supremely relevant. That course is presumably all about means: how to detect and prosecute criminal activity. It is therefore assumed that the end is good in an ethical sense. When I ask fire science students to articulate the end, or purpose, of their field, they eventually generalize to something like, The safety and welfare of society, which seems right. As we have seen, someone could use the very same knowledge of means to achieve a much less noble end, such as personal profit via destructive, dangerous, reckless activity. But we would not call that firefighting. We have a separate word for it: arson. Similarly, if you employed the principles of marketing in an unprincipled way, you would not be doing marketing. We have another term for it: fraud. Kant gives the example of a doctor and a poisoner, who use the identical knowledge to achieve their divergent ends. We would say that one is practicing medicine, the other, murder.", "hypothesis": "The Arson for Profit course would be useful for people intending to set fire to buildings.", "gold_label": "entailment"}
{"uid": "id_549", "premise": "Whats the purpose of gaining knowledge? I would found an institution where any person can find instruction in any subject That was the founders motto for Cornell University, and it seems an apt characterization of the different university, also in the USA, where I currently teach philosophy. A student can prepare for a career in resort management, engineering, interior design, accounting, music, law enforcement, you name it. But what would the founders of these two institutions have thought of a course called Arson for Profit? I kid you not: we have it on the books. Any undergraduates who have met the academic requirements can sign up for the course in our program in fire science. Naturally, the course is intended for prospective arson investigators, who can learn all the tricks of the trade for detecting whether a fire was deliberately set, discovering who did it, and establishing a chain of evidence for effective prosecution in a court of law. But wouldnt this also be the perfect course for prospective arsonists to sign up for? My point is not to criticize academic programs in fire science: they are highly welcome as part of the increasing professionalization of this and many other occupations. However, its not unknown for a firefighter to torch a building. This example suggests how dishonest and illegal behavior, with the help of higher education, can creep into every aspect of public and business life. I realized this anew when I was invited to speak before a class in marketing, which is another of our degree programs. The regular instructor is a colleague who appreciates the kind of ethical perspective I can bring as a philosopher. There are endless ways I could have approached this assignment, but I took my cue from the title of the course: Principles of Marketing. It made me think to ask the students, Is marketing principled? After all, a subject matter can have principles in the sense of being codified, having rules, as with football or chess, without being principled in the sense of being ethical. Many of the students immediately assumed that the answer to my question about marketing principles was obvious: no. Just look at the ways in which everything under the sun has been marketed; obviously it need not be done in a principled (=ethical) fashion. Is that obvious? I made the suggestion, which may sound downright crazy in light of the evidence, that perhaps marketing is by definition principled. My inspiration for this judgement is the philosopher Immanuel Kant, who argued that any body of knowledge consists of an end (or purpose) and a means. Let us apply both the terms means and end to marketing. The students have signed up for a course in order to learn how to market effectively. But to what end? There seem to be two main attitudes toward that question. One is that the answer is obvious: the purpose of marketing is to sell things and to make money. The other attitude is that the purpose of marketing is irrelevant: Each person comes to the program and course with his or her own plans, and these need not even concern the acquisition of marketing expertise as such. My proposal, which I believe would also be Kants, is that neither of these attitudes captures the significance of the end to the means for marketing. A field of knowledge or a professional endeavor is defined by both the means and the end; hence both deserve scrutiny. Students need to study both how to achieve X, and also what X is. It is at this point that Arson for Profit becomes supremely relevant. That course is presumably all about means: how to detect and prosecute criminal activity. It is therefore assumed that the end is good in an ethical sense. When I ask fire science students to articulate the end, or purpose, of their field, they eventually generalize to something like, The safety and welfare of society, which seems right. As we have seen, someone could use the very same knowledge of means to achieve a much less noble end, such as personal profit via destructive, dangerous, reckless activity. But we would not call that firefighting. We have a separate word for it: arson. Similarly, if you employed the principles of marketing in an unprincipled way, you would not be doing marketing. We have another term for it: fraud. Kant gives the example of a doctor and a poisoner, who use the identical knowledge to achieve their divergent ends. We would say that one is practicing medicine, the other, murder.", "hypothesis": "It is difficult to attract students onto courses that do no focus on a career.", "gold_label": "neutral"}
{"uid": "id_550", "premise": "When Christianity was first established by law, a corrupt form of Latin had become the common language of all the western parts of Europe. The service of the Church accordingly, and the translation of the Bible which was read in churches, were both in that corrupted Latin which was the common language of the country. After the fall of the Roman Empire, Latin gradually ceased to be the language of any part of Europe. However, although Latin was no longer understood anywhere by the great body of the people, Church services still continued to be performed in that language. Two different languages were thus established in Europe: a language of the priests and a language of the people.", "hypothesis": "Latin continued to be used in church services because of the continuing influence of Rome.", "gold_label": "contradiction"}
{"uid": "id_551", "premise": "When Christianity was first established by law, a corrupt form of Latin had become the common language of all the western parts of Europe. The service of the Church accordingly, and the translation of the Bible which was read in churches, were both in that corrupted Latin which was the common language of the country. After the fall of the Roman Empire, Latin gradually ceased to be the language of any part of Europe. However, although Latin was no longer understood anywhere by the great body of the people, Church services still continued to be performed in that language. Two different languages were thus established in Europe: a language of the priests and a language of the people.", "hypothesis": "Priests spoke a different language from the common people.", "gold_label": "entailment"}
{"uid": "id_552", "premise": "When Christianity was first established by law, a corrupt form of Latin had become the common language of all the western parts of Europe. The service of the Church accordingly, and the translation of the Bible which was read in churches, were both in that corrupted Latin which was the common language of the country. After the fall of the Roman Empire, Latin gradually ceased to be the language of any part of Europe. However, although Latin was no longer understood anywhere by the great body of the people, Church services still continued to be performed in that language. Two different languages were thus established in Europe: a language of the priests and a language of the people.", "hypothesis": "After the fall of the Roman Empire, people who had previously spoken Latin returned to their original languages.", "gold_label": "neutral"}
{"uid": "id_553", "premise": "When Christianity was first established by law, a corrupt form of Latin had become the common language of all the western parts of Europe. The service of the Church accordingly, and the translation of the Bible which was read in churches, were both in that corrupted Latin which was the common language of the country. After the fall of the Roman Empire, Latin gradually ceased to be the language of any part of Europe. However, although Latin was no longer understood anywhere by the great body of the people, Church services still continued to be performed in that language. Two different languages were thus established in Europe: a language of the priests and a language of the people.", "hypothesis": "Prior to the fall of the Roman Empire, Latin had been established by law as the language of the Church in Western Europe.", "gold_label": "neutral"}
{"uid": "id_554", "premise": "When any company moves from a sales to a marketing approach, it is not just a case of re-titling the Sales Director as Marketing Director and doubling the advertising budget. It requires a complete reorientation in thinking and a revolution in how a company organises and practises its business activities. whereas selling focuses on the needs of the seller, marketing focuses on the needs of the buyer. Whereas selling is preoccupied with the seller s need to convert his or her product into cash, marketing is preoccupied with the idea of identifying and hence satisfying the needs of the customer. However, subscribing to a philosophy of marketing, even though an important first step, is not the same as putting that philosophy into practice.", "hypothesis": "Advertising budgets are normally doubled when a company moves over to a marketing approach.", "gold_label": "neutral"}
{"uid": "id_555", "premise": "When any company moves from a sales to a marketing approach, it is not just a case of re-titling the Sales Director as Marketing Director and doubling the advertising budget. It requires a complete reorientation in thinking and a revolution in how a company organizes and practices its business activities. Whereas selling focuses on the needs of the seller, marketing focuses on the needs of the buyer. Whereas selling is preoccupied with the sellers need to convert his or her product into cash, marketing is preoccupied with the idea of identifying and hence satisfying the needs of the customer. However, subscribing to a philosophy of marketing, even though an important first step, is not the same as putting that philosophy into practice.", "hypothesis": "Advertising budgets are normally doubled when a company moves over to a marketing approach.", "gold_label": "neutral"}
{"uid": "id_556", "premise": "When conversations flow We spend a large part of our daily life talking with other people and, consequently, we are very accustomed to the art of conversing. But why do we feel comfortable in conversations that have flow, but get nervous and distressed when a conversation is interrupted by unexpected silences? To answer this question we will first look at some of the effects of conversational flow. Then we will explain how flow can serve different social needs. The positive consequences of conversational flow show some similarities with the effects of processing fluency. Research has shown that processing fluency the ease with which people process information influences peoples judgments across a broad range of social dimensions. For instance, people feel that when something is easily processed, it is more true or accurate. Moreover, they have more confidence in their judgments regarding information that came to them fluently, and they like things that are easy to process more than things that are difficult to process. Research indicates that a speaker is judged to be more knowledgeable when they answer questions instantly; responding with disfluent speech markers such as uh or urn or simply remaining silent for a moment too long can destroy that positive image. One of the social needs addressed by conversational flow is the human need for synchrony to be in sync or in harmony with one another. Many studies have shown how people attempt to synchronize with their partners, by coordinating their behavior. This interpersonal coordination underlies a wide array of human activities, ranging from more complicated ones like ballroom dancing to simply walking or talking with friends. In conversations, interpersonal coordination is found when people adjust the duration of their utterances and their speech rate to one another so that they can enable turn-taking to occur, without talking over each other or experiencing awkward silences. Since people are very well-trained in having conversations, they are often able to take turns within milliseconds, resulting in a conversational flow of smoothly meshed behaviors. A lack of flow is characterized by interruptions, simultaneous speech or mutual silences. Avoiding these features is important for defining and maintaining interpersonal relationships. The need to belong has been identified as one of the most basic of human motivations and plays a role in many human behaviors. That conversational flow is related to belonging may be most easily illustrated by the consequences of flow disruptions. What happens when the positive experience of flow is disrupted by, for instance, a brief silence? We all know that silences can be pretty awkward, and research shows that even short disruptions in conversational flow can lead to a sharp rise in distress levels. In movies, silences are often used to signal non-compliance or confrontation (Piazza, 2006). Some researchers even argue that silencing someone is one of the most serious forms of exclusion. Group membership is of elementary importance to our wellbeing and because humans are very sensitive to signals of exclusion, a silence is generally taken as a sign of rejection. In this way, a lack of flow in a conversation may signal that our relationship is not as solid as we thought it was. Another aspect of synchrony is that people often try to validate their opinions to those of others. That is, people like to see others as having similar ideas or worldviews as they have themselves, because this informs people that they are correct and their worldviews are justified. One way in which people can justify their worldviews is by assuming that, as long as their conversations run smoothly, their interaction partners probably agree with them. This idea was tested by researchers using video observations. Participants imagined being one out of three people in a video clip who had either a fluent conversation or a conversation in which flow was disrupted by a brief silence. Except for the silence, the videos were identical. After watching the video, participants were asked to what extent the people in the video agreed with each other. Participants who watched the fluent conversation rated agreement to be higher than participants watching the conversation that was disrupted by a silence, even though participants were not consciously aware of the disruption. It appears that the subjective feeling of being out of sync informs people of possible disagreements, regardless of the content of the conversation. Because people are generally so well- trained in having smooth conversations, any disruption of this flow indicates that something is wrong, either interpersonally or within the group as a whole. Consequently, people who do not talk very easily may be incorrectly understood as being less agreeable than those who have no difficulty keeping up a conversation. On a societal level, one could even imagine that a lack of conversational flow may hamper the integration of immigrants who have not completely mastered the language of their new country yet. In a similar sense, the ever- increasing number of online conversations may be disrupted by misinterpretations and anxiety that are produced by insuperable delays in the Internet connection. Keeping in mind the effects of conversational flow for feelings of belonging and validation may help one to be prepared to avoid such misunderstandings in future conversations.", "hypothesis": "People assess information according to how readily they can understand it.", "gold_label": "entailment"}
{"uid": "id_557", "premise": "When conversations flow We spend a large part of our daily life talking with other people and, consequently, we are very accustomed to the art of conversing. But why do we feel comfortable in conversations that have flow, but get nervous and distressed when a conversation is interrupted by unexpected silences? To answer this question we will first look at some of the effects of conversational flow. Then we will explain how flow can serve different social needs. The positive consequences of conversational flow show some similarities with the effects of processing fluency. Research has shown that processing fluency the ease with which people process information influences peoples judgments across a broad range of social dimensions. For instance, people feel that when something is easily processed, it is more true or accurate. Moreover, they have more confidence in their judgments regarding information that came to them fluently, and they like things that are easy to process more than things that are difficult to process. Research indicates that a speaker is judged to be more knowledgeable when they answer questions instantly; responding with disfluent speech markers such as uh or urn or simply remaining silent for a moment too long can destroy that positive image. One of the social needs addressed by conversational flow is the human need for synchrony to be in sync or in harmony with one another. Many studies have shown how people attempt to synchronize with their partners, by coordinating their behavior. This interpersonal coordination underlies a wide array of human activities, ranging from more complicated ones like ballroom dancing to simply walking or talking with friends. In conversations, interpersonal coordination is found when people adjust the duration of their utterances and their speech rate to one another so that they can enable turn-taking to occur, without talking over each other or experiencing awkward silences. Since people are very well-trained in having conversations, they are often able to take turns within milliseconds, resulting in a conversational flow of smoothly meshed behaviors. A lack of flow is characterized by interruptions, simultaneous speech or mutual silences. Avoiding these features is important for defining and maintaining interpersonal relationships. The need to belong has been identified as one of the most basic of human motivations and plays a role in many human behaviors. That conversational flow is related to belonging may be most easily illustrated by the consequences of flow disruptions. What happens when the positive experience of flow is disrupted by, for instance, a brief silence? We all know that silences can be pretty awkward, and research shows that even short disruptions in conversational flow can lead to a sharp rise in distress levels. In movies, silences are often used to signal non-compliance or confrontation (Piazza, 2006). Some researchers even argue that silencing someone is one of the most serious forms of exclusion. Group membership is of elementary importance to our wellbeing and because humans are very sensitive to signals of exclusion, a silence is generally taken as a sign of rejection. In this way, a lack of flow in a conversation may signal that our relationship is not as solid as we thought it was. Another aspect of synchrony is that people often try to validate their opinions to those of others. That is, people like to see others as having similar ideas or worldviews as they have themselves, because this informs people that they are correct and their worldviews are justified. One way in which people can justify their worldviews is by assuming that, as long as their conversations run smoothly, their interaction partners probably agree with them. This idea was tested by researchers using video observations. Participants imagined being one out of three people in a video clip who had either a fluent conversation or a conversation in which flow was disrupted by a brief silence. Except for the silence, the videos were identical. After watching the video, participants were asked to what extent the people in the video agreed with each other. Participants who watched the fluent conversation rated agreement to be higher than participants watching the conversation that was disrupted by a silence, even though participants were not consciously aware of the disruption. It appears that the subjective feeling of being out of sync informs people of possible disagreements, regardless of the content of the conversation. Because people are generally so well- trained in having smooth conversations, any disruption of this flow indicates that something is wrong, either interpersonally or within the group as a whole. Consequently, people who do not talk very easily may be incorrectly understood as being less agreeable than those who have no difficulty keeping up a conversation. On a societal level, one could even imagine that a lack of conversational flow may hamper the integration of immigrants who have not completely mastered the language of their new country yet. In a similar sense, the ever- increasing number of online conversations may be disrupted by misinterpretations and anxiety that are produced by insuperable delays in the Internet connection. Keeping in mind the effects of conversational flow for feelings of belonging and validation may help one to be prepared to avoid such misunderstandings in future conversations.", "hypothesis": "Delays in online chat fail to have the same negative effect as disruptions that occur in natural conversation.", "gold_label": "contradiction"}
{"uid": "id_558", "premise": "When conversations flow We spend a large part of our daily life talking with other people and, consequently, we are very accustomed to the art of conversing. But why do we feel comfortable in conversations that have flow, but get nervous and distressed when a conversation is interrupted by unexpected silences? To answer this question we will first look at some of the effects of conversational flow. Then we will explain how flow can serve different social needs. The positive consequences of conversational flow show some similarities with the effects of processing fluency. Research has shown that processing fluency the ease with which people process information influences peoples judgments across a broad range of social dimensions. For instance, people feel that when something is easily processed, it is more true or accurate. Moreover, they have more confidence in their judgments regarding information that came to them fluently, and they like things that are easy to process more than things that are difficult to process. Research indicates that a speaker is judged to be more knowledgeable when they answer questions instantly; responding with disfluent speech markers such as uh or urn or simply remaining silent for a moment too long can destroy that positive image. One of the social needs addressed by conversational flow is the human need for synchrony to be in sync or in harmony with one another. Many studies have shown how people attempt to synchronize with their partners, by coordinating their behavior. This interpersonal coordination underlies a wide array of human activities, ranging from more complicated ones like ballroom dancing to simply walking or talking with friends. In conversations, interpersonal coordination is found when people adjust the duration of their utterances and their speech rate to one another so that they can enable turn-taking to occur, without talking over each other or experiencing awkward silences. Since people are very well-trained in having conversations, they are often able to take turns within milliseconds, resulting in a conversational flow of smoothly meshed behaviors. A lack of flow is characterized by interruptions, simultaneous speech or mutual silences. Avoiding these features is important for defining and maintaining interpersonal relationships. The need to belong has been identified as one of the most basic of human motivations and plays a role in many human behaviors. That conversational flow is related to belonging may be most easily illustrated by the consequences of flow disruptions. What happens when the positive experience of flow is disrupted by, for instance, a brief silence? We all know that silences can be pretty awkward, and research shows that even short disruptions in conversational flow can lead to a sharp rise in distress levels. In movies, silences are often used to signal non-compliance or confrontation (Piazza, 2006). Some researchers even argue that silencing someone is one of the most serious forms of exclusion. Group membership is of elementary importance to our wellbeing and because humans are very sensitive to signals of exclusion, a silence is generally taken as a sign of rejection. In this way, a lack of flow in a conversation may signal that our relationship is not as solid as we thought it was. Another aspect of synchrony is that people often try to validate their opinions to those of others. That is, people like to see others as having similar ideas or worldviews as they have themselves, because this informs people that they are correct and their worldviews are justified. One way in which people can justify their worldviews is by assuming that, as long as their conversations run smoothly, their interaction partners probably agree with them. This idea was tested by researchers using video observations. Participants imagined being one out of three people in a video clip who had either a fluent conversation or a conversation in which flow was disrupted by a brief silence. Except for the silence, the videos were identical. After watching the video, participants were asked to what extent the people in the video agreed with each other. Participants who watched the fluent conversation rated agreement to be higher than participants watching the conversation that was disrupted by a silence, even though participants were not consciously aware of the disruption. It appears that the subjective feeling of being out of sync informs people of possible disagreements, regardless of the content of the conversation. Because people are generally so well- trained in having smooth conversations, any disruption of this flow indicates that something is wrong, either interpersonally or within the group as a whole. Consequently, people who do not talk very easily may be incorrectly understood as being less agreeable than those who have no difficulty keeping up a conversation. On a societal level, one could even imagine that a lack of conversational flow may hamper the integration of immigrants who have not completely mastered the language of their new country yet. In a similar sense, the ever- increasing number of online conversations may be disrupted by misinterpretations and anxiety that are produced by insuperable delays in the Internet connection. Keeping in mind the effects of conversational flow for feelings of belonging and validation may help one to be prepared to avoid such misunderstandings in future conversations.", "hypothesis": "People who talk less often have clearer ideas than those who talk a lot.", "gold_label": "neutral"}
{"uid": "id_559", "premise": "When conversations flow We spend a large part of our daily life talking with other people and, consequently, we are very accustomed to the art of conversing. But why do we feel comfortable in conversations that have flow, but get nervous and distressed when a conversation is interrupted by unexpected silences? To answer this question we will first look at some of the effects of conversational flow. Then we will explain how flow can serve different social needs. The positive consequences of conversational flow show some similarities with the effects of processing fluency. Research has shown that processing fluency the ease with which people process information influences peoples judgments across a broad range of social dimensions. For instance, people feel that when something is easily processed, it is more true or accurate. Moreover, they have more confidence in their judgments regarding information that came to them fluently, and they like things that are easy to process more than things that are difficult to process. Research indicates that a speaker is judged to be more knowledgeable when they answer questions instantly; responding with disfluent speech markers such as uh or urn or simply remaining silent for a moment too long can destroy that positive image. One of the social needs addressed by conversational flow is the human need for synchrony to be in sync or in harmony with one another. Many studies have shown how people attempt to synchronize with their partners, by coordinating their behavior. This interpersonal coordination underlies a wide array of human activities, ranging from more complicated ones like ballroom dancing to simply walking or talking with friends. In conversations, interpersonal coordination is found when people adjust the duration of their utterances and their speech rate to one another so that they can enable turn-taking to occur, without talking over each other or experiencing awkward silences. Since people are very well-trained in having conversations, they are often able to take turns within milliseconds, resulting in a conversational flow of smoothly meshed behaviors. A lack of flow is characterized by interruptions, simultaneous speech or mutual silences. Avoiding these features is important for defining and maintaining interpersonal relationships. The need to belong has been identified as one of the most basic of human motivations and plays a role in many human behaviors. That conversational flow is related to belonging may be most easily illustrated by the consequences of flow disruptions. What happens when the positive experience of flow is disrupted by, for instance, a brief silence? We all know that silences can be pretty awkward, and research shows that even short disruptions in conversational flow can lead to a sharp rise in distress levels. In movies, silences are often used to signal non-compliance or confrontation (Piazza, 2006). Some researchers even argue that silencing someone is one of the most serious forms of exclusion. Group membership is of elementary importance to our wellbeing and because humans are very sensitive to signals of exclusion, a silence is generally taken as a sign of rejection. In this way, a lack of flow in a conversation may signal that our relationship is not as solid as we thought it was. Another aspect of synchrony is that people often try to validate their opinions to those of others. That is, people like to see others as having similar ideas or worldviews as they have themselves, because this informs people that they are correct and their worldviews are justified. One way in which people can justify their worldviews is by assuming that, as long as their conversations run smoothly, their interaction partners probably agree with them. This idea was tested by researchers using video observations. Participants imagined being one out of three people in a video clip who had either a fluent conversation or a conversation in which flow was disrupted by a brief silence. Except for the silence, the videos were identical. After watching the video, participants were asked to what extent the people in the video agreed with each other. Participants who watched the fluent conversation rated agreement to be higher than participants watching the conversation that was disrupted by a silence, even though participants were not consciously aware of the disruption. It appears that the subjective feeling of being out of sync informs people of possible disagreements, regardless of the content of the conversation. Because people are generally so well- trained in having smooth conversations, any disruption of this flow indicates that something is wrong, either interpersonally or within the group as a whole. Consequently, people who do not talk very easily may be incorrectly understood as being less agreeable than those who have no difficulty keeping up a conversation. On a societal level, one could even imagine that a lack of conversational flow may hamper the integration of immigrants who have not completely mastered the language of their new country yet. In a similar sense, the ever- increasing number of online conversations may be disrupted by misinterpretations and anxiety that are produced by insuperable delays in the Internet connection. Keeping in mind the effects of conversational flow for feelings of belonging and validation may help one to be prepared to avoid such misunderstandings in future conversations.", "hypothesis": "Video observations have often been used to assess conversational flow.", "gold_label": "neutral"}
{"uid": "id_560", "premise": "When conversations flow We spend a large part of our daily life talking with other people and, consequently, we are very accustomed to the art of conversing. But why do we feel comfortable in conversations that have flow, but get nervous and distressed when a conversation is interrupted by unexpected silences? To answer this question we will first look at some of the effects of conversational flow. Then we will explain how flow can serve different social needs. The positive consequences of conversational flow show some similarities with the effects of processing fluency. Research has shown that processing fluency the ease with which people process information influences peoples judgments across a broad range of social dimensions. For instance, people feel that when something is easily processed, it is more true or accurate. Moreover, they have more confidence in their judgments regarding information that came to them fluently, and they like things that are easy to process more than things that are difficult to process. Research indicates that a speaker is judged to be more knowledgeable when they answer questions instantly; responding with disfluent speech markers such as uh or urn or simply remaining silent for a moment too long can destroy that positive image. One of the social needs addressed by conversational flow is the human need for synchrony to be in sync or in harmony with one another. Many studies have shown how people attempt to synchronize with their partners, by coordinating their behavior. This interpersonal coordination underlies a wide array of human activities, ranging from more complicated ones like ballroom dancing to simply walking or talking with friends. In conversations, interpersonal coordination is found when people adjust the duration of their utterances and their speech rate to one another so that they can enable turn-taking to occur, without talking over each other or experiencing awkward silences. Since people are very well-trained in having conversations, they are often able to take turns within milliseconds, resulting in a conversational flow of smoothly meshed behaviors. A lack of flow is characterized by interruptions, simultaneous speech or mutual silences. Avoiding these features is important for defining and maintaining interpersonal relationships. The need to belong has been identified as one of the most basic of human motivations and plays a role in many human behaviors. That conversational flow is related to belonging may be most easily illustrated by the consequences of flow disruptions. What happens when the positive experience of flow is disrupted by, for instance, a brief silence? We all know that silences can be pretty awkward, and research shows that even short disruptions in conversational flow can lead to a sharp rise in distress levels. In movies, silences are often used to signal non-compliance or confrontation (Piazza, 2006). Some researchers even argue that silencing someone is one of the most serious forms of exclusion. Group membership is of elementary importance to our wellbeing and because humans are very sensitive to signals of exclusion, a silence is generally taken as a sign of rejection. In this way, a lack of flow in a conversation may signal that our relationship is not as solid as we thought it was. Another aspect of synchrony is that people often try to validate their opinions to those of others. That is, people like to see others as having similar ideas or worldviews as they have themselves, because this informs people that they are correct and their worldviews are justified. One way in which people can justify their worldviews is by assuming that, as long as their conversations run smoothly, their interaction partners probably agree with them. This idea was tested by researchers using video observations. Participants imagined being one out of three people in a video clip who had either a fluent conversation or a conversation in which flow was disrupted by a brief silence. Except for the silence, the videos were identical. After watching the video, participants were asked to what extent the people in the video agreed with each other. Participants who watched the fluent conversation rated agreement to be higher than participants watching the conversation that was disrupted by a silence, even though participants were not consciously aware of the disruption. It appears that the subjective feeling of being out of sync informs people of possible disagreements, regardless of the content of the conversation. Because people are generally so well- trained in having smooth conversations, any disruption of this flow indicates that something is wrong, either interpersonally or within the group as a whole. Consequently, people who do not talk very easily may be incorrectly understood as being less agreeable than those who have no difficulty keeping up a conversation. On a societal level, one could even imagine that a lack of conversational flow may hamper the integration of immigrants who have not completely mastered the language of their new country yet. In a similar sense, the ever- increasing number of online conversations may be disrupted by misinterpretations and anxiety that are produced by insuperable delays in the Internet connection. Keeping in mind the effects of conversational flow for feelings of belonging and validation may help one to be prepared to avoid such misunderstandings in future conversations.", "hypothesis": "A quick response to a question is thought to show a lack of knowledge.", "gold_label": "contradiction"}
{"uid": "id_561", "premise": "When conversations flow We spend a large part of our daily life talking with other people and, consequently, we are very accustomed to the art of conversing. But why do we feel comfortable in conversations that have flow, but get nervous and distressed when a conversation is interrupted by unexpected silences? To answer this question we will first look at some of the effects of conversational flow. Then we will explain how flow can serve different social needs. The positive consequences of conversational flow show some similarities with the effects of processing fluency. Research has shown that processing fluency the ease with which people process information influences peoples judgments across a broad range of social dimensions. For instance, people feel that when something is easily processed, it is more true or accurate. Moreover, they have more confidence in their judgments regarding information that came to them fluently, and they like things that are easy to process more than things that are difficult to process. Research indicates that a speaker is judged to be more knowledgeable when they answer questions instantly; responding with disfluent speech markers such as uh or urn or simply remaining silent for a moment too long can destroy that positive image. One of the social needs addressed by conversational flow is the human need for synchrony to be in sync or in harmony with one another. Many studies have shown how people attempt to synchronize with their partners, by coordinating their behavior. This interpersonal coordination underlies a wide array of human activities, ranging from more complicated ones like ballroom dancing to simply walking or talking with friends. In conversations, interpersonal coordination is found when people adjust the duration of their utterances and their speech rate to one another so that they can enable turn-taking to occur, without talking over each other or experiencing awkward silences. Since people are very well-trained in having conversations, they are often able to take turns within milliseconds, resulting in a conversational flow of smoothly meshed behaviors. A lack of flow is characterized by interruptions, simultaneous speech or mutual silences. Avoiding these features is important for defining and maintaining interpersonal relationships. The need to belong has been identified as one of the most basic of human motivations and plays a role in many human behaviors. That conversational flow is related to belonging may be most easily illustrated by the consequences of flow disruptions. What happens when the positive experience of flow is disrupted by, for instance, a brief silence? We all know that silences can be pretty awkward, and research shows that even short disruptions in conversational flow can lead to a sharp rise in distress levels. In movies, silences are often used to signal non-compliance or confrontation (Piazza, 2006). Some researchers even argue that silencing someone is one of the most serious forms of exclusion. Group membership is of elementary importance to our wellbeing and because humans are very sensitive to signals of exclusion, a silence is generally taken as a sign of rejection. In this way, a lack of flow in a conversation may signal that our relationship is not as solid as we thought it was. Another aspect of synchrony is that people often try to validate their opinions to those of others. That is, people like to see others as having similar ideas or worldviews as they have themselves, because this informs people that they are correct and their worldviews are justified. One way in which people can justify their worldviews is by assuming that, as long as their conversations run smoothly, their interaction partners probably agree with them. This idea was tested by researchers using video observations. Participants imagined being one out of three people in a video clip who had either a fluent conversation or a conversation in which flow was disrupted by a brief silence. Except for the silence, the videos were identical. After watching the video, participants were asked to what extent the people in the video agreed with each other. Participants who watched the fluent conversation rated agreement to be higher than participants watching the conversation that was disrupted by a silence, even though participants were not consciously aware of the disruption. It appears that the subjective feeling of being out of sync informs people of possible disagreements, regardless of the content of the conversation. Because people are generally so well- trained in having smooth conversations, any disruption of this flow indicates that something is wrong, either interpersonally or within the group as a whole. Consequently, people who do not talk very easily may be incorrectly understood as being less agreeable than those who have no difficulty keeping up a conversation. On a societal level, one could even imagine that a lack of conversational flow may hamper the integration of immigrants who have not completely mastered the language of their new country yet. In a similar sense, the ever- increasing number of online conversations may be disrupted by misinterpretations and anxiety that are produced by insuperable delays in the Internet connection. Keeping in mind the effects of conversational flow for feelings of belonging and validation may help one to be prepared to avoid such misunderstandings in future conversations.", "hypothesis": "Conversation occupies much of our time.", "gold_label": "entailment"}
{"uid": "id_562", "premise": "When discussing his famous character Rorschach, the antihero of Watchmen, Moore explains, I originally intended Rorschach to be a warning about the possible outcome of vigilante thinking. But an awful lot of comic readers felt his remorseless, frightening, psychotic toughness was his most appealing characteristic not quite what I was going for. Moore misunderstands his own heros appeal within this quotation: it is not that Rorschach is willing to break little fingers to extract information, or that he is happy to use violence, that makes him laudable. The Comedian, another superhero within the alternative world of Watchmen, is a thug who has won no great fan base; his remorselessness (killing a pregnant Vietnamese woman), frightening (attempt at rape), psychotic toughness (one only has to look at the panels of him shooting out into a crowd to witness this) is repulsive, not winning. This is because The Comedian has no purpose: he is a nihilist, and as a nihilist, denies any potential meaning to his fellow man, and so to the comics reader. Everything to him is a joke, including his self, and consequently his own death could be seen as just another gag. Rorschach, on the other hand, does believe in something: he questions if his fight for justice is futile? then instantly corrects himself, stating there is good and evil, and evil must be punished. Even in the face of Armageddon I shall not compromise in this. Jacob Held, in his essay comparing Rorschachs motivation with Kantian ethics, put forward the postulation perhaps our dignity is found in acting as if the world were just, even when it is clearly not. Rorschach then causes pain in others not because he is a sadist, but because he feels the need to punish wrong and to uphold the good, and though he cannot make the world just, he can act according to his sense of justice - through the use of violence.", "hypothesis": "The Comedian is a misnomer - the character that goes by this title should not, logically, be called this.", "gold_label": "contradiction"}
{"uid": "id_563", "premise": "When each year an average of 500,000 immigrants entered the country the Home Office calculated that the fiscal benefit of this level of inward migration was 2.5 billion a year. This calculation was used extensively by the government of the day to support their immigration policies. The findings of the Home Office stood out against the findings of other western nations which found the benefits of large-scale inward migration to be so small as to be close to zero. The difference in the findings arose because the Home Office figure was based only on the effect of inward migration on the country's total Gross Domestic Product (GDP), while the other studies measured the effect on GDP per head. However, the Home Office calculation was obviously flawed, and they have since stopped using it, because immigration manifestly increases both the total GDP and the population. While the overall effect of inward migration may be negligible nationally in fiscal terms, the indigenous low paid and low skilled stand to lose out because as a consequence of the inward migration they face greater competition for work. Some employers have much to gain from the improved supply of labour and savings made from not having to train young people.", "hypothesis": "The authors intended meaning when he wrote However, the Home Office calculation was obviously flawed, and they have since stopped using it, because immigration manifestly increases both the total GDP and the population would be better served if instead of immigration he wrote inward migration.", "gold_label": "entailment"}
{"uid": "id_564", "premise": "When each year an average of 500,000 immigrants entered the country the Home Office calculated that the fiscal benefit of this level of inward migration was 2.5 billion a year. This calculation was used extensively by the government of the day to support their immigration policies. The findings of the Home Office stood out against the findings of other western nations which found the benefits of large-scale inward migration to be so small as to be close to zero. The difference in the findings arose because the Home Office figure was based only on the effect of inward migration on the country's total Gross Domestic Product (GDP), while the other studies measured the effect on GDP per head. However, the Home Office calculation was obviously flawed, and they have since stopped using it, because immigration manifestly increases both the total GDP and the population. While the overall effect of inward migration may be negligible nationally in fiscal terms, the indigenous low paid and low skilled stand to lose out because as a consequence of the inward migration they face greater competition for work. Some employers have much to gain from the improved supply of labour and savings made from not having to train young people.", "hypothesis": "There are no clear winners in an economy experiencing large-scale inward migration.", "gold_label": "contradiction"}
{"uid": "id_565", "premise": "When each year an average of 500,000 immigrants entered the country the Home Office calculated that the fiscal benefit of this level of inward migration was 2.5 billion a year. This calculation was used extensively by the government of the day to support their immigration policies. The findings of the Home Office stood out against the findings of other western nations which found the benefits of large-scale inward migration to be so small as to be close to zero. The difference in the findings arose because the Home Office figure was based only on the effect of inward migration on the country's total Gross Domestic Product (GDP), while the other studies measured the effect on GDP per head. However, the Home Office calculation was obviously flawed, and they have since stopped using it, because immigration manifestly increases both the total GDP and the population. While the overall effect of inward migration may be negligible nationally in fiscal terms, the indigenous low paid and low skilled stand to lose out because as a consequence of the inward migration they face greater competition for work. Some employers have much to gain from the improved supply of labour and savings made from not having to train young people.", "hypothesis": "It is no longer the case that half a million immigrants enter the country.", "gold_label": "entailment"}
{"uid": "id_566", "premise": "When evolution runs backwards Evolution isnt supposed to run backwards - yet an increasing number of examples show that it does and that it can sometimes represent the future of a species. The description of any animal as an evolutionary throwback is controversial. For the better part of a century, most biologists have been reluctant to use those words, mindful of a principle of evolution that says evolution cannot run backwards. But as more and more examples come to light and modern genetics enters the scene, that principle is having to be rewritten. Not only are evolutionary throwbacks possible, they sometimes play an important role in the forward march of evolution. The technical term for an evolutionary throwback is an atavism, from the Latin atavus, meaning forefather. The word has ugly connotations thanks largely to Cesare Lombroso, a 19th-century Italian medic who argued that criminals were born not made and could be identified by certain physical features that were throwbacks to a primitive, sub-human state. While Lombroso was measuring criminals, a Belgian palaeontologist called Louis Dollo was studying fossil records and coming to the opposite conclusion. In 1890 he proposed that evolution was irreversible: that an organism is unable to return, even partially, to a previous stage already realised in the ranks of its ancestors. Early 20th-century biologists came to a similar conclusion, though they qualified it in terms of probability, stating that there is no reason why evolution cannot run backwards -it is just very unlikely. And so the idea of irreversibility in evolution stuck and came to be known as Dollos law. If Dollos law is right, atavisms should occur only very rarely, if at all. Yet almost since the idea took root, exceptions have been cropping up. In 1919, for example, a humpback whale with a pair of leglike appendages over a metre long, complete with a full set of limb bones, was caught off Vancouver Island in Canada. Explorer Roy Chapman Andrews argued at the time that the whale must be a throwback to a land-living ancestor. I can see no other explanation, he wrote in 1921. Since then, so many other examples have been discovered that it no longer makes sense to say that evolution is as good as irreversible. And this poses a puzzle: how can characteristics that disappeared millions of years ago suddenly reappear? In 1994, Rudolf Raff and colleagues at Indiana University in the USA decided to use genetics to put a number on the probability of evolution going into reverse. They reasoned that while some evolutionary changes involve the loss of genes and are therefore irreversible, others may be the result of genes being switched off. If these silent genes are somehow switched back on, they argued, longlost traits could reappear. Raffs team went on to calculate the likelihood of it happening. Silent genes accumulate random mutations, they reasoned, eventually rendering them useless. So how long can a gene survive in a species if it is no longer used? The team calculated that there is a good chance of silent genes surviving for up to 6 million years in at least a few individuals in a population, and that some might survive as long as 10 million years. In other words, throwbacks are possible, but only to the relatively recent evolutionary past. As a possible example, the team pointed to the mole salamanders of Mexico and California. Like most amphibians these begin life in a juvenile tadpole state, then metamorphose into the adult form except for one species, the axolotl, which famously lives its entire life as a juvenile. The simplest explanation for this is that the axolotl lineage alone lost the ability to metamorphose, while others retained it. From a detailed analysis of the salamanders family tree, however, it is clear that the other lineages evolved from an ancestor that itself had lost the ability to metamorphose. In other words, metamorphosis in mole salamanders is an atavism. The salamander example fits with Raffs 10million-year time frame. 82More recently, however, examples have been reported that break the time limit, suggesting that silent genes may not be the whole story. In a paper published last year, biologist Gunter Wagner of Yale University reported some work on the evolutionary history of a group of South American lizards called Bachia. Many of these have minuscule limbs; some look more like snakes than lizards and a few have completely lost the toes on their hind limbs. Other species, however, sport up to four toes on their hind legs. The simplest explanation is that the toed lineages never lost their toes, but Wagner begs to differ. According to his analysis of the Bachia family tree, the toed species re-evolved toes from toeless ancestors and, what is more, digit loss and gain has occurred on more than one occasion over tens of millions of years. So whats going on? One possibility is that these traits are lost and then simply reappear, in much the same way that similar structures can independently arise in unrelated species, such as the dorsal fins of sharks and killer whales. Another more intriguing possibility is that the genetic information needed to make toes somehow survived for tens or perhaps hundreds of millions of years in the lizards and was reactivated. These atavistic traits provided an advantage and spread through the population, effectively reversing evolution. But if silent genes degrade within 6 to million years, how can long-lost traits be reactivated over longer timescales? The answer may lie in the womb. Early embryos of many species develop ancestral features. Snake embryos, for example, sprout hind limb buds. Later in development these features disappear thanks to developmental programs that say lose the leg. If for any reason this does not happen, the ancestral feature may not disappear, leading to an atavism.", "hypothesis": "Evolutionary throwbacks might be caused by developmental problems in the womb.", "gold_label": "entailment"}
{"uid": "id_567", "premise": "When evolution runs backwards Evolution isnt supposed to run backwards - yet an increasing number of examples show that it does and that it can sometimes represent the future of a species. The description of any animal as an evolutionary throwback is controversial. For the better part of a century, most biologists have been reluctant to use those words, mindful of a principle of evolution that says evolution cannot run backwards. But as more and more examples come to light and modern genetics enters the scene, that principle is having to be rewritten. Not only are evolutionary throwbacks possible, they sometimes play an important role in the forward march of evolution. The technical term for an evolutionary throwback is an atavism, from the Latin atavus, meaning forefather. The word has ugly connotations thanks largely to Cesare Lombroso, a 19th-century Italian medic who argued that criminals were born not made and could be identified by certain physical features that were throwbacks to a primitive, sub-human state. While Lombroso was measuring criminals, a Belgian palaeontologist called Louis Dollo was studying fossil records and coming to the opposite conclusion. In 1890 he proposed that evolution was irreversible: that an organism is unable to return, even partially, to a previous stage already realised in the ranks of its ancestors. Early 20th-century biologists came to a similar conclusion, though they qualified it in terms of probability, stating that there is no reason why evolution cannot run backwards -it is just very unlikely. And so the idea of irreversibility in evolution stuck and came to be known as Dollos law. If Dollos law is right, atavisms should occur only very rarely, if at all. Yet almost since the idea took root, exceptions have been cropping up. In 1919, for example, a humpback whale with a pair of leglike appendages over a metre long, complete with a full set of limb bones, was caught off Vancouver Island in Canada. Explorer Roy Chapman Andrews argued at the time that the whale must be a throwback to a land-living ancestor. I can see no other explanation, he wrote in 1921. Since then, so many other examples have been discovered that it no longer makes sense to say that evolution is as good as irreversible. And this poses a puzzle: how can characteristics that disappeared millions of years ago suddenly reappear? In 1994, Rudolf Raff and colleagues at Indiana University in the USA decided to use genetics to put a number on the probability of evolution going into reverse. They reasoned that while some evolutionary changes involve the loss of genes and are therefore irreversible, others may be the result of genes being switched off. If these silent genes are somehow switched back on, they argued, longlost traits could reappear. Raffs team went on to calculate the likelihood of it happening. Silent genes accumulate random mutations, they reasoned, eventually rendering them useless. So how long can a gene survive in a species if it is no longer used? The team calculated that there is a good chance of silent genes surviving for up to 6 million years in at least a few individuals in a population, and that some might survive as long as 10 million years. In other words, throwbacks are possible, but only to the relatively recent evolutionary past. As a possible example, the team pointed to the mole salamanders of Mexico and California. Like most amphibians these begin life in a juvenile tadpole state, then metamorphose into the adult form except for one species, the axolotl, which famously lives its entire life as a juvenile. The simplest explanation for this is that the axolotl lineage alone lost the ability to metamorphose, while others retained it. From a detailed analysis of the salamanders family tree, however, it is clear that the other lineages evolved from an ancestor that itself had lost the ability to metamorphose. In other words, metamorphosis in mole salamanders is an atavism. The salamander example fits with Raffs 10million-year time frame. 82More recently, however, examples have been reported that break the time limit, suggesting that silent genes may not be the whole story. In a paper published last year, biologist Gunter Wagner of Yale University reported some work on the evolutionary history of a group of South American lizards called Bachia. Many of these have minuscule limbs; some look more like snakes than lizards and a few have completely lost the toes on their hind limbs. Other species, however, sport up to four toes on their hind legs. The simplest explanation is that the toed lineages never lost their toes, but Wagner begs to differ. According to his analysis of the Bachia family tree, the toed species re-evolved toes from toeless ancestors and, what is more, digit loss and gain has occurred on more than one occasion over tens of millions of years. So whats going on? One possibility is that these traits are lost and then simply reappear, in much the same way that similar structures can independently arise in unrelated species, such as the dorsal fins of sharks and killer whales. Another more intriguing possibility is that the genetic information needed to make toes somehow survived for tens or perhaps hundreds of millions of years in the lizards and was reactivated. These atavistic traits provided an advantage and spread through the population, effectively reversing evolution. But if silent genes degrade within 6 to million years, how can long-lost traits be reactivated over longer timescales? The answer may lie in the womb. Early embryos of many species develop ancestral features. Snake embryos, for example, sprout hind limb buds. Later in development these features disappear thanks to developmental programs that say lose the leg. If for any reason this does not happen, the ancestral feature may not disappear, leading to an atavism.", "hypothesis": "The temporary occurence of longlost traits in embryos is rare.", "gold_label": "contradiction"}
{"uid": "id_568", "premise": "When evolution runs backwards Evolution isnt supposed to run backwards - yet an increasing number of examples show that it does and that it can sometimes represent the future of a species. The description of any animal as an evolutionary throwback is controversial. For the better part of a century, most biologists have been reluctant to use those words, mindful of a principle of evolution that says evolution cannot run backwards. But as more and more examples come to light and modern genetics enters the scene, that principle is having to be rewritten. Not only are evolutionary throwbacks possible, they sometimes play an important role in the forward march of evolution. The technical term for an evolutionary throwback is an atavism, from the Latin atavus, meaning forefather. The word has ugly connotations thanks largely to Cesare Lombroso, a 19th-century Italian medic who argued that criminals were born not made and could be identified by certain physical features that were throwbacks to a primitive, sub-human state. While Lombroso was measuring criminals, a Belgian palaeontologist called Louis Dollo was studying fossil records and coming to the opposite conclusion. In 1890 he proposed that evolution was irreversible: that an organism is unable to return, even partially, to a previous stage already realised in the ranks of its ancestors. Early 20th-century biologists came to a similar conclusion, though they qualified it in terms of probability, stating that there is no reason why evolution cannot run backwards -it is just very unlikely. And so the idea of irreversibility in evolution stuck and came to be known as Dollos law. If Dollos law is right, atavisms should occur only very rarely, if at all. Yet almost since the idea took root, exceptions have been cropping up. In 1919, for example, a humpback whale with a pair of leglike appendages over a metre long, complete with a full set of limb bones, was caught off Vancouver Island in Canada. Explorer Roy Chapman Andrews argued at the time that the whale must be a throwback to a land-living ancestor. I can see no other explanation, he wrote in 1921. Since then, so many other examples have been discovered that it no longer makes sense to say that evolution is as good as irreversible. And this poses a puzzle: how can characteristics that disappeared millions of years ago suddenly reappear? In 1994, Rudolf Raff and colleagues at Indiana University in the USA decided to use genetics to put a number on the probability of evolution going into reverse. They reasoned that while some evolutionary changes involve the loss of genes and are therefore irreversible, others may be the result of genes being switched off. If these silent genes are somehow switched back on, they argued, longlost traits could reappear. Raffs team went on to calculate the likelihood of it happening. Silent genes accumulate random mutations, they reasoned, eventually rendering them useless. So how long can a gene survive in a species if it is no longer used? The team calculated that there is a good chance of silent genes surviving for up to 6 million years in at least a few individuals in a population, and that some might survive as long as 10 million years. In other words, throwbacks are possible, but only to the relatively recent evolutionary past. As a possible example, the team pointed to the mole salamanders of Mexico and California. Like most amphibians these begin life in a juvenile tadpole state, then metamorphose into the adult form except for one species, the axolotl, which famously lives its entire life as a juvenile. The simplest explanation for this is that the axolotl lineage alone lost the ability to metamorphose, while others retained it. From a detailed analysis of the salamanders family tree, however, it is clear that the other lineages evolved from an ancestor that itself had lost the ability to metamorphose. In other words, metamorphosis in mole salamanders is an atavism. The salamander example fits with Raffs 10million-year time frame. 82More recently, however, examples have been reported that break the time limit, suggesting that silent genes may not be the whole story. In a paper published last year, biologist Gunter Wagner of Yale University reported some work on the evolutionary history of a group of South American lizards called Bachia. Many of these have minuscule limbs; some look more like snakes than lizards and a few have completely lost the toes on their hind limbs. Other species, however, sport up to four toes on their hind legs. The simplest explanation is that the toed lineages never lost their toes, but Wagner begs to differ. According to his analysis of the Bachia family tree, the toed species re-evolved toes from toeless ancestors and, what is more, digit loss and gain has occurred on more than one occasion over tens of millions of years. So whats going on? One possibility is that these traits are lost and then simply reappear, in much the same way that similar structures can independently arise in unrelated species, such as the dorsal fins of sharks and killer whales. Another more intriguing possibility is that the genetic information needed to make toes somehow survived for tens or perhaps hundreds of millions of years in the lizards and was reactivated. These atavistic traits provided an advantage and spread through the population, effectively reversing evolution. But if silent genes degrade within 6 to million years, how can long-lost traits be reactivated over longer timescales? The answer may lie in the womb. Early embryos of many species develop ancestral features. Snake embryos, for example, sprout hind limb buds. Later in development these features disappear thanks to developmental programs that say lose the leg. If for any reason this does not happen, the ancestral feature may not disappear, leading to an atavism.", "hypothesis": "Wagner was the first person to do research on South American lizards.", "gold_label": "neutral"}
{"uid": "id_569", "premise": "When evolution runs backwards Evolution isnt supposed to run backwards - yet an increasing number of examples show that it does and that it can sometimes represent the future of a species. The description of any animal as an evolutionary throwback is controversial. For the better part of a century, most biologists have been reluctant to use those words, mindful of a principle of evolution that says evolution cannot run backwards. But as more and more examples come to light and modern genetics enters the scene, that principle is having to be rewritten. Not only are evolutionary throwbacks possible, they sometimes play an important role in the forward march of evolution. The technical term for an evolutionary throwback is an atavism, from the Latin atavus, meaning forefather. The word has ugly connotations thanks largely to Cesare Lombroso, a 19th-century Italian medic who argued that criminals were born not made and could be identified by certain physical features that were throwbacks to a primitive, sub-human state. While Lombroso was measuring criminals, a Belgian palaeontologist called Louis Dollo was studying fossil records and coming to the opposite conclusion. In 1890 he proposed that evolution was irreversible: that an organism is unable to return, even partially, to a previous stage already realised in the ranks of its ancestors. Early 20th-century biologists came to a similar conclusion, though they qualified it in terms of probability, stating that there is no reason why evolution cannot run backwards -it is just very unlikely. And so the idea of irreversibility in evolution stuck and came to be known as Dollos law. If Dollos law is right, atavisms should occur only very rarely, if at all. Yet almost since the idea took root, exceptions have been cropping up. In 1919, for example, a humpback whale with a pair of leglike appendages over a metre long, complete with a full set of limb bones, was caught off Vancouver Island in Canada. Explorer Roy Chapman Andrews argued at the time that the whale must be a throwback to a land-living ancestor. I can see no other explanation, he wrote in 1921. Since then, so many other examples have been discovered that it no longer makes sense to say that evolution is as good as irreversible. And this poses a puzzle: how can characteristics that disappeared millions of years ago suddenly reappear? In 1994, Rudolf Raff and colleagues at Indiana University in the USA decided to use genetics to put a number on the probability of evolution going into reverse. They reasoned that while some evolutionary changes involve the loss of genes and are therefore irreversible, others may be the result of genes being switched off. If these silent genes are somehow switched back on, they argued, longlost traits could reappear. Raffs team went on to calculate the likelihood of it happening. Silent genes accumulate random mutations, they reasoned, eventually rendering them useless. So how long can a gene survive in a species if it is no longer used? The team calculated that there is a good chance of silent genes surviving for up to 6 million years in at least a few individuals in a population, and that some might survive as long as 10 million years. In other words, throwbacks are possible, but only to the relatively recent evolutionary past. As a possible example, the team pointed to the mole salamanders of Mexico and California. Like most amphibians these begin life in a juvenile tadpole state, then metamorphose into the adult form except for one species, the axolotl, which famously lives its entire life as a juvenile. The simplest explanation for this is that the axolotl lineage alone lost the ability to metamorphose, while others retained it. From a detailed analysis of the salamanders family tree, however, it is clear that the other lineages evolved from an ancestor that itself had lost the ability to metamorphose. In other words, metamorphosis in mole salamanders is an atavism. The salamander example fits with Raffs 10million-year time frame. 82More recently, however, examples have been reported that break the time limit, suggesting that silent genes may not be the whole story. In a paper published last year, biologist Gunter Wagner of Yale University reported some work on the evolutionary history of a group of South American lizards called Bachia. Many of these have minuscule limbs; some look more like snakes than lizards and a few have completely lost the toes on their hind limbs. Other species, however, sport up to four toes on their hind legs. The simplest explanation is that the toed lineages never lost their toes, but Wagner begs to differ. According to his analysis of the Bachia family tree, the toed species re-evolved toes from toeless ancestors and, what is more, digit loss and gain has occurred on more than one occasion over tens of millions of years. So whats going on? One possibility is that these traits are lost and then simply reappear, in much the same way that similar structures can independently arise in unrelated species, such as the dorsal fins of sharks and killer whales. Another more intriguing possibility is that the genetic information needed to make toes somehow survived for tens or perhaps hundreds of millions of years in the lizards and was reactivated. These atavistic traits provided an advantage and spread through the population, effectively reversing evolution. But if silent genes degrade within 6 to million years, how can long-lost traits be reactivated over longer timescales? The answer may lie in the womb. Early embryos of many species develop ancestral features. Snake embryos, for example, sprout hind limb buds. Later in development these features disappear thanks to developmental programs that say lose the leg. If for any reason this does not happen, the ancestral feature may not disappear, leading to an atavism.", "hypothesis": "Wagner believes that Bachia lizards with toes had toeless ancestors.", "gold_label": "entailment"}
{"uid": "id_570", "premise": "When evolution runs backwards. Evolution isnt supposed to run backwards yet an increasing number of examples show that it does and that it can sometimes represent the future of a species The description of any animal as an evolutionary throwback is controversial. For the better part of a century, most biologists have been reluctant to use those words, mindful of a principle of evolution that says evolution cannot run backwards. But as more and more examples come to light and modern genetics enters the scene, that principle is having to be rewritten. Not only are evolutionary throwbacks possible, they sometimes play an important role in the forward march of evolution. The technical term for an evolutionary throwback is an atavism, from the Latin atavus, meaning forefather. The word has ugly connotations thanks largely to Cesare Lombroso, a 19th-century Italian medic who argued that criminals were born not made and could be identified by certain physical features that were throwbacks to a primitive, sub-human state. While Lombroso was measuring criminals, a Belgian palaeontologist called Louis Dollo was studying fossil records and coming to the opposite conclusion. In 1890 he proposed that evolution was irreversible: that an organism is unable to return, even partially, to a previous stage already realised in the ranks of its ancestors. Early 20th-century biologists came to a similar conclusion, though they qualified it in terms of probability, stating that there is no reason why evolution cannot run backwards it is just very unlikely. And so the idea of irreversibility in evolution stuck and came to be known as Dollos law. If Dollos law is right, atavisms should occur only very rarely, if at all. Yet almost since the idea took root, exceptions have been cropping up. In 1919, for example, a humpback whale with a pair of leg-like appendages over a metre long, complete with a full set of limb bones, was caught off Vancouver Island in Canada. Explorer Roy Chapman Andrews argued at the time that the whale must be a throwback to a land-living ancestor. I can see no other explanation, he wrote in 1921. Since then, so many other examples have been discovered that it no longer makes sense to say that evolution is as good as irreversible. And this poses a puzzle: how can characteristics that disappeared millions of years ago suddenly reappear? In 1994, Rudolf Raff and colleagues at Indiana University in the USA decided to use genetics to put a number on the probability of evolution going into reverse. They reasoned that while some evolutionary changes involve the loss of genes and are therefore irreversible, others may be the result of genes being switched off. If these silent genes are somehow switched back on, they argued, long-lost traits could reappear. Raffs team went on to calculate the likelihood of it happening. Silent genes accumulate random mutations, they reasoned, eventually rendering them useless. So how long can a gene survive in a species if it is no longer used? The team calculated that there is a good chance of silent genes surviving for up to 6 million years in at least a few individuals in a population, and that some might survive as long as 10 million years. In other words, throwbacks are possible, but only to the relatively recent evolutionary past. As a possible example, the team pointed to the mole salamanders of Mexico and California. Like most amphibians these begin life in a juvenile tadpole state, then metamorphose into the adult form except for one species, the axolotl, which famously lives its entire life as a juvenile. The simplest explanation for this is that the axolotl lineage alone lost the ability to metamorphose, while others retained it. From a detailed analysis of the salamanders family tree, however, it is clear that the other lineages evolved from an ancestor that itself had lost the ability to metamorphose. In other words, metamorphosis in mole salamanders is an atavism. The salamander example fits with Raffs 10-million-year time frame. More recently, however, examples have been reported that break the time limit, suggesting that silent genes may not be the whole story. In a paper published last year, biologist Gunter Wagner of Yale University reported some work on the evolutionary history of a group of South American lizards called Bachia. Many of these have minuscule limbs; some look more like snakes than lizards and a few have completely lost the toes on their hind limbs. Other species, however, sport up to four toes on their hind legs. The simplest explanation is that the toed lineages never lost their toes, but Wagner begs to differ. According to his analysis of the Bachia family tree, the toed species re-evolved toes from toeless ancestors and, what is more, digit loss and gain has occurred on more than one occasion over tens of millions of years. So whats going on? One possibility is that these traits are lost and then simply reappear, in much the same way that similar structures can independently arise in unrelated species, such as the dorsal fins of sharks and killer whales. Another more intriguing possibility is that the genetic information needed to make toes somehow survived for tens or perhaps hundreds of millions of years in the lizards and was reactivated. These atavistic traits provided an advantage and spread through the population, effectively reversing evolution. But if silent genes degrade within 6 to 10 million years, how can long-lost traits be reactivated over longer timescales? The answer may lie in the womb. Early embryos of many species develop ancestral features. Snake embryos, for example, sprout hind limb buds. Later in development these features disappear thanks to developmental programs that say lose the leg. If for any reason this does not happen, the ancestral feature may not disappear, leading to an atavism.", "hypothesis": "Evolutionary throwbacks might be caused by developmental problems in the womb.", "gold_label": "entailment"}
{"uid": "id_571", "premise": "When evolution runs backwards. Evolution isnt supposed to run backwards yet an increasing number of examples show that it does and that it can sometimes represent the future of a species The description of any animal as an evolutionary throwback is controversial. For the better part of a century, most biologists have been reluctant to use those words, mindful of a principle of evolution that says evolution cannot run backwards. But as more and more examples come to light and modern genetics enters the scene, that principle is having to be rewritten. Not only are evolutionary throwbacks possible, they sometimes play an important role in the forward march of evolution. The technical term for an evolutionary throwback is an atavism, from the Latin atavus, meaning forefather. The word has ugly connotations thanks largely to Cesare Lombroso, a 19th-century Italian medic who argued that criminals were born not made and could be identified by certain physical features that were throwbacks to a primitive, sub-human state. While Lombroso was measuring criminals, a Belgian palaeontologist called Louis Dollo was studying fossil records and coming to the opposite conclusion. In 1890 he proposed that evolution was irreversible: that an organism is unable to return, even partially, to a previous stage already realised in the ranks of its ancestors. Early 20th-century biologists came to a similar conclusion, though they qualified it in terms of probability, stating that there is no reason why evolution cannot run backwards it is just very unlikely. And so the idea of irreversibility in evolution stuck and came to be known as Dollos law. If Dollos law is right, atavisms should occur only very rarely, if at all. Yet almost since the idea took root, exceptions have been cropping up. In 1919, for example, a humpback whale with a pair of leg-like appendages over a metre long, complete with a full set of limb bones, was caught off Vancouver Island in Canada. Explorer Roy Chapman Andrews argued at the time that the whale must be a throwback to a land-living ancestor. I can see no other explanation, he wrote in 1921. Since then, so many other examples have been discovered that it no longer makes sense to say that evolution is as good as irreversible. And this poses a puzzle: how can characteristics that disappeared millions of years ago suddenly reappear? In 1994, Rudolf Raff and colleagues at Indiana University in the USA decided to use genetics to put a number on the probability of evolution going into reverse. They reasoned that while some evolutionary changes involve the loss of genes and are therefore irreversible, others may be the result of genes being switched off. If these silent genes are somehow switched back on, they argued, long-lost traits could reappear. Raffs team went on to calculate the likelihood of it happening. Silent genes accumulate random mutations, they reasoned, eventually rendering them useless. So how long can a gene survive in a species if it is no longer used? The team calculated that there is a good chance of silent genes surviving for up to 6 million years in at least a few individuals in a population, and that some might survive as long as 10 million years. In other words, throwbacks are possible, but only to the relatively recent evolutionary past. As a possible example, the team pointed to the mole salamanders of Mexico and California. Like most amphibians these begin life in a juvenile tadpole state, then metamorphose into the adult form except for one species, the axolotl, which famously lives its entire life as a juvenile. The simplest explanation for this is that the axolotl lineage alone lost the ability to metamorphose, while others retained it. From a detailed analysis of the salamanders family tree, however, it is clear that the other lineages evolved from an ancestor that itself had lost the ability to metamorphose. In other words, metamorphosis in mole salamanders is an atavism. The salamander example fits with Raffs 10-million-year time frame. More recently, however, examples have been reported that break the time limit, suggesting that silent genes may not be the whole story. In a paper published last year, biologist Gunter Wagner of Yale University reported some work on the evolutionary history of a group of South American lizards called Bachia. Many of these have minuscule limbs; some look more like snakes than lizards and a few have completely lost the toes on their hind limbs. Other species, however, sport up to four toes on their hind legs. The simplest explanation is that the toed lineages never lost their toes, but Wagner begs to differ. According to his analysis of the Bachia family tree, the toed species re-evolved toes from toeless ancestors and, what is more, digit loss and gain has occurred on more than one occasion over tens of millions of years. So whats going on? One possibility is that these traits are lost and then simply reappear, in much the same way that similar structures can independently arise in unrelated species, such as the dorsal fins of sharks and killer whales. Another more intriguing possibility is that the genetic information needed to make toes somehow survived for tens or perhaps hundreds of millions of years in the lizards and was reactivated. These atavistic traits provided an advantage and spread through the population, effectively reversing evolution. But if silent genes degrade within 6 to 10 million years, how can long-lost traits be reactivated over longer timescales? The answer may lie in the womb. Early embryos of many species develop ancestral features. Snake embryos, for example, sprout hind limb buds. Later in development these features disappear thanks to developmental programs that say lose the leg. If for any reason this does not happen, the ancestral feature may not disappear, leading to an atavism.", "hypothesis": "The temporary occurrence of long-lost traits in embryos is rare.", "gold_label": "contradiction"}
{"uid": "id_572", "premise": "When evolution runs backwards. Evolution isnt supposed to run backwards yet an increasing number of examples show that it does and that it can sometimes represent the future of a species The description of any animal as an evolutionary throwback is controversial. For the better part of a century, most biologists have been reluctant to use those words, mindful of a principle of evolution that says evolution cannot run backwards. But as more and more examples come to light and modern genetics enters the scene, that principle is having to be rewritten. Not only are evolutionary throwbacks possible, they sometimes play an important role in the forward march of evolution. The technical term for an evolutionary throwback is an atavism, from the Latin atavus, meaning forefather. The word has ugly connotations thanks largely to Cesare Lombroso, a 19th-century Italian medic who argued that criminals were born not made and could be identified by certain physical features that were throwbacks to a primitive, sub-human state. While Lombroso was measuring criminals, a Belgian palaeontologist called Louis Dollo was studying fossil records and coming to the opposite conclusion. In 1890 he proposed that evolution was irreversible: that an organism is unable to return, even partially, to a previous stage already realised in the ranks of its ancestors. Early 20th-century biologists came to a similar conclusion, though they qualified it in terms of probability, stating that there is no reason why evolution cannot run backwards it is just very unlikely. And so the idea of irreversibility in evolution stuck and came to be known as Dollos law. If Dollos law is right, atavisms should occur only very rarely, if at all. Yet almost since the idea took root, exceptions have been cropping up. In 1919, for example, a humpback whale with a pair of leg-like appendages over a metre long, complete with a full set of limb bones, was caught off Vancouver Island in Canada. Explorer Roy Chapman Andrews argued at the time that the whale must be a throwback to a land-living ancestor. I can see no other explanation, he wrote in 1921. Since then, so many other examples have been discovered that it no longer makes sense to say that evolution is as good as irreversible. And this poses a puzzle: how can characteristics that disappeared millions of years ago suddenly reappear? In 1994, Rudolf Raff and colleagues at Indiana University in the USA decided to use genetics to put a number on the probability of evolution going into reverse. They reasoned that while some evolutionary changes involve the loss of genes and are therefore irreversible, others may be the result of genes being switched off. If these silent genes are somehow switched back on, they argued, long-lost traits could reappear. Raffs team went on to calculate the likelihood of it happening. Silent genes accumulate random mutations, they reasoned, eventually rendering them useless. So how long can a gene survive in a species if it is no longer used? The team calculated that there is a good chance of silent genes surviving for up to 6 million years in at least a few individuals in a population, and that some might survive as long as 10 million years. In other words, throwbacks are possible, but only to the relatively recent evolutionary past. As a possible example, the team pointed to the mole salamanders of Mexico and California. Like most amphibians these begin life in a juvenile tadpole state, then metamorphose into the adult form except for one species, the axolotl, which famously lives its entire life as a juvenile. The simplest explanation for this is that the axolotl lineage alone lost the ability to metamorphose, while others retained it. From a detailed analysis of the salamanders family tree, however, it is clear that the other lineages evolved from an ancestor that itself had lost the ability to metamorphose. In other words, metamorphosis in mole salamanders is an atavism. The salamander example fits with Raffs 10-million-year time frame. More recently, however, examples have been reported that break the time limit, suggesting that silent genes may not be the whole story. In a paper published last year, biologist Gunter Wagner of Yale University reported some work on the evolutionary history of a group of South American lizards called Bachia. Many of these have minuscule limbs; some look more like snakes than lizards and a few have completely lost the toes on their hind limbs. Other species, however, sport up to four toes on their hind legs. The simplest explanation is that the toed lineages never lost their toes, but Wagner begs to differ. According to his analysis of the Bachia family tree, the toed species re-evolved toes from toeless ancestors and, what is more, digit loss and gain has occurred on more than one occasion over tens of millions of years. So whats going on? One possibility is that these traits are lost and then simply reappear, in much the same way that similar structures can independently arise in unrelated species, such as the dorsal fins of sharks and killer whales. Another more intriguing possibility is that the genetic information needed to make toes somehow survived for tens or perhaps hundreds of millions of years in the lizards and was reactivated. These atavistic traits provided an advantage and spread through the population, effectively reversing evolution. But if silent genes degrade within 6 to 10 million years, how can long-lost traits be reactivated over longer timescales? The answer may lie in the womb. Early embryos of many species develop ancestral features. Snake embryos, for example, sprout hind limb buds. Later in development these features disappear thanks to developmental programs that say lose the leg. If for any reason this does not happen, the ancestral feature may not disappear, leading to an atavism.", "hypothesis": "Wagner believes that Bachia lizards with toes had toeless ancestors.", "gold_label": "entailment"}
{"uid": "id_573", "premise": "When evolution runs backwards. Evolution isnt supposed to run backwards yet an increasing number of examples show that it does and that it can sometimes represent the future of a species The description of any animal as an evolutionary throwback is controversial. For the better part of a century, most biologists have been reluctant to use those words, mindful of a principle of evolution that says evolution cannot run backwards. But as more and more examples come to light and modern genetics enters the scene, that principle is having to be rewritten. Not only are evolutionary throwbacks possible, they sometimes play an important role in the forward march of evolution. The technical term for an evolutionary throwback is an atavism, from the Latin atavus, meaning forefather. The word has ugly connotations thanks largely to Cesare Lombroso, a 19th-century Italian medic who argued that criminals were born not made and could be identified by certain physical features that were throwbacks to a primitive, sub-human state. While Lombroso was measuring criminals, a Belgian palaeontologist called Louis Dollo was studying fossil records and coming to the opposite conclusion. In 1890 he proposed that evolution was irreversible: that an organism is unable to return, even partially, to a previous stage already realised in the ranks of its ancestors. Early 20th-century biologists came to a similar conclusion, though they qualified it in terms of probability, stating that there is no reason why evolution cannot run backwards it is just very unlikely. And so the idea of irreversibility in evolution stuck and came to be known as Dollos law. If Dollos law is right, atavisms should occur only very rarely, if at all. Yet almost since the idea took root, exceptions have been cropping up. In 1919, for example, a humpback whale with a pair of leg-like appendages over a metre long, complete with a full set of limb bones, was caught off Vancouver Island in Canada. Explorer Roy Chapman Andrews argued at the time that the whale must be a throwback to a land-living ancestor. I can see no other explanation, he wrote in 1921. Since then, so many other examples have been discovered that it no longer makes sense to say that evolution is as good as irreversible. And this poses a puzzle: how can characteristics that disappeared millions of years ago suddenly reappear? In 1994, Rudolf Raff and colleagues at Indiana University in the USA decided to use genetics to put a number on the probability of evolution going into reverse. They reasoned that while some evolutionary changes involve the loss of genes and are therefore irreversible, others may be the result of genes being switched off. If these silent genes are somehow switched back on, they argued, long-lost traits could reappear. Raffs team went on to calculate the likelihood of it happening. Silent genes accumulate random mutations, they reasoned, eventually rendering them useless. So how long can a gene survive in a species if it is no longer used? The team calculated that there is a good chance of silent genes surviving for up to 6 million years in at least a few individuals in a population, and that some might survive as long as 10 million years. In other words, throwbacks are possible, but only to the relatively recent evolutionary past. As a possible example, the team pointed to the mole salamanders of Mexico and California. Like most amphibians these begin life in a juvenile tadpole state, then metamorphose into the adult form except for one species, the axolotl, which famously lives its entire life as a juvenile. The simplest explanation for this is that the axolotl lineage alone lost the ability to metamorphose, while others retained it. From a detailed analysis of the salamanders family tree, however, it is clear that the other lineages evolved from an ancestor that itself had lost the ability to metamorphose. In other words, metamorphosis in mole salamanders is an atavism. The salamander example fits with Raffs 10-million-year time frame. More recently, however, examples have been reported that break the time limit, suggesting that silent genes may not be the whole story. In a paper published last year, biologist Gunter Wagner of Yale University reported some work on the evolutionary history of a group of South American lizards called Bachia. Many of these have minuscule limbs; some look more like snakes than lizards and a few have completely lost the toes on their hind limbs. Other species, however, sport up to four toes on their hind legs. The simplest explanation is that the toed lineages never lost their toes, but Wagner begs to differ. According to his analysis of the Bachia family tree, the toed species re-evolved toes from toeless ancestors and, what is more, digit loss and gain has occurred on more than one occasion over tens of millions of years. So whats going on? One possibility is that these traits are lost and then simply reappear, in much the same way that similar structures can independently arise in unrelated species, such as the dorsal fins of sharks and killer whales. Another more intriguing possibility is that the genetic information needed to make toes somehow survived for tens or perhaps hundreds of millions of years in the lizards and was reactivated. These atavistic traits provided an advantage and spread through the population, effectively reversing evolution. But if silent genes degrade within 6 to 10 million years, how can long-lost traits be reactivated over longer timescales? The answer may lie in the womb. Early embryos of many species develop ancestral features. Snake embryos, for example, sprout hind limb buds. Later in development these features disappear thanks to developmental programs that say lose the leg. If for any reason this does not happen, the ancestral feature may not disappear, leading to an atavism.", "hypothesis": "Wagner was the first person to do research on South American lizards.", "gold_label": "neutral"}
{"uid": "id_574", "premise": "When the American War of Independence started, the Americans had no regular army. But one was soon formed under the command of George Washington. However, this army was badly equipped and lacked proper training. The war lasted for six years, from 1775 to 1781, and the Americans drew up the formal Declaration of Independence on 4 July 1776. This stated that the United States would be an independent republic.", "hypothesis": "The war lasted for six years and the Declaration of Independence was made shortly after the end of the war.", "gold_label": "contradiction"}
{"uid": "id_575", "premise": "When the American War of Independence started, the Americans had no regular army. But one was soon formed under the command of George Washington. However, this army was badly equipped and lacked proper training. The war lasted for six years, from 1775 to 1781, and the Americans drew up the formal Declaration of Independence on 4 July 1776. This stated that the United States would be an independent republic.", "hypothesis": "The first regular American army was commanded by Washington.", "gold_label": "entailment"}
{"uid": "id_576", "premise": "When the American War of Independence started, the Americans had no regular army. But one was soon formed under the command of George Washington. However, this army was badly equipped and lacked proper training. The war lasted for six years, from 1775 to 1781, and the Americans drew up the formal Declaration of Independence on 4 July 1776. This stated that the United States would be an independent republic.", "hypothesis": "The highly trained American army quickly won the war.", "gold_label": "contradiction"}
{"uid": "id_577", "premise": "When the Tulip Bubble Burst Tulips are spring-blooming perennials that grow from bulbs. Depending on the species, tulip plants can grow as short as 4 inches (10 cm) or as high as 28 inches (71 cm). The tulip's large flowers usually bloom on scapes or sub-scapose stems that lack bracts. Most tulips produce only one flower per stem, but a few species bear multiple flowers on their scapes (e. g. Tulipa turkestanica). The showy, generally cup or star-shaped tulip flower has three petals and three sepals, which are often termed tepals because they are nearly identical. These six tepals are often marked on the interior surface near the bases with darker colorings. Tulip flowers come in a wide variety of colors, except pure blue (several tulips with \"blue\" in the name have a faint violet hue) A. Long before anyone ever heard of Qualcomm, CMGI, Cisco Systems, or the other high-tech stocks that have soared during the current bull market, there was Semper Augustus. Both more prosaic and more sublime than any stock or bond, it was a tulip of extraordinary beauty, its midnight-blue petals topped by a band of pure white and accented with crimson flares. To denizens of 17th century Holland, little was as desirable. B. Around 1624, the Amsterdam man who owned the only dozen specimens was offered 3,000 guilders for one bulb. While there's no accurate way to render that in today's greenbacks, the sum was roughly equal to the annual income of a wealthy merchant. (A few years later, Rembrandt received about half that amount for painting The Night Watch. ) Yet the bulb's owner, whose name is now lost to history, nixed the offer. C. Who was crazier, the tulip lover who refused to sell for a small fortune or the one who was willing to splurge. That's a question that springs to mind after reading Tulip mania: The Story of the World's Most Coveted Flower and the Extraordinary Passions It Aroused by British journalist Mike Dash. In recent years, as investors have intentionally forgotten everything they learned in Investing 101 in order to load up on unproved, unprofitable dot- com issues, tulip mania has been invoked frequently. In this concise, artfully written account, Dash tells the real history behind the buzzword and in doing so, offers a cautionary tale for our times. D. The Dutch were not the first to go gaga over the tulip. Long before the first tulip bloomed in Europe-in Bavaria, it turns out, in 1559-the flower had enchanted the Persians and bewitched the rulers of the Ottoman Empire. It was in Holland, however, that the passion for tulips found its most fertile ground, forreasons that had little to do with horticulture. E. Holland in the early 17th century was embarking on its Golden Age. Resources that had just a few years earlier gone toward fighting for independence from Spain now flowed into commerce. Amsterdam merchants were at the center of the lucrative East Indies trade, where a single voyage could yield profits of 400%. They displayed their success by erecting grand estates surrounded by flower gardens. The Dutch population seemed tom by two contradictory impulses: a horror of living beyond one's means and the love of a long shot. F. Enter the tulip. \"It is impossible to comprehend the tulip mania without understanding just how different tulips were from every other flower known to horticulturists in the 17th century, \" says Dash. \"The colors they exhibited were more intense and more concentrated than those of ordinary plants. \" Despite the outlandish prices commanded by rare bulbs, ordinary tulips were sold by the pound. Around 1630, however, a new type of tulip fancier appeared, lured by tales of fat profits. These \"florists, \" or professional tulip traders, sought out flower lovers and speculators alike. But if the supply of tulip buyers grew quickly, the supply of bulbs did not. The tulip was a conspirator in the supply squeeze: It takes seven years to grow one from seed. And while bulbs can produce two or three clones, or \"offsets, \" annually, the mother bulb only lasts a few years. G. Bulb prices rose steadily throughout the 1630s, as ever more speculators into the market. Weavers and farmers mortgaged whatever they could to raise cash to begin trading. In 1633, a farmhouse in Hoorn changed hands for three rare bulbs. By 1636 any tulip-even bulbs recently considered garbage-could be sold off, often for hundreds of guilders. A futures market for bulbs existed, and tulip traders could be found conducting their business in hundreds of Dutch taverns. Tulip mania reached its peak during the winter of 1636-37, when some bulbs were changing hands ten times in a day. The zenith came early that winter, at an auction to benefit seven orphans whose only asset was 70 fine tulips left by then father. One, a rare Violetten Admirael van Enkhuizen bulb that was about to split in two, sold for 5,200 guilders, the all-time record. All told, the flowers brought in nearly 53,000 guilders. H. Soon after, the tulip market crashed utterly, spectacularly. It began inHaarlem, at a routine bulb auction when, for the first time, the greater fool refused to show up and pay. Within days, the panic had spread across the country. Despite the efforts of traders to prop up demand, the market for tulips evaporated. Flowers that had commanded 5,000 guilders a few weeks before now fetched one-hundredth that amount. Tulip mania is not without flaws. Dash dwells too long on the tulip's migration from Asia to Holland. But he does a service with this illuminating, accessible account of incredible financial folly. I. Tulip mania differed in one crucial aspect from the dot-com craze that grips our attention today: Even at its height, the Amsterdam Stock Exchange, well- established in 1630, wouldn't touch tulips. \"The speculation in tulip bulbs always existed at the margins of Dutch economic life, \" Dash writes. After the market crashed, a compromise was brokered that let most traders settle then debts for a fraction of then liability. The overall fallout on the Dutch economy was negligible. Will we say the same when Wall Street's current obsession finally runs its course?", "hypothesis": "In 1624, all the tulip collection belonged to a man in Amsterdam.", "gold_label": "entailment"}
{"uid": "id_578", "premise": "When the Tulip Bubble Burst Tulips are spring-blooming perennials that grow from bulbs. Depending on the species, tulip plants can grow as short as 4 inches (10 cm) or as high as 28 inches (71 cm). The tulip's large flowers usually bloom on scapes or sub-scapose stems that lack bracts. Most tulips produce only one flower per stem, but a few species bear multiple flowers on their scapes (e. g. Tulipa turkestanica). The showy, generally cup or star-shaped tulip flower has three petals and three sepals, which are often termed tepals because they are nearly identical. These six tepals are often marked on the interior surface near the bases with darker colorings. Tulip flowers come in a wide variety of colors, except pure blue (several tulips with \"blue\" in the name have a faint violet hue) A. Long before anyone ever heard of Qualcomm, CMGI, Cisco Systems, or the other high-tech stocks that have soared during the current bull market, there was Semper Augustus. Both more prosaic and more sublime than any stock or bond, it was a tulip of extraordinary beauty, its midnight-blue petals topped by a band of pure white and accented with crimson flares. To denizens of 17th century Holland, little was as desirable. B. Around 1624, the Amsterdam man who owned the only dozen specimens was offered 3,000 guilders for one bulb. While there's no accurate way to render that in today's greenbacks, the sum was roughly equal to the annual income of a wealthy merchant. (A few years later, Rembrandt received about half that amount for painting The Night Watch. ) Yet the bulb's owner, whose name is now lost to history, nixed the offer. C. Who was crazier, the tulip lover who refused to sell for a small fortune or the one who was willing to splurge. That's a question that springs to mind after reading Tulip mania: The Story of the World's Most Coveted Flower and the Extraordinary Passions It Aroused by British journalist Mike Dash. In recent years, as investors have intentionally forgotten everything they learned in Investing 101 in order to load up on unproved, unprofitable dot- com issues, tulip mania has been invoked frequently. In this concise, artfully written account, Dash tells the real history behind the buzzword and in doing so, offers a cautionary tale for our times. D. The Dutch were not the first to go gaga over the tulip. Long before the first tulip bloomed in Europe-in Bavaria, it turns out, in 1559-the flower had enchanted the Persians and bewitched the rulers of the Ottoman Empire. It was in Holland, however, that the passion for tulips found its most fertile ground, forreasons that had little to do with horticulture. E. Holland in the early 17th century was embarking on its Golden Age. Resources that had just a few years earlier gone toward fighting for independence from Spain now flowed into commerce. Amsterdam merchants were at the center of the lucrative East Indies trade, where a single voyage could yield profits of 400%. They displayed their success by erecting grand estates surrounded by flower gardens. The Dutch population seemed tom by two contradictory impulses: a horror of living beyond one's means and the love of a long shot. F. Enter the tulip. \"It is impossible to comprehend the tulip mania without understanding just how different tulips were from every other flower known to horticulturists in the 17th century, \" says Dash. \"The colors they exhibited were more intense and more concentrated than those of ordinary plants. \" Despite the outlandish prices commanded by rare bulbs, ordinary tulips were sold by the pound. Around 1630, however, a new type of tulip fancier appeared, lured by tales of fat profits. These \"florists, \" or professional tulip traders, sought out flower lovers and speculators alike. But if the supply of tulip buyers grew quickly, the supply of bulbs did not. The tulip was a conspirator in the supply squeeze: It takes seven years to grow one from seed. And while bulbs can produce two or three clones, or \"offsets, \" annually, the mother bulb only lasts a few years. G. Bulb prices rose steadily throughout the 1630s, as ever more speculators into the market. Weavers and farmers mortgaged whatever they could to raise cash to begin trading. In 1633, a farmhouse in Hoorn changed hands for three rare bulbs. By 1636 any tulip-even bulbs recently considered garbage-could be sold off, often for hundreds of guilders. A futures market for bulbs existed, and tulip traders could be found conducting their business in hundreds of Dutch taverns. Tulip mania reached its peak during the winter of 1636-37, when some bulbs were changing hands ten times in a day. The zenith came early that winter, at an auction to benefit seven orphans whose only asset was 70 fine tulips left by then father. One, a rare Violetten Admirael van Enkhuizen bulb that was about to split in two, sold for 5,200 guilders, the all-time record. All told, the flowers brought in nearly 53,000 guilders. H. Soon after, the tulip market crashed utterly, spectacularly. It began inHaarlem, at a routine bulb auction when, for the first time, the greater fool refused to show up and pay. Within days, the panic had spread across the country. Despite the efforts of traders to prop up demand, the market for tulips evaporated. Flowers that had commanded 5,000 guilders a few weeks before now fetched one-hundredth that amount. Tulip mania is not without flaws. Dash dwells too long on the tulip's migration from Asia to Holland. But he does a service with this illuminating, accessible account of incredible financial folly. I. Tulip mania differed in one crucial aspect from the dot-com craze that grips our attention today: Even at its height, the Amsterdam Stock Exchange, well- established in 1630, wouldn't touch tulips. \"The speculation in tulip bulbs always existed at the margins of Dutch economic life, \" Dash writes. After the market crashed, a compromise was brokered that let most traders settle then debts for a fraction of then liability. The overall fallout on the Dutch economy was negligible. Will we say the same when Wall Street's current obsession finally runs its course?", "hypothesis": "From 1630, Amsterdam Stock Exchange started to regulate Tulips exchange market.", "gold_label": "contradiction"}
{"uid": "id_579", "premise": "When the Tulip Bubble Burst Tulips are spring-blooming perennials that grow from bulbs. Depending on the species, tulip plants can grow as short as 4 inches (10 cm) or as high as 28 inches (71 cm). The tulip's large flowers usually bloom on scapes or sub-scapose stems that lack bracts. Most tulips produce only one flower per stem, but a few species bear multiple flowers on their scapes (e. g. Tulipa turkestanica). The showy, generally cup or star-shaped tulip flower has three petals and three sepals, which are often termed tepals because they are nearly identical. These six tepals are often marked on the interior surface near the bases with darker colorings. Tulip flowers come in a wide variety of colors, except pure blue (several tulips with \"blue\" in the name have a faint violet hue) A. Long before anyone ever heard of Qualcomm, CMGI, Cisco Systems, or the other high-tech stocks that have soared during the current bull market, there was Semper Augustus. Both more prosaic and more sublime than any stock or bond, it was a tulip of extraordinary beauty, its midnight-blue petals topped by a band of pure white and accented with crimson flares. To denizens of 17th century Holland, little was as desirable. B. Around 1624, the Amsterdam man who owned the only dozen specimens was offered 3,000 guilders for one bulb. While there's no accurate way to render that in today's greenbacks, the sum was roughly equal to the annual income of a wealthy merchant. (A few years later, Rembrandt received about half that amount for painting The Night Watch. ) Yet the bulb's owner, whose name is now lost to history, nixed the offer. C. Who was crazier, the tulip lover who refused to sell for a small fortune or the one who was willing to splurge. That's a question that springs to mind after reading Tulip mania: The Story of the World's Most Coveted Flower and the Extraordinary Passions It Aroused by British journalist Mike Dash. In recent years, as investors have intentionally forgotten everything they learned in Investing 101 in order to load up on unproved, unprofitable dot- com issues, tulip mania has been invoked frequently. In this concise, artfully written account, Dash tells the real history behind the buzzword and in doing so, offers a cautionary tale for our times. D. The Dutch were not the first to go gaga over the tulip. Long before the first tulip bloomed in Europe-in Bavaria, it turns out, in 1559-the flower had enchanted the Persians and bewitched the rulers of the Ottoman Empire. It was in Holland, however, that the passion for tulips found its most fertile ground, forreasons that had little to do with horticulture. E. Holland in the early 17th century was embarking on its Golden Age. Resources that had just a few years earlier gone toward fighting for independence from Spain now flowed into commerce. Amsterdam merchants were at the center of the lucrative East Indies trade, where a single voyage could yield profits of 400%. They displayed their success by erecting grand estates surrounded by flower gardens. The Dutch population seemed tom by two contradictory impulses: a horror of living beyond one's means and the love of a long shot. F. Enter the tulip. \"It is impossible to comprehend the tulip mania without understanding just how different tulips were from every other flower known to horticulturists in the 17th century, \" says Dash. \"The colors they exhibited were more intense and more concentrated than those of ordinary plants. \" Despite the outlandish prices commanded by rare bulbs, ordinary tulips were sold by the pound. Around 1630, however, a new type of tulip fancier appeared, lured by tales of fat profits. These \"florists, \" or professional tulip traders, sought out flower lovers and speculators alike. But if the supply of tulip buyers grew quickly, the supply of bulbs did not. The tulip was a conspirator in the supply squeeze: It takes seven years to grow one from seed. And while bulbs can produce two or three clones, or \"offsets, \" annually, the mother bulb only lasts a few years. G. Bulb prices rose steadily throughout the 1630s, as ever more speculators into the market. Weavers and farmers mortgaged whatever they could to raise cash to begin trading. In 1633, a farmhouse in Hoorn changed hands for three rare bulbs. By 1636 any tulip-even bulbs recently considered garbage-could be sold off, often for hundreds of guilders. A futures market for bulbs existed, and tulip traders could be found conducting their business in hundreds of Dutch taverns. Tulip mania reached its peak during the winter of 1636-37, when some bulbs were changing hands ten times in a day. The zenith came early that winter, at an auction to benefit seven orphans whose only asset was 70 fine tulips left by then father. One, a rare Violetten Admirael van Enkhuizen bulb that was about to split in two, sold for 5,200 guilders, the all-time record. All told, the flowers brought in nearly 53,000 guilders. H. Soon after, the tulip market crashed utterly, spectacularly. It began inHaarlem, at a routine bulb auction when, for the first time, the greater fool refused to show up and pay. Within days, the panic had spread across the country. Despite the efforts of traders to prop up demand, the market for tulips evaporated. Flowers that had commanded 5,000 guilders a few weeks before now fetched one-hundredth that amount. Tulip mania is not without flaws. Dash dwells too long on the tulip's migration from Asia to Holland. But he does a service with this illuminating, accessible account of incredible financial folly. I. Tulip mania differed in one crucial aspect from the dot-com craze that grips our attention today: Even at its height, the Amsterdam Stock Exchange, well- established in 1630, wouldn't touch tulips. \"The speculation in tulip bulbs always existed at the margins of Dutch economic life, \" Dash writes. After the market crashed, a compromise was brokered that let most traders settle then debts for a fraction of then liability. The overall fallout on the Dutch economy was negligible. Will we say the same when Wall Street's current obsession finally runs its course?", "hypothesis": "Holland was the most wealthy country in the world in 17th century.", "gold_label": "neutral"}
{"uid": "id_580", "premise": "When the Tulip Bubble Burst Tulips are spring-blooming perennials that grow from bulbs. Depending on the species, tulip plants can grow as short as 4 inches (10 cm) or as high as 28 inches (71 cm). The tulip's large flowers usually bloom on scapes or sub-scapose stems that lack bracts. Most tulips produce only one flower per stem, but a few species bear multiple flowers on their scapes (e. g. Tulipa turkestanica). The showy, generally cup or star-shaped tulip flower has three petals and three sepals, which are often termed tepals because they are nearly identical. These six tepals are often marked on the interior surface near the bases with darker colorings. Tulip flowers come in a wide variety of colors, except pure blue (several tulips with \"blue\" in the name have a faint violet hue) A. Long before anyone ever heard of Qualcomm, CMGI, Cisco Systems, or the other high-tech stocks that have soared during the current bull market, there was Semper Augustus. Both more prosaic and more sublime than any stock or bond, it was a tulip of extraordinary beauty, its midnight-blue petals topped by a band of pure white and accented with crimson flares. To denizens of 17th century Holland, little was as desirable. B. Around 1624, the Amsterdam man who owned the only dozen specimens was offered 3,000 guilders for one bulb. While there's no accurate way to render that in today's greenbacks, the sum was roughly equal to the annual income of a wealthy merchant. (A few years later, Rembrandt received about half that amount for painting The Night Watch. ) Yet the bulb's owner, whose name is now lost to history, nixed the offer. C. Who was crazier, the tulip lover who refused to sell for a small fortune or the one who was willing to splurge. That's a question that springs to mind after reading Tulip mania: The Story of the World's Most Coveted Flower and the Extraordinary Passions It Aroused by British journalist Mike Dash. In recent years, as investors have intentionally forgotten everything they learned in Investing 101 in order to load up on unproved, unprofitable dot- com issues, tulip mania has been invoked frequently. In this concise, artfully written account, Dash tells the real history behind the buzzword and in doing so, offers a cautionary tale for our times. D. The Dutch were not the first to go gaga over the tulip. Long before the first tulip bloomed in Europe-in Bavaria, it turns out, in 1559-the flower had enchanted the Persians and bewitched the rulers of the Ottoman Empire. It was in Holland, however, that the passion for tulips found its most fertile ground, forreasons that had little to do with horticulture. E. Holland in the early 17th century was embarking on its Golden Age. Resources that had just a few years earlier gone toward fighting for independence from Spain now flowed into commerce. Amsterdam merchants were at the center of the lucrative East Indies trade, where a single voyage could yield profits of 400%. They displayed their success by erecting grand estates surrounded by flower gardens. The Dutch population seemed tom by two contradictory impulses: a horror of living beyond one's means and the love of a long shot. F. Enter the tulip. \"It is impossible to comprehend the tulip mania without understanding just how different tulips were from every other flower known to horticulturists in the 17th century, \" says Dash. \"The colors they exhibited were more intense and more concentrated than those of ordinary plants. \" Despite the outlandish prices commanded by rare bulbs, ordinary tulips were sold by the pound. Around 1630, however, a new type of tulip fancier appeared, lured by tales of fat profits. These \"florists, \" or professional tulip traders, sought out flower lovers and speculators alike. But if the supply of tulip buyers grew quickly, the supply of bulbs did not. The tulip was a conspirator in the supply squeeze: It takes seven years to grow one from seed. And while bulbs can produce two or three clones, or \"offsets, \" annually, the mother bulb only lasts a few years. G. Bulb prices rose steadily throughout the 1630s, as ever more speculators into the market. Weavers and farmers mortgaged whatever they could to raise cash to begin trading. In 1633, a farmhouse in Hoorn changed hands for three rare bulbs. By 1636 any tulip-even bulbs recently considered garbage-could be sold off, often for hundreds of guilders. A futures market for bulbs existed, and tulip traders could be found conducting their business in hundreds of Dutch taverns. Tulip mania reached its peak during the winter of 1636-37, when some bulbs were changing hands ten times in a day. The zenith came early that winter, at an auction to benefit seven orphans whose only asset was 70 fine tulips left by then father. One, a rare Violetten Admirael van Enkhuizen bulb that was about to split in two, sold for 5,200 guilders, the all-time record. All told, the flowers brought in nearly 53,000 guilders. H. Soon after, the tulip market crashed utterly, spectacularly. It began inHaarlem, at a routine bulb auction when, for the first time, the greater fool refused to show up and pay. Within days, the panic had spread across the country. Despite the efforts of traders to prop up demand, the market for tulips evaporated. Flowers that had commanded 5,000 guilders a few weeks before now fetched one-hundredth that amount. Tulip mania is not without flaws. Dash dwells too long on the tulip's migration from Asia to Holland. But he does a service with this illuminating, accessible account of incredible financial folly. I. Tulip mania differed in one crucial aspect from the dot-com craze that grips our attention today: Even at its height, the Amsterdam Stock Exchange, well- established in 1630, wouldn't touch tulips. \"The speculation in tulip bulbs always existed at the margins of Dutch economic life, \" Dash writes. After the market crashed, a compromise was brokered that let most traders settle then debts for a fraction of then liability. The overall fallout on the Dutch economy was negligible. Will we say the same when Wall Street's current obsession finally runs its course?", "hypothesis": "Popularity of Tulip in Holland was much higher than any other countries in17th century.", "gold_label": "entailment"}
{"uid": "id_581", "premise": "When the Tulip Bubble Burst Tulips are spring-blooming perennials that grow from bulbs. Depending on the species, tulip plants can grow as short as 4 inches (10 cm) or as high as 28 inches (71 cm). The tulip's large flowers usually bloom on scapes or sub-scapose stems that lack bracts. Most tulips produce only one flower per stem, but a few species bear multiple flowers on their scapes (e. g. Tulipa turkestanica). The showy, generally cup or star-shaped tulip flower has three petals and three sepals, which are often termed tepals because they are nearly identical. These six tepals are often marked on the interior surface near the bases with darker colorings. Tulip flowers come in a wide variety of colors, except pure blue (several tulips with \"blue\" in the name have a faint violet hue) A. Long before anyone ever heard of Qualcomm, CMGI, Cisco Systems, or the other high-tech stocks that have soared during the current bull market, there was Semper Augustus. Both more prosaic and more sublime than any stock or bond, it was a tulip of extraordinary beauty, its midnight-blue petals topped by a band of pure white and accented with crimson flares. To denizens of 17th century Holland, little was as desirable. B. Around 1624, the Amsterdam man who owned the only dozen specimens was offered 3,000 guilders for one bulb. While there's no accurate way to render that in today's greenbacks, the sum was roughly equal to the annual income of a wealthy merchant. (A few years later, Rembrandt received about half that amount for painting The Night Watch. ) Yet the bulb's owner, whose name is now lost to history, nixed the offer. C. Who was crazier, the tulip lover who refused to sell for a small fortune or the one who was willing to splurge. That's a question that springs to mind after reading Tulip mania: The Story of the World's Most Coveted Flower and the Extraordinary Passions It Aroused by British journalist Mike Dash. In recent years, as investors have intentionally forgotten everything they learned in Investing 101 in order to load up on unproved, unprofitable dot- com issues, tulip mania has been invoked frequently. In this concise, artfully written account, Dash tells the real history behind the buzzword and in doing so, offers a cautionary tale for our times. D. The Dutch were not the first to go gaga over the tulip. Long before the first tulip bloomed in Europe-in Bavaria, it turns out, in 1559-the flower had enchanted the Persians and bewitched the rulers of the Ottoman Empire. It was in Holland, however, that the passion for tulips found its most fertile ground, forreasons that had little to do with horticulture. E. Holland in the early 17th century was embarking on its Golden Age. Resources that had just a few years earlier gone toward fighting for independence from Spain now flowed into commerce. Amsterdam merchants were at the center of the lucrative East Indies trade, where a single voyage could yield profits of 400%. They displayed their success by erecting grand estates surrounded by flower gardens. The Dutch population seemed tom by two contradictory impulses: a horror of living beyond one's means and the love of a long shot. F. Enter the tulip. \"It is impossible to comprehend the tulip mania without understanding just how different tulips were from every other flower known to horticulturists in the 17th century, \" says Dash. \"The colors they exhibited were more intense and more concentrated than those of ordinary plants. \" Despite the outlandish prices commanded by rare bulbs, ordinary tulips were sold by the pound. Around 1630, however, a new type of tulip fancier appeared, lured by tales of fat profits. These \"florists, \" or professional tulip traders, sought out flower lovers and speculators alike. But if the supply of tulip buyers grew quickly, the supply of bulbs did not. The tulip was a conspirator in the supply squeeze: It takes seven years to grow one from seed. And while bulbs can produce two or three clones, or \"offsets, \" annually, the mother bulb only lasts a few years. G. Bulb prices rose steadily throughout the 1630s, as ever more speculators into the market. Weavers and farmers mortgaged whatever they could to raise cash to begin trading. In 1633, a farmhouse in Hoorn changed hands for three rare bulbs. By 1636 any tulip-even bulbs recently considered garbage-could be sold off, often for hundreds of guilders. A futures market for bulbs existed, and tulip traders could be found conducting their business in hundreds of Dutch taverns. Tulip mania reached its peak during the winter of 1636-37, when some bulbs were changing hands ten times in a day. The zenith came early that winter, at an auction to benefit seven orphans whose only asset was 70 fine tulips left by then father. One, a rare Violetten Admirael van Enkhuizen bulb that was about to split in two, sold for 5,200 guilders, the all-time record. All told, the flowers brought in nearly 53,000 guilders. H. Soon after, the tulip market crashed utterly, spectacularly. It began inHaarlem, at a routine bulb auction when, for the first time, the greater fool refused to show up and pay. Within days, the panic had spread across the country. Despite the efforts of traders to prop up demand, the market for tulips evaporated. Flowers that had commanded 5,000 guilders a few weeks before now fetched one-hundredth that amount. Tulip mania is not without flaws. Dash dwells too long on the tulip's migration from Asia to Holland. But he does a service with this illuminating, accessible account of incredible financial folly. I. Tulip mania differed in one crucial aspect from the dot-com craze that grips our attention today: Even at its height, the Amsterdam Stock Exchange, well- established in 1630, wouldn't touch tulips. \"The speculation in tulip bulbs always existed at the margins of Dutch economic life, \" Dash writes. After the market crashed, a compromise was brokered that let most traders settle then debts for a fraction of then liability. The overall fallout on the Dutch economy was negligible. Will we say the same when Wall Street's current obsession finally runs its course?", "hypothesis": "Tulip was first planted in Holland according to this passage.", "gold_label": "contradiction"}
{"uid": "id_582", "premise": "When they saw that it was snowing, Sheila and Bob Crandall decided to take the train to visit Sheila's Aunt Janet. Aunt Janet lives 218 miles from Sheila and Bob. The roundtrip train tickets cost $32.50 each. On all their other trips to visit Aunt Janet, Sheila and Bob had driven their car.", "hypothesis": "For Sheila and Bob, taking the train is cheaper than driving the car.", "gold_label": "neutral"}
{"uid": "id_583", "premise": "When they saw that it was snowing, Sheila and Bob Crandall decided to take the train to visit Sheila's Aunt Janet. Aunt Janet lives 218 miles from Sheila and Bob. The roundtrip train tickets cost $32.50 each. On all their other trips to visit Aunt Janet, Sheila and Bob had driven their car.", "hypothesis": "Sheila and Bob will have to buy four different train tickets.", "gold_label": "contradiction"}
{"uid": "id_584", "premise": "When they saw that it was snowing, Sheila and Bob Crandall decided to take the train to visit Sheila's Aunt Janet. Aunt Janet lives 218 miles from Sheila and Bob. The roundtrip train tickets cost $32.50 each. On all their other trips to visit Aunt Janet, Sheila and Bob had driven their car.", "hypothesis": "Based on the weather, Sheila and Bob made a decision to take the train.", "gold_label": "entailment"}
{"uid": "id_585", "premise": "When they saw that it was snowing, Sheila and Bob Crandall decided to take the train to visit Sheila's Aunt Janet. Aunt Janet lives 218 miles from Sheila and Bob. The roundtrip train tickets cost $32.50 each. On all their other trips to visit Aunt Janet, Sheila and Bob had driven their car.", "hypothesis": "Aunt Janet persuaded Sheila and Bob to take the train.", "gold_label": "neutral"}
{"uid": "id_586", "premise": "When was the last time you saw a frog? Chances are, if you live in a city, you have not seen one for some time. Even in wet areas once teeming with frogs and toads, it is becoming less and less easy to find those slimy, hopping and sometimes poisonous members of the animal kingdom. All over the world, and even in remote parts of Australia, frogs are losing the ecological battle for survival, and biologists are at a loss to explain their demise. Are amphibians simply oversensitive to changes in the ecosystem? Could it be that their rapid decline in numbers is signaling some coming environmental disaster for us all? This frightening scenario is in part the consequence of a dramatic increase over the last quarter century in the development of once natural areas of wet marshland; home not only to frogs but to all manner of wildlife. However, as yet, there are no obvious reasons why certain frog species are disappearing from rainforests in Australia that have barely been touched by human hand. The mystery is unsettling to say the least, for it is known that amphibian species are extremely sensitive to environmental variations in temperature and moisture levels. The danger is that planet Earth might not only lose a vital link in the ecological food chain (frogs keep populations of otherwise pestilent insects at manageable levels), but we might be increasing our output of air pollutants to levels that may have already become irreversible. Frogs could be inadvertently warning us of a catastrophe. An example of a species of frog that, at far as is known, has become extinct, is the platypus frog. Like the well-known Australian mammal it was named after, it exhibited some very strange behaviour; instead of giving birth to tadpoles in the water, it raised its young within its stomach. The baby frogs were actually born from out of their mother's mouth. Discovered in 1981, less than ten years later the frog had completely vanished from the crystal clear waters of Booloumba Creek near Queensland's Sunshine Coast. Unfortunately, this freak of nature is not the only frog species to have been lost in Australia. Since the 1970s, no less than eight others have suffered the same fate. One theory that seems to fit the facts concerns the depletion of the ozone layer, a well documented phenomenon which has led to a sharp increase in ultraviolet radiation levels. The ozone layer is meant to shield the Earth from UV rays, but increased radiation may be having a greater effect upon frog populations than previously believed. Another theory is that worldwide temperature increases are upsetting the breeding cycles of frogs.", "hypothesis": "Frogs and toads are usually poisonous.", "gold_label": "contradiction"}
{"uid": "id_587", "premise": "When was the last time you saw a frog? Chances are, if you live in a city, you have not seen one for some time. Even in wet areas once teeming with frogs and toads, it is becoming less and less easy to find those slimy, hopping and sometimes poisonous members of the animal kingdom. All over the world, and even in remote parts of Australia, frogs are losing the ecological battle for survival, and biologists are at a loss to explain their demise. Are amphibians simply oversensitive to changes in the ecosystem? Could it be that their rapid decline in numbers is signaling some coming environmental disaster for us all? This frightening scenario is in part the consequence of a dramatic increase over the last quarter century in the development of once natural areas of wet marshland; home not only to frogs but to all manner of wildlife. However, as yet, there are no obvious reasons why certain frog species are disappearing from rainforests in Australia that have barely been touched by human hand. The mystery is unsettling to say the least, for it is known that amphibian species are extremely sensitive to environmental variations in temperature and moisture levels. The danger is that planet Earth might not only lose a vital link in the ecological food chain (frogs keep populations of otherwise pestilent insects at manageable levels), but we might be increasing our output of air pollutants to levels that may have already become irreversible. Frogs could be inadvertently warning us of a catastrophe. An example of a species of frog that, at far as is known, has become extinct, is the platypus frog. Like the well-known Australian mammal it was named after, it exhibited some very strange behaviour; instead of giving birth to tadpoles in the water, it raised its young within its stomach. The baby frogs were actually born from out of their mother's mouth. Discovered in 1981, less than ten years later the frog had completely vanished from the crystal clear waters of Booloumba Creek near Queensland's Sunshine Coast. Unfortunately, this freak of nature is not the only frog species to have been lost in Australia. Since the 1970s, no less than eight others have suffered the same fate. One theory that seems to fit the facts concerns the depletion of the ozone layer, a well documented phenomenon which has led to a sharp increase in ultraviolet radiation levels. The ozone layer is meant to shield the Earth from UV rays, but increased radiation may be having a greater effect upon frog populations than previously believed. Another theory is that worldwide temperature increases are upsetting the breeding cycles of frogs.", "hypothesis": "The frogs' natural habitat is becoming more and more developed.", "gold_label": "entailment"}
{"uid": "id_588", "premise": "When was the last time you saw a frog? Chances are, if you live in a city, you have not seen one for some time. Even in wet areas once teeming with frogs and toads, it is becoming less and less easy to find those slimy, hopping and sometimes poisonous members of the animal kingdom. All over the world, and even in remote parts of Australia, frogs are losing the ecological battle for survival, and biologists are at a loss to explain their demise. Are amphibians simply oversensitive to changes in the ecosystem? Could it be that their rapid decline in numbers is signaling some coming environmental disaster for us all? This frightening scenario is in part the consequence of a dramatic increase over the last quarter century in the development of once natural areas of wet marshland; home not only to frogs but to all manner of wildlife. However, as yet, there are no obvious reasons why certain frog species are disappearing from rainforests in Australia that have barely been touched by human hand. The mystery is unsettling to say the least, for it is known that amphibian species are extremely sensitive to environmental variations in temperature and moisture levels. The danger is that planet Earth might not only lose a vital link in the ecological food chain (frogs keep populations of otherwise pestilent insects at manageable levels), but we might be increasing our output of air pollutants to levels that may have already become irreversible. Frogs could be inadvertently warning us of a catastrophe. An example of a species of frog that, at far as is known, has become extinct, is the platypus frog. Like the well-known Australian mammal it was named after, it exhibited some very strange behaviour; instead of giving birth to tadpoles in the water, it raised its young within its stomach. The baby frogs were actually born from out of their mother's mouth. Discovered in 1981, less than ten years later the frog had completely vanished from the crystal clear waters of Booloumba Creek near Queensland's Sunshine Coast. Unfortunately, this freak of nature is not the only frog species to have been lost in Australia. Since the 1970s, no less than eight others have suffered the same fate. One theory that seems to fit the facts concerns the depletion of the ozone layer, a well documented phenomenon which has led to a sharp increase in ultraviolet radiation levels. The ozone layer is meant to shield the Earth from UV rays, but increased radiation may be having a greater effect upon frog populations than previously believed. Another theory is that worldwide temperature increases are upsetting the breeding cycles of frogs.", "hypothesis": "Frogs are disappearing only from city areas.", "gold_label": "contradiction"}
{"uid": "id_589", "premise": "When was the last time you saw a frog? Chances are, if you live in a city, you have not seen one for some time. Even in wet areas once teeming with frogs and toads, it is becoming less and less easy to find those slimy, hopping and sometimes poisonous members of the animal kingdom. All over the world, and even in remote parts of Australia, frogs are losing the ecological battle for survival, and biologists are at a loss to explain their demise. Are amphibians simply oversensitive to changes in the ecosystem? Could it be that their rapid decline in numbers is signaling some coming environmental disaster for us all? This frightening scenario is in part the consequence of a dramatic increase over the last quarter century in the development of once natural areas of wet marshland; home not only to frogs but to all manner of wildlife. However, as yet, there are no obvious reasons why certain frog species are disappearing from rainforests in Australia that have barely been touched by human hand. The mystery is unsettling to say the least, for it is known that amphibian species are extremely sensitive to environmental variations in temperature and moisture levels. The danger is that planet Earth might not only lose a vital link in the ecological food chain (frogs keep populations of otherwise pestilent insects at manageable levels), but we might be increasing our output of air pollutants to levels that may have already become irreversible. Frogs could be inadvertently warning us of a catastrophe. An example of a species of frog that, at far as is known, has become extinct, is the platypus frog. Like the well-known Australian mammal it was named after, it exhibited some very strange behaviour; instead of giving birth to tadpoles in the water, it raised its young within its stomach. The baby frogs were actually born from out of their mother's mouth. Discovered in 1981, less than ten years later the frog had completely vanished from the crystal clear waters of Booloumba Creek near Queensland's Sunshine Coast. Unfortunately, this freak of nature is not the only frog species to have been lost in Australia. Since the 1970s, no less than eight others have suffered the same fate. One theory that seems to fit the facts concerns the depletion of the ozone layer, a well documented phenomenon which has led to a sharp increase in ultraviolet radiation levels. The ozone layer is meant to shield the Earth from UV rays, but increased radiation may be having a greater effect upon frog populations than previously believed. Another theory is that worldwide temperature increases are upsetting the breeding cycles of frogs.", "hypothesis": "Biologists are unable to explain why frogs are dying.", "gold_label": "entailment"}
{"uid": "id_590", "premise": "When was the last time you saw a frog? Chances are, if you live in a city, you have not seen one for some time. Even in wet areas once teeming with frogs and toads, it is becoming less and less easy to find those slimy, hopping and sometimes poisonous members of the animal kingdom. All over the world, and even in remote parts of Australia, frogs are losing the ecological battle for survival, and biologists are at a loss to explain their demise. Are amphibians simply oversensitive to changes in the ecosystem? Could it be that their rapid decline in numbers is signaling some coming environmental disaster for us all? This frightening scenario is in part the consequence of a dramatic increase over the last quarter century in the development of once natural areas of wet marshland; home not only to frogs but to all manner of wildlife. However, as yet, there are no obvious reasons why certain frog species are disappearing from rainforests in Australia that have barely been touched by human hand. The mystery is unsettling to say the least, for it is known that amphibian species are extremely sensitive to environmental variations in temperature and moisture levels. The danger is that planet Earth might not only lose a vital link in the ecological food chain (frogs keep populations of otherwise pestilent insects at manageable levels), but we might be increasing our output of air pollutants to levels that may have already become irreversible. Frogs could be inadvertently warning us of a catastrophe. An example of a species of frog that, at far as is known, has become extinct, is the platypus frog. Like the well-known Australian mammal it was named after, it exhibited some very strange behaviour; instead of giving birth to tadpoles in the water, it raised its young within its stomach. The baby frogs were actually born from out of their mother's mouth. Discovered in 1981, less than ten years later the frog had completely vanished from the crystal clear waters of Booloumba Creek near Queensland's Sunshine Coast. Unfortunately, this freak of nature is not the only frog species to have been lost in Australia. Since the 1970s, no less than eight others have suffered the same fate. One theory that seems to fit the facts concerns the depletion of the ozone layer, a well documented phenomenon which has led to a sharp increase in ultraviolet radiation levels. The ozone layer is meant to shield the Earth from UV rays, but increased radiation may be having a greater effect upon frog populations than previously believed. Another theory is that worldwide temperature increases are upsetting the breeding cycles of frogs.", "hypothesis": "Attempts are being made to halt the development of wet marshland.", "gold_label": "neutral"}
{"uid": "id_591", "premise": "When was the last time you saw a frog? Chances are, if you live in a city, you have not seen one for some time. Even in wet areas once teeming with frogs and toads, it is becoming less and less easy to find those slimy, hopping and sometimes poisonous members of the animal kingdom. All over the world, and even in remote parts of Australia, frogs are losing the ecological battle for survival, and biologists are at a loss to explain their demise. Are amphibians simply oversensitive to changes in the ecosystem? Could it be that their rapid decline in numbers is signaling some coming environmental disaster for us all? This frightening scenario is in part the consequence of a dramatic increase over the last quarter century in the development of once natural areas of wet marshland; home not only to frogs but to all manner of wildlife. However, as yet, there are no obvious reasons why certain frog species are disappearing from rainforests in Australia that have barely been touched by human hand. The mystery is unsettling to say the least, for it is known that amphibian species are extremely sensitive to environmental variations in temperature and moisture levels. The danger is that planet Earth might not only lose a vital link in the ecological food chain (frogs keep populations of otherwise pestilent insects at manageable levels), but we might be increasing our output of air pollutants to levels that may have already become irreversible. Frogs could be inadvertently warning us of a catastrophe. An example of a species of frog that, at far as is known, has become extinct, is the platypus frog. Like the well-known Australian mammal it was named after, it exhibited some very strange behaviour; instead of giving birth to tadpoles in the water, it raised its young within its stomach. The baby frogs were actually born from out of their mother's mouth. Discovered in 1981, less than ten years later the frog had completely vanished from the crystal clear waters of Booloumba Creek near Queensland's Sunshine Coast. Unfortunately, this freak of nature is not the only frog species to have been lost in Australia. Since the 1970s, no less than eight others have suffered the same fate. One theory that seems to fit the facts concerns the depletion of the ozone layer, a well documented phenomenon which has led to a sharp increase in ultraviolet radiation levels. The ozone layer is meant to shield the Earth from UV rays, but increased radiation may be having a greater effect upon frog populations than previously believed. Another theory is that worldwide temperature increases are upsetting the breeding cycles of frogs.", "hypothesis": "Frogs are important in the ecosystem because they control pests.", "gold_label": "entailment"}
{"uid": "id_592", "premise": "When was the last time you saw a frog? Chances are, if you live in a city, you have not seen one for some time. Even in wet areas once teeming with frogs and toads, it is becoming less and less easy to find those slimy, hopping and sometimes poisonous members of the animal kingdom. All over the world, and even in remote parts of Australia, frogs are losing the ecological battle for survival, and biologists are at a loss to explain their demise. Are amphibians simply oversensitive to changes in the ecosystem? Could it be that their rapid decline in numbers is signaling some coming environmental disaster for us all? This frightening scenario is in part the consequence of a dramatic increase over the last quarter century in the development of once natural areas of wet marshland; home not only to frogs but to all manner of wildlife. However, as yet, there are no obvious reasons why certain frog species are disappearing from rainforests in Australia that have barely been touched by human hand. The mystery is unsettling to say the least, for it is known that amphibian species are extremely sensitive to environmental variations in temperature and moisture levels. The danger is that planet Earth might not only lose a vital link in the ecological food chain (frogs keep populations of otherwise pestilent insects at manageable levels), but we might be increasing our output of air pollutants to levels that may have already become irreversible. Frogs could be inadvertently warning us of a catastrophe. An example of a species of frog that, at far as is known, has become extinct, is the platypus frog. Like the well-known Australian mammal it was named after, it exhibited some very strange behaviour; instead of giving birth to tadpoles in the water, it raised its young within its stomach. The baby frogs were actually born from out of their mother's mouth. Discovered in 1981, less than ten years later the frog had completely vanished from the crystal clear waters of Booloumba Creek near Queensland's Sunshine Coast. Unfortunately, this freak of nature is not the only frog species to have been lost in Australia. Since the 1970s, no less than eight others have suffered the same fate. One theory that seems to fit the facts concerns the depletion of the ozone layer, a well documented phenomenon which has led to a sharp increase in ultraviolet radiation levels. The ozone layer is meant to shield the Earth from UV rays, but increased radiation may be having a greater effect upon frog populations than previously believed. Another theory is that worldwide temperature increases are upsetting the breeding cycles of frogs.", "hypothesis": "The platypus frog became extinct by 1991.", "gold_label": "entailment"}
{"uid": "id_593", "premise": "When was the last time you saw a frog? Chances are, if you live in a city, you have not seen one for some time. Even in wet areas once teeming with frogs and toads, it is becoming less and less easy to find those slimy, hopping and sometimes poisonous members of the animal kingdom. All over the world, and even in remote parts of Australia, frogs are losing the ecological battle for survival, and biologists are at a loss to explain their demise. Are amphibians simply oversensitive to changes in the ecosystem? Could it be that their rapid decline in numbers is signaling some coming environmental disaster for us all? This frightening scenario is in part the consequence of a dramatic increase over the last quarter century in the development of once natural areas of wet marshland; home not only to frogs but to all manner of wildlife. However, as yet, there are no obvious reasons why certain frog species are disappearing from rainforests in Australia that have barely been touched by human hand. The mystery is unsettling to say the least, for it is known that amphibian species are extremely sensitive to environmental variations in temperature and moisture levels. The danger is that planet Earth might not only lose a vital link in the ecological food chain (frogs keep populations of otherwise pestilent insects at manageable levels), but we might be increasing our output of air pollutants to levels that may have already become irreversible. Frogs could be inadvertently warning us of a catastrophe. An example of a species of frog that, at far as is known, has become extinct, is the platypus frog. Like the well-known Australian mammal it was named after, it exhibited some very strange behaviour; instead of giving birth to tadpoles in the water, it raised its young within its stomach. The baby frogs were actually born from out of their mother's mouth. Discovered in 1981, less than ten years later the frog had completely vanished from the crystal clear waters of Booloumba Creek near Queensland's Sunshine Coast. Unfortunately, this freak of nature is not the only frog species to have been lost in Australia. Since the 1970s, no less than eight others have suffered the same fate. One theory that seems to fit the facts concerns the depletion of the ozone layer, a well documented phenomenon which has led to a sharp increase in ultraviolet radiation levels. The ozone layer is meant to shield the Earth from UV rays, but increased radiation may be having a greater effect upon frog populations than previously believed. Another theory is that worldwide temperature increases are upsetting the breeding cycles of frogs.", "hypothesis": "Frogs usually give birth to their young in an underwater nest.", "gold_label": "neutral"}
{"uid": "id_594", "premise": "When was the last time you saw a frog? Chances are, if you live in a city, you have not seen one for some time. Even in wet areas once teeming with frogs and toads, it is becoming less and less easy to find those slimy, hopping and sometimes poisonous members of the animal kingdom. All over the world, and even in remote parts of Australia, frogs are losing the ecological battle for survival, and biologists are at a loss to explain their demise. Are amphibians simply oversensitive to changes in the ecosystem? Could it be that their rapid decline in numbers is signaling some coming environmental disaster for us all? This frightening scenario is in part the consequence of a dramatic increase over the last quarter century in the development of once natural areas of wet marshland; home not only to frogs but to all manner of wildlife. However, as yet, there are no obvious reasons why certain frog species are disappearing from rainforests in Australia that have barely been touched by human hand. The mystery is unsettling to say the least, for it is known that amphibian species are extremely sensitive to environmental variations in temperature and moisture levels. The danger is that planet Earth might not only lose a vital link in the ecological food chain (frogs keep populations of otherwise pestilent insects at manageable levels), but we might be increasing our output of air pollutants to levels that may have already become irreversible. Frogs could be inadvertently warning us of a catastrophe. An example of a species of frog that, at far as is known, has become extinct, is the platypus frog. Like the well-known Australian mammal it was named after, it exhibited some very strange behaviour; instead of giving birth to tadpoles in the water, it raised its young within its stomach. The baby frogs were actually born from out of their mother's mouth. Discovered in 1981, less than ten years later the frog had completely vanished from the crystal clear waters of Booloumba Creek near Queensland's Sunshine Coast. Unfortunately, this freak of nature is not the only frog species to have been lost in Australia. Since the 1970s, no less than eight others have suffered the same fate. One theory that seems to fit the facts concerns the depletion of the ozone layer, a well documented phenomenon which has led to a sharp increase in ultraviolet radiation levels. The ozone layer is meant to shield the Earth from UV rays, but increased radiation may be having a greater effect upon frog populations than previously believed. Another theory is that worldwide temperature increases are upsetting the breeding cycles of frogs.", "hypothesis": "Eight frog species have become extinct so far in Australia.", "gold_label": "contradiction"}
{"uid": "id_595", "premise": "When was the last time you saw a frog? Chances are, if you live in a city, you have not seen one for some time. Even in wet areas once teeming with frogs and toads, it is becoming less and less easy to find those slimy, hopping and sometimes poisonous members of the animal kingdom. All over the world, and even in remote parts of Australia, frogs are losing the ecological battle for survival, and biologists are at a loss to explain their demise. Are amphibians simply oversensitive to changes in the ecosystem? Could it be that their rapid decline in numbers is signaling some coming environmental disaster for us all? This frightening scenario is in part the consequence of a dramatic increase over the last quarter century in the development of once natural areas of wet marshland; home not only to frogs but to all manner of wildlife. However, as yet, there are no obvious reasons why certain frog species are disappearing from rainforests in Australia that have barely been touched by human hand. The mystery is unsettling to say the least, for it is known that amphibian species are extremely sensitive to environmental variations in temperature and moisture levels. The danger is that planet Earth might not only lose a vital link in the ecological food chain (frogs keep populations of otherwise pestilent insects at manageable levels), but we might be increasing our output of air pollutants to levels that may have already become irreversible. Frogs could be inadvertently warning us of a catastrophe. An example of a species of frog that, at far as is known, has become extinct, is the platypus frog. Like the well-known Australian mammal it was named after, it exhibited some very strange behaviour; instead of giving birth to tadpoles in the water, it raised its young within its stomach. The baby frogs were actually born from out of their mother's mouth. Discovered in 1981, less than ten years later the frog had completely vanished from the crystal clear waters of Booloumba Creek near Queensland's Sunshine Coast. Unfortunately, this freak of nature is not the only frog species to have been lost in Australia. Since the 1970s, no less than eight others have suffered the same fate. One theory that seems to fit the facts concerns the depletion of the ozone layer, a well documented phenomenon which has led to a sharp increase in ultraviolet radiation levels. The ozone layer is meant to shield the Earth from UV rays, but increased radiation may be having a greater effect upon frog populations than previously believed. Another theory is that worldwide temperature increases are upsetting the breeding cycles of frogs.", "hypothesis": "There is convincing evidence that the ozone layer is being depleted.", "gold_label": "entailment"}
{"uid": "id_596", "premise": "When was the last time you saw a frog? Chances are, if you live in a city, you have not seen one for some time. Even in wet areas once teeming with frogs and toads, it is becoming less and less easy to find those slimy, hopping and sometimes poisonous members of the animal kingdom. All over the world, and even in remote parts of Australia, frogs are losing the ecological battle for survival, and biologists are at a loss to explain their demise. Are amphibians simply oversensitive to changes in the ecosystem? Could it be that their rapid decline in numbers is signaling some coming environmental disaster for us all? This frightening scenario is in part the consequence of a dramatic increase over the last quarter century in the development of once natural areas of wet marshland; home not only to frogs but to all manner of wildlife. However, as yet, there are no obvious reasons why certain frog species are disappearing from rainforests in Australia that have barely been touched by human hand. The mystery is unsettling to say the least, for it is known that amphibian species are extremely sensitive to environmental variations in temperature and moisture levels. The danger is that planet Earth might not only lose a vital link in the ecological food chain (frogs keep populations of otherwise pestilent insects at manageable levels), but we might be increasing our output of air pollutants to levels that may have already become irreversible. Frogs could be inadvertently warning us of a catastrophe. An example of a species of frog that, at far as is known, has become extinct, is the platypus frog. Like the well-known Australian mammal it was named after, it exhibited some very strange behaviour; instead of giving birth to tadpoles in the water, it raised its young within its stomach. The baby frogs were actually born from out of their mother's mouth. Discovered in 1981, less than ten years later the frog had completely vanished from the crystal clear waters of Booloumba Creek near Queensland's Sunshine Coast. Unfortunately, this freak of nature is not the only frog species to have been lost in Australia. Since the 1970s, no less than eight others have suffered the same fate. One theory that seems to fit the facts concerns the depletion of the ozone layer, a well documented phenomenon which has led to a sharp increase in ultraviolet radiation levels. The ozone layer is meant to shield the Earth from UV rays, but increased radiation may be having a greater effect upon frog populations than previously believed. Another theory is that worldwide temperature increases are upsetting the breeding cycles of frogs.", "hypothesis": "It is a fact that frogs' breeding cycles are upset by worldwide in creases in temperature.", "gold_label": "contradiction"}
{"uid": "id_597", "premise": "When you think about it, kissing is strange and a bit icky. You share saliva with someone, sometimes for a prolonged period of time. One kiss could pass on 80 million bacteria, not all of them good. Yet everyone surely remembers their first kiss, in all its embarrassing or delightful detail, and kissing continues to play a big role in new romances. At least, it does in some societies. People in western societies may assume that romantic kissing is a universal human behaviour, but a new analysis suggests that less than half of all cultures actually do it. Kissing is also extremely rare in the animal kingdom. So whats really behind this odd behaviour? If it is useful, why dont all animals do it and all humans too? It turns out that the very fact that most animals dont kiss helps explain why some do. According to a new study of kissing preferences, which looked at 168 cultures from around the world, only 46% of cultures kiss in the romantic sense. Previous estimates had put the figure at 90%. The new study excluded parents kissing their children, and focused solely on romantic lip-on-lip action between couples. Many hunter-gatherer groups showed no evidence of kissing or desire to do so. Some even considered it revolting. The Mehinaku tribe in Brazil reportedly said it was gross. Given that hunter-gatherer groups are the closest modern humans get to living our ancestral lifestyle, our ancestors may not have been kissing either. The study overturns the belief that romantic kissing is a near-universal human behaviour, says lead author William Jankowiak of the University of Nevada in Las Vegas. Instead it seems to be a product of western societies, passed on from one generation to the next, he says. There is some historical evidence to back that up. Kissing as we do it today seems to be a fairly recent invention, says Rafael Wlodarski of the University of Oxford in the UK. He has trawled through records to find evidence of how kissing has changed. The oldest evidence of a kissing-type behaviour comes from Hindu Vedic Sanskrit texts from over 3,500 years ago. Kissing was described as inhaling each others soul. In contrast, Egyptian hieroglyphics picture people close to each other rather than pressing their lips together. So what is going on? Is kissing something we do naturally, but that some cultures have suppressed? Or is it something modern humans have invented? We can find some insight by looking at animals. Our closest relatives, chimpanzees and bonobos, do kiss. Primatologist Frans de Waal of Emory University in Atlanta, Georgia, has seen many instances of chimps kissing and hugging after conflict. For chimpanzees, kissing is a form of reconciliation. It is more common among males than females. In other words, it is not a romantic behaviour. Their cousins the bonobos kiss more often, and they often use tongues while doing so. Thats perhaps not surprising, because bonobos are highly sexual beings. When two humans meet, we might shake hands. Bonobos have sex: the so-called bonobo handshake. They also use sex for many other kinds of bonding. So their kisses are not particularly romantic, either. These two apes are exceptions. As far as we know, other animals do not kiss at all. They may nuzzle or touch their faces together, but even those that have lips dont share saliva or purse and smack their lips together. They dont need to. Take wild boars. Males produce a pungent smell that females find extremely attractive. The key chemical is a pheromone called androstenone that triggers the females desire to mate. From a females point of view this is a good thing, because males with the most androstonene are also the most fertile. Her sense of smell is so acute, she doesnt need to get close enough to kiss the male. The same is true of many other mammals. For example, female hamsters emit a pheromone that gets males very excited. Mice follow similar chemical traces to help them find partners that are genetically different, minimising the risk of accidental incest. Animals often release these pheromones in their urine. Their urine is much more pungent, says Wlodarski. If theres urine present in the environment they can assess compatibility through that. Its not just mammals that have a great sense of smell. A male black widow spider can smell pheromones produced by a female that tell him if she has recently eaten. To minimise the risk of being eaten, he will only mate with her if she is not hungry. The point is, animals do not need to get close to each other to smell out a good potential mate. On the other hand, humans have an atrocious sense of smell, so we benefit from getting close. Smell isnt the only cue we use to assess each others fitness, but studies have shown that it plays an important role in mate choice. A study published in 1995 showed that women, just like mice, prefer the smell of men who are genetically different from them. This makes sense, as mating with someone with different genes is likely to produce healthy offspring. Kissing is a great way to get close enough to sniff out your partners genes. In 2013, Wlodarski examined kissing preferences in detail. He asked several hundred people what was most important when kissing someone. How they smelled featured highly, and the importance of smell increased when women were most fertile. It turns out that men also make a version of the pheromone that female boars find attractive. It is present in male sweat, and when women are exposed to it their arousal levels increase slightly. Pheromones are a big part of how mammals chose a mate, says Wlodarski, and we share some of them. Weve inherited all of our biology from mammals, weve just added extra things through evolutionary time. On that view, kissing is just a culturally acceptable way to get close enough to another person to detect their pheromones. In some cultures, this sniffing behaviour turned into physical lip contact. Its hard to pinpoint when this happened, but both serve the same purpose, says Wlodarski. So if you want to find a perfect match, you could forego kissing and start smelling people instead. Youll find just as good a partner, and you wont get half as many germs. Be prepared for some funny looks, though.", "hypothesis": "Wlodarski surveyed several men to figure out the importance of kissing.", "gold_label": "neutral"}
{"uid": "id_598", "premise": "When you think about it, kissing is strange and a bit icky. You share saliva with someone, sometimes for a prolonged period of time. One kiss could pass on 80 million bacteria, not all of them good. Yet everyone surely remembers their first kiss, in all its embarrassing or delightful detail, and kissing continues to play a big role in new romances. At least, it does in some societies. People in western societies may assume that romantic kissing is a universal human behaviour, but a new analysis suggests that less than half of all cultures actually do it. Kissing is also extremely rare in the animal kingdom. So whats really behind this odd behaviour? If it is useful, why dont all animals do it and all humans too? It turns out that the very fact that most animals dont kiss helps explain why some do. According to a new study of kissing preferences, which looked at 168 cultures from around the world, only 46% of cultures kiss in the romantic sense. Previous estimates had put the figure at 90%. The new study excluded parents kissing their children, and focused solely on romantic lip-on-lip action between couples. Many hunter-gatherer groups showed no evidence of kissing or desire to do so. Some even considered it revolting. The Mehinaku tribe in Brazil reportedly said it was gross. Given that hunter-gatherer groups are the closest modern humans get to living our ancestral lifestyle, our ancestors may not have been kissing either. The study overturns the belief that romantic kissing is a near-universal human behaviour, says lead author William Jankowiak of the University of Nevada in Las Vegas. Instead it seems to be a product of western societies, passed on from one generation to the next, he says. There is some historical evidence to back that up. Kissing as we do it today seems to be a fairly recent invention, says Rafael Wlodarski of the University of Oxford in the UK. He has trawled through records to find evidence of how kissing has changed. The oldest evidence of a kissing-type behaviour comes from Hindu Vedic Sanskrit texts from over 3,500 years ago. Kissing was described as inhaling each others soul. In contrast, Egyptian hieroglyphics picture people close to each other rather than pressing their lips together. So what is going on? Is kissing something we do naturally, but that some cultures have suppressed? Or is it something modern humans have invented? We can find some insight by looking at animals. Our closest relatives, chimpanzees and bonobos, do kiss. Primatologist Frans de Waal of Emory University in Atlanta, Georgia, has seen many instances of chimps kissing and hugging after conflict. For chimpanzees, kissing is a form of reconciliation. It is more common among males than females. In other words, it is not a romantic behaviour. Their cousins the bonobos kiss more often, and they often use tongues while doing so. Thats perhaps not surprising, because bonobos are highly sexual beings. When two humans meet, we might shake hands. Bonobos have sex: the so-called bonobo handshake. They also use sex for many other kinds of bonding. So their kisses are not particularly romantic, either. These two apes are exceptions. As far as we know, other animals do not kiss at all. They may nuzzle or touch their faces together, but even those that have lips dont share saliva or purse and smack their lips together. They dont need to. Take wild boars. Males produce a pungent smell that females find extremely attractive. The key chemical is a pheromone called androstenone that triggers the females desire to mate. From a females point of view this is a good thing, because males with the most androstonene are also the most fertile. Her sense of smell is so acute, she doesnt need to get close enough to kiss the male. The same is true of many other mammals. For example, female hamsters emit a pheromone that gets males very excited. Mice follow similar chemical traces to help them find partners that are genetically different, minimising the risk of accidental incest. Animals often release these pheromones in their urine. Their urine is much more pungent, says Wlodarski. If theres urine present in the environment they can assess compatibility through that. Its not just mammals that have a great sense of smell. A male black widow spider can smell pheromones produced by a female that tell him if she has recently eaten. To minimise the risk of being eaten, he will only mate with her if she is not hungry. The point is, animals do not need to get close to each other to smell out a good potential mate. On the other hand, humans have an atrocious sense of smell, so we benefit from getting close. Smell isnt the only cue we use to assess each others fitness, but studies have shown that it plays an important role in mate choice. A study published in 1995 showed that women, just like mice, prefer the smell of men who are genetically different from them. This makes sense, as mating with someone with different genes is likely to produce healthy offspring. Kissing is a great way to get close enough to sniff out your partners genes. In 2013, Wlodarski examined kissing preferences in detail. He asked several hundred people what was most important when kissing someone. How they smelled featured highly, and the importance of smell increased when women were most fertile. It turns out that men also make a version of the pheromone that female boars find attractive. It is present in male sweat, and when women are exposed to it their arousal levels increase slightly. Pheromones are a big part of how mammals chose a mate, says Wlodarski, and we share some of them. Weve inherited all of our biology from mammals, weve just added extra things through evolutionary time. On that view, kissing is just a culturally acceptable way to get close enough to another person to detect their pheromones. In some cultures, this sniffing behaviour turned into physical lip contact. Its hard to pinpoint when this happened, but both serve the same purpose, says Wlodarski. So if you want to find a perfect match, you could forego kissing and start smelling people instead. Youll find just as good a partner, and you wont get half as many germs. Be prepared for some funny looks, though.", "hypothesis": "Scent might be important in choosing your partner.", "gold_label": "entailment"}
{"uid": "id_599", "premise": "When you think about it, kissing is strange and a bit icky. You share saliva with someone, sometimes for a prolonged period of time. One kiss could pass on 80 million bacteria, not all of them good. Yet everyone surely remembers their first kiss, in all its embarrassing or delightful detail, and kissing continues to play a big role in new romances. At least, it does in some societies. People in western societies may assume that romantic kissing is a universal human behaviour, but a new analysis suggests that less than half of all cultures actually do it. Kissing is also extremely rare in the animal kingdom. So whats really behind this odd behaviour? If it is useful, why dont all animals do it and all humans too? It turns out that the very fact that most animals dont kiss helps explain why some do. According to a new study of kissing preferences, which looked at 168 cultures from around the world, only 46% of cultures kiss in the romantic sense. Previous estimates had put the figure at 90%. The new study excluded parents kissing their children, and focused solely on romantic lip-on-lip action between couples. Many hunter-gatherer groups showed no evidence of kissing or desire to do so. Some even considered it revolting. The Mehinaku tribe in Brazil reportedly said it was gross. Given that hunter-gatherer groups are the closest modern humans get to living our ancestral lifestyle, our ancestors may not have been kissing either. The study overturns the belief that romantic kissing is a near-universal human behaviour, says lead author William Jankowiak of the University of Nevada in Las Vegas. Instead it seems to be a product of western societies, passed on from one generation to the next, he says. There is some historical evidence to back that up. Kissing as we do it today seems to be a fairly recent invention, says Rafael Wlodarski of the University of Oxford in the UK. He has trawled through records to find evidence of how kissing has changed. The oldest evidence of a kissing-type behaviour comes from Hindu Vedic Sanskrit texts from over 3,500 years ago. Kissing was described as inhaling each others soul. In contrast, Egyptian hieroglyphics picture people close to each other rather than pressing their lips together. So what is going on? Is kissing something we do naturally, but that some cultures have suppressed? Or is it something modern humans have invented? We can find some insight by looking at animals. Our closest relatives, chimpanzees and bonobos, do kiss. Primatologist Frans de Waal of Emory University in Atlanta, Georgia, has seen many instances of chimps kissing and hugging after conflict. For chimpanzees, kissing is a form of reconciliation. It is more common among males than females. In other words, it is not a romantic behaviour. Their cousins the bonobos kiss more often, and they often use tongues while doing so. Thats perhaps not surprising, because bonobos are highly sexual beings. When two humans meet, we might shake hands. Bonobos have sex: the so-called bonobo handshake. They also use sex for many other kinds of bonding. So their kisses are not particularly romantic, either. These two apes are exceptions. As far as we know, other animals do not kiss at all. They may nuzzle or touch their faces together, but even those that have lips dont share saliva or purse and smack their lips together. They dont need to. Take wild boars. Males produce a pungent smell that females find extremely attractive. The key chemical is a pheromone called androstenone that triggers the females desire to mate. From a females point of view this is a good thing, because males with the most androstonene are also the most fertile. Her sense of smell is so acute, she doesnt need to get close enough to kiss the male. The same is true of many other mammals. For example, female hamsters emit a pheromone that gets males very excited. Mice follow similar chemical traces to help them find partners that are genetically different, minimising the risk of accidental incest. Animals often release these pheromones in their urine. Their urine is much more pungent, says Wlodarski. If theres urine present in the environment they can assess compatibility through that. Its not just mammals that have a great sense of smell. A male black widow spider can smell pheromones produced by a female that tell him if she has recently eaten. To minimise the risk of being eaten, he will only mate with her if she is not hungry. The point is, animals do not need to get close to each other to smell out a good potential mate. On the other hand, humans have an atrocious sense of smell, so we benefit from getting close. Smell isnt the only cue we use to assess each others fitness, but studies have shown that it plays an important role in mate choice. A study published in 1995 showed that women, just like mice, prefer the smell of men who are genetically different from them. This makes sense, as mating with someone with different genes is likely to produce healthy offspring. Kissing is a great way to get close enough to sniff out your partners genes. In 2013, Wlodarski examined kissing preferences in detail. He asked several hundred people what was most important when kissing someone. How they smelled featured highly, and the importance of smell increased when women were most fertile. It turns out that men also make a version of the pheromone that female boars find attractive. It is present in male sweat, and when women are exposed to it their arousal levels increase slightly. Pheromones are a big part of how mammals chose a mate, says Wlodarski, and we share some of them. Weve inherited all of our biology from mammals, weve just added extra things through evolutionary time. On that view, kissing is just a culturally acceptable way to get close enough to another person to detect their pheromones. In some cultures, this sniffing behaviour turned into physical lip contact. Its hard to pinpoint when this happened, but both serve the same purpose, says Wlodarski. So if you want to find a perfect match, you could forego kissing and start smelling people instead. Youll find just as good a partner, and you wont get half as many germs. Be prepared for some funny looks, though.", "hypothesis": "Both Easter and Wester societies presume that kissing is essential for any part of the world.", "gold_label": "contradiction"}
{"uid": "id_600", "premise": "When you think about it, kissing is strange and a bit icky. You share saliva with someone, sometimes for a prolonged period of time. One kiss could pass on 80 million bacteria, not all of them good. Yet everyone surely remembers their first kiss, in all its embarrassing or delightful detail, and kissing continues to play a big role in new romances. At least, it does in some societies. People in western societies may assume that romantic kissing is a universal human behaviour, but a new analysis suggests that less than half of all cultures actually do it. Kissing is also extremely rare in the animal kingdom. So whats really behind this odd behaviour? If it is useful, why dont all animals do it and all humans too? It turns out that the very fact that most animals dont kiss helps explain why some do. According to a new study of kissing preferences, which looked at 168 cultures from around the world, only 46% of cultures kiss in the romantic sense. Previous estimates had put the figure at 90%. The new study excluded parents kissing their children, and focused solely on romantic lip-on-lip action between couples. Many hunter-gatherer groups showed no evidence of kissing or desire to do so. Some even considered it revolting. The Mehinaku tribe in Brazil reportedly said it was gross. Given that hunter-gatherer groups are the closest modern humans get to living our ancestral lifestyle, our ancestors may not have been kissing either. The study overturns the belief that romantic kissing is a near-universal human behaviour, says lead author William Jankowiak of the University of Nevada in Las Vegas. Instead it seems to be a product of western societies, passed on from one generation to the next, he says. There is some historical evidence to back that up. Kissing as we do it today seems to be a fairly recent invention, says Rafael Wlodarski of the University of Oxford in the UK. He has trawled through records to find evidence of how kissing has changed. The oldest evidence of a kissing-type behaviour comes from Hindu Vedic Sanskrit texts from over 3,500 years ago. Kissing was described as inhaling each others soul. In contrast, Egyptian hieroglyphics picture people close to each other rather than pressing their lips together. So what is going on? Is kissing something we do naturally, but that some cultures have suppressed? Or is it something modern humans have invented? We can find some insight by looking at animals. Our closest relatives, chimpanzees and bonobos, do kiss. Primatologist Frans de Waal of Emory University in Atlanta, Georgia, has seen many instances of chimps kissing and hugging after conflict. For chimpanzees, kissing is a form of reconciliation. It is more common among males than females. In other words, it is not a romantic behaviour. Their cousins the bonobos kiss more often, and they often use tongues while doing so. Thats perhaps not surprising, because bonobos are highly sexual beings. When two humans meet, we might shake hands. Bonobos have sex: the so-called bonobo handshake. They also use sex for many other kinds of bonding. So their kisses are not particularly romantic, either. These two apes are exceptions. As far as we know, other animals do not kiss at all. They may nuzzle or touch their faces together, but even those that have lips dont share saliva or purse and smack their lips together. They dont need to. Take wild boars. Males produce a pungent smell that females find extremely attractive. The key chemical is a pheromone called androstenone that triggers the females desire to mate. From a females point of view this is a good thing, because males with the most androstonene are also the most fertile. Her sense of smell is so acute, she doesnt need to get close enough to kiss the male. The same is true of many other mammals. For example, female hamsters emit a pheromone that gets males very excited. Mice follow similar chemical traces to help them find partners that are genetically different, minimising the risk of accidental incest. Animals often release these pheromones in their urine. Their urine is much more pungent, says Wlodarski. If theres urine present in the environment they can assess compatibility through that. Its not just mammals that have a great sense of smell. A male black widow spider can smell pheromones produced by a female that tell him if she has recently eaten. To minimise the risk of being eaten, he will only mate with her if she is not hungry. The point is, animals do not need to get close to each other to smell out a good potential mate. On the other hand, humans have an atrocious sense of smell, so we benefit from getting close. Smell isnt the only cue we use to assess each others fitness, but studies have shown that it plays an important role in mate choice. A study published in 1995 showed that women, just like mice, prefer the smell of men who are genetically different from them. This makes sense, as mating with someone with different genes is likely to produce healthy offspring. Kissing is a great way to get close enough to sniff out your partners genes. In 2013, Wlodarski examined kissing preferences in detail. He asked several hundred people what was most important when kissing someone. How they smelled featured highly, and the importance of smell increased when women were most fertile. It turns out that men also make a version of the pheromone that female boars find attractive. It is present in male sweat, and when women are exposed to it their arousal levels increase slightly. Pheromones are a big part of how mammals chose a mate, says Wlodarski, and we share some of them. Weve inherited all of our biology from mammals, weve just added extra things through evolutionary time. On that view, kissing is just a culturally acceptable way to get close enough to another person to detect their pheromones. In some cultures, this sniffing behaviour turned into physical lip contact. Its hard to pinpoint when this happened, but both serve the same purpose, says Wlodarski. So if you want to find a perfect match, you could forego kissing and start smelling people instead. Youll find just as good a partner, and you wont get half as many germs. Be prepared for some funny looks, though.", "hypothesis": "Our ancestors were not likely to kiss.", "gold_label": "entailment"}
{"uid": "id_601", "premise": "When you think about it, kissing is strange and a bit icky. You share saliva with someone, sometimes for a prolonged period of time. One kiss could pass on 80 million bacteria, not all of them good. Yet everyone surely remembers their first kiss, in all its embarrassing or delightful detail, and kissing continues to play a big role in new romances. At least, it does in some societies. People in western societies may assume that romantic kissing is a universal human behaviour, but a new analysis suggests that less than half of all cultures actually do it. Kissing is also extremely rare in the animal kingdom. So whats really behind this odd behaviour? If it is useful, why dont all animals do it and all humans too? It turns out that the very fact that most animals dont kiss helps explain why some do. According to a new study of kissing preferences, which looked at 168 cultures from around the world, only 46% of cultures kiss in the romantic sense. Previous estimates had put the figure at 90%. The new study excluded parents kissing their children, and focused solely on romantic lip-on-lip action between couples. Many hunter-gatherer groups showed no evidence of kissing or desire to do so. Some even considered it revolting. The Mehinaku tribe in Brazil reportedly said it was gross. Given that hunter-gatherer groups are the closest modern humans get to living our ancestral lifestyle, our ancestors may not have been kissing either. The study overturns the belief that romantic kissing is a near-universal human behaviour, says lead author William Jankowiak of the University of Nevada in Las Vegas. Instead it seems to be a product of western societies, passed on from one generation to the next, he says. There is some historical evidence to back that up. Kissing as we do it today seems to be a fairly recent invention, says Rafael Wlodarski of the University of Oxford in the UK. He has trawled through records to find evidence of how kissing has changed. The oldest evidence of a kissing-type behaviour comes from Hindu Vedic Sanskrit texts from over 3,500 years ago. Kissing was described as inhaling each others soul. In contrast, Egyptian hieroglyphics picture people close to each other rather than pressing their lips together. So what is going on? Is kissing something we do naturally, but that some cultures have suppressed? Or is it something modern humans have invented? We can find some insight by looking at animals. Our closest relatives, chimpanzees and bonobos, do kiss. Primatologist Frans de Waal of Emory University in Atlanta, Georgia, has seen many instances of chimps kissing and hugging after conflict. For chimpanzees, kissing is a form of reconciliation. It is more common among males than females. In other words, it is not a romantic behaviour. Their cousins the bonobos kiss more often, and they often use tongues while doing so. Thats perhaps not surprising, because bonobos are highly sexual beings. When two humans meet, we might shake hands. Bonobos have sex: the so-called bonobo handshake. They also use sex for many other kinds of bonding. So their kisses are not particularly romantic, either. These two apes are exceptions. As far as we know, other animals do not kiss at all. They may nuzzle or touch their faces together, but even those that have lips dont share saliva or purse and smack their lips together. They dont need to. Take wild boars. Males produce a pungent smell that females find extremely attractive. The key chemical is a pheromone called androstenone that triggers the females desire to mate. From a females point of view this is a good thing, because males with the most androstonene are also the most fertile. Her sense of smell is so acute, she doesnt need to get close enough to kiss the male. The same is true of many other mammals. For example, female hamsters emit a pheromone that gets males very excited. Mice follow similar chemical traces to help them find partners that are genetically different, minimising the risk of accidental incest. Animals often release these pheromones in their urine. Their urine is much more pungent, says Wlodarski. If theres urine present in the environment they can assess compatibility through that. Its not just mammals that have a great sense of smell. A male black widow spider can smell pheromones produced by a female that tell him if she has recently eaten. To minimise the risk of being eaten, he will only mate with her if she is not hungry. The point is, animals do not need to get close to each other to smell out a good potential mate. On the other hand, humans have an atrocious sense of smell, so we benefit from getting close. Smell isnt the only cue we use to assess each others fitness, but studies have shown that it plays an important role in mate choice. A study published in 1995 showed that women, just like mice, prefer the smell of men who are genetically different from them. This makes sense, as mating with someone with different genes is likely to produce healthy offspring. Kissing is a great way to get close enough to sniff out your partners genes. In 2013, Wlodarski examined kissing preferences in detail. He asked several hundred people what was most important when kissing someone. How they smelled featured highly, and the importance of smell increased when women were most fertile. It turns out that men also make a version of the pheromone that female boars find attractive. It is present in male sweat, and when women are exposed to it their arousal levels increase slightly. Pheromones are a big part of how mammals chose a mate, says Wlodarski, and we share some of them. Weve inherited all of our biology from mammals, weve just added extra things through evolutionary time. On that view, kissing is just a culturally acceptable way to get close enough to another person to detect their pheromones. In some cultures, this sniffing behaviour turned into physical lip contact. Its hard to pinpoint when this happened, but both serve the same purpose, says Wlodarski. So if you want to find a perfect match, you could forego kissing and start smelling people instead. Youll find just as good a partner, and you wont get half as many germs. Be prepared for some funny looks, though.", "hypothesis": "Chimpanzees and bonbons kiss not for the romance.", "gold_label": "entailment"}
{"uid": "id_602", "premise": "When you think about it, kissing is strange and a bit icky. You share saliva with someone, sometimes for a prolonged period of time. One kiss could pass on 80 million bacteria, not all of them good. Yet everyone surely remembers their first kiss, in all its embarrassing or delightful detail, and kissing continues to play a big role in new romances. At least, it does in some societies. People in western societies may assume that romantic kissing is a universal human behaviour, but a new analysis suggests that less than half of all cultures actually do it. Kissing is also extremely rare in the animal kingdom. So whats really behind this odd behaviour? If it is useful, why dont all animals do it and all humans too? It turns out that the very fact that most animals dont kiss helps explain why some do. According to a new study of kissing preferences, which looked at 168 cultures from around the world, only 46% of cultures kiss in the romantic sense. Previous estimates had put the figure at 90%. The new study excluded parents kissing their children, and focused solely on romantic lip-on-lip action between couples. Many hunter-gatherer groups showed no evidence of kissing or desire to do so. Some even considered it revolting. The Mehinaku tribe in Brazil reportedly said it was gross. Given that hunter-gatherer groups are the closest modern humans get to living our ancestral lifestyle, our ancestors may not have been kissing either. The study overturns the belief that romantic kissing is a near-universal human behaviour, says lead author William Jankowiak of the University of Nevada in Las Vegas. Instead it seems to be a product of western societies, passed on from one generation to the next, he says. There is some historical evidence to back that up. Kissing as we do it today seems to be a fairly recent invention, says Rafael Wlodarski of the University of Oxford in the UK. He has trawled through records to find evidence of how kissing has changed. The oldest evidence of a kissing-type behaviour comes from Hindu Vedic Sanskrit texts from over 3,500 years ago. Kissing was described as inhaling each others soul. In contrast, Egyptian hieroglyphics picture people close to each other rather than pressing their lips together. So what is going on? Is kissing something we do naturally, but that some cultures have suppressed? Or is it something modern humans have invented? We can find some insight by looking at animals. Our closest relatives, chimpanzees and bonobos, do kiss. Primatologist Frans de Waal of Emory University in Atlanta, Georgia, has seen many instances of chimps kissing and hugging after conflict. For chimpanzees, kissing is a form of reconciliation. It is more common among males than females. In other words, it is not a romantic behaviour. Their cousins the bonobos kiss more often, and they often use tongues while doing so. Thats perhaps not surprising, because bonobos are highly sexual beings. When two humans meet, we might shake hands. Bonobos have sex: the so-called bonobo handshake. They also use sex for many other kinds of bonding. So their kisses are not particularly romantic, either. These two apes are exceptions. As far as we know, other animals do not kiss at all. They may nuzzle or touch their faces together, but even those that have lips dont share saliva or purse and smack their lips together. They dont need to. Take wild boars. Males produce a pungent smell that females find extremely attractive. The key chemical is a pheromone called androstenone that triggers the females desire to mate. From a females point of view this is a good thing, because males with the most androstonene are also the most fertile. Her sense of smell is so acute, she doesnt need to get close enough to kiss the male. The same is true of many other mammals. For example, female hamsters emit a pheromone that gets males very excited. Mice follow similar chemical traces to help them find partners that are genetically different, minimising the risk of accidental incest. Animals often release these pheromones in their urine. Their urine is much more pungent, says Wlodarski. If theres urine present in the environment they can assess compatibility through that. Its not just mammals that have a great sense of smell. A male black widow spider can smell pheromones produced by a female that tell him if she has recently eaten. To minimise the risk of being eaten, he will only mate with her if she is not hungry. The point is, animals do not need to get close to each other to smell out a good potential mate. On the other hand, humans have an atrocious sense of smell, so we benefit from getting close. Smell isnt the only cue we use to assess each others fitness, but studies have shown that it plays an important role in mate choice. A study published in 1995 showed that women, just like mice, prefer the smell of men who are genetically different from them. This makes sense, as mating with someone with different genes is likely to produce healthy offspring. Kissing is a great way to get close enough to sniff out your partners genes. In 2013, Wlodarski examined kissing preferences in detail. He asked several hundred people what was most important when kissing someone. How they smelled featured highly, and the importance of smell increased when women were most fertile. It turns out that men also make a version of the pheromone that female boars find attractive. It is present in male sweat, and when women are exposed to it their arousal levels increase slightly. Pheromones are a big part of how mammals chose a mate, says Wlodarski, and we share some of them. Weve inherited all of our biology from mammals, weve just added extra things through evolutionary time. On that view, kissing is just a culturally acceptable way to get close enough to another person to detect their pheromones. In some cultures, this sniffing behaviour turned into physical lip contact. Its hard to pinpoint when this happened, but both serve the same purpose, says Wlodarski. So if you want to find a perfect match, you could forego kissing and start smelling people instead. Youll find just as good a partner, and you wont get half as many germs. Be prepared for some funny looks, though.", "hypothesis": "There are other animal, rather than apes, that kiss.", "gold_label": "contradiction"}
{"uid": "id_603", "premise": "When you think about it, kissing is strange and a bit icky. You share saliva with someone, sometimes for a prolonged period of time. One kiss could pass on 80 million bacteria, not all of them good. Yet everyone surely remembers their first kiss, in all its embarrassing or delightful detail, and kissing continues to play a big role in new romances. At least, it does in some societies. People in western societies may assume that romantic kissing is a universal human behaviour, but a new analysis suggests that less than half of all cultures actually do it. Kissing is also extremely rare in the animal kingdom. So whats really behind this odd behaviour? If it is useful, why dont all animals do it and all humans too? It turns out that the very fact that most animals dont kiss helps explain why some do. According to a new study of kissing preferences, which looked at 168 cultures from around the world, only 46% of cultures kiss in the romantic sense. Previous estimates had put the figure at 90%. The new study excluded parents kissing their children, and focused solely on romantic lip-on-lip action between couples. Many hunter-gatherer groups showed no evidence of kissing or desire to do so. Some even considered it revolting. The Mehinaku tribe in Brazil reportedly said it was gross. Given that hunter-gatherer groups are the closest modern humans get to living our ancestral lifestyle, our ancestors may not have been kissing either. The study overturns the belief that romantic kissing is a near-universal human behaviour, says lead author William Jankowiak of the University of Nevada in Las Vegas. Instead it seems to be a product of western societies, passed on from one generation to the next, he says. There is some historical evidence to back that up. Kissing as we do it today seems to be a fairly recent invention, says Rafael Wlodarski of the University of Oxford in the UK. He has trawled through records to find evidence of how kissing has changed. The oldest evidence of a kissing-type behaviour comes from Hindu Vedic Sanskrit texts from over 3,500 years ago. Kissing was described as inhaling each others soul. In contrast, Egyptian hieroglyphics picture people close to each other rather than pressing their lips together. So what is going on? Is kissing something we do naturally, but that some cultures have suppressed? Or is it something modern humans have invented? We can find some insight by looking at animals. Our closest relatives, chimpanzees and bonobos, do kiss. Primatologist Frans de Waal of Emory University in Atlanta, Georgia, has seen many instances of chimps kissing and hugging after conflict. For chimpanzees, kissing is a form of reconciliation. It is more common among males than females. In other words, it is not a romantic behaviour. Their cousins the bonobos kiss more often, and they often use tongues while doing so. Thats perhaps not surprising, because bonobos are highly sexual beings. When two humans meet, we might shake hands. Bonobos have sex: the so-called bonobo handshake. They also use sex for many other kinds of bonding. So their kisses are not particularly romantic, either. These two apes are exceptions. As far as we know, other animals do not kiss at all. They may nuzzle or touch their faces together, but even those that have lips dont share saliva or purse and smack their lips together. They dont need to. Take wild boars. Males produce a pungent smell that females find extremely attractive. The key chemical is a pheromone called androstenone that triggers the females desire to mate. From a females point of view this is a good thing, because males with the most androstonene are also the most fertile. Her sense of smell is so acute, she doesnt need to get close enough to kiss the male. The same is true of many other mammals. For example, female hamsters emit a pheromone that gets males very excited. Mice follow similar chemical traces to help them find partners that are genetically different, minimising the risk of accidental incest. Animals often release these pheromones in their urine. Their urine is much more pungent, says Wlodarski. If theres urine present in the environment they can assess compatibility through that. Its not just mammals that have a great sense of smell. A male black widow spider can smell pheromones produced by a female that tell him if she has recently eaten. To minimise the risk of being eaten, he will only mate with her if she is not hungry. The point is, animals do not need to get close to each other to smell out a good potential mate. On the other hand, humans have an atrocious sense of smell, so we benefit from getting close. Smell isnt the only cue we use to assess each others fitness, but studies have shown that it plays an important role in mate choice. A study published in 1995 showed that women, just like mice, prefer the smell of men who are genetically different from them. This makes sense, as mating with someone with different genes is likely to produce healthy offspring. Kissing is a great way to get close enough to sniff out your partners genes. In 2013, Wlodarski examined kissing preferences in detail. He asked several hundred people what was most important when kissing someone. How they smelled featured highly, and the importance of smell increased when women were most fertile. It turns out that men also make a version of the pheromone that female boars find attractive. It is present in male sweat, and when women are exposed to it their arousal levels increase slightly. Pheromones are a big part of how mammals chose a mate, says Wlodarski, and we share some of them. Weve inherited all of our biology from mammals, weve just added extra things through evolutionary time. On that view, kissing is just a culturally acceptable way to get close enough to another person to detect their pheromones. In some cultures, this sniffing behaviour turned into physical lip contact. Its hard to pinpoint when this happened, but both serve the same purpose, says Wlodarski. So if you want to find a perfect match, you could forego kissing and start smelling people instead. Youll find just as good a partner, and you wont get half as many germs. Be prepared for some funny looks, though.", "hypothesis": "According to a Hindu text, kissing is a means to exchange souls.", "gold_label": "entailment"}
{"uid": "id_604", "premise": "When you think about it, kissing is strange and a bit icky. You share saliva with someone, sometimes for a prolonged period of time. One kiss could pass on 80 million bacteria, not all of them good. Yet everyone surely remembers their first kiss, in all its embarrassing or delightful detail, and kissing continues to play a big role in new romances. At least, it does in some societies. People in western societies may assume that romantic kissing is a universal human behaviour, but a new analysis suggests that less than half of all cultures actually do it. Kissing is also extremely rare in the animal kingdom. So whats really behind this odd behaviour? If it is useful, why dont all animals do it and all humans too? It turns out that the very fact that most animals dont kiss helps explain why some do. According to a new study of kissing preferences, which looked at 168 cultures from around the world, only 46% of cultures kiss in the romantic sense. Previous estimates had put the figure at 90%. The new study excluded parents kissing their children, and focused solely on romantic lip-on-lip action between couples. Many hunter-gatherer groups showed no evidence of kissing or desire to do so. Some even considered it revolting. The Mehinaku tribe in Brazil reportedly said it was gross. Given that hunter-gatherer groups are the closest modern humans get to living our ancestral lifestyle, our ancestors may not have been kissing either. The study overturns the belief that romantic kissing is a near-universal human behaviour, says lead author William Jankowiak of the University of Nevada in Las Vegas. Instead it seems to be a product of western societies, passed on from one generation to the next, he says. There is some historical evidence to back that up. Kissing as we do it today seems to be a fairly recent invention, says Rafael Wlodarski of the University of Oxford in the UK. He has trawled through records to find evidence of how kissing has changed. The oldest evidence of a kissing-type behaviour comes from Hindu Vedic Sanskrit texts from over 3,500 years ago. Kissing was described as inhaling each others soul. In contrast, Egyptian hieroglyphics picture people close to each other rather than pressing their lips together. So what is going on? Is kissing something we do naturally, but that some cultures have suppressed? Or is it something modern humans have invented? We can find some insight by looking at animals. Our closest relatives, chimpanzees and bonobos, do kiss. Primatologist Frans de Waal of Emory University in Atlanta, Georgia, has seen many instances of chimps kissing and hugging after conflict. For chimpanzees, kissing is a form of reconciliation. It is more common among males than females. In other words, it is not a romantic behaviour. Their cousins the bonobos kiss more often, and they often use tongues while doing so. Thats perhaps not surprising, because bonobos are highly sexual beings. When two humans meet, we might shake hands. Bonobos have sex: the so-called bonobo handshake. They also use sex for many other kinds of bonding. So their kisses are not particularly romantic, either. These two apes are exceptions. As far as we know, other animals do not kiss at all. They may nuzzle or touch their faces together, but even those that have lips dont share saliva or purse and smack their lips together. They dont need to. Take wild boars. Males produce a pungent smell that females find extremely attractive. The key chemical is a pheromone called androstenone that triggers the females desire to mate. From a females point of view this is a good thing, because males with the most androstonene are also the most fertile. Her sense of smell is so acute, she doesnt need to get close enough to kiss the male. The same is true of many other mammals. For example, female hamsters emit a pheromone that gets males very excited. Mice follow similar chemical traces to help them find partners that are genetically different, minimising the risk of accidental incest. Animals often release these pheromones in their urine. Their urine is much more pungent, says Wlodarski. If theres urine present in the environment they can assess compatibility through that. Its not just mammals that have a great sense of smell. A male black widow spider can smell pheromones produced by a female that tell him if she has recently eaten. To minimise the risk of being eaten, he will only mate with her if she is not hungry. The point is, animals do not need to get close to each other to smell out a good potential mate. On the other hand, humans have an atrocious sense of smell, so we benefit from getting close. Smell isnt the only cue we use to assess each others fitness, but studies have shown that it plays an important role in mate choice. A study published in 1995 showed that women, just like mice, prefer the smell of men who are genetically different from them. This makes sense, as mating with someone with different genes is likely to produce healthy offspring. Kissing is a great way to get close enough to sniff out your partners genes. In 2013, Wlodarski examined kissing preferences in detail. He asked several hundred people what was most important when kissing someone. How they smelled featured highly, and the importance of smell increased when women were most fertile. It turns out that men also make a version of the pheromone that female boars find attractive. It is present in male sweat, and when women are exposed to it their arousal levels increase slightly. Pheromones are a big part of how mammals chose a mate, says Wlodarski, and we share some of them. Weve inherited all of our biology from mammals, weve just added extra things through evolutionary time. On that view, kissing is just a culturally acceptable way to get close enough to another person to detect their pheromones. In some cultures, this sniffing behaviour turned into physical lip contact. Its hard to pinpoint when this happened, but both serve the same purpose, says Wlodarski. So if you want to find a perfect match, you could forego kissing and start smelling people instead. Youll find just as good a partner, and you wont get half as many germs. Be prepared for some funny looks, though.", "hypothesis": "Majority of the microorganisms passed by kissing are beneficial for the body.", "gold_label": "neutral"}
{"uid": "id_605", "premise": "Whereas mvertebrates have an external exoskeleton, humans and other vertebrates have an mternal endoskeleton. The human endoskeleton is comprised of cartilage and the bodys 206 bones, which are connected to each other by ligaments. As well as protecting and supporting the bodys internal organs, the human endoskeketon also works in conjunction with muscles, joints and the nervous system to enable movement. Jomts occur between bones, making the skeleton flexible by acting as hinges or pivots. Tendons attach muscles to bones and contract in response to a stimulus from the bodys nervous system. Those muscles that are under conscious control, the skeletal muscles, act by pullmg against the bones of the skeleton.", "hypothesis": "Bones contract skeletal muscles m response to signals from the nervous system.", "gold_label": "contradiction"}
{"uid": "id_606", "premise": "Whereas mvertebrates have an external exoskeleton, humans and other vertebrates have an mternal endoskeleton. The human endoskeleton is comprised of cartilage and the bodys 206 bones, which are connected to each other by ligaments. As well as protecting and supporting the bodys internal organs, the human endoskeketon also works in conjunction with muscles, joints and the nervous system to enable movement. Jomts occur between bones, making the skeleton flexible by acting as hinges or pivots. Tendons attach muscles to bones and contract in response to a stimulus from the bodys nervous system. Those muscles that are under conscious control, the skeletal muscles, act by pullmg against the bones of the skeleton.", "hypothesis": "Unlike invertebrates, humans have an mternal exoskeleton.", "gold_label": "contradiction"}
{"uid": "id_607", "premise": "Whereas mvertebrates have an external exoskeleton, humans and other vertebrates have an mternal endoskeleton. The human endoskeleton is comprised of cartilage and the bodys 206 bones, which are connected to each other by ligaments. As well as protecting and supporting the bodys internal organs, the human endoskeketon also works in conjunction with muscles, joints and the nervous system to enable movement. Jomts occur between bones, making the skeleton flexible by acting as hinges or pivots. Tendons attach muscles to bones and contract in response to a stimulus from the bodys nervous system. Those muscles that are under conscious control, the skeletal muscles, act by pullmg against the bones of the skeleton.", "hypothesis": "The human skeleton is comprised mamly of bone.", "gold_label": "neutral"}
{"uid": "id_608", "premise": "Whereas mvertebrates have an external exoskeleton, humans and other vertebrates have an mternal endoskeleton. The human endoskeleton is comprised of cartilage and the bodys 206 bones, which are connected to each other by ligaments. As well as protecting and supporting the bodys internal organs, the human endoskeketon also works in conjunction with muscles, joints and the nervous system to enable movement. Jomts occur between bones, making the skeleton flexible by acting as hinges or pivots. Tendons attach muscles to bones and contract in response to a stimulus from the bodys nervous system. Those muscles that are under conscious control, the skeletal muscles, act by pullmg against the bones of the skeleton.", "hypothesis": "The human endoskeleton provides connection pomts for the bodys muscles.", "gold_label": "entailment"}
{"uid": "id_609", "premise": "Whereas mvertebrates have an external exoskeleton, humans and other vertebrates have an mternal endoskeleton. The human endoskeleton is comprised of cartilage and the bodys 206 bones, which are connected to each other by ligaments. As well as protecting and supporting the bodys internal organs, the human endoskeketon also works in conjunction with muscles, joints and the nervous system to enable movement. Jomts occur between bones, making the skeleton flexible by acting as hinges or pivots. Tendons attach muscles to bones and contract in response to a stimulus from the bodys nervous system. Those muscles that are under conscious control, the skeletal muscles, act by pullmg against the bones of the skeleton.", "hypothesis": "Physical activity requires the muscles and bones to synchronise.", "gold_label": "entailment"}
{"uid": "id_610", "premise": "Which of the following can be concluded from the above statement?", "hypothesis": "Indoor air is 10 to 30 times more polluted than outdoor air, and pollutants include dust mites, bacteria, fungi, viruses and pollen.", "gold_label": "contradiction"}
{"uid": "id_611", "premise": "Which of the following can be concluded from the above statement?", "hypothesis": "The highest demand for air purifiers is from Delhi.", "gold_label": "entailment"}
{"uid": "id_612", "premise": "Which of the following can be concluded from the above statement?", "hypothesis": "The sales of air purifier increase due to rise in air pollution.", "gold_label": "entailment"}
{"uid": "id_613", "premise": "Which of the following can be concluded from the above statement?", "hypothesis": "Delhi has been market as the most polluted city in the country by several reputed bodies.", "gold_label": "contradiction"}
{"uid": "id_614", "premise": "While most forms of discrimination in the workplace have been outlawed, discrimination or bias against some employees seeking career advancement still happens. This discrimination is both unwritten and unacknowledged. A glass ceiling is the term used to describe this type of discrimination and refers to the invisible barrier that people hit when they try to progress beyond a certain level in some businesses and organisations. Originally coined to illustrate the hidden use of sexual discrimination against women in professional environments, it is now used to describe any form of discrimination, such as racism or ageism, which prevents qualified or experienced employees reaching even basic levels within their organisation. Some reports and studies now suggest that change is happening and that cracks are beginning to appear in the glass. The studies also claim however that change is happening slowly and that the cracks are small.", "hypothesis": "A glass ceiling can prevent qualified people from getting to the top of their field.", "gold_label": "entailment"}
{"uid": "id_615", "premise": "While most forms of discrimination in the workplace have been outlawed, discrimination or bias against some employees seeking career advancement still happens. This discrimination is both unwritten and unacknowledged. A glass ceiling is the term used to describe this type of discrimination and refers to the invisible barrier that people hit when they try to progress beyond a certain level in some businesses and organisations. Originally coined to illustrate the hidden use of sexual discrimination against women in professional environments, it is now used to describe any form of discrimination, such as racism or ageism, which prevents qualified or experienced employees reaching even basic levels within their organisation. Some reports and studies now suggest that change is happening and that cracks are beginning to appear in the glass. The studies also claim however that change is happening slowly and that the cracks are small.", "hypothesis": "Males are less likely to experience the glass ceiling effect than females.", "gold_label": "neutral"}
{"uid": "id_616", "premise": "While most forms of discrimination in the workplace have been outlawed, discrimination or bias against some employees seeking career advancement still happens. This discrimination is both unwritten and unacknowledged. A glass ceiling is the term used to describe this type of discrimination and refers to the invisible barrier that people hit when they try to progress beyond a certain level in some businesses and organisations. Originally coined to illustrate the hidden use of sexual discrimination against women in professional environments, it is now used to describe any form of discrimination, such as racism or ageism, which prevents qualified or experienced employees reaching even basic levels within their organisation. Some reports and studies now suggest that change is happening and that cracks are beginning to appear in the glass. The studies also claim however that change is happening slowly and that the cracks are small.", "hypothesis": "There is no legislation covering discrimination at work so employers have to develop their own ways of preventing it.", "gold_label": "contradiction"}
{"uid": "id_617", "premise": "Whilst Mr Black, Mr Saul and Mr Hardy travel to work by bus, Mr Jones and Mr Peters travel by train. Mr Black and Mr Saul also walk part of the way. Mr Saul, Mr Peters and Mr Hardy have season tickets.", "hypothesis": "one people have neither a season ticket nor walk", "gold_label": "entailment"}
{"uid": "id_618", "premise": "Whilst Mr Black, Mr Saul and Mr Hardy travel to work by bus, Mr Jones and Mr Peters travel by train. Mr Black and Mr Saul also walk part of the way. Mr Saul, Mr Peters and Mr Hardy have season tickets.", "hypothesis": "Mr Black travels by bus, but does not have a season ticket", "gold_label": "entailment"}
{"uid": "id_619", "premise": "Whilst Mr Black, Mr Saul and Mr Hardy travel to work by bus, Mr Jones and Mr Peters travel by train. Mr Black and Mr Saul also walk part of the way. Mr Saul, Mr Peters and Mr Hardy have season tickets.", "hypothesis": "Mr Saul has a season ticket, but also walks", "gold_label": "entailment"}
{"uid": "id_620", "premise": "Whilst Mr Black, Mr Saul and Mr Hardy travel to work by bus, Mr Jones and Mr Peters travel by train. Mr Black and Mr Saul also walk part of the way. Mr Saul, Mr Peters and Mr Hardy have season tickets.", "hypothesis": "Mr Peters lives closest to a bus stop", "gold_label": "neutral"}
{"uid": "id_621", "premise": "Whilst Mr Black, Mr Saul and Mr Hardy travel to work by bus, Mr Jones and Mr Peters travel by train. Mr Black and Mr Saul also walk part of the way. Mr Saul, Mr Peters and Mr Hardy have season tickets.", "hypothesis": "Mr Jones does not have a season ticket and does not walk", "gold_label": "entailment"}
{"uid": "id_622", "premise": "Whilst having similar effects on employees, there tend to be major difference between a merger and an acquisition. In an acquisition, power is substantially assumed by the new parent company. Change is often swift and brutal as the acquirer imposes its own control systems and financial restraints. Parties to a merger are likely to be evenly matched in terms of size, and the power and cultural dynamics of the combination are more ambiguous, integration is a more drawn out process. During an acquisition, there is often more overt conflict and resistance and a sense of powerlessness. In mergers, because of the prolonged period between the initial announcement and full integration, uncertainty and anxiety continue for a much longer time as the organization remains in a state of limbo.", "hypothesis": "Mergers yield a shorter period of anxiety and uncertainty amongst employees.", "gold_label": "contradiction"}
{"uid": "id_623", "premise": "Whilst having similar effects on employees, there tend to be major difference between a merger and an acquisition. In an acquisition, power is substantially assumed by the new parent company. Change is often swift and brutal as the acquirer imposes its own control systems and financial restraints. Parties to a merger are likely to be evenly matched in terms of size, and the power and cultural dynamics of the combination are more ambiguous, integration is a more drawn out process. During an acquisition, there is often more overt conflict and resistance and a sense of powerlessness. In mergers, because of the prolonged period between the initial announcement and full integration, uncertainty and anxiety continue for a much longer time as the organization remains in a state of limbo.", "hypothesis": "Mergers and acquisition tend to have distinctly different impacts on employees.", "gold_label": "neutral"}
{"uid": "id_624", "premise": "Whilst having similar effects on employees, there tend to be major difference between a merger and an acquisition. In an acquisition, power is substantially assumed by the new parent company. Change is often swift and brutal as the acquirer imposes its own control systems and financial restraints. Parties to a merger are likely to be evenly matched in terms of size, and the power and cultural dynamics of the combination are more ambiguous, integration is a more drawn out process. During an acquisition, there is often more overt conflict and resistance and a sense of powerlessness. In mergers, because of the prolonged period between the initial announcement and full integration, uncertainty and anxiety continue for a much longer time as the organization remains in a state of limbo.", "hypothesis": "There tends to be a major power difference between parties in an acquisition.", "gold_label": "entailment"}
{"uid": "id_625", "premise": "Whilst having similar effects on employees, there tend to be major difference between a merger and an acquisition. In an acquisition, power is substantially assumed by the new parent company. Change is often swift and brutal as the acquirer imposes its own control systems and financial restraints. Parties to a merger are likely to be evenly matched in terms of size, and the power and cultural dynamics of the combination are more ambiguous, integration is a more drawn out process. During an acquisition, there is often more overt conflict and resistance and a sense of powerlessness. In mergers, because of the prolonged period between the initial announcement and full integration, uncertainty and anxiety continue for a much longer time as the organization remains in a state of limbo.", "hypothesis": "Mergers and acquisition tend to have distinctly different impacts on employees.", "gold_label": "contradiction"}
{"uid": "id_626", "premise": "Whilst high visibility crime such as night-time drunken disturbance has increased, total urban and rural crime, both reported and unreported, has fallen over the last two years, yet paradoxically people feel less safe, believing that the converse is the case. This fall in crime has coincided with a drop in the number of police officer on the street. A citizens fear of crime seems not to be a matter of reality at all- the visibility of law enforcement officials has a greater impact on their view of reality than hard facts.", "hypothesis": "Reducing the number of police officer has led to a reduction in crime.", "gold_label": "neutral"}
{"uid": "id_627", "premise": "Whilst high visibility crime such as night-time drunken disturbance has increased, total urban and rural crime, both reported and unreported, has fallen over the last two years, yet paradoxically people feel less safe, believing that the converse is the case. This fall in crime has coincided with a drop in the number of police officer on the street. A citizens fear of crime seems not to be a matter of reality at all- the visibility of law enforcement officials has a greater impact on their view of reality than hard facts.", "hypothesis": "Crime statistics support popular belief about the level of crime.", "gold_label": "contradiction"}
{"uid": "id_628", "premise": "Whilst high visibility crime such as night-time drunken disturbance has increased, total urban and rural crime, both reported and unreported, has fallen over the last two years, yet paradoxically people feel less safe, believing that the converse is the case. This fall in crime has coincided with a drop in the number of police officer on the street. A citizens fear of crime seems not to be a matter of reality at all- the visibility of law enforcement officials has a greater impact on their view of reality than hard facts.", "hypothesis": "People feel safer when there are more police on the street.", "gold_label": "entailment"}
{"uid": "id_629", "premise": "Whilst high visibility crime such as night-time drunken disturbance has increased, total urban and rural crime, both reported and unreported, has fallen over the last two years, yet people feel less safe, believing that the converse is the case. This fall in crime has coincided with a drop in the number of police officer on the street. A citizens fear of seems not to be a matter of reality at all; the visibility of law enforcement officials has a greater impact on their view of reality than hard facts.", "hypothesis": "Reducing the number of police officer has led to a reduction in crime.", "gold_label": "neutral"}
{"uid": "id_630", "premise": "Whilst high visibility crime such as night-time drunken disturbance has increased, total urban and rural crime, both reported and unreported, has fallen over the last two years, yet people feel less safe, believing that the converse is the case. This fall in crime has coincided with a drop in the number of police officer on the street. A citizens fear of seems not to be a matter of reality at all; the visibility of law enforcement officials has a greater impact on their view of reality than hard facts.", "hypothesis": "Crime statistics support popular belief about the level of crime.", "gold_label": "contradiction"}
{"uid": "id_631", "premise": "Whilst high visibility crime such as night-time drunken disturbance has increased, total urban and rural crime, both reported and unreported, has fallen over the last two years, yet people feel less safe, believing that the converse is the case. This fall in crime has coincided with a drop in the number of police officer on the street. A citizens fear of seems not to be a matter of reality at all; the visibility of law enforcement officials has a greater impact on their view of reality than hard facts.", "hypothesis": "People feel safer when there are more police on the street.", "gold_label": "neutral"}
{"uid": "id_632", "premise": "Whiskers weighs less than Paws. Whiskers weighs more than Tabby.", "hypothesis": "Of the three cats, Tabby weighs the least.", "gold_label": "entailment"}
{"uid": "id_633", "premise": "Why Pagodas Dont Fall Down In a land swept by typhoons and shaken by earthquakes, how have Japans tallest and seemingly flimsiest old buildings 500 or so wooden pagodas remained standing for centuries? Records show that only two have collapsed during the past 1400 years. Those that have disappeared were destroyed by fire as a result of lightning or civil war. The disastrous Hanshin earthquake in 1995 killed 6,400 people, toppled elevated highways, flattened office blocks and devastated the port area of Kobe. Yet it left the magnificent five-storey pagoda at the Toji temple in nearby Kyoto unscathed, though it levelled a number of buildings in the neighbourhood. Japanese scholars have been mystified for ages about why these tall, slender buildings are so stable. It was only thirty years ago that the building industry felt confident enough to erect office blocks of steel and reinforced concrete that had more than a dozen floors. With its special shock absorbers to dampen the effect of sudden sideways movements from an earthquake, the thirty-six-storey Kasumigaseki building in central Tokyo Japans first skyscraper was considered a masterpiece of modern engineering when it was built in 1968. Yet in 826, with only pegs and wedges to keep his wooden structure upright, the master builder Kobodaishi had no hesitation in sending his majestic Toji pagoda soaring fifty-five metres into the sky nearly half as high as the Kasumigaseki skyscraper built some eleven centuries later. Clearly, Japanese carpenters of the day knew a few tricks about allowing a building to sway and settle itself rather than fight natures forces. But what sort of tricks? The multi-storey pagoda came to Japan from China in the sixth century. As in China, they were first introduced with Buddhism and were attached to important temples. The Chinese built their pagodas in brick or stone, with inner staircases, and used them in later centuries mainly as watchtowers. When the pagoda reached Japan, however, its architecture was freely adapted to local conditions they were built less high, typically five rather than nine storeys, made mainly of wood and the staircase was dispensed with because the Japanese pagoda did not have any practical use but became more of an art object. Because of the typhoons that batter Japan in the summer, Japanese builders learned to extend the eaves of buildings further beyond the walls. This prevents rainwater gushing down the walls. Pagodas in China and Korea have nothing like the overhang that is found on pagodas in Japan. The roof of a Japanese temple building can be made to overhang the sides of the structure by fifty per cent or more of the buildings overall width. For the same reason, the builders of Japanese pagodas seem to have further increased their weight by choosing to cover these extended eaves not with the porcelain tiles of many Chinese pagodas but with much heavier earthenware tiles. But this does not totally explain the great resilience of Japanese pagodas. Is the answer that, like a tall pine tree, the Japanese pagoda with its massive trunk-like central pillar known as shinbashira simply flexes and sways during a typhoon or earthquake? For centuries, many thought so. But the answer is not so simple because the startling thing is that the shinbashira actually carries no load at all. In fact, in some pagoda designs, it does not even rest on the ground, but is suspended from the top of the pagoda hanging loosely down through the middle of the building. The weight of the building is supported entirely by twelve outer and four inner columns. And what is the role of the shinbashira, the central pillar? The best way to understand the shinbashiras role is to watch a video made by Shuzo Ishida, a structural engineer at Kyoto Institute of Technology. Mr Ishida, known to his students as Professor Pagoda because of his passion to understand the pagoda, has built a series of models and tested them on a shake- table in his laboratory. In short, the shinbashira was acting like an enormous stationary pendulum. The ancient craftsmen, apparently without the assistance of very advanced mathematics, seemed to grasp the principles that were, more than a thousand years later, applied in the construction of Japans first skyscraper. What those early craftsmen had found by trial and error was that under pressure a pagodas loose stack of floors could be made to slither to and fro independent of one another. Viewed from the side, the pagoda seemed to be doing a snake dance with each consecutive floor moving in the opposite direction to its neighbours above and below. The shinbashira, running up through a hole in the centre of the building, constrained individual storeys from moving too far because, after moving a certain distance, they banged into it, transmitting energy away along the column. Another strange feature of the Japanese pagoda is that, because the building tapers, with each successive floor plan being smaller than the one below, none of the vertical pillars that carry the weight of the building is connected to its corresponding pillar above. In other words, a five- storey pagoda contains not even one pillar that travels right up through the building to carry the structural loads from the top to the bottom. More surprising is the fact that the individual storeys of a Japanese pagoda, unlike their counterparts elsewhere, are not actually connected to each other. They are simply stacked one on top of another like a pile of hats. Interestingly, such a design would not be permitted under current Japanese building regulations. And the extra-wide eaves? Think of them as a tightrope walkers balancing pole. The bigger the mass at each end of the pole, the easier it is for the tightrope walker to maintain his or her balance. The same holds true for a pagoda. With the eaves extending out on all sides like balancing poles, says Mr Ishida, the building responds to even the most powerful jolt of an earthquake with a graceful swaying, never an abrupt shaking. Here again, Japanese master builders of a thousand years ago anticipated concepts of modern structural engineering.", "hypothesis": "Only two Japanese pagodas have collapsed in 1400 years.", "gold_label": "entailment"}
{"uid": "id_634", "premise": "Why Pagodas Dont Fall Down In a land swept by typhoons and shaken by earthquakes, how have Japans tallest and seemingly flimsiest old buildings 500 or so wooden pagodas remained standing for centuries? Records show that only two have collapsed during the past 1400 years. Those that have disappeared were destroyed by fire as a result of lightning or civil war. The disastrous Hanshin earthquake in 1995 killed 6,400 people, toppled elevated highways, flattened office blocks and devastated the port area of Kobe. Yet it left the magnificent five-storey pagoda at the Toji temple in nearby Kyoto unscathed, though it levelled a number of buildings in the neighbourhood. Japanese scholars have been mystified for ages about why these tall, slender buildings are so stable. It was only thirty years ago that the building industry felt confident enough to erect office blocks of steel and reinforced concrete that had more than a dozen floors. With its special shock absorbers to dampen the effect of sudden sideways movements from an earthquake, the thirty-six-storey Kasumigaseki building in central Tokyo Japans first skyscraper was considered a masterpiece of modern engineering when it was built in 1968. Yet in 826, with only pegs and wedges to keep his wooden structure upright, the master builder Kobodaishi had no hesitation in sending his majestic Toji pagoda soaring fifty-five metres into the sky nearly half as high as the Kasumigaseki skyscraper built some eleven centuries later. Clearly, Japanese carpenters of the day knew a few tricks about allowing a building to sway and settle itself rather than fight natures forces. But what sort of tricks? The multi-storey pagoda came to Japan from China in the sixth century. As in China, they were first introduced with Buddhism and were attached to important temples. The Chinese built their pagodas in brick or stone, with inner staircases, and used them in later centuries mainly as watchtowers. When the pagoda reached Japan, however, its architecture was freely adapted to local conditions they were built less high, typically five rather than nine storeys, made mainly of wood and the staircase was dispensed with because the Japanese pagoda did not have any practical use but became more of an art object. Because of the typhoons that batter Japan in the summer, Japanese builders learned to extend the eaves of buildings further beyond the walls. This prevents rainwater gushing down the walls. Pagodas in China and Korea have nothing like the overhang that is found on pagodas in Japan. The roof of a Japanese temple building can be made to overhang the sides of the structure by fifty per cent or more of the buildings overall width. For the same reason, the builders of Japanese pagodas seem to have further increased their weight by choosing to cover these extended eaves not with the porcelain tiles of many Chinese pagodas but with much heavier earthenware tiles. But this does not totally explain the great resilience of Japanese pagodas. Is the answer that, like a tall pine tree, the Japanese pagoda with its massive trunk-like central pillar known as shinbashira simply flexes and sways during a typhoon or earthquake? For centuries, many thought so. But the answer is not so simple because the startling thing is that the shinbashira actually carries no load at all. In fact, in some pagoda designs, it does not even rest on the ground, but is suspended from the top of the pagoda hanging loosely down through the middle of the building. The weight of the building is supported entirely by twelve outer and four inner columns. And what is the role of the shinbashira, the central pillar? The best way to understand the shinbashiras role is to watch a video made by Shuzo Ishida, a structural engineer at Kyoto Institute of Technology. Mr Ishida, known to his students as Professor Pagoda because of his passion to understand the pagoda, has built a series of models and tested them on a shake- table in his laboratory. In short, the shinbashira was acting like an enormous stationary pendulum. The ancient craftsmen, apparently without the assistance of very advanced mathematics, seemed to grasp the principles that were, more than a thousand years later, applied in the construction of Japans first skyscraper. What those early craftsmen had found by trial and error was that under pressure a pagodas loose stack of floors could be made to slither to and fro independent of one another. Viewed from the side, the pagoda seemed to be doing a snake dance with each consecutive floor moving in the opposite direction to its neighbours above and below. The shinbashira, running up through a hole in the centre of the building, constrained individual storeys from moving too far because, after moving a certain distance, they banged into it, transmitting energy away along the column. Another strange feature of the Japanese pagoda is that, because the building tapers, with each successive floor plan being smaller than the one below, none of the vertical pillars that carry the weight of the building is connected to its corresponding pillar above. In other words, a five- storey pagoda contains not even one pillar that travels right up through the building to carry the structural loads from the top to the bottom. More surprising is the fact that the individual storeys of a Japanese pagoda, unlike their counterparts elsewhere, are not actually connected to each other. They are simply stacked one on top of another like a pile of hats. Interestingly, such a design would not be permitted under current Japanese building regulations. And the extra-wide eaves? Think of them as a tightrope walkers balancing pole. The bigger the mass at each end of the pole, the easier it is for the tightrope walker to maintain his or her balance. The same holds true for a pagoda. With the eaves extending out on all sides like balancing poles, says Mr Ishida, the building responds to even the most powerful jolt of an earthquake with a graceful swaying, never an abrupt shaking. Here again, Japanese master builders of a thousand years ago anticipated concepts of modern structural engineering.", "hypothesis": "The Hanshin earthquake of 1995 destroyed the pagoda at the Toji temple.", "gold_label": "contradiction"}
{"uid": "id_635", "premise": "Why Pagodas Dont Fall Down In a land swept by typhoons and shaken by earthquakes, how have Japans tallest and seemingly flimsiest old buildings 500 or so wooden pagodas remained standing for centuries? Records show that only two have collapsed during the past 1400 years. Those that have disappeared were destroyed by fire as a result of lightning or civil war. The disastrous Hanshin earthquake in 1995 killed 6,400 people, toppled elevated highways, flattened office blocks and devastated the port area of Kobe. Yet it left the magnificent five-storey pagoda at the Toji temple in nearby Kyoto unscathed, though it levelled a number of buildings in the neighbourhood. Japanese scholars have been mystified for ages about why these tall, slender buildings are so stable. It was only thirty years ago that the building industry felt confident enough to erect office blocks of steel and reinforced concrete that had more than a dozen floors. With its special shock absorbers to dampen the effect of sudden sideways movements from an earthquake, the thirty-six-storey Kasumigaseki building in central Tokyo Japans first skyscraper was considered a masterpiece of modern engineering when it was built in 1968. Yet in 826, with only pegs and wedges to keep his wooden structure upright, the master builder Kobodaishi had no hesitation in sending his majestic Toji pagoda soaring fifty-five metres into the sky nearly half as high as the Kasumigaseki skyscraper built some eleven centuries later. Clearly, Japanese carpenters of the day knew a few tricks about allowing a building to sway and settle itself rather than fight natures forces. But what sort of tricks? The multi-storey pagoda came to Japan from China in the sixth century. As in China, they were first introduced with Buddhism and were attached to important temples. The Chinese built their pagodas in brick or stone, with inner staircases, and used them in later centuries mainly as watchtowers. When the pagoda reached Japan, however, its architecture was freely adapted to local conditions they were built less high, typically five rather than nine storeys, made mainly of wood and the staircase was dispensed with because the Japanese pagoda did not have any practical use but became more of an art object. Because of the typhoons that batter Japan in the summer, Japanese builders learned to extend the eaves of buildings further beyond the walls. This prevents rainwater gushing down the walls. Pagodas in China and Korea have nothing like the overhang that is found on pagodas in Japan. The roof of a Japanese temple building can be made to overhang the sides of the structure by fifty per cent or more of the buildings overall width. For the same reason, the builders of Japanese pagodas seem to have further increased their weight by choosing to cover these extended eaves not with the porcelain tiles of many Chinese pagodas but with much heavier earthenware tiles. But this does not totally explain the great resilience of Japanese pagodas. Is the answer that, like a tall pine tree, the Japanese pagoda with its massive trunk-like central pillar known as shinbashira simply flexes and sways during a typhoon or earthquake? For centuries, many thought so. But the answer is not so simple because the startling thing is that the shinbashira actually carries no load at all. In fact, in some pagoda designs, it does not even rest on the ground, but is suspended from the top of the pagoda hanging loosely down through the middle of the building. The weight of the building is supported entirely by twelve outer and four inner columns. And what is the role of the shinbashira, the central pillar? The best way to understand the shinbashiras role is to watch a video made by Shuzo Ishida, a structural engineer at Kyoto Institute of Technology. Mr Ishida, known to his students as Professor Pagoda because of his passion to understand the pagoda, has built a series of models and tested them on a shake- table in his laboratory. In short, the shinbashira was acting like an enormous stationary pendulum. The ancient craftsmen, apparently without the assistance of very advanced mathematics, seemed to grasp the principles that were, more than a thousand years later, applied in the construction of Japans first skyscraper. What those early craftsmen had found by trial and error was that under pressure a pagodas loose stack of floors could be made to slither to and fro independent of one another. Viewed from the side, the pagoda seemed to be doing a snake dance with each consecutive floor moving in the opposite direction to its neighbours above and below. The shinbashira, running up through a hole in the centre of the building, constrained individual storeys from moving too far because, after moving a certain distance, they banged into it, transmitting energy away along the column. Another strange feature of the Japanese pagoda is that, because the building tapers, with each successive floor plan being smaller than the one below, none of the vertical pillars that carry the weight of the building is connected to its corresponding pillar above. In other words, a five- storey pagoda contains not even one pillar that travels right up through the building to carry the structural loads from the top to the bottom. More surprising is the fact that the individual storeys of a Japanese pagoda, unlike their counterparts elsewhere, are not actually connected to each other. They are simply stacked one on top of another like a pile of hats. Interestingly, such a design would not be permitted under current Japanese building regulations. And the extra-wide eaves? Think of them as a tightrope walkers balancing pole. The bigger the mass at each end of the pole, the easier it is for the tightrope walker to maintain his or her balance. The same holds true for a pagoda. With the eaves extending out on all sides like balancing poles, says Mr Ishida, the building responds to even the most powerful jolt of an earthquake with a graceful swaying, never an abrupt shaking. Here again, Japanese master builders of a thousand years ago anticipated concepts of modern structural engineering.", "hypothesis": "The builders of pagodas knew how to absorb some of the power produced by severe weather conditions.", "gold_label": "entailment"}
{"uid": "id_636", "premise": "Why Pagodas Dont Fall Down In a land swept by typhoons and shaken by earthquakes, how have Japans tallest and seemingly flimsiest old buildings 500 or so wooden pagodas remained standing for centuries? Records show that only two have collapsed during the past 1400 years. Those that have disappeared were destroyed by fire as a result of lightning or civil war. The disastrous Hanshin earthquake in 1995 killed 6,400 people, toppled elevated highways, flattened office blocks and devastated the port area of Kobe. Yet it left the magnificent five-storey pagoda at the Toji temple in nearby Kyoto unscathed, though it levelled a number of buildings in the neighbourhood. Japanese scholars have been mystified for ages about why these tall, slender buildings are so stable. It was only thirty years ago that the building industry felt confident enough to erect office blocks of steel and reinforced concrete that had more than a dozen floors. With its special shock absorbers to dampen the effect of sudden sideways movements from an earthquake, the thirty-six-storey Kasumigaseki building in central Tokyo Japans first skyscraper was considered a masterpiece of modern engineering when it was built in 1968. Yet in 826, with only pegs and wedges to keep his wooden structure upright, the master builder Kobodaishi had no hesitation in sending his majestic Toji pagoda soaring fifty-five metres into the sky nearly half as high as the Kasumigaseki skyscraper built some eleven centuries later. Clearly, Japanese carpenters of the day knew a few tricks about allowing a building to sway and settle itself rather than fight natures forces. But what sort of tricks? The multi-storey pagoda came to Japan from China in the sixth century. As in China, they were first introduced with Buddhism and were attached to important temples. The Chinese built their pagodas in brick or stone, with inner staircases, and used them in later centuries mainly as watchtowers. When the pagoda reached Japan, however, its architecture was freely adapted to local conditions they were built less high, typically five rather than nine storeys, made mainly of wood and the staircase was dispensed with because the Japanese pagoda did not have any practical use but became more of an art object. Because of the typhoons that batter Japan in the summer, Japanese builders learned to extend the eaves of buildings further beyond the walls. This prevents rainwater gushing down the walls. Pagodas in China and Korea have nothing like the overhang that is found on pagodas in Japan. The roof of a Japanese temple building can be made to overhang the sides of the structure by fifty per cent or more of the buildings overall width. For the same reason, the builders of Japanese pagodas seem to have further increased their weight by choosing to cover these extended eaves not with the porcelain tiles of many Chinese pagodas but with much heavier earthenware tiles. But this does not totally explain the great resilience of Japanese pagodas. Is the answer that, like a tall pine tree, the Japanese pagoda with its massive trunk-like central pillar known as shinbashira simply flexes and sways during a typhoon or earthquake? For centuries, many thought so. But the answer is not so simple because the startling thing is that the shinbashira actually carries no load at all. In fact, in some pagoda designs, it does not even rest on the ground, but is suspended from the top of the pagoda hanging loosely down through the middle of the building. The weight of the building is supported entirely by twelve outer and four inner columns. And what is the role of the shinbashira, the central pillar? The best way to understand the shinbashiras role is to watch a video made by Shuzo Ishida, a structural engineer at Kyoto Institute of Technology. Mr Ishida, known to his students as Professor Pagoda because of his passion to understand the pagoda, has built a series of models and tested them on a shake- table in his laboratory. In short, the shinbashira was acting like an enormous stationary pendulum. The ancient craftsmen, apparently without the assistance of very advanced mathematics, seemed to grasp the principles that were, more than a thousand years later, applied in the construction of Japans first skyscraper. What those early craftsmen had found by trial and error was that under pressure a pagodas loose stack of floors could be made to slither to and fro independent of one another. Viewed from the side, the pagoda seemed to be doing a snake dance with each consecutive floor moving in the opposite direction to its neighbours above and below. The shinbashira, running up through a hole in the centre of the building, constrained individual storeys from moving too far because, after moving a certain distance, they banged into it, transmitting energy away along the column. Another strange feature of the Japanese pagoda is that, because the building tapers, with each successive floor plan being smaller than the one below, none of the vertical pillars that carry the weight of the building is connected to its corresponding pillar above. In other words, a five- storey pagoda contains not even one pillar that travels right up through the building to carry the structural loads from the top to the bottom. More surprising is the fact that the individual storeys of a Japanese pagoda, unlike their counterparts elsewhere, are not actually connected to each other. They are simply stacked one on top of another like a pile of hats. Interestingly, such a design would not be permitted under current Japanese building regulations. And the extra-wide eaves? Think of them as a tightrope walkers balancing pole. The bigger the mass at each end of the pole, the easier it is for the tightrope walker to maintain his or her balance. The same holds true for a pagoda. With the eaves extending out on all sides like balancing poles, says Mr Ishida, the building responds to even the most powerful jolt of an earthquake with a graceful swaying, never an abrupt shaking. Here again, Japanese master builders of a thousand years ago anticipated concepts of modern structural engineering.", "hypothesis": "The other buildings near the Toji pagoda had been built in the last 30 years.", "gold_label": "neutral"}
{"uid": "id_637", "premise": "Why are so few tigers man-eaters? As you leave the Bandhavgarh National Park in central India, there is a notice which shows a huge, placid tiger. The notice says, You may not have seen me, but I have seen you. There are more than a billion people In India and Indian tigers probably see humans every single day of their lives. Tigers can and do kill almost everything they meet in the jungle, they will kill even attack elephants and rhino. Surely, then, it is a little strange that attacks on humans are not more frequent. Some people might argue that these attacks were in fact common in the past. British writers of adventure stories, such as Jim Corbett, gave the impression that village life in India in the early years of the twentieth century involved a stage of constant siege by man-eating tigers. But they may have overstated the terror spread by tigers. There were also far more tigers around in those days (probably 60.000 in the subcontinent compared to just 3000 today). So in proportion, attacks appear to have been as rare then as they are today. It is widely assumed that the constraint is fear; but what exactly are tigers afraid of? Can they really know that we may be even better armed than they are? Surely not. Has the species programmed the experiences of all tigers with humans its genes to be inherited as instinct? Perhaps. But I think the explanation may be more simple and, in a way, more intriguing. Since the growth of ethology in the 1950s. we have tried to understand animal behaviour from the animals point of view. Until the first elegant experiments by pioneers in the field such as Konrad Lorenz, naturalists wrote about animals as if they were slightly less intelligent humans. Jim Corbetts breathless accounts of his duels with a an-eaters in truth tell us more about Jim Corbett than they do about the animals. The principle of ethology, on the other hand, requires us to attempt to think in the same way as the animal we are studying thinks, and to observe every tiny detail of its behaviour without imposing our own human significances on its actions. I suspect that a tigers afraid of humans lies not in some preprogramed ancestral logic but in the way he actually perceives us visually. If you think like a tiger, a human in a car might appear just to be a part of the car, and because tigers dont eat cars the human is safe-unless the car is menacing the tiger or its cubs, in which case a brave or enraged tiger may charge. A human on foot is a different sort of puzzle. Imagine a tiger sees a man who is 1.8m tall. A tiger is less than 1m tall but they may be up to 3m long from head to tail. So when a tiger sees the man face on, it might not be unreasonable for him to assume that the man is 6m long. If he meet a deer of this size, he might attack the animal by leaping on its back, but when he looks behind the mind he cant see a back. From the front the man is huge, but looked at from the side he all but disappears. This must be very disconcerting. A hunter has to be confident that it can tackle its prey, and no one is confident when they are disconcerted. This is especially true of a solitary hunter such as the tiger and may explain why lions-particularly young lionesses who tend to encourage one another to take risks are more dangerous than tigers. If the theory that a tiger is disconcerted to find that a standing human is both very big and yet somehow invisible is correct, the opposite should be true of a squatting human. A squatting human is half he size and presents twice the spread of back, and more closely resembles a medium-sized deer. If tigers were simply frightened of all humans, then a squatting person would be no more attractive as a target than a standing one. This, however appears not to be the case. Many incidents of attacks on people involving villagers squatting or bending over to cut grass for fodder or building material. The fact that humans stand upright may therefore not just be something that distinguishes them from nearly all other species, but also a factor that helped them to survive in a dangerous and unpredictable environment.", "hypothesis": "Some writers of fiction have exaggerated the danger of tigers to man.", "gold_label": "entailment"}
{"uid": "id_638", "premise": "Why are so few tigers man-eaters? As you leave the Bandhavgarh National Park in central India, there is a notice which shows a huge, placid tiger. The notice says, You may not have seen me, but I have seen you. There are more than a billion people In India and Indian tigers probably see humans every single day of their lives. Tigers can and do kill almost everything they meet in the jungle, they will kill even attack elephants and rhino. Surely, then, it is a little strange that attacks on humans are not more frequent. Some people might argue that these attacks were in fact common in the past. British writers of adventure stories, such as Jim Corbett, gave the impression that village life in India in the early years of the twentieth century involved a stage of constant siege by man-eating tigers. But they may have overstated the terror spread by tigers. There were also far more tigers around in those days (probably 60.000 in the subcontinent compared to just 3000 today). So in proportion, attacks appear to have been as rare then as they are today. It is widely assumed that the constraint is fear; but what exactly are tigers afraid of? Can they really know that we may be even better armed than they are? Surely not. Has the species programmed the experiences of all tigers with humans its genes to be inherited as instinct? Perhaps. But I think the explanation may be more simple and, in a way, more intriguing. Since the growth of ethology in the 1950s. we have tried to understand animal behaviour from the animals point of view. Until the first elegant experiments by pioneers in the field such as Konrad Lorenz, naturalists wrote about animals as if they were slightly less intelligent humans. Jim Corbetts breathless accounts of his duels with a an-eaters in truth tell us more about Jim Corbett than they do about the animals. The principle of ethology, on the other hand, requires us to attempt to think in the same way as the animal we are studying thinks, and to observe every tiny detail of its behaviour without imposing our own human significances on its actions. I suspect that a tigers afraid of humans lies not in some preprogramed ancestral logic but in the way he actually perceives us visually. If you think like a tiger, a human in a car might appear just to be a part of the car, and because tigers dont eat cars the human is safe-unless the car is menacing the tiger or its cubs, in which case a brave or enraged tiger may charge. A human on foot is a different sort of puzzle. Imagine a tiger sees a man who is 1.8m tall. A tiger is less than 1m tall but they may be up to 3m long from head to tail. So when a tiger sees the man face on, it might not be unreasonable for him to assume that the man is 6m long. If he meet a deer of this size, he might attack the animal by leaping on its back, but when he looks behind the mind he cant see a back. From the front the man is huge, but looked at from the side he all but disappears. This must be very disconcerting. A hunter has to be confident that it can tackle its prey, and no one is confident when they are disconcerted. This is especially true of a solitary hunter such as the tiger and may explain why lions-particularly young lionesses who tend to encourage one another to take risks are more dangerous than tigers. If the theory that a tiger is disconcerted to find that a standing human is both very big and yet somehow invisible is correct, the opposite should be true of a squatting human. A squatting human is half he size and presents twice the spread of back, and more closely resembles a medium-sized deer. If tigers were simply frightened of all humans, then a squatting person would be no more attractive as a target than a standing one. This, however appears not to be the case. Many incidents of attacks on people involving villagers squatting or bending over to cut grass for fodder or building material. The fact that humans stand upright may therefore not just be something that distinguishes them from nearly all other species, but also a factor that helped them to survive in a dangerous and unpredictable environment.", "hypothesis": "The fear of humans may be passed down in a tigers genes.", "gold_label": "entailment"}
{"uid": "id_639", "premise": "Why are so few tigers man-eaters? As you leave the Bandhavgarh National Park in central India, there is a notice which shows a huge, placid tiger. The notice says, You may not have seen me, but I have seen you. There are more than a billion people In India and Indian tigers probably see humans every single day of their lives. Tigers can and do kill almost everything they meet in the jungle, they will kill even attack elephants and rhino. Surely, then, it is a little strange that attacks on humans are not more frequent. Some people might argue that these attacks were in fact common in the past. British writers of adventure stories, such as Jim Corbett, gave the impression that village life in India in the early years of the twentieth century involved a stage of constant siege by man-eating tigers. But they may have overstated the terror spread by tigers. There were also far more tigers around in those days (probably 60.000 in the subcontinent compared to just 3000 today). So in proportion, attacks appear to have been as rare then as they are today. It is widely assumed that the constraint is fear; but what exactly are tigers afraid of? Can they really know that we may be even better armed than they are? Surely not. Has the species programmed the experiences of all tigers with humans its genes to be inherited as instinct? Perhaps. But I think the explanation may be more simple and, in a way, more intriguing. Since the growth of ethology in the 1950s. we have tried to understand animal behaviour from the animals point of view. Until the first elegant experiments by pioneers in the field such as Konrad Lorenz, naturalists wrote about animals as if they were slightly less intelligent humans. Jim Corbetts breathless accounts of his duels with a an-eaters in truth tell us more about Jim Corbett than they do about the animals. The principle of ethology, on the other hand, requires us to attempt to think in the same way as the animal we are studying thinks, and to observe every tiny detail of its behaviour without imposing our own human significances on its actions. I suspect that a tigers afraid of humans lies not in some preprogramed ancestral logic but in the way he actually perceives us visually. If you think like a tiger, a human in a car might appear just to be a part of the car, and because tigers dont eat cars the human is safe-unless the car is menacing the tiger or its cubs, in which case a brave or enraged tiger may charge. A human on foot is a different sort of puzzle. Imagine a tiger sees a man who is 1.8m tall. A tiger is less than 1m tall but they may be up to 3m long from head to tail. So when a tiger sees the man face on, it might not be unreasonable for him to assume that the man is 6m long. If he meet a deer of this size, he might attack the animal by leaping on its back, but when he looks behind the mind he cant see a back. From the front the man is huge, but looked at from the side he all but disappears. This must be very disconcerting. A hunter has to be confident that it can tackle its prey, and no one is confident when they are disconcerted. This is especially true of a solitary hunter such as the tiger and may explain why lions-particularly young lionesses who tend to encourage one another to take risks are more dangerous than tigers. If the theory that a tiger is disconcerted to find that a standing human is both very big and yet somehow invisible is correct, the opposite should be true of a squatting human. A squatting human is half he size and presents twice the spread of back, and more closely resembles a medium-sized deer. If tigers were simply frightened of all humans, then a squatting person would be no more attractive as a target than a standing one. This, however appears not to be the case. Many incidents of attacks on people involving villagers squatting or bending over to cut grass for fodder or building material. The fact that humans stand upright may therefore not just be something that distinguishes them from nearly all other species, but also a factor that helped them to survive in a dangerous and unpredictable environment.", "hypothesis": "Konrad Lorenz claimed that some animals are more intelligent than humans.", "gold_label": "neutral"}
{"uid": "id_640", "premise": "Why are so few tigers man-eaters? As you leave the Bandhavgarh National Park in central India, there is a notice which shows a huge, placid tiger. The notice says, You may not have seen me, but I have seen you. There are more than a billion people In India and Indian tigers probably see humans every single day of their lives. Tigers can and do kill almost everything they meet in the jungle, they will kill even attack elephants and rhino. Surely, then, it is a little strange that attacks on humans are not more frequent. Some people might argue that these attacks were in fact common in the past. British writers of adventure stories, such as Jim Corbett, gave the impression that village life in India in the early years of the twentieth century involved a stage of constant siege by man-eating tigers. But they may have overstated the terror spread by tigers. There were also far more tigers around in those days (probably 60.000 in the subcontinent compared to just 3000 today). So in proportion, attacks appear to have been as rare then as they are today. It is widely assumed that the constraint is fear; but what exactly are tigers afraid of? Can they really know that we may be even better armed than they are? Surely not. Has the species programmed the experiences of all tigers with humans its genes to be inherited as instinct? Perhaps. But I think the explanation may be more simple and, in a way, more intriguing. Since the growth of ethology in the 1950s. we have tried to understand animal behaviour from the animals point of view. Until the first elegant experiments by pioneers in the field such as Konrad Lorenz, naturalists wrote about animals as if they were slightly less intelligent humans. Jim Corbetts breathless accounts of his duels with a an-eaters in truth tell us more about Jim Corbett than they do about the animals. The principle of ethology, on the other hand, requires us to attempt to think in the same way as the animal we are studying thinks, and to observe every tiny detail of its behaviour without imposing our own human significances on its actions. I suspect that a tigers afraid of humans lies not in some preprogramed ancestral logic but in the way he actually perceives us visually. If you think like a tiger, a human in a car might appear just to be a part of the car, and because tigers dont eat cars the human is safe-unless the car is menacing the tiger or its cubs, in which case a brave or enraged tiger may charge. A human on foot is a different sort of puzzle. Imagine a tiger sees a man who is 1.8m tall. A tiger is less than 1m tall but they may be up to 3m long from head to tail. So when a tiger sees the man face on, it might not be unreasonable for him to assume that the man is 6m long. If he meet a deer of this size, he might attack the animal by leaping on its back, but when he looks behind the mind he cant see a back. From the front the man is huge, but looked at from the side he all but disappears. This must be very disconcerting. A hunter has to be confident that it can tackle its prey, and no one is confident when they are disconcerted. This is especially true of a solitary hunter such as the tiger and may explain why lions-particularly young lionesses who tend to encourage one another to take risks are more dangerous than tigers. If the theory that a tiger is disconcerted to find that a standing human is both very big and yet somehow invisible is correct, the opposite should be true of a squatting human. A squatting human is half he size and presents twice the spread of back, and more closely resembles a medium-sized deer. If tigers were simply frightened of all humans, then a squatting person would be no more attractive as a target than a standing one. This, however appears not to be the case. Many incidents of attacks on people involving villagers squatting or bending over to cut grass for fodder or building material. The fact that humans stand upright may therefore not just be something that distinguishes them from nearly all other species, but also a factor that helped them to survive in a dangerous and unpredictable environment.", "hypothesis": "Ethology involves applying principles of human behaviour to animals.", "gold_label": "contradiction"}
{"uid": "id_641", "premise": "Why are so few tigers man-eaters? As you leave the Bandhavgarh National Park in central India, there is a notice which shows a huge, placid tiger. The notice says, You may not have seen me, but I have seen you. There are more than a billion people In India and Indian tigers probably see humans every single day of their lives. Tigers can and do kill almost everything they meet in the jungle, they will kill even attack elephants and rhino. Surely, then, it is a little strange that attacks on humans are not more frequent. Some people might argue that these attacks were in fact common in the past. British writers of adventure stories, such as Jim Corbett, gave the impression that village life in India in the early years of the twentieth century involved a stage of constant siege by man-eating tigers. But they may have overstated the terror spread by tigers. There were also far more tigers around in those days (probably 60.000 in the subcontinent compared to just 3000 today). So in proportion, attacks appear to have been as rare then as they are today. It is widely assumed that the constraint is fear; but what exactly are tigers afraid of? Can they really know that we may be even better armed than they are? Surely not. Has the species programmed the experiences of all tigers with humans its genes to be inherited as instinct? Perhaps. But I think the explanation may be more simple and, in a way, more intriguing. Since the growth of ethology in the 1950s. we have tried to understand animal behaviour from the animals point of view. Until the first elegant experiments by pioneers in the field such as Konrad Lorenz, naturalists wrote about animals as if they were slightly less intelligent humans. Jim Corbetts breathless accounts of his duels with a an-eaters in truth tell us more about Jim Corbett than they do about the animals. The principle of ethology, on the other hand, requires us to attempt to think in the same way as the animal we are studying thinks, and to observe every tiny detail of its behaviour without imposing our own human significances on its actions. I suspect that a tigers afraid of humans lies not in some preprogramed ancestral logic but in the way he actually perceives us visually. If you think like a tiger, a human in a car might appear just to be a part of the car, and because tigers dont eat cars the human is safe-unless the car is menacing the tiger or its cubs, in which case a brave or enraged tiger may charge. A human on foot is a different sort of puzzle. Imagine a tiger sees a man who is 1.8m tall. A tiger is less than 1m tall but they may be up to 3m long from head to tail. So when a tiger sees the man face on, it might not be unreasonable for him to assume that the man is 6m long. If he meet a deer of this size, he might attack the animal by leaping on its back, but when he looks behind the mind he cant see a back. From the front the man is huge, but looked at from the side he all but disappears. This must be very disconcerting. A hunter has to be confident that it can tackle its prey, and no one is confident when they are disconcerted. This is especially true of a solitary hunter such as the tiger and may explain why lions-particularly young lionesses who tend to encourage one another to take risks are more dangerous than tigers. If the theory that a tiger is disconcerted to find that a standing human is both very big and yet somehow invisible is correct, the opposite should be true of a squatting human. A squatting human is half he size and presents twice the spread of back, and more closely resembles a medium-sized deer. If tigers were simply frightened of all humans, then a squatting person would be no more attractive as a target than a standing one. This, however appears not to be the case. Many incidents of attacks on people involving villagers squatting or bending over to cut grass for fodder or building material. The fact that humans stand upright may therefore not just be something that distinguishes them from nearly all other species, but also a factor that helped them to survive in a dangerous and unpredictable environment.", "hypothesis": "Tigers in the Bandhavgarh National Park are a protected species.", "gold_label": "neutral"}
{"uid": "id_642", "premise": "Why companies should welcome disorder Organisation is big business. Whether it is of our lives - all those inboxes and calendars - or how companies are structured, a multi-billion dollar industry helps to meet this need. We have more strategies for time management, project management and self-organisation than at any other time in human history. We are told that we ought to organise our company, our home life, our week, our day and even our sleep, all as a means to becoming more productive. Every week, countless seminars and workshops take place around the world to tell a paying public that they ought to structure their lives in order to achieve this. This rhetoric has also crept into the thinking of business leaders and entrepreneurs, much to the delight of self-proclaimed perfectionists with the need to get everything right. The number of business schools and graduates has massively increased over the past 50 years, essentially teaching people how to organise well. Ironically, however, the number of businesses that fail has also steadily increased. Work-related stress has increased. A large proportion of workers from all demographics claim to be dissatisfied with the way their work is structured and the way they are managed. This begs the question: what has gone wrong? Why is it that on paper the drive for organisation seems a sure shot for increasing productivity, but in reality falls well short of what is expected? This has been a problem for a while now. Frederick Taylor was one of the forefathers of scientific management. Writing in the first half of the 20th century, he designed a number of principles to improve the efficiency of the work process, which have since become widespread in modern companies. So the approach has been around for a while. New research suggests that this obsession with efficiency is misguided. The problem is not necessarily the management theories or strategies we use to organise our work; it's the basic assumptions we hold in approaching how we work. Here it's the assumption that order is a necessary condition for productivity. This assumption has also fostered the idea that disorder must be detrimental to organisational productivity. The result is that businesses and people spend time and money organising themselves for the sake of organising, rather than actually looking at the end goal and usefulness of such an effort. What's more, recent studies show that order actually has diminishing returns. Order does increase productivity to a certain extent, but eventually the usefulness of the process of organisation, and the benefit it yields, reduce until the point where any further increase in order reduces productivity. Some argue that in a business, if the cost of formally structuring something outweighs the benefit of doing it, then that thing ought not to be formally structured. Instead, the resources involved can be better used elsewhere. In fact, research shows that, when innovating, the best approach is to create an environment devoid of structure and hierarchy and enable everyone involved to engage as one organic group. These environments can lead to new solutions that, under conventionally structured environments (filled with bottlenecks in terms of information flow, power structures, rules, and routines) would never be reached. In recent times companies have slowly started to embrace this disorganisation. Many of them embrace it in terms of perception (embracing the idea of disorder, as opposed to fearing it) and in terms of process (putting mechanisms in place to reduce structure). For example, Oticon, a large Danish manufacturer of hearing aids, used what it called a 'spaghetti' structure in order to reduce the organisation's rigid hierarchies. This involved scrapping formal job titles and giving staff huge amounts of ownership over their own time and projects. This approach proved to be highly successful initially, with clear improvements in worker productivity in all facets of the business. In similar fashion, the former chairman of General Electric embraced disorganisation, putting forward the idea of the 'boundaryless' organisation. Again, it involves breaking down the barriers between different parts of a company and encouraging virtual collaboration and flexible working. Google and a number of other tech companies have embraced (at least in part) these kinds of flexible structures, facilitated by technology and strong company values which glue people together. A word of warning to others thinking of jumping on this bandwagon: the evidence so far suggests disorder, much like order, also seems to have diminishing utility, and can also have detrimental effects on performance if overused. Like order, disorder should be embraced only so far as it is useful. But we should not fear it - nor venerate one over the other. This research also shows that we should continually question whether or not our existing assumptions work.", "hypothesis": "Google was inspired to adopt flexibility by the success of General Electric.", "gold_label": "neutral"}
{"uid": "id_643", "premise": "Why companies should welcome disorder Organisation is big business. Whether it is of our lives - all those inboxes and calendars - or how companies are structured, a multi-billion dollar industry helps to meet this need. We have more strategies for time management, project management and self-organisation than at any other time in human history. We are told that we ought to organise our company, our home life, our week, our day and even our sleep, all as a means to becoming more productive. Every week, countless seminars and workshops take place around the world to tell a paying public that they ought to structure their lives in order to achieve this. This rhetoric has also crept into the thinking of business leaders and entrepreneurs, much to the delight of self-proclaimed perfectionists with the need to get everything right. The number of business schools and graduates has massively increased over the past 50 years, essentially teaching people how to organise well. Ironically, however, the number of businesses that fail has also steadily increased. Work-related stress has increased. A large proportion of workers from all demographics claim to be dissatisfied with the way their work is structured and the way they are managed. This begs the question: what has gone wrong? Why is it that on paper the drive for organisation seems a sure shot for increasing productivity, but in reality falls well short of what is expected? This has been a problem for a while now. Frederick Taylor was one of the forefathers of scientific management. Writing in the first half of the 20th century, he designed a number of principles to improve the efficiency of the work process, which have since become widespread in modern companies. So the approach has been around for a while. New research suggests that this obsession with efficiency is misguided. The problem is not necessarily the management theories or strategies we use to organise our work; it's the basic assumptions we hold in approaching how we work. Here it's the assumption that order is a necessary condition for productivity. This assumption has also fostered the idea that disorder must be detrimental to organisational productivity. The result is that businesses and people spend time and money organising themselves for the sake of organising, rather than actually looking at the end goal and usefulness of such an effort. What's more, recent studies show that order actually has diminishing returns. Order does increase productivity to a certain extent, but eventually the usefulness of the process of organisation, and the benefit it yields, reduce until the point where any further increase in order reduces productivity. Some argue that in a business, if the cost of formally structuring something outweighs the benefit of doing it, then that thing ought not to be formally structured. Instead, the resources involved can be better used elsewhere. In fact, research shows that, when innovating, the best approach is to create an environment devoid of structure and hierarchy and enable everyone involved to engage as one organic group. These environments can lead to new solutions that, under conventionally structured environments (filled with bottlenecks in terms of information flow, power structures, rules, and routines) would never be reached. In recent times companies have slowly started to embrace this disorganisation. Many of them embrace it in terms of perception (embracing the idea of disorder, as opposed to fearing it) and in terms of process (putting mechanisms in place to reduce structure). For example, Oticon, a large Danish manufacturer of hearing aids, used what it called a 'spaghetti' structure in order to reduce the organisation's rigid hierarchies. This involved scrapping formal job titles and giving staff huge amounts of ownership over their own time and projects. This approach proved to be highly successful initially, with clear improvements in worker productivity in all facets of the business. In similar fashion, the former chairman of General Electric embraced disorganisation, putting forward the idea of the 'boundaryless' organisation. Again, it involves breaking down the barriers between different parts of a company and encouraging virtual collaboration and flexible working. Google and a number of other tech companies have embraced (at least in part) these kinds of flexible structures, facilitated by technology and strong company values which glue people together. A word of warning to others thinking of jumping on this bandwagon: the evidence so far suggests disorder, much like order, also seems to have diminishing utility, and can also have detrimental effects on performance if overused. Like order, disorder should be embraced only so far as it is useful. But we should not fear it - nor venerate one over the other. This research also shows that we should continually question whether or not our existing assumptions work.", "hypothesis": "Innovation is most successful if the people involved have distinct roles.", "gold_label": "contradiction"}
{"uid": "id_644", "premise": "Why companies should welcome disorder Organisation is big business. Whether it is of our lives - all those inboxes and calendars - or how companies are structured, a multi-billion dollar industry helps to meet this need. We have more strategies for time management, project management and self-organisation than at any other time in human history. We are told that we ought to organise our company, our home life, our week, our day and even our sleep, all as a means to becoming more productive. Every week, countless seminars and workshops take place around the world to tell a paying public that they ought to structure their lives in order to achieve this. This rhetoric has also crept into the thinking of business leaders and entrepreneurs, much to the delight of self-proclaimed perfectionists with the need to get everything right. The number of business schools and graduates has massively increased over the past 50 years, essentially teaching people how to organise well. Ironically, however, the number of businesses that fail has also steadily increased. Work-related stress has increased. A large proportion of workers from all demographics claim to be dissatisfied with the way their work is structured and the way they are managed. This begs the question: what has gone wrong? Why is it that on paper the drive for organisation seems a sure shot for increasing productivity, but in reality falls well short of what is expected? This has been a problem for a while now. Frederick Taylor was one of the forefathers of scientific management. Writing in the first half of the 20th century, he designed a number of principles to improve the efficiency of the work process, which have since become widespread in modern companies. So the approach has been around for a while. New research suggests that this obsession with efficiency is misguided. The problem is not necessarily the management theories or strategies we use to organise our work; it's the basic assumptions we hold in approaching how we work. Here it's the assumption that order is a necessary condition for productivity. This assumption has also fostered the idea that disorder must be detrimental to organisational productivity. The result is that businesses and people spend time and money organising themselves for the sake of organising, rather than actually looking at the end goal and usefulness of such an effort. What's more, recent studies show that order actually has diminishing returns. Order does increase productivity to a certain extent, but eventually the usefulness of the process of organisation, and the benefit it yields, reduce until the point where any further increase in order reduces productivity. Some argue that in a business, if the cost of formally structuring something outweighs the benefit of doing it, then that thing ought not to be formally structured. Instead, the resources involved can be better used elsewhere. In fact, research shows that, when innovating, the best approach is to create an environment devoid of structure and hierarchy and enable everyone involved to engage as one organic group. These environments can lead to new solutions that, under conventionally structured environments (filled with bottlenecks in terms of information flow, power structures, rules, and routines) would never be reached. In recent times companies have slowly started to embrace this disorganisation. Many of them embrace it in terms of perception (embracing the idea of disorder, as opposed to fearing it) and in terms of process (putting mechanisms in place to reduce structure). For example, Oticon, a large Danish manufacturer of hearing aids, used what it called a 'spaghetti' structure in order to reduce the organisation's rigid hierarchies. This involved scrapping formal job titles and giving staff huge amounts of ownership over their own time and projects. This approach proved to be highly successful initially, with clear improvements in worker productivity in all facets of the business. In similar fashion, the former chairman of General Electric embraced disorganisation, putting forward the idea of the 'boundaryless' organisation. Again, it involves breaking down the barriers between different parts of a company and encouraging virtual collaboration and flexible working. Google and a number of other tech companies have embraced (at least in part) these kinds of flexible structures, facilitated by technology and strong company values which glue people together. A word of warning to others thinking of jumping on this bandwagon: the evidence so far suggests disorder, much like order, also seems to have diminishing utility, and can also have detrimental effects on performance if overused. Like order, disorder should be embraced only so far as it is useful. But we should not fear it - nor venerate one over the other. This research also shows that we should continually question whether or not our existing assumptions work.", "hypothesis": "Both businesses and people aim at order without really considering its value.", "gold_label": "entailment"}
{"uid": "id_645", "premise": "Why dont you go to the court if the employer does not pay you the Provident Fund contribution?", "hypothesis": "It is obligatory for the employer to pay the Provident Fund contribution to the Employees.", "gold_label": "entailment"}
{"uid": "id_646", "premise": "Why dont you go to the court if the employer does not pay you the Provident Fund contribution?", "hypothesis": "Courts can intervene in matters of dispute between employer and employees", "gold_label": "entailment"}
{"uid": "id_647", "premise": "Why pagodas don't fall down In a land swept by typhoons and shaken by earthquakes, how have Japan's tallest and seemingly flimsiest old buildings 500 or so wooden pagodas remained standing for centuries? Records show that only two have collapsed during the past 1400 years. Those that have disappeared were destroyed by fire as a result of lightning or civil war. The disastrous Hanshin earthquake in 1995 killed 6,400 people, toppled elevated highways, flattened office blocks and devastated the port area of Kobe. Yet it left the magnificent five-storey pagoda at the Toji temple in nearby Kyoto unscathed, though it levelled a number of buildings in the neighbourhood. Japanese scholars have been mystified for ages about why these tall, slender buildings are so stable. It was only thirty years ago that the building industry felt confident enough to erect office blocks of steel and reinforced concrete that had more than a dozen floors. With its special shock absorbers to dampen the effect of sudden sideways movements from an earthquake, the thirty-six-storey Kasumigaseki building in central Tokyo Japan's first skyscraper was considered a masterpiece of modern engineering when it was built in 1968. Yet in 826, with only pegs and wedges to keep his wooden structure upright, the master builder Kobodaishi had no hesitation in sending his majestic Toji pagoda soaring fifty-five metres into the sky nearly half as high as the Kasumigaseki skyscraper built some eleven centuries later. Clearly, Japanese carpenters of the day knew a few tricks about allowing a building to sway and settle itself rather than fight nature's forces. But what sort of tricks? The multi-storey pagoda came to Japan from China in the sixth century. As in China, they were first introduced with Buddhism and were attached to important temples. The Chinese built their pagodas in brick or stone, with inner staircases, and used them in later centuries mainly as watchtowers. When the pagoda reached Japan, however, its architecture was freely adapted to local conditions they were built less high, typically five rather than nine storeys, made mainly of wood and the staircase was dispensed with because the Japanese pagoda did not have any practical use but became more of an art object. Because of the typhoons that batter Japan in the summer, Japanese builders learned to extend the eaves of buildings further beyond the walls. This prevents rainwater gushing down the walls. Pagodas in China and Korea have nothing like the overhang that is found on pagodas in Japan. The roof of a Japanese temple building can be made to overhang the sides of the structure by fifty per cent or more of the building's overall width. For the same reason, the builders of Japanese pagodas seem to have further increased their weight by choosing to cover these extended eaves not with the porcelain tiles of many Chinese pagodas but with much heavier earthenware tiles. But this does not totally explain the great resilience of Japanese pagodas. Is the answer that, like a tall pine tree, the Japanese pagoda with its massive trunk-like central pillar known as shinbashira simply flexes and sways during a typhoon or earthquake? For centuries, many thought so. But the answer is not so simple because the startling thing is that the shinbashira actually carries no load at all. In fact, in some pagoda designs, it does not even rest on the ground, but is suspended from the top of the pagoda hanging loosely down through the middle of the building. The weight of the building is supported entirely by twelve outer and four inner columns. And what is the role of the shinbashira, the central pillar? The best way to understand the shinbashira's role is to watch a video made by Shuzo Ishida, a structural engineer at Kyoto Institute of Technology. Mr Ishida, known to his students as 'Professor Pagoda' because of his passion to understand the pagoda, has built a series of models and tested them on a 'shake-table' in his laboratory. In short, the shinbashira was acting like an enormous stationary pendulum. The ancient craftsmen, apparently without the assistance of very advanced mathematics, seemed to grasp the principles that were, more than a thousand years later, applied in the construction of Japan's first skyscraper. What those early craftsmen had found by trial and error was that under pressure a pagoda's loose stack of floors could be made to slither to and fro independent of one another. Viewed from the side, the pagoda seemed to be doing a snake dance with each consecutive floor moving in the opposite direction to its neighbours above and below. The shinbashira, running up through a hole in the centre of the building, constrained individual stories from moving too far because, after moving a certain distance, they banged into it, transmitting energy away along the column. Another strange feature of the Japanese pagoda is that, because the building tapers, with each successive floor plan being smaller than the one below, none of the vertical pillars that carry the weight of the building is connected to its corresponding pillar above. In other words, a five-storey pagoda contains not even one pillar that travels right up through the building to carry the structural loads from the top to the bottom. More surprising is the fact that the individual stories of a Japanese pagoda, unlike their counterparts elsewhere, are not actually connected to each other. They are simply stacked one on top of another like a pile of hats. Interestingly, such a design would not be permitted under current Japanese building regulations. And the extra-wide eaves? Think of them as a tightrope walker's balancing pole. The bigger the mass at each end of the pole, the easier it is for the tightrope walker to maintain his or her balance. The same holds true for a pagoda. 'With the eaves extending out on all sides like balancing poles, ' says Mr Ishida, 'the building responds to even the most powerful jolt of an earthquake with a graceful swaying, never an abrupt shaking. ' Here again, Japanese master builders of a thousand years ago anticipated concepts of modern structural engineering.", "hypothesis": "The builders of pagodas knew how to absorb some of the power produced by severe weather conditions.", "gold_label": "entailment"}
{"uid": "id_648", "premise": "Why pagodas don't fall down In a land swept by typhoons and shaken by earthquakes, how have Japan's tallest and seemingly flimsiest old buildings 500 or so wooden pagodas remained standing for centuries? Records show that only two have collapsed during the past 1400 years. Those that have disappeared were destroyed by fire as a result of lightning or civil war. The disastrous Hanshin earthquake in 1995 killed 6,400 people, toppled elevated highways, flattened office blocks and devastated the port area of Kobe. Yet it left the magnificent five-storey pagoda at the Toji temple in nearby Kyoto unscathed, though it levelled a number of buildings in the neighbourhood. Japanese scholars have been mystified for ages about why these tall, slender buildings are so stable. It was only thirty years ago that the building industry felt confident enough to erect office blocks of steel and reinforced concrete that had more than a dozen floors. With its special shock absorbers to dampen the effect of sudden sideways movements from an earthquake, the thirty-six-storey Kasumigaseki building in central Tokyo Japan's first skyscraper was considered a masterpiece of modern engineering when it was built in 1968. Yet in 826, with only pegs and wedges to keep his wooden structure upright, the master builder Kobodaishi had no hesitation in sending his majestic Toji pagoda soaring fifty-five metres into the sky nearly half as high as the Kasumigaseki skyscraper built some eleven centuries later. Clearly, Japanese carpenters of the day knew a few tricks about allowing a building to sway and settle itself rather than fight nature's forces. But what sort of tricks? The multi-storey pagoda came to Japan from China in the sixth century. As in China, they were first introduced with Buddhism and were attached to important temples. The Chinese built their pagodas in brick or stone, with inner staircases, and used them in later centuries mainly as watchtowers. When the pagoda reached Japan, however, its architecture was freely adapted to local conditions they were built less high, typically five rather than nine storeys, made mainly of wood and the staircase was dispensed with because the Japanese pagoda did not have any practical use but became more of an art object. Because of the typhoons that batter Japan in the summer, Japanese builders learned to extend the eaves of buildings further beyond the walls. This prevents rainwater gushing down the walls. Pagodas in China and Korea have nothing like the overhang that is found on pagodas in Japan. The roof of a Japanese temple building can be made to overhang the sides of the structure by fifty per cent or more of the building's overall width. For the same reason, the builders of Japanese pagodas seem to have further increased their weight by choosing to cover these extended eaves not with the porcelain tiles of many Chinese pagodas but with much heavier earthenware tiles. But this does not totally explain the great resilience of Japanese pagodas. Is the answer that, like a tall pine tree, the Japanese pagoda with its massive trunk-like central pillar known as shinbashira simply flexes and sways during a typhoon or earthquake? For centuries, many thought so. But the answer is not so simple because the startling thing is that the shinbashira actually carries no load at all. In fact, in some pagoda designs, it does not even rest on the ground, but is suspended from the top of the pagoda hanging loosely down through the middle of the building. The weight of the building is supported entirely by twelve outer and four inner columns. And what is the role of the shinbashira, the central pillar? The best way to understand the shinbashira's role is to watch a video made by Shuzo Ishida, a structural engineer at Kyoto Institute of Technology. Mr Ishida, known to his students as 'Professor Pagoda' because of his passion to understand the pagoda, has built a series of models and tested them on a 'shake-table' in his laboratory. In short, the shinbashira was acting like an enormous stationary pendulum. The ancient craftsmen, apparently without the assistance of very advanced mathematics, seemed to grasp the principles that were, more than a thousand years later, applied in the construction of Japan's first skyscraper. What those early craftsmen had found by trial and error was that under pressure a pagoda's loose stack of floors could be made to slither to and fro independent of one another. Viewed from the side, the pagoda seemed to be doing a snake dance with each consecutive floor moving in the opposite direction to its neighbours above and below. The shinbashira, running up through a hole in the centre of the building, constrained individual stories from moving too far because, after moving a certain distance, they banged into it, transmitting energy away along the column. Another strange feature of the Japanese pagoda is that, because the building tapers, with each successive floor plan being smaller than the one below, none of the vertical pillars that carry the weight of the building is connected to its corresponding pillar above. In other words, a five-storey pagoda contains not even one pillar that travels right up through the building to carry the structural loads from the top to the bottom. More surprising is the fact that the individual stories of a Japanese pagoda, unlike their counterparts elsewhere, are not actually connected to each other. They are simply stacked one on top of another like a pile of hats. Interestingly, such a design would not be permitted under current Japanese building regulations. And the extra-wide eaves? Think of them as a tightrope walker's balancing pole. The bigger the mass at each end of the pole, the easier it is for the tightrope walker to maintain his or her balance. The same holds true for a pagoda. 'With the eaves extending out on all sides like balancing poles, ' says Mr Ishida, 'the building responds to even the most powerful jolt of an earthquake with a graceful swaying, never an abrupt shaking. ' Here again, Japanese master builders of a thousand years ago anticipated concepts of modern structural engineering.", "hypothesis": "The other buildings near the Toji pagoda had been built in the last 30 years.", "gold_label": "neutral"}
{"uid": "id_649", "premise": "Why pagodas don't fall down In a land swept by typhoons and shaken by earthquakes, how have Japan's tallest and seemingly flimsiest old buildings 500 or so wooden pagodas remained standing for centuries? Records show that only two have collapsed during the past 1400 years. Those that have disappeared were destroyed by fire as a result of lightning or civil war. The disastrous Hanshin earthquake in 1995 killed 6,400 people, toppled elevated highways, flattened office blocks and devastated the port area of Kobe. Yet it left the magnificent five-storey pagoda at the Toji temple in nearby Kyoto unscathed, though it levelled a number of buildings in the neighbourhood. Japanese scholars have been mystified for ages about why these tall, slender buildings are so stable. It was only thirty years ago that the building industry felt confident enough to erect office blocks of steel and reinforced concrete that had more than a dozen floors. With its special shock absorbers to dampen the effect of sudden sideways movements from an earthquake, the thirty-six-storey Kasumigaseki building in central Tokyo Japan's first skyscraper was considered a masterpiece of modern engineering when it was built in 1968. Yet in 826, with only pegs and wedges to keep his wooden structure upright, the master builder Kobodaishi had no hesitation in sending his majestic Toji pagoda soaring fifty-five metres into the sky nearly half as high as the Kasumigaseki skyscraper built some eleven centuries later. Clearly, Japanese carpenters of the day knew a few tricks about allowing a building to sway and settle itself rather than fight nature's forces. But what sort of tricks? The multi-storey pagoda came to Japan from China in the sixth century. As in China, they were first introduced with Buddhism and were attached to important temples. The Chinese built their pagodas in brick or stone, with inner staircases, and used them in later centuries mainly as watchtowers. When the pagoda reached Japan, however, its architecture was freely adapted to local conditions they were built less high, typically five rather than nine storeys, made mainly of wood and the staircase was dispensed with because the Japanese pagoda did not have any practical use but became more of an art object. Because of the typhoons that batter Japan in the summer, Japanese builders learned to extend the eaves of buildings further beyond the walls. This prevents rainwater gushing down the walls. Pagodas in China and Korea have nothing like the overhang that is found on pagodas in Japan. The roof of a Japanese temple building can be made to overhang the sides of the structure by fifty per cent or more of the building's overall width. For the same reason, the builders of Japanese pagodas seem to have further increased their weight by choosing to cover these extended eaves not with the porcelain tiles of many Chinese pagodas but with much heavier earthenware tiles. But this does not totally explain the great resilience of Japanese pagodas. Is the answer that, like a tall pine tree, the Japanese pagoda with its massive trunk-like central pillar known as shinbashira simply flexes and sways during a typhoon or earthquake? For centuries, many thought so. But the answer is not so simple because the startling thing is that the shinbashira actually carries no load at all. In fact, in some pagoda designs, it does not even rest on the ground, but is suspended from the top of the pagoda hanging loosely down through the middle of the building. The weight of the building is supported entirely by twelve outer and four inner columns. And what is the role of the shinbashira, the central pillar? The best way to understand the shinbashira's role is to watch a video made by Shuzo Ishida, a structural engineer at Kyoto Institute of Technology. Mr Ishida, known to his students as 'Professor Pagoda' because of his passion to understand the pagoda, has built a series of models and tested them on a 'shake-table' in his laboratory. In short, the shinbashira was acting like an enormous stationary pendulum. The ancient craftsmen, apparently without the assistance of very advanced mathematics, seemed to grasp the principles that were, more than a thousand years later, applied in the construction of Japan's first skyscraper. What those early craftsmen had found by trial and error was that under pressure a pagoda's loose stack of floors could be made to slither to and fro independent of one another. Viewed from the side, the pagoda seemed to be doing a snake dance with each consecutive floor moving in the opposite direction to its neighbours above and below. The shinbashira, running up through a hole in the centre of the building, constrained individual stories from moving too far because, after moving a certain distance, they banged into it, transmitting energy away along the column. Another strange feature of the Japanese pagoda is that, because the building tapers, with each successive floor plan being smaller than the one below, none of the vertical pillars that carry the weight of the building is connected to its corresponding pillar above. In other words, a five-storey pagoda contains not even one pillar that travels right up through the building to carry the structural loads from the top to the bottom. More surprising is the fact that the individual stories of a Japanese pagoda, unlike their counterparts elsewhere, are not actually connected to each other. They are simply stacked one on top of another like a pile of hats. Interestingly, such a design would not be permitted under current Japanese building regulations. And the extra-wide eaves? Think of them as a tightrope walker's balancing pole. The bigger the mass at each end of the pole, the easier it is for the tightrope walker to maintain his or her balance. The same holds true for a pagoda. 'With the eaves extending out on all sides like balancing poles, ' says Mr Ishida, 'the building responds to even the most powerful jolt of an earthquake with a graceful swaying, never an abrupt shaking. ' Here again, Japanese master builders of a thousand years ago anticipated concepts of modern structural engineering.", "hypothesis": "The Hanshin earthquake of 1995 destroyed the pagoda at the Toji temple.", "gold_label": "contradiction"}
{"uid": "id_650", "premise": "Why pagodas don't fall down In a land swept by typhoons and shaken by earthquakes, how have Japan's tallest and seemingly flimsiest old buildings 500 or so wooden pagodas remained standing for centuries? Records show that only two have collapsed during the past 1400 years. Those that have disappeared were destroyed by fire as a result of lightning or civil war. The disastrous Hanshin earthquake in 1995 killed 6,400 people, toppled elevated highways, flattened office blocks and devastated the port area of Kobe. Yet it left the magnificent five-storey pagoda at the Toji temple in nearby Kyoto unscathed, though it levelled a number of buildings in the neighbourhood. Japanese scholars have been mystified for ages about why these tall, slender buildings are so stable. It was only thirty years ago that the building industry felt confident enough to erect office blocks of steel and reinforced concrete that had more than a dozen floors. With its special shock absorbers to dampen the effect of sudden sideways movements from an earthquake, the thirty-six-storey Kasumigaseki building in central Tokyo Japan's first skyscraper was considered a masterpiece of modern engineering when it was built in 1968. Yet in 826, with only pegs and wedges to keep his wooden structure upright, the master builder Kobodaishi had no hesitation in sending his majestic Toji pagoda soaring fifty-five metres into the sky nearly half as high as the Kasumigaseki skyscraper built some eleven centuries later. Clearly, Japanese carpenters of the day knew a few tricks about allowing a building to sway and settle itself rather than fight nature's forces. But what sort of tricks? The multi-storey pagoda came to Japan from China in the sixth century. As in China, they were first introduced with Buddhism and were attached to important temples. The Chinese built their pagodas in brick or stone, with inner staircases, and used them in later centuries mainly as watchtowers. When the pagoda reached Japan, however, its architecture was freely adapted to local conditions they were built less high, typically five rather than nine storeys, made mainly of wood and the staircase was dispensed with because the Japanese pagoda did not have any practical use but became more of an art object. Because of the typhoons that batter Japan in the summer, Japanese builders learned to extend the eaves of buildings further beyond the walls. This prevents rainwater gushing down the walls. Pagodas in China and Korea have nothing like the overhang that is found on pagodas in Japan. The roof of a Japanese temple building can be made to overhang the sides of the structure by fifty per cent or more of the building's overall width. For the same reason, the builders of Japanese pagodas seem to have further increased their weight by choosing to cover these extended eaves not with the porcelain tiles of many Chinese pagodas but with much heavier earthenware tiles. But this does not totally explain the great resilience of Japanese pagodas. Is the answer that, like a tall pine tree, the Japanese pagoda with its massive trunk-like central pillar known as shinbashira simply flexes and sways during a typhoon or earthquake? For centuries, many thought so. But the answer is not so simple because the startling thing is that the shinbashira actually carries no load at all. In fact, in some pagoda designs, it does not even rest on the ground, but is suspended from the top of the pagoda hanging loosely down through the middle of the building. The weight of the building is supported entirely by twelve outer and four inner columns. And what is the role of the shinbashira, the central pillar? The best way to understand the shinbashira's role is to watch a video made by Shuzo Ishida, a structural engineer at Kyoto Institute of Technology. Mr Ishida, known to his students as 'Professor Pagoda' because of his passion to understand the pagoda, has built a series of models and tested them on a 'shake-table' in his laboratory. In short, the shinbashira was acting like an enormous stationary pendulum. The ancient craftsmen, apparently without the assistance of very advanced mathematics, seemed to grasp the principles that were, more than a thousand years later, applied in the construction of Japan's first skyscraper. What those early craftsmen had found by trial and error was that under pressure a pagoda's loose stack of floors could be made to slither to and fro independent of one another. Viewed from the side, the pagoda seemed to be doing a snake dance with each consecutive floor moving in the opposite direction to its neighbours above and below. The shinbashira, running up through a hole in the centre of the building, constrained individual stories from moving too far because, after moving a certain distance, they banged into it, transmitting energy away along the column. Another strange feature of the Japanese pagoda is that, because the building tapers, with each successive floor plan being smaller than the one below, none of the vertical pillars that carry the weight of the building is connected to its corresponding pillar above. In other words, a five-storey pagoda contains not even one pillar that travels right up through the building to carry the structural loads from the top to the bottom. More surprising is the fact that the individual stories of a Japanese pagoda, unlike their counterparts elsewhere, are not actually connected to each other. They are simply stacked one on top of another like a pile of hats. Interestingly, such a design would not be permitted under current Japanese building regulations. And the extra-wide eaves? Think of them as a tightrope walker's balancing pole. The bigger the mass at each end of the pole, the easier it is for the tightrope walker to maintain his or her balance. The same holds true for a pagoda. 'With the eaves extending out on all sides like balancing poles, ' says Mr Ishida, 'the building responds to even the most powerful jolt of an earthquake with a graceful swaying, never an abrupt shaking. ' Here again, Japanese master builders of a thousand years ago anticipated concepts of modern structural engineering.", "hypothesis": "Only two Japanese pagodas have collapsed in 1400 years.", "gold_label": "entailment"}
{"uid": "id_651", "premise": "Why pagodas dont fall down. In a land swept by typhoons and shaken by earthquakes, how have Japans tallest and seemingly flimsiest old buildings 500 or so wooden pagodas remained standing for centuries? Records show that only two have collapsed during the past 1400 years. Those that have disappeared were destroyed by fire as a result of lightning or civil war. The disastrous Hanshin earthquake in 1995 killed 6,400 people, toppled elevated highways, flattened office blocks and devastated the port area of Kobe. Yet it left the magnificent five-storey pagoda at the Toji temple in nearby Kyoto unscathed, though it levelled a number of buildings in the neighbourhood. Japanese scholars have been mystified for ages about why these tall, slender buildings are so stable. It was only thirty years ago that the building industry felt confident enough to erect office blocks of steel and reinforced concrete that had more than a dozen floors. With its special shock absorbers to dampen the effect of sudden sideways movements from an earthquake, the thirty-six-storey Kasumigaseki building in central Tokyo Japans first skyscraper was considered a masterpiece of modern engineering when it was built in 1968. Yet in 826, with only pegs and wedges to keep his wooden structure upright, the master builder Kobodaishi had no hesitation in sending his majestic Toji pagoda soaring fifty-five metres into the sky nearly half as high as the Kasumigaseki skyscraper built some eleven centuries later. Clearly, Japanese carpenters of the day knew a few tricks about allowing a building to sway and settle itself rather than fight natures forces. But what sort of tricks? The multi-storey pagoda came to Japan from China in the sixth century. As in China, they were first introduced with Buddhism and were attached to important temples. The Chinese built their pagodas in brick or stone, with inner staircases, and used them in later centuries mainly as watchtowers. When the pagoda reached Japan, however, its architecture was freely adapted to local conditions they were built less high, typically five rather than nine storeys, made mainly of wood and the staircase was dispensed with because the Japanese pagoda did not have any practical use but became more of an art object. Because of the typhoons that batter Japan in the summer, Japanese builders learned to extend the eaves of buildings further beyond the walls. This prevents rainwater gushing down the walls. Pagodas in China and Korea have nothing like the overhang that is found on pagodas in Japan. The roof of a Japanese temple building can be made to overhang the sides of the structure by fifty per cent or more of the buildings overall width. For the same reason, the builders of Japanese pagodas seem to have further increased their weight by choosing to cover these extended eaves not with the porcelain tiles of many Chinese pagodas but with much heavier earthenware tiles. But this does not totally explain the great resilience of Japanese pagodas. Is the answer that, like a tall pine tree, the Japanese pagoda with its massive trunk-like central pillar known as shinbashira simply flexes and sways during a typhoon or earthquake? For centuries, many thought so. But the answer is not so simple because the startling thing is that the shinbashira actually carries no load at all. In fact, in some pagoda designs, it does not even rest on the ground, but is suspended from the top of the pagoda hanging loosely down through the middle of the building. The weight of the building is supported entirely by twelve outer and four inner columns. And what is the role of the shinbashira, the central pillar? The best way to understand the shinbashiras role is to watch a video made by Shuzo Ishida, a structural engineer at Kyoto Institute of Technology. Mr Ishida, known to his students as Professor Pagoda because of his passion to understand the pagoda, has built a series of models and tested them on a shake-table in his laboratory. In short, the shinbashira was acting like an enormous stationary pendulum. The ancient craftsmen, apparently without the assistance of very advanced mathematics, seemed to grasp the principles that were, more than a thousand years later, applied in the construction of Japans first skyscraper. What those early craftsmen had found by trial and error was that under pressure a pagodas loose stack of floors could be made to slither to and fro independent of one another. Viewed from the side, the pagoda seemed to be doing a snake dance with each consecutive floor moving in the opposite direction to its neighbours above and below. The shinbashira, running up through a hole in the centre of the building, constrained individual stories from moving too far because, after moving a certain distance, they banged into it, transmitting energy away along the column. Another strange feature of the Japanese pagoda is that, because the building tapers, with each successive floor plan being smaller than the one below, none of the vertical pillars that carry the weight of the building is connected to its corresponding pillar above. In other words, a five-storey pagoda contains not even one pillar that travels right up through the building to carry the structural loads from the top to the bottom. More surprising is the fact that the individual stories of a Japanese pagoda, unlike their counterparts elsewhere, are not actually connected to each other. They are simply stacked one on top of another like a pile of hats. Interestingly, such a design would not be permitted under current Japanese building regulations. And the extra-wide eaves? Think of them as a tightrope walkers balancing pole. The bigger the mass at each end of the pole, the easier it is for the tightrope walker to maintain his or her balance. The same holds true for a pagoda. With the eaves extending out on all sides like balancing poles, says Mr Ishida, the building responds to even the most powerful jolt of an earthquake with a graceful swaying, never an abrupt shaking. Here again, Japanese master builders of a thousand years ago anticipated concepts of modern structural engineering.", "hypothesis": "The builders of pagodas knew how to absorb some of the power produced by severe weather conditions.", "gold_label": "entailment"}
{"uid": "id_652", "premise": "Why pagodas dont fall down. In a land swept by typhoons and shaken by earthquakes, how have Japans tallest and seemingly flimsiest old buildings 500 or so wooden pagodas remained standing for centuries? Records show that only two have collapsed during the past 1400 years. Those that have disappeared were destroyed by fire as a result of lightning or civil war. The disastrous Hanshin earthquake in 1995 killed 6,400 people, toppled elevated highways, flattened office blocks and devastated the port area of Kobe. Yet it left the magnificent five-storey pagoda at the Toji temple in nearby Kyoto unscathed, though it levelled a number of buildings in the neighbourhood. Japanese scholars have been mystified for ages about why these tall, slender buildings are so stable. It was only thirty years ago that the building industry felt confident enough to erect office blocks of steel and reinforced concrete that had more than a dozen floors. With its special shock absorbers to dampen the effect of sudden sideways movements from an earthquake, the thirty-six-storey Kasumigaseki building in central Tokyo Japans first skyscraper was considered a masterpiece of modern engineering when it was built in 1968. Yet in 826, with only pegs and wedges to keep his wooden structure upright, the master builder Kobodaishi had no hesitation in sending his majestic Toji pagoda soaring fifty-five metres into the sky nearly half as high as the Kasumigaseki skyscraper built some eleven centuries later. Clearly, Japanese carpenters of the day knew a few tricks about allowing a building to sway and settle itself rather than fight natures forces. But what sort of tricks? The multi-storey pagoda came to Japan from China in the sixth century. As in China, they were first introduced with Buddhism and were attached to important temples. The Chinese built their pagodas in brick or stone, with inner staircases, and used them in later centuries mainly as watchtowers. When the pagoda reached Japan, however, its architecture was freely adapted to local conditions they were built less high, typically five rather than nine storeys, made mainly of wood and the staircase was dispensed with because the Japanese pagoda did not have any practical use but became more of an art object. Because of the typhoons that batter Japan in the summer, Japanese builders learned to extend the eaves of buildings further beyond the walls. This prevents rainwater gushing down the walls. Pagodas in China and Korea have nothing like the overhang that is found on pagodas in Japan. The roof of a Japanese temple building can be made to overhang the sides of the structure by fifty per cent or more of the buildings overall width. For the same reason, the builders of Japanese pagodas seem to have further increased their weight by choosing to cover these extended eaves not with the porcelain tiles of many Chinese pagodas but with much heavier earthenware tiles. But this does not totally explain the great resilience of Japanese pagodas. Is the answer that, like a tall pine tree, the Japanese pagoda with its massive trunk-like central pillar known as shinbashira simply flexes and sways during a typhoon or earthquake? For centuries, many thought so. But the answer is not so simple because the startling thing is that the shinbashira actually carries no load at all. In fact, in some pagoda designs, it does not even rest on the ground, but is suspended from the top of the pagoda hanging loosely down through the middle of the building. The weight of the building is supported entirely by twelve outer and four inner columns. And what is the role of the shinbashira, the central pillar? The best way to understand the shinbashiras role is to watch a video made by Shuzo Ishida, a structural engineer at Kyoto Institute of Technology. Mr Ishida, known to his students as Professor Pagoda because of his passion to understand the pagoda, has built a series of models and tested them on a shake-table in his laboratory. In short, the shinbashira was acting like an enormous stationary pendulum. The ancient craftsmen, apparently without the assistance of very advanced mathematics, seemed to grasp the principles that were, more than a thousand years later, applied in the construction of Japans first skyscraper. What those early craftsmen had found by trial and error was that under pressure a pagodas loose stack of floors could be made to slither to and fro independent of one another. Viewed from the side, the pagoda seemed to be doing a snake dance with each consecutive floor moving in the opposite direction to its neighbours above and below. The shinbashira, running up through a hole in the centre of the building, constrained individual stories from moving too far because, after moving a certain distance, they banged into it, transmitting energy away along the column. Another strange feature of the Japanese pagoda is that, because the building tapers, with each successive floor plan being smaller than the one below, none of the vertical pillars that carry the weight of the building is connected to its corresponding pillar above. In other words, a five-storey pagoda contains not even one pillar that travels right up through the building to carry the structural loads from the top to the bottom. More surprising is the fact that the individual stories of a Japanese pagoda, unlike their counterparts elsewhere, are not actually connected to each other. They are simply stacked one on top of another like a pile of hats. Interestingly, such a design would not be permitted under current Japanese building regulations. And the extra-wide eaves? Think of them as a tightrope walkers balancing pole. The bigger the mass at each end of the pole, the easier it is for the tightrope walker to maintain his or her balance. The same holds true for a pagoda. With the eaves extending out on all sides like balancing poles, says Mr Ishida, the building responds to even the most powerful jolt of an earthquake with a graceful swaying, never an abrupt shaking. Here again, Japanese master builders of a thousand years ago anticipated concepts of modern structural engineering.", "hypothesis": "The other buildings near the Toji pagoda had been built in the last 30 years.", "gold_label": "neutral"}
{"uid": "id_653", "premise": "Why pagodas dont fall down. In a land swept by typhoons and shaken by earthquakes, how have Japans tallest and seemingly flimsiest old buildings 500 or so wooden pagodas remained standing for centuries? Records show that only two have collapsed during the past 1400 years. Those that have disappeared were destroyed by fire as a result of lightning or civil war. The disastrous Hanshin earthquake in 1995 killed 6,400 people, toppled elevated highways, flattened office blocks and devastated the port area of Kobe. Yet it left the magnificent five-storey pagoda at the Toji temple in nearby Kyoto unscathed, though it levelled a number of buildings in the neighbourhood. Japanese scholars have been mystified for ages about why these tall, slender buildings are so stable. It was only thirty years ago that the building industry felt confident enough to erect office blocks of steel and reinforced concrete that had more than a dozen floors. With its special shock absorbers to dampen the effect of sudden sideways movements from an earthquake, the thirty-six-storey Kasumigaseki building in central Tokyo Japans first skyscraper was considered a masterpiece of modern engineering when it was built in 1968. Yet in 826, with only pegs and wedges to keep his wooden structure upright, the master builder Kobodaishi had no hesitation in sending his majestic Toji pagoda soaring fifty-five metres into the sky nearly half as high as the Kasumigaseki skyscraper built some eleven centuries later. Clearly, Japanese carpenters of the day knew a few tricks about allowing a building to sway and settle itself rather than fight natures forces. But what sort of tricks? The multi-storey pagoda came to Japan from China in the sixth century. As in China, they were first introduced with Buddhism and were attached to important temples. The Chinese built their pagodas in brick or stone, with inner staircases, and used them in later centuries mainly as watchtowers. When the pagoda reached Japan, however, its architecture was freely adapted to local conditions they were built less high, typically five rather than nine storeys, made mainly of wood and the staircase was dispensed with because the Japanese pagoda did not have any practical use but became more of an art object. Because of the typhoons that batter Japan in the summer, Japanese builders learned to extend the eaves of buildings further beyond the walls. This prevents rainwater gushing down the walls. Pagodas in China and Korea have nothing like the overhang that is found on pagodas in Japan. The roof of a Japanese temple building can be made to overhang the sides of the structure by fifty per cent or more of the buildings overall width. For the same reason, the builders of Japanese pagodas seem to have further increased their weight by choosing to cover these extended eaves not with the porcelain tiles of many Chinese pagodas but with much heavier earthenware tiles. But this does not totally explain the great resilience of Japanese pagodas. Is the answer that, like a tall pine tree, the Japanese pagoda with its massive trunk-like central pillar known as shinbashira simply flexes and sways during a typhoon or earthquake? For centuries, many thought so. But the answer is not so simple because the startling thing is that the shinbashira actually carries no load at all. In fact, in some pagoda designs, it does not even rest on the ground, but is suspended from the top of the pagoda hanging loosely down through the middle of the building. The weight of the building is supported entirely by twelve outer and four inner columns. And what is the role of the shinbashira, the central pillar? The best way to understand the shinbashiras role is to watch a video made by Shuzo Ishida, a structural engineer at Kyoto Institute of Technology. Mr Ishida, known to his students as Professor Pagoda because of his passion to understand the pagoda, has built a series of models and tested them on a shake-table in his laboratory. In short, the shinbashira was acting like an enormous stationary pendulum. The ancient craftsmen, apparently without the assistance of very advanced mathematics, seemed to grasp the principles that were, more than a thousand years later, applied in the construction of Japans first skyscraper. What those early craftsmen had found by trial and error was that under pressure a pagodas loose stack of floors could be made to slither to and fro independent of one another. Viewed from the side, the pagoda seemed to be doing a snake dance with each consecutive floor moving in the opposite direction to its neighbours above and below. The shinbashira, running up through a hole in the centre of the building, constrained individual stories from moving too far because, after moving a certain distance, they banged into it, transmitting energy away along the column. Another strange feature of the Japanese pagoda is that, because the building tapers, with each successive floor plan being smaller than the one below, none of the vertical pillars that carry the weight of the building is connected to its corresponding pillar above. In other words, a five-storey pagoda contains not even one pillar that travels right up through the building to carry the structural loads from the top to the bottom. More surprising is the fact that the individual stories of a Japanese pagoda, unlike their counterparts elsewhere, are not actually connected to each other. They are simply stacked one on top of another like a pile of hats. Interestingly, such a design would not be permitted under current Japanese building regulations. And the extra-wide eaves? Think of them as a tightrope walkers balancing pole. The bigger the mass at each end of the pole, the easier it is for the tightrope walker to maintain his or her balance. The same holds true for a pagoda. With the eaves extending out on all sides like balancing poles, says Mr Ishida, the building responds to even the most powerful jolt of an earthquake with a graceful swaying, never an abrupt shaking. Here again, Japanese master builders of a thousand years ago anticipated concepts of modern structural engineering.", "hypothesis": "The Hanshin earthquake of 1995 destroyed the pagoda at the Toji temple.", "gold_label": "contradiction"}
{"uid": "id_654", "premise": "Why pagodas dont fall down. In a land swept by typhoons and shaken by earthquakes, how have Japans tallest and seemingly flimsiest old buildings 500 or so wooden pagodas remained standing for centuries? Records show that only two have collapsed during the past 1400 years. Those that have disappeared were destroyed by fire as a result of lightning or civil war. The disastrous Hanshin earthquake in 1995 killed 6,400 people, toppled elevated highways, flattened office blocks and devastated the port area of Kobe. Yet it left the magnificent five-storey pagoda at the Toji temple in nearby Kyoto unscathed, though it levelled a number of buildings in the neighbourhood. Japanese scholars have been mystified for ages about why these tall, slender buildings are so stable. It was only thirty years ago that the building industry felt confident enough to erect office blocks of steel and reinforced concrete that had more than a dozen floors. With its special shock absorbers to dampen the effect of sudden sideways movements from an earthquake, the thirty-six-storey Kasumigaseki building in central Tokyo Japans first skyscraper was considered a masterpiece of modern engineering when it was built in 1968. Yet in 826, with only pegs and wedges to keep his wooden structure upright, the master builder Kobodaishi had no hesitation in sending his majestic Toji pagoda soaring fifty-five metres into the sky nearly half as high as the Kasumigaseki skyscraper built some eleven centuries later. Clearly, Japanese carpenters of the day knew a few tricks about allowing a building to sway and settle itself rather than fight natures forces. But what sort of tricks? The multi-storey pagoda came to Japan from China in the sixth century. As in China, they were first introduced with Buddhism and were attached to important temples. The Chinese built their pagodas in brick or stone, with inner staircases, and used them in later centuries mainly as watchtowers. When the pagoda reached Japan, however, its architecture was freely adapted to local conditions they were built less high, typically five rather than nine storeys, made mainly of wood and the staircase was dispensed with because the Japanese pagoda did not have any practical use but became more of an art object. Because of the typhoons that batter Japan in the summer, Japanese builders learned to extend the eaves of buildings further beyond the walls. This prevents rainwater gushing down the walls. Pagodas in China and Korea have nothing like the overhang that is found on pagodas in Japan. The roof of a Japanese temple building can be made to overhang the sides of the structure by fifty per cent or more of the buildings overall width. For the same reason, the builders of Japanese pagodas seem to have further increased their weight by choosing to cover these extended eaves not with the porcelain tiles of many Chinese pagodas but with much heavier earthenware tiles. But this does not totally explain the great resilience of Japanese pagodas. Is the answer that, like a tall pine tree, the Japanese pagoda with its massive trunk-like central pillar known as shinbashira simply flexes and sways during a typhoon or earthquake? For centuries, many thought so. But the answer is not so simple because the startling thing is that the shinbashira actually carries no load at all. In fact, in some pagoda designs, it does not even rest on the ground, but is suspended from the top of the pagoda hanging loosely down through the middle of the building. The weight of the building is supported entirely by twelve outer and four inner columns. And what is the role of the shinbashira, the central pillar? The best way to understand the shinbashiras role is to watch a video made by Shuzo Ishida, a structural engineer at Kyoto Institute of Technology. Mr Ishida, known to his students as Professor Pagoda because of his passion to understand the pagoda, has built a series of models and tested them on a shake-table in his laboratory. In short, the shinbashira was acting like an enormous stationary pendulum. The ancient craftsmen, apparently without the assistance of very advanced mathematics, seemed to grasp the principles that were, more than a thousand years later, applied in the construction of Japans first skyscraper. What those early craftsmen had found by trial and error was that under pressure a pagodas loose stack of floors could be made to slither to and fro independent of one another. Viewed from the side, the pagoda seemed to be doing a snake dance with each consecutive floor moving in the opposite direction to its neighbours above and below. The shinbashira, running up through a hole in the centre of the building, constrained individual stories from moving too far because, after moving a certain distance, they banged into it, transmitting energy away along the column. Another strange feature of the Japanese pagoda is that, because the building tapers, with each successive floor plan being smaller than the one below, none of the vertical pillars that carry the weight of the building is connected to its corresponding pillar above. In other words, a five-storey pagoda contains not even one pillar that travels right up through the building to carry the structural loads from the top to the bottom. More surprising is the fact that the individual stories of a Japanese pagoda, unlike their counterparts elsewhere, are not actually connected to each other. They are simply stacked one on top of another like a pile of hats. Interestingly, such a design would not be permitted under current Japanese building regulations. And the extra-wide eaves? Think of them as a tightrope walkers balancing pole. The bigger the mass at each end of the pole, the easier it is for the tightrope walker to maintain his or her balance. The same holds true for a pagoda. With the eaves extending out on all sides like balancing poles, says Mr Ishida, the building responds to even the most powerful jolt of an earthquake with a graceful swaying, never an abrupt shaking. Here again, Japanese master builders of a thousand years ago anticipated concepts of modern structural engineering.", "hypothesis": "Only two Japanese pagodas have collapsed in 1400 years.", "gold_label": "entailment"}
{"uid": "id_655", "premise": "Why zoos are good Scientist David Hone makes the case for zoos In my view, it is perfectly possible for many species of animals living in zoos or wildlife parks to have a quality of life as high as, or higher than, in the wild. Animals in good zoos get a varied and high-quality diet with all the supplements required, and any illnesses they might have will be treated. Their movement might be somewhat restricted, but they have a safe environment in which to live, and they are spared bullying and social ostracism by others of their kind. They do not suffer from the threat or stress of predators, or the irritation and pain of parasites or injuries. The average captive animal will have a greater life expectancy compared with its wild counterpart, and will not die of drought, of starvation or in the jaws of a predator. A lot of very nasty things happen to truly 'wild' animals that simply don't happen in good zoos, and to view a life that is 'free' as one that is automatically 'good' is, I think, an error. Furthermore, zoos serve several key purposes. Firstly, zoos aid conservation. Colossal numbers of species are becoming extinct across the world, and many more are increasingly threatened and therefore risk extinction. Moreover, some of these collapses have been sudden, dramatic and unexpected, or were simply discovered very late in the day. A species protected in captivity can be bred up to provide a reservoir population against a population crash or extinction in the wild. A good number of species only exist in captivity, with many of these living in zoos. Still more only exist in the wild because they have been reintroduced from zoos, or have wild populations that have been boosted by captive bred animals. Without these efforts there would be fewer species alive today. Although reintroduction successes are few and far between, the numbers are increasing, and the very fact that species have been saved or reintroduced as a result of captive breeding proves the value of such initiatives. Zoos also provide education. Many children and adults, especially those in cities, will never see a wild animal beyond a fox or pigeon. While it is true that television documentaries are becoming ever more detailed and impressive, and many natural history specimens are on display in museums, there really is nothing to compare with seeing a living creature in the flesh, hearing it, smelling it, watching what it does and having the time to absorb details. That alone will bring a greater understanding and perspective to many, and hopefully give them a greater appreciation for wildlife, conservation efforts and how they can contribute. In addition to this, there is also the education that can take place in zoos through signs, talks and presentations which directly communicate information to visitors about the animals they are seeing and their place in the world. This was an area where zoos used to be lacking, but they are now increasingly sophisticated in their communication and outreach work. Many zoos also work directly to educate conservation workers in other countries, or send their animal keepers abroad to contribute their knowledge and skills to those working in zoos and reserves, thereby helping to improve conditions and reintroductions all over the world. Zoos also play a key role in research. If we are to save wild species and restore and repair ecosystems we need to know about how key species live, act and react. Being able to undertake research on animals in zoos where there is less risk and fewer variables means real changes can be effected on wild populations. Finding out about, for example, the oestrus cycle of an animal or its breeding rate helps us manage wild populations. Procedures such as capturing and moving at-risk or dangerous individuals are bolstered by knowledge gained in zoos about doses for anaesthetics, and by experience in handling arid transporting animals. This can make a real difference to conservation efforts and to the reduction of human-animal conflicts, and can provide a knowledge base for helping with the increasing threats of habitat destruction and other problems. In conclusion, considering the many ongoing global threats to the environment, it is hard for me to see zoos as anything other than essential to the long-term survival of numerous species. They are vital not just in terms of protecting animals, but as a means of learning about them to aid those still in the wild, as well as educating and informing the general population about these animals and their world so that they can assist or at least accept the need to be more environmentally conscious. Without them, the world would be, and would increasingly become, a much poorer place.", "hypothesis": "Improvements in the quality of TV wildlife documentaries have resulted in increased numbers of zoo visitors.", "gold_label": "neutral"}
{"uid": "id_656", "premise": "Why zoos are good Scientist David Hone makes the case for zoos In my view, it is perfectly possible for many species of animals living in zoos or wildlife parks to have a quality of life as high as, or higher than, in the wild. Animals in good zoos get a varied and high-quality diet with all the supplements required, and any illnesses they might have will be treated. Their movement might be somewhat restricted, but they have a safe environment in which to live, and they are spared bullying and social ostracism by others of their kind. They do not suffer from the threat or stress of predators, or the irritation and pain of parasites or injuries. The average captive animal will have a greater life expectancy compared with its wild counterpart, and will not die of drought, of starvation or in the jaws of a predator. A lot of very nasty things happen to truly 'wild' animals that simply don't happen in good zoos, and to view a life that is 'free' as one that is automatically 'good' is, I think, an error. Furthermore, zoos serve several key purposes. Firstly, zoos aid conservation. Colossal numbers of species are becoming extinct across the world, and many more are increasingly threatened and therefore risk extinction. Moreover, some of these collapses have been sudden, dramatic and unexpected, or were simply discovered very late in the day. A species protected in captivity can be bred up to provide a reservoir population against a population crash or extinction in the wild. A good number of species only exist in captivity, with many of these living in zoos. Still more only exist in the wild because they have been reintroduced from zoos, or have wild populations that have been boosted by captive bred animals. Without these efforts there would be fewer species alive today. Although reintroduction successes are few and far between, the numbers are increasing, and the very fact that species have been saved or reintroduced as a result of captive breeding proves the value of such initiatives. Zoos also provide education. Many children and adults, especially those in cities, will never see a wild animal beyond a fox or pigeon. While it is true that television documentaries are becoming ever more detailed and impressive, and many natural history specimens are on display in museums, there really is nothing to compare with seeing a living creature in the flesh, hearing it, smelling it, watching what it does and having the time to absorb details. That alone will bring a greater understanding and perspective to many, and hopefully give them a greater appreciation for wildlife, conservation efforts and how they can contribute. In addition to this, there is also the education that can take place in zoos through signs, talks and presentations which directly communicate information to visitors about the animals they are seeing and their place in the world. This was an area where zoos used to be lacking, but they are now increasingly sophisticated in their communication and outreach work. Many zoos also work directly to educate conservation workers in other countries, or send their animal keepers abroad to contribute their knowledge and skills to those working in zoos and reserves, thereby helping to improve conditions and reintroductions all over the world. Zoos also play a key role in research. If we are to save wild species and restore and repair ecosystems we need to know about how key species live, act and react. Being able to undertake research on animals in zoos where there is less risk and fewer variables means real changes can be effected on wild populations. Finding out about, for example, the oestrus cycle of an animal or its breeding rate helps us manage wild populations. Procedures such as capturing and moving at-risk or dangerous individuals are bolstered by knowledge gained in zoos about doses for anaesthetics, and by experience in handling arid transporting animals. This can make a real difference to conservation efforts and to the reduction of human-animal conflicts, and can provide a knowledge base for helping with the increasing threats of habitat destruction and other problems. In conclusion, considering the many ongoing global threats to the environment, it is hard for me to see zoos as anything other than essential to the long-term survival of numerous species. They are vital not just in terms of protecting animals, but as a means of learning about them to aid those still in the wild, as well as educating and informing the general population about these animals and their world so that they can assist or at least accept the need to be more environmentally conscious. Without them, the world would be, and would increasingly become, a much poorer place.", "hypothesis": "There are some species in zoos which can no longer be found in the wild.", "gold_label": "entailment"}
{"uid": "id_657", "premise": "Why zoos are good Scientist David Hone makes the case for zoos In my view, it is perfectly possible for many species of animals living in zoos or wildlife parks to have a quality of life as high as, or higher than, in the wild. Animals in good zoos get a varied and high-quality diet with all the supplements required, and any illnesses they might have will be treated. Their movement might be somewhat restricted, but they have a safe environment in which to live, and they are spared bullying and social ostracism by others of their kind. They do not suffer from the threat or stress of predators, or the irritation and pain of parasites or injuries. The average captive animal will have a greater life expectancy compared with its wild counterpart, and will not die of drought, of starvation or in the jaws of a predator. A lot of very nasty things happen to truly 'wild' animals that simply don't happen in good zoos, and to view a life that is 'free' as one that is automatically 'good' is, I think, an error. Furthermore, zoos serve several key purposes. Firstly, zoos aid conservation. Colossal numbers of species are becoming extinct across the world, and many more are increasingly threatened and therefore risk extinction. Moreover, some of these collapses have been sudden, dramatic and unexpected, or were simply discovered very late in the day. A species protected in captivity can be bred up to provide a reservoir population against a population crash or extinction in the wild. A good number of species only exist in captivity, with many of these living in zoos. Still more only exist in the wild because they have been reintroduced from zoos, or have wild populations that have been boosted by captive bred animals. Without these efforts there would be fewer species alive today. Although reintroduction successes are few and far between, the numbers are increasing, and the very fact that species have been saved or reintroduced as a result of captive breeding proves the value of such initiatives. Zoos also provide education. Many children and adults, especially those in cities, will never see a wild animal beyond a fox or pigeon. While it is true that television documentaries are becoming ever more detailed and impressive, and many natural history specimens are on display in museums, there really is nothing to compare with seeing a living creature in the flesh, hearing it, smelling it, watching what it does and having the time to absorb details. That alone will bring a greater understanding and perspective to many, and hopefully give them a greater appreciation for wildlife, conservation efforts and how they can contribute. In addition to this, there is also the education that can take place in zoos through signs, talks and presentations which directly communicate information to visitors about the animals they are seeing and their place in the world. This was an area where zoos used to be lacking, but they are now increasingly sophisticated in their communication and outreach work. Many zoos also work directly to educate conservation workers in other countries, or send their animal keepers abroad to contribute their knowledge and skills to those working in zoos and reserves, thereby helping to improve conditions and reintroductions all over the world. Zoos also play a key role in research. If we are to save wild species and restore and repair ecosystems we need to know about how key species live, act and react. Being able to undertake research on animals in zoos where there is less risk and fewer variables means real changes can be effected on wild populations. Finding out about, for example, the oestrus cycle of an animal or its breeding rate helps us manage wild populations. Procedures such as capturing and moving at-risk or dangerous individuals are bolstered by knowledge gained in zoos about doses for anaesthetics, and by experience in handling arid transporting animals. This can make a real difference to conservation efforts and to the reduction of human-animal conflicts, and can provide a knowledge base for helping with the increasing threats of habitat destruction and other problems. In conclusion, considering the many ongoing global threats to the environment, it is hard for me to see zoos as anything other than essential to the long-term survival of numerous species. They are vital not just in terms of protecting animals, but as a means of learning about them to aid those still in the wild, as well as educating and informing the general population about these animals and their world so that they can assist or at least accept the need to be more environmentally conscious. Without them, the world would be, and would increasingly become, a much poorer place.", "hypothesis": "An animal is likely to live longer in a zoo than in the wild.", "gold_label": "entailment"}
{"uid": "id_658", "premise": "Why zoos are good Scientist David Hone makes the case for zoos In my view, it is perfectly possible for many species of animals living in zoos or wildlife parks to have a quality of life as high as, or higher than, in the wild. Animals in good zoos get a varied and high-quality diet with all the supplements required, and any illnesses they might have will be treated. Their movement might be somewhat restricted, but they have a safe environment in which to live, and they are spared bullying and social ostracism by others of their kind. They do not suffer from the threat or stress of predators, or the irritation and pain of parasites or injuries. The average captive animal will have a greater life expectancy compared with its wild counterpart, and will not die of drought, of starvation or in the jaws of a predator. A lot of very nasty things happen to truly 'wild' animals that simply don't happen in good zoos, and to view a life that is 'free' as one that is automatically 'good' is, I think, an error. Furthermore, zoos serve several key purposes. Firstly, zoos aid conservation. Colossal numbers of species are becoming extinct across the world, and many more are increasingly threatened and therefore risk extinction. Moreover, some of these collapses have been sudden, dramatic and unexpected, or were simply discovered very late in the day. A species protected in captivity can be bred up to provide a reservoir population against a population crash or extinction in the wild. A good number of species only exist in captivity, with many of these living in zoos. Still more only exist in the wild because they have been reintroduced from zoos, or have wild populations that have been boosted by captive bred animals. Without these efforts there would be fewer species alive today. Although reintroduction successes are few and far between, the numbers are increasing, and the very fact that species have been saved or reintroduced as a result of captive breeding proves the value of such initiatives. Zoos also provide education. Many children and adults, especially those in cities, will never see a wild animal beyond a fox or pigeon. While it is true that television documentaries are becoming ever more detailed and impressive, and many natural history specimens are on display in museums, there really is nothing to compare with seeing a living creature in the flesh, hearing it, smelling it, watching what it does and having the time to absorb details. That alone will bring a greater understanding and perspective to many, and hopefully give them a greater appreciation for wildlife, conservation efforts and how they can contribute. In addition to this, there is also the education that can take place in zoos through signs, talks and presentations which directly communicate information to visitors about the animals they are seeing and their place in the world. This was an area where zoos used to be lacking, but they are now increasingly sophisticated in their communication and outreach work. Many zoos also work directly to educate conservation workers in other countries, or send their animal keepers abroad to contribute their knowledge and skills to those working in zoos and reserves, thereby helping to improve conditions and reintroductions all over the world. Zoos also play a key role in research. If we are to save wild species and restore and repair ecosystems we need to know about how key species live, act and react. Being able to undertake research on animals in zoos where there is less risk and fewer variables means real changes can be effected on wild populations. Finding out about, for example, the oestrus cycle of an animal or its breeding rate helps us manage wild populations. Procedures such as capturing and moving at-risk or dangerous individuals are bolstered by knowledge gained in zoos about doses for anaesthetics, and by experience in handling arid transporting animals. This can make a real difference to conservation efforts and to the reduction of human-animal conflicts, and can provide a knowledge base for helping with the increasing threats of habitat destruction and other problems. In conclusion, considering the many ongoing global threats to the environment, it is hard for me to see zoos as anything other than essential to the long-term survival of numerous species. They are vital not just in terms of protecting animals, but as a means of learning about them to aid those still in the wild, as well as educating and informing the general population about these animals and their world so that they can assist or at least accept the need to be more environmentally conscious. Without them, the world would be, and would increasingly become, a much poorer place.", "hypothesis": "Zoos have always excelled at transmitting information about animals to the public.", "gold_label": "contradiction"}
{"uid": "id_659", "premise": "Why zoos are good Scientist David Hone makes the case for zoos In my view, it is perfectly possible for many species of animals living in zoos or wildlife parks to have a quality of life as high as, or higher than, in the wild. Animals in good zoos get a varied and high-quality diet with all the supplements required, and any illnesses they might have will be treated. Their movement might be somewhat restricted, but they have a safe environment in which to live, and they are spared bullying and social ostracism by others of their kind. They do not suffer from the threat or stress of predators, or the irritation and pain of parasites or injuries. The average captive animal will have a greater life expectancy compared with its wild counterpart, and will not die of drought, of starvation or in the jaws of a predator. A lot of very nasty things happen to truly 'wild' animals that simply don't happen in good zoos, and to view a life that is 'free' as one that is automatically 'good' is, I think, an error. Furthermore, zoos serve several key purposes. Firstly, zoos aid conservation. Colossal numbers of species are becoming extinct across the world, and many more are increasingly threatened and therefore risk extinction. Moreover, some of these collapses have been sudden, dramatic and unexpected, or were simply discovered very late in the day. A species protected in captivity can be bred up to provide a reservoir population against a population crash or extinction in the wild. A good number of species only exist in captivity, with many of these living in zoos. Still more only exist in the wild because they have been reintroduced from zoos, or have wild populations that have been boosted by captive bred animals. Without these efforts there would be fewer species alive today. Although reintroduction successes are few and far between, the numbers are increasing, and the very fact that species have been saved or reintroduced as a result of captive breeding proves the value of such initiatives. Zoos also provide education. Many children and adults, especially those in cities, will never see a wild animal beyond a fox or pigeon. While it is true that television documentaries are becoming ever more detailed and impressive, and many natural history specimens are on display in museums, there really is nothing to compare with seeing a living creature in the flesh, hearing it, smelling it, watching what it does and having the time to absorb details. That alone will bring a greater understanding and perspective to many, and hopefully give them a greater appreciation for wildlife, conservation efforts and how they can contribute. In addition to this, there is also the education that can take place in zoos through signs, talks and presentations which directly communicate information to visitors about the animals they are seeing and their place in the world. This was an area where zoos used to be lacking, but they are now increasingly sophisticated in their communication and outreach work. Many zoos also work directly to educate conservation workers in other countries, or send their animal keepers abroad to contribute their knowledge and skills to those working in zoos and reserves, thereby helping to improve conditions and reintroductions all over the world. Zoos also play a key role in research. If we are to save wild species and restore and repair ecosystems we need to know about how key species live, act and react. Being able to undertake research on animals in zoos where there is less risk and fewer variables means real changes can be effected on wild populations. Finding out about, for example, the oestrus cycle of an animal or its breeding rate helps us manage wild populations. Procedures such as capturing and moving at-risk or dangerous individuals are bolstered by knowledge gained in zoos about doses for anaesthetics, and by experience in handling arid transporting animals. This can make a real difference to conservation efforts and to the reduction of human-animal conflicts, and can provide a knowledge base for helping with the increasing threats of habitat destruction and other problems. In conclusion, considering the many ongoing global threats to the environment, it is hard for me to see zoos as anything other than essential to the long-term survival of numerous species. They are vital not just in terms of protecting animals, but as a means of learning about them to aid those still in the wild, as well as educating and informing the general population about these animals and their world so that they can assist or at least accept the need to be more environmentally conscious. Without them, the world would be, and would increasingly become, a much poorer place.", "hypothesis": "Studying animals in zoos is less stressful for the animals than studying them in the wild.", "gold_label": "neutral"}
{"uid": "id_660", "premise": "Wildlife expert Dr Ellen Boyle spoke at this years Wildlife Conservation Conference about the lack of a strategy to prevent the immment extinction of a number of primate species across Asia. Her talk focused on the dangers of hunters and the clearing of tropical ramforests across the continent. Several species of Asian monkey, some only recently discovered, are facing these dual threats to their natural habitats. Dr Boyle differentiated the most at-risk primates as critically endangered, but the talk stressed that other species were also living under constant threat. Dr Boyles scientific paper Several species of Asian monkey, some only recently discovered, are facing these dual threats to ther natural habitats. Dr Boyle differentiated the most at-risk primates as critically endangered, but the talk stressed that other species were also living under constant threat. Dr Boyles scientific paper presented compelling evidence of the need to halt deforestation, but in some developing Asian economies, where wood 1s collected for fuel and for sale and land 1s cleared for farming, human Interests currently take precedence over the fate of the regions lower- order primates.", "hypothesis": "The deforestation of ramforests is the only threat to Asian primates.", "gold_label": "contradiction"}
{"uid": "id_661", "premise": "Wildlife expert Dr Ellen Boyle spoke at this years Wildlife Conservation Conference about the lack of a strategy to prevent the immment extinction of a number of primate species across Asia. Her talk focused on the dangers of hunters and the clearing of tropical ramforests across the continent. Several species of Asian monkey, some only recently discovered, are facing these dual threats to their natural habitats. Dr Boyle differentiated the most at-risk primates as critically endangered, but the talk stressed that other species were also living under constant threat. Dr Boyles scientific paper Several species of Asian monkey, some only recently discovered, are facing these dual threats to ther natural habitats. Dr Boyle differentiated the most at-risk primates as critically endangered, but the talk stressed that other species were also living under constant threat. Dr Boyles scientific paper presented compelling evidence of the need to halt deforestation, but in some developing Asian economies, where wood 1s collected for fuel and for sale and land 1s cleared for farming, human Interests currently take precedence over the fate of the regions lower- order primates.", "hypothesis": "Dr Boyle suggests that all Asian countries prioritise economs over the survival of monkeys.", "gold_label": "contradiction"}
{"uid": "id_662", "premise": "Wildlife expert Dr Ellen Boyle spoke at this years Wildlife Conservation Conference about the lack of a strategy to prevent the immment extinction of a number of primate species across Asia. Her talk focused on the dangers of hunters and the clearing of tropical ramforests across the continent. Several species of Asian monkey, some only recently discovered, are facing these dual threats to their natural habitats. Dr Boyle differentiated the most at-risk primates as critically endangered, but the talk stressed that other species were also living under constant threat. Dr Boyles scientific paper Several species of Asian monkey, some only recently discovered, are facing these dual threats to ther natural habitats. Dr Boyle differentiated the most at-risk primates as critically endangered, but the talk stressed that other species were also living under constant threat. Dr Boyles scientific paper presented compelling evidence of the need to halt deforestation, but in some developing Asian economies, where wood 1s collected for fuel and for sale and land 1s cleared for farming, human Interests currently take precedence over the fate of the regions lower- order primates.", "hypothesis": "The passage gives three reasons for the destruction of tropical ramforests.", "gold_label": "entailment"}
{"uid": "id_663", "premise": "Wildlife expert Dr Ellen Boyle spoke at this years Wildlife Conservation Conference about the lack of a strategy to prevent the immment extinction of a number of primate species across Asia. Her talk focused on the dangers of hunters and the clearing of tropical ramforests across the continent. Several species of Asian monkey, some only recently discovered, are facing these dual threats to their natural habitats. Dr Boyle differentiated the most at-risk primates as critically endangered, but the talk stressed that other species were also living under constant threat. Dr Boyles scientific paper Several species of Asian monkey, some only recently discovered, are facing these dual threats to ther natural habitats. Dr Boyle differentiated the most at-risk primates as critically endangered, but the talk stressed that other species were also living under constant threat. Dr Boyles scientific paper presented compelling evidence of the need to halt deforestation, but in some developing Asian economies, where wood 1s collected for fuel and for sale and land 1s cleared for farming, human Interests currently take precedence over the fate of the regions lower- order primates.", "hypothesis": "Dr Boyles talk at the Wildlife Conservation Conference explained the strategy for protecting Asian primates.", "gold_label": "contradiction"}
{"uid": "id_664", "premise": "Wildlife expert Dr Ellen Boyle spoke at this years Wildlife Conservation Conference about the lack of a strategy to prevent the immment extinction of a number of primate species across Asia. Her talk focused on the dangers of hunters and the clearing of tropical ramforests across the continent. Several species of Asian monkey, some only recently discovered, are facing these dual threats to their natural habitats. Dr Boyle differentiated the most at-risk primates as critically endangered, but the talk stressed that other species were also living under constant threat. Dr Boyles scientific paper Several species of Asian monkey, some only recently discovered, are facing these dual threats to ther natural habitats. Dr Boyle differentiated the most at-risk primates as critically endangered, but the talk stressed that other species were also living under constant threat. Dr Boyles scientific paper presented compelling evidence of the need to halt deforestation, but in some developing Asian economies, where wood 1s collected for fuel and for sale and land 1s cleared for farming, human Interests currently take precedence over the fate of the regions lower- order primates.", "hypothesis": "All Asian primates are threatened by extinction.", "gold_label": "contradiction"}
{"uid": "id_665", "premise": "Will the electric vehicle known as the Segway alter the ways that individuals get around? Dean Kamer, the inventor of the Segway, believes that this revolutionary vehicle will someday substitute for the bicycles and automobiles that now crowd our cities. When he introduced the Segway in 2001, he believed it would change our lives. Although the Segway uses up-to-the-minute technology, it looks very ordinary. The metal framework of the Segway consists of a platform where an individual stands. Attached to the front of the platform is a tall post with handles for the driver to hold. On each side of the platform is a wide, rubber wheel. Except for these two wheels, there are no mechanical parts on the Segway. It has no engine, no brakes, no pedal power, no gears, and no steering wheel. Instead it uses a computer system that imitates the ability of humans to keep their balance. This system seems to move to the driver's thoughts. For example, when the driver thinks \"Go forward\", the Segway moves forwards, and when the driver thinks, \"Stop\", it stops. The Segway is not really responding to the driver's thoughts, but to the tiny changes in balance that the driver makes as he prepares his body to move forward or to stop. For example, when the driver thinks about moving forward, he actually leans slightly forward, and when he thinks of stopping or slowing, the driver leans slightly back. The Segway is powered by batteries that allow it to travel about 17miles on one battery charge. It is designed for short-range, low-speed operation. It has three speed settings. The slowest is the setting for learning, with speeds of up to miles per hour. Next is the sidewalk setting, with speeds of up to 9 miles , per hour. The highest setting allows the driver to travel up to 12.5 miles per hour in open, flat areas. At all three speed settings, the Segway can go wherever a person can walk, both indoors and outdoors. Workers who must walk a lot in their jobs might be the primary users of Segways. For example, police officers could drive Segways to patrol city streets, and mail carriers could drive from house to house to deliver letters and packages. Farmers could quickly inspect distant fields and bams, and rangers, or parks. Security guards could protect neighborhoods or large buildings. Any task requiring a lot of walking could be made easier. In cities, shoppers could leave their cars at home and ride Segway from store to store. Also, people who cannot comfortably walk due to age, illness, or injury could minimize their walking but still be able to go many places on a Segway. Why is it, then, that our job sites, parks, and shopping centers have not been subsequently filled with Segways since they were introduced in 2001? Why hasn't the expected revolution taken place? Studies have shown that Segways can help workers get more done in a shorter time. This saves money. Engineers admire Segways as a technological marvel. Business, government agencies, and individuals, however, have been unwilling to accept the Segway. Ves, there have been some successes. In a few cities, for example, mail carriers drive Segway on their routes, and police officers patrol on Segways. San Francisco, California, and Florence, Italy, are among several cities in the world that offer tours on Segways for a small fee. Occasionally you will see golfers riding Segways around golf courses. Throughout the world more than 150 security agencies use Segways, and China has recently entered the overseas market. These examples are encouraging, but can hardly be called a revolution. The primary reason seems to be that people have an inherent fear of doing something new. They fear others will laugh at them for buying a \"toy\". They fear losing control of the vehicle. They fear being injured. They fear not knowing the rules for using a Segway. They fear making people angry if they ride on the sidewalk. All these fears and others have kept sales low. The inventor explained why people have been slow to accept the Segway. He said, \"We didn't realize that although technology moves very quickly, people's mind-set changes very slowly. \" Perhaps a hundred years from now millions of people around the world will be riding Segways.", "hypothesis": "The driver can alter the direction of the Segway by leaning to the left or right", "gold_label": "contradiction"}
{"uid": "id_666", "premise": "Will the electric vehicle known as the Segway alter the ways that individuals get around? Dean Kamer, the inventor of the Segway, believes that this revolutionary vehicle will someday substitute for the bicycles and automobiles that now crowd our cities. When he introduced the Segway in 2001, he believed it would change our lives. Although the Segway uses up-to-the-minute technology, it looks very ordinary. The metal framework of the Segway consists of a platform where an individual stands. Attached to the front of the platform is a tall post with handles for the driver to hold. On each side of the platform is a wide, rubber wheel. Except for these two wheels, there are no mechanical parts on the Segway. It has no engine, no brakes, no pedal power, no gears, and no steering wheel. Instead it uses a computer system that imitates the ability of humans to keep their balance. This system seems to move to the driver's thoughts. For example, when the driver thinks \"Go forward\", the Segway moves forwards, and when the driver thinks, \"Stop\", it stops. The Segway is not really responding to the driver's thoughts, but to the tiny changes in balance that the driver makes as he prepares his body to move forward or to stop. For example, when the driver thinks about moving forward, he actually leans slightly forward, and when he thinks of stopping or slowing, the driver leans slightly back. The Segway is powered by batteries that allow it to travel about 17miles on one battery charge. It is designed for short-range, low-speed operation. It has three speed settings. The slowest is the setting for learning, with speeds of up to miles per hour. Next is the sidewalk setting, with speeds of up to 9 miles , per hour. The highest setting allows the driver to travel up to 12.5 miles per hour in open, flat areas. At all three speed settings, the Segway can go wherever a person can walk, both indoors and outdoors. Workers who must walk a lot in their jobs might be the primary users of Segways. For example, police officers could drive Segways to patrol city streets, and mail carriers could drive from house to house to deliver letters and packages. Farmers could quickly inspect distant fields and bams, and rangers, or parks. Security guards could protect neighborhoods or large buildings. Any task requiring a lot of walking could be made easier. In cities, shoppers could leave their cars at home and ride Segway from store to store. Also, people who cannot comfortably walk due to age, illness, or injury could minimize their walking but still be able to go many places on a Segway. Why is it, then, that our job sites, parks, and shopping centers have not been subsequently filled with Segways since they were introduced in 2001? Why hasn't the expected revolution taken place? Studies have shown that Segways can help workers get more done in a shorter time. This saves money. Engineers admire Segways as a technological marvel. Business, government agencies, and individuals, however, have been unwilling to accept the Segway. Ves, there have been some successes. In a few cities, for example, mail carriers drive Segway on their routes, and police officers patrol on Segways. San Francisco, California, and Florence, Italy, are among several cities in the world that offer tours on Segways for a small fee. Occasionally you will see golfers riding Segways around golf courses. Throughout the world more than 150 security agencies use Segways, and China has recently entered the overseas market. These examples are encouraging, but can hardly be called a revolution. The primary reason seems to be that people have an inherent fear of doing something new. They fear others will laugh at them for buying a \"toy\". They fear losing control of the vehicle. They fear being injured. They fear not knowing the rules for using a Segway. They fear making people angry if they ride on the sidewalk. All these fears and others have kept sales low. The inventor explained why people have been slow to accept the Segway. He said, \"We didn't realize that although technology moves very quickly, people's mind-set changes very slowly. \" Perhaps a hundred years from now millions of people around the world will be riding Segways.", "hypothesis": "The Segway's framework consists of a platform and a post with handles", "gold_label": "entailment"}
{"uid": "id_667", "premise": "Will the electric vehicle known as the Segway alter the ways that individuals get around? Dean Kamer, the inventor of the Segway, believes that this revolutionary vehicle will someday substitute for the bicycles and automobiles that now crowd our cities. When he introduced the Segway in 2001, he believed it would change our lives. Although the Segway uses up-to-the-minute technology, it looks very ordinary. The metal framework of the Segway consists of a platform where an individual stands. Attached to the front of the platform is a tall post with handles for the driver to hold. On each side of the platform is a wide, rubber wheel. Except for these two wheels, there are no mechanical parts on the Segway. It has no engine, no brakes, no pedal power, no gears, and no steering wheel. Instead it uses a computer system that imitates the ability of humans to keep their balance. This system seems to move to the driver's thoughts. For example, when the driver thinks \"Go forward\", the Segway moves forwards, and when the driver thinks, \"Stop\", it stops. The Segway is not really responding to the driver's thoughts, but to the tiny changes in balance that the driver makes as he prepares his body to move forward or to stop. For example, when the driver thinks about moving forward, he actually leans slightly forward, and when he thinks of stopping or slowing, the driver leans slightly back. The Segway is powered by batteries that allow it to travel about 17miles on one battery charge. It is designed for short-range, low-speed operation. It has three speed settings. The slowest is the setting for learning, with speeds of up to miles per hour. Next is the sidewalk setting, with speeds of up to 9 miles , per hour. The highest setting allows the driver to travel up to 12.5 miles per hour in open, flat areas. At all three speed settings, the Segway can go wherever a person can walk, both indoors and outdoors. Workers who must walk a lot in their jobs might be the primary users of Segways. For example, police officers could drive Segways to patrol city streets, and mail carriers could drive from house to house to deliver letters and packages. Farmers could quickly inspect distant fields and bams, and rangers, or parks. Security guards could protect neighborhoods or large buildings. Any task requiring a lot of walking could be made easier. In cities, shoppers could leave their cars at home and ride Segway from store to store. Also, people who cannot comfortably walk due to age, illness, or injury could minimize their walking but still be able to go many places on a Segway. Why is it, then, that our job sites, parks, and shopping centers have not been subsequently filled with Segways since they were introduced in 2001? Why hasn't the expected revolution taken place? Studies have shown that Segways can help workers get more done in a shorter time. This saves money. Engineers admire Segways as a technological marvel. Business, government agencies, and individuals, however, have been unwilling to accept the Segway. Ves, there have been some successes. In a few cities, for example, mail carriers drive Segway on their routes, and police officers patrol on Segways. San Francisco, California, and Florence, Italy, are among several cities in the world that offer tours on Segways for a small fee. Occasionally you will see golfers riding Segways around golf courses. Throughout the world more than 150 security agencies use Segways, and China has recently entered the overseas market. These examples are encouraging, but can hardly be called a revolution. The primary reason seems to be that people have an inherent fear of doing something new. They fear others will laugh at them for buying a \"toy\". They fear losing control of the vehicle. They fear being injured. They fear not knowing the rules for using a Segway. They fear making people angry if they ride on the sidewalk. All these fears and others have kept sales low. The inventor explained why people have been slow to accept the Segway. He said, \"We didn't realize that although technology moves very quickly, people's mind-set changes very slowly. \" Perhaps a hundred years from now millions of people around the world will be riding Segways.", "hypothesis": "The Segway was primarily designed for student to make their travel much more comfortable", "gold_label": "neutral"}
{"uid": "id_668", "premise": "William Gilbert and Magnetism 16th and 17th centuries saw two great pioneers of modem science: Galileo and Gilbert. The impact of their findings is eminent. Gilbert was the first modem scientist, also the accredited father of the science of electricity and magnetism, an Englishman of learning and a physician at the court of Elizabeth. Prior to him, all that was known of electricity and magnetism was what the ancients knew, nothing more than that the: lodestone possessed magnetic properties and that amber and jet, when rubbed, would attract bits of paper or other substances of small specific gravity. However, he is less well-known than he deserves. Gilberts birth predated Galileo. Born in an eminent local family in Colchester county in the UK, on May 24,1544, he went to grammar school, and then studied medicine at St. Johns College, Cambridge, graduating in 1573. Later he traveled in the continent and eventually settled down in London. He was a very successful and eminent doctor. All this culminated in his election to the president of the Royal Science Society. He was also appointed the personal physician to the Queen (Elizabeth I) , and later knighted by the Queen. He faithfully served her until her death. However, he didnt outlive the Queen for long and died on December 10, 1603, only a few months after his appointment as a personal physician to King James. Gilbert was first interested in chemistry but later changed his focus due to the large portion of the mysticism of alchemy involved (such as the transmutation of metal). He gradually developed his interest in physics after the great minds of the ancient, particularly about the knowledge the ancient Greeks had about lodestones, strange minerals with the power to attract iron. In the meantime, Britain became a major seafaring nation in 1588 when the Spanish Armada was defeated, opening the way to the British settlement of America. British ships depended on the magnetic: compass, yet no one understood why it worked. Did the pole star attract it, as Columbus once speculated; or was there a magnetic mountain at the pole, as described in Odyssey which ships would never approach because the sailors thought its pull would yank out all their iron nails and fittings? For nearly 20 years William Gilbert conducted ingenious experiments to understand magnetism. His works include On the Magnet and Magnetic Bodies, Great Magnet of the Earth. Gilberts discovery was so important to modem physics. He investigated the nature of magnetism and electricity. He even coined the word electric. Though the early beliefs of magnetism were also largely entangled with superstitions such as that rubbing garlic on lodestone can neutralize its magnetism, one example being that sailors even believed the smell of garlic would even interfere with the action of the compass, which is why helmsmen were forbidden to eat it near a ships compass. Gilbert also found that metals can be magnetized by rubbing materials such as fur, plastic or the like on them. He named the ends of a magnet north pole and south pole. The magnetic poles can attract or repel, depending on polarity. In addition, however, ordinary iron is always attracted to a magnet. Though he started to study the relationship between magnetism and electricity, sadly he didnt complete it. His research of static electricity using amber and jet only demonstrated that objects with electrical charges can work like magnets attracting small pieces of paper and stuff. It is a French guy named du Fay that discovered that there are actually two electrical charges, positive and negative. He also questioned the traditional astronomical beliefs. Though a Copernican, he didnt express in his quintessential beliefs whether the earth is at the center of the universe or in orbit around the sun. However, he believed that stars are not equidistant from the earth, but have their own earth-like planets orbiting around them. The earth is itself like a giant magnet, which is also why compasses always point north. They spin on an axis that is aligned with the earths polarity. He even likened the polarity of the magnet to the polarity of the earth and built an entire magnetic philosophy on this analogy. In his explanation, magnetism was the soul of the earth. Thus a perfectly spherical lodestone, when aligned with the earths poles, would wobble all by itself in 24 hours. Further, he also believed that suns and other stars wobble just like the earth does around a crystal core, and speculated that the moon might also be a magnet caused to orbit by its magnetic attraction to the earth. This was perhaps the first proposal that a force might cause a heavenly orbit. His research method was revolutionary in that he used experiments rather than pure logic and reasoning like the ancient Greek philosophers did. It was a new attitude toward the scientific investigation. Until then, scientific experiments were not in fashion. It was because of this scientific attitude, together with his contribution to our knowledge of magnetism, that a unit of magnetomotive force, also known as magnetic potential, was named Gilbert in his honor. His approach of careful observation and experimentation rather than the authoritative opinion or deductive philosophy of others had laid the very foundation for modem science.", "hypothesis": "He was famous as a doctor before he was employed by the Queen", "gold_label": "entailment"}
{"uid": "id_669", "premise": "William Gilbert and Magnetism 16th and 17th centuries saw two great pioneers of modem science: Galileo and Gilbert. The impact of their findings is eminent. Gilbert was the first modem scientist, also the accredited father of the science of electricity and magnetism, an Englishman of learning and a physician at the court of Elizabeth. Prior to him, all that was known of electricity and magnetism was what the ancients knew, nothing more than that the: lodestone possessed magnetic properties and that amber and jet, when rubbed, would attract bits of paper or other substances of small specific gravity. However, he is less well-known than he deserves. Gilberts birth predated Galileo. Born in an eminent local family in Colchester county in the UK, on May 24,1544, he went to grammar school, and then studied medicine at St. Johns College, Cambridge, graduating in 1573. Later he traveled in the continent and eventually settled down in London. He was a very successful and eminent doctor. All this culminated in his election to the president of the Royal Science Society. He was also appointed the personal physician to the Queen (Elizabeth I) , and later knighted by the Queen. He faithfully served her until her death. However, he didnt outlive the Queen for long and died on December 10, 1603, only a few months after his appointment as a personal physician to King James. Gilbert was first interested in chemistry but later changed his focus due to the large portion of the mysticism of alchemy involved (such as the transmutation of metal). He gradually developed his interest in physics after the great minds of the ancient, particularly about the knowledge the ancient Greeks had about lodestones, strange minerals with the power to attract iron. In the meantime, Britain became a major seafaring nation in 1588 when the Spanish Armada was defeated, opening the way to the British settlement of America. British ships depended on the magnetic: compass, yet no one understood why it worked. Did the pole star attract it, as Columbus once speculated; or was there a magnetic mountain at the pole, as described in Odyssey which ships would never approach because the sailors thought its pull would yank out all their iron nails and fittings? For nearly 20 years William Gilbert conducted ingenious experiments to understand magnetism. His works include On the Magnet and Magnetic Bodies, Great Magnet of the Earth. Gilberts discovery was so important to modem physics. He investigated the nature of magnetism and electricity. He even coined the word electric. Though the early beliefs of magnetism were also largely entangled with superstitions such as that rubbing garlic on lodestone can neutralize its magnetism, one example being that sailors even believed the smell of garlic would even interfere with the action of the compass, which is why helmsmen were forbidden to eat it near a ships compass. Gilbert also found that metals can be magnetized by rubbing materials such as fur, plastic or the like on them. He named the ends of a magnet north pole and south pole. The magnetic poles can attract or repel, depending on polarity. In addition, however, ordinary iron is always attracted to a magnet. Though he started to study the relationship between magnetism and electricity, sadly he didnt complete it. His research of static electricity using amber and jet only demonstrated that objects with electrical charges can work like magnets attracting small pieces of paper and stuff. It is a French guy named du Fay that discovered that there are actually two electrical charges, positive and negative. He also questioned the traditional astronomical beliefs. Though a Copernican, he didnt express in his quintessential beliefs whether the earth is at the center of the universe or in orbit around the sun. However, he believed that stars are not equidistant from the earth, but have their own earth-like planets orbiting around them. The earth is itself like a giant magnet, which is also why compasses always point north. They spin on an axis that is aligned with the earths polarity. He even likened the polarity of the magnet to the polarity of the earth and built an entire magnetic philosophy on this analogy. In his explanation, magnetism was the soul of the earth. Thus a perfectly spherical lodestone, when aligned with the earths poles, would wobble all by itself in 24 hours. Further, he also believed that suns and other stars wobble just like the earth does around a crystal core, and speculated that the moon might also be a magnet caused to orbit by its magnetic attraction to the earth. This was perhaps the first proposal that a force might cause a heavenly orbit. His research method was revolutionary in that he used experiments rather than pure logic and reasoning like the ancient Greek philosophers did. It was a new attitude toward the scientific investigation. Until then, scientific experiments were not in fashion. It was because of this scientific attitude, together with his contribution to our knowledge of magnetism, that a unit of magnetomotive force, also known as magnetic potential, was named Gilbert in his honor. His approach of careful observation and experimentation rather than the authoritative opinion or deductive philosophy of others had laid the very foundation for modem science.", "hypothesis": "He lost faith in the medical theories of his time.", "gold_label": "neutral"}
{"uid": "id_670", "premise": "William Gilbert and Magnetism 16th and 17th centuries saw two great pioneers of modem science: Galileo and Gilbert. The impact of their findings is eminent. Gilbert was the first modem scientist, also the accredited father of the science of electricity and magnetism, an Englishman of learning and a physician at the court of Elizabeth. Prior to him, all that was known of electricity and magnetism was what the ancients knew, nothing more than that the: lodestone possessed magnetic properties and that amber and jet, when rubbed, would attract bits of paper or other substances of small specific gravity. However, he is less well-known than he deserves. Gilberts birth predated Galileo. Born in an eminent local family in Colchester county in the UK, on May 24,1544, he went to grammar school, and then studied medicine at St. Johns College, Cambridge, graduating in 1573. Later he traveled in the continent and eventually settled down in London. He was a very successful and eminent doctor. All this culminated in his election to the president of the Royal Science Society. He was also appointed the personal physician to the Queen (Elizabeth I) , and later knighted by the Queen. He faithfully served her until her death. However, he didnt outlive the Queen for long and died on December 10, 1603, only a few months after his appointment as a personal physician to King James. Gilbert was first interested in chemistry but later changed his focus due to the large portion of the mysticism of alchemy involved (such as the transmutation of metal). He gradually developed his interest in physics after the great minds of the ancient, particularly about the knowledge the ancient Greeks had about lodestones, strange minerals with the power to attract iron. In the meantime, Britain became a major seafaring nation in 1588 when the Spanish Armada was defeated, opening the way to the British settlement of America. British ships depended on the magnetic: compass, yet no one understood why it worked. Did the pole star attract it, as Columbus once speculated; or was there a magnetic mountain at the pole, as described in Odyssey which ships would never approach because the sailors thought its pull would yank out all their iron nails and fittings? For nearly 20 years William Gilbert conducted ingenious experiments to understand magnetism. His works include On the Magnet and Magnetic Bodies, Great Magnet of the Earth. Gilberts discovery was so important to modem physics. He investigated the nature of magnetism and electricity. He even coined the word electric. Though the early beliefs of magnetism were also largely entangled with superstitions such as that rubbing garlic on lodestone can neutralize its magnetism, one example being that sailors even believed the smell of garlic would even interfere with the action of the compass, which is why helmsmen were forbidden to eat it near a ships compass. Gilbert also found that metals can be magnetized by rubbing materials such as fur, plastic or the like on them. He named the ends of a magnet north pole and south pole. The magnetic poles can attract or repel, depending on polarity. In addition, however, ordinary iron is always attracted to a magnet. Though he started to study the relationship between magnetism and electricity, sadly he didnt complete it. His research of static electricity using amber and jet only demonstrated that objects with electrical charges can work like magnets attracting small pieces of paper and stuff. It is a French guy named du Fay that discovered that there are actually two electrical charges, positive and negative. He also questioned the traditional astronomical beliefs. Though a Copernican, he didnt express in his quintessential beliefs whether the earth is at the center of the universe or in orbit around the sun. However, he believed that stars are not equidistant from the earth, but have their own earth-like planets orbiting around them. The earth is itself like a giant magnet, which is also why compasses always point north. They spin on an axis that is aligned with the earths polarity. He even likened the polarity of the magnet to the polarity of the earth and built an entire magnetic philosophy on this analogy. In his explanation, magnetism was the soul of the earth. Thus a perfectly spherical lodestone, when aligned with the earths poles, would wobble all by itself in 24 hours. Further, he also believed that suns and other stars wobble just like the earth does around a crystal core, and speculated that the moon might also be a magnet caused to orbit by its magnetic attraction to the earth. This was perhaps the first proposal that a force might cause a heavenly orbit. His research method was revolutionary in that he used experiments rather than pure logic and reasoning like the ancient Greek philosophers did. It was a new attitude toward the scientific investigation. Until then, scientific experiments were not in fashion. It was because of this scientific attitude, together with his contribution to our knowledge of magnetism, that a unit of magnetomotive force, also known as magnetic potential, was named Gilbert in his honor. His approach of careful observation and experimentation rather than the authoritative opinion or deductive philosophy of others had laid the very foundation for modem science.", "hypothesis": "He is less famous than he should be.", "gold_label": "entailment"}
{"uid": "id_671", "premise": "William Henry Perkin The man who invented synthetic dyes William Henry Perkin was born on March 12,1838, in London, England. As a boy, Perkins curiosity prompted early interests in the arts, sciences, photography, and engineering. But it was a chance stumbling upon a run-down, yet functional, laboratory in his late grandfathers home that solidified the young mans enthusiasm for chemistry. As a student at the City of London School, Perkin became immersed in the study of chemistry. His talent and devotion to the subject were perceived by his teacher, Thomas Hall, who encouraged him to attend a series of lectures given by the eminent scientist Michael Faraday at the Royal Institution. Those speeches fired the young chemists enthusiasm further, and he later went on to attend the Royal College of Chemistry, which he succeeded in entering in 1853, at the age of 15. At the time of Perkins enrolment, the Royal College of Chemistry was headed by the noted German chemist August Wilhelm Hofmann. Perkins scientific gifts soon caught Hofmanns attention and, within two years, he became Hofmanns youngest assistant. Not long after that, Perkin made the scientific breakthrough that would bring him both fame and fortune. At the time, quinine was the only viable medical treatment for malaria. The drug is derived from the bark of the cinchona tree, native to South America, and by 1856 demand for the drug was surpassing the available supply. Thus, when Hofmann made some passing comments about the desirability of a synthetic substitute for quinine, it was unsurprising that his star pupil was moved to take up the challenge. During his vacation in 1856, Perkin spent his time in the laboratory on the top floor of his familys house. He was attempting to manufacture quinine from aniline, an inexpensive and readily available coal tar waste product. Despite his best efforts, however, he did not end up with quinine. Instead, he produced a mysterious dark sludge. Luckily, Perkins scientific training and nature prompted him to investigate the substance further. Incorporating potassium dichromate and alcohol into the aniline at various stages of the experimental process, he finally produced a deep purple solution. And, proving the truth of the famous scientist Louis Pasteurs words chance favours only the prepared mind, Perkin saw the potential of his unexpected find. Historically, textile dyes were made from such natural sources as plants and animal excretions. Some of these, such as the glandular mucus of snails, were difficult to obtain and outrageously expensive. Indeed, the purple colour extracted from a snail was once so costly that in society at the time only the rich could afford it. Further, natural dyes tended to be muddy in hue and fade quickly. It was against this backdrop that Perkins discovery was made. Perkin quickly grasped that his purple solution could be used to colour fabric, thus making it the worlds first synthetic dye. Realising the importance of this breakthrough, he lost no time in patenting it. But perhaps the most fascinating of all Perkins reactions to his find was his nearly instant recognition that the new dye had commercial possibilities. 28Perkin originally named his dye Tyrian Purple, but it later became commonly known as mauve (from the French for the plant used to make the colour violet). He asked advice of Scottish dye works owner Robert Pullar, who assured him that manufacturing the dye would be well worth it if the colour remained fast (i. e. would not fade) and the cost was relatively low. So, over the fierce objections of his mentor Hofmann, he left college to give birth to the modern chemical industry. With the help of his father and brother, Perkin set up a factory not far from London. Utilising the cheap and plentiful coal tar that was an almost unlimited by product of Londons gas street lighting, the dye works began producing the worlds first synthetically dyed material in 1857. The company received a commercial boost from the Empress Eugenie of France, when she decided the new colour flattered her. Very soon, mauve was the necessary shade for all the fashionable ladies in that country. Not to be outdone, Englands Queen Victoria also appeared in public wearing a mauve gown, thus making it all the rage in England as well. The dye was bold and fast, and the public clamoured for more. Perkin went back to the drawing board. Although Perkins fame was achieved and fortune assured by his first discovery, the chemist continued his research. Among other dyes he developed and introduced were aniline red (1859) and aniline black (1863) and, in the late 1860s, Perkins green. It is important to note that Perkins synthetic dye discoveries had outcomes far beyond the merely decorative. The dyes also became vital to medical research in many ways. For instance, they were used to stain previously invisible microbes and bacteria, allowing researchers to identify such bacilli as tuberculosis, cholera, and anthrax. Artificial dyes continue to play a crucial role today. And, in what would have been particularly pleasing to Perkin, their current use is in the search for a vaccine against malaria.", "hypothesis": "Perkin was still young when he made the discovery that made him rich and famous.", "gold_label": "entailment"}
{"uid": "id_672", "premise": "William Henry Perkin The man who invented synthetic dyes William Henry Perkin was born on March 12,1838, in London, England. As a boy, Perkins curiosity prompted early interests in the arts, sciences, photography, and engineering. But it was a chance stumbling upon a run-down, yet functional, laboratory in his late grandfathers home that solidified the young mans enthusiasm for chemistry. As a student at the City of London School, Perkin became immersed in the study of chemistry. His talent and devotion to the subject were perceived by his teacher, Thomas Hall, who encouraged him to attend a series of lectures given by the eminent scientist Michael Faraday at the Royal Institution. Those speeches fired the young chemists enthusiasm further, and he later went on to attend the Royal College of Chemistry, which he succeeded in entering in 1853, at the age of 15. At the time of Perkins enrolment, the Royal College of Chemistry was headed by the noted German chemist August Wilhelm Hofmann. Perkins scientific gifts soon caught Hofmanns attention and, within two years, he became Hofmanns youngest assistant. Not long after that, Perkin made the scientific breakthrough that would bring him both fame and fortune. At the time, quinine was the only viable medical treatment for malaria. The drug is derived from the bark of the cinchona tree, native to South America, and by 1856 demand for the drug was surpassing the available supply. Thus, when Hofmann made some passing comments about the desirability of a synthetic substitute for quinine, it was unsurprising that his star pupil was moved to take up the challenge. During his vacation in 1856, Perkin spent his time in the laboratory on the top floor of his familys house. He was attempting to manufacture quinine from aniline, an inexpensive and readily available coal tar waste product. Despite his best efforts, however, he did not end up with quinine. Instead, he produced a mysterious dark sludge. Luckily, Perkins scientific training and nature prompted him to investigate the substance further. Incorporating potassium dichromate and alcohol into the aniline at various stages of the experimental process, he finally produced a deep purple solution. And, proving the truth of the famous scientist Louis Pasteurs words chance favours only the prepared mind, Perkin saw the potential of his unexpected find. Historically, textile dyes were made from such natural sources as plants and animal excretions. Some of these, such as the glandular mucus of snails, were difficult to obtain and outrageously expensive. Indeed, the purple colour extracted from a snail was once so costly that in society at the time only the rich could afford it. Further, natural dyes tended to be muddy in hue and fade quickly. It was against this backdrop that Perkins discovery was made. Perkin quickly grasped that his purple solution could be used to colour fabric, thus making it the worlds first synthetic dye. Realising the importance of this breakthrough, he lost no time in patenting it. But perhaps the most fascinating of all Perkins reactions to his find was his nearly instant recognition that the new dye had commercial possibilities. 28Perkin originally named his dye Tyrian Purple, but it later became commonly known as mauve (from the French for the plant used to make the colour violet). He asked advice of Scottish dye works owner Robert Pullar, who assured him that manufacturing the dye would be well worth it if the colour remained fast (i. e. would not fade) and the cost was relatively low. So, over the fierce objections of his mentor Hofmann, he left college to give birth to the modern chemical industry. With the help of his father and brother, Perkin set up a factory not far from London. Utilising the cheap and plentiful coal tar that was an almost unlimited by product of Londons gas street lighting, the dye works began producing the worlds first synthetically dyed material in 1857. The company received a commercial boost from the Empress Eugenie of France, when she decided the new colour flattered her. Very soon, mauve was the necessary shade for all the fashionable ladies in that country. Not to be outdone, Englands Queen Victoria also appeared in public wearing a mauve gown, thus making it all the rage in England as well. The dye was bold and fast, and the public clamoured for more. Perkin went back to the drawing board. Although Perkins fame was achieved and fortune assured by his first discovery, the chemist continued his research. Among other dyes he developed and introduced were aniline red (1859) and aniline black (1863) and, in the late 1860s, Perkins green. It is important to note that Perkins synthetic dye discoveries had outcomes far beyond the merely decorative. The dyes also became vital to medical research in many ways. For instance, they were used to stain previously invisible microbes and bacteria, allowing researchers to identify such bacilli as tuberculosis, cholera, and anthrax. Artificial dyes continue to play a crucial role today. And, in what would have been particularly pleasing to Perkin, their current use is in the search for a vaccine against malaria.", "hypothesis": "The trees from which quinine is derived grow only in South America.", "gold_label": "neutral"}
{"uid": "id_673", "premise": "William Henry Perkin The man who invented synthetic dyes William Henry Perkin was born on March 12,1838, in London, England. As a boy, Perkins curiosity prompted early interests in the arts, sciences, photography, and engineering. But it was a chance stumbling upon a run-down, yet functional, laboratory in his late grandfathers home that solidified the young mans enthusiasm for chemistry. As a student at the City of London School, Perkin became immersed in the study of chemistry. His talent and devotion to the subject were perceived by his teacher, Thomas Hall, who encouraged him to attend a series of lectures given by the eminent scientist Michael Faraday at the Royal Institution. Those speeches fired the young chemists enthusiasm further, and he later went on to attend the Royal College of Chemistry, which he succeeded in entering in 1853, at the age of 15. At the time of Perkins enrolment, the Royal College of Chemistry was headed by the noted German chemist August Wilhelm Hofmann. Perkins scientific gifts soon caught Hofmanns attention and, within two years, he became Hofmanns youngest assistant. Not long after that, Perkin made the scientific breakthrough that would bring him both fame and fortune. At the time, quinine was the only viable medical treatment for malaria. The drug is derived from the bark of the cinchona tree, native to South America, and by 1856 demand for the drug was surpassing the available supply. Thus, when Hofmann made some passing comments about the desirability of a synthetic substitute for quinine, it was unsurprising that his star pupil was moved to take up the challenge. During his vacation in 1856, Perkin spent his time in the laboratory on the top floor of his familys house. He was attempting to manufacture quinine from aniline, an inexpensive and readily available coal tar waste product. Despite his best efforts, however, he did not end up with quinine. Instead, he produced a mysterious dark sludge. Luckily, Perkins scientific training and nature prompted him to investigate the substance further. Incorporating potassium dichromate and alcohol into the aniline at various stages of the experimental process, he finally produced a deep purple solution. And, proving the truth of the famous scientist Louis Pasteurs words chance favours only the prepared mind, Perkin saw the potential of his unexpected find. Historically, textile dyes were made from such natural sources as plants and animal excretions. Some of these, such as the glandular mucus of snails, were difficult to obtain and outrageously expensive. Indeed, the purple colour extracted from a snail was once so costly that in society at the time only the rich could afford it. Further, natural dyes tended to be muddy in hue and fade quickly. It was against this backdrop that Perkins discovery was made. Perkin quickly grasped that his purple solution could be used to colour fabric, thus making it the worlds first synthetic dye. Realising the importance of this breakthrough, he lost no time in patenting it. But perhaps the most fascinating of all Perkins reactions to his find was his nearly instant recognition that the new dye had commercial possibilities. 28Perkin originally named his dye Tyrian Purple, but it later became commonly known as mauve (from the French for the plant used to make the colour violet). He asked advice of Scottish dye works owner Robert Pullar, who assured him that manufacturing the dye would be well worth it if the colour remained fast (i. e. would not fade) and the cost was relatively low. So, over the fierce objections of his mentor Hofmann, he left college to give birth to the modern chemical industry. With the help of his father and brother, Perkin set up a factory not far from London. Utilising the cheap and plentiful coal tar that was an almost unlimited by product of Londons gas street lighting, the dye works began producing the worlds first synthetically dyed material in 1857. The company received a commercial boost from the Empress Eugenie of France, when she decided the new colour flattered her. Very soon, mauve was the necessary shade for all the fashionable ladies in that country. Not to be outdone, Englands Queen Victoria also appeared in public wearing a mauve gown, thus making it all the rage in England as well. The dye was bold and fast, and the public clamoured for more. Perkin went back to the drawing board. Although Perkins fame was achieved and fortune assured by his first discovery, the chemist continued his research. Among other dyes he developed and introduced were aniline red (1859) and aniline black (1863) and, in the late 1860s, Perkins green. It is important to note that Perkins synthetic dye discoveries had outcomes far beyond the merely decorative. The dyes also became vital to medical research in many ways. For instance, they were used to stain previously invisible microbes and bacteria, allowing researchers to identify such bacilli as tuberculosis, cholera, and anthrax. Artificial dyes continue to play a crucial role today. And, in what would have been particularly pleasing to Perkin, their current use is in the search for a vaccine against malaria.", "hypothesis": "Michael Faraday was the first person to recognise Perkins ability as a student of chemistry.", "gold_label": "contradiction"}
{"uid": "id_674", "premise": "William Henry Perkin The man who invented synthetic dyes William Henry Perkin was born on March 12,1838, in London, England. As a boy, Perkins curiosity prompted early interests in the arts, sciences, photography, and engineering. But it was a chance stumbling upon a run-down, yet functional, laboratory in his late grandfathers home that solidified the young mans enthusiasm for chemistry. As a student at the City of London School, Perkin became immersed in the study of chemistry. His talent and devotion to the subject were perceived by his teacher, Thomas Hall, who encouraged him to attend a series of lectures given by the eminent scientist Michael Faraday at the Royal Institution. Those speeches fired the young chemists enthusiasm further, and he later went on to attend the Royal College of Chemistry, which he succeeded in entering in 1853, at the age of 15. At the time of Perkins enrolment, the Royal College of Chemistry was headed by the noted German chemist August Wilhelm Hofmann. Perkins scientific gifts soon caught Hofmanns attention and, within two years, he became Hofmanns youngest assistant. Not long after that, Perkin made the scientific breakthrough that would bring him both fame and fortune. At the time, quinine was the only viable medical treatment for malaria. The drug is derived from the bark of the cinchona tree, native to South America, and by 1856 demand for the drug was surpassing the available supply. Thus, when Hofmann made some passing comments about the desirability of a synthetic substitute for quinine, it was unsurprising that his star pupil was moved to take up the challenge. During his vacation in 1856, Perkin spent his time in the laboratory on the top floor of his familys house. He was attempting to manufacture quinine from aniline, an inexpensive and readily available coal tar waste product. Despite his best efforts, however, he did not end up with quinine. Instead, he produced a mysterious dark sludge. Luckily, Perkins scientific training and nature prompted him to investigate the substance further. Incorporating potassium dichromate and alcohol into the aniline at various stages of the experimental process, he finally produced a deep purple solution. And, proving the truth of the famous scientist Louis Pasteurs words chance favours only the prepared mind, Perkin saw the potential of his unexpected find. Historically, textile dyes were made from such natural sources as plants and animal excretions. Some of these, such as the glandular mucus of snails, were difficult to obtain and outrageously expensive. Indeed, the purple colour extracted from a snail was once so costly that in society at the time only the rich could afford it. Further, natural dyes tended to be muddy in hue and fade quickly. It was against this backdrop that Perkins discovery was made. Perkin quickly grasped that his purple solution could be used to colour fabric, thus making it the worlds first synthetic dye. Realising the importance of this breakthrough, he lost no time in patenting it. But perhaps the most fascinating of all Perkins reactions to his find was his nearly instant recognition that the new dye had commercial possibilities. 28Perkin originally named his dye Tyrian Purple, but it later became commonly known as mauve (from the French for the plant used to make the colour violet). He asked advice of Scottish dye works owner Robert Pullar, who assured him that manufacturing the dye would be well worth it if the colour remained fast (i. e. would not fade) and the cost was relatively low. So, over the fierce objections of his mentor Hofmann, he left college to give birth to the modern chemical industry. With the help of his father and brother, Perkin set up a factory not far from London. Utilising the cheap and plentiful coal tar that was an almost unlimited by product of Londons gas street lighting, the dye works began producing the worlds first synthetically dyed material in 1857. The company received a commercial boost from the Empress Eugenie of France, when she decided the new colour flattered her. Very soon, mauve was the necessary shade for all the fashionable ladies in that country. Not to be outdone, Englands Queen Victoria also appeared in public wearing a mauve gown, thus making it all the rage in England as well. The dye was bold and fast, and the public clamoured for more. Perkin went back to the drawing board. Although Perkins fame was achieved and fortune assured by his first discovery, the chemist continued his research. Among other dyes he developed and introduced were aniline red (1859) and aniline black (1863) and, in the late 1860s, Perkins green. It is important to note that Perkins synthetic dye discoveries had outcomes far beyond the merely decorative. The dyes also became vital to medical research in many ways. For instance, they were used to stain previously invisible microbes and bacteria, allowing researchers to identify such bacilli as tuberculosis, cholera, and anthrax. Artificial dyes continue to play a crucial role today. And, in what would have been particularly pleasing to Perkin, their current use is in the search for a vaccine against malaria.", "hypothesis": "Michael Faraday suggested Perkin should enrol in the Royal College of Chemistry.", "gold_label": "neutral"}
{"uid": "id_675", "premise": "William Henry Perkin The man who invented synthetic dyes William Henry Perkin was born on March 12,1838, in London, England. As a boy, Perkins curiosity prompted early interests in the arts, sciences, photography, and engineering. But it was a chance stumbling upon a run-down, yet functional, laboratory in his late grandfathers home that solidified the young mans enthusiasm for chemistry. As a student at the City of London School, Perkin became immersed in the study of chemistry. His talent and devotion to the subject were perceived by his teacher, Thomas Hall, who encouraged him to attend a series of lectures given by the eminent scientist Michael Faraday at the Royal Institution. Those speeches fired the young chemists enthusiasm further, and he later went on to attend the Royal College of Chemistry, which he succeeded in entering in 1853, at the age of 15. At the time of Perkins enrolment, the Royal College of Chemistry was headed by the noted German chemist August Wilhelm Hofmann. Perkins scientific gifts soon caught Hofmanns attention and, within two years, he became Hofmanns youngest assistant. Not long after that, Perkin made the scientific breakthrough that would bring him both fame and fortune. At the time, quinine was the only viable medical treatment for malaria. The drug is derived from the bark of the cinchona tree, native to South America, and by 1856 demand for the drug was surpassing the available supply. Thus, when Hofmann made some passing comments about the desirability of a synthetic substitute for quinine, it was unsurprising that his star pupil was moved to take up the challenge. During his vacation in 1856, Perkin spent his time in the laboratory on the top floor of his familys house. He was attempting to manufacture quinine from aniline, an inexpensive and readily available coal tar waste product. Despite his best efforts, however, he did not end up with quinine. Instead, he produced a mysterious dark sludge. Luckily, Perkins scientific training and nature prompted him to investigate the substance further. Incorporating potassium dichromate and alcohol into the aniline at various stages of the experimental process, he finally produced a deep purple solution. And, proving the truth of the famous scientist Louis Pasteurs words chance favours only the prepared mind, Perkin saw the potential of his unexpected find. Historically, textile dyes were made from such natural sources as plants and animal excretions. Some of these, such as the glandular mucus of snails, were difficult to obtain and outrageously expensive. Indeed, the purple colour extracted from a snail was once so costly that in society at the time only the rich could afford it. Further, natural dyes tended to be muddy in hue and fade quickly. It was against this backdrop that Perkins discovery was made. Perkin quickly grasped that his purple solution could be used to colour fabric, thus making it the worlds first synthetic dye. Realising the importance of this breakthrough, he lost no time in patenting it. But perhaps the most fascinating of all Perkins reactions to his find was his nearly instant recognition that the new dye had commercial possibilities. 28Perkin originally named his dye Tyrian Purple, but it later became commonly known as mauve (from the French for the plant used to make the colour violet). He asked advice of Scottish dye works owner Robert Pullar, who assured him that manufacturing the dye would be well worth it if the colour remained fast (i. e. would not fade) and the cost was relatively low. So, over the fierce objections of his mentor Hofmann, he left college to give birth to the modern chemical industry. With the help of his father and brother, Perkin set up a factory not far from London. Utilising the cheap and plentiful coal tar that was an almost unlimited by product of Londons gas street lighting, the dye works began producing the worlds first synthetically dyed material in 1857. The company received a commercial boost from the Empress Eugenie of France, when she decided the new colour flattered her. Very soon, mauve was the necessary shade for all the fashionable ladies in that country. Not to be outdone, Englands Queen Victoria also appeared in public wearing a mauve gown, thus making it all the rage in England as well. The dye was bold and fast, and the public clamoured for more. Perkin went back to the drawing board. Although Perkins fame was achieved and fortune assured by his first discovery, the chemist continued his research. Among other dyes he developed and introduced were aniline red (1859) and aniline black (1863) and, in the late 1860s, Perkins green. It is important to note that Perkins synthetic dye discoveries had outcomes far beyond the merely decorative. The dyes also became vital to medical research in many ways. For instance, they were used to stain previously invisible microbes and bacteria, allowing researchers to identify such bacilli as tuberculosis, cholera, and anthrax. Artificial dyes continue to play a crucial role today. And, in what would have been particularly pleasing to Perkin, their current use is in the search for a vaccine against malaria.", "hypothesis": "Perkin was inspired by the discoveries of the famous scientist Louis Pasteur.", "gold_label": "neutral"}
{"uid": "id_676", "premise": "William Henry Perkin The man who invented synthetic dyes William Henry Perkin was born on March 12,1838, in London, England. As a boy, Perkins curiosity prompted early interests in the arts, sciences, photography, and engineering. But it was a chance stumbling upon a run-down, yet functional, laboratory in his late grandfathers home that solidified the young mans enthusiasm for chemistry. As a student at the City of London School, Perkin became immersed in the study of chemistry. His talent and devotion to the subject were perceived by his teacher, Thomas Hall, who encouraged him to attend a series of lectures given by the eminent scientist Michael Faraday at the Royal Institution. Those speeches fired the young chemists enthusiasm further, and he later went on to attend the Royal College of Chemistry, which he succeeded in entering in 1853, at the age of 15. At the time of Perkins enrolment, the Royal College of Chemistry was headed by the noted German chemist August Wilhelm Hofmann. Perkins scientific gifts soon caught Hofmanns attention and, within two years, he became Hofmanns youngest assistant. Not long after that, Perkin made the scientific breakthrough that would bring him both fame and fortune. At the time, quinine was the only viable medical treatment for malaria. The drug is derived from the bark of the cinchona tree, native to South America, and by 1856 demand for the drug was surpassing the available supply. Thus, when Hofmann made some passing comments about the desirability of a synthetic substitute for quinine, it was unsurprising that his star pupil was moved to take up the challenge. During his vacation in 1856, Perkin spent his time in the laboratory on the top floor of his familys house. He was attempting to manufacture quinine from aniline, an inexpensive and readily available coal tar waste product. Despite his best efforts, however, he did not end up with quinine. Instead, he produced a mysterious dark sludge. Luckily, Perkins scientific training and nature prompted him to investigate the substance further. Incorporating potassium dichromate and alcohol into the aniline at various stages of the experimental process, he finally produced a deep purple solution. And, proving the truth of the famous scientist Louis Pasteurs words chance favours only the prepared mind, Perkin saw the potential of his unexpected find. Historically, textile dyes were made from such natural sources as plants and animal excretions. Some of these, such as the glandular mucus of snails, were difficult to obtain and outrageously expensive. Indeed, the purple colour extracted from a snail was once so costly that in society at the time only the rich could afford it. Further, natural dyes tended to be muddy in hue and fade quickly. It was against this backdrop that Perkins discovery was made. Perkin quickly grasped that his purple solution could be used to colour fabric, thus making it the worlds first synthetic dye. Realising the importance of this breakthrough, he lost no time in patenting it. But perhaps the most fascinating of all Perkins reactions to his find was his nearly instant recognition that the new dye had commercial possibilities. 28Perkin originally named his dye Tyrian Purple, but it later became commonly known as mauve (from the French for the plant used to make the colour violet). He asked advice of Scottish dye works owner Robert Pullar, who assured him that manufacturing the dye would be well worth it if the colour remained fast (i. e. would not fade) and the cost was relatively low. So, over the fierce objections of his mentor Hofmann, he left college to give birth to the modern chemical industry. With the help of his father and brother, Perkin set up a factory not far from London. Utilising the cheap and plentiful coal tar that was an almost unlimited by product of Londons gas street lighting, the dye works began producing the worlds first synthetically dyed material in 1857. The company received a commercial boost from the Empress Eugenie of France, when she decided the new colour flattered her. Very soon, mauve was the necessary shade for all the fashionable ladies in that country. Not to be outdone, Englands Queen Victoria also appeared in public wearing a mauve gown, thus making it all the rage in England as well. The dye was bold and fast, and the public clamoured for more. Perkin went back to the drawing board. Although Perkins fame was achieved and fortune assured by his first discovery, the chemist continued his research. Among other dyes he developed and introduced were aniline red (1859) and aniline black (1863) and, in the late 1860s, Perkins green. It is important to note that Perkins synthetic dye discoveries had outcomes far beyond the merely decorative. The dyes also became vital to medical research in many ways. For instance, they were used to stain previously invisible microbes and bacteria, allowing researchers to identify such bacilli as tuberculosis, cholera, and anthrax. Artificial dyes continue to play a crucial role today. And, in what would have been particularly pleasing to Perkin, their current use is in the search for a vaccine against malaria.", "hypothesis": "Perkin employed August Wilhelm Hofmann as his assistant.", "gold_label": "contradiction"}
{"uid": "id_677", "premise": "William Henry Perkin The man who invented synthetic dyes William Henry Perkin was born on March 12,1838, in London, England. As a boy, Perkins curiosity prompted early interests in the arts, sciences, photography, and engineering. But it was a chance stumbling upon a run-down, yet functional, laboratory in his late grandfathers home that solidified the young mans enthusiasm for chemistry. As a student at the City of London School, Perkin became immersed in the study of chemistry. His talent and devotion to the subject were perceived by his teacher, Thomas Hall, who encouraged him to attend a series of lectures given by the eminent scientist Michael Faraday at the Royal Institution. Those speeches fired the young chemists enthusiasm further, and he later went on to attend the Royal College of Chemistry, which he succeeded in entering in 1853, at the age of 15. At the time of Perkins enrolment, the Royal College of Chemistry was headed by the noted German chemist August Wilhelm Hofmann. Perkins scientific gifts soon caught Hofmanns attention and, within two years, he became Hofmanns youngest assistant. Not long after that, Perkin made the scientific breakthrough that would bring him both fame and fortune. At the time, quinine was the only viable medical treatment for malaria. The drug is derived from the bark of the cinchona tree, native to South America, and by 1856 demand for the drug was surpassing the available supply. Thus, when Hofmann made some passing comments about the desirability of a synthetic substitute for quinine, it was unsurprising that his star pupil was moved to take up the challenge. During his vacation in 1856, Perkin spent his time in the laboratory on the top floor of his familys house. He was attempting to manufacture quinine from aniline, an inexpensive and readily available coal tar waste product. Despite his best efforts, however, he did not end up with quinine. Instead, he produced a mysterious dark sludge. Luckily, Perkins scientific training and nature prompted him to investigate the substance further. Incorporating potassium dichromate and alcohol into the aniline at various stages of the experimental process, he finally produced a deep purple solution. And, proving the truth of the famous scientist Louis Pasteurs words chance favours only the prepared mind, Perkin saw the potential of his unexpected find. Historically, textile dyes were made from such natural sources as plants and animal excretions. Some of these, such as the glandular mucus of snails, were difficult to obtain and outrageously expensive. Indeed, the purple colour extracted from a snail was once so costly that in society at the time only the rich could afford it. Further, natural dyes tended to be muddy in hue and fade quickly. It was against this backdrop that Perkins discovery was made. Perkin quickly grasped that his purple solution could be used to colour fabric, thus making it the worlds first synthetic dye. Realising the importance of this breakthrough, he lost no time in patenting it. But perhaps the most fascinating of all Perkins reactions to his find was his nearly instant recognition that the new dye had commercial possibilities. 28Perkin originally named his dye Tyrian Purple, but it later became commonly known as mauve (from the French for the plant used to make the colour violet). He asked advice of Scottish dye works owner Robert Pullar, who assured him that manufacturing the dye would be well worth it if the colour remained fast (i. e. would not fade) and the cost was relatively low. So, over the fierce objections of his mentor Hofmann, he left college to give birth to the modern chemical industry. With the help of his father and brother, Perkin set up a factory not far from London. Utilising the cheap and plentiful coal tar that was an almost unlimited by product of Londons gas street lighting, the dye works began producing the worlds first synthetically dyed material in 1857. The company received a commercial boost from the Empress Eugenie of France, when she decided the new colour flattered her. Very soon, mauve was the necessary shade for all the fashionable ladies in that country. Not to be outdone, Englands Queen Victoria also appeared in public wearing a mauve gown, thus making it all the rage in England as well. The dye was bold and fast, and the public clamoured for more. Perkin went back to the drawing board. Although Perkins fame was achieved and fortune assured by his first discovery, the chemist continued his research. Among other dyes he developed and introduced were aniline red (1859) and aniline black (1863) and, in the late 1860s, Perkins green. It is important to note that Perkins synthetic dye discoveries had outcomes far beyond the merely decorative. The dyes also became vital to medical research in many ways. For instance, they were used to stain previously invisible microbes and bacteria, allowing researchers to identify such bacilli as tuberculosis, cholera, and anthrax. Artificial dyes continue to play a crucial role today. And, in what would have been particularly pleasing to Perkin, their current use is in the search for a vaccine against malaria.", "hypothesis": "Perkin hoped to manufacture a drug from a coal tar waste product.", "gold_label": "entailment"}
{"uid": "id_678", "premise": "William Henry Perkin, The man who invented synthetic dyes. William Henry Perkin was born on March 12, 1838, in London, England. As a boy, Perkins curiosity prompted early interests in the arts, sciences, photography, and engineering. But it was a chance stumbling upon a run-down, yet functional, laboratory in his late grandfathers home that solidified the young mans enthusiasm for chemistry. As a student at the City of London School, Perkin became immersed in the study of chemistry. His talent and devotion to the subject were perceived by his teacher, Thomas Hall, who encouraged him to attend a series of lectures given by the eminent scientist Michael Faraday at the Royal Institution. Those speeches fired the young chemists enthusiasm further, and he later went on to attend the Royal College of Chemistry, which he succeeded in entering in 1853, at the age of 15. At the time of Perkins enrolment, the Royal College of Chemistry was headed by the noted German chemist August Wilhelm Hofmann. Perkins scientific gifts soon caught Hofmanns attention and, within two years, he became Hofmanns youngest assistant. Not long after that, Perkin made the scientific breakthrough that would bring him both fame and fortune. At the time, quinine was the only viable medical treatment for malaria. The drug is derived from the bark of the cinchona tree, native to South America, and by 1856 demand for the drug was surpassing the available supply. Thus, when Hofmann made some passing comments about the desirability of a synthetic substitute for quinine, it was unsurprising that his star pupil was moved to take up the challenge. During his vacation in 1856, Perkin spent his time in the laboratory on the top floor of his familys house. He was attempting to manufacture quinine from aniline, an inexpensive and readily available coal tar waste product. Despite his best efforts, however, he did not end up with quinine. Instead, he produced a mysterious dark sludge. Luckily, Perkins scientific training and nature prompted him to investigate the substance further. Incorporating potassium dichromate and alcohol into the aniline at various stages of the experimental process, he finally produced a deep purple solution. And, proving the truth of the famous scientist Louis Pasteurs words chance favours only the prepared mind, Perkin saw the potential of his unexpected find. Historically, textile dyes were made from such natural sources as plants and animal excretions. Some of these, such as the glandular mucus of snails, were difficult to obtain and outrageously expensive. Indeed, the purple colour extracted from a snail was once so costly in society at the time only the rich could afford it. Further, natural dyes tended to be muddy in hue and fade quickly. It was against this backdrop that Perkins discovery was made. Perkin quickly grasped that his purple solution could be used to colour fabric, thus making it the worlds first synthetic dye. Realising the importance of this breakthrough, he lost no time in patenting it. But perhaps the most fascinating of all Perkins reactions to his find was his nearly instant recognition that the new dye had commercial possibilities. Perkin originally named his dye Tyrian Purple, but it later became commonly known as mauve (from the French for the plant used to make the colour violet). He asked advice of Scottish dye works owner Robert Pullar, who assured him that manufacturing the dye would be well worth it if the colour remained fast (i. e. would not fade) and the cost was relatively low. So, over the fierce objections of his mentor Hofmann, he left college to give birth to the modern chemical industry. With the help of his father and brother, Perkin set up a factory not far from London. Utilising the cheap and plentiful coal tar that was an almost unlimited byproduct of Londons gas street lighting, the dye works began producing the worlds first synthetically dyed material in 1857. The company received a commercial boost from the Empress Eugenie of France, when she decided the new colour flattered her. Very soon, mauve was the necessary shade for all the fashionable ladies in that country. Not to be outdone, Englands Queen Victoria also appeared in public wearing a mauve gown, thus making it all the rage in England as well. The dye was bold and fast, and the public clamoured for more. Perkin went back to the drawing board. Although Perkins fame was achieved and fortune assured by his first discovery, the chemist continued his research. Among other dyes he developed and introduced were aniline red (1859) and aniline black (1863) and, in the late 1860s, Perkins green. It is important to note that Perkins synthetic dye discoveries had outcomes far beyond the merely decorative. The dyes also became vital to medical research in many ways. For instance, they were used to stain previously invisible microbes and bacteria, allowing researchers to identify such bacilli as tuberculosis, cholera, and anthrax. Artificial dyes continue to play a crucial role today. And, in what would have been particularly pleasing to Perkin, their current use is in the search for a vaccine against malaria.", "hypothesis": "Michael Faraday was the first person to recognise Perkins ability as a student of chemistry.", "gold_label": "contradiction"}
{"uid": "id_679", "premise": "William Henry Perkin, The man who invented synthetic dyes. William Henry Perkin was born on March 12, 1838, in London, England. As a boy, Perkins curiosity prompted early interests in the arts, sciences, photography, and engineering. But it was a chance stumbling upon a run-down, yet functional, laboratory in his late grandfathers home that solidified the young mans enthusiasm for chemistry. As a student at the City of London School, Perkin became immersed in the study of chemistry. His talent and devotion to the subject were perceived by his teacher, Thomas Hall, who encouraged him to attend a series of lectures given by the eminent scientist Michael Faraday at the Royal Institution. Those speeches fired the young chemists enthusiasm further, and he later went on to attend the Royal College of Chemistry, which he succeeded in entering in 1853, at the age of 15. At the time of Perkins enrolment, the Royal College of Chemistry was headed by the noted German chemist August Wilhelm Hofmann. Perkins scientific gifts soon caught Hofmanns attention and, within two years, he became Hofmanns youngest assistant. Not long after that, Perkin made the scientific breakthrough that would bring him both fame and fortune. At the time, quinine was the only viable medical treatment for malaria. The drug is derived from the bark of the cinchona tree, native to South America, and by 1856 demand for the drug was surpassing the available supply. Thus, when Hofmann made some passing comments about the desirability of a synthetic substitute for quinine, it was unsurprising that his star pupil was moved to take up the challenge. During his vacation in 1856, Perkin spent his time in the laboratory on the top floor of his familys house. He was attempting to manufacture quinine from aniline, an inexpensive and readily available coal tar waste product. Despite his best efforts, however, he did not end up with quinine. Instead, he produced a mysterious dark sludge. Luckily, Perkins scientific training and nature prompted him to investigate the substance further. Incorporating potassium dichromate and alcohol into the aniline at various stages of the experimental process, he finally produced a deep purple solution. And, proving the truth of the famous scientist Louis Pasteurs words chance favours only the prepared mind, Perkin saw the potential of his unexpected find. Historically, textile dyes were made from such natural sources as plants and animal excretions. Some of these, such as the glandular mucus of snails, were difficult to obtain and outrageously expensive. Indeed, the purple colour extracted from a snail was once so costly in society at the time only the rich could afford it. Further, natural dyes tended to be muddy in hue and fade quickly. It was against this backdrop that Perkins discovery was made. Perkin quickly grasped that his purple solution could be used to colour fabric, thus making it the worlds first synthetic dye. Realising the importance of this breakthrough, he lost no time in patenting it. But perhaps the most fascinating of all Perkins reactions to his find was his nearly instant recognition that the new dye had commercial possibilities. Perkin originally named his dye Tyrian Purple, but it later became commonly known as mauve (from the French for the plant used to make the colour violet). He asked advice of Scottish dye works owner Robert Pullar, who assured him that manufacturing the dye would be well worth it if the colour remained fast (i. e. would not fade) and the cost was relatively low. So, over the fierce objections of his mentor Hofmann, he left college to give birth to the modern chemical industry. With the help of his father and brother, Perkin set up a factory not far from London. Utilising the cheap and plentiful coal tar that was an almost unlimited byproduct of Londons gas street lighting, the dye works began producing the worlds first synthetically dyed material in 1857. The company received a commercial boost from the Empress Eugenie of France, when she decided the new colour flattered her. Very soon, mauve was the necessary shade for all the fashionable ladies in that country. Not to be outdone, Englands Queen Victoria also appeared in public wearing a mauve gown, thus making it all the rage in England as well. The dye was bold and fast, and the public clamoured for more. Perkin went back to the drawing board. Although Perkins fame was achieved and fortune assured by his first discovery, the chemist continued his research. Among other dyes he developed and introduced were aniline red (1859) and aniline black (1863) and, in the late 1860s, Perkins green. It is important to note that Perkins synthetic dye discoveries had outcomes far beyond the merely decorative. The dyes also became vital to medical research in many ways. For instance, they were used to stain previously invisible microbes and bacteria, allowing researchers to identify such bacilli as tuberculosis, cholera, and anthrax. Artificial dyes continue to play a crucial role today. And, in what would have been particularly pleasing to Perkin, their current use is in the search for a vaccine against malaria.", "hypothesis": "Perkin employed August Wilhelm Hofmann as his assistant.", "gold_label": "contradiction"}
{"uid": "id_680", "premise": "William Henry Perkin, The man who invented synthetic dyes. William Henry Perkin was born on March 12, 1838, in London, England. As a boy, Perkins curiosity prompted early interests in the arts, sciences, photography, and engineering. But it was a chance stumbling upon a run-down, yet functional, laboratory in his late grandfathers home that solidified the young mans enthusiasm for chemistry. As a student at the City of London School, Perkin became immersed in the study of chemistry. His talent and devotion to the subject were perceived by his teacher, Thomas Hall, who encouraged him to attend a series of lectures given by the eminent scientist Michael Faraday at the Royal Institution. Those speeches fired the young chemists enthusiasm further, and he later went on to attend the Royal College of Chemistry, which he succeeded in entering in 1853, at the age of 15. At the time of Perkins enrolment, the Royal College of Chemistry was headed by the noted German chemist August Wilhelm Hofmann. Perkins scientific gifts soon caught Hofmanns attention and, within two years, he became Hofmanns youngest assistant. Not long after that, Perkin made the scientific breakthrough that would bring him both fame and fortune. At the time, quinine was the only viable medical treatment for malaria. The drug is derived from the bark of the cinchona tree, native to South America, and by 1856 demand for the drug was surpassing the available supply. Thus, when Hofmann made some passing comments about the desirability of a synthetic substitute for quinine, it was unsurprising that his star pupil was moved to take up the challenge. During his vacation in 1856, Perkin spent his time in the laboratory on the top floor of his familys house. He was attempting to manufacture quinine from aniline, an inexpensive and readily available coal tar waste product. Despite his best efforts, however, he did not end up with quinine. Instead, he produced a mysterious dark sludge. Luckily, Perkins scientific training and nature prompted him to investigate the substance further. Incorporating potassium dichromate and alcohol into the aniline at various stages of the experimental process, he finally produced a deep purple solution. And, proving the truth of the famous scientist Louis Pasteurs words chance favours only the prepared mind, Perkin saw the potential of his unexpected find. Historically, textile dyes were made from such natural sources as plants and animal excretions. Some of these, such as the glandular mucus of snails, were difficult to obtain and outrageously expensive. Indeed, the purple colour extracted from a snail was once so costly in society at the time only the rich could afford it. Further, natural dyes tended to be muddy in hue and fade quickly. It was against this backdrop that Perkins discovery was made. Perkin quickly grasped that his purple solution could be used to colour fabric, thus making it the worlds first synthetic dye. Realising the importance of this breakthrough, he lost no time in patenting it. But perhaps the most fascinating of all Perkins reactions to his find was his nearly instant recognition that the new dye had commercial possibilities. Perkin originally named his dye Tyrian Purple, but it later became commonly known as mauve (from the French for the plant used to make the colour violet). He asked advice of Scottish dye works owner Robert Pullar, who assured him that manufacturing the dye would be well worth it if the colour remained fast (i. e. would not fade) and the cost was relatively low. So, over the fierce objections of his mentor Hofmann, he left college to give birth to the modern chemical industry. With the help of his father and brother, Perkin set up a factory not far from London. Utilising the cheap and plentiful coal tar that was an almost unlimited byproduct of Londons gas street lighting, the dye works began producing the worlds first synthetically dyed material in 1857. The company received a commercial boost from the Empress Eugenie of France, when she decided the new colour flattered her. Very soon, mauve was the necessary shade for all the fashionable ladies in that country. Not to be outdone, Englands Queen Victoria also appeared in public wearing a mauve gown, thus making it all the rage in England as well. The dye was bold and fast, and the public clamoured for more. Perkin went back to the drawing board. Although Perkins fame was achieved and fortune assured by his first discovery, the chemist continued his research. Among other dyes he developed and introduced were aniline red (1859) and aniline black (1863) and, in the late 1860s, Perkins green. It is important to note that Perkins synthetic dye discoveries had outcomes far beyond the merely decorative. The dyes also became vital to medical research in many ways. For instance, they were used to stain previously invisible microbes and bacteria, allowing researchers to identify such bacilli as tuberculosis, cholera, and anthrax. Artificial dyes continue to play a crucial role today. And, in what would have been particularly pleasing to Perkin, their current use is in the search for a vaccine against malaria.", "hypothesis": "Michael Faraday suggested Perkin should enrol in the Royal College of Chemistry.", "gold_label": "neutral"}
{"uid": "id_681", "premise": "William Henry Perkin, The man who invented synthetic dyes. William Henry Perkin was born on March 12, 1838, in London, England. As a boy, Perkins curiosity prompted early interests in the arts, sciences, photography, and engineering. But it was a chance stumbling upon a run-down, yet functional, laboratory in his late grandfathers home that solidified the young mans enthusiasm for chemistry. As a student at the City of London School, Perkin became immersed in the study of chemistry. His talent and devotion to the subject were perceived by his teacher, Thomas Hall, who encouraged him to attend a series of lectures given by the eminent scientist Michael Faraday at the Royal Institution. Those speeches fired the young chemists enthusiasm further, and he later went on to attend the Royal College of Chemistry, which he succeeded in entering in 1853, at the age of 15. At the time of Perkins enrolment, the Royal College of Chemistry was headed by the noted German chemist August Wilhelm Hofmann. Perkins scientific gifts soon caught Hofmanns attention and, within two years, he became Hofmanns youngest assistant. Not long after that, Perkin made the scientific breakthrough that would bring him both fame and fortune. At the time, quinine was the only viable medical treatment for malaria. The drug is derived from the bark of the cinchona tree, native to South America, and by 1856 demand for the drug was surpassing the available supply. Thus, when Hofmann made some passing comments about the desirability of a synthetic substitute for quinine, it was unsurprising that his star pupil was moved to take up the challenge. During his vacation in 1856, Perkin spent his time in the laboratory on the top floor of his familys house. He was attempting to manufacture quinine from aniline, an inexpensive and readily available coal tar waste product. Despite his best efforts, however, he did not end up with quinine. Instead, he produced a mysterious dark sludge. Luckily, Perkins scientific training and nature prompted him to investigate the substance further. Incorporating potassium dichromate and alcohol into the aniline at various stages of the experimental process, he finally produced a deep purple solution. And, proving the truth of the famous scientist Louis Pasteurs words chance favours only the prepared mind, Perkin saw the potential of his unexpected find. Historically, textile dyes were made from such natural sources as plants and animal excretions. Some of these, such as the glandular mucus of snails, were difficult to obtain and outrageously expensive. Indeed, the purple colour extracted from a snail was once so costly in society at the time only the rich could afford it. Further, natural dyes tended to be muddy in hue and fade quickly. It was against this backdrop that Perkins discovery was made. Perkin quickly grasped that his purple solution could be used to colour fabric, thus making it the worlds first synthetic dye. Realising the importance of this breakthrough, he lost no time in patenting it. But perhaps the most fascinating of all Perkins reactions to his find was his nearly instant recognition that the new dye had commercial possibilities. Perkin originally named his dye Tyrian Purple, but it later became commonly known as mauve (from the French for the plant used to make the colour violet). He asked advice of Scottish dye works owner Robert Pullar, who assured him that manufacturing the dye would be well worth it if the colour remained fast (i. e. would not fade) and the cost was relatively low. So, over the fierce objections of his mentor Hofmann, he left college to give birth to the modern chemical industry. With the help of his father and brother, Perkin set up a factory not far from London. Utilising the cheap and plentiful coal tar that was an almost unlimited byproduct of Londons gas street lighting, the dye works began producing the worlds first synthetically dyed material in 1857. The company received a commercial boost from the Empress Eugenie of France, when she decided the new colour flattered her. Very soon, mauve was the necessary shade for all the fashionable ladies in that country. Not to be outdone, Englands Queen Victoria also appeared in public wearing a mauve gown, thus making it all the rage in England as well. The dye was bold and fast, and the public clamoured for more. Perkin went back to the drawing board. Although Perkins fame was achieved and fortune assured by his first discovery, the chemist continued his research. Among other dyes he developed and introduced were aniline red (1859) and aniline black (1863) and, in the late 1860s, Perkins green. It is important to note that Perkins synthetic dye discoveries had outcomes far beyond the merely decorative. The dyes also became vital to medical research in many ways. For instance, they were used to stain previously invisible microbes and bacteria, allowing researchers to identify such bacilli as tuberculosis, cholera, and anthrax. Artificial dyes continue to play a crucial role today. And, in what would have been particularly pleasing to Perkin, their current use is in the search for a vaccine against malaria.", "hypothesis": "The trees from which quinine is derived grow only in South America.", "gold_label": "neutral"}
{"uid": "id_682", "premise": "William Henry Perkin, The man who invented synthetic dyes. William Henry Perkin was born on March 12, 1838, in London, England. As a boy, Perkins curiosity prompted early interests in the arts, sciences, photography, and engineering. But it was a chance stumbling upon a run-down, yet functional, laboratory in his late grandfathers home that solidified the young mans enthusiasm for chemistry. As a student at the City of London School, Perkin became immersed in the study of chemistry. His talent and devotion to the subject were perceived by his teacher, Thomas Hall, who encouraged him to attend a series of lectures given by the eminent scientist Michael Faraday at the Royal Institution. Those speeches fired the young chemists enthusiasm further, and he later went on to attend the Royal College of Chemistry, which he succeeded in entering in 1853, at the age of 15. At the time of Perkins enrolment, the Royal College of Chemistry was headed by the noted German chemist August Wilhelm Hofmann. Perkins scientific gifts soon caught Hofmanns attention and, within two years, he became Hofmanns youngest assistant. Not long after that, Perkin made the scientific breakthrough that would bring him both fame and fortune. At the time, quinine was the only viable medical treatment for malaria. The drug is derived from the bark of the cinchona tree, native to South America, and by 1856 demand for the drug was surpassing the available supply. Thus, when Hofmann made some passing comments about the desirability of a synthetic substitute for quinine, it was unsurprising that his star pupil was moved to take up the challenge. During his vacation in 1856, Perkin spent his time in the laboratory on the top floor of his familys house. He was attempting to manufacture quinine from aniline, an inexpensive and readily available coal tar waste product. Despite his best efforts, however, he did not end up with quinine. Instead, he produced a mysterious dark sludge. Luckily, Perkins scientific training and nature prompted him to investigate the substance further. Incorporating potassium dichromate and alcohol into the aniline at various stages of the experimental process, he finally produced a deep purple solution. And, proving the truth of the famous scientist Louis Pasteurs words chance favours only the prepared mind, Perkin saw the potential of his unexpected find. Historically, textile dyes were made from such natural sources as plants and animal excretions. Some of these, such as the glandular mucus of snails, were difficult to obtain and outrageously expensive. Indeed, the purple colour extracted from a snail was once so costly in society at the time only the rich could afford it. Further, natural dyes tended to be muddy in hue and fade quickly. It was against this backdrop that Perkins discovery was made. Perkin quickly grasped that his purple solution could be used to colour fabric, thus making it the worlds first synthetic dye. Realising the importance of this breakthrough, he lost no time in patenting it. But perhaps the most fascinating of all Perkins reactions to his find was his nearly instant recognition that the new dye had commercial possibilities. Perkin originally named his dye Tyrian Purple, but it later became commonly known as mauve (from the French for the plant used to make the colour violet). He asked advice of Scottish dye works owner Robert Pullar, who assured him that manufacturing the dye would be well worth it if the colour remained fast (i. e. would not fade) and the cost was relatively low. So, over the fierce objections of his mentor Hofmann, he left college to give birth to the modern chemical industry. With the help of his father and brother, Perkin set up a factory not far from London. Utilising the cheap and plentiful coal tar that was an almost unlimited byproduct of Londons gas street lighting, the dye works began producing the worlds first synthetically dyed material in 1857. The company received a commercial boost from the Empress Eugenie of France, when she decided the new colour flattered her. Very soon, mauve was the necessary shade for all the fashionable ladies in that country. Not to be outdone, Englands Queen Victoria also appeared in public wearing a mauve gown, thus making it all the rage in England as well. The dye was bold and fast, and the public clamoured for more. Perkin went back to the drawing board. Although Perkins fame was achieved and fortune assured by his first discovery, the chemist continued his research. Among other dyes he developed and introduced were aniline red (1859) and aniline black (1863) and, in the late 1860s, Perkins green. It is important to note that Perkins synthetic dye discoveries had outcomes far beyond the merely decorative. The dyes also became vital to medical research in many ways. For instance, they were used to stain previously invisible microbes and bacteria, allowing researchers to identify such bacilli as tuberculosis, cholera, and anthrax. Artificial dyes continue to play a crucial role today. And, in what would have been particularly pleasing to Perkin, their current use is in the search for a vaccine against malaria.", "hypothesis": "Perkin hoped to manufacture a drug from a coal tar waste product.", "gold_label": "entailment"}
{"uid": "id_683", "premise": "William Henry Perkin, The man who invented synthetic dyes. William Henry Perkin was born on March 12, 1838, in London, England. As a boy, Perkins curiosity prompted early interests in the arts, sciences, photography, and engineering. But it was a chance stumbling upon a run-down, yet functional, laboratory in his late grandfathers home that solidified the young mans enthusiasm for chemistry. As a student at the City of London School, Perkin became immersed in the study of chemistry. His talent and devotion to the subject were perceived by his teacher, Thomas Hall, who encouraged him to attend a series of lectures given by the eminent scientist Michael Faraday at the Royal Institution. Those speeches fired the young chemists enthusiasm further, and he later went on to attend the Royal College of Chemistry, which he succeeded in entering in 1853, at the age of 15. At the time of Perkins enrolment, the Royal College of Chemistry was headed by the noted German chemist August Wilhelm Hofmann. Perkins scientific gifts soon caught Hofmanns attention and, within two years, he became Hofmanns youngest assistant. Not long after that, Perkin made the scientific breakthrough that would bring him both fame and fortune. At the time, quinine was the only viable medical treatment for malaria. The drug is derived from the bark of the cinchona tree, native to South America, and by 1856 demand for the drug was surpassing the available supply. Thus, when Hofmann made some passing comments about the desirability of a synthetic substitute for quinine, it was unsurprising that his star pupil was moved to take up the challenge. During his vacation in 1856, Perkin spent his time in the laboratory on the top floor of his familys house. He was attempting to manufacture quinine from aniline, an inexpensive and readily available coal tar waste product. Despite his best efforts, however, he did not end up with quinine. Instead, he produced a mysterious dark sludge. Luckily, Perkins scientific training and nature prompted him to investigate the substance further. Incorporating potassium dichromate and alcohol into the aniline at various stages of the experimental process, he finally produced a deep purple solution. And, proving the truth of the famous scientist Louis Pasteurs words chance favours only the prepared mind, Perkin saw the potential of his unexpected find. Historically, textile dyes were made from such natural sources as plants and animal excretions. Some of these, such as the glandular mucus of snails, were difficult to obtain and outrageously expensive. Indeed, the purple colour extracted from a snail was once so costly in society at the time only the rich could afford it. Further, natural dyes tended to be muddy in hue and fade quickly. It was against this backdrop that Perkins discovery was made. Perkin quickly grasped that his purple solution could be used to colour fabric, thus making it the worlds first synthetic dye. Realising the importance of this breakthrough, he lost no time in patenting it. But perhaps the most fascinating of all Perkins reactions to his find was his nearly instant recognition that the new dye had commercial possibilities. Perkin originally named his dye Tyrian Purple, but it later became commonly known as mauve (from the French for the plant used to make the colour violet). He asked advice of Scottish dye works owner Robert Pullar, who assured him that manufacturing the dye would be well worth it if the colour remained fast (i. e. would not fade) and the cost was relatively low. So, over the fierce objections of his mentor Hofmann, he left college to give birth to the modern chemical industry. With the help of his father and brother, Perkin set up a factory not far from London. Utilising the cheap and plentiful coal tar that was an almost unlimited byproduct of Londons gas street lighting, the dye works began producing the worlds first synthetically dyed material in 1857. The company received a commercial boost from the Empress Eugenie of France, when she decided the new colour flattered her. Very soon, mauve was the necessary shade for all the fashionable ladies in that country. Not to be outdone, Englands Queen Victoria also appeared in public wearing a mauve gown, thus making it all the rage in England as well. The dye was bold and fast, and the public clamoured for more. Perkin went back to the drawing board. Although Perkins fame was achieved and fortune assured by his first discovery, the chemist continued his research. Among other dyes he developed and introduced were aniline red (1859) and aniline black (1863) and, in the late 1860s, Perkins green. It is important to note that Perkins synthetic dye discoveries had outcomes far beyond the merely decorative. The dyes also became vital to medical research in many ways. For instance, they were used to stain previously invisible microbes and bacteria, allowing researchers to identify such bacilli as tuberculosis, cholera, and anthrax. Artificial dyes continue to play a crucial role today. And, in what would have been particularly pleasing to Perkin, their current use is in the search for a vaccine against malaria.", "hypothesis": "Perkin was still young when he made the discovery that made him rich and famous.", "gold_label": "entailment"}
{"uid": "id_684", "premise": "William Henry Perkin, The man who invented synthetic dyes. William Henry Perkin was born on March 12, 1838, in London, England. As a boy, Perkins curiosity prompted early interests in the arts, sciences, photography, and engineering. But it was a chance stumbling upon a run-down, yet functional, laboratory in his late grandfathers home that solidified the young mans enthusiasm for chemistry. As a student at the City of London School, Perkin became immersed in the study of chemistry. His talent and devotion to the subject were perceived by his teacher, Thomas Hall, who encouraged him to attend a series of lectures given by the eminent scientist Michael Faraday at the Royal Institution. Those speeches fired the young chemists enthusiasm further, and he later went on to attend the Royal College of Chemistry, which he succeeded in entering in 1853, at the age of 15. At the time of Perkins enrolment, the Royal College of Chemistry was headed by the noted German chemist August Wilhelm Hofmann. Perkins scientific gifts soon caught Hofmanns attention and, within two years, he became Hofmanns youngest assistant. Not long after that, Perkin made the scientific breakthrough that would bring him both fame and fortune. At the time, quinine was the only viable medical treatment for malaria. The drug is derived from the bark of the cinchona tree, native to South America, and by 1856 demand for the drug was surpassing the available supply. Thus, when Hofmann made some passing comments about the desirability of a synthetic substitute for quinine, it was unsurprising that his star pupil was moved to take up the challenge. During his vacation in 1856, Perkin spent his time in the laboratory on the top floor of his familys house. He was attempting to manufacture quinine from aniline, an inexpensive and readily available coal tar waste product. Despite his best efforts, however, he did not end up with quinine. Instead, he produced a mysterious dark sludge. Luckily, Perkins scientific training and nature prompted him to investigate the substance further. Incorporating potassium dichromate and alcohol into the aniline at various stages of the experimental process, he finally produced a deep purple solution. And, proving the truth of the famous scientist Louis Pasteurs words chance favours only the prepared mind, Perkin saw the potential of his unexpected find. Historically, textile dyes were made from such natural sources as plants and animal excretions. Some of these, such as the glandular mucus of snails, were difficult to obtain and outrageously expensive. Indeed, the purple colour extracted from a snail was once so costly in society at the time only the rich could afford it. Further, natural dyes tended to be muddy in hue and fade quickly. It was against this backdrop that Perkins discovery was made. Perkin quickly grasped that his purple solution could be used to colour fabric, thus making it the worlds first synthetic dye. Realising the importance of this breakthrough, he lost no time in patenting it. But perhaps the most fascinating of all Perkins reactions to his find was his nearly instant recognition that the new dye had commercial possibilities. Perkin originally named his dye Tyrian Purple, but it later became commonly known as mauve (from the French for the plant used to make the colour violet). He asked advice of Scottish dye works owner Robert Pullar, who assured him that manufacturing the dye would be well worth it if the colour remained fast (i. e. would not fade) and the cost was relatively low. So, over the fierce objections of his mentor Hofmann, he left college to give birth to the modern chemical industry. With the help of his father and brother, Perkin set up a factory not far from London. Utilising the cheap and plentiful coal tar that was an almost unlimited byproduct of Londons gas street lighting, the dye works began producing the worlds first synthetically dyed material in 1857. The company received a commercial boost from the Empress Eugenie of France, when she decided the new colour flattered her. Very soon, mauve was the necessary shade for all the fashionable ladies in that country. Not to be outdone, Englands Queen Victoria also appeared in public wearing a mauve gown, thus making it all the rage in England as well. The dye was bold and fast, and the public clamoured for more. Perkin went back to the drawing board. Although Perkins fame was achieved and fortune assured by his first discovery, the chemist continued his research. Among other dyes he developed and introduced were aniline red (1859) and aniline black (1863) and, in the late 1860s, Perkins green. It is important to note that Perkins synthetic dye discoveries had outcomes far beyond the merely decorative. The dyes also became vital to medical research in many ways. For instance, they were used to stain previously invisible microbes and bacteria, allowing researchers to identify such bacilli as tuberculosis, cholera, and anthrax. Artificial dyes continue to play a crucial role today. And, in what would have been particularly pleasing to Perkin, their current use is in the search for a vaccine against malaria.", "hypothesis": "Perkin was inspired by the discoveries of the famous scientist Louis Pasteur.", "gold_label": "neutral"}
{"uid": "id_685", "premise": "With increased demands on business executives to travel in the globalised economy, how do globe-trotting executives manager their travel demands? A highly invaluable resources tapped by senior executives is the use of one or more personal assistants. More than glorified receptionists, PAs hold considerable power in the work place, deciding who gains access to their employer and when, being privy to highly sensitive information and maintaining order in the executives absence. Having this extra helping hand can allow executives to focus on the more important tasks and objectives, allowing them to save time, effort and improve efficiency.", "hypothesis": "Personal assistants are expensive.", "gold_label": "neutral"}
{"uid": "id_686", "premise": "With increased demands on business executives to travel in the globalised economy, how do globe-trotting executives manager their travel demands? A highly invaluable resources tapped by senior executives is the use of one or more personal assistants. More than glorified receptionists, PAs hold considerable power in the work place, deciding who gains access to their employer and when, being privy to highly sensitive information and maintaining order in the executives absence. Having this extra helping hand can allow executives to focus on the more important tasks and objectives, allowing them to save time, effort and improve efficiency.", "hypothesis": "Personal assistants are glorified receptionists.", "gold_label": "contradiction"}
{"uid": "id_687", "premise": "With increased demands on business executives to travel in the globalised economy, how do globe-trotting executives manager their travel demands? A highly invaluable resources tapped by senior executives is the use of one or more personal assistants. More than glorified receptionists, PAs hold considerable power in the work place, deciding who gains access to their employer and when, being privy to highly sensitive information and maintaining order in the executives absence. Having this extra helping hand can allow executives to focus on the more important tasks and objectives, allowing them to save time, effort and improve efficiency.", "hypothesis": "Personal assistants are efficient.", "gold_label": "neutral"}
{"uid": "id_688", "premise": "With increased demands on business executives to travel in the globalised economy, how do globe-trotting executives manager their travel demands? A highly invaluable resources tapped by senior executives is the use of one or more personal assistants. More than glorified receptionists, PAs hold considerable power in the work place, deciding who gains access to their employer and when, being privy to highly sensitive information and maintaining order in the executives absence. Having this extra helping hand can allow executives to focus on the more important tasks and objectives, allowing them to save time, effort and improve efficiency.", "hypothesis": "Personal assistants are privy to sensitive information.", "gold_label": "entailment"}
{"uid": "id_689", "premise": "With more than 32 million smart phones in the United Kingdom alone, the number of mobile phone applications or apps is rapidly increasing. These apps are used for gaming, travel, shopping, and banking and soon the department of health will be encouraging the development of medical apps to help manage medical conditions. Potentially popular apps could include blood pressure monitors, blood sugar monitors and contraceptive choice apps. These apps could make managing disease far more convenient and efficient, improving the quality of life for millions in the UK.", "hypothesis": "Heart rate monitor is listed as a potential popular app", "gold_label": "neutral"}
{"uid": "id_690", "premise": "With more than 32 million smart phones in the United Kingdom alone, the number of mobile phone applications or apps is rapidly increasing. These apps are used for gaming, travel, shopping, and banking and soon the department of health will be encouraging the development of medical apps to help manage medical conditions. Potentially popular apps could include blood pressure monitors, blood sugar monitors and contraceptive choice apps. These apps could make managing disease far more convenient and efficient, improving the quality of life for millions in the UK.", "hypothesis": "Blood sugar monitor is listed as a potential popular app", "gold_label": "entailment"}
{"uid": "id_691", "premise": "With over half a billion citizens in the European Union, the stability of its food market is important. The Common Agricultural Policy (also known as CAP) is an EU initiative designed to provide farmers with the economic support to help them withstand the outcomes of unexpected natural events like heavy rains, floods, cold temperatures, and fires. For the CAP to improve, information regarding the current economic situation of farms across the EU is needed. As of January 4th 2010, each farm in the EU should provide a document called \"Farm Return\", containing two types of data: income assessment and a description of the farm's business operation. The EU then uses these data to predict the implications of changes made to the CAP on the farmers, as well as to understand the current situation better. The Farm Return's route from the farm to the EU begins with a local agency called the Liaison Agency. This agency then passes the report on to a National Committee, which hands it over to the EU.", "hypothesis": "The EU has been collecting data on farms since before January 4th 2010.", "gold_label": "neutral"}
{"uid": "id_692", "premise": "With over half a billion citizens in the European Union, the stability of its food market is important. The Common Agricultural Policy (also known as CAP) is an EU initiative designed to provide farmers with the economic support to help them withstand the outcomes of unexpected natural events like heavy rains, floods, cold temperatures, and fires. For the CAP to improve, information regarding the current economic situation of farms across the EU is needed. As of January 4th 2010, each farm in the EU should provide a document called \"Farm Return\", containing two types of data: income assessment and a description of the farm's business operation. The EU then uses these data to predict the implications of changes made to the CAP on the farmers, as well as to understand the current situation better. The Farm Return's route from the farm to the EU begins with a local agency called the Liaison Agency. This agency then passes the report on to a National Committee, which hands it over to the EU.", "hypothesis": "The Farm Return would be submitted by the farm to the National Committee, a local agency, which would then hand it over to the EU.", "gold_label": "contradiction"}
{"uid": "id_693", "premise": "With over half a billion citizens in the European Union, the stability of its food market is important. The Common Agricultural Policy (also known as CAP) is an EU initiative designed to provide farmers with the economic support to help them withstand the outcomes of unexpected natural events like heavy rains, floods, cold temperatures, and fires. For the CAP to improve, information regarding the current economic situation of farms across the EU is needed. As of January 4th 2010, each farm in the EU should provide a document called \"Farm Return\", containing two types of data: income assessment and a description of the farm's business operation. The EU then uses these data to predict the implications of changes made to the CAP on the farmers, as well as to understand the current situation better. The Farm Return's route from the farm to the EU begins with a local agency called the Liaison Agency. This agency then passes the report on to a National Committee, which hands it over to the EU.", "hypothesis": "The EU could use the data collected via the Farm Return to simulate potential consequences of different CAP policy scenarios.", "gold_label": "entailment"}
{"uid": "id_694", "premise": "With the rapid technological advancement today, bridges are becoming increasingly more sophisticated, and are spanning significantly greater distances. Earthquakes, however, remain a potential threat to these immense structures as they may do irreparable and costly damage to an important bridge. As a bridges major vulnerability to earth movement lies in its supportive structures, a promising solution has been found to be a self-anchored suspension bridge. This bridge design is one in which the pull of the cables is opposed by the push or the deck, thus eliminating the supporting anchorages.", "hypothesis": "The self-anchored suspension bridge is the established solution to the threat of the earthquake damage.", "gold_label": "contradiction"}
{"uid": "id_695", "premise": "With the rapid technological advancement today, bridges are becoming increasingly more sophisticated, and are spanning significantly greater distances. Earthquakes, however, remain a potential threat to these immense structures as they may do irreparable and costly damage to an important bridge. As a bridges major vulnerability to earth movement lies in its supportive structures, a promising solution has been found to be a self-anchored suspension bridge. This bridge design is one in which the pull of the cables is opposed by the push or the deck, thus eliminating the supporting anchorages.", "hypothesis": "A possible solution to the risk of earthquake damage is the self-anchored suspension bridge as the forces of the cables and the anchorages oppose each other.", "gold_label": "entailment"}
{"uid": "id_696", "premise": "With the rapid technological advancement today, bridges are becoming increasingly more sophisticated, and are spanning significantly greater distances. Earthquakes, however, remain a potential threat to these immense structures as they may do irreparable and costly damage to an important bridge. As a bridges major vulnerability to earth movement lies in its supportive structures, a promising solution has been found to be a self-anchored suspension bridge. This bridge design is one in which the pull of the cables is opposed by the push or the deck, thus eliminating the supporting anchorages.", "hypothesis": "Earthquakes inevitably cause costly damage to the bridges structure.", "gold_label": "neutral"}
{"uid": "id_697", "premise": "With the rapid technological advancement today, bridges are becoming increasingly more sophisticated, and are spanning significantly greater distances. Earthquakes, however, remain a potential threat to these immense structures as they may do irreparable and costly damage to an important bridge. As a bridges major vulnerability to earth movement lies in its supportive structures, a promising solution has been found to be a self-anchored suspension bridge. This bridge design is one in which the pull of the cables is opposed by the push or the deck, thus eliminating the supporting anchorages.", "hypothesis": "Modern bridges have different structural features to those built before technological advancement of today.", "gold_label": "neutral"}
{"uid": "id_698", "premise": "With the rapid technological advancement today, bridges are becoming increasingly more sophisticated, and are spanning significantly greater distances. Earthquakes, however, remain a potential threat to these immense structures as they may do irreparable and costly damage to an important bridge. As a bridges major vulnerability to earth movement lies in its supportive structures, a promising solution has been found to be a self-anchored suspension bridge. This bridge design is one in which the pull of the cables is opposed by the push or the deck, thus eliminating the supporting anchorages.", "hypothesis": "The elimination of the anchorages has been a proposed solution to the threat of damage caused by seismic activity.", "gold_label": "entailment"}
{"uid": "id_699", "premise": "With the rapid technological advancement today, bridges are becoming increasingly more sophisticated, and are spanning significantly greater distances. Earthquakes, however, remain a potential threat to these immense structures as they may do irreparable and costly damage to an important bridge. As a bridges major vulnerability to earth movement lies in its supportive structures, a promising solution has been found to be a self-anchored suspension bridge. This bridge design is one in which the pull of the cables is opposed by the push or the deck, thus elimination the supporting anchorages.", "hypothesis": "Modern bridges have different structural features to those built before the technological advancement of today.", "gold_label": "neutral"}
{"uid": "id_700", "premise": "With the rapid technological advancement today, bridges are becoming increasingly more sophisticated, and are spanning significantly greater distances. Earthquakes, however, remain a potential threat to these immense structures as they may do irreparable and costly damage to an important bridge. As a bridges major vulnerability to earth movement lies in its supportive structures, a promising solution has been found to be a self-anchored suspension bridge. This bridge design is one in which the pull of the cables is opposed by the push or the deck, thus elimination the supporting anchorages.", "hypothesis": "The elimination of the anchorages has been a proposed solution to the threat of damage caused by seismic activity.", "gold_label": "entailment"}
{"uid": "id_701", "premise": "With the rapid technological advancement today, bridges are becoming increasingly more sophisticated, and are spanning significantly greater distances. Earthquakes, however, remain a potential threat to these immense structures as they may do irreparable and costly damage to an important bridge. As a bridges major vulnerability to earth movement lies in its supportive structures, a promising solution has been found to be a self-anchored suspension bridge. This bridge design is one in which the pull of the cables is opposed by the push or the deck, thus elimination the supporting anchorages.", "hypothesis": "The self-anchored suspension bridge is established solution to the threat of earthquake damage", "gold_label": "contradiction"}
{"uid": "id_702", "premise": "With the rapid technological advancement today, bridges are becoming increasingly more sophisticated, and are spanning significantly greater distances. Earthquakes, however, remain a potential threat to these immense structures as they may do irreparable and costly damage to an important bridge. As a bridges major vulnerability to earth movement lies in its supportive structures, a promising solution has been found to be a self-anchored suspension bridge. This bridge design is one in which the pull of the cables is opposed by the push or the deck, thus elimination the supporting anchorages.", "hypothesis": "Earthquakes inevitably cause costly damage to the bridges structure.", "gold_label": "contradiction"}
{"uid": "id_703", "premise": "With the rapid technological advancement today, bridges are becoming increasingly more sophisticated, and are spanning significantly greater distances. Earthquakes, however, remain a potential threat to these immense structures as they may do irreparable and costly damage to an important bridge. As a bridges major vulnerability to earth movement lies in its supportive structures, a promising solution has been found to be a self-anchored suspension bridge. This bridge design is one in which the pull of the cables is opposed by the push or the deck, thus elimination the supporting anchorages.", "hypothesis": "A possible solution to the risk of earthquake damage is the self-anchored suspension bridge as the forces of cables and the anchorages oppose each other.", "gold_label": "contradiction"}
{"uid": "id_704", "premise": "Within the next decade, the weakening rural economy will be the biggest challenge faced by rural areas. Agriculture, which supplies a quarter of rural job opportunities, is experiencing a recession, while tourism provides fewer than half of the job opportunities provided by agriculture. However, rural manufacturing has developed dramatically in the past decade. Even so, fewer than one In every 20 people in rural areas are working in rural manufacturing. Rural manufacturing Is threatened by companies in industrial areas, because rural areas have a larger skilled worker team and better developed transportation system.", "hypothesis": "In the future, agriculture Is likely to provide more Job opportunities.", "gold_label": "contradiction"}
{"uid": "id_705", "premise": "Within the next decade, the weakening rural economy will be the biggest challenge faced by rural areas. Agriculture, which supplies a quarter of rural job opportunities, is experiencing a recession, while tourism provides fewer than half of the job opportunities provided by agriculture. However, rural manufacturing has developed dramatically in the past decade. Even so, fewer than one In every 20 people in rural areas are working in rural manufacturing. Rural manufacturing Is threatened by companies in industrial areas, because rural areas have a larger skilled worker team and better developed transportation system.", "hypothesis": "In rural areas, manufacture industry provides the fewest job opportunities.", "gold_label": "neutral"}
{"uid": "id_706", "premise": "Within the next decade, the weakening rural economy will be the biggest challenge faced by rural areas. Agriculture, which supplies a quarter of rural job opportunities, is experiencing a recession, while tourism provides fewer than half of the job opportunities provided by agriculture. However, rural manufacturing has developed dramatically in the past decade. Even so, fewer than one In every 20 people in rural areas are working in rural manufacturing. Rural manufacturing Is threatened by companies in industrial areas, because rural areas have a larger skilled worker team and better developed transportation system.", "hypothesis": "In the next decade, rural economy is expected to become stronger.", "gold_label": "neutral"}
{"uid": "id_707", "premise": "Without exception, living non-human primates habitually more around on all fours, or quadrupedally, when they are on the ground. Scientists generally assume therefore that the last common ancestor of humans and chimpanzees (our closest living relative) was also a quadrupted. Exactly when the last common ancestor lived is unknown, but clear indications of bipedalism, the trait that distinguishes ancient humans from other apes, are evident in the oldest known species of Australopithecus, which lived in Africa roughly four millions years ago.", "hypothesis": "Bipedal apes are more evolutionarily advantaged than quadrupedal ones.", "gold_label": "neutral"}
{"uid": "id_708", "premise": "Without exception, living non-human primates habitually more around on all fours, or quadrupedally, when they are on the ground. Scientists generally assume therefore that the last common ancestor of humans and chimpanzees (our closest living relative) was also a quadrupted. Exactly when the last common ancestor lived is unknown, but clear indications of bipedalism, the trait that distinguishes ancient humans from other apes, are evident in the oldest known species of Australopithecus, which lived in Africa roughly four millions years ago.", "hypothesis": "Australopithecus is as closely related to ancient man as to the chimpanzee.", "gold_label": "contradiction"}
{"uid": "id_709", "premise": "Without exception, living non-human primates habitually more around on all fours, or quadrupedally, when they are on the ground. Scientists generally assume therefore that the last common ancestor of humans and chimpanzees (our closest living relative) was also a quadrupted. Exactly when the last common ancestor lived is unknown, but clear indications of bipedalism, the trait that distinguishes ancient humans from other apes, are evident in the oldest known species of Australopithecus, which lived in Africa roughly four millions years ago.", "hypothesis": "Bipedalism is the main trait that distinguishes ancient humans from Australopithecus.", "gold_label": "contradiction"}
{"uid": "id_710", "premise": "Without exception, living non-human primates habitually more around on all fours, or quadrupedally, when they are on the ground. Scientists generally assume therefore that the last common ancestor of humans and chimpanzees (our closest living relative) was also a quadrupted. Exactly when the last common ancestor lived is unknown, but clear indications of bipedalism, the trait that distinguishes ancient humans from other apes, are evident in the oldest known species of Australopithecus, which lived in Africa roughly four millions years ago.", "hypothesis": "Australopithecus is as closely related to ancient man as to the chimpanzee.", "gold_label": "neutral"}
{"uid": "id_711", "premise": "Words fail them It seems companies will soon begin to say goodbye to the written word. The basic unit of communication will no longer be typed out in e-mails. It will be shot in pictures and shown on video. Companies have already discovered that the written word is failing them. Its feebleness compared with the moving image was rammed home in 2010 when the sight of BP's oil spewing out into the Gulf of Mexico on YouTube sent a message to the world far more compelling than any written statement could ever be. If the word has become weak at conveying big corporate messages, it has become even weaker at conveying small ones. For years the in-boxes of all office workers have been overflowing with unread e-mails. But managers will do something about it and desist from communicating with staff in this way. E-mail will still exist as a way of talking to one person at a time, but as a means of mass communication it will be finished. Companies will find instead that to get a message over to employees, customers, shareholders and the outside world, video is far more effective. In the past three years video has come from nothing to make up nearly half of internet traffic; in another three, it is likely to be more than three-quarters. So far corporations have taken a back seat in this growth, but they will soon need to climb into the front and start to drive it. This shift in communications will have three important effects. It will change the sort of person who makes it to the corner office. It will alter the way that businesses are managed. And it will shift the position corporations occupy in society and possibly make us like some of them just a little bit more. The new corporate leaders will no longer be pen pushers and bean counters. The 20-year reign of faceless bosses will come to an end. Charisma will be back in: all successful business chiefs will have to be storytellers and performers. Just as political leaders have long had to be dynamite on TV to stand much hope of election or survival, so too will corporate leaders. They must be able to sell not only their vision of their companies but their vision of themselves. The new big boss will be expected to set an example; any leaders showing signs of human frailty will be out on their ears. The moral majority will tighten its hold on corporate life, first in America, but then elsewhere too. With this shift will come a change in management style. Numbers and facts will be supplanted by appeals to emotion to make employees and customers do what they are told. The businessperson's emotion may be no more genuine than the politician's, but successful bosses will get good at faking it. Others will struggle: prepare to cringe in as corporate leaders spout a lot of phoney stuff that used to look bad enough when written down, but will sound even worse spoken. One good consequence of the change, however, will be a greater clarity in the way companies think about their businesses. The written word was a forgiving medium for over-complicated, ill-conceived messages. Video demands simplicity. The best companies will use this to their advantage by thinking through more rigorously what it is they are trying to say and do.", "hypothesis": "A business leaders ability to sell themselves will become more important.", "gold_label": "entailment"}
{"uid": "id_712", "premise": "Words fail them It seems companies will soon begin to say goodbye to the written word. The basic unit of communication will no longer be typed out in e-mails. It will be shot in pictures and shown on video. Companies have already discovered that the written word is failing them. Its feebleness compared with the moving image was rammed home in 2010 when the sight of BP's oil spewing out into the Gulf of Mexico on YouTube sent a message to the world far more compelling than any written statement could ever be. If the word has become weak at conveying big corporate messages, it has become even weaker at conveying small ones. For years the in-boxes of all office workers have been overflowing with unread e-mails. But managers will do something about it and desist from communicating with staff in this way. E-mail will still exist as a way of talking to one person at a time, but as a means of mass communication it will be finished. Companies will find instead that to get a message over to employees, customers, shareholders and the outside world, video is far more effective. In the past three years video has come from nothing to make up nearly half of internet traffic; in another three, it is likely to be more than three-quarters. So far corporations have taken a back seat in this growth, but they will soon need to climb into the front and start to drive it. This shift in communications will have three important effects. It will change the sort of person who makes it to the corner office. It will alter the way that businesses are managed. And it will shift the position corporations occupy in society and possibly make us like some of them just a little bit more. The new corporate leaders will no longer be pen pushers and bean counters. The 20-year reign of faceless bosses will come to an end. Charisma will be back in: all successful business chiefs will have to be storytellers and performers. Just as political leaders have long had to be dynamite on TV to stand much hope of election or survival, so too will corporate leaders. They must be able to sell not only their vision of their companies but their vision of themselves. The new big boss will be expected to set an example; any leaders showing signs of human frailty will be out on their ears. The moral majority will tighten its hold on corporate life, first in America, but then elsewhere too. With this shift will come a change in management style. Numbers and facts will be supplanted by appeals to emotion to make employees and customers do what they are told. The businessperson's emotion may be no more genuine than the politician's, but successful bosses will get good at faking it. Others will struggle: prepare to cringe in as corporate leaders spout a lot of phoney stuff that used to look bad enough when written down, but will sound even worse spoken. One good consequence of the change, however, will be a greater clarity in the way companies think about their businesses. The written word was a forgiving medium for over-complicated, ill-conceived messages. Video demands simplicity. The best companies will use this to their advantage by thinking through more rigorously what it is they are trying to say and do.", "hypothesis": "The new bosses will have to be physically stronger.", "gold_label": "neutral"}
{"uid": "id_713", "premise": "Words fail them It seems companies will soon begin to say goodbye to the written word. The basic unit of communication will no longer be typed out in e-mails. It will be shot in pictures and shown on video. Companies have already discovered that the written word is failing them. Its feebleness compared with the moving image was rammed home in 2010 when the sight of BP's oil spewing out into the Gulf of Mexico on YouTube sent a message to the world far more compelling than any written statement could ever be. If the word has become weak at conveying big corporate messages, it has become even weaker at conveying small ones. For years the in-boxes of all office workers have been overflowing with unread e-mails. But managers will do something about it and desist from communicating with staff in this way. E-mail will still exist as a way of talking to one person at a time, but as a means of mass communication it will be finished. Companies will find instead that to get a message over to employees, customers, shareholders and the outside world, video is far more effective. In the past three years video has come from nothing to make up nearly half of internet traffic; in another three, it is likely to be more than three-quarters. So far corporations have taken a back seat in this growth, but they will soon need to climb into the front and start to drive it. This shift in communications will have three important effects. It will change the sort of person who makes it to the corner office. It will alter the way that businesses are managed. And it will shift the position corporations occupy in society and possibly make us like some of them just a little bit more. The new corporate leaders will no longer be pen pushers and bean counters. The 20-year reign of faceless bosses will come to an end. Charisma will be back in: all successful business chiefs will have to be storytellers and performers. Just as political leaders have long had to be dynamite on TV to stand much hope of election or survival, so too will corporate leaders. They must be able to sell not only their vision of their companies but their vision of themselves. The new big boss will be expected to set an example; any leaders showing signs of human frailty will be out on their ears. The moral majority will tighten its hold on corporate life, first in America, but then elsewhere too. With this shift will come a change in management style. Numbers and facts will be supplanted by appeals to emotion to make employees and customers do what they are told. The businessperson's emotion may be no more genuine than the politician's, but successful bosses will get good at faking it. Others will struggle: prepare to cringe in as corporate leaders spout a lot of phoney stuff that used to look bad enough when written down, but will sound even worse spoken. One good consequence of the change, however, will be a greater clarity in the way companies think about their businesses. The written word was a forgiving medium for over-complicated, ill-conceived messages. Video demands simplicity. The best companies will use this to their advantage by thinking through more rigorously what it is they are trying to say and do.", "hypothesis": "Business leaders will have to be seen in public.", "gold_label": "entailment"}
{"uid": "id_714", "premise": "Words fail them It seems companies will soon begin to say goodbye to the written word. The basic unit of communication will no longer be typed out in e-mails. It will be shot in pictures and shown on video. Companies have already discovered that the written word is failing them. Its feebleness compared with the moving image was rammed home in 2010 when the sight of BP's oil spewing out into the Gulf of Mexico on YouTube sent a message to the world far more compelling than any written statement could ever be. If the word has become weak at conveying big corporate messages, it has become even weaker at conveying small ones. For years the in-boxes of all office workers have been overflowing with unread e-mails. But managers will do something about it and desist from communicating with staff in this way. E-mail will still exist as a way of talking to one person at a time, but as a means of mass communication it will be finished. Companies will find instead that to get a message over to employees, customers, shareholders and the outside world, video is far more effective. In the past three years video has come from nothing to make up nearly half of internet traffic; in another three, it is likely to be more than three-quarters. So far corporations have taken a back seat in this growth, but they will soon need to climb into the front and start to drive it. This shift in communications will have three important effects. It will change the sort of person who makes it to the corner office. It will alter the way that businesses are managed. And it will shift the position corporations occupy in society and possibly make us like some of them just a little bit more. The new corporate leaders will no longer be pen pushers and bean counters. The 20-year reign of faceless bosses will come to an end. Charisma will be back in: all successful business chiefs will have to be storytellers and performers. Just as political leaders have long had to be dynamite on TV to stand much hope of election or survival, so too will corporate leaders. They must be able to sell not only their vision of their companies but their vision of themselves. The new big boss will be expected to set an example; any leaders showing signs of human frailty will be out on their ears. The moral majority will tighten its hold on corporate life, first in America, but then elsewhere too. With this shift will come a change in management style. Numbers and facts will be supplanted by appeals to emotion to make employees and customers do what they are told. The businessperson's emotion may be no more genuine than the politician's, but successful bosses will get good at faking it. Others will struggle: prepare to cringe in as corporate leaders spout a lot of phoney stuff that used to look bad enough when written down, but will sound even worse spoken. One good consequence of the change, however, will be a greater clarity in the way companies think about their businesses. The written word was a forgiving medium for over-complicated, ill-conceived messages. Video demands simplicity. The best companies will use this to their advantage by thinking through more rigorously what it is they are trying to say and do.", "hypothesis": "Large corporations are already using video extensively.", "gold_label": "contradiction"}
{"uid": "id_715", "premise": "Words fail them It seems companies will soon begin to say goodbye to the written word. The basic unit of communication will no longer be typed out in e-mails. It will be shot in pictures and shown on video. Companies have already discovered that the written word is failing them. Its feebleness compared with the moving image was rammed home in 2010 when the sight of BP's oil spewing out into the Gulf of Mexico on YouTube sent a message to the world far more compelling than any written statement could ever be. If the word has become weak at conveying big corporate messages, it has become even weaker at conveying small ones. For years the in-boxes of all office workers have been overflowing with unread e-mails. But managers will do something about it and desist from communicating with staff in this way. E-mail will still exist as a way of talking to one person at a time, but as a means of mass communication it will be finished. Companies will find instead that to get a message over to employees, customers, shareholders and the outside world, video is far more effective. In the past three years video has come from nothing to make up nearly half of internet traffic; in another three, it is likely to be more than three-quarters. So far corporations have taken a back seat in this growth, but they will soon need to climb into the front and start to drive it. This shift in communications will have three important effects. It will change the sort of person who makes it to the corner office. It will alter the way that businesses are managed. And it will shift the position corporations occupy in society and possibly make us like some of them just a little bit more. The new corporate leaders will no longer be pen pushers and bean counters. The 20-year reign of faceless bosses will come to an end. Charisma will be back in: all successful business chiefs will have to be storytellers and performers. Just as political leaders have long had to be dynamite on TV to stand much hope of election or survival, so too will corporate leaders. They must be able to sell not only their vision of their companies but their vision of themselves. The new big boss will be expected to set an example; any leaders showing signs of human frailty will be out on their ears. The moral majority will tighten its hold on corporate life, first in America, but then elsewhere too. With this shift will come a change in management style. Numbers and facts will be supplanted by appeals to emotion to make employees and customers do what they are told. The businessperson's emotion may be no more genuine than the politician's, but successful bosses will get good at faking it. Others will struggle: prepare to cringe in as corporate leaders spout a lot of phoney stuff that used to look bad enough when written down, but will sound even worse spoken. One good consequence of the change, however, will be a greater clarity in the way companies think about their businesses. The written word was a forgiving medium for over-complicated, ill-conceived messages. Video demands simplicity. The best companies will use this to their advantage by thinking through more rigorously what it is they are trying to say and do.", "hypothesis": "We will probably like the managers of corporations a lot more.", "gold_label": "contradiction"}
{"uid": "id_716", "premise": "Work-related stress is one of the biggest causes of sick leave in the UK. If you've noticed you always seem to be rushing about, or miss meal breaks, take work home or dont have enough time for relaxation, seeing your family or for exercise, then you may well find yourself under stress, especially at work. There is often no single cause of work-related stress, but it can be caused by poor working conditions, long hours, relationship problems with colleagues, or lack of job security. Stress is often the result of a combination of these factors that builds up over time. Work-related stress can result in both physical problems such as headaches, muscular tension, back or neck pain, tiredness, digestive problems and sweating; or emotional problems, such as a lower sex drive, feelings of inadequacy, irritability and lack of concentration. According to recent surveys, one in six of the UK working population said their job is very stressful, and thirty percent of men said that the demands of their job interfere with their private lives.", "hypothesis": "If you spend more time with your family, you will not suffer from stress.", "gold_label": "neutral"}
{"uid": "id_717", "premise": "Work-related stress is one of the biggest causes of sick leave in the UK. If you've noticed you always seem to be rushing about, or miss meal breaks, take work home or dont have enough time for relaxation, seeing your family or for exercise, then you may well find yourself under stress, especially at work. There is often no single cause of work-related stress, but it can be caused by poor working conditions, long hours, relationship problems with colleagues, or lack of job security. Stress is often the result of a combination of these factors that builds up over time. Work-related stress can result in both physical problems such as headaches, muscular tension, back or neck pain, tiredness, digestive problems and sweating; or emotional problems, such as a lower sex drive, feelings of inadequacy, irritability and lack of concentration. According to recent surveys, one in six of the UK working population said their job is very stressful, and thirty percent of men said that the demands of their job interfere with their private lives.", "hypothesis": "One in six working men say their job is very stressful.", "gold_label": "neutral"}
{"uid": "id_718", "premise": "Work-related stress is one of the biggest causes of sick leave in the UK. If you've noticed you always seem to be rushing about, or miss meal breaks, take work home or dont have enough time for relaxation, seeing your family or for exercise, then you may well find yourself under stress, especially at work. There is often no single cause of work-related stress, but it can be caused by poor working conditions, long hours, relationship problems with colleagues, or lack of job security. Stress is often the result of a combination of these factors that builds up over time. Work-related stress can result in both physical problems such as headaches, muscular tension, back or neck pain, tiredness, digestive problems and sweating; or emotional problems, such as a lower sex drive, feelings of inadequacy, irritability and lack of concentration. According to recent surveys, one in six of the UK working population said their job is very stressful, and thirty percent of men said that the demands of their job interfere with their private lives.", "hypothesis": "Work-related stress can result in tiredness and a lack of concentration.", "gold_label": "entailment"}
{"uid": "id_719", "premise": "Work-related stress is one of the biggest causes of sick leave in the UK. If you've noticed you always seem to be rushing about, or miss meal breaks, take work home or dont have enough time for relaxation, seeing your family or for exercise, then you may well find yourself under stress, especially at work. There is often no single cause of work-related stress, but it can be caused by poor working conditions, long hours, relationship problems with colleagues, or lack of job security. Stress is often the result of a combination of these factors that builds up over time. Work-related stress can result in both physical problems such as headaches, muscular tension, back or neck pain, tiredness, digestive problems and sweating; or emotional problems, such as a lower sex drive, feelings of inadequacy, irritability and lack of concentration. According to recent surveys, one in six of the UK working population said their job is very stressful, and thirty percent of men said that the demands of their job interfere with their private lives.", "hypothesis": "Stress at work is often caused by relationship problems with your partner.", "gold_label": "neutral"}
{"uid": "id_720", "premise": "Workers are becoming increasingly concerned about company relocation due to its association with employee distress and isolation, which can be caused by issues such as the management of property transitions and loss of community ties. Furthermore, moving home can put a strain on workers financial resources and close relationships, especially for those working parents who may feel guilty about moving children to new schools. Regardless of the disruption created, some individuals are very willing to relocate, due to the potential for enhanced career prospects and long-term financial stability.", "hypothesis": "The potential benefits of job relocation are seen, by some, to be worth the associated distress and strain.", "gold_label": "entailment"}
{"uid": "id_721", "premise": "Workers are becoming increasingly concerned about company relocation due to its association with employee distress and isolation, which can be caused by issues such as the management of property transitions and loss of community ties. Furthermore, moving home can put a strain on workers financial resources and close relationships, especially for those working parents who may feel guilty about moving children to new schools. Regardless of the disruption created, some individuals are very willing to relocate, due to the potential for enhanced career prospects and long-term financial stability.", "hypothesis": "The majority of employees feel isolated following relocation.", "gold_label": "neutral"}
{"uid": "id_722", "premise": "Workers are becoming increasingly concerned about company relocation due to its association with employee distress and isolation, which can be caused by issues such as the management of property transitions and loss of community ties. Furthermore, moving home can put a strain on workers financial resources and close relationships, especially for those working parents who may feel guilty about moving children to new schools. Regardless of the disruption created, some individuals are very willing to relocate, due to the potential for enhanced career prospects and long-term financial stability.", "hypothesis": "Some people may feel guilty about the consequences of relocating.", "gold_label": "entailment"}
{"uid": "id_723", "premise": "Workers are becoming increasingly concerned about company relocation due to its association with employee distress and isolation, which can be caused by issues such as the management of property transitions and loss of community ties. Furthermore, moving home can put a strain on workers financial resources and close relationships, especially for those working parents who may feel guilty about moving children to new schools. Regardless of the disruption created, some individuals are very willing to relocate, due to the potential for enhanced career prospects and long-term financial stability.", "hypothesis": "Company relocation has increased.", "gold_label": "neutral"}
{"uid": "id_724", "premise": "Workers are becoming increasingly concerned about company relocation due to its association with employee distress and isolation, which can be caused by issues such as the management of property transitions and loss of community ties. Furthermore, moving home can put a strain on workers financial resources and close relationships, especially for those working parents who may feel guilty about moving children to new schools. Regardless of the disruption created, some individuals are very willing to relocate, due to the potential for enhanced career prospects and long; term financial stability.", "hypothesis": "Some people may feel guilty about the consequences of relocating.", "gold_label": "entailment"}
{"uid": "id_725", "premise": "Workers are becoming increasingly concerned about company relocation due to its association with employee distress and isolation, which can be caused by issues such as the management of property transitions and loss of community ties. Furthermore, moving home can put a strain on workers financial resources and close relationships, especially for those working parents who may feel guilty about moving children to new schools. Regardless of the disruption created, some individuals are very willing to relocate, due to the potential for enhanced career prospects and long; term financial stability.", "hypothesis": "Company relocation has increased.", "gold_label": "neutral"}
{"uid": "id_726", "premise": "Workers are becoming increasingly concerned about company relocation due to its association with employee distress and isolation, which can be caused by issues such as the management of property transitions and loss of community ties. Furthermore, moving home can put a strain on workers financial resources and close relationships, especially for those working parents who may feel guilty about moving children to new schools. Regardless of the disruption created, some individuals are very willing to relocate, due to the potential for enhanced career prospects and long; term financial stability.", "hypothesis": "The potential benefits of job relocation are seen, by some, to be worth the associated distress and strain.", "gold_label": "entailment"}
{"uid": "id_727", "premise": "Workers now caught by the top rate of income tax include university lecturers, mid-ranking civil servants and officers of local authorities, specialist nurses and sisters, police inspectors and senior officers in the ambulance and fire service. This trend means that an extra 3.5 million workers are liable for the higher rate of tax compared to 10 years ago. More than 1 million extra people pay tax at the higher rate because growth in pay has increased faster than inflation-linked tax allowances. Over the period, these allowances have been increased in line with or less than inflation, while wages have increased at a rate of more than inflation. As a result, every year more people find themselves taxed at the highest rate for the first time. The Treasury defends the trend on the basis that the increase in numbers is a result of rising incomes and living standards. Critics point out that the higher rate of tax begins at a far lower point that in other countries. In Spain, the highest rate of tax is not applied until income is 2.5 times the average wage, while in the UK the highest rate is paid by anyone who earns 1.3 times the average wage.", "hypothesis": "Linking tax allowances to inflation has caused over 3 million people to pay the higher rate of tax.", "gold_label": "contradiction"}
{"uid": "id_728", "premise": "Workers now caught by the top rate of income tax include university lecturers, mid-ranking civil servants and officers of local authorities, specialist nurses and sisters, police inspectors and senior officers in the ambulance and fire service. This trend means that an extra 3.5 million workers are liable for the higher rate of tax compared to 10 years ago. More than 1 million extra people pay tax at the higher rate because growth in pay has increased faster than inflation-linked tax allowances. Over the period, these allowances have been increased in line with or less than inflation, while wages have increased at a rate of more than inflation. As a result, every year more people find themselves taxed at the highest rate for the first time. The Treasury defends the trend on the basis that the increase in numbers is a result of rising incomes and living standards. Critics point out that the higher rate of tax begins at a far lower point that in other countries. In Spain, the highest rate of tax is not applied until income is 2.5 times the average wage, while in the UK the highest rate is paid by anyone who earns 1.3 times the average wage.", "hypothesis": "The cause of the increase can correctly be summarized as growth in pay having outstripped inflation-linked tax allowances, so the number of people paying tax at the highest rate has increased.", "gold_label": "entailment"}
{"uid": "id_729", "premise": "Workers now caught by the top rate of income tax include university lecturers, mid-ranking civil servants and officers of local authorities, specialist nurses and sisters, police inspectors and senior officers in the ambulance and fire service. This trend means that an extra 3.5 million workers are liable for the higher rate of tax compared to 10 years ago. More than 1 million extra people pay tax at the higher rate because growth in pay has increased faster than inflation-linked tax allowances. Over the period, these allowances have been increased in line with or less than inflation, while wages have increased at a rate of more than inflation. As a result, every year more people find themselves taxed at the highest rate for the first time. The Treasury defends the trend on the basis that the increase in numbers is a result of rising incomes and living standards. Critics point out that the higher rate of tax begins at a far lower point that in other countries. In Spain, the highest rate of tax is not applied until income is 2.5 times the average wage, while in the UK the highest rate is paid by anyone who earns 1.3 times the average wage.", "hypothesis": "The trend to which the passage refers is of wages increasing at a rate higher than inflation.", "gold_label": "contradiction"}
{"uid": "id_730", "premise": "Working in the movies When people ask French translator Virginie Verdier what she does for a living, it must be tempting to say enigmatically: Oh me? Im in the movies. Its strictly true, but her starring role is behind the scenes. As translating goes, it doesnt get more entertaining or glamorous than subtitling films. If youre very lucky, you get to work on the new blockbuster films before theyre in the cinema, and if youre just plain lucky, you get to work on the blockbuster movies that are going to video or DVD. The process starts when you get the original script and a tape. We would start with translating and adapting the film script. The next step is what we call timing, which means synchronising the subtitles to the dialogue and pictures. This task requires discipline. You play the film, listen to the voice and the subtitles are up on your screen ready to be timed. You insert your subtitle when you hear the corresponding dialogue and delete . it when the dialogue finishes. The video tape carries a time code which runs in hours, minutes, seconds and frames. Think of it as a clock. The subtitling unit has an insert key to capture the time code where you want the subtitle to appear. When you press the delete key, it captures the time code where you want the subtitle to disappear. So each subtitle would Subtitling is an exacting part of the translation profession. Melanie Leyshon talks to Virginie Verdier of London translation company VSI about the glamour and the grind. Virginie is quick to point out that this is as exacting as any translating job. You work hard. Its not all entertainment as you are doing the translating. You need all the skills of a good translator and those of a top-notch editor. You have to be precise and, of course, much more concise than in traditional translation work. have an in point and an out point which represent the exact time when the subtitle comes in and goes out. This process is then followed by a manual review, subtitle by subtitle, and time- codes are adjusted to improve synchronisation and respect shot changes. This process involves playing the film literally frame by frame as it is essential the subtitles respect the visual rhythm of the film. Different subtitlers use different techniques. I would go through the film and do the whole translation and then go right back from the beginning and start the timing process. But you could do it in different stages, translate lets say 20 minutes of the film, then time this section and translate the next 20 minutes, and so on. Its just a different method. For multi-lingual projects, the timing is done first to create what is called a spotting list, a subtitle template, which is in effect a list of English subtitles pre-timed and edited for translation purposes. This is then translated and the timing is adapted to the target language with the help of the translator for quality control. Like any translation work, you cant hurry subtitling, says Virginie. If subtitles are translated and timed in a rush, the quality will be affected and it will show. Mistakes usually occur when the translator does not master the source language and misunderstands the original dialogue. Our work also involves checking and reworking subtitles when the translation is not up to standard. However, the reason for redoing subtitles is not just because of poor quality translation. We may need to adapt subtitles to a new version of the film: the time code may be different. The film may have been edited or the subtitles may have been created for the cinema rather than video. If subtitles were done for cinema on 35mm, we would need to reformat the timing for video, as subtitles could be out of synch or too fast. If the translation is good, we would obviously respect the work of the original translator. On a more practical level, there are general subtitling rules to follow, says Virginie. Subtitles should appear at the bottom of the screen and usually in the centre. She says that different countries use different standards and rules. In Scandinavian countries and Holland, for example, subtitles are traditionally left justified. Characters usually appear in white with a thin black border for easy reading against a white or light background. We can also use different colours for each speaker when subtitling for the hearing impaired. Subtitles should have a maximum of two lines and the maximum number of characters on each line should be between 32 and 39. Our company standard is 37 (different companies and countries have different standards). Translators often have a favourite genre, whether its war films, musicals, comedies (one of the most difficult because of the subtleties and nuances of comedy in different countries), drama or corporate programmes. Each requires a certain tone and style. VSI employs American subtitlers, which is incredibly useful as many of the films we subtitle are American, says Virginie. For an English person, it would not be so easy to understand the meaning behind typically American expressions, and vice-versa.", "hypothesis": "For translators, all subtitling work on films is desirable.", "gold_label": "entailment"}
{"uid": "id_731", "premise": "Working in the movies When people ask French translator Virginie Verdier what she does for a living, it must be tempting to say enigmatically: Oh me? Im in the movies. Its strictly true, but her starring role is behind the scenes. As translating goes, it doesnt get more entertaining or glamorous than subtitling films. If youre very lucky, you get to work on the new blockbuster films before theyre in the cinema, and if youre just plain lucky, you get to work on the blockbuster movies that are going to video or DVD. The process starts when you get the original script and a tape. We would start with translating and adapting the film script. The next step is what we call timing, which means synchronising the subtitles to the dialogue and pictures. This task requires discipline. You play the film, listen to the voice and the subtitles are up on your screen ready to be timed. You insert your subtitle when you hear the corresponding dialogue and delete . it when the dialogue finishes. The video tape carries a time code which runs in hours, minutes, seconds and frames. Think of it as a clock. The subtitling unit has an insert key to capture the time code where you want the subtitle to appear. When you press the delete key, it captures the time code where you want the subtitle to disappear. So each subtitle would Subtitling is an exacting part of the translation profession. Melanie Leyshon talks to Virginie Verdier of London translation company VSI about the glamour and the grind. Virginie is quick to point out that this is as exacting as any translating job. You work hard. Its not all entertainment as you are doing the translating. You need all the skills of a good translator and those of a top-notch editor. You have to be precise and, of course, much more concise than in traditional translation work. have an in point and an out point which represent the exact time when the subtitle comes in and goes out. This process is then followed by a manual review, subtitle by subtitle, and time- codes are adjusted to improve synchronisation and respect shot changes. This process involves playing the film literally frame by frame as it is essential the subtitles respect the visual rhythm of the film. Different subtitlers use different techniques. I would go through the film and do the whole translation and then go right back from the beginning and start the timing process. But you could do it in different stages, translate lets say 20 minutes of the film, then time this section and translate the next 20 minutes, and so on. Its just a different method. For multi-lingual projects, the timing is done first to create what is called a spotting list, a subtitle template, which is in effect a list of English subtitles pre-timed and edited for translation purposes. This is then translated and the timing is adapted to the target language with the help of the translator for quality control. Like any translation work, you cant hurry subtitling, says Virginie. If subtitles are translated and timed in a rush, the quality will be affected and it will show. Mistakes usually occur when the translator does not master the source language and misunderstands the original dialogue. Our work also involves checking and reworking subtitles when the translation is not up to standard. However, the reason for redoing subtitles is not just because of poor quality translation. We may need to adapt subtitles to a new version of the film: the time code may be different. The film may have been edited or the subtitles may have been created for the cinema rather than video. If subtitles were done for cinema on 35mm, we would need to reformat the timing for video, as subtitles could be out of synch or too fast. If the translation is good, we would obviously respect the work of the original translator. On a more practical level, there are general subtitling rules to follow, says Virginie. Subtitles should appear at the bottom of the screen and usually in the centre. She says that different countries use different standards and rules. In Scandinavian countries and Holland, for example, subtitles are traditionally left justified. Characters usually appear in white with a thin black border for easy reading against a white or light background. We can also use different colours for each speaker when subtitling for the hearing impaired. Subtitles should have a maximum of two lines and the maximum number of characters on each line should be between 32 and 39. Our company standard is 37 (different companies and countries have different standards). Translators often have a favourite genre, whether its war films, musicals, comedies (one of the most difficult because of the subtleties and nuances of comedy in different countries), drama or corporate programmes. Each requires a certain tone and style. VSI employs American subtitlers, which is incredibly useful as many of the films we subtitle are American, says Virginie. For an English person, it would not be so easy to understand the meaning behind typically American expressions, and vice-versa.", "hypothesis": "Some subtitling techniques work better than others.", "gold_label": "contradiction"}
{"uid": "id_732", "premise": "Working in the movies When people ask French translator Virginie Verdier what she does for a living, it must be tempting to say enigmatically: Oh me? Im in the movies. Its strictly true, but her starring role is behind the scenes. As translating goes, it doesnt get more entertaining or glamorous than subtitling films. If youre very lucky, you get to work on the new blockbuster films before theyre in the cinema, and if youre just plain lucky, you get to work on the blockbuster movies that are going to video or DVD. The process starts when you get the original script and a tape. We would start with translating and adapting the film script. The next step is what we call timing, which means synchronising the subtitles to the dialogue and pictures. This task requires discipline. You play the film, listen to the voice and the subtitles are up on your screen ready to be timed. You insert your subtitle when you hear the corresponding dialogue and delete . it when the dialogue finishes. The video tape carries a time code which runs in hours, minutes, seconds and frames. Think of it as a clock. The subtitling unit has an insert key to capture the time code where you want the subtitle to appear. When you press the delete key, it captures the time code where you want the subtitle to disappear. So each subtitle would Subtitling is an exacting part of the translation profession. Melanie Leyshon talks to Virginie Verdier of London translation company VSI about the glamour and the grind. Virginie is quick to point out that this is as exacting as any translating job. You work hard. Its not all entertainment as you are doing the translating. You need all the skills of a good translator and those of a top-notch editor. You have to be precise and, of course, much more concise than in traditional translation work. have an in point and an out point which represent the exact time when the subtitle comes in and goes out. This process is then followed by a manual review, subtitle by subtitle, and time- codes are adjusted to improve synchronisation and respect shot changes. This process involves playing the film literally frame by frame as it is essential the subtitles respect the visual rhythm of the film. Different subtitlers use different techniques. I would go through the film and do the whole translation and then go right back from the beginning and start the timing process. But you could do it in different stages, translate lets say 20 minutes of the film, then time this section and translate the next 20 minutes, and so on. Its just a different method. For multi-lingual projects, the timing is done first to create what is called a spotting list, a subtitle template, which is in effect a list of English subtitles pre-timed and edited for translation purposes. This is then translated and the timing is adapted to the target language with the help of the translator for quality control. Like any translation work, you cant hurry subtitling, says Virginie. If subtitles are translated and timed in a rush, the quality will be affected and it will show. Mistakes usually occur when the translator does not master the source language and misunderstands the original dialogue. Our work also involves checking and reworking subtitles when the translation is not up to standard. However, the reason for redoing subtitles is not just because of poor quality translation. We may need to adapt subtitles to a new version of the film: the time code may be different. The film may have been edited or the subtitles may have been created for the cinema rather than video. If subtitles were done for cinema on 35mm, we would need to reformat the timing for video, as subtitles could be out of synch or too fast. If the translation is good, we would obviously respect the work of the original translator. On a more practical level, there are general subtitling rules to follow, says Virginie. Subtitles should appear at the bottom of the screen and usually in the centre. She says that different countries use different standards and rules. In Scandinavian countries and Holland, for example, subtitles are traditionally left justified. Characters usually appear in white with a thin black border for easy reading against a white or light background. We can also use different colours for each speaker when subtitling for the hearing impaired. Subtitles should have a maximum of two lines and the maximum number of characters on each line should be between 32 and 39. Our company standard is 37 (different companies and countries have different standards). Translators often have a favourite genre, whether its war films, musicals, comedies (one of the most difficult because of the subtleties and nuances of comedy in different countries), drama or corporate programmes. Each requires a certain tone and style. VSI employs American subtitlers, which is incredibly useful as many of the films we subtitle are American, says Virginie. For an English person, it would not be so easy to understand the meaning behind typically American expressions, and vice-versa.", "hypothesis": "Subtitling work involves a requirement that does not apply to other translation work.", "gold_label": "entailment"}
{"uid": "id_733", "premise": "Working in the movies When people ask French translator Virginie Verdier what she does for a living, it must be tempting to say enigmatically: Oh me? Im in the movies. Its strictly true, but her starring role is behind the scenes. As translating goes, it doesnt get more entertaining or glamorous than subtitling films. If youre very lucky, you get to work on the new blockbuster films before theyre in the cinema, and if youre just plain lucky, you get to work on the blockbuster movies that are going to video or DVD. The process starts when you get the original script and a tape. We would start with translating and adapting the film script. The next step is what we call timing, which means synchronising the subtitles to the dialogue and pictures. This task requires discipline. You play the film, listen to the voice and the subtitles are up on your screen ready to be timed. You insert your subtitle when you hear the corresponding dialogue and delete . it when the dialogue finishes. The video tape carries a time code which runs in hours, minutes, seconds and frames. Think of it as a clock. The subtitling unit has an insert key to capture the time code where you want the subtitle to appear. When you press the delete key, it captures the time code where you want the subtitle to disappear. So each subtitle would Subtitling is an exacting part of the translation profession. Melanie Leyshon talks to Virginie Verdier of London translation company VSI about the glamour and the grind. Virginie is quick to point out that this is as exacting as any translating job. You work hard. Its not all entertainment as you are doing the translating. You need all the skills of a good translator and those of a top-notch editor. You have to be precise and, of course, much more concise than in traditional translation work. have an in point and an out point which represent the exact time when the subtitle comes in and goes out. This process is then followed by a manual review, subtitle by subtitle, and time- codes are adjusted to improve synchronisation and respect shot changes. This process involves playing the film literally frame by frame as it is essential the subtitles respect the visual rhythm of the film. Different subtitlers use different techniques. I would go through the film and do the whole translation and then go right back from the beginning and start the timing process. But you could do it in different stages, translate lets say 20 minutes of the film, then time this section and translate the next 20 minutes, and so on. Its just a different method. For multi-lingual projects, the timing is done first to create what is called a spotting list, a subtitle template, which is in effect a list of English subtitles pre-timed and edited for translation purposes. This is then translated and the timing is adapted to the target language with the help of the translator for quality control. Like any translation work, you cant hurry subtitling, says Virginie. If subtitles are translated and timed in a rush, the quality will be affected and it will show. Mistakes usually occur when the translator does not master the source language and misunderstands the original dialogue. Our work also involves checking and reworking subtitles when the translation is not up to standard. However, the reason for redoing subtitles is not just because of poor quality translation. We may need to adapt subtitles to a new version of the film: the time code may be different. The film may have been edited or the subtitles may have been created for the cinema rather than video. If subtitles were done for cinema on 35mm, we would need to reformat the timing for video, as subtitles could be out of synch or too fast. If the translation is good, we would obviously respect the work of the original translator. On a more practical level, there are general subtitling rules to follow, says Virginie. Subtitles should appear at the bottom of the screen and usually in the centre. She says that different countries use different standards and rules. In Scandinavian countries and Holland, for example, subtitles are traditionally left justified. Characters usually appear in white with a thin black border for easy reading against a white or light background. We can also use different colours for each speaker when subtitling for the hearing impaired. Subtitles should have a maximum of two lines and the maximum number of characters on each line should be between 32 and 39. Our company standard is 37 (different companies and countries have different standards). Translators often have a favourite genre, whether its war films, musicals, comedies (one of the most difficult because of the subtleties and nuances of comedy in different countries), drama or corporate programmes. Each requires a certain tone and style. VSI employs American subtitlers, which is incredibly useful as many of the films we subtitle are American, says Virginie. For an English person, it would not be so easy to understand the meaning behind typically American expressions, and vice-versa.", "hypothesis": "Few people are completely successful at subtitling comedies.", "gold_label": "neutral"}
{"uid": "id_734", "premise": "Worlds language. The pre-eminence of the English language globally may be under threat. One billion people in the world speak Mandarin, the dominant language of China, more than three times the number who speak English. If economic trends continue then China is set to dominate world trade and quite possibly global communication with it. It is perhaps surprising then that learning English is growing fast in China, where there are more English-language teaching jobs than in any other country. The International English Language Testing System or IELTS is taken by more than one million people worldwide, and last year 270,000 tests were taken in China. This fact belies the notion that the number of speakers of a language determines its status. English is set to remain influential because it is seen as the language of academia, diplomacy and especially science, where 95 per cent of scientific publications worldwide are written in English. The language of English is robust because it has a great literary heritage and prestige (though notably so did Latin, which subsequently declined), and it is the main language of the prosperous and stable nations of the West. The use of English became widespread following the expansion of the British Empire, and it remains the primary language of at least 45 countries and the official language of many international organizations. Above all else, it is the popularity of English as a second and third language that confirms its status as the worlds language. Globally there are almost three times as many non-native speakers of English as native speakers. The number of people who can speak English in India now exceeds the number in the United States. In Nigeria, more people can speak English (pidgin) than in the UK.", "hypothesis": "More people speak English outside of the UK than in the UK.", "gold_label": "entailment"}
{"uid": "id_735", "premise": "Worlds language. The pre-eminence of the English language globally may be under threat. One billion people in the world speak Mandarin, the dominant language of China, more than three times the number who speak English. If economic trends continue then China is set to dominate world trade and quite possibly global communication with it. It is perhaps surprising then that learning English is growing fast in China, where there are more English-language teaching jobs than in any other country. The International English Language Testing System or IELTS is taken by more than one million people worldwide, and last year 270,000 tests were taken in China. This fact belies the notion that the number of speakers of a language determines its status. English is set to remain influential because it is seen as the language of academia, diplomacy and especially science, where 95 per cent of scientific publications worldwide are written in English. The language of English is robust because it has a great literary heritage and prestige (though notably so did Latin, which subsequently declined), and it is the main language of the prosperous and stable nations of the West. The use of English became widespread following the expansion of the British Empire, and it remains the primary language of at least 45 countries and the official language of many international organizations. Above all else, it is the popularity of English as a second and third language that confirms its status as the worlds language. Globally there are almost three times as many non-native speakers of English as native speakers. The number of people who can speak English in India now exceeds the number in the United States. In Nigeria, more people can speak English (pidgin) than in the UK.", "hypothesis": "In terms of English speakers, four countries are ranked as follows: India, United States, Nigeria, UK (highest number first).", "gold_label": "neutral"}
{"uid": "id_736", "premise": "Worlds language. The pre-eminence of the English language globally may be under threat. One billion people in the world speak Mandarin, the dominant language of China, more than three times the number who speak English. If economic trends continue then China is set to dominate world trade and quite possibly global communication with it. It is perhaps surprising then that learning English is growing fast in China, where there are more English-language teaching jobs than in any other country. The International English Language Testing System or IELTS is taken by more than one million people worldwide, and last year 270,000 tests were taken in China. This fact belies the notion that the number of speakers of a language determines its status. English is set to remain influential because it is seen as the language of academia, diplomacy and especially science, where 95 per cent of scientific publications worldwide are written in English. The language of English is robust because it has a great literary heritage and prestige (though notably so did Latin, which subsequently declined), and it is the main language of the prosperous and stable nations of the West. The use of English became widespread following the expansion of the British Empire, and it remains the primary language of at least 45 countries and the official language of many international organizations. Above all else, it is the popularity of English as a second and third language that confirms its status as the worlds language. Globally there are almost three times as many non-native speakers of English as native speakers. The number of people who can speak English in India now exceeds the number in the United States. In Nigeria, more people can speak English (pidgin) than in the UK.", "hypothesis": "There are fewer English-language teaching jobs in the UK than in China.", "gold_label": "entailment"}
{"uid": "id_737", "premise": "Worlds language. The pre-eminence of the English language globally may be under threat. One billion people in the world speak Mandarin, the dominant language of China, more than three times the number who speak English. If economic trends continue then China is set to dominate world trade and quite possibly global communication with it. It is perhaps surprising then that learning English is growing fast in China, where there are more English-language teaching jobs than in any other country. The International English Language Testing System or IELTS is taken by more than one million people worldwide, and last year 270,000 tests were taken in China. This fact belies the notion that the number of speakers of a language determines its status. English is set to remain influential because it is seen as the language of academia, diplomacy and especially science, where 95 per cent of scientific publications worldwide are written in English. The language of English is robust because it has a great literary heritage and prestige (though notably so did Latin, which subsequently declined), and it is the main language of the prosperous and stable nations of the West. The use of English became widespread following the expansion of the British Empire, and it remains the primary language of at least 45 countries and the official language of many international organizations. Above all else, it is the popularity of English as a second and third language that confirms its status as the worlds language. Globally there are almost three times as many non-native speakers of English as native speakers. The number of people who can speak English in India now exceeds the number in the United States. In Nigeria, more people can speak English (pidgin) than in the UK.", "hypothesis": "The language of Latin was gradually displaced by English.", "gold_label": "neutral"}
{"uid": "id_738", "premise": "YoGo is a company that makes low-fat dairy products. It built its reputation making virtually fat-free yogurts, but has since branched out to produce low fat ice-creams, milkshakes and cooking sauces. YoGos biggest competitor is DairyFree, a company that makes fat-free, dairy-free products. In order to compete with DairyFree, YoGo is trying to lower the cost of its products. It hopes to do this by buying its ingredients in bulk, using automated production lines and reducing the amount of packaging. Since implementing these changes, YoGo has seen an increase in its profit margin but sales figures are yet to change. In comparison, DairyFree has out-sold its target for this month, as a result of a marketing scheme. This scheme included the giving away free samples and discount vouchers, a marketing ploy that YoGo will not be able to compete with.", "hypothesis": "YoGo has lowered the costs and given away free samples", "gold_label": "contradiction"}
{"uid": "id_739", "premise": "YoGo is a company that makes low-fat dairy products. It built its reputation making virtually fat-free yogurts, but has since branched out to produce low fat ice-creams, milkshakes and cooking sauces. YoGos biggest competitor is DairyFree, a company that makes fat-free, dairy-free products. In order to compete with DairyFree, YoGo is trying to lower the cost of its products. It hopes to do this by buying its ingredients in bulk, using automated production lines and reducing the amount of packaging. Since implementing these changes, YoGo has seen an increase in its profit margin but sales figures are yet to change. In comparison, DairyFree has out-sold its target for this month, as a result of a marketing scheme. This scheme included the giving away free samples and discount vouchers, a marketing ploy that YoGo will not be able to compete with.", "hypothesis": "YoGo will go into administration.", "gold_label": "neutral"}
{"uid": "id_740", "premise": "YoGo is a company that makes low-fat dairy products. It built its reputation making virtually fat-free yogurts, but has since branched out to produce low fat ice-creams, milkshakes and cooking sauces. YoGos biggest competitor is DairyFree, a company that makes fat-free, dairy-free products. In order to compete with DairyFree, YoGo is trying to lower the cost of its products. It hopes to do this by buying its ingredients in bulk, using automated production lines and reducing the amount of packaging. Since implementing these changes, YoGo has seen an increase in its profit margin but sales figures are yet to change. In comparison, DairyFree has out-sold its target for this month, as a result of a marketing scheme. This scheme included the giving away free samples and discount vouchers, a marketing ploy that YoGo will not be able to compete with.", "hypothesis": "YoGo implemented a scheme that aims to reduce the cost of production in attempt to compete with DairyFree", "gold_label": "entailment"}
{"uid": "id_741", "premise": "YoGo is a company that makes low-fat dairy products. It built its reputation making virtually fat-free yogurts, but has since branched out to produce low fat ice-creams, milkshakes and cooking sauces. YoGos biggest competitor is DairyFree, a company that makes fat-free, dairy-free products. In order to compete with DairyFree, YoGo is trying to lower the cost of its products. It hopes to do this by buying its ingredients in bulk, using automated production lines and reducing the amount of packaging. Since implementing these changes, YoGo has seen an increase in its profit margin but sales figures are yet to change. In comparison, DairyFree has out-sold its target for this month, as a result of a marketing scheme. This scheme included the giving away free samples and discount vouchers, a marketing ploy that YoGo will not be able to compete with.", "hypothesis": "YoGo implemented a scheme that gives away free samples and discount vouchers in attempt to compete with DairyFree", "gold_label": "contradiction"}
{"uid": "id_742", "premise": "You and your CV It is the first thing a future employer sees about you, and if its not right, may be the last. An employer will do no more than glance at your CV its estimated that most employers spend more than twenty seconds looking at each CV, so you have very little time to make the impression. Heres some advice to help you make the most of those twenty seconds. What it should look like The first rule of all CVs is to keep them clear and simple anything complicated or long tends to get rejected instantly. Achieving that is a matter of making good use of lists, bullet points and note form, and of keeping your CV to the right length. There are no fixed rules on how long it should be, and it will vary, of course, according to your age, experience, etc. , but keep it to one page if you can this length is convenient for your reader to work with. As for style, there are different kinds of layouts you can follow look at the examples on this site to see which one you prefer but the basic rule is to use headings well to signal clearly where all the relevant information is. Make sure you include these sections: qualifications, skills, education, work experience, references, personal interests/hobbies, personal qualities, then label them clearly so that your prospective employer can find the information they want quickly and easily. Content CVs tend to follow a fixed order. They start with your personal details such as name, address and contact details, then go on to personal qualities such as those things in your personality that might attract an employer e. g. conscientious, adventurous, punctual, etc. , and your career goals. After this comes the main part of your CV starting with education, then work experience. Use reverse chronological order to list these, starting with what youre doing now. Its most common to go back no more than 10 years. Give your job details such as job titles, the names of the organisations you worked for, an outline of your job duties and then note your particular achievements. Then go on to your personal interests and finish up with the details of some good, reliable referees. Your future employer may not follow up on these, but they do make an impression. Dos and donts A glance at your CV should create a good impression. Dont make spelling mistakes, and dont send in anything crumpled or with coffee stains on it. Anything like that leads to instant rejection. Use good quality A4 paper and dont send in anything other than a cover letter. Diplomas, testimonials, etc. , will be requested later ~ theyre interested in you. When you think youve finished writing your CV, read it over very carefully. Check your full stops, use of bullets, indentation, use of capital letters, etc. And never include in your CV anything thats not true. Its very easy for an employer to check, and if your CV doesnt match what they find out, then your chances of getting that job are probably gone. Finally, carry out the instructions in the job ad very carefully. If they require three copies, then send them three copies, not two or four. Make sure you meet the deadline too, and put the right stamp on your envelope. Youll need to accompany your CV with a cover letter. This should be tailored to each job you apply for. Follow the link below for advice on how to write a cover letter. And last of all Good luck! Remember to include: Career history Skills and strengths Awards and achievements Contact details", "hypothesis": "The style of CVs varies from country to country.", "gold_label": "neutral"}
{"uid": "id_743", "premise": "You and your CV It is the first thing a future employer sees about you, and if its not right, may be the last. An employer will do no more than glance at your CV its estimated that most employers spend more than twenty seconds looking at each CV, so you have very little time to make the impression. Heres some advice to help you make the most of those twenty seconds. What it should look like The first rule of all CVs is to keep them clear and simple anything complicated or long tends to get rejected instantly. Achieving that is a matter of making good use of lists, bullet points and note form, and of keeping your CV to the right length. There are no fixed rules on how long it should be, and it will vary, of course, according to your age, experience, etc. , but keep it to one page if you can this length is convenient for your reader to work with. As for style, there are different kinds of layouts you can follow look at the examples on this site to see which one you prefer but the basic rule is to use headings well to signal clearly where all the relevant information is. Make sure you include these sections: qualifications, skills, education, work experience, references, personal interests/hobbies, personal qualities, then label them clearly so that your prospective employer can find the information they want quickly and easily. Content CVs tend to follow a fixed order. They start with your personal details such as name, address and contact details, then go on to personal qualities such as those things in your personality that might attract an employer e. g. conscientious, adventurous, punctual, etc. , and your career goals. After this comes the main part of your CV starting with education, then work experience. Use reverse chronological order to list these, starting with what youre doing now. Its most common to go back no more than 10 years. Give your job details such as job titles, the names of the organisations you worked for, an outline of your job duties and then note your particular achievements. Then go on to your personal interests and finish up with the details of some good, reliable referees. Your future employer may not follow up on these, but they do make an impression. Dos and donts A glance at your CV should create a good impression. Dont make spelling mistakes, and dont send in anything crumpled or with coffee stains on it. Anything like that leads to instant rejection. Use good quality A4 paper and dont send in anything other than a cover letter. Diplomas, testimonials, etc. , will be requested later ~ theyre interested in you. When you think youve finished writing your CV, read it over very carefully. Check your full stops, use of bullets, indentation, use of capital letters, etc. And never include in your CV anything thats not true. Its very easy for an employer to check, and if your CV doesnt match what they find out, then your chances of getting that job are probably gone. Finally, carry out the instructions in the job ad very carefully. If they require three copies, then send them three copies, not two or four. Make sure you meet the deadline too, and put the right stamp on your envelope. Youll need to accompany your CV with a cover letter. This should be tailored to each job you apply for. Follow the link below for advice on how to write a cover letter. And last of all Good luck! Remember to include: Career history Skills and strengths Awards and achievements Contact details", "hypothesis": "Employers spend a long time reading applicants CVs.", "gold_label": "contradiction"}
{"uid": "id_744", "premise": "You and your CV It is the first thing a future employer sees about you, and if its not right, may be the last. An employer will do no more than glance at your CV its estimated that most employers spend more than twenty seconds looking at each CV, so you have very little time to make the impression. Heres some advice to help you make the most of those twenty seconds. What it should look like The first rule of all CVs is to keep them clear and simple anything complicated or long tends to get rejected instantly. Achieving that is a matter of making good use of lists, bullet points and note form, and of keeping your CV to the right length. There are no fixed rules on how long it should be, and it will vary, of course, according to your age, experience, etc. , but keep it to one page if you can this length is convenient for your reader to work with. As for style, there are different kinds of layouts you can follow look at the examples on this site to see which one you prefer but the basic rule is to use headings well to signal clearly where all the relevant information is. Make sure you include these sections: qualifications, skills, education, work experience, references, personal interests/hobbies, personal qualities, then label them clearly so that your prospective employer can find the information they want quickly and easily. Content CVs tend to follow a fixed order. They start with your personal details such as name, address and contact details, then go on to personal qualities such as those things in your personality that might attract an employer e. g. conscientious, adventurous, punctual, etc. , and your career goals. After this comes the main part of your CV starting with education, then work experience. Use reverse chronological order to list these, starting with what youre doing now. Its most common to go back no more than 10 years. Give your job details such as job titles, the names of the organisations you worked for, an outline of your job duties and then note your particular achievements. Then go on to your personal interests and finish up with the details of some good, reliable referees. Your future employer may not follow up on these, but they do make an impression. Dos and donts A glance at your CV should create a good impression. Dont make spelling mistakes, and dont send in anything crumpled or with coffee stains on it. Anything like that leads to instant rejection. Use good quality A4 paper and dont send in anything other than a cover letter. Diplomas, testimonials, etc. , will be requested later ~ theyre interested in you. When you think youve finished writing your CV, read it over very carefully. Check your full stops, use of bullets, indentation, use of capital letters, etc. And never include in your CV anything thats not true. Its very easy for an employer to check, and if your CV doesnt match what they find out, then your chances of getting that job are probably gone. Finally, carry out the instructions in the job ad very carefully. If they require three copies, then send them three copies, not two or four. Make sure you meet the deadline too, and put the right stamp on your envelope. Youll need to accompany your CV with a cover letter. This should be tailored to each job you apply for. Follow the link below for advice on how to write a cover letter. And last of all Good luck! Remember to include: Career history Skills and strengths Awards and achievements Contact details", "hypothesis": "CVs are essential when applying for jobs.", "gold_label": "entailment"}
{"uid": "id_745", "premise": "You can find out so much about people on the internet these days that civil liberty campaigners are arguing for new laws so that people can get back some vestige of control over their personal data. The 1998 Data Protection Act gives us the right to know the personal information companies are holding. But the new threat to personal liberty is quite the opposite it is the threat of complete strangers finding out our personal details. Undertake an internet search on someone you know with any of the main search engines and you are likely to obtain thousands of results which if trawled through can provide particulars of employment, a work phone number and e-mail address. Find a CV belonging to that person and you will get hold of their home address, date of birth, home telephone number, personal e-mail address and a listing of their educational history and interests. If the person for whom you are searching is active on a social network site or an internet specialist interest forum then you may well be able to identify a database of friends and contacts and by reading recent postings obtain a flavour of their views and preferences. Search the database of a genealogy site and you may well be able to identify generations of family members.", "hypothesis": "The threat to personal liberty is no longer one of secrecy and finding out what organizations know about us.", "gold_label": "contradiction"}
{"uid": "id_746", "premise": "You can find out so much about people on the internet these days that civil liberty campaigners are arguing for new laws so that people can get back some vestige of control over their personal data. The 1998 Data Protection Act gives us the right to know the personal information companies are holding. But the new threat to personal liberty is quite the opposite it is the threat of complete strangers finding out our personal details. Undertake an internet search on someone you know with any of the main search engines and you are likely to obtain thousands of results which if trawled through can provide particulars of employment, a work phone number and e-mail address. Find a CV belonging to that person and you will get hold of their home address, date of birth, home telephone number, personal e-mail address and a listing of their educational history and interests. If the person for whom you are searching is active on a social network site or an internet specialist interest forum then you may well be able to identify a database of friends and contacts and by reading recent postings obtain a flavour of their views and preferences. Search the database of a genealogy site and you may well be able to identify generations of family members.", "hypothesis": "The penultimate sentence of the passage illustrates the sort of things that people post on the internet.", "gold_label": "entailment"}
{"uid": "id_747", "premise": "You cannot be very intelligent if you do not know how smart you are until you have been told your IQ rate. It is probably unwise to take an IQ test because if you do then you risk feeling either superior or disappointed when you get the result, and neither of these sentiments is beneficial. What difference would it make to your life anyway, if you were to find out that you have the IQ of a genius or well below average? These considerations did not stop almost half a million Europeans from taking part in an internet IQ test. In the test, men scored 110 while women scored 105; left- handed people scored much higher than right-handed people; and people with brown eyes scored best while people with red hair scored the least.", "hypothesis": "The results suggest that men are more intelligent than women.", "gold_label": "contradiction"}
{"uid": "id_748", "premise": "You cannot be very intelligent if you do not know how smart you are until you have been told your IQ rate. It is probably unwise to take an IQ test because if you do then you risk feeling either superior or disappointed when you get the result, and neither of these sentiments is beneficial. What difference would it make to your life anyway, if you were to find out that you have the IQ of a genius or well below average? These considerations did not stop almost half a million Europeans from taking part in an internet IQ test. In the test, men scored 110 while women scored 105; left- handed people scored much higher than right-handed people; and people with brown eyes scored best while people with red hair scored the least.", "hypothesis": "It is reasonable to surmise that the author would have difficulty understanding why someone would want to know their IQ.", "gold_label": "entailment"}
{"uid": "id_749", "premise": "You cannot be very intelligent if you do not know how smart you are until you have been told your IQ rate. It is probably unwise to take an IQ test because if you do then you risk feeling either superior or disappointed when you get the result, and neither of these sentiments is beneficial. What difference would it make to your life anyway, if you were to find out that you have the IQ of a genius or well below average? These considerations did not stop almost half a million Europeans from taking part in an internet IQ test. In the test, men scored 110 while women scored 105; left- handed people scored much higher than right-handed people; and people with brown eyes scored best while people with red hair scored the least.", "hypothesis": "The passage is written in a satirical style.", "gold_label": "contradiction"}
{"uid": "id_750", "premise": "Your New Electron Washing Machine These introductory notes will outline some basic information regarding your new Electron Washing Machine. Read the notes carefully, as you will avoid some possible problems. 1. Remember, always get your washing machine installed by a qualified installer. This will include all qualified electricians and plumbers. Your retailer will probably be able to recommend someone or provide the service. Dont use friends or try it yourself and beware of cowboys! Non-qualified installation will lead to the nullification of the guarantee. 2. Your new Electron Washing Machine will work with any good quality washing detergent, but it has been designed to work with some better brands. See the main users guide for a list of recommended detergents. 3. It is very possible that the water where you live is hard. Prolonged use with hard water will lead to scale calcification in all washing machines, and no technology can stop this. To avoid this, it is recommended that you install a water softener to the washing machine water supply. Local plumbers will be able to advise you of your areas water type and what water softener would be suitable if applicable. 4. All new Electron Washing Machines come with a standard 2 year manufacturers guarantee. While we are confident that your new Electron Washing Machine has been manufactured to the highest possible quality standards, if you would like to invest in a 5 year guarantee, this can be purchased online on our website, www. electronmachines. com. We believe its the best thing to do for peace of mind. 5. Before washing clothes for the first time in your new Electron Washing Machine, it is important that you run the machine one time with no clothes. You can use detergent if you wish, but this is not necessary. Use setting 8 at 40 degrees for best results. 6. Remember, before washing clothes, check all pockets etc. for any coins, tissues or other belongings. Coins and tissues can sometimes get into the machinery and cause your new Electron Washing Machine to break down. 7. Some minor faults with your new Electron Washing Machine can be fixed without having to call in expensive help. To help you with this, we have created a troubleshooting guide on our website, www. electronmachines. com. There are straightforward questions that cover most possible problems and, once diagnosed, the problems can usually be dealt with by yourself without having to call the plumber or electrician. 8. Why not take a little time to register your new Electron Washing Machine with us? It doesnt take much time, and if we know who you are, we will be able to service you better. Just go to the appropriate icon on our website (www. electronmachines. com) to register. You will be taken to a page where you will be asked for a few details. 9. Finally, we are extremely interested to know what your experience is like with your new Electron Washing Machine. On our website, www. electronmachines. com, we have feedback pages, blogs and forums where you can have your say. Come and share with us!", "hypothesis": "The Electron washing machine includes technology that stops calcification", "gold_label": "contradiction"}
{"uid": "id_751", "premise": "Your New Electron Washing Machine These introductory notes will outline some basic information regarding your new Electron Washing Machine. Read the notes carefully, as you will avoid some possible problems. 1. Remember, always get your washing machine installed by a qualified installer. This will include all qualified electricians and plumbers. Your retailer will probably be able to recommend someone or provide the service. Dont use friends or try it yourself and beware of cowboys! Non-qualified installation will lead to the nullification of the guarantee. 2. Your new Electron Washing Machine will work with any good quality washing detergent, but it has been designed to work with some better brands. See the main users guide for a list of recommended detergents. 3. It is very possible that the water where you live is hard. Prolonged use with hard water will lead to scale calcification in all washing machines, and no technology can stop this. To avoid this, it is recommended that you install a water softener to the washing machine water supply. Local plumbers will be able to advise you of your areas water type and what water softener would be suitable if applicable. 4. All new Electron Washing Machines come with a standard 2 year manufacturers guarantee. While we are confident that your new Electron Washing Machine has been manufactured to the highest possible quality standards, if you would like to invest in a 5 year guarantee, this can be purchased online on our website, www. electronmachines. com. We believe its the best thing to do for peace of mind. 5. Before washing clothes for the first time in your new Electron Washing Machine, it is important that you run the machine one time with no clothes. You can use detergent if you wish, but this is not necessary. Use setting 8 at 40 degrees for best results. 6. Remember, before washing clothes, check all pockets etc. for any coins, tissues or other belongings. Coins and tissues can sometimes get into the machinery and cause your new Electron Washing Machine to break down. 7. Some minor faults with your new Electron Washing Machine can be fixed without having to call in expensive help. To help you with this, we have created a troubleshooting guide on our website, www. electronmachines. com. There are straightforward questions that cover most possible problems and, once diagnosed, the problems can usually be dealt with by yourself without having to call the plumber or electrician. 8. Why not take a little time to register your new Electron Washing Machine with us? It doesnt take much time, and if we know who you are, we will be able to service you better. Just go to the appropriate icon on our website (www. electronmachines. com) to register. You will be taken to a page where you will be asked for a few details. 9. Finally, we are extremely interested to know what your experience is like with your new Electron Washing Machine. On our website, www. electronmachines. com, we have feedback pages, blogs and forums where you can have your say. Come and share with us!", "hypothesis": "Registering the washing machine requires giving an email address.", "gold_label": "neutral"}
{"uid": "id_752", "premise": "Your New Electron Washing Machine These introductory notes will outline some basic information regarding your new Electron Washing Machine. Read the notes carefully, as you will avoid some possible problems. 1. Remember, always get your washing machine installed by a qualified installer. This will include all qualified electricians and plumbers. Your retailer will probably be able to recommend someone or provide the service. Dont use friends or try it yourself and beware of cowboys! Non-qualified installation will lead to the nullification of the guarantee. 2. Your new Electron Washing Machine will work with any good quality washing detergent, but it has been designed to work with some better brands. See the main users guide for a list of recommended detergents. 3. It is very possible that the water where you live is hard. Prolonged use with hard water will lead to scale calcification in all washing machines, and no technology can stop this. To avoid this, it is recommended that you install a water softener to the washing machine water supply. Local plumbers will be able to advise you of your areas water type and what water softener would be suitable if applicable. 4. All new Electron Washing Machines come with a standard 2 year manufacturers guarantee. While we are confident that your new Electron Washing Machine has been manufactured to the highest possible quality standards, if you would like to invest in a 5 year guarantee, this can be purchased online on our website, www. electronmachines. com. We believe its the best thing to do for peace of mind. 5. Before washing clothes for the first time in your new Electron Washing Machine, it is important that you run the machine one time with no clothes. You can use detergent if you wish, but this is not necessary. Use setting 8 at 40 degrees for best results. 6. Remember, before washing clothes, check all pockets etc. for any coins, tissues or other belongings. Coins and tissues can sometimes get into the machinery and cause your new Electron Washing Machine to break down. 7. Some minor faults with your new Electron Washing Machine can be fixed without having to call in expensive help. To help you with this, we have created a troubleshooting guide on our website, www. electronmachines. com. There are straightforward questions that cover most possible problems and, once diagnosed, the problems can usually be dealt with by yourself without having to call the plumber or electrician. 8. Why not take a little time to register your new Electron Washing Machine with us? It doesnt take much time, and if we know who you are, we will be able to service you better. Just go to the appropriate icon on our website (www. electronmachines. com) to register. You will be taken to a page where you will be asked for a few details. 9. Finally, we are extremely interested to know what your experience is like with your new Electron Washing Machine. On our website, www. electronmachines. com, we have feedback pages, blogs and forums where you can have your say. Come and share with us!", "hypothesis": "Reading the troubleshooting guide can save you money.", "gold_label": "entailment"}
{"uid": "id_753", "premise": "Your New Electron Washing Machine These introductory notes will outline some basic information regarding your new Electron Washing Machine. Read the notes carefully, as you will avoid some possible problems. 1. Remember, always get your washing machine installed by a qualified installer. This will include all qualified electricians and plumbers. Your retailer will probably be able to recommend someone or provide the service. Dont use friends or try it yourself and beware of cowboys! Non-qualified installation will lead to the nullification of the guarantee. 2. Your new Electron Washing Machine will work with any good quality washing detergent, but it has been designed to work with some better brands. See the main users guide for a list of recommended detergents. 3. It is very possible that the water where you live is hard. Prolonged use with hard water will lead to scale calcification in all washing machines, and no technology can stop this. To avoid this, it is recommended that you install a water softener to the washing machine water supply. Local plumbers will be able to advise you of your areas water type and what water softener would be suitable if applicable. 4. All new Electron Washing Machines come with a standard 2 year manufacturers guarantee. While we are confident that your new Electron Washing Machine has been manufactured to the highest possible quality standards, if you would like to invest in a 5 year guarantee, this can be purchased online on our website, www. electronmachines. com. We believe its the best thing to do for peace of mind. 5. Before washing clothes for the first time in your new Electron Washing Machine, it is important that you run the machine one time with no clothes. You can use detergent if you wish, but this is not necessary. Use setting 8 at 40 degrees for best results. 6. Remember, before washing clothes, check all pockets etc. for any coins, tissues or other belongings. Coins and tissues can sometimes get into the machinery and cause your new Electron Washing Machine to break down. 7. Some minor faults with your new Electron Washing Machine can be fixed without having to call in expensive help. To help you with this, we have created a troubleshooting guide on our website, www. electronmachines. com. There are straightforward questions that cover most possible problems and, once diagnosed, the problems can usually be dealt with by yourself without having to call the plumber or electrician. 8. Why not take a little time to register your new Electron Washing Machine with us? It doesnt take much time, and if we know who you are, we will be able to service you better. Just go to the appropriate icon on our website (www. electronmachines. com) to register. You will be taken to a page where you will be asked for a few details. 9. Finally, we are extremely interested to know what your experience is like with your new Electron Washing Machine. On our website, www. electronmachines. com, we have feedback pages, blogs and forums where you can have your say. Come and share with us!", "hypothesis": "Buying an extended warranty is a good idea.", "gold_label": "entailment"}
{"uid": "id_754", "premise": "Your New Electron Washing Machine These introductory notes will outline some basic information regarding your new Electron Washing Machine. Read the notes carefully, as you will avoid some possible problems. 1. Remember, always get your washing machine installed by a qualified installer. This will include all qualified electricians and plumbers. Your retailer will probably be able to recommend someone or provide the service. Dont use friends or try it yourself and beware of cowboys! Non-qualified installation will lead to the nullification of the guarantee. 2. Your new Electron Washing Machine will work with any good quality washing detergent, but it has been designed to work with some better brands. See the main users guide for a list of recommended detergents. 3. It is very possible that the water where you live is hard. Prolonged use with hard water will lead to scale calcification in all washing machines, and no technology can stop this. To avoid this, it is recommended that you install a water softener to the washing machine water supply. Local plumbers will be able to advise you of your areas water type and what water softener would be suitable if applicable. 4. All new Electron Washing Machines come with a standard 2 year manufacturers guarantee. While we are confident that your new Electron Washing Machine has been manufactured to the highest possible quality standards, if you would like to invest in a 5 year guarantee, this can be purchased online on our website, www. electronmachines. com. We believe its the best thing to do for peace of mind. 5. Before washing clothes for the first time in your new Electron Washing Machine, it is important that you run the machine one time with no clothes. You can use detergent if you wish, but this is not necessary. Use setting 8 at 40 degrees for best results. 6. Remember, before washing clothes, check all pockets etc. for any coins, tissues or other belongings. Coins and tissues can sometimes get into the machinery and cause your new Electron Washing Machine to break down. 7. Some minor faults with your new Electron Washing Machine can be fixed without having to call in expensive help. To help you with this, we have created a troubleshooting guide on our website, www. electronmachines. com. There are straightforward questions that cover most possible problems and, once diagnosed, the problems can usually be dealt with by yourself without having to call the plumber or electrician. 8. Why not take a little time to register your new Electron Washing Machine with us? It doesnt take much time, and if we know who you are, we will be able to service you better. Just go to the appropriate icon on our website (www. electronmachines. com) to register. You will be taken to a page where you will be asked for a few details. 9. Finally, we are extremely interested to know what your experience is like with your new Electron Washing Machine. On our website, www. electronmachines. com, we have feedback pages, blogs and forums where you can have your say. Come and share with us!", "hypothesis": "When using the washing machine for the first time, run a cycle with some old clothes or towels.", "gold_label": "contradiction"}
{"uid": "id_755", "premise": "Your New Electron Washing Machine These introductory notes will outline some basic information regarding your new Electron Washing Machine. Read the notes carefully, as you will avoid some possible problems. 1. Remember, always get your washing machine installed by a qualified installer. This will include all qualified electricians and plumbers. Your retailer will probably be able to recommend someone or provide the service. Dont use friends or try it yourself and beware of cowboys! Non-qualified installation will lead to the nullification of the guarantee. 2. Your new Electron Washing Machine will work with any good quality washing detergent, but it has been designed to work with some better brands. See the main users guide for a list of recommended detergents. 3. It is very possible that the water where you live is hard. Prolonged use with hard water will lead to scale calcification in all washing machines, and no technology can stop this. To avoid this, it is recommended that you install a water softener to the washing machine water supply. Local plumbers will be able to advise you of your areas water type and what water softener would be suitable if applicable. 4. All new Electron Washing Machines come with a standard 2 year manufacturers guarantee. While we are confident that your new Electron Washing Machine has been manufactured to the highest possible quality standards, if you would like to invest in a 5 year guarantee, this can be purchased online on our website, www. electronmachines. com. We believe its the best thing to do for peace of mind. 5. Before washing clothes for the first time in your new Electron Washing Machine, it is important that you run the machine one time with no clothes. You can use detergent if you wish, but this is not necessary. Use setting 8 at 40 degrees for best results. 6. Remember, before washing clothes, check all pockets etc. for any coins, tissues or other belongings. Coins and tissues can sometimes get into the machinery and cause your new Electron Washing Machine to break down. 7. Some minor faults with your new Electron Washing Machine can be fixed without having to call in expensive help. To help you with this, we have created a troubleshooting guide on our website, www. electronmachines. com. There are straightforward questions that cover most possible problems and, once diagnosed, the problems can usually be dealt with by yourself without having to call the plumber or electrician. 8. Why not take a little time to register your new Electron Washing Machine with us? It doesnt take much time, and if we know who you are, we will be able to service you better. Just go to the appropriate icon on our website (www. electronmachines. com) to register. You will be taken to a page where you will be asked for a few details. 9. Finally, we are extremely interested to know what your experience is like with your new Electron Washing Machine. On our website, www. electronmachines. com, we have feedback pages, blogs and forums where you can have your say. Come and share with us!", "hypothesis": "Installers must provide the customer with a certificate of installation.", "gold_label": "neutral"}
{"uid": "id_756", "premise": "Zeus Temple Holds Secrets of Ancient Game Athens already is preparing for the summer games of 2004. But todays games offer a far different spectacle from the contests of ancient Greece, where naked young men with oiled bodies raced and wrestled and boxed to honor their gods. Those great Panhellenic events began more than 2,700 years ago, first in Olympia and later at Delphi, lsthmia and Nemea. And at Nemea, where the games began in 573 B. C. , a Berkeley archaeologist has been patiently reconstructing a site whose legends helped inspire the modern Olympics. For Stephen G. Miller, exploring the site at Nemea, 70 miles from Athens, involves more than analyzing artifacts and ruins, dating ancient rock strata or patiently assembling broken pottery shards. It also means reliving the events he's studying. For the last two summers, large crowds have flocked to an ancient Nemean stadium (capacity 40,000) to watch a modern re-enactment of the ancient Nemean games. Seven hundred runners from 45 nations bare foot and clad in white tunics raced around the reborn stadium in groups of 12. Winners of the races were crowned just as they were in antiquity with wreaths of wild celery. Miller is a professor of classics at the University of California at Berkeley, but he also has been a barefoot runner, a slave carrying water for the athletes and a priest presiding over the re-enacted rituals of the legendary Nemean games. Playing those roles gives you a deeper sense of antiquity and a feel for the spirit of the people who lived and worked and played there so long ago, he said recently after returning from this years field work. Excavating the site every summer since 1973, Miller and his crew have found and re-assembled limestone columns that once stood proudly around the Temple of Zeus. Exactly a decade after they began the excavation and just east of the temple, they found the remains of a great altar to Zeus where athletes and their trainers performed sacrifices and swore oaths just before competing. And from ancient Greek records, two years later, Millers team also learned that his Nemea site had once seen major horse races in a hippodrome that must have existed next to the great stadium. In an earthen mound his team could trace the patterns of faint wheel marks indicating that chariots must have raced there too. In 1997 Miller and his crew, seeking more evidence of the hippodrome, dug down into a spot where four low rock walls indicate there might be a structure underneath. There they found a wine jug, drinking mugs, coins and a crude little figure of a centaur. The next summer, after digging down 20 feet, they still hadnt reached bottom. Miller wondered what purpose this deep rock-walled pit might have served, and finally concluded it must have been a reservoir holding copious quantities of water from a river near the site that now irrigates vineyards. The reservoir is a phenomenal find, Miller said, We believe it provided water for as many as 150 horses who raced in the hippodrome during the games. But how were the horses fed? And what did they do with that much manure every day? Trying to answer questions like that is one of the joys of the whole project. Eight months after finding the reservoir Miller and his team uncovered an ancient chamber that served the Nemean athletes as a locker room the apodyterion where they anointed themselves with olive oil. They then would have walked 120 feet through a vaulted entrance tunnel the krypte esodos whose walls are still marked by graffiti scratched by the athletes on their way into the stadium. The wine jug and cups unearthed in one layer of the buried reservoir may have been left by victors in one of the ancient Nemean races, but just what kind of wine they drank remains unknown. Today, the local red wine served in Nemean taverns is called the Blood of Hercules, honoring the hero who strangled the ferocious Nemean lion there more than 5,000 years ago. As in so much of archaeology, the discoveries that Miller has made at Nemea all seem to recall ancient legends and link them to reality. The Berkeley team, for example, has unearthed a tiny bronze figurine identified as the image of an infant named Opheltes, whose fate inspired the first of the Nemean games. As Miller recounts the tale, Opheltes was the son of Lykourgos and Eurydike, who had tried for many years to produce an heir. When the Oracle at Delphi warned them that their child must not touch the ground until he had learned to walk, they ordered a Nemean slave woman to care for the infant day and night. One day, when seven warrior heroes passed through Nemea on their way to march against the citadel of Thebes they were the legendary Seven Against Thebes whose bloody war was immortalized by Aeschylus the nurse placed the child on a bed of wild celery while she offered drink to the heroes. Instantly, a serpent lurking in the vegetation killed the infant and the warriors re-named the boy Archemoros, the Beginner-of- Doom, and held the first Nemean games in his honor as a funerary festival. Wreaths of wild celery crowned winners of those games, as they did the modern winners at Nemea last summer. As with all classical archaeologists, whose excavations shed so much surprising light on antiquity, Miller and his students are now ready to organize and classify their treasured finds from the summer season, and to plan for next seasons dig. In the earthen mound where we saw the imprints of wheel cuts, we also have a bronze vessel of the kind that was always used for pouring libations, Miller said. That mound goes back to 600 B. C. , so now we wonder what happened there in that complex of religion and athletics even before the Nemean games. Archaeology doesnt come cheap, and each season at Nemea costs at least $150,000 for the team, the equipment, and the 35 local workers from the nearby town of modern Nemea, whom Miller calls the core of the project. The money all comes from private sources and not the least of Millers jobs is lecturing to the public and combing the territory for contributions.", "hypothesis": "Religion played a key role in the games.", "gold_label": "entailment"}
{"uid": "id_757", "premise": "Zeus Temple Holds Secrets of Ancient Game Athens already is preparing for the summer games of 2004. But todays games offer a far different spectacle from the contests of ancient Greece, where naked young men with oiled bodies raced and wrestled and boxed to honor their gods. Those great Panhellenic events began more than 2,700 years ago, first in Olympia and later at Delphi, lsthmia and Nemea. And at Nemea, where the games began in 573 B. C. , a Berkeley archaeologist has been patiently reconstructing a site whose legends helped inspire the modern Olympics. For Stephen G. Miller, exploring the site at Nemea, 70 miles from Athens, involves more than analyzing artifacts and ruins, dating ancient rock strata or patiently assembling broken pottery shards. It also means reliving the events he's studying. For the last two summers, large crowds have flocked to an ancient Nemean stadium (capacity 40,000) to watch a modern re-enactment of the ancient Nemean games. Seven hundred runners from 45 nations bare foot and clad in white tunics raced around the reborn stadium in groups of 12. Winners of the races were crowned just as they were in antiquity with wreaths of wild celery. Miller is a professor of classics at the University of California at Berkeley, but he also has been a barefoot runner, a slave carrying water for the athletes and a priest presiding over the re-enacted rituals of the legendary Nemean games. Playing those roles gives you a deeper sense of antiquity and a feel for the spirit of the people who lived and worked and played there so long ago, he said recently after returning from this years field work. Excavating the site every summer since 1973, Miller and his crew have found and re-assembled limestone columns that once stood proudly around the Temple of Zeus. Exactly a decade after they began the excavation and just east of the temple, they found the remains of a great altar to Zeus where athletes and their trainers performed sacrifices and swore oaths just before competing. And from ancient Greek records, two years later, Millers team also learned that his Nemea site had once seen major horse races in a hippodrome that must have existed next to the great stadium. In an earthen mound his team could trace the patterns of faint wheel marks indicating that chariots must have raced there too. In 1997 Miller and his crew, seeking more evidence of the hippodrome, dug down into a spot where four low rock walls indicate there might be a structure underneath. There they found a wine jug, drinking mugs, coins and a crude little figure of a centaur. The next summer, after digging down 20 feet, they still hadnt reached bottom. Miller wondered what purpose this deep rock-walled pit might have served, and finally concluded it must have been a reservoir holding copious quantities of water from a river near the site that now irrigates vineyards. The reservoir is a phenomenal find, Miller said, We believe it provided water for as many as 150 horses who raced in the hippodrome during the games. But how were the horses fed? And what did they do with that much manure every day? Trying to answer questions like that is one of the joys of the whole project. Eight months after finding the reservoir Miller and his team uncovered an ancient chamber that served the Nemean athletes as a locker room the apodyterion where they anointed themselves with olive oil. They then would have walked 120 feet through a vaulted entrance tunnel the krypte esodos whose walls are still marked by graffiti scratched by the athletes on their way into the stadium. The wine jug and cups unearthed in one layer of the buried reservoir may have been left by victors in one of the ancient Nemean races, but just what kind of wine they drank remains unknown. Today, the local red wine served in Nemean taverns is called the Blood of Hercules, honoring the hero who strangled the ferocious Nemean lion there more than 5,000 years ago. As in so much of archaeology, the discoveries that Miller has made at Nemea all seem to recall ancient legends and link them to reality. The Berkeley team, for example, has unearthed a tiny bronze figurine identified as the image of an infant named Opheltes, whose fate inspired the first of the Nemean games. As Miller recounts the tale, Opheltes was the son of Lykourgos and Eurydike, who had tried for many years to produce an heir. When the Oracle at Delphi warned them that their child must not touch the ground until he had learned to walk, they ordered a Nemean slave woman to care for the infant day and night. One day, when seven warrior heroes passed through Nemea on their way to march against the citadel of Thebes they were the legendary Seven Against Thebes whose bloody war was immortalized by Aeschylus the nurse placed the child on a bed of wild celery while she offered drink to the heroes. Instantly, a serpent lurking in the vegetation killed the infant and the warriors re-named the boy Archemoros, the Beginner-of- Doom, and held the first Nemean games in his honor as a funerary festival. Wreaths of wild celery crowned winners of those games, as they did the modern winners at Nemea last summer. As with all classical archaeologists, whose excavations shed so much surprising light on antiquity, Miller and his students are now ready to organize and classify their treasured finds from the summer season, and to plan for next seasons dig. In the earthen mound where we saw the imprints of wheel cuts, we also have a bronze vessel of the kind that was always used for pouring libations, Miller said. That mound goes back to 600 B. C. , so now we wonder what happened there in that complex of religion and athletics even before the Nemean games. Archaeology doesnt come cheap, and each season at Nemea costs at least $150,000 for the team, the equipment, and the 35 local workers from the nearby town of modern Nemea, whom Miller calls the core of the project. The money all comes from private sources and not the least of Millers jobs is lecturing to the public and combing the territory for contributions.", "hypothesis": "Miller goes far beyond what an archaeologist traditionally normally does.", "gold_label": "entailment"}
{"uid": "id_758", "premise": "Zeus Temple Holds Secrets of Ancient Game Athens already is preparing for the summer games of 2004. But todays games offer a far different spectacle from the contests of ancient Greece, where naked young men with oiled bodies raced and wrestled and boxed to honor their gods. Those great Panhellenic events began more than 2,700 years ago, first in Olympia and later at Delphi, lsthmia and Nemea. And at Nemea, where the games began in 573 B. C. , a Berkeley archaeologist has been patiently reconstructing a site whose legends helped inspire the modern Olympics. For Stephen G. Miller, exploring the site at Nemea, 70 miles from Athens, involves more than analyzing artifacts and ruins, dating ancient rock strata or patiently assembling broken pottery shards. It also means reliving the events he's studying. For the last two summers, large crowds have flocked to an ancient Nemean stadium (capacity 40,000) to watch a modern re-enactment of the ancient Nemean games. Seven hundred runners from 45 nations bare foot and clad in white tunics raced around the reborn stadium in groups of 12. Winners of the races were crowned just as they were in antiquity with wreaths of wild celery. Miller is a professor of classics at the University of California at Berkeley, but he also has been a barefoot runner, a slave carrying water for the athletes and a priest presiding over the re-enacted rituals of the legendary Nemean games. Playing those roles gives you a deeper sense of antiquity and a feel for the spirit of the people who lived and worked and played there so long ago, he said recently after returning from this years field work. Excavating the site every summer since 1973, Miller and his crew have found and re-assembled limestone columns that once stood proudly around the Temple of Zeus. Exactly a decade after they began the excavation and just east of the temple, they found the remains of a great altar to Zeus where athletes and their trainers performed sacrifices and swore oaths just before competing. And from ancient Greek records, two years later, Millers team also learned that his Nemea site had once seen major horse races in a hippodrome that must have existed next to the great stadium. In an earthen mound his team could trace the patterns of faint wheel marks indicating that chariots must have raced there too. In 1997 Miller and his crew, seeking more evidence of the hippodrome, dug down into a spot where four low rock walls indicate there might be a structure underneath. There they found a wine jug, drinking mugs, coins and a crude little figure of a centaur. The next summer, after digging down 20 feet, they still hadnt reached bottom. Miller wondered what purpose this deep rock-walled pit might have served, and finally concluded it must have been a reservoir holding copious quantities of water from a river near the site that now irrigates vineyards. The reservoir is a phenomenal find, Miller said, We believe it provided water for as many as 150 horses who raced in the hippodrome during the games. But how were the horses fed? And what did they do with that much manure every day? Trying to answer questions like that is one of the joys of the whole project. Eight months after finding the reservoir Miller and his team uncovered an ancient chamber that served the Nemean athletes as a locker room the apodyterion where they anointed themselves with olive oil. They then would have walked 120 feet through a vaulted entrance tunnel the krypte esodos whose walls are still marked by graffiti scratched by the athletes on their way into the stadium. The wine jug and cups unearthed in one layer of the buried reservoir may have been left by victors in one of the ancient Nemean races, but just what kind of wine they drank remains unknown. Today, the local red wine served in Nemean taverns is called the Blood of Hercules, honoring the hero who strangled the ferocious Nemean lion there more than 5,000 years ago. As in so much of archaeology, the discoveries that Miller has made at Nemea all seem to recall ancient legends and link them to reality. The Berkeley team, for example, has unearthed a tiny bronze figurine identified as the image of an infant named Opheltes, whose fate inspired the first of the Nemean games. As Miller recounts the tale, Opheltes was the son of Lykourgos and Eurydike, who had tried for many years to produce an heir. When the Oracle at Delphi warned them that their child must not touch the ground until he had learned to walk, they ordered a Nemean slave woman to care for the infant day and night. One day, when seven warrior heroes passed through Nemea on their way to march against the citadel of Thebes they were the legendary Seven Against Thebes whose bloody war was immortalized by Aeschylus the nurse placed the child on a bed of wild celery while she offered drink to the heroes. Instantly, a serpent lurking in the vegetation killed the infant and the warriors re-named the boy Archemoros, the Beginner-of- Doom, and held the first Nemean games in his honor as a funerary festival. Wreaths of wild celery crowned winners of those games, as they did the modern winners at Nemea last summer. As with all classical archaeologists, whose excavations shed so much surprising light on antiquity, Miller and his students are now ready to organize and classify their treasured finds from the summer season, and to plan for next seasons dig. In the earthen mound where we saw the imprints of wheel cuts, we also have a bronze vessel of the kind that was always used for pouring libations, Miller said. That mound goes back to 600 B. C. , so now we wonder what happened there in that complex of religion and athletics even before the Nemean games. Archaeology doesnt come cheap, and each season at Nemea costs at least $150,000 for the team, the equipment, and the 35 local workers from the nearby town of modern Nemea, whom Miller calls the core of the project. The money all comes from private sources and not the least of Millers jobs is lecturing to the public and combing the territory for contributions.", "hypothesis": "The games were far more interesting in the past than now.", "gold_label": "neutral"}
{"uid": "id_759", "premise": "Zeus Temple Holds Secrets of Ancient Game Athens already is preparing for the summer games of 2004. But todays games offer a far different spectacle from the contests of ancient Greece, where naked young men with oiled bodies raced and wrestled and boxed to honor their gods. Those great Panhellenic events began more than 2,700 years ago, first in Olympia and later at Delphi, lsthmia and Nemea. And at Nemea, where the games began in 573 B. C. , a Berkeley archaeologist has been patiently reconstructing a site whose legends helped inspire the modern Olympics. For Stephen G. Miller, exploring the site at Nemea, 70 miles from Athens, involves more than analyzing artifacts and ruins, dating ancient rock strata or patiently assembling broken pottery shards. It also means reliving the events he's studying. For the last two summers, large crowds have flocked to an ancient Nemean stadium (capacity 40,000) to watch a modern re-enactment of the ancient Nemean games. Seven hundred runners from 45 nations bare foot and clad in white tunics raced around the reborn stadium in groups of 12. Winners of the races were crowned just as they were in antiquity with wreaths of wild celery. Miller is a professor of classics at the University of California at Berkeley, but he also has been a barefoot runner, a slave carrying water for the athletes and a priest presiding over the re-enacted rituals of the legendary Nemean games. Playing those roles gives you a deeper sense of antiquity and a feel for the spirit of the people who lived and worked and played there so long ago, he said recently after returning from this years field work. Excavating the site every summer since 1973, Miller and his crew have found and re-assembled limestone columns that once stood proudly around the Temple of Zeus. Exactly a decade after they began the excavation and just east of the temple, they found the remains of a great altar to Zeus where athletes and their trainers performed sacrifices and swore oaths just before competing. And from ancient Greek records, two years later, Millers team also learned that his Nemea site had once seen major horse races in a hippodrome that must have existed next to the great stadium. In an earthen mound his team could trace the patterns of faint wheel marks indicating that chariots must have raced there too. In 1997 Miller and his crew, seeking more evidence of the hippodrome, dug down into a spot where four low rock walls indicate there might be a structure underneath. There they found a wine jug, drinking mugs, coins and a crude little figure of a centaur. The next summer, after digging down 20 feet, they still hadnt reached bottom. Miller wondered what purpose this deep rock-walled pit might have served, and finally concluded it must have been a reservoir holding copious quantities of water from a river near the site that now irrigates vineyards. The reservoir is a phenomenal find, Miller said, We believe it provided water for as many as 150 horses who raced in the hippodrome during the games. But how were the horses fed? And what did they do with that much manure every day? Trying to answer questions like that is one of the joys of the whole project. Eight months after finding the reservoir Miller and his team uncovered an ancient chamber that served the Nemean athletes as a locker room the apodyterion where they anointed themselves with olive oil. They then would have walked 120 feet through a vaulted entrance tunnel the krypte esodos whose walls are still marked by graffiti scratched by the athletes on their way into the stadium. The wine jug and cups unearthed in one layer of the buried reservoir may have been left by victors in one of the ancient Nemean races, but just what kind of wine they drank remains unknown. Today, the local red wine served in Nemean taverns is called the Blood of Hercules, honoring the hero who strangled the ferocious Nemean lion there more than 5,000 years ago. As in so much of archaeology, the discoveries that Miller has made at Nemea all seem to recall ancient legends and link them to reality. The Berkeley team, for example, has unearthed a tiny bronze figurine identified as the image of an infant named Opheltes, whose fate inspired the first of the Nemean games. As Miller recounts the tale, Opheltes was the son of Lykourgos and Eurydike, who had tried for many years to produce an heir. When the Oracle at Delphi warned them that their child must not touch the ground until he had learned to walk, they ordered a Nemean slave woman to care for the infant day and night. One day, when seven warrior heroes passed through Nemea on their way to march against the citadel of Thebes they were the legendary Seven Against Thebes whose bloody war was immortalized by Aeschylus the nurse placed the child on a bed of wild celery while she offered drink to the heroes. Instantly, a serpent lurking in the vegetation killed the infant and the warriors re-named the boy Archemoros, the Beginner-of- Doom, and held the first Nemean games in his honor as a funerary festival. Wreaths of wild celery crowned winners of those games, as they did the modern winners at Nemea last summer. As with all classical archaeologists, whose excavations shed so much surprising light on antiquity, Miller and his students are now ready to organize and classify their treasured finds from the summer season, and to plan for next seasons dig. In the earthen mound where we saw the imprints of wheel cuts, we also have a bronze vessel of the kind that was always used for pouring libations, Miller said. That mound goes back to 600 B. C. , so now we wonder what happened there in that complex of religion and athletics even before the Nemean games. Archaeology doesnt come cheap, and each season at Nemea costs at least $150,000 for the team, the equipment, and the 35 local workers from the nearby town of modern Nemea, whom Miller calls the core of the project. The money all comes from private sources and not the least of Millers jobs is lecturing to the public and combing the territory for contributions.", "hypothesis": "The author believes it must be also difficult for Miller to find funds for the excavation.", "gold_label": "entailment"}
{"uid": "id_760", "premise": "Zeus Temple Holds Secrets of Ancient Game Athens already is preparing for the summer games of 2004. But todays games offer a far different spectacle from the contests of ancient Greece, where naked young men with oiled bodies raced and wrestled and boxed to honor their gods. Those great Panhellenic events began more than 2,700 years ago, first in Olympia and later at Delphi, lsthmia and Nemea. And at Nemea, where the games began in 573 B. C. , a Berkeley archaeologist has been patiently reconstructing a site whose legends helped inspire the modern Olympics. For Stephen G. Miller, exploring the site at Nemea, 70 miles from Athens, involves more than analyzing artifacts and ruins, dating ancient rock strata or patiently assembling broken pottery shards. It also means reliving the events he's studying. For the last two summers, large crowds have flocked to an ancient Nemean stadium (capacity 40,000) to watch a modern re-enactment of the ancient Nemean games. Seven hundred runners from 45 nations bare foot and clad in white tunics raced around the reborn stadium in groups of 12. Winners of the races were crowned just as they were in antiquity with wreaths of wild celery. Miller is a professor of classics at the University of California at Berkeley, but he also has been a barefoot runner, a slave carrying water for the athletes and a priest presiding over the re-enacted rituals of the legendary Nemean games. Playing those roles gives you a deeper sense of antiquity and a feel for the spirit of the people who lived and worked and played there so long ago, he said recently after returning from this years field work. Excavating the site every summer since 1973, Miller and his crew have found and re-assembled limestone columns that once stood proudly around the Temple of Zeus. Exactly a decade after they began the excavation and just east of the temple, they found the remains of a great altar to Zeus where athletes and their trainers performed sacrifices and swore oaths just before competing. And from ancient Greek records, two years later, Millers team also learned that his Nemea site had once seen major horse races in a hippodrome that must have existed next to the great stadium. In an earthen mound his team could trace the patterns of faint wheel marks indicating that chariots must have raced there too. In 1997 Miller and his crew, seeking more evidence of the hippodrome, dug down into a spot where four low rock walls indicate there might be a structure underneath. There they found a wine jug, drinking mugs, coins and a crude little figure of a centaur. The next summer, after digging down 20 feet, they still hadnt reached bottom. Miller wondered what purpose this deep rock-walled pit might have served, and finally concluded it must have been a reservoir holding copious quantities of water from a river near the site that now irrigates vineyards. The reservoir is a phenomenal find, Miller said, We believe it provided water for as many as 150 horses who raced in the hippodrome during the games. But how were the horses fed? And what did they do with that much manure every day? Trying to answer questions like that is one of the joys of the whole project. Eight months after finding the reservoir Miller and his team uncovered an ancient chamber that served the Nemean athletes as a locker room the apodyterion where they anointed themselves with olive oil. They then would have walked 120 feet through a vaulted entrance tunnel the krypte esodos whose walls are still marked by graffiti scratched by the athletes on their way into the stadium. The wine jug and cups unearthed in one layer of the buried reservoir may have been left by victors in one of the ancient Nemean races, but just what kind of wine they drank remains unknown. Today, the local red wine served in Nemean taverns is called the Blood of Hercules, honoring the hero who strangled the ferocious Nemean lion there more than 5,000 years ago. As in so much of archaeology, the discoveries that Miller has made at Nemea all seem to recall ancient legends and link them to reality. The Berkeley team, for example, has unearthed a tiny bronze figurine identified as the image of an infant named Opheltes, whose fate inspired the first of the Nemean games. As Miller recounts the tale, Opheltes was the son of Lykourgos and Eurydike, who had tried for many years to produce an heir. When the Oracle at Delphi warned them that their child must not touch the ground until he had learned to walk, they ordered a Nemean slave woman to care for the infant day and night. One day, when seven warrior heroes passed through Nemea on their way to march against the citadel of Thebes they were the legendary Seven Against Thebes whose bloody war was immortalized by Aeschylus the nurse placed the child on a bed of wild celery while she offered drink to the heroes. Instantly, a serpent lurking in the vegetation killed the infant and the warriors re-named the boy Archemoros, the Beginner-of- Doom, and held the first Nemean games in his honor as a funerary festival. Wreaths of wild celery crowned winners of those games, as they did the modern winners at Nemea last summer. As with all classical archaeologists, whose excavations shed so much surprising light on antiquity, Miller and his students are now ready to organize and classify their treasured finds from the summer season, and to plan for next seasons dig. In the earthen mound where we saw the imprints of wheel cuts, we also have a bronze vessel of the kind that was always used for pouring libations, Miller said. That mound goes back to 600 B. C. , so now we wonder what happened there in that complex of religion and athletics even before the Nemean games. Archaeology doesnt come cheap, and each season at Nemea costs at least $150,000 for the team, the equipment, and the 35 local workers from the nearby town of modern Nemea, whom Miller calls the core of the project. The money all comes from private sources and not the least of Millers jobs is lecturing to the public and combing the territory for contributions.", "hypothesis": "The Nemean games influenced the modern Olympic Games.", "gold_label": "entailment"}
{"uid": "id_761", "premise": "Zoo conservation programmes One of London Zoos recent advertisements caused me some irritation, so patently did it distort reality. Headlined Without zoos you might as well tell these animals to get stuffed, it was bordered with illustrations of several endangered species and went on to extol the myth that without zoos like London Zoo these animals will almost certainly disappear forever. With the zoo worlds rather mediocre record on conservation, one might be forgiven for being slightly sceptical about such an advertisement. Zoos were originally created as places of entertainment, and their suggested involvement with conservation didnt seriously arise until about 30 years ago, when the Zoological Society of London held the first formal international meeting on the subject. Eight years later, a series of world conferences took place, entitled The Breeding of Endangered Species, and from this point onwards conservation became the zoo communitys buzzword. This commitment has now been clearh defined in The World Zpo Conservation Strategy (WZGS, September 1993), which although an important and welcome document does seem to be based on an unrealistic optimism about the nature of the zoo industry The WZCS estimates that there are about 10,000 zoos in the world, of which around 1,000 represent a core of quality collections capable of participating in co-ordinated conservation programmes. This is probably the documents first failing, as I believe that 10,000 is a serious underestimate of the total number of places masquerading as zoological establishments. Of course it is difficult to get accurate data but, to put the issue into perspective, I have found that, in a year of working in Eastern Europe, I discover fresh zoos on almost a weekly basis. The second flaw in the reasoning of the WZCS document is the naive faith it places in its 1,000 core zoos. One would assume that the calibre of these institutions would have been carefully examined, but it appears that the criterion for inclusion on this select list might merely be that the zoo is a member of a zoo federation or association. This might be a good starting point, working on the premise that members must meet certain standards, but again the facts dont support the theory. The greatly respected American Association of Zoological Parks and Aquariums (AAZPA) has had extremely dubious members, and in the UK the Federation of Zoological Gardens of Great Britain and Ireland has 24Reading occasionally had members that have been roundly censured in the national press. These include Robin Hill Adventure Park on the Isle of Wight, which many considered the most notorious collection of animals in the country. This establishment, which for years was protected by the Isles local council (which viewed it as a tourist amenity), was finally closed down following a damning report by a veterinary inspector appointed under the terms of the Zoo Licensing Act 1981. As it was always a collection of dubious repute, one is obliged to reflect upon the standards that the Zoo Federation sets when granting membership. The situation is even worse in developing countries where little money is available for redevelopment and it is hard to see a way of incorporating collections into the overall scheme of the WZCS. Even assuming that the WZCSs 1,000 core zoos are all of a high standard complete with scientific staff and research facilities, trained and dedicated keepers, accommodation that permits normal or natural behaviour, and a policy of co-operating fully with one another what might be the potential for conservation? Colin Tudge, author of Last Animals at the Zoo (Oxford University Press, 1992), argues that if the worlds zoos worked together in co-operative breeding programmes, then even without further expansion they could save around 2,000 species of endangered land vertebrates. This seems an extremely optimistic proposition from a man who must be aware of the failings and weaknesses of the zoo industry the man who, when a member of the council of London Zoo, had to persuade the zoo to devote more of its activities to conservation. Moreover, where are the facts to support such optimism? Today approximately 16 species might be said to have been saved by captive breeding programmes, although a number of these can hardly be looked upon as resounding successes. Beyond that, about a further 20 species are being seriously considered for zoo conservation programmes. Given that the international conference at London Zoo was held 30 years ago, this is pretty slow progress, and a long way off Tudges target of 2,000.", "hypothesis": "The number of successful zoo conservation programmes is unsatisfactory.", "gold_label": "entailment"}
{"uid": "id_762", "premise": "Zoo conservation programmes One of London Zoos recent advertisements caused me some irritation, so patently did it distort reality. Headlined Without zoos you might as well tell these animals to get stuffed, it was bordered with illustrations of several endangered species and went on to extol the myth that without zoos like London Zoo these animals will almost certainly disappear forever. With the zoo worlds rather mediocre record on conservation, one might be forgiven for being slightly sceptical about such an advertisement. Zoos were originally created as places of entertainment, and their suggested involvement with conservation didnt seriously arise until about 30 years ago, when the Zoological Society of London held the first formal international meeting on the subject. Eight years later, a series of world conferences took place, entitled The Breeding of Endangered Species, and from this point onwards conservation became the zoo communitys buzzword. This commitment has now been clearh defined in The World Zpo Conservation Strategy (WZGS, September 1993), which although an important and welcome document does seem to be based on an unrealistic optimism about the nature of the zoo industry The WZCS estimates that there are about 10,000 zoos in the world, of which around 1,000 represent a core of quality collections capable of participating in co-ordinated conservation programmes. This is probably the documents first failing, as I believe that 10,000 is a serious underestimate of the total number of places masquerading as zoological establishments. Of course it is difficult to get accurate data but, to put the issue into perspective, I have found that, in a year of working in Eastern Europe, I discover fresh zoos on almost a weekly basis. The second flaw in the reasoning of the WZCS document is the naive faith it places in its 1,000 core zoos. One would assume that the calibre of these institutions would have been carefully examined, but it appears that the criterion for inclusion on this select list might merely be that the zoo is a member of a zoo federation or association. This might be a good starting point, working on the premise that members must meet certain standards, but again the facts dont support the theory. The greatly respected American Association of Zoological Parks and Aquariums (AAZPA) has had extremely dubious members, and in the UK the Federation of Zoological Gardens of Great Britain and Ireland has 24Reading occasionally had members that have been roundly censured in the national press. These include Robin Hill Adventure Park on the Isle of Wight, which many considered the most notorious collection of animals in the country. This establishment, which for years was protected by the Isles local council (which viewed it as a tourist amenity), was finally closed down following a damning report by a veterinary inspector appointed under the terms of the Zoo Licensing Act 1981. As it was always a collection of dubious repute, one is obliged to reflect upon the standards that the Zoo Federation sets when granting membership. The situation is even worse in developing countries where little money is available for redevelopment and it is hard to see a way of incorporating collections into the overall scheme of the WZCS. Even assuming that the WZCSs 1,000 core zoos are all of a high standard complete with scientific staff and research facilities, trained and dedicated keepers, accommodation that permits normal or natural behaviour, and a policy of co-operating fully with one another what might be the potential for conservation? Colin Tudge, author of Last Animals at the Zoo (Oxford University Press, 1992), argues that if the worlds zoos worked together in co-operative breeding programmes, then even without further expansion they could save around 2,000 species of endangered land vertebrates. This seems an extremely optimistic proposition from a man who must be aware of the failings and weaknesses of the zoo industry the man who, when a member of the council of London Zoo, had to persuade the zoo to devote more of its activities to conservation. Moreover, where are the facts to support such optimism? Today approximately 16 species might be said to have been saved by captive breeding programmes, although a number of these can hardly be looked upon as resounding successes. Beyond that, about a further 20 species are being seriously considered for zoo conservation programmes. Given that the international conference at London Zoo was held 30 years ago, this is pretty slow progress, and a long way off Tudges target of 2,000.", "hypothesis": "Colin Tudge was dissatisfied with the treatment of animals at London Zoo.", "gold_label": "neutral"}
{"uid": "id_763", "premise": "Zoo conservation programmes One of London Zoos recent advertisements caused me some irritation, so patently did it distort reality. Headlined Without zoos you might as well tell these animals to get stuffed, it was bordered with illustrations of several endangered species and went on to extol the myth that without zoos like London Zoo these animals will almost certainly disappear forever. With the zoo worlds rather mediocre record on conservation, one might be forgiven for being slightly sceptical about such an advertisement. Zoos were originally created as places of entertainment, and their suggested involvement with conservation didnt seriously arise until about 30 years ago, when the Zoological Society of London held the first formal international meeting on the subject. Eight years later, a series of world conferences took place, entitled The Breeding of Endangered Species, and from this point onwards conservation became the zoo communitys buzzword. This commitment has now been clearh defined in The World Zpo Conservation Strategy (WZGS, September 1993), which although an important and welcome document does seem to be based on an unrealistic optimism about the nature of the zoo industry The WZCS estimates that there are about 10,000 zoos in the world, of which around 1,000 represent a core of quality collections capable of participating in co-ordinated conservation programmes. This is probably the documents first failing, as I believe that 10,000 is a serious underestimate of the total number of places masquerading as zoological establishments. Of course it is difficult to get accurate data but, to put the issue into perspective, I have found that, in a year of working in Eastern Europe, I discover fresh zoos on almost a weekly basis. The second flaw in the reasoning of the WZCS document is the naive faith it places in its 1,000 core zoos. One would assume that the calibre of these institutions would have been carefully examined, but it appears that the criterion for inclusion on this select list might merely be that the zoo is a member of a zoo federation or association. This might be a good starting point, working on the premise that members must meet certain standards, but again the facts dont support the theory. The greatly respected American Association of Zoological Parks and Aquariums (AAZPA) has had extremely dubious members, and in the UK the Federation of Zoological Gardens of Great Britain and Ireland has 24Reading occasionally had members that have been roundly censured in the national press. These include Robin Hill Adventure Park on the Isle of Wight, which many considered the most notorious collection of animals in the country. This establishment, which for years was protected by the Isles local council (which viewed it as a tourist amenity), was finally closed down following a damning report by a veterinary inspector appointed under the terms of the Zoo Licensing Act 1981. As it was always a collection of dubious repute, one is obliged to reflect upon the standards that the Zoo Federation sets when granting membership. The situation is even worse in developing countries where little money is available for redevelopment and it is hard to see a way of incorporating collections into the overall scheme of the WZCS. Even assuming that the WZCSs 1,000 core zoos are all of a high standard complete with scientific staff and research facilities, trained and dedicated keepers, accommodation that permits normal or natural behaviour, and a policy of co-operating fully with one another what might be the potential for conservation? Colin Tudge, author of Last Animals at the Zoo (Oxford University Press, 1992), argues that if the worlds zoos worked together in co-operative breeding programmes, then even without further expansion they could save around 2,000 species of endangered land vertebrates. This seems an extremely optimistic proposition from a man who must be aware of the failings and weaknesses of the zoo industry the man who, when a member of the council of London Zoo, had to persuade the zoo to devote more of its activities to conservation. Moreover, where are the facts to support such optimism? Today approximately 16 species might be said to have been saved by captive breeding programmes, although a number of these can hardly be looked upon as resounding successes. Beyond that, about a further 20 species are being seriously considered for zoo conservation programmes. Given that the international conference at London Zoo was held 30 years ago, this is pretty slow progress, and a long way off Tudges target of 2,000.", "hypothesis": "London Zoos advertisements are dishonest.", "gold_label": "entailment"}
{"uid": "id_764", "premise": "Zoo conservation programmes One of London Zoos recent advertisements caused me some irritation, so patently did it distort reality. Headlined Without zoos you might as well tell these animals to get stuffed, it was bordered with illustrations of several endangered species and went on to extol the myth that without zoos like London Zoo these animals will almost certainly disappear forever. With the zoo worlds rather mediocre record on conservation, one might be forgiven for being slightly sceptical about such an advertisement. Zoos were originally created as places of entertainment, and their suggested involvement with conservation didnt seriously arise until about 30 years ago, when the Zoological Society of London held the first formal international meeting on the subject. Eight years later, a series of world conferences took place, entitled The Breeding of Endangered Species, and from this point onwards conservation became the zoo communitys buzzword. This commitment has now been clearh defined in The World Zpo Conservation Strategy (WZGS, September 1993), which although an important and welcome document does seem to be based on an unrealistic optimism about the nature of the zoo industry The WZCS estimates that there are about 10,000 zoos in the world, of which around 1,000 represent a core of quality collections capable of participating in co-ordinated conservation programmes. This is probably the documents first failing, as I believe that 10,000 is a serious underestimate of the total number of places masquerading as zoological establishments. Of course it is difficult to get accurate data but, to put the issue into perspective, I have found that, in a year of working in Eastern Europe, I discover fresh zoos on almost a weekly basis. The second flaw in the reasoning of the WZCS document is the naive faith it places in its 1,000 core zoos. One would assume that the calibre of these institutions would have been carefully examined, but it appears that the criterion for inclusion on this select list might merely be that the zoo is a member of a zoo federation or association. This might be a good starting point, working on the premise that members must meet certain standards, but again the facts dont support the theory. The greatly respected American Association of Zoological Parks and Aquariums (AAZPA) has had extremely dubious members, and in the UK the Federation of Zoological Gardens of Great Britain and Ireland has 24Reading occasionally had members that have been roundly censured in the national press. These include Robin Hill Adventure Park on the Isle of Wight, which many considered the most notorious collection of animals in the country. This establishment, which for years was protected by the Isles local council (which viewed it as a tourist amenity), was finally closed down following a damning report by a veterinary inspector appointed under the terms of the Zoo Licensing Act 1981. As it was always a collection of dubious repute, one is obliged to reflect upon the standards that the Zoo Federation sets when granting membership. The situation is even worse in developing countries where little money is available for redevelopment and it is hard to see a way of incorporating collections into the overall scheme of the WZCS. Even assuming that the WZCSs 1,000 core zoos are all of a high standard complete with scientific staff and research facilities, trained and dedicated keepers, accommodation that permits normal or natural behaviour, and a policy of co-operating fully with one another what might be the potential for conservation? Colin Tudge, author of Last Animals at the Zoo (Oxford University Press, 1992), argues that if the worlds zoos worked together in co-operative breeding programmes, then even without further expansion they could save around 2,000 species of endangered land vertebrates. This seems an extremely optimistic proposition from a man who must be aware of the failings and weaknesses of the zoo industry the man who, when a member of the council of London Zoo, had to persuade the zoo to devote more of its activities to conservation. Moreover, where are the facts to support such optimism? Today approximately 16 species might be said to have been saved by captive breeding programmes, although a number of these can hardly be looked upon as resounding successes. Beyond that, about a further 20 species are being seriously considered for zoo conservation programmes. Given that the international conference at London Zoo was held 30 years ago, this is pretty slow progress, and a long way off Tudges target of 2,000.", "hypothesis": "Zoos made an insignificant contribution to conservation up until 30 years ago.", "gold_label": "entailment"}
{"uid": "id_765", "premise": "Zoo conservation programmes One of London Zoos recent advertisements caused me some irritation, so patently did it distort reality. Headlined Without zoos you might as well tell these animals to get stuffed, it was bordered with illustrations of several endangered species and went on to extol the myth that without zoos like London Zoo these animals will almost certainly disappear forever. With the zoo worlds rather mediocre record on conservation, one might be forgiven for being slightly sceptical about such an advertisement. Zoos were originally created as places of entertainment, and their suggested involvement with conservation didnt seriously arise until about 30 years ago, when the Zoological Society of London held the first formal international meeting on the subject. Eight years later, a series of world conferences took place, entitled The Breeding of Endangered Species, and from this point onwards conservation became the zoo communitys buzzword. This commitment has now been clearh defined in The World Zpo Conservation Strategy (WZGS, September 1993), which although an important and welcome document does seem to be based on an unrealistic optimism about the nature of the zoo industry The WZCS estimates that there are about 10,000 zoos in the world, of which around 1,000 represent a core of quality collections capable of participating in co-ordinated conservation programmes. This is probably the documents first failing, as I believe that 10,000 is a serious underestimate of the total number of places masquerading as zoological establishments. Of course it is difficult to get accurate data but, to put the issue into perspective, I have found that, in a year of working in Eastern Europe, I discover fresh zoos on almost a weekly basis. The second flaw in the reasoning of the WZCS document is the naive faith it places in its 1,000 core zoos. One would assume that the calibre of these institutions would have been carefully examined, but it appears that the criterion for inclusion on this select list might merely be that the zoo is a member of a zoo federation or association. This might be a good starting point, working on the premise that members must meet certain standards, but again the facts dont support the theory. The greatly respected American Association of Zoological Parks and Aquariums (AAZPA) has had extremely dubious members, and in the UK the Federation of Zoological Gardens of Great Britain and Ireland has 24Reading occasionally had members that have been roundly censured in the national press. These include Robin Hill Adventure Park on the Isle of Wight, which many considered the most notorious collection of animals in the country. This establishment, which for years was protected by the Isles local council (which viewed it as a tourist amenity), was finally closed down following a damning report by a veterinary inspector appointed under the terms of the Zoo Licensing Act 1981. As it was always a collection of dubious repute, one is obliged to reflect upon the standards that the Zoo Federation sets when granting membership. The situation is even worse in developing countries where little money is available for redevelopment and it is hard to see a way of incorporating collections into the overall scheme of the WZCS. Even assuming that the WZCSs 1,000 core zoos are all of a high standard complete with scientific staff and research facilities, trained and dedicated keepers, accommodation that permits normal or natural behaviour, and a policy of co-operating fully with one another what might be the potential for conservation? Colin Tudge, author of Last Animals at the Zoo (Oxford University Press, 1992), argues that if the worlds zoos worked together in co-operative breeding programmes, then even without further expansion they could save around 2,000 species of endangered land vertebrates. This seems an extremely optimistic proposition from a man who must be aware of the failings and weaknesses of the zoo industry the man who, when a member of the council of London Zoo, had to persuade the zoo to devote more of its activities to conservation. Moreover, where are the facts to support such optimism? Today approximately 16 species might be said to have been saved by captive breeding programmes, although a number of these can hardly be looked upon as resounding successes. Beyond that, about a further 20 species are being seriously considered for zoo conservation programmes. Given that the international conference at London Zoo was held 30 years ago, this is pretty slow progress, and a long way off Tudges target of 2,000.", "hypothesis": "No-one knew how the animals were being treated at Robin Hill Adventure Park.", "gold_label": "contradiction"}
{"uid": "id_766", "premise": "Zoo conservation programmes One of London Zoos recent advertisements caused me some irritation, so patently did it distort reality. Headlined Without zoos you might as well tell these animals to get stuffed, it was bordered with illustrations of several endangered species and went on to extol the myth that without zoos like London Zoo these animals will almost certainly disappear forever. With the zoo worlds rather mediocre record on conservation, one might be forgiven for being slightly sceptical about such an advertisement. Zoos were originally created as places of entertainment, and their suggested involvement with conservation didnt seriously arise until about 30 years ago, when the Zoological Society of London held the first formal international meeting on the subject. Eight years later, a series of world conferences took place, entitled The Breeding of Endangered Species, and from this point onwards conservation became the zoo communitys buzzword. This commitment has now been clearh defined in The World Zpo Conservation Strategy (WZGS, September 1993), which although an important and welcome document does seem to be based on an unrealistic optimism about the nature of the zoo industry The WZCS estimates that there are about 10,000 zoos in the world, of which around 1,000 represent a core of quality collections capable of participating in co-ordinated conservation programmes. This is probably the documents first failing, as I believe that 10,000 is a serious underestimate of the total number of places masquerading as zoological establishments. Of course it is difficult to get accurate data but, to put the issue into perspective, I have found that, in a year of working in Eastern Europe, I discover fresh zoos on almost a weekly basis. The second flaw in the reasoning of the WZCS document is the naive faith it places in its 1,000 core zoos. One would assume that the calibre of these institutions would have been carefully examined, but it appears that the criterion for inclusion on this select list might merely be that the zoo is a member of a zoo federation or association. This might be a good starting point, working on the premise that members must meet certain standards, but again the facts dont support the theory. The greatly respected American Association of Zoological Parks and Aquariums (AAZPA) has had extremely dubious members, and in the UK the Federation of Zoological Gardens of Great Britain and Ireland has 24Reading occasionally had members that have been roundly censured in the national press. These include Robin Hill Adventure Park on the Isle of Wight, which many considered the most notorious collection of animals in the country. This establishment, which for years was protected by the Isles local council (which viewed it as a tourist amenity), was finally closed down following a damning report by a veterinary inspector appointed under the terms of the Zoo Licensing Act 1981. As it was always a collection of dubious repute, one is obliged to reflect upon the standards that the Zoo Federation sets when granting membership. The situation is even worse in developing countries where little money is available for redevelopment and it is hard to see a way of incorporating collections into the overall scheme of the WZCS. Even assuming that the WZCSs 1,000 core zoos are all of a high standard complete with scientific staff and research facilities, trained and dedicated keepers, accommodation that permits normal or natural behaviour, and a policy of co-operating fully with one another what might be the potential for conservation? Colin Tudge, author of Last Animals at the Zoo (Oxford University Press, 1992), argues that if the worlds zoos worked together in co-operative breeding programmes, then even without further expansion they could save around 2,000 species of endangered land vertebrates. This seems an extremely optimistic proposition from a man who must be aware of the failings and weaknesses of the zoo industry the man who, when a member of the council of London Zoo, had to persuade the zoo to devote more of its activities to conservation. Moreover, where are the facts to support such optimism? Today approximately 16 species might be said to have been saved by captive breeding programmes, although a number of these can hardly be looked upon as resounding successes. Beyond that, about a further 20 species are being seriously considered for zoo conservation programmes. Given that the international conference at London Zoo was held 30 years ago, this is pretty slow progress, and a long way off Tudges target of 2,000.", "hypothesis": "The WZCS document is not known in Eastern Europe.", "gold_label": "neutral"}
{"uid": "id_767", "premise": "Zoo conservation programmes One of London Zoos recent advertisements caused me some irritation, so patently did it distort reality. Headlined Without zoos you might as well tell these animals to get stuffed, it was bordered with illustrations of several endangered species and went on to extol the myth that without zoos like London Zoo these animals will almost certainly disappear forever. With the zoo worlds rather mediocre record on conservation, one might be forgiven for being slightly sceptical about such an advertisement. Zoos were originally created as places of entertainment, and their suggested involvement with conservation didnt seriously arise until about 30 years ago, when the Zoological Society of London held the first formal international meeting on the subject. Eight years later, a series of world conferences took place, entitled The Breeding of Endangered Species, and from this point onwards conservation became the zoo communitys buzzword. This commitment has now been clearh defined in The World Zpo Conservation Strategy (WZGS, September 1993), which although an important and welcome document does seem to be based on an unrealistic optimism about the nature of the zoo industry The WZCS estimates that there are about 10,000 zoos in the world, of which around 1,000 represent a core of quality collections capable of participating in co-ordinated conservation programmes. This is probably the documents first failing, as I believe that 10,000 is a serious underestimate of the total number of places masquerading as zoological establishments. Of course it is difficult to get accurate data but, to put the issue into perspective, I have found that, in a year of working in Eastern Europe, I discover fresh zoos on almost a weekly basis. The second flaw in the reasoning of the WZCS document is the naive faith it places in its 1,000 core zoos. One would assume that the calibre of these institutions would have been carefully examined, but it appears that the criterion for inclusion on this select list might merely be that the zoo is a member of a zoo federation or association. This might be a good starting point, working on the premise that members must meet certain standards, but again the facts dont support the theory. The greatly respected American Association of Zoological Parks and Aquariums (AAZPA) has had extremely dubious members, and in the UK the Federation of Zoological Gardens of Great Britain and Ireland has 24Reading occasionally had members that have been roundly censured in the national press. These include Robin Hill Adventure Park on the Isle of Wight, which many considered the most notorious collection of animals in the country. This establishment, which for years was protected by the Isles local council (which viewed it as a tourist amenity), was finally closed down following a damning report by a veterinary inspector appointed under the terms of the Zoo Licensing Act 1981. As it was always a collection of dubious repute, one is obliged to reflect upon the standards that the Zoo Federation sets when granting membership. The situation is even worse in developing countries where little money is available for redevelopment and it is hard to see a way of incorporating collections into the overall scheme of the WZCS. Even assuming that the WZCSs 1,000 core zoos are all of a high standard complete with scientific staff and research facilities, trained and dedicated keepers, accommodation that permits normal or natural behaviour, and a policy of co-operating fully with one another what might be the potential for conservation? Colin Tudge, author of Last Animals at the Zoo (Oxford University Press, 1992), argues that if the worlds zoos worked together in co-operative breeding programmes, then even without further expansion they could save around 2,000 species of endangered land vertebrates. This seems an extremely optimistic proposition from a man who must be aware of the failings and weaknesses of the zoo industry the man who, when a member of the council of London Zoo, had to persuade the zoo to devote more of its activities to conservation. Moreover, where are the facts to support such optimism? Today approximately 16 species might be said to have been saved by captive breeding programmes, although a number of these can hardly be looked upon as resounding successes. Beyond that, about a further 20 species are being seriously considered for zoo conservation programmes. Given that the international conference at London Zoo was held 30 years ago, this is pretty slow progress, and a long way off Tudges target of 2,000.", "hypothesis": "Zoos in the WZCS select list were carefully inspected.", "gold_label": "contradiction"}
{"uid": "id_768", "premise": "asset liquidity and market liquidity Asset liquidity is influenced by the mobility of market. Stock market exchanges liquidable finacial instruments such as bonds and shares. Some assets are not liquidable due to market is said to be \"illiquid\".", "hypothesis": "Asset liquidity is influenced by the market mobility.", "gold_label": "entailment"}
{"uid": "id_769", "premise": "asset liquidity and market liquidity Asset liquidity is influenced by the mobility of market. Stock market exchanges liquidable finacial instruments such as bonds and shares. Some assets are not liquidable due to market is said to be \"illiquid\".", "hypothesis": "Some assets are not liquidable on the market because they are unsellable.", "gold_label": "neutral"}
{"uid": "id_770", "premise": "asset liquidity and market liquidity Asset liquidity is influenced by the mobility of market. Stock market exchanges liquidable finacial instruments such as bonds and shares. Some assets are not liquidable due to market is said to be \"illiquid\".", "hypothesis": "Bonds and stocks are \"illiquid\" on the market.", "gold_label": "contradiction"}
{"uid": "id_771", "premise": "directors should work with all other groups in the community", "hypothesis": "the group's meetings are solely for directors", "gold_label": "contradiction"}
{"uid": "id_772", "premise": "final salary and commission distributionFinal Salary Scheme: -They provide benefits according to a fixed formula. The benefits are based on salary on the date of retirement (Guarantee payment of a fraction of the final salary)-Employer assumed all risk -Both the employer and the employee will make contributions into this type of pension scheme -Benefits not depend on investment returns or annuity rateFinal salary exists before world war two, final salary system requires more pension funds that the company has to pay for employees, and distribution salary reduces cost. Companies adopt distribution salary have fewer employees register scheme.", "hypothesis": "Company wants more to use the distribution salary than final salary.", "gold_label": "entailment"}
{"uid": "id_773", "premise": "final salary and commission distributionFinal Salary Scheme: -They provide benefits according to a fixed formula. The benefits are based on salary on the date of retirement (Guarantee payment of a fraction of the final salary)-Employer assumed all risk -Both the employer and the employee will make contributions into this type of pension scheme -Benefits not depend on investment returns or annuity rateFinal salary exists before world war two, final salary system requires more pension funds that the company has to pay for employees, and distribution salary reduces cost. Companies adopt distribution salary have fewer employees register scheme.", "hypothesis": "The popularization of distribution salary drives its uptake.", "gold_label": "contradiction"}
{"uid": "id_774", "premise": "final salary and commission distributionFinal Salary Scheme: -They provide benefits according to a fixed formula. The benefits are based on salary on the date of retirement (Guarantee payment of a fraction of the final salary)-Employer assumed all risk -Both the employer and the employee will make contributions into this type of pension scheme -Benefits not depend on investment returns or annuity rateFinal salary exists before world war two, final salary system requires more pension funds that the company has to pay for employees, and distribution salary reduces cost. Companies adopt distribution salary have fewer employees register scheme.", "hypothesis": "Distribution salary reduces cost", "gold_label": "entailment"}
{"uid": "id_775", "premise": "final salary and commission distributionFinal Salary Scheme: -They provide benefits according to a fixed formula. The benefits are based on salary on the date of retirement (Guarantee payment of a fraction of the final salary)-Employer assumed all risk -Both the employer and the employee will make contributions into this type of pension scheme -Benefits not depend on investment returns or annuity rateFinal salary exists before world war two, final salary system requires more pension funds that the company has to pay for employees, and distribution salary reduces cost. Companies adopt distribution salary have fewer employees register scheme.", "hypothesis": "There are fewer companies that use final salary system.", "gold_label": "neutral"}
{"uid": "id_776", "premise": "globalisation is causing a shift in the roles of government and business. Since the end of the Cold war the rivalry between nations has assumed a predominantly economic form. Foreign policy is increasingly subordinated to commercial policy. Yet at the same time the joint interests of national governments and corporations are diverging. As corporations become more independent of their national roots, governments will have to attract foreign business investment to become globally competitive. However, because the population at large is unenthusiastic about globalisation, governments risk gaining business while losing votes.", "hypothesis": "The general public does not understand the advantages of competing at the global level.", "gold_label": "neutral"}
{"uid": "id_777", "premise": "globalisation is causing a shift in the roles of government and business. Since the end of the Cold war the rivalry between nations has assumed a predominantly economic form. Foreign policy is increasingly subordinated to commercial policy. Yet at the same time the joint interests of national governments and corporations are diverging. As corporations become more independent of their national roots, governments will have to attract foreign business investment to become globally competitive. However, because the population at large is unenthusiastic about globalisation, governments risk gaining business while losing votes.", "hypothesis": "Governments and corporations used to have more similar interests.", "gold_label": "entailment"}
{"uid": "id_778", "premise": "he Large Hadron Collider (LHC), located underneath the border of France and Switzerland, 1s currently the biggest experiment in the world. Its construction mvolved 9,000 magnets and over 10,000 tons of nitrogen are used for its cooling processes. Scientists and engineers have spent 4.5 billion on building an underground track at CERN, the worlds largest particle physics laboratory. This enormous scientific instrument will collect a huge amount of data, but only a small percentage of what is recorded will be useful. When proton atoms travelling almost at light speed collide inside the LHC, theoretical physicists expect new forces and particles to be produced. It may even be possible to study black holes using this experiment.", "hypothesis": "The LHC 1s the largest experiment ever conducted in Europe.", "gold_label": "entailment"}
{"uid": "id_779", "premise": "he Large Hadron Collider (LHC), located underneath the border of France and Switzerland, 1s currently the biggest experiment in the world. Its construction mvolved 9,000 magnets and over 10,000 tons of nitrogen are used for its cooling processes. Scientists and engineers have spent 4.5 billion on building an underground track at CERN, the worlds largest particle physics laboratory. This enormous scientific instrument will collect a huge amount of data, but only a small percentage of what is recorded will be useful. When proton atoms travelling almost at light speed collide inside the LHC, theoretical physicists expect new forces and particles to be produced. It may even be possible to study black holes using this experiment.", "hypothesis": "The cost of the LHCs track was over 4.5 billion.", "gold_label": "contradiction"}
{"uid": "id_780", "premise": "he Large Hadron Collider (LHC), located underneath the border of France and Switzerland, 1s currently the biggest experiment in the world. Its construction mvolved 9,000 magnets and over 10,000 tons of nitrogen are used for its cooling processes. Scientists and engineers have spent 4.5 billion on building an underground track at CERN, the worlds largest particle physics laboratory. This enormous scientific instrument will collect a huge amount of data, but only a small percentage of what is recorded will be useful. When proton atoms travelling almost at light speed collide inside the LHC, theoretical physicists expect new forces and particles to be produced. It may even be possible to study black holes using this experiment.", "hypothesis": "Protons travel around the LHC at light speed.", "gold_label": "contradiction"}
{"uid": "id_781", "premise": "he Large Hadron Collider (LHC), located underneath the border of France and Switzerland, 1s currently the biggest experiment in the world. Its construction mvolved 9,000 magnets and over 10,000 tons of nitrogen are used for its cooling processes. Scientists and engineers have spent 4.5 billion on building an underground track at CERN, the worlds largest particle physics laboratory. This enormous scientific instrument will collect a huge amount of data, but only a small percentage of what is recorded will be useful. When proton atoms travelling almost at light speed collide inside the LHC, theoretical physicists expect new forces and particles to be produced. It may even be possible to study black holes using this experiment.", "hypothesis": "The LHC was designed to study black holes.", "gold_label": "contradiction"}
{"uid": "id_782", "premise": "he Large Hadron Collider (LHC), located underneath the border of France and Switzerland, 1s currently the biggest experiment in the world. Its construction mvolved 9,000 magnets and over 10,000 tons of nitrogen are used for its cooling processes. Scientists and engineers have spent 4.5 billion on building an underground track at CERN, the worlds largest particle physics laboratory. This enormous scientific instrument will collect a huge amount of data, but only a small percentage of what is recorded will be useful. When proton atoms travelling almost at light speed collide inside the LHC, theoretical physicists expect new forces and particles to be produced. It may even be possible to study black holes using this experiment.", "hypothesis": "The LHC uses over 10,000 tons of oxygen for its coohng processes.", "gold_label": "contradiction"}
{"uid": "id_783", "premise": "he concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influential 1960 book Centuries of Childhood, written by French historian Aries. He argued that \"childhood\" is a concept created by modern society. A. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries, and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. B. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense children are seen as 'useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. C. With industrialization in the eighteenth and nineteenth centuries, a newdemand for child labour was created, and many children were forced to work for long hours, in mines, workshops and factories. Social reformers began to question whether labouring long hours from an early age would harm children's growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting children's development. D. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labour redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as 'useful' children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development and learning. Even so, work continued to play a significant, if less central role in children's lives throughout the later nineteenth and twentieth century. And the 'useful child' has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the world's children engaged in child labour. E. The Factory Act of 1833 established half-time schools which allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or 11. The situation was very different by the end of the nineteenth century in Britain. The school became central to images of 'a normal' childhood . F. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, children's lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behaviour and morals of the young. Education dominated the management of children's waking hours, not just through the hours spent in classrooms but through 'home' work, the growth of 'after school' activities and the importance attached to 'parental involvement. G. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting children's welfare, and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess children's progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "During the Middle Age, going to work necessarily means children were unloved indicated by Aries.", "gold_label": "contradiction"}
{"uid": "id_784", "premise": "he concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influential 1960 book Centuries of Childhood, written by French historian Aries. He argued that \"childhood\" is a concept created by modern society. A. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries, and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. B. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense children are seen as 'useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. C. With industrialization in the eighteenth and nineteenth centuries, a newdemand for child labour was created, and many children were forced to work for long hours, in mines, workshops and factories. Social reformers began to question whether labouring long hours from an early age would harm children's growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting children's development. D. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labour redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as 'useful' children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development and learning. Even so, work continued to play a significant, if less central role in children's lives throughout the later nineteenth and twentieth century. And the 'useful child' has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the world's children engaged in child labour. E. The Factory Act of 1833 established half-time schools which allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or 11. The situation was very different by the end of the nineteenth century in Britain. The school became central to images of 'a normal' childhood . F. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, children's lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behaviour and morals of the young. Education dominated the management of children's waking hours, not just through the hours spent in classrooms but through 'home' work, the growth of 'after school' activities and the importance attached to 'parental involvement. G. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting children's welfare, and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess children's progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "Scientists think that overworked labour damages the health of young children", "gold_label": "entailment"}
{"uid": "id_785", "premise": "he concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influential 1960 book Centuries of Childhood, written by French historian Aries. He argued that \"childhood\" is a concept created by modern society. A. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries, and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. B. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense children are seen as 'useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. C. With industrialization in the eighteenth and nineteenth centuries, a newdemand for child labour was created, and many children were forced to work for long hours, in mines, workshops and factories. Social reformers began to question whether labouring long hours from an early age would harm children's growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting children's development. D. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labour redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as 'useful' children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development and learning. Even so, work continued to play a significant, if less central role in children's lives throughout the later nineteenth and twentieth century. And the 'useful child' has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the world's children engaged in child labour. E. The Factory Act of 1833 established half-time schools which allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or 11. The situation was very different by the end of the nineteenth century in Britain. The school became central to images of 'a normal' childhood . F. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, children's lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behaviour and morals of the young. Education dominated the management of children's waking hours, not just through the hours spent in classrooms but through 'home' work, the growth of 'after school' activities and the importance attached to 'parental involvement. G. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting children's welfare, and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess children's progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "Aries pointed out that children did different types of work as adults during the Middle Age.", "gold_label": "contradiction"}
{"uid": "id_786", "premise": "he concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influential 1960 book Centuries of Childhood, written by French historian Aries. He argued that \"childhood\" is a concept created by modern society. A. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries, and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. B. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense children are seen as 'useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. C. With industrialization in the eighteenth and nineteenth centuries, a newdemand for child labour was created, and many children were forced to work for long hours, in mines, workshops and factories. Social reformers began to question whether labouring long hours from an early age would harm children's growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting children's development. D. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labour redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as 'useful' children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development and learning. Even so, work continued to play a significant, if less central role in children's lives throughout the later nineteenth and twentieth century. And the 'useful child' has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the world's children engaged in child labour. E. The Factory Act of 1833 established half-time schools which allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or 11. The situation was very different by the end of the nineteenth century in Britain. The school became central to images of 'a normal' childhood . F. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, children's lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behaviour and morals of the young. Education dominated the management of children's waking hours, not just through the hours spent in classrooms but through 'home' work, the growth of 'after school' activities and the importance attached to 'parental involvement. G. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting children's welfare, and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess children's progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "the rise of trade union majorly contributed to the protection children fromexploitation in 19 th century", "gold_label": "neutral"}
{"uid": "id_787", "premise": "he concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influential 1960 book Centuries of Childhood, written by French historian Aries. He argued that \"childhood\" is a concept created by modern society. A. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries, and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. B. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense children are seen as 'useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. C. With industrialization in the eighteenth and nineteenth centuries, a newdemand for child labour was created, and many children were forced to work for long hours, in mines, workshops and factories. Social reformers began to question whether labouring long hours from an early age would harm children's growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting children's development. D. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labour redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as 'useful' children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development and learning. Even so, work continued to play a significant, if less central role in children's lives throughout the later nineteenth and twentieth century. And the 'useful child' has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the world's children engaged in child labour. E. The Factory Act of 1833 established half-time schools which allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or 11. The situation was very different by the end of the nineteenth century in Britain. The school became central to images of 'a normal' childhood . F. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, children's lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behaviour and morals of the young. Education dominated the management of children's waking hours, not just through the hours spent in classrooms but through 'home' work, the growth of 'after school' activities and the importance attached to 'parental involvement. G. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting children's welfare, and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess children's progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "By the aid of half-time schools, most children went to school in the mid of 19 century.", "gold_label": "contradiction"}
{"uid": "id_788", "premise": "he concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influential 1960 book Centuries of Childhood, written by French historian Aries. He argued that \"childhood\" is a concept created by modern society. A. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries, and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. B. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense children are seen as 'useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. C. With industrialization in the eighteenth and nineteenth centuries, a newdemand for child labour was created, and many children were forced to work for long hours, in mines, workshops and factories. Social reformers began to question whether labouring long hours from an early age would harm children's growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting children's development. D. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labour redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as 'useful' children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development and learning. Even so, work continued to play a significant, if less central role in children's lives throughout the later nineteenth and twentieth century. And the 'useful child' has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the world's children engaged in child labour. E. The Factory Act of 1833 established half-time schools which allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or 11. The situation was very different by the end of the nineteenth century in Britain. The school became central to images of 'a normal' childhood . F. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, children's lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behaviour and morals of the young. Education dominated the management of children's waking hours, not just through the hours spent in classrooms but through 'home' work, the growth of 'after school' activities and the importance attached to 'parental involvement. G. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting children's welfare, and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess children's progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "In 20 century almost all children need to go to school in full time schedule.", "gold_label": "neutral"}
{"uid": "id_789", "premise": "he concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influential 1960 book Centuries of Childhood, written by French historian Aries. He argued that \"childhood\" is a concept created by modern society. A. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries, and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. B. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense children are seen as 'useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. C. With industrialization in the eighteenth and nineteenth centuries, a newdemand for child labour was created, and many children were forced to work for long hours, in mines, workshops and factories. Social reformers began to question whether labouring long hours from an early age would harm children's growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting children's development. D. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labour redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as 'useful' children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development and learning. Even so, work continued to play a significant, if less central role in children's lives throughout the later nineteenth and twentieth century. And the 'useful child' has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the world's children engaged in child labour. E. The Factory Act of 1833 established half-time schools which allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or 11. The situation was very different by the end of the nineteenth century in Britain. The school became central to images of 'a normal' childhood . F. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, children's lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behaviour and morals of the young. Education dominated the management of children's waking hours, not just through the hours spent in classrooms but through 'home' work, the growth of 'after school' activities and the importance attached to 'parental involvement. G. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting children's welfare, and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess children's progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "Nowadays, childrens needs were much differentiated and categorised based on how old they are", "gold_label": "entailment"}
{"uid": "id_790", "premise": "lack of water is an ever-worsening global crisis, with over forty percent of the worlds population now suffering from regular and severe water shortage. Increases in population mean that there is less water available per capita. In addition, pollution-related global warming is making some countries, which were already short of water, even hotter and drier(). Demand for water is doubling every twenty year and there are predictions that, in the future, nations may go to war to fight for its control.", "hypothesis": "Neither climate change nor population expansion are exacerbating the water shortage problem.", "gold_label": "contradiction"}
{"uid": "id_791", "premise": "lack of water is an ever-worsening global crisis, with over forty percent of the worlds population now suffering from regular and severe water shortage. Increases in population mean that there is less water available per capita. In addition, pollution-related global warming is making some countries, which were already short of water, even hotter and drier(). Demand for water is doubling every twenty year and there are predictions that, in the future, nations may go to war to fight for its control.", "hypothesis": "Oil shortages, more than a lack of water, are likely to result in war.", "gold_label": "neutral"}
{"uid": "id_792", "premise": "lack of water is an ever-worsening global crisis, with over forty percent of the worlds population now suffering from regular and severe water shortage. Increases in population mean that there is less water available per capita. In addition, pollution-related global warming is making some countries, which were already short of water, even hotter and drier(). Demand for water is doubling every twenty year and there are predictions that, in the future, nations may go to war to fight for its control.", "hypothesis": "Some countries are not affected by global warning.", "gold_label": "neutral"}
{"uid": "id_793", "premise": "new weapon to fight cancer British scientists are preparing to launch trials of a radical new way to fight cancer, which kills tumours by infecting them with viruses like the common cold. If successful, virus therapy could eventually form a third pillar alongside radiotherapy and chemotherapy in the standard arsenal against cancer, while avoiding some of the debilitating side-effects. Leonard Seymour, a professor of gene therapy at Oxford University, who has been working on the virus therapy with colleagues in London and the US, will lead the trials later this year. Cancer Research UK said yesterday that it was excited by the potential of Prof Seymour's pioneering techniques. One of the country's leading geneticists, Prof Seymour has been working with viruses that kill cancer cells directly, while avoiding harm to healthy tissue. \"In principle, you've got something which could be many times more effective than regular chemotherapy, \" he said. Cancer-killing viruses exploit the fact that cancer cells suppress the body's local immune system. \"If a cancer doesn't do that, the immune system wipes it out. If you can get a virus into a tumour, viruses find them a very good place to be because there's no immune system to stop them replicating. You can regard it as the cancer's Achilles' heel. \" Only a small amount of the virus needs to get to the cancer. \"They replicate, you get a million copies in each cell and the cell bursts and they infect the tumour cells adjacent and repeat the process, \" said Prof Seymour. Preliminary research on mice shows that the viruses work well on tumours resistant to standard cancer drugs. \"It's an interesting possibility that they may have an advantage in killing drug-resistant tumours, which could be quite different to anything we've had before. \" Researchers have known for some time that viruses can kill tumour cells and some aspects of the work have already been published in scientific journals. American scientists have previously injected viruses directly into tumours but this technique will not work if the cancer is inaccessible or has spread throughout the body. Prof Seymour's innovative solution is to mask the virus from the body's immune system, effectively allowing the viruses to do what chemotherapy drugs do - spread through the blood and reach tumours wherever they are. The big hurdle has always been to find a way to deliver viruses to tumours via the bloodstream without the body's immune system destroying them on the way. \"What we've done is make chemical modifications to the virus to put a polymer coat around it - it's a stealth virus when you inject it, \" he said. After the stealth virus infects the tumour, it replicates, but the copies do not have the chemical modifications. If they escape from the tumour, the copies will be quickly recognised and mopped up by the body's immune system. The therapy would be especially useful for secondary cancers, called metastases, which sometimes spread around the body after the first tumour appears. \"There's an awful statistic of patients in the west ... with malignant cancers; 75% of them go on to die from metastases, \" said Prof Seymour. Two viruses are likely to be examined in the first clinical trials: adenovirus, which normally causes a cold-like illness, and vaccinia, which causes cowpox and is also used in the vaccine against smallpox. For safety reasons, both will be disabled to make them less pathogenic in the trial, but Prof Seymour said he eventually hopes to use natural viruses. The first trials will use uncoated adenovirus and vaccinia and will be delivered locally to liver tumours, in order to establish whether the treatment is safe in humans and what dose of virus will be needed. Several more years of trials will be needed, eventually also on the polymer-coated viruses, before the therapy can be considered for use in the NHS. Though the approach will be examined at first for cancers that do not respond to conventional treatments, Prof Seymour hopes that one day it might be applied to all cancers.", "hypothesis": "Virus therapy, if successful, has an advantage in eliminating side-effects.", "gold_label": "contradiction"}
{"uid": "id_794", "premise": "new weapon to fight cancer British scientists are preparing to launch trials of a radical new way to fight cancer, which kills tumours by infecting them with viruses like the common cold. If successful, virus therapy could eventually form a third pillar alongside radiotherapy and chemotherapy in the standard arsenal against cancer, while avoiding some of the debilitating side-effects. Leonard Seymour, a professor of gene therapy at Oxford University, who has been working on the virus therapy with colleagues in London and the US, will lead the trials later this year. Cancer Research UK said yesterday that it was excited by the potential of Prof Seymour's pioneering techniques. One of the country's leading geneticists, Prof Seymour has been working with viruses that kill cancer cells directly, while avoiding harm to healthy tissue. \"In principle, you've got something which could be many times more effective than regular chemotherapy, \" he said. Cancer-killing viruses exploit the fact that cancer cells suppress the body's local immune system. \"If a cancer doesn't do that, the immune system wipes it out. If you can get a virus into a tumour, viruses find them a very good place to be because there's no immune system to stop them replicating. You can regard it as the cancer's Achilles' heel. \" Only a small amount of the virus needs to get to the cancer. \"They replicate, you get a million copies in each cell and the cell bursts and they infect the tumour cells adjacent and repeat the process, \" said Prof Seymour. Preliminary research on mice shows that the viruses work well on tumours resistant to standard cancer drugs. \"It's an interesting possibility that they may have an advantage in killing drug-resistant tumours, which could be quite different to anything we've had before. \" Researchers have known for some time that viruses can kill tumour cells and some aspects of the work have already been published in scientific journals. American scientists have previously injected viruses directly into tumours but this technique will not work if the cancer is inaccessible or has spread throughout the body. Prof Seymour's innovative solution is to mask the virus from the body's immune system, effectively allowing the viruses to do what chemotherapy drugs do - spread through the blood and reach tumours wherever they are. The big hurdle has always been to find a way to deliver viruses to tumours via the bloodstream without the body's immune system destroying them on the way. \"What we've done is make chemical modifications to the virus to put a polymer coat around it - it's a stealth virus when you inject it, \" he said. After the stealth virus infects the tumour, it replicates, but the copies do not have the chemical modifications. If they escape from the tumour, the copies will be quickly recognised and mopped up by the body's immune system. The therapy would be especially useful for secondary cancers, called metastases, which sometimes spread around the body after the first tumour appears. \"There's an awful statistic of patients in the west ... with malignant cancers; 75% of them go on to die from metastases, \" said Prof Seymour. Two viruses are likely to be examined in the first clinical trials: adenovirus, which normally causes a cold-like illness, and vaccinia, which causes cowpox and is also used in the vaccine against smallpox. For safety reasons, both will be disabled to make them less pathogenic in the trial, but Prof Seymour said he eventually hopes to use natural viruses. The first trials will use uncoated adenovirus and vaccinia and will be delivered locally to liver tumours, in order to establish whether the treatment is safe in humans and what dose of virus will be needed. Several more years of trials will be needed, eventually also on the polymer-coated viruses, before the therapy can be considered for use in the NHS. Though the approach will be examined at first for cancers that do not respond to conventional treatments, Prof Seymour hopes that one day it might be applied to all cancers.", "hypothesis": "Cancer Research UK is quite hopeful about Professor Seymours work on the virus therapy.", "gold_label": "entailment"}
{"uid": "id_795", "premise": "new weapon to fight cancer British scientists are preparing to launch trials of a radical new way to fight cancer, which kills tumours by infecting them with viruses like the common cold. If successful, virus therapy could eventually form a third pillar alongside radiotherapy and chemotherapy in the standard arsenal against cancer, while avoiding some of the debilitating side-effects. Leonard Seymour, a professor of gene therapy at Oxford University, who has been working on the virus therapy with colleagues in London and the US, will lead the trials later this year. Cancer Research UK said yesterday that it was excited by the potential of Prof Seymour's pioneering techniques. One of the country's leading geneticists, Prof Seymour has been working with viruses that kill cancer cells directly, while avoiding harm to healthy tissue. \"In principle, you've got something which could be many times more effective than regular chemotherapy, \" he said. Cancer-killing viruses exploit the fact that cancer cells suppress the body's local immune system. \"If a cancer doesn't do that, the immune system wipes it out. If you can get a virus into a tumour, viruses find them a very good place to be because there's no immune system to stop them replicating. You can regard it as the cancer's Achilles' heel. \" Only a small amount of the virus needs to get to the cancer. \"They replicate, you get a million copies in each cell and the cell bursts and they infect the tumour cells adjacent and repeat the process, \" said Prof Seymour. Preliminary research on mice shows that the viruses work well on tumours resistant to standard cancer drugs. \"It's an interesting possibility that they may have an advantage in killing drug-resistant tumours, which could be quite different to anything we've had before. \" Researchers have known for some time that viruses can kill tumour cells and some aspects of the work have already been published in scientific journals. American scientists have previously injected viruses directly into tumours but this technique will not work if the cancer is inaccessible or has spread throughout the body. Prof Seymour's innovative solution is to mask the virus from the body's immune system, effectively allowing the viruses to do what chemotherapy drugs do - spread through the blood and reach tumours wherever they are. The big hurdle has always been to find a way to deliver viruses to tumours via the bloodstream without the body's immune system destroying them on the way. \"What we've done is make chemical modifications to the virus to put a polymer coat around it - it's a stealth virus when you inject it, \" he said. After the stealth virus infects the tumour, it replicates, but the copies do not have the chemical modifications. If they escape from the tumour, the copies will be quickly recognised and mopped up by the body's immune system. The therapy would be especially useful for secondary cancers, called metastases, which sometimes spread around the body after the first tumour appears. \"There's an awful statistic of patients in the west ... with malignant cancers; 75% of them go on to die from metastases, \" said Prof Seymour. Two viruses are likely to be examined in the first clinical trials: adenovirus, which normally causes a cold-like illness, and vaccinia, which causes cowpox and is also used in the vaccine against smallpox. For safety reasons, both will be disabled to make them less pathogenic in the trial, but Prof Seymour said he eventually hopes to use natural viruses. The first trials will use uncoated adenovirus and vaccinia and will be delivered locally to liver tumours, in order to establish whether the treatment is safe in humans and what dose of virus will be needed. Several more years of trials will be needed, eventually also on the polymer-coated viruses, before the therapy can be considered for use in the NHS. Though the approach will be examined at first for cancers that do not respond to conventional treatments, Prof Seymour hopes that one day it might be applied to all cancers.", "hypothesis": "Virus can kill cancer cells and stop them from growing again.", "gold_label": "neutral"}
{"uid": "id_796", "premise": "new weapon to fight cancer British scientists are preparing to launch trials of a radical new way to fight cancer, which kills tumours by infecting them with viruses like the common cold. If successful, virus therapy could eventually form a third pillar alongside radiotherapy and chemotherapy in the standard arsenal against cancer, while avoiding some of the debilitating side-effects. Leonard Seymour, a professor of gene therapy at Oxford University, who has been working on the virus therapy with colleagues in London and the US, will lead the trials later this year. Cancer Research UK said yesterday that it was excited by the potential of Prof Seymour's pioneering techniques. One of the country's leading geneticists, Prof Seymour has been working with viruses that kill cancer cells directly, while avoiding harm to healthy tissue. \"In principle, you've got something which could be many times more effective than regular chemotherapy, \" he said. Cancer-killing viruses exploit the fact that cancer cells suppress the body's local immune system. \"If a cancer doesn't do that, the immune system wipes it out. If you can get a virus into a tumour, viruses find them a very good place to be because there's no immune system to stop them replicating. You can regard it as the cancer's Achilles' heel. \" Only a small amount of the virus needs to get to the cancer. \"They replicate, you get a million copies in each cell and the cell bursts and they infect the tumour cells adjacent and repeat the process, \" said Prof Seymour. Preliminary research on mice shows that the viruses work well on tumours resistant to standard cancer drugs. \"It's an interesting possibility that they may have an advantage in killing drug-resistant tumours, which could be quite different to anything we've had before. \" Researchers have known for some time that viruses can kill tumour cells and some aspects of the work have already been published in scientific journals. American scientists have previously injected viruses directly into tumours but this technique will not work if the cancer is inaccessible or has spread throughout the body. Prof Seymour's innovative solution is to mask the virus from the body's immune system, effectively allowing the viruses to do what chemotherapy drugs do - spread through the blood and reach tumours wherever they are. The big hurdle has always been to find a way to deliver viruses to tumours via the bloodstream without the body's immune system destroying them on the way. \"What we've done is make chemical modifications to the virus to put a polymer coat around it - it's a stealth virus when you inject it, \" he said. After the stealth virus infects the tumour, it replicates, but the copies do not have the chemical modifications. If they escape from the tumour, the copies will be quickly recognised and mopped up by the body's immune system. The therapy would be especially useful for secondary cancers, called metastases, which sometimes spread around the body after the first tumour appears. \"There's an awful statistic of patients in the west ... with malignant cancers; 75% of them go on to die from metastases, \" said Prof Seymour. Two viruses are likely to be examined in the first clinical trials: adenovirus, which normally causes a cold-like illness, and vaccinia, which causes cowpox and is also used in the vaccine against smallpox. For safety reasons, both will be disabled to make them less pathogenic in the trial, but Prof Seymour said he eventually hopes to use natural viruses. The first trials will use uncoated adenovirus and vaccinia and will be delivered locally to liver tumours, in order to establish whether the treatment is safe in humans and what dose of virus will be needed. Several more years of trials will be needed, eventually also on the polymer-coated viruses, before the therapy can be considered for use in the NHS. Though the approach will be examined at first for cancers that do not respond to conventional treatments, Prof Seymour hopes that one day it might be applied to all cancers.", "hypothesis": "Cancers Achilles heel refers to the fact that virus may stay safely in a tumor and replicate.", "gold_label": "entailment"}
{"uid": "id_797", "premise": "new weapon to fight cancer British scientists are preparing to launch trials of a radical new way to fight cancer, which kills tumours by infecting them with viruses like the common cold. If successful, virus therapy could eventually form a third pillar alongside radiotherapy and chemotherapy in the standard arsenal against cancer, while avoiding some of the debilitating side-effects. Leonard Seymour, a professor of gene therapy at Oxford University, who has been working on the virus therapy with colleagues in London and the US, will lead the trials later this year. Cancer Research UK said yesterday that it was excited by the potential of Prof Seymour's pioneering techniques. One of the country's leading geneticists, Prof Seymour has been working with viruses that kill cancer cells directly, while avoiding harm to healthy tissue. \"In principle, you've got something which could be many times more effective than regular chemotherapy, \" he said. Cancer-killing viruses exploit the fact that cancer cells suppress the body's local immune system. \"If a cancer doesn't do that, the immune system wipes it out. If you can get a virus into a tumour, viruses find them a very good place to be because there's no immune system to stop them replicating. You can regard it as the cancer's Achilles' heel. \" Only a small amount of the virus needs to get to the cancer. \"They replicate, you get a million copies in each cell and the cell bursts and they infect the tumour cells adjacent and repeat the process, \" said Prof Seymour. Preliminary research on mice shows that the viruses work well on tumours resistant to standard cancer drugs. \"It's an interesting possibility that they may have an advantage in killing drug-resistant tumours, which could be quite different to anything we've had before. \" Researchers have known for some time that viruses can kill tumour cells and some aspects of the work have already been published in scientific journals. American scientists have previously injected viruses directly into tumours but this technique will not work if the cancer is inaccessible or has spread throughout the body. Prof Seymour's innovative solution is to mask the virus from the body's immune system, effectively allowing the viruses to do what chemotherapy drugs do - spread through the blood and reach tumours wherever they are. The big hurdle has always been to find a way to deliver viruses to tumours via the bloodstream without the body's immune system destroying them on the way. \"What we've done is make chemical modifications to the virus to put a polymer coat around it - it's a stealth virus when you inject it, \" he said. After the stealth virus infects the tumour, it replicates, but the copies do not have the chemical modifications. If they escape from the tumour, the copies will be quickly recognised and mopped up by the body's immune system. The therapy would be especially useful for secondary cancers, called metastases, which sometimes spread around the body after the first tumour appears. \"There's an awful statistic of patients in the west ... with malignant cancers; 75% of them go on to die from metastases, \" said Prof Seymour. Two viruses are likely to be examined in the first clinical trials: adenovirus, which normally causes a cold-like illness, and vaccinia, which causes cowpox and is also used in the vaccine against smallpox. For safety reasons, both will be disabled to make them less pathogenic in the trial, but Prof Seymour said he eventually hopes to use natural viruses. The first trials will use uncoated adenovirus and vaccinia and will be delivered locally to liver tumours, in order to establish whether the treatment is safe in humans and what dose of virus will be needed. Several more years of trials will be needed, eventually also on the polymer-coated viruses, before the therapy can be considered for use in the NHS. Though the approach will be examined at first for cancers that do not respond to conventional treatments, Prof Seymour hopes that one day it might be applied to all cancers.", "hypothesis": "To infect the cancer cells, a good deal of viruses should be injected into the tumor.", "gold_label": "contradiction"}
{"uid": "id_798", "premise": "new weapon to fight cancer British scientists are preparing to launch trials of a radical new way to fight cancer, which kills tumours by infecting them with viruses like the common cold. If successful, virus therapy could eventually form a third pillar alongside radiotherapy and chemotherapy in the standard arsenal against cancer, while avoiding some of the debilitating side-effects. Leonard Seymour, a professor of gene therapy at Oxford University, who has been working on the virus therapy with colleagues in London and the US, will lead the trials later this year. Cancer Research UK said yesterday that it was excited by the potential of Prof Seymour's pioneering techniques. One of the country's leading geneticists, Prof Seymour has been working with viruses that kill cancer cells directly, while avoiding harm to healthy tissue. \"In principle, you've got something which could be many times more effective than regular chemotherapy, \" he said. Cancer-killing viruses exploit the fact that cancer cells suppress the body's local immune system. \"If a cancer doesn't do that, the immune system wipes it out. If you can get a virus into a tumour, viruses find them a very good place to be because there's no immune system to stop them replicating. You can regard it as the cancer's Achilles' heel. \" Only a small amount of the virus needs to get to the cancer. \"They replicate, you get a million copies in each cell and the cell bursts and they infect the tumour cells adjacent and repeat the process, \" said Prof Seymour. Preliminary research on mice shows that the viruses work well on tumours resistant to standard cancer drugs. \"It's an interesting possibility that they may have an advantage in killing drug-resistant tumours, which could be quite different to anything we've had before. \" Researchers have known for some time that viruses can kill tumour cells and some aspects of the work have already been published in scientific journals. American scientists have previously injected viruses directly into tumours but this technique will not work if the cancer is inaccessible or has spread throughout the body. Prof Seymour's innovative solution is to mask the virus from the body's immune system, effectively allowing the viruses to do what chemotherapy drugs do - spread through the blood and reach tumours wherever they are. The big hurdle has always been to find a way to deliver viruses to tumours via the bloodstream without the body's immune system destroying them on the way. \"What we've done is make chemical modifications to the virus to put a polymer coat around it - it's a stealth virus when you inject it, \" he said. After the stealth virus infects the tumour, it replicates, but the copies do not have the chemical modifications. If they escape from the tumour, the copies will be quickly recognised and mopped up by the body's immune system. The therapy would be especially useful for secondary cancers, called metastases, which sometimes spread around the body after the first tumour appears. \"There's an awful statistic of patients in the west ... with malignant cancers; 75% of them go on to die from metastases, \" said Prof Seymour. Two viruses are likely to be examined in the first clinical trials: adenovirus, which normally causes a cold-like illness, and vaccinia, which causes cowpox and is also used in the vaccine against smallpox. For safety reasons, both will be disabled to make them less pathogenic in the trial, but Prof Seymour said he eventually hopes to use natural viruses. The first trials will use uncoated adenovirus and vaccinia and will be delivered locally to liver tumours, in order to establish whether the treatment is safe in humans and what dose of virus will be needed. Several more years of trials will be needed, eventually also on the polymer-coated viruses, before the therapy can be considered for use in the NHS. Though the approach will be examined at first for cancers that do not respond to conventional treatments, Prof Seymour hopes that one day it might be applied to all cancers.", "hypothesis": "Researches on animals indicate that virus could be used as a new way to treat drug-resistant tumors.", "gold_label": "entailment"}
{"uid": "id_799", "premise": "some time on the night of October 1st, the Copacabana Club was burnt to the ground. The police are treating the fire as suspicious. The only facts known at this stage are: The club was insured for more than its real value. The club belonged to John Hodges. Les Braithwaite was known to dislike John Hodges. Between October 1st and October 2nd, Les Braithwaite was away from home on a business trip. There were no fatalities. A plan of the club was found in Les Braithwaite's flat.", "hypothesis": "John Hodges could have been at the club when the fire took place.", "gold_label": "entailment"}
{"uid": "id_800", "premise": "some time on the night of October 1st, the Copacabana Club was burnt to the ground. The police are treating the fire as suspicious. The only facts known at this stage are: The club was insured for more than its real value. The club belonged to John Hodges. Les Braithwaite was known to dislike John Hodges. Between October 1st and October 2nd, Les Braithwaite was away from home on a business trip. There were no fatalities. A plan of the club was found in Les Braithwaite's flat.", "hypothesis": "The flat where the plan was found is close to the club.", "gold_label": "neutral"}
{"uid": "id_801", "premise": "some time on the night of October 1st, the Copacabana Club was burnt to the ground. The police are treating the fire as suspicious. The only facts known at this stage are: The club was insured for more than its real value. The club belonged to John Hodges. Les Braithwaite was known to dislike John Hodges. Between October 1st and October 2nd, Les Braithwaite was away from home on a business trip. There were no fatalities. A plan of the club was found in Les Braithwaite's flat.", "hypothesis": "A member of John Hodges' family died in the blaze", "gold_label": "contradiction"}
{"uid": "id_802", "premise": "some time on the night of October 1st, the Copacabana Club was burnt to the ground. The police are treating the fire as suspicious. The only facts known at this stage are: The club was insured for more than its real value. The club belonged to John Hodges. Les Braithwaite was known to dislike John Hodges. Between October 1st and October 2nd, Les Braithwaite was away from home on a business trip. There were no fatalities. A plan of the club was found in Les Braithwaite's flat.", "hypothesis": "There are definite grounds to arrest John Hodges for arson.", "gold_label": "contradiction"}
{"uid": "id_803", "premise": "some time on the night of October 1st, the Copacabana Club was burnt to the ground. The police are treating the fire as suspicious. The only facts known at this stage are: The club was insured for more than its real value. The club belonged to John Hodges. Les Braithwaite was known to dislike John Hodges. Between October 1st and October 2nd, Les Braithwaite was away from home on a business trip. There were no fatalities. A plan of the club was found in Les Braithwaite's flat.", "hypothesis": "If the insurance company pays out in full, John Hodges stands to profit from the fire.", "gold_label": "neutral"}
{"uid": "id_0", "premise": "The concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influence 1960 book Centuries of Childhood, written by French historian Philippe Aries. He argued that childhood is a concept created by modern society. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries, and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense children are seen as useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. With industrialization in the eighteenth and nineteenth centuries, a new demand for child labor was created, and many children were forced to work for long hours, in mines, workshops and factories. Social reformers began to question whether laboring long hours from an early age would harm childrens growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting childrens development. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labor redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as useful children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development and learning. Even so, work continued to play a significant, if less central role in childrens lives throughout the later nineteenth and twentieth century. And the useful child has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the worlds children engaged in child labor. The Factory Act of 1833 established half-time schools which allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or 11. The situation was very different by the end of the nineteenth century in Britain. The school became central to linages of a normal childhood. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, childrens lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behavior and morals of the young. Education dominated the management of childrens waking hours, not just through the hours spent in classrooms but through home work, the growth of after school activities and the importance attached to parental involvement. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting childrens welfare, and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess childrens progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "In 20 th century almost all children needed to go to school in full time schedule", "gold_label": "neutral"}
{"uid": "id_1", "premise": "The concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influence 1960 book Centuries of Childhood, written by French historian Philippe Aries. He argued that childhood is a concept created by modern society. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries, and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense children are seen as useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. With industrialization in the eighteenth and nineteenth centuries, a new demand for child labor was created, and many children were forced to work for long hours, in mines, workshops and factories. Social reformers began to question whether laboring long hours from an early age would harm childrens growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting childrens development. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labor redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as useful children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development and learning. Even so, work continued to play a significant, if less central role in childrens lives throughout the later nineteenth and twentieth century. And the useful child has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the worlds children engaged in child labor. The Factory Act of 1833 established half-time schools which allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or 11. The situation was very different by the end of the nineteenth century in Britain. The school became central to linages of a normal childhood. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, childrens lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behavior and morals of the young. Education dominated the management of childrens waking hours, not just through the hours spent in classrooms but through home work, the growth of after school activities and the importance attached to parental involvement. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting childrens welfare, and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess childrens progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "By the aid of half-time schools, most children went to school in the mid of 19 th century.", "gold_label": "contradiction"}
{"uid": "id_2", "premise": "The concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influence 1960 book Centuries of Childhood, written by French historian Philippe Aries. He argued that childhood is a concept created by modern society. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries, and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense children are seen as useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. With industrialization in the eighteenth and nineteenth centuries, a new demand for child labor was created, and many children were forced to work for long hours, in mines, workshops and factories. Social reformers began to question whether laboring long hours from an early age would harm childrens growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting childrens development. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labor redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as useful children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development and learning. Even so, work continued to play a significant, if less central role in childrens lives throughout the later nineteenth and twentieth century. And the useful child has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the worlds children engaged in child labor. The Factory Act of 1833 established half-time schools which allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or 11. The situation was very different by the end of the nineteenth century in Britain. The school became central to linages of a normal childhood. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, childrens lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behavior and morals of the young. Education dominated the management of childrens waking hours, not just through the hours spent in classrooms but through home work, the growth of after school activities and the importance attached to parental involvement. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting childrens welfare, and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess childrens progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "the rise of trade union majorly contributed to the protection children from exploitation in 19 th century", "gold_label": "neutral"}
{"uid": "id_3", "premise": "The concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influence 1960 book Centuries of Childhood, written by French historian Philippe Aries. He argued that childhood is a concept created by modern society. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries, and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense children are seen as useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. With industrialization in the eighteenth and nineteenth centuries, a new demand for child labor was created, and many children were forced to work for long hours, in mines, workshops and factories. Social reformers began to question whether laboring long hours from an early age would harm childrens growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting childrens development. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labor redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as useful children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development and learning. Even so, work continued to play a significant, if less central role in childrens lives throughout the later nineteenth and twentieth century. And the useful child has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the worlds children engaged in child labor. The Factory Act of 1833 established half-time schools which allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or 11. The situation was very different by the end of the nineteenth century in Britain. The school became central to linages of a normal childhood. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, childrens lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behavior and morals of the young. Education dominated the management of childrens waking hours, not just through the hours spent in classrooms but through home work, the growth of after school activities and the importance attached to parental involvement. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting childrens welfare, and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess childrens progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "Scientists think that overworked labor damages the health of young children", "gold_label": "entailment"}
{"uid": "id_4", "premise": "The concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influence 1960 book Centuries of Childhood, written by French historian Philippe Aries. He argued that childhood is a concept created by modern society. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries, and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense children are seen as useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. With industrialization in the eighteenth and nineteenth centuries, a new demand for child labor was created, and many children were forced to work for long hours, in mines, workshops and factories. Social reformers began to question whether laboring long hours from an early age would harm childrens growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting childrens development. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labor redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as useful children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development and learning. Even so, work continued to play a significant, if less central role in childrens lives throughout the later nineteenth and twentieth century. And the useful child has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the worlds children engaged in child labor. The Factory Act of 1833 established half-time schools which allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or 11. The situation was very different by the end of the nineteenth century in Britain. The school became central to linages of a normal childhood. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, childrens lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behavior and morals of the young. Education dominated the management of childrens waking hours, not just through the hours spent in classrooms but through home work, the growth of after school activities and the importance attached to parental involvement. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting childrens welfare, and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess childrens progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "Aries pointed out that children did different types of work as adults during the Middle Age.", "gold_label": "contradiction"}
{"uid": "id_5", "premise": "The concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influence 1960 book Centuries of Childhood, written by French historian Philippe Aries. He argued that childhood is a concept created by modern society. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries, and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense children are seen as useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. With industrialization in the eighteenth and nineteenth centuries, a new demand for child labor was created, and many children were forced to work for long hours, in mines, workshops and factories. Social reformers began to question whether laboring long hours from an early age would harm childrens growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting childrens development. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labor redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as useful children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development and learning. Even so, work continued to play a significant, if less central role in childrens lives throughout the later nineteenth and twentieth century. And the useful child has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the worlds children engaged in child labor. The Factory Act of 1833 established half-time schools which allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or 11. The situation was very different by the end of the nineteenth century in Britain. The school became central to linages of a normal childhood. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, childrens lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behavior and morals of the young. Education dominated the management of childrens waking hours, not just through the hours spent in classrooms but through home work, the growth of after school activities and the importance attached to parental involvement. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting childrens welfare, and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess childrens progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "During the Middle Age, going to work necessarily means children were unloved indicated by Aries.", "gold_label": "entailment"}
{"uid": "id_6", "premise": "The concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influential 1960 book Centuries of Childhood, written by French historian Philippe Aries. He argued that childhood is a concept created by modern society. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense, children are seen as useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. With industrialization in the eighteenth and nineteenth centuries, a new demand for child labor was created, and many children were forced to work for long hours, in mines, workshops, and factories. Social reformers began to question whether laboring long hours from an early age would harm childrens growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting childrens development. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labor redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as useful children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development, and learning. Even so, work continued to play a significant, if less central role in childrens lives throughout the later nineteenth and twentieth century. And the useful child, has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the worlds children engaged in child labor. The Factory Act of 1833 established half-time schools that allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or11. The situation was very different by the end of the nineteenth century in Britain. The school became central to images of7a normal childhood. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, childrens lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behavior, and morals of the young. Education dominated the management of childrens waking hours, not just through the hours spent in classrooms but through /home/ work, the growth of after school7 activities and the importance attached to parental involvement. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting childrens welfare and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess childrens progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "By the aid of half-time schools, most children went to school in the mid of 19 century.", "gold_label": "contradiction"}
{"uid": "id_7", "premise": "The concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influential 1960 book Centuries of Childhood, written by French historian Philippe Aries. He argued that childhood is a concept created by modern society. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense, children are seen as useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. With industrialization in the eighteenth and nineteenth centuries, a new demand for child labor was created, and many children were forced to work for long hours, in mines, workshops, and factories. Social reformers began to question whether laboring long hours from an early age would harm childrens growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting childrens development. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labor redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as useful children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development, and learning. Even so, work continued to play a significant, if less central role in childrens lives throughout the later nineteenth and twentieth century. And the useful child, has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the worlds children engaged in child labor. The Factory Act of 1833 established half-time schools that allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or11. The situation was very different by the end of the nineteenth century in Britain. The school became central to images of7a normal childhood. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, childrens lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behavior, and morals of the young. Education dominated the management of childrens waking hours, not just through the hours spent in classrooms but through /home/ work, the growth of after school7 activities and the importance attached to parental involvement. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting childrens welfare and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess childrens progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "the rise of trade union majorly contributed to the protection of children from exploitation in the 19th century", "gold_label": "neutral"}
{"uid": "id_8", "premise": "The concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influential 1960 book Centuries of Childhood, written by French historian Philippe Aries. He argued that childhood is a concept created by modern society. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense, children are seen as useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. With industrialization in the eighteenth and nineteenth centuries, a new demand for child labor was created, and many children were forced to work for long hours, in mines, workshops, and factories. Social reformers began to question whether laboring long hours from an early age would harm childrens growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting childrens development. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labor redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as useful children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development, and learning. Even so, work continued to play a significant, if less central role in childrens lives throughout the later nineteenth and twentieth century. And the useful child, has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the worlds children engaged in child labor. The Factory Act of 1833 established half-time schools that allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or11. The situation was very different by the end of the nineteenth century in Britain. The school became central to images of7a normal childhood. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, childrens lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behavior, and morals of the young. Education dominated the management of childrens waking hours, not just through the hours spent in classrooms but through /home/ work, the growth of after school7 activities and the importance attached to parental involvement. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting childrens welfare and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess childrens progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "Nowadays, childrens needs were much differentiated and categorized based on how old they are", "gold_label": "entailment"}
{"uid": "id_9", "premise": "The concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influential 1960 book Centuries of Childhood, written by French historian Philippe Aries. He argued that childhood is a concept created by modern society. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense, children are seen as useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. With industrialization in the eighteenth and nineteenth centuries, a new demand for child labor was created, and many children were forced to work for long hours, in mines, workshops, and factories. Social reformers began to question whether laboring long hours from an early age would harm childrens growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting childrens development. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labor redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as useful children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development, and learning. Even so, work continued to play a significant, if less central role in childrens lives throughout the later nineteenth and twentieth century. And the useful child, has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the worlds children engaged in child labor. The Factory Act of 1833 established half-time schools that allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or11. The situation was very different by the end of the nineteenth century in Britain. The school became central to images of7a normal childhood. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, childrens lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behavior, and morals of the young. Education dominated the management of childrens waking hours, not just through the hours spent in classrooms but through /home/ work, the growth of after school7 activities and the importance attached to parental involvement. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting childrens welfare and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess childrens progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "In 20 century almost all children need to go to school in a full-time schedule.", "gold_label": "neutral"}
{"uid": "id_10", "premise": "The concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influential 1960 book Centuries of Childhood, written by French historian Philippe Aries. He argued that childhood is a concept created by modern society. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense, children are seen as useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. With industrialization in the eighteenth and nineteenth centuries, a new demand for child labor was created, and many children were forced to work for long hours, in mines, workshops, and factories. Social reformers began to question whether laboring long hours from an early age would harm childrens growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting childrens development. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labor redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as useful children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development, and learning. Even so, work continued to play a significant, if less central role in childrens lives throughout the later nineteenth and twentieth century. And the useful child, has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the worlds children engaged in child labor. The Factory Act of 1833 established half-time schools that allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or11. The situation was very different by the end of the nineteenth century in Britain. The school became central to images of7a normal childhood. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, childrens lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behavior, and morals of the young. Education dominated the management of childrens waking hours, not just through the hours spent in classrooms but through /home/ work, the growth of after school7 activities and the importance attached to parental involvement. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting childrens welfare and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess childrens progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "Scientists think that overworked labor damages the health of young children", "gold_label": "entailment"}
{"uid": "id_11", "premise": "The concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influential 1960 book Centuries of Childhood, written by French historian Philippe Aries. He argued that childhood is a concept created by modern society. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense, children are seen as useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. With industrialization in the eighteenth and nineteenth centuries, a new demand for child labor was created, and many children were forced to work for long hours, in mines, workshops, and factories. Social reformers began to question whether laboring long hours from an early age would harm childrens growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting childrens development. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labor redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as useful children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development, and learning. Even so, work continued to play a significant, if less central role in childrens lives throughout the later nineteenth and twentieth century. And the useful child, has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the worlds children engaged in child labor. The Factory Act of 1833 established half-time schools that allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or11. The situation was very different by the end of the nineteenth century in Britain. The school became central to images of7a normal childhood. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, childrens lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behavior, and morals of the young. Education dominated the management of childrens waking hours, not just through the hours spent in classrooms but through /home/ work, the growth of after school7 activities and the importance attached to parental involvement. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting childrens welfare and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess childrens progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "During the Middle Age, going to work necessarily means children were unloved indicated by Aries.", "gold_label": "entailment"}
{"uid": "id_12", "premise": "The concept of childhood in the western countries The history of childhood has been a topic of interest in social history since the highly influential 1960 book Centuries of Childhood, written by French historian Philippe Aries. He argued that childhood is a concept created by modern society. One of the most hotly debated issues in the history of childhood has been whether childhood is itself a recent invention. The historian Philippe Aries argued that in Western Europe during the Middle Ages (up to about the end of the fifteenth century) children were regarded as miniature adults, with all the intellect and personality that this implies. He scrutinized medieval pictures and diaries and found no distinction between children and adults as they shared similar leisure activities and often the same type of work. Aries, however, pointed out that this is not to suggest that children were neglected, forsaken or despised. The idea of childhood is not to be confused with affection for children; it corresponds to an awareness of the particular nature of childhood, that particular nature which distinguishes the child from the adult, even the young adult. There is a long tradition of the children of the poor playing a functional role in contributing to the family income by working either inside or outside the home. In this sense, children are seen as useful. Back in the Middle Ages, children as young as 5 or 6 did important chores for their parents and, from the sixteenth century, were often encouraged (or forced) to leave the family by the age of 9 or 10 to work as servants for wealthier families or to be apprenticed to a trade. With industrialization in the eighteenth and nineteenth centuries, a new demand for child labor was created, and many children were forced to work for long hours, in mines, workshops, and factories. Social reformers began to question whether laboring long hours from an early age would harm childrens growing bodies. They began to recognize the potential of carrying out systematic studies to monitor how far these early deprivations might be affecting childrens development. Gradually, the concerns of the reformers began to impact on the working conditions of children. In Britain, the Factory Act of 1833 signified the beginning of legal protection of children from exploitation and was linked to the rise of schools for factory children. The worst forms of child exploitation were gradually eliminated, partly through factory reform but also through the influence of trade unions and economic changes during the nineteenth century which made some forms of child labor redundant. Childhood was increasingly seen as a time for play and education for all children, not just for a privileged minority. Initiating children into work as useful children became less of a priority. As the age for starting full-time work was delayed, so childhood was increasingly understood as a more extended phase of dependency, development, and learning. Even so, work continued to play a significant, if less central role in childrens lives throughout the later nineteenth and twentieth century. And the useful child, has become a controversial image during the first decade of the twenty-first century especially in the context of global concern about large numbers of the worlds children engaged in child labor. The Factory Act of 1833 established half-time schools that allowed children to work and attend school. But in the 1840s, a large proportion of children never went to school, and if they did, they left by the age of 10 or11. The situation was very different by the end of the nineteenth century in Britain. The school became central to images of7a normal childhood. Attending school was no longer a privilege and all children were expected to spend a significant part of their day in a classroom. By going to school, childrens lives were now separated from domestic life at home and from the adult world of work. School became an institution dedicated to shaping the minds, behavior, and morals of the young. Education dominated the management of childrens waking hours, not just through the hours spent in classrooms but through /home/ work, the growth of after school7 activities and the importance attached to parental involvement. Industrialization, urbanization and mass schooling also set new challenges for those responsible for protecting childrens welfare and promoting their learning. Increasingly, children were being treated as a group with distinctive needs and they were organized into groups according to their age. For example, teachers needed to know what to expect of children in their classrooms, what kinds of instruction were appropriate for different age groups and how best to assess childrens progress. They also wanted tools that could enable them to sort and select children according to their abilities and potential.", "hypothesis": "Aries pointed out that children did different types of work as adults during the Middle Age.", "gold_label": "contradiction"}
{"uid": "id_13", "premise": "The concept of intelligence Looked at in one way, everyone knows what intelligence is; looked at in another way, no one does. In other words, people all have unconscious notions - known as 'implicit theories'- of intelligence, but no one knows for certain what it actually is. This chapter addresses how people conceptualize intelligence, whatever it may actually be. But why should we even care what people think intelligence is, as opposed only to valuing whatever it actually is? There are at least four reasons people's conceptions of intelligence matter. First, implicit theories of intelligence drive the way in which people perceive and evaluate their own intelligence and that of others. To better understand the judgments people make about their own and others' abilities, it is useful to learn about people's implicit theories. For example, parents' implicit theories of their children's language development will determine at what ages they will be willing to make various corrections in their children's speech. More generally, parents' implicit theories of intelligence will determine at what ages they believe their children are ready to perform various cognitive tasks. Job interviewers will make hiring decisions on the basis of their implicit theories of intelligence. People will decide who to be friends with on the basis of such theories. In sum, knowledge about implicit theories of intelligence is important because this knowledge is so often used by people to make judgments in the course of their everyday lives. Second, the implicit theories of scientific investigators ultimately give rise to their explicit theories. Thus it is useful to find out what these implicit theories are. Implicit theories provide a framework that is useful in defining the general scope of a phenomenon - especially a not-well-understood phenomenon. These implicit theories can suggest what aspects of the phenomenon have been more or less attended to in previous investigations. Third, implicit theories can be useful when an investigator suspects that existing explicit theories are wrong or misleading. If an investigation of implicit theories reveals little correspondence between the extant implicit and explicit theories, the implicit theories may be wrong. But the possibility also needs to be taken into account that the explicit theories are wrong and in need of correction or supplementation. For example, some implicit theories of intelligence suggest the need for expansion of some of our explicit theories of the construct. Finally, understanding implicit theories of intelligence can help elucidate developmental and cross-cultural differences. As mentioned earlier, people have expectations for intellectual performances that differ for children of different ages. How these expectations differ is in part a function of culture. For example, expectations for children who participate in Western-style schooling are almost certain to be different from those for children who do not participate in such schooling. I have suggested that there are three major implicit theories of how intelligence relates to society as a whole (Sternberg, 1997). These might be called Hamiltonian, Jeffersonian, and Jacksonian. These views are not based strictly, but rather, loosely, on the philosophies of Alexander Hamilton, Thomas Jefferson, and Andrew Jackson, three great statesmen in the history of the United States. The Hamiltonian view, which is similar to the Platonic view, is that people are born with different levels of intelligence and that those who are less intelligent need the good offices of the more intelligent to keep them in line, whether they are called government officials or, in Plato's term, philosopher-kings. Herrnstein and Murray (1994) seem to have shared this belief when they wrote about the emergence of a cognitive (high-IQ) elite, which eventually would have to take responsibility for the largely irresponsible masses of non-elite (low-IQ) people who cannot take care of themselves. Left to themselves, the unintelligent would create, as they always have created, a kind of chaos. The Jeffersonian view is that people should have equal opportunities, but they do not necessarily avail themselves equally of these opportunities and are not necessarily equally rewarded for their accomplishments. People are rewarded for what they accomplish, if given equal opportunity. Low achievers are not rewarded to the same extent as high achievers. In the Jeffersonian view, the goal of education is not to favor or foster an elite, as in the Hamiltonian tradition, but rather to allow children the opportunities to make full use of the skills they have. My own views are similar to these (Sternberg, 1997). The Jacksonian view is that all people are equal, not only as human beings but in terms of their competencies - that one person would serve as well as another in government or on a jury or in almost any position of responsibility. In this view of democracy, people are essentially intersubstitutable except for specialized skills, all of which can be learned. In this view, we do not need or want any institutions that might lead to favoring one group over another. Implicit theories of intelligence and of the relationship of intelligence to society perhaps need to be considered more carefully than they have been because they often serve as underlying presuppositions for explicit theories and even experimental designs that are then taken as scientific contributions. Until scholars are able to discuss their implicit theories and thus their assumptions, they are likely to miss the point of what others are saying when discussing their explicit theories and their data.", "hypothesis": "Slow language development in children is likely to prove disappointing to their parents.", "gold_label": "neutral"}
{"uid": "id_14", "premise": "The concept of intelligence Looked at in one way, everyone knows what intelligence is; looked at in another way, no one does. In other words, people all have unconscious notions - known as 'implicit theories'- of intelligence, but no one knows for certain what it actually is. This chapter addresses how people conceptualize intelligence, whatever it may actually be. But why should we even care what people think intelligence is, as opposed only to valuing whatever it actually is? There are at least four reasons people's conceptions of intelligence matter. First, implicit theories of intelligence drive the way in which people perceive and evaluate their own intelligence and that of others. To better understand the judgments people make about their own and others' abilities, it is useful to learn about people's implicit theories. For example, parents' implicit theories of their children's language development will determine at what ages they will be willing to make various corrections in their children's speech. More generally, parents' implicit theories of intelligence will determine at what ages they believe their children are ready to perform various cognitive tasks. Job interviewers will make hiring decisions on the basis of their implicit theories of intelligence. People will decide who to be friends with on the basis of such theories. In sum, knowledge about implicit theories of intelligence is important because this knowledge is so often used by people to make judgments in the course of their everyday lives. Second, the implicit theories of scientific investigators ultimately give rise to their explicit theories. Thus it is useful to find out what these implicit theories are. Implicit theories provide a framework that is useful in defining the general scope of a phenomenon - especially a not-well-understood phenomenon. These implicit theories can suggest what aspects of the phenomenon have been more or less attended to in previous investigations. Third, implicit theories can be useful when an investigator suspects that existing explicit theories are wrong or misleading. If an investigation of implicit theories reveals little correspondence between the extant implicit and explicit theories, the implicit theories may be wrong. But the possibility also needs to be taken into account that the explicit theories are wrong and in need of correction or supplementation. For example, some implicit theories of intelligence suggest the need for expansion of some of our explicit theories of the construct. Finally, understanding implicit theories of intelligence can help elucidate developmental and cross-cultural differences. As mentioned earlier, people have expectations for intellectual performances that differ for children of different ages. How these expectations differ is in part a function of culture. For example, expectations for children who participate in Western-style schooling are almost certain to be different from those for children who do not participate in such schooling. I have suggested that there are three major implicit theories of how intelligence relates to society as a whole (Sternberg, 1997). These might be called Hamiltonian, Jeffersonian, and Jacksonian. These views are not based strictly, but rather, loosely, on the philosophies of Alexander Hamilton, Thomas Jefferson, and Andrew Jackson, three great statesmen in the history of the United States. The Hamiltonian view, which is similar to the Platonic view, is that people are born with different levels of intelligence and that those who are less intelligent need the good offices of the more intelligent to keep them in line, whether they are called government officials or, in Plato's term, philosopher-kings. Herrnstein and Murray (1994) seem to have shared this belief when they wrote about the emergence of a cognitive (high-IQ) elite, which eventually would have to take responsibility for the largely irresponsible masses of non-elite (low-IQ) people who cannot take care of themselves. Left to themselves, the unintelligent would create, as they always have created, a kind of chaos. The Jeffersonian view is that people should have equal opportunities, but they do not necessarily avail themselves equally of these opportunities and are not necessarily equally rewarded for their accomplishments. People are rewarded for what they accomplish, if given equal opportunity. Low achievers are not rewarded to the same extent as high achievers. In the Jeffersonian view, the goal of education is not to favor or foster an elite, as in the Hamiltonian tradition, but rather to allow children the opportunities to make full use of the skills they have. My own views are similar to these (Sternberg, 1997). The Jacksonian view is that all people are equal, not only as human beings but in terms of their competencies - that one person would serve as well as another in government or on a jury or in almost any position of responsibility. In this view of democracy, people are essentially intersubstitutable except for specialized skills, all of which can be learned. In this view, we do not need or want any institutions that might lead to favoring one group over another. Implicit theories of intelligence and of the relationship of intelligence to society perhaps need to be considered more carefully than they have been because they often serve as underlying presuppositions for explicit theories and even experimental designs that are then taken as scientific contributions. Until scholars are able to discuss their implicit theories and thus their assumptions, they are likely to miss the point of what others are saying when discussing their explicit theories and their data.", "hypothesis": "People's expectations of what children should gain from education are universal.", "gold_label": "contradiction"}
{"uid": "id_15", "premise": "The concept of intelligence Looked at in one way, everyone knows what intelligence is; looked at in another way, no one does. In other words, people all have unconscious notions - known as 'implicit theories'- of intelligence, but no one knows for certain what it actually is. This chapter addresses how people conceptualize intelligence, whatever it may actually be. But why should we even care what people think intelligence is, as opposed only to valuing whatever it actually is? There are at least four reasons people's conceptions of intelligence matter. First, implicit theories of intelligence drive the way in which people perceive and evaluate their own intelligence and that of others. To better understand the judgments people make about their own and others' abilities, it is useful to learn about people's implicit theories. For example, parents' implicit theories of their children's language development will determine at what ages they will be willing to make various corrections in their children's speech. More generally, parents' implicit theories of intelligence will determine at what ages they believe their children are ready to perform various cognitive tasks. Job interviewers will make hiring decisions on the basis of their implicit theories of intelligence. People will decide who to be friends with on the basis of such theories. In sum, knowledge about implicit theories of intelligence is important because this knowledge is so often used by people to make judgments in the course of their everyday lives. Second, the implicit theories of scientific investigators ultimately give rise to their explicit theories. Thus it is useful to find out what these implicit theories are. Implicit theories provide a framework that is useful in defining the general scope of a phenomenon - especially a not-well-understood phenomenon. These implicit theories can suggest what aspects of the phenomenon have been more or less attended to in previous investigations. Third, implicit theories can be useful when an investigator suspects that existing explicit theories are wrong or misleading. If an investigation of implicit theories reveals little correspondence between the extant implicit and explicit theories, the implicit theories may be wrong. But the possibility also needs to be taken into account that the explicit theories are wrong and in need of correction or supplementation. For example, some implicit theories of intelligence suggest the need for expansion of some of our explicit theories of the construct. Finally, understanding implicit theories of intelligence can help elucidate developmental and cross-cultural differences. As mentioned earlier, people have expectations for intellectual performances that differ for children of different ages. How these expectations differ is in part a function of culture. For example, expectations for children who participate in Western-style schooling are almost certain to be different from those for children who do not participate in such schooling. I have suggested that there are three major implicit theories of how intelligence relates to society as a whole (Sternberg, 1997). These might be called Hamiltonian, Jeffersonian, and Jacksonian. These views are not based strictly, but rather, loosely, on the philosophies of Alexander Hamilton, Thomas Jefferson, and Andrew Jackson, three great statesmen in the history of the United States. The Hamiltonian view, which is similar to the Platonic view, is that people are born with different levels of intelligence and that those who are less intelligent need the good offices of the more intelligent to keep them in line, whether they are called government officials or, in Plato's term, philosopher-kings. Herrnstein and Murray (1994) seem to have shared this belief when they wrote about the emergence of a cognitive (high-IQ) elite, which eventually would have to take responsibility for the largely irresponsible masses of non-elite (low-IQ) people who cannot take care of themselves. Left to themselves, the unintelligent would create, as they always have created, a kind of chaos. The Jeffersonian view is that people should have equal opportunities, but they do not necessarily avail themselves equally of these opportunities and are not necessarily equally rewarded for their accomplishments. People are rewarded for what they accomplish, if given equal opportunity. Low achievers are not rewarded to the same extent as high achievers. In the Jeffersonian view, the goal of education is not to favor or foster an elite, as in the Hamiltonian tradition, but rather to allow children the opportunities to make full use of the skills they have. My own views are similar to these (Sternberg, 1997). The Jacksonian view is that all people are equal, not only as human beings but in terms of their competencies - that one person would serve as well as another in government or on a jury or in almost any position of responsibility. In this view of democracy, people are essentially intersubstitutable except for specialized skills, all of which can be learned. In this view, we do not need or want any institutions that might lead to favoring one group over another. Implicit theories of intelligence and of the relationship of intelligence to society perhaps need to be considered more carefully than they have been because they often serve as underlying presuppositions for explicit theories and even experimental designs that are then taken as scientific contributions. Until scholars are able to discuss their implicit theories and thus their assumptions, they are likely to miss the point of what others are saying when discussing their explicit theories and their data.", "hypothesis": "Scholars may discuss theories without fully understanding each other.", "gold_label": "entailment"}
{"uid": "id_16", "premise": "The construction of roads and bridges Roads Although there were highway links in Mesopotamia from as early as 3500 bc, the Romans were probably the first road-builders with fixed engineering standards. At the peak of the Roman Empire in the first century ad, Rome had road connections totalling about 85,000 kilometres. Roman roads were constructed with a deep stone surface for stability and load-bearing. They had straight alignments and therefore were often hilly. The Roman roads remained the main arteries of European transport for many centuries, and even today many roads follow the Roman routes. New roads were generally of inferior quality, and the achievements of Roman builders were largely unsurpassed until the resurgence of road-building in the eighteenth century. With horse-drawn coaches in mind, eighteenth-century engineers preferred to curve their roads to avoid hills. The road surface was regarded as merely a face to absorb wear, the load-bearing strength being obtained from a properly prepared and well-drained foundation. Immediately above this, the Scottish engineer John McAdam (1756-1836) typically laid crushed stone, to which stone dust mixed with water was added, and which was compacted to a thickness of just five centimetres, and then rolled. McAdams surface layer hot tar onto which a layer of stone chips was laid became known as tarmacadam, or tarmac. Roads of this kind were known as flexible pavements. By the early nineteenth century the start of the railway age men such as John McAdam and Thomas Telford had created a British road network totalling some 200,000 km, of which about one sixth was privately owned toll roads called turnpikes. In the first half of the nineteenth century, many roads in the US were built to the new standards, of which the National Pike from West Virginia to Illinois was perhaps the most notable. In the twentieth century, the ever-increasing use of motor vehicles threatened to break up roads built to nineteenth-century standards, so new techniques had to be developed. On routes with heavy traffic, flexible pavements were replaced by rigid pavements, in which the top layer was concrete, 15 to 30 centimetres thick, laid on a prepared bed. Nowadays steel bars are laid within the concrete. This not only restrains shrinkage during setting, but also reduces expansion in warm weather. As a result, it is, possible to lay long slabs without danger of cracking. The demands of heavy traffic led to the concept of high-speed, long-distance roads, with access or slip-lanes spaced widely apart. The US Bronx River Parkway of 1925 was followed by several variants Germanys autobahns and the Pan American Highway. Such roads especially the intercity autobahns with their separate multi-lane carriageways for each direction were the predecessors of todays motorways. Bridges The development by the Romans of the arched bridge marked the beginning of scientific bridge-building; hitherto, bridges had generally been crossings in the form of felled trees or flat stone blocks. Absorbing the load by compression, arched bridges are very strong. Most were built of stone, but brick and timber were also used. A fine early example is at Alcantara in Spain, built of granite by the Romans in AD 105 to span the River Tagus. In modern times, metal and concrete arched bridges have been constructed. The first significant metal bridge, built of cast iron in 1779, still stands at Ironbridge in England. Steel, with its superior strength-to-weight ratio, soon replaced iron in metal bridge-work. In the railway age, the truss (or girder) bridge became popular. Built of wood or metal, the truss beam consists of upper and lower horizontal booms joined by vertical or inclined members. The suspension bridge has a deck supported by suspenders that drop from one or more overhead cables. It requires strong anchorage at each end to resist the inward tension of the cables, and the deck is strengthened to control distortion by moving loads or high winds. Such bridges are nevertheless light, and therefore the most suitable for very long spans. The Clifton Suspension Bridge in the UK, designed by Isambard Kingdom Brunei (180659) to span the Avon Gorge in England, is famous both for its beautiful setting and for its elegant design. The 1998 Akashi Kaikyo Bridge in Japan has a span of 1,991 metres, which is the longest to date. Cantilever bridges, such as the 1889 Forth Rail Bridge in Scotland, exploit the potential of steel construction to produce a wide clearwater space. The spans have a central supporting pier and meet midstream. The downward thrust, where the spans meet, is countered by firm anchorage of the spans at their other ends. Although the suspension bridge can span a wider gap, the cantilever is relatively stable, and this was important for nineteenth-century railway builders. The worlds longest cantilever span 549 metres is that of the Quebec rail bridge in Canada, constructed in 1918.", "hypothesis": "In Britain, during the nineteenth century, only the very rich could afford to use toll roads.", "gold_label": "neutral"}
{"uid": "id_17", "premise": "The construction of roads and bridges Roads Although there were highway links in Mesopotamia from as early as 3500 bc, the Romans were probably the first road-builders with fixed engineering standards. At the peak of the Roman Empire in the first century ad, Rome had road connections totalling about 85,000 kilometres. Roman roads were constructed with a deep stone surface for stability and load-bearing. They had straight alignments and therefore were often hilly. The Roman roads remained the main arteries of European transport for many centuries, and even today many roads follow the Roman routes. New roads were generally of inferior quality, and the achievements of Roman builders were largely unsurpassed until the resurgence of road-building in the eighteenth century. With horse-drawn coaches in mind, eighteenth-century engineers preferred to curve their roads to avoid hills. The road surface was regarded as merely a face to absorb wear, the load-bearing strength being obtained from a properly prepared and well-drained foundation. Immediately above this, the Scottish engineer John McAdam (1756-1836) typically laid crushed stone, to which stone dust mixed with water was added, and which was compacted to a thickness of just five centimetres, and then rolled. McAdams surface layer hot tar onto which a layer of stone chips was laid became known as tarmacadam, or tarmac. Roads of this kind were known as flexible pavements. By the early nineteenth century the start of the railway age men such as John McAdam and Thomas Telford had created a British road network totalling some 200,000 km, of which about one sixth was privately owned toll roads called turnpikes. In the first half of the nineteenth century, many roads in the US were built to the new standards, of which the National Pike from West Virginia to Illinois was perhaps the most notable. In the twentieth century, the ever-increasing use of motor vehicles threatened to break up roads built to nineteenth-century standards, so new techniques had to be developed. On routes with heavy traffic, flexible pavements were replaced by rigid pavements, in which the top layer was concrete, 15 to 30 centimetres thick, laid on a prepared bed. Nowadays steel bars are laid within the concrete. This not only restrains shrinkage during setting, but also reduces expansion in warm weather. As a result, it is, possible to lay long slabs without danger of cracking. The demands of heavy traffic led to the concept of high-speed, long-distance roads, with access or slip-lanes spaced widely apart. The US Bronx River Parkway of 1925 was followed by several variants Germanys autobahns and the Pan American Highway. Such roads especially the intercity autobahns with their separate multi-lane carriageways for each direction were the predecessors of todays motorways. Bridges The development by the Romans of the arched bridge marked the beginning of scientific bridge-building; hitherto, bridges had generally been crossings in the form of felled trees or flat stone blocks. Absorbing the load by compression, arched bridges are very strong. Most were built of stone, but brick and timber were also used. A fine early example is at Alcantara in Spain, built of granite by the Romans in AD 105 to span the River Tagus. In modern times, metal and concrete arched bridges have been constructed. The first significant metal bridge, built of cast iron in 1779, still stands at Ironbridge in England. Steel, with its superior strength-to-weight ratio, soon replaced iron in metal bridge-work. In the railway age, the truss (or girder) bridge became popular. Built of wood or metal, the truss beam consists of upper and lower horizontal booms joined by vertical or inclined members. The suspension bridge has a deck supported by suspenders that drop from one or more overhead cables. It requires strong anchorage at each end to resist the inward tension of the cables, and the deck is strengthened to control distortion by moving loads or high winds. Such bridges are nevertheless light, and therefore the most suitable for very long spans. The Clifton Suspension Bridge in the UK, designed by Isambard Kingdom Brunei (180659) to span the Avon Gorge in England, is famous both for its beautiful setting and for its elegant design. The 1998 Akashi Kaikyo Bridge in Japan has a span of 1,991 metres, which is the longest to date. Cantilever bridges, such as the 1889 Forth Rail Bridge in Scotland, exploit the potential of steel construction to produce a wide clearwater space. The spans have a central supporting pier and meet midstream. The downward thrust, where the spans meet, is countered by firm anchorage of the spans at their other ends. Although the suspension bridge can span a wider gap, the cantilever is relatively stable, and this was important for nineteenth-century railway builders. The worlds longest cantilever span 549 metres is that of the Quebec rail bridge in Canada, constructed in 1918.", "hypothesis": "Road construction improved continuously between the first and eighteenth centuries.", "gold_label": "contradiction"}
{"uid": "id_18", "premise": "The construction of roads and bridges Roads Although there were highway links in Mesopotamia from as early as 3500 bc, the Romans were probably the first road-builders with fixed engineering standards. At the peak of the Roman Empire in the first century ad, Rome had road connections totalling about 85,000 kilometres. Roman roads were constructed with a deep stone surface for stability and load-bearing. They had straight alignments and therefore were often hilly. The Roman roads remained the main arteries of European transport for many centuries, and even today many roads follow the Roman routes. New roads were generally of inferior quality, and the achievements of Roman builders were largely unsurpassed until the resurgence of road-building in the eighteenth century. With horse-drawn coaches in mind, eighteenth-century engineers preferred to curve their roads to avoid hills. The road surface was regarded as merely a face to absorb wear, the load-bearing strength being obtained from a properly prepared and well-drained foundation. Immediately above this, the Scottish engineer John McAdam (1756-1836) typically laid crushed stone, to which stone dust mixed with water was added, and which was compacted to a thickness of just five centimetres, and then rolled. McAdams surface layer hot tar onto which a layer of stone chips was laid became known as tarmacadam, or tarmac. Roads of this kind were known as flexible pavements. By the early nineteenth century the start of the railway age men such as John McAdam and Thomas Telford had created a British road network totalling some 200,000 km, of which about one sixth was privately owned toll roads called turnpikes. In the first half of the nineteenth century, many roads in the US were built to the new standards, of which the National Pike from West Virginia to Illinois was perhaps the most notable. In the twentieth century, the ever-increasing use of motor vehicles threatened to break up roads built to nineteenth-century standards, so new techniques had to be developed. On routes with heavy traffic, flexible pavements were replaced by rigid pavements, in which the top layer was concrete, 15 to 30 centimetres thick, laid on a prepared bed. Nowadays steel bars are laid within the concrete. This not only restrains shrinkage during setting, but also reduces expansion in warm weather. As a result, it is, possible to lay long slabs without danger of cracking. The demands of heavy traffic led to the concept of high-speed, long-distance roads, with access or slip-lanes spaced widely apart. The US Bronx River Parkway of 1925 was followed by several variants Germanys autobahns and the Pan American Highway. Such roads especially the intercity autobahns with their separate multi-lane carriageways for each direction were the predecessors of todays motorways. Bridges The development by the Romans of the arched bridge marked the beginning of scientific bridge-building; hitherto, bridges had generally been crossings in the form of felled trees or flat stone blocks. Absorbing the load by compression, arched bridges are very strong. Most were built of stone, but brick and timber were also used. A fine early example is at Alcantara in Spain, built of granite by the Romans in AD 105 to span the River Tagus. In modern times, metal and concrete arched bridges have been constructed. The first significant metal bridge, built of cast iron in 1779, still stands at Ironbridge in England. Steel, with its superior strength-to-weight ratio, soon replaced iron in metal bridge-work. In the railway age, the truss (or girder) bridge became popular. Built of wood or metal, the truss beam consists of upper and lower horizontal booms joined by vertical or inclined members. The suspension bridge has a deck supported by suspenders that drop from one or more overhead cables. It requires strong anchorage at each end to resist the inward tension of the cables, and the deck is strengthened to control distortion by moving loads or high winds. Such bridges are nevertheless light, and therefore the most suitable for very long spans. The Clifton Suspension Bridge in the UK, designed by Isambard Kingdom Brunei (180659) to span the Avon Gorge in England, is famous both for its beautiful setting and for its elegant design. The 1998 Akashi Kaikyo Bridge in Japan has a span of 1,991 metres, which is the longest to date. Cantilever bridges, such as the 1889 Forth Rail Bridge in Scotland, exploit the potential of steel construction to produce a wide clearwater space. The spans have a central supporting pier and meet midstream. The downward thrust, where the spans meet, is countered by firm anchorage of the spans at their other ends. Although the suspension bridge can span a wider gap, the cantilever is relatively stable, and this was important for nineteenth-century railway builders. The worlds longest cantilever span 549 metres is that of the Quebec rail bridge in Canada, constructed in 1918.", "hypothesis": "Traffic speeds on long-distance highways were unregulated in the early part of the twentieth century.", "gold_label": "neutral"}
{"uid": "id_19", "premise": "The construction of roads and bridges Roads Although there were highway links in Mesopotamia from as early as 3500 bc, the Romans were probably the first road-builders with fixed engineering standards. At the peak of the Roman Empire in the first century ad, Rome had road connections totalling about 85,000 kilometres. Roman roads were constructed with a deep stone surface for stability and load-bearing. They had straight alignments and therefore were often hilly. The Roman roads remained the main arteries of European transport for many centuries, and even today many roads follow the Roman routes. New roads were generally of inferior quality, and the achievements of Roman builders were largely unsurpassed until the resurgence of road-building in the eighteenth century. With horse-drawn coaches in mind, eighteenth-century engineers preferred to curve their roads to avoid hills. The road surface was regarded as merely a face to absorb wear, the load-bearing strength being obtained from a properly prepared and well-drained foundation. Immediately above this, the Scottish engineer John McAdam (1756-1836) typically laid crushed stone, to which stone dust mixed with water was added, and which was compacted to a thickness of just five centimetres, and then rolled. McAdams surface layer hot tar onto which a layer of stone chips was laid became known as tarmacadam, or tarmac. Roads of this kind were known as flexible pavements. By the early nineteenth century the start of the railway age men such as John McAdam and Thomas Telford had created a British road network totalling some 200,000 km, of which about one sixth was privately owned toll roads called turnpikes. In the first half of the nineteenth century, many roads in the US were built to the new standards, of which the National Pike from West Virginia to Illinois was perhaps the most notable. In the twentieth century, the ever-increasing use of motor vehicles threatened to break up roads built to nineteenth-century standards, so new techniques had to be developed. On routes with heavy traffic, flexible pavements were replaced by rigid pavements, in which the top layer was concrete, 15 to 30 centimetres thick, laid on a prepared bed. Nowadays steel bars are laid within the concrete. This not only restrains shrinkage during setting, but also reduces expansion in warm weather. As a result, it is, possible to lay long slabs without danger of cracking. The demands of heavy traffic led to the concept of high-speed, long-distance roads, with access or slip-lanes spaced widely apart. The US Bronx River Parkway of 1925 was followed by several variants Germanys autobahns and the Pan American Highway. Such roads especially the intercity autobahns with their separate multi-lane carriageways for each direction were the predecessors of todays motorways. Bridges The development by the Romans of the arched bridge marked the beginning of scientific bridge-building; hitherto, bridges had generally been crossings in the form of felled trees or flat stone blocks. Absorbing the load by compression, arched bridges are very strong. Most were built of stone, but brick and timber were also used. A fine early example is at Alcantara in Spain, built of granite by the Romans in AD 105 to span the River Tagus. In modern times, metal and concrete arched bridges have been constructed. The first significant metal bridge, built of cast iron in 1779, still stands at Ironbridge in England. Steel, with its superior strength-to-weight ratio, soon replaced iron in metal bridge-work. In the railway age, the truss (or girder) bridge became popular. Built of wood or metal, the truss beam consists of upper and lower horizontal booms joined by vertical or inclined members. The suspension bridge has a deck supported by suspenders that drop from one or more overhead cables. It requires strong anchorage at each end to resist the inward tension of the cables, and the deck is strengthened to control distortion by moving loads or high winds. Such bridges are nevertheless light, and therefore the most suitable for very long spans. The Clifton Suspension Bridge in the UK, designed by Isambard Kingdom Brunei (180659) to span the Avon Gorge in England, is famous both for its beautiful setting and for its elegant design. The 1998 Akashi Kaikyo Bridge in Japan has a span of 1,991 metres, which is the longest to date. Cantilever bridges, such as the 1889 Forth Rail Bridge in Scotland, exploit the potential of steel construction to produce a wide clearwater space. The spans have a central supporting pier and meet midstream. The downward thrust, where the spans meet, is countered by firm anchorage of the spans at their other ends. Although the suspension bridge can span a wider gap, the cantilever is relatively stable, and this was important for nineteenth-century railway builders. The worlds longest cantilever span 549 metres is that of the Quebec rail bridge in Canada, constructed in 1918.", "hypothesis": "Nineteenth-century road surfaces were inadequate for heavy motor traffic.", "gold_label": "entailment"}
{"uid": "id_20", "premise": "The controversial new code on corporate governance has been reassessed and significantly changed in advance of publication. Following intense pressure from company directors many of the original proposals have been scrapped, and many others have been watered down to reduce the pressure of compliance on organizations. Overall, the revisions have resulted in the removal of rules that restrict company behaviors in favor of the introduction of a recommendations-based approach, which does not set specific standards of behavior. The changes have highlighted the divide between company directors, who generally support the changes as vital to keep away from a culture of rule avoidance, and other shareholder groups who believe that a best practice approach lacks teeth and will not result in greater board accountability.", "hypothesis": "A culture of rule avoidance leads to less board accountability.", "gold_label": "neutral"}
{"uid": "id_21", "premise": "The controversial new code on corporate governance has been reassessed and significantly changed in advance of publication. Following intense pressure from company directors many of the original proposals have been scrapped, and many others have been watered down to reduce the pressure of compliance on organizations. Overall, the revisions have resulted in the removal of rules that restrict company behaviors in favor of the introduction of a recommendations-based approach, which does not set specific standards of behavior. The changes have highlighted the divide between company directors, who generally support the changes as vital to keep away from a culture of rule avoidance, and other shareholder groups who believe that a best practice approach lacks teeth and will not result in greater board accountability.", "hypothesis": "Company directors and shareholders are in agreement that something has to be done to improve processes of corporate governance.", "gold_label": "contradiction"}
{"uid": "id_22", "premise": "The controversial new code on corporate governance has been reassessed and significantly changed in advance of publication. Following intense pressure from company directors many of the original proposals have been scrapped, and many others have been watered down to reduce the pressure of compliance on organizations. Overall, the revisions have resulted in the removal of rules that restrict company behaviors in favor of the introduction of a recommendations-based approach, which does not set specific standards of behavior. The changes have highlighted the divide between company directors, who generally support the changes as vital to keep away from a culture of rule avoidance, and other shareholder groups who believe that a best practice approach lacks teeth and will not result in greater board accountability.", "hypothesis": "Following the revision, the code is now much more prescriptive in its approach to corporate governance.", "gold_label": "neutral"}
{"uid": "id_23", "premise": "The controversial new code on corporate governance has been reassessed and significantly changed in advance of publication. Following intense pressure from company directors many of the original proposals have been scrapped, and many others have been watered down to reduce the pressure of compliance on organizations. Overall, the revisions have resulted in the removal of rules that restrict company behaviors in favor of the introduction of a recommendations; based approach, which does not set specific standards of behavior. The changes have highlighted the divide between company directors, who generally support the changes as vital to keep away from a culture of rule avoidance, and other shareholder groups who believe that a best practice approach lacks teeth and will not result in greater board accountability.", "hypothesis": "Company directors and shareholders are in agreement that something has to be done to improve processes of corporate governance.", "gold_label": "contradiction"}
{"uid": "id_24", "premise": "The controversial new code on corporate governance has been reassessed and significantly changed in advance of publication. Following intense pressure from company directors many of the original proposals have been scrapped, and many others have been watered down to reduce the pressure of compliance on organizations. Overall, the revisions have resulted in the removal of rules that restrict company behaviors in favor of the introduction of a recommendations; based approach, which does not set specific standards of behavior. The changes have highlighted the divide between company directors, who generally support the changes as vital to keep away from a culture of rule avoidance, and other shareholder groups who believe that a best practice approach lacks teeth and will not result in greater board accountability.", "hypothesis": "Following the revision, the code is now much more prescriptive in its approach to corporate governance.", "gold_label": "contradiction"}
{"uid": "id_25", "premise": "The controversial new code on corporate governance has been reassessed and significantly changed in advance of publication. Following intense pressure from company directors many of the original proposals have been scrapped, and many others have been watered down to reduce the pressure of compliance on organizations. Overall, the revisions have resulted in the removal of rules that restrict company behaviors in favor of the introduction of a recommendations; based approach, which does not set specific standards of behavior. The changes have highlighted the divide between company directors, who generally support the changes as vital to keep away from a culture of rule avoidance, and other shareholder groups who believe that a best practice approach lacks teeth and will not result in greater board accountability.", "hypothesis": "A culture of rule avoidance leads to less board accountability.", "gold_label": "neutral"}
{"uid": "id_26", "premise": "The corporate mission statement needs detailed consideration by top management to establish the business the company is really in and to relate this consideration to future business intentions. It is a general statement that provides an integrating function for the business, from which a clear sense of business definition and direction can be achieved. By formulating a clear business statement, boundaries for the corporate entity can be conceived in the context of wider environmental trends that influence the business. This stage is often overlooked in marketing planning, and yet without it the marketing plan will lack a sense of contribution to the development of the total business.", "hypothesis": "Different functions within a business are likely to interpret the mission statement in different ways.", "gold_label": "entailment"}
{"uid": "id_27", "premise": "The corporate mission statement needs detailed consideration by top management to establish the business the company is really in and to relate this consideration to future business intentions. It is a general statement that provides an integrating function for the business, from which a clear sense of business definition and direction can be achieved. By formulating a clear business statement, boundaries for the corporate entity can be conceived in the context of wider environmental trends that influence the business. This stage is often overlooked in marketing planning, and yet without it the marketing plan will lack a sense of contribution to the development of the total business.", "hypothesis": "The boundaries of a corporate entity can only be assessed in the context of wider environment trends.", "gold_label": "contradiction"}
{"uid": "id_28", "premise": "The corporate mission statement needs detailed consideration by top management to establish the business the company is really in and to relate this consideration to future business intentions. It is a general statement that provides an integrating function for the business, from which a clear sense of business definition and direction can be achieved. By formulating a clear business statement, boundaries for the corporate entity can be conceived in the context of wider environmental trends that influence the business. This stage is often overlooked in marketing planning, and yet without it the marketing plan will lack a sense of contribution to the development of the total business.", "hypothesis": "Marketing planning does not often take account of the corporate mission statement.", "gold_label": "contradiction"}
{"uid": "id_29", "premise": "The corporate mission statement needs detailed consideration by top management to establish the business the company is really in and to relate this consideration to future business intentions. It is a general statement that provides an integrating function for the business, from which a clear sense of business definition and direction can be achieved. By formulating a clear business statement, boundaries for the corporate entity can be conceived in the context of wider environmental trends that influence the business. This stage is often overlooked in marketing planning, and yet without it the marketing plan will lack a sense of contribution to the development of the total business.", "hypothesis": "A corporate mission statement enables top management to define the future direction of a business.", "gold_label": "neutral"}
{"uid": "id_30", "premise": "The corporate mission statement needs detailed consideration by top management to establish the business the company is really in and to relate this consideration to future business intentions. It is a general statement that provides an integrating function for the business, from which a clear sense of business definition and direction can be achieved. By formulating a clear business statement, boundaries for the corporate entity can be conceived in the context of wider environmental trends that influence the business. This stage is often overlooked in marketing planning, and yet without it the marketing plan will lack a sense of contribution to the development of the total business.", "hypothesis": "A corporate mission statement enables top management to define the future direction of a business.", "gold_label": "entailment"}
{"uid": "id_31", "premise": "The corporate mission statement needs detailed consideration by top management to establish the business the company is really in and to relate this consideration to future business intentions. It is a general statement that provides an integrating function for the business, from which a clear sense of business definition and direction can be achieved. By formulating a clear business statement, boundaries for the corporate entity can be conceived in the context of wider environmental trends that influence the business. This stage is often overlooked in marketing planning, and yet without it the marketing plan will lack a sense of contribution to the development of the total business.", "hypothesis": "The boundaries of a corporate entity can only be assessed in the context of wider environment trends.", "gold_label": "contradiction"}
{"uid": "id_32", "premise": "The corporate mission statement needs detailed consideration by top management to establish the business the company is really in and to relate this consideration to future business intentions. It is a general statement that provides an integrating function for the business, from which a clear sense of business definition and direction can be achieved. By formulating a clear business statement, boundaries for the corporate entity can be conceived in the context of wider environmental trends that influence the business. This stage is often overlooked in marketing planning, and yet without it the marketing plan will lack a sense of contribution to the development of the total business.", "hypothesis": "Different functions within a business are likely to interpret the mission statement in different ways.", "gold_label": "neutral"}
{"uid": "id_33", "premise": "The corporate mission statement needs detailed consideration by top management to establish the business the company is really in and to relate this consideration to future business intentions. It is a general statement that provides an integrating function for the business, from which a clear sense of business definition and direction can be achieved. By formulating a clear business statement, boundaries for the corporate entity can be conceived in the context of wider environmental trends that influence the business. This stage is often overlooked in marketing planning, and yet without it the marketing plan will lack a sense of contribution to the development of the total business.", "hypothesis": "Marketing planning does not often take account of the corporate mission statement.", "gold_label": "entailment"}
{"uid": "id_34", "premise": "The cosmic microwave background (CMB) radiation is the afterglow from the Big Bang, and weak as it may be today, these primeval microwaves hold valuable information about fundamental properties of the early universe. Slight differences, or anisotropies, in the brightness and polarization of the CMB reveal clues about the nature of the primeval plasma: that the discrepancies exist at all shows that the plasma was not perfectly uniform. The variations in the brightness seen in the CMB reflect differences in the density of the primordial plasma, whereas the anisotropic polarization reveals information about the dynamics of the early universe, such as the movement of material and the number of gravitational waves. The CMB, however, is not the only source of polarized microwaves and the cosmological polarization must thus be measured at different wavelengths so as to isolate them from foreground signals.", "hypothesis": "Through studying the cosmological microwaves, one may learn about the forces of gravity in the early universe.", "gold_label": "neutral"}
{"uid": "id_35", "premise": "The cosmic microwave background (CMB) radiation is the afterglow from the Big Bang, and weak as it may be today, these primeval microwaves hold valuable information about fundamental properties of the early universe. Slight differences, or anisotropies, in the brightness and polarization of the CMB reveal clues about the nature of the primeval plasma: that the discrepancies exist at all shows that the plasma was not perfectly uniform. The variations in the brightness seen in the CMB reflect differences in the density of the primordial plasma, whereas the anisotropic polarization reveals information about the dynamics of the early universe, such as the movement of material and the number of gravitational waves. The CMB, however, is not the only source of polarized microwaves and the cosmological polarization must thus be measured at different wavelengths so as to isolate them from foreground signals.", "hypothesis": "The wave lengths of the foreground signals are disregarded once they have been distinguished from the CMB.", "gold_label": "neutral"}
{"uid": "id_36", "premise": "The cosmic microwave background (CMB) radiation is the afterglow from the Big Bang, and weak as it may be today, these primeval microwaves hold valuable information about fundamental properties of the early universe. Slight differences, or anisotropies, in the brightness and polarization of the CMB reveal clues about the nature of the primeval plasma: that the discrepancies exist at all shows that the plasma was not perfectly uniform. The variations in the brightness seen in the CMB reflect differences in the density of the primordial plasma, whereas the anisotropic polarization reveals information about the dynamics of the early universe, such as the movement of material and the number of gravitational waves. The CMB, however, is not the only source of polarized microwaves and the cosmological polarization must thus be measured at different wavelengths so as to isolate them from foreground signals.", "hypothesis": "The anisotropies of the CMB show solely that the primordial plasma was not uniform.", "gold_label": "contradiction"}
{"uid": "id_37", "premise": "The cosmic microwave background (CMB) radiation is the afterglow from the Big Bang, and weak as it may be today, these primeval microwaves hold valuable information about fundamental properties of the early universe. Slight differences, or anisotropies, in the brightness and polarization of the CMB reveal clues about the nature of the primeval plasma: that the discrepancies exist at all shows that the plasma was not perfectly uniform. The variations in the brightness seen in the CMB reflect differences in the density of the primordial plasma, whereas the anisotropic polarization reveals information about the dynamics of the early universe, such as the movement of material and the number of gravitational waves. The CMB, however, is not the only source of polarized microwaves and the cosmological polarization must thus be measured at different wavelengths so as to isolate them from foreground signals.", "hypothesis": "The polarization of cosmic microwaves is measured at different wavelength so as to separate the foreground from the background signals.", "gold_label": "entailment"}
{"uid": "id_38", "premise": "The cosmic microwave background (CMB) radiation is the afterglow from the Big Bang, and weak as it may be today, these primeval microwaves hold valuable information about fundamental properties of the early universe. Slight differences, or anisotropies, in the brightness and polarization of the CMB reveal clues about the nature of the primeval plasma: that the discrepancies exist at all shows that the plasma was not perfectly uniform. The variations in the brightness seen in the CMB reflect differences in the density of the primordial plasma, whereas the anisotropic polarization reveals information about the dynamics of the early universe, such as the movement of material and the number of gravitational waves. The CMB, however, is not the only source of polarized microwaves and the cosmological polarization must thus be measured at different wavelengths so as to isolate them from foreground signals.", "hypothesis": "Through studying the cosmological microwaves, one may learn about the forces of gravity in the early universe.", "gold_label": "entailment"}
{"uid": "id_39", "premise": "The cost of stamp duty for the average house purchase has more than doubled since 1997. In some towns the bills have risen by more than 10,000. Four successive rises in the tax on house purchases and the introduction of incremental bands, with the highest a 4% band for homes valued over 500,000, have sharply increased the amount raised by the Treasury. A spokesperson for the Treasury said that stamp duty remains a very small proportion of overall housing costs and property transaction costs are far lower in the UK than the rest of the EU and United States.", "hypothesis": "In some towns the cost of stamp duty on a house purchased in 1997 was less than 5,000.", "gold_label": "neutral"}
{"uid": "id_40", "premise": "The cost of stamp duty for the average house purchase has more than doubled since 1997. In some towns the bills have risen by more than 10,000. Four successive rises in the tax on house purchases and the introduction of incremental bands, with the highest a 4% band for homes valued over 500,000, have sharply increased the amount raised by the Treasury. A spokesperson for the Treasury said that stamp duty remains a very small proportion of overall housing costs and property transaction costs are far lower in the UK than the rest of the EU and United States.", "hypothesis": "A house sold for half a million pounds incurs a 20,000 stamp duty bill.", "gold_label": "contradiction"}
{"uid": "id_41", "premise": "The cost of stamp duty for the average house purchase has more than doubled since 1997. In some towns the bills have risen by more than 10,000. Four successive rises in the tax on house purchases and the introduction of incremental bands, with the highest a 4% band for homes valued over 500,000, have sharply increased the amount raised by the Treasury. A spokesperson for the Treasury said that stamp duty remains a very small proportion of overall housing costs and property transaction costs are far lower in the UK than the rest of the EU and United States.", "hypothesis": "Taxation on property transactions in the UK has been increased four times.", "gold_label": "entailment"}
{"uid": "id_42", "premise": "The cost of using electrical items, such as tumble dryers, can be one of the greatest household expenses. For this reason, companies offering to reduce the amount of money spent yearly on such items are of increasing popularity. An example of this is provided by the website sus-it. net, which promises to save consumers up to 690 a year by following its simple tips. These tips range from changing your appliances to energy-saving options, to insulating and building advice. Such sites often provide a comparison of the usual running cost or products, allowing consumers to compare models and assess their expected savings. For example, according to the information provided by sus-it. net, a Panasonic NA washing machine can save an average of 32.80 a year compared to other models.", "hypothesis": "It is impossible to save money by changing the model of appliance.", "gold_label": "contradiction"}
{"uid": "id_43", "premise": "The cost of using electrical items, such as tumble dryers, can be one of the greatest household expenses. For this reason, companies offering to reduce the amount of money spent yearly on such items are of increasing popularity. An example of this is provided by the website sus-it. net, which promises to save consumers up to 690 a year by following its simple tips. These tips range from changing your appliances to energy-saving options, to insulating and building advice. Such sites often provide a comparison of the usual running cost or products, allowing consumers to compare models and assess their expected savings. For example, according to the information provided by sus-it. net, a Panasonic NA washing machine can save an average of 32.80 a year compared to other models.", "hypothesis": "Old-fashioned methods like washing lines and brooms save money", "gold_label": "neutral"}
{"uid": "id_44", "premise": "The cost of using electrical items, such as tumble dryers, can be one of the greatest household expenses. For this reason, companies offering to reduce the amount of money spent yearly on such items are of increasing popularity. An example of this is provided by the website sus-it. net, which promises to save consumers up to 690 a year by following its simple tips. These tips range from changing your appliances to energy-saving options, to insulating and building advice. Such sites often provide a comparison of the usual running cost or products, allowing consumers to compare models and assess their expected savings. For example, according to the information provided by sus-it. net, a Panasonic NA washing machine can save an average of 32.80 a year compared to other models.", "hypothesis": "A way to save money is to avoid using energy saving appliances.", "gold_label": "contradiction"}
{"uid": "id_45", "premise": "The cost of using electrical items, such as tumble dryers, can be one of the greatest household expenses. For this reason, companies offering to reduce the amount of money spent yearly on such items are of increasing popularity. An example of this is provided by the website sus-it. net, which promises to save consumers up to 690 a year by following its simple tips. These tips range from changing your appliances to energy-saving options, to insulating and building advice. Such sites often provide a comparison of the usual running cost or products, allowing consumers to compare models and assess their expected savings. For example, according to the information provided by sus-it. net, a Panasonic NA washing machine can save an average of 32.80 a year compared to other models.", "hypothesis": "Brands claiming to amount spent on electric items are increasingly popular.", "gold_label": "entailment"}
{"uid": "id_46", "premise": "The costs of roaming - the service which allows UK customers to use their mobile phone abroad - are much higher than those in France, Germany, Sweden and Italy. Many people get caught out because they are unaware of the high prices, and that they get charged for simply receiving calls while abroad. Less than a quarter of consumers had any knowledge of the price of using a mobile phone abroad when they bought their phone. Better consumer information is vital if prices for pre-pay international roaming in the UK are to come down.", "hypothesis": "Pay-as-you-go roaming rates are lower than they are for contract customers.", "gold_label": "neutral"}
{"uid": "id_47", "premise": "The costs of roaming - the service which allows UK customers to use their mobile phone abroad - are much higher than those in France, Germany, Sweden and Italy. Many people get caught out because they are unaware of the high prices, and that they get charged for simply receiving calls while abroad. Less than a quarter of consumers had any knowledge of the price of using a mobile phone abroad when they bought their phone. Better consumer information is vital if prices for pre-pay international roaming in the UK are to come down.", "hypothesis": "Customers can be charged for calls which they do not make themselves.", "gold_label": "entailment"}
{"uid": "id_48", "premise": "The costs of roaming - the service which allows UK customers to use their mobile phone abroad - are much higher than those in France, Germany, Sweden and Italy. Many people get caught out because they are unaware of the high prices, and that they get charged for simply receiving calls while abroad. Less than a quarter of consumers had any knowledge of the price of using a mobile phone abroad when they bought their phone. Better consumer information is vital if prices for pre-pay international roaming in the UK are to come down.", "hypothesis": "It is more expensive for German customers to use a roaming service than it is for UK customers.", "gold_label": "contradiction"}
{"uid": "id_49", "premise": "The costs of roaming - the service which allows UK customers to use their mobile phone abroad - are much higher than those in France, Germany, Sweden and Italy. Many people get caught out because they are unaware of the high prices, and that they get charged for simply receiving calls whilst abroad. Less than a quarter of consumers had any knowledge of the price of using a mobile phone aboard when they bought their phone. Better consumer information is vital if prices for pre-pay international roaming in the UK are to come down.", "hypothesis": "It is more expensive for German customers to use a roaming service than it is for UK customers.", "gold_label": "contradiction"}
{"uid": "id_50", "premise": "The costs of roaming - the service which allows UK customers to use their mobile phone abroad - are much higher than those in France, Germany, Sweden and Italy. Many people get caught out because they are unaware of the high prices, and that they get charged for simply receiving calls whilst abroad. Less than a quarter of consumers had any knowledge of the price of using a mobile phone aboard when they bought their phone. Better consumer information is vital if prices for pre-pay international roaming in the UK are to come down.", "hypothesis": "Pay-as-you-go roaming rates are lower than they are for contract customers.", "gold_label": "neutral"}
{"uid": "id_51", "premise": "The costs of roaming - the service which allows UK customers to use their mobile phone abroad - are much higher than those in France, Germany, Sweden and Italy. Many people get caught out because they are unaware of the high prices, and that they get charged for simply receiving calls whilst abroad. Less than a quarter of consumers had any knowledge of the price of using a mobile phone aboard when they bought their phone. Better consumer information is vital if prices for pre-pay international roaming in the UK are to come down.", "hypothesis": "Customers can be charged for calls which they do not make themselves.", "gold_label": "entailment"}
{"uid": "id_52", "premise": "The creation of lasting memories Many studies of the brain processes underlying the creation of memory consolidation (lasting memories) have involved giving various human and animal subjects treatment, while training them to perform a task. These have contributed greatly to our understanding. In pioneering studies using goldfish, Bernard Agranoff found that protein synthesis inhibitors injected after training caused the goldfish to forget what they had learned. In other experiments, he administered protein synthesis inhibitors immediately before the fish were trained. The remarkable finding was that the fish learned the task completely normally, but forgot it within a few hours that is, the protein synthesis inhibitors blocked memory consolidation, but did not influence short-term memory. There is now extensive evidence that short-term memory is spared by many kinds of treatments, including electro-convulsive therapy (ECT), that block memory consolidation. On the other hand, and equally importantly, neuroscientist Ivan Izquierdo found that many drug treatments can block short-term memory without blocking memory consolidation. Contrary to the hypothesis put forward by Canadian psychologist Donald Hebb, in 1949, long-term memory does not require short-term memory, and vice versa. Such findings suggest that our experiences create parallel, and possibly independent stages of memory, each with a different life span. All of this evidence from clinical and experimental studies strongly indicates that the brain handles recent and remote memory in different ways; but why does it do that? We obviously need to have memory that is created rapidly: reacting to an ever and rapidly changing environment requires that. For example, most current building codes require that the heights of all steps in a staircase be equal. After taking a couple of steps, up or down, we implicitly remember the heights of the steps and assume that the others will be the same. If they are not the same, we are very likely to trip and fall. Lack of this kind of rapidly created implicit memory would be bad for us and for insurance companies, but perhaps good for lawyers. It would be of little value to us if we remembered the heights of the steps only after a delay of many hours, when the memory becomes consolidated. The hypothesis that lasting memory consolidates slowly over time is supported primarily by clinical and experimental evidence that the formation of long-term memory is influenced by treatments and disorders affecting brain functioning. There are also other kinds of evidence indicating more directly that the memories consolidate over time after learning. Avi Kami and Dov Sagi reported that the performance of human subjects trained in a visual skill did not improve until eight hours after the training was completed, and that improvement was even greater the following day. Furthermore, the skill was retained for several years. Studies using human brain imaging to study changes in neural activity induced by learning have also reported that the changes continue to develop for hours after learning. In an innovative study using functional imaging of the brain, Reza Shadmehr and Henry Holcomb examined brain activity in several brain regions shortly after human subjects were trained in a motor learning task requiring arm and hand movements. They found that while the performance of the subjects remained stable for several hours after completion of the training, their brain activity did not; different regions of the brain were predominantly active at different times over a period of several hours after the training. The activity shifted from the prefrontal cortex to two areas known to be involved in controlling movements, the motor cortex and cerebellar cortex. Consolidation of the motor skill appeared to involve activation of different neural systems that increased the stability of the brain processes underlying the skill. There is also evidence that learning-induced changes in the activity of neurons in the cerebral cortex continue to increase for many days after the training. In an extensive series of studies using rats with electrodes implanted in the auditory cortex, Norman Weinberger reported that, after a tone of specific frequency was paired a few times with footshock, neurons in the rats auditory cortex responded more to that specific tone and less to other tones of other frequencies. Even more interestingly, the selectivity of the neurons response to the specific tone used in training continued to increase for several days after the training was terminated. It is not intuitively obvious why our lasting memories consolidate slowly. Certainly, one can wonder why we have a form of memory that we have to rely on for many hours, days or a lifetime, that is so susceptible to disruption shortly after it is initiated. Perhaps the brain system that consolidates long-term memory over time was a late development in vertebrate evolution. Moreover, maybe we consolidate memories slowly because our mammalian brains are large and enormously complex. We can readily reject these ideas. All species of animals studied to date have both short and long-term memory; and all are susceptible to retrograde amnesia. Like humans, birds, bees, and molluscs, as well as fish and rats, make long-term memory slowly. Consolidation of memory clearly emerged early in evolution, and was conserved. Although there seems to be no compelling reason to conclude that a biological system such as a brain could not quickly make a lasting memory, the fact is that animal brains do not. Thus, memory consolidation must serve some very important adaptive function or functions. There is considerable evidence suggesting that the slow consolidation is adaptive because it enables neurobiological processes occurring shortly after learning to influence the strength of memory for experiences. The extensive evidence that memory can be enhanced, as well as impaired, by treatments administered shortly after training, provides intriguing support for this hypothesis.", "hypothesis": "Long-term memories in humans are more stable than in many other species.", "gold_label": "neutral"}
{"uid": "id_53", "premise": "The creation of lasting memories Many studies of the brain processes underlying the creation of memory consolidation (lasting memories) have involved giving various human and animal subjects treatment, while training them to perform a task. These have contributed greatly to our understanding. In pioneering studies using goldfish, Bernard Agranoff found that protein synthesis inhibitors injected after training caused the goldfish to forget what they had learned. In other experiments, he administered protein synthesis inhibitors immediately before the fish were trained. The remarkable finding was that the fish learned the task completely normally, but forgot it within a few hours that is, the protein synthesis inhibitors blocked memory consolidation, but did not influence short-term memory. There is now extensive evidence that short-term memory is spared by many kinds of treatments, including electro-convulsive therapy (ECT), that block memory consolidation. On the other hand, and equally importantly, neuroscientist Ivan Izquierdo found that many drug treatments can block short-term memory without blocking memory consolidation. Contrary to the hypothesis put forward by Canadian psychologist Donald Hebb, in 1949, long-term memory does not require short-term memory, and vice versa. Such findings suggest that our experiences create parallel, and possibly independent stages of memory, each with a different life span. All of this evidence from clinical and experimental studies strongly indicates that the brain handles recent and remote memory in different ways; but why does it do that? We obviously need to have memory that is created rapidly: reacting to an ever and rapidly changing environment requires that. For example, most current building codes require that the heights of all steps in a staircase be equal. After taking a couple of steps, up or down, we implicitly remember the heights of the steps and assume that the others will be the same. If they are not the same, we are very likely to trip and fall. Lack of this kind of rapidly created implicit memory would be bad for us and for insurance companies, but perhaps good for lawyers. It would be of little value to us if we remembered the heights of the steps only after a delay of many hours, when the memory becomes consolidated. The hypothesis that lasting memory consolidates slowly over time is supported primarily by clinical and experimental evidence that the formation of long-term memory is influenced by treatments and disorders affecting brain functioning. There are also other kinds of evidence indicating more directly that the memories consolidate over time after learning. Avi Kami and Dov Sagi reported that the performance of human subjects trained in a visual skill did not improve until eight hours after the training was completed, and that improvement was even greater the following day. Furthermore, the skill was retained for several years. Studies using human brain imaging to study changes in neural activity induced by learning have also reported that the changes continue to develop for hours after learning. In an innovative study using functional imaging of the brain, Reza Shadmehr and Henry Holcomb examined brain activity in several brain regions shortly after human subjects were trained in a motor learning task requiring arm and hand movements. They found that while the performance of the subjects remained stable for several hours after completion of the training, their brain activity did not; different regions of the brain were predominantly active at different times over a period of several hours after the training. The activity shifted from the prefrontal cortex to two areas known to be involved in controlling movements, the motor cortex and cerebellar cortex. Consolidation of the motor skill appeared to involve activation of different neural systems that increased the stability of the brain processes underlying the skill. There is also evidence that learning-induced changes in the activity of neurons in the cerebral cortex continue to increase for many days after the training. In an extensive series of studies using rats with electrodes implanted in the auditory cortex, Norman Weinberger reported that, after a tone of specific frequency was paired a few times with footshock, neurons in the rats auditory cortex responded more to that specific tone and less to other tones of other frequencies. Even more interestingly, the selectivity of the neurons response to the specific tone used in training continued to increase for several days after the training was terminated. It is not intuitively obvious why our lasting memories consolidate slowly. Certainly, one can wonder why we have a form of memory that we have to rely on for many hours, days or a lifetime, that is so susceptible to disruption shortly after it is initiated. Perhaps the brain system that consolidates long-term memory over time was a late development in vertebrate evolution. Moreover, maybe we consolidate memories slowly because our mammalian brains are large and enormously complex. We can readily reject these ideas. All species of animals studied to date have both short and long-term memory; and all are susceptible to retrograde amnesia. Like humans, birds, bees, and molluscs, as well as fish and rats, make long-term memory slowly. Consolidation of memory clearly emerged early in evolution, and was conserved. Although there seems to be no compelling reason to conclude that a biological system such as a brain could not quickly make a lasting memory, the fact is that animal brains do not. Thus, memory consolidation must serve some very important adaptive function or functions. There is considerable evidence suggesting that the slow consolidation is adaptive because it enables neurobiological processes occurring shortly after learning to influence the strength of memory for experiences. The extensive evidence that memory can be enhanced, as well as impaired, by treatments administered shortly after training, provides intriguing support for this hypothesis.", "hypothesis": "The rats in Weinbergers studies learned to associate a certain sound with a specific experience.", "gold_label": "entailment"}
{"uid": "id_54", "premise": "The creation of lasting memories Many studies of the brain processes underlying the creation of memory consolidation (lasting memories) have involved giving various human and animal subjects treatment, while training them to perform a task. These have contributed greatly to our understanding. In pioneering studies using goldfish, Bernard Agranoff found that protein synthesis inhibitors injected after training caused the goldfish to forget what they had learned. In other experiments, he administered protein synthesis inhibitors immediately before the fish were trained. The remarkable finding was that the fish learned the task completely normally, but forgot it within a few hours that is, the protein synthesis inhibitors blocked memory consolidation, but did not influence short-term memory. There is now extensive evidence that short-term memory is spared by many kinds of treatments, including electro-convulsive therapy (ECT), that block memory consolidation. On the other hand, and equally importantly, neuroscientist Ivan Izquierdo found that many drug treatments can block short-term memory without blocking memory consolidation. Contrary to the hypothesis put forward by Canadian psychologist Donald Hebb, in 1949, long-term memory does not require short-term memory, and vice versa. Such findings suggest that our experiences create parallel, and possibly independent stages of memory, each with a different life span. All of this evidence from clinical and experimental studies strongly indicates that the brain handles recent and remote memory in different ways; but why does it do that? We obviously need to have memory that is created rapidly: reacting to an ever and rapidly changing environment requires that. For example, most current building codes require that the heights of all steps in a staircase be equal. After taking a couple of steps, up or down, we implicitly remember the heights of the steps and assume that the others will be the same. If they are not the same, we are very likely to trip and fall. Lack of this kind of rapidly created implicit memory would be bad for us and for insurance companies, but perhaps good for lawyers. It would be of little value to us if we remembered the heights of the steps only after a delay of many hours, when the memory becomes consolidated. The hypothesis that lasting memory consolidates slowly over time is supported primarily by clinical and experimental evidence that the formation of long-term memory is influenced by treatments and disorders affecting brain functioning. There are also other kinds of evidence indicating more directly that the memories consolidate over time after learning. Avi Kami and Dov Sagi reported that the performance of human subjects trained in a visual skill did not improve until eight hours after the training was completed, and that improvement was even greater the following day. Furthermore, the skill was retained for several years. Studies using human brain imaging to study changes in neural activity induced by learning have also reported that the changes continue to develop for hours after learning. In an innovative study using functional imaging of the brain, Reza Shadmehr and Henry Holcomb examined brain activity in several brain regions shortly after human subjects were trained in a motor learning task requiring arm and hand movements. They found that while the performance of the subjects remained stable for several hours after completion of the training, their brain activity did not; different regions of the brain were predominantly active at different times over a period of several hours after the training. The activity shifted from the prefrontal cortex to two areas known to be involved in controlling movements, the motor cortex and cerebellar cortex. Consolidation of the motor skill appeared to involve activation of different neural systems that increased the stability of the brain processes underlying the skill. There is also evidence that learning-induced changes in the activity of neurons in the cerebral cortex continue to increase for many days after the training. In an extensive series of studies using rats with electrodes implanted in the auditory cortex, Norman Weinberger reported that, after a tone of specific frequency was paired a few times with footshock, neurons in the rats auditory cortex responded more to that specific tone and less to other tones of other frequencies. Even more interestingly, the selectivity of the neurons response to the specific tone used in training continued to increase for several days after the training was terminated. It is not intuitively obvious why our lasting memories consolidate slowly. Certainly, one can wonder why we have a form of memory that we have to rely on for many hours, days or a lifetime, that is so susceptible to disruption shortly after it is initiated. Perhaps the brain system that consolidates long-term memory over time was a late development in vertebrate evolution. Moreover, maybe we consolidate memories slowly because our mammalian brains are large and enormously complex. We can readily reject these ideas. All species of animals studied to date have both short and long-term memory; and all are susceptible to retrograde amnesia. Like humans, birds, bees, and molluscs, as well as fish and rats, make long-term memory slowly. Consolidation of memory clearly emerged early in evolution, and was conserved. Although there seems to be no compelling reason to conclude that a biological system such as a brain could not quickly make a lasting memory, the fact is that animal brains do not. Thus, memory consolidation must serve some very important adaptive function or functions. There is considerable evidence suggesting that the slow consolidation is adaptive because it enables neurobiological processes occurring shortly after learning to influence the strength of memory for experiences. The extensive evidence that memory can be enhanced, as well as impaired, by treatments administered shortly after training, provides intriguing support for this hypothesis.", "hypothesis": "The training which Kami and Sagis subjects were given was repeated over several days.", "gold_label": "neutral"}
{"uid": "id_55", "premise": "The creation of lasting memories Many studies of the brain processes underlying the creation of memory consolidation (lasting memories) have involved giving various human and animal subjects treatment, while training them to perform a task. These have contributed greatly to our understanding. In pioneering studies using goldfish, Bernard Agranoff found that protein synthesis inhibitors injected after training caused the goldfish to forget what they had learned. In other experiments, he administered protein synthesis inhibitors immediately before the fish were trained. The remarkable finding was that the fish learned the task completely normally, but forgot it within a few hours that is, the protein synthesis inhibitors blocked memory consolidation, but did not influence short-term memory. There is now extensive evidence that short-term memory is spared by many kinds of treatments, including electro-convulsive therapy (ECT), that block memory consolidation. On the other hand, and equally importantly, neuroscientist Ivan Izquierdo found that many drug treatments can block short-term memory without blocking memory consolidation. Contrary to the hypothesis put forward by Canadian psychologist Donald Hebb, in 1949, long-term memory does not require short-term memory, and vice versa. Such findings suggest that our experiences create parallel, and possibly independent stages of memory, each with a different life span. All of this evidence from clinical and experimental studies strongly indicates that the brain handles recent and remote memory in different ways; but why does it do that? We obviously need to have memory that is created rapidly: reacting to an ever and rapidly changing environment requires that. For example, most current building codes require that the heights of all steps in a staircase be equal. After taking a couple of steps, up or down, we implicitly remember the heights of the steps and assume that the others will be the same. If they are not the same, we are very likely to trip and fall. Lack of this kind of rapidly created implicit memory would be bad for us and for insurance companies, but perhaps good for lawyers. It would be of little value to us if we remembered the heights of the steps only after a delay of many hours, when the memory becomes consolidated. The hypothesis that lasting memory consolidates slowly over time is supported primarily by clinical and experimental evidence that the formation of long-term memory is influenced by treatments and disorders affecting brain functioning. There are also other kinds of evidence indicating more directly that the memories consolidate over time after learning. Avi Kami and Dov Sagi reported that the performance of human subjects trained in a visual skill did not improve until eight hours after the training was completed, and that improvement was even greater the following day. Furthermore, the skill was retained for several years. Studies using human brain imaging to study changes in neural activity induced by learning have also reported that the changes continue to develop for hours after learning. In an innovative study using functional imaging of the brain, Reza Shadmehr and Henry Holcomb examined brain activity in several brain regions shortly after human subjects were trained in a motor learning task requiring arm and hand movements. They found that while the performance of the subjects remained stable for several hours after completion of the training, their brain activity did not; different regions of the brain were predominantly active at different times over a period of several hours after the training. The activity shifted from the prefrontal cortex to two areas known to be involved in controlling movements, the motor cortex and cerebellar cortex. Consolidation of the motor skill appeared to involve activation of different neural systems that increased the stability of the brain processes underlying the skill. There is also evidence that learning-induced changes in the activity of neurons in the cerebral cortex continue to increase for many days after the training. In an extensive series of studies using rats with electrodes implanted in the auditory cortex, Norman Weinberger reported that, after a tone of specific frequency was paired a few times with footshock, neurons in the rats auditory cortex responded more to that specific tone and less to other tones of other frequencies. Even more interestingly, the selectivity of the neurons response to the specific tone used in training continued to increase for several days after the training was terminated. It is not intuitively obvious why our lasting memories consolidate slowly. Certainly, one can wonder why we have a form of memory that we have to rely on for many hours, days or a lifetime, that is so susceptible to disruption shortly after it is initiated. Perhaps the brain system that consolidates long-term memory over time was a late development in vertebrate evolution. Moreover, maybe we consolidate memories slowly because our mammalian brains are large and enormously complex. We can readily reject these ideas. All species of animals studied to date have both short and long-term memory; and all are susceptible to retrograde amnesia. Like humans, birds, bees, and molluscs, as well as fish and rats, make long-term memory slowly. Consolidation of memory clearly emerged early in evolution, and was conserved. Although there seems to be no compelling reason to conclude that a biological system such as a brain could not quickly make a lasting memory, the fact is that animal brains do not. Thus, memory consolidation must serve some very important adaptive function or functions. There is considerable evidence suggesting that the slow consolidation is adaptive because it enables neurobiological processes occurring shortly after learning to influence the strength of memory for experiences. The extensive evidence that memory can be enhanced, as well as impaired, by treatments administered shortly after training, provides intriguing support for this hypothesis.", "hypothesis": "The results of Weinbergers studies indicated that the strength of the rats learned associations increases with time.", "gold_label": "entailment"}
{"uid": "id_56", "premise": "The creation of lasting memories Many studies of the brain processes underlying the creation of memory consolidation (lasting memories) have involved giving various human and animal subjects treatment, while training them to perform a task. These have contributed greatly to our understanding. In pioneering studies using goldfish, Bernard Agranoff found that protein synthesis inhibitors injected after training caused the goldfish to forget what they had learned. In other experiments, he administered protein synthesis inhibitors immediately before the fish were trained. The remarkable finding was that the fish learned the task completely normally, but forgot it within a few hours that is, the protein synthesis inhibitors blocked memory consolidation, but did not influence short-term memory. There is now extensive evidence that short-term memory is spared by many kinds of treatments, including electro-convulsive therapy (ECT), that block memory consolidation. On the other hand, and equally importantly, neuroscientist Ivan Izquierdo found that many drug treatments can block short-term memory without blocking memory consolidation. Contrary to the hypothesis put forward by Canadian psychologist Donald Hebb, in 1949, long-term memory does not require short-term memory, and vice versa. Such findings suggest that our experiences create parallel, and possibly independent stages of memory, each with a different life span. All of this evidence from clinical and experimental studies strongly indicates that the brain handles recent and remote memory in different ways; but why does it do that? We obviously need to have memory that is created rapidly: reacting to an ever and rapidly changing environment requires that. For example, most current building codes require that the heights of all steps in a staircase be equal. After taking a couple of steps, up or down, we implicitly remember the heights of the steps and assume that the others will be the same. If they are not the same, we are very likely to trip and fall. Lack of this kind of rapidly created implicit memory would be bad for us and for insurance companies, but perhaps good for lawyers. It would be of little value to us if we remembered the heights of the steps only after a delay of many hours, when the memory becomes consolidated. The hypothesis that lasting memory consolidates slowly over time is supported primarily by clinical and experimental evidence that the formation of long-term memory is influenced by treatments and disorders affecting brain functioning. There are also other kinds of evidence indicating more directly that the memories consolidate over time after learning. Avi Kami and Dov Sagi reported that the performance of human subjects trained in a visual skill did not improve until eight hours after the training was completed, and that improvement was even greater the following day. Furthermore, the skill was retained for several years. Studies using human brain imaging to study changes in neural activity induced by learning have also reported that the changes continue to develop for hours after learning. In an innovative study using functional imaging of the brain, Reza Shadmehr and Henry Holcomb examined brain activity in several brain regions shortly after human subjects were trained in a motor learning task requiring arm and hand movements. They found that while the performance of the subjects remained stable for several hours after completion of the training, their brain activity did not; different regions of the brain were predominantly active at different times over a period of several hours after the training. The activity shifted from the prefrontal cortex to two areas known to be involved in controlling movements, the motor cortex and cerebellar cortex. Consolidation of the motor skill appeared to involve activation of different neural systems that increased the stability of the brain processes underlying the skill. There is also evidence that learning-induced changes in the activity of neurons in the cerebral cortex continue to increase for many days after the training. In an extensive series of studies using rats with electrodes implanted in the auditory cortex, Norman Weinberger reported that, after a tone of specific frequency was paired a few times with footshock, neurons in the rats auditory cortex responded more to that specific tone and less to other tones of other frequencies. Even more interestingly, the selectivity of the neurons response to the specific tone used in training continued to increase for several days after the training was terminated. It is not intuitively obvious why our lasting memories consolidate slowly. Certainly, one can wonder why we have a form of memory that we have to rely on for many hours, days or a lifetime, that is so susceptible to disruption shortly after it is initiated. Perhaps the brain system that consolidates long-term memory over time was a late development in vertebrate evolution. Moreover, maybe we consolidate memories slowly because our mammalian brains are large and enormously complex. We can readily reject these ideas. All species of animals studied to date have both short and long-term memory; and all are susceptible to retrograde amnesia. Like humans, birds, bees, and molluscs, as well as fish and rats, make long-term memory slowly. Consolidation of memory clearly emerged early in evolution, and was conserved. Although there seems to be no compelling reason to conclude that a biological system such as a brain could not quickly make a lasting memory, the fact is that animal brains do not. Thus, memory consolidation must serve some very important adaptive function or functions. There is considerable evidence suggesting that the slow consolidation is adaptive because it enables neurobiological processes occurring shortly after learning to influence the strength of memory for experiences. The extensive evidence that memory can be enhanced, as well as impaired, by treatments administered shortly after training, provides intriguing support for this hypothesis.", "hypothesis": "It is easy to see the evolutionary advantage of the way lasting memories in humans are created.", "gold_label": "contradiction"}
{"uid": "id_57", "premise": "The debate over the British Museums Parthenon sculptures, also called the Elgin Marbles, has run for nearly two centuries. Marble statues were removed with official permission from the ruins of the Parthenon in 1801 by Lord Elgin, the British Ambassador to the Ottoman Empire. He sold these ancient Greek treasures to the British Museum in 1816, where they have been housed ever since. Today, five million visitors from around the world visit the sculptures, free of charge, at the British Museum. Since gaining independence in 1830, however, the Greek government has argued for their return to Athens. Historically, the Hellenic position centred on ownership, claiming that Lord Elgin bribed authorities to acquire the marbles illegally. The counterargument is that Lord Elgin saved these classical treasures from neglect. Greece no longer disputes the British Museums ownership, but states that the sculptures should be loaned to the New Acropolis Museum in Athens, where they would be reunited with other surviving sculptures and displayed in their proper geographic and cultural context. Despite public sympathy for the return of the Elgin marbles, the British Museum believes that the Parthenon marbles are part of shared world heritage and thus should be widely accessible. Furthermore, returning the Parthenon statues would set a precedent for returning other artefacts to their land of origin.", "hypothesis": "The British Museum takes the view that the Parthenon sculptures transcend national boundaries.", "gold_label": "entailment"}
{"uid": "id_58", "premise": "The debate over the British Museums Parthenon sculptures, also called the Elgin Marbles, has run for nearly two centuries. Marble statues were removed with official permission from the ruins of the Parthenon in 1801 by Lord Elgin, the British Ambassador to the Ottoman Empire. He sold these ancient Greek treasures to the British Museum in 1816, where they have been housed ever since. Today, five million visitors from around the world visit the sculptures, free of charge, at the British Museum. Since gaining independence in 1830, however, the Greek government has argued for their return to Athens. Historically, the Hellenic position centred on ownership, claiming that Lord Elgin bribed authorities to acquire the marbles illegally. The counterargument is that Lord Elgin saved these classical treasures from neglect. Greece no longer disputes the British Museums ownership, but states that the sculptures should be loaned to the New Acropolis Museum in Athens, where they would be reunited with other surviving sculptures and displayed in their proper geographic and cultural context. Despite public sympathy for the return of the Elgin marbles, the British Museum believes that the Parthenon marbles are part of shared world heritage and thus should be widely accessible. Furthermore, returning the Parthenon statues would set a precedent for returning other artefacts to their land of origin.", "hypothesis": "The British public cannot understand why the Greek government want the Parthenon marbles returned.", "gold_label": "contradiction"}
{"uid": "id_59", "premise": "The debate over the British Museums Parthenon sculptures, also called the Elgin Marbles, has run for nearly two centuries. Marble statues were removed with official permission from the ruins of the Parthenon in 1801 by Lord Elgin, the British Ambassador to the Ottoman Empire. He sold these ancient Greek treasures to the British Museum in 1816, where they have been housed ever since. Today, five million visitors from around the world visit the sculptures, free of charge, at the British Museum. Since gaining independence in 1830, however, the Greek government has argued for their return to Athens. Historically, the Hellenic position centred on ownership, claiming that Lord Elgin bribed authorities to acquire the marbles illegally. The counterargument is that Lord Elgin saved these classical treasures from neglect. Greece no longer disputes the British Museums ownership, but states that the sculptures should be loaned to the New Acropolis Museum in Athens, where they would be reunited with other surviving sculptures and displayed in their proper geographic and cultural context. Despite public sympathy for the return of the Elgin marbles, the British Museum believes that the Parthenon marbles are part of shared world heritage and thus should be widely accessible. Furthermore, returning the Parthenon statues would set a precedent for returning other artefacts to their land of origin.", "hypothesis": "Greeks believe that the Elgin Marbles technically do not belong to the British Museum.", "gold_label": "contradiction"}
{"uid": "id_60", "premise": "The debate over the British Museums Parthenon sculptures, also called the Elgin Marbles, has run for nearly two centuries. Marble statues were removed with official permission from the ruins of the Parthenon in 1801 by Lord Elgin, the British Ambassador to the Ottoman Empire. He sold these ancient Greek treasures to the British Museum in 1816, where they have been housed ever since. Today, five million visitors from around the world visit the sculptures, free of charge, at the British Museum. Since gaining independence in 1830, however, the Greek government has argued for their return to Athens. Historically, the Hellenic position centred on ownership, claiming that Lord Elgin bribed authorities to acquire the marbles illegally. The counterargument is that Lord Elgin saved these classical treasures from neglect. Greece no longer disputes the British Museums ownership, but states that the sculptures should be loaned to the New Acropolis Museum in Athens, where they would be reunited with other surviving sculptures and displayed in their proper geographic and cultural context. Despite public sympathy for the return of the Elgin marbles, the British Museum believes that the Parthenon marbles are part of shared world heritage and thus should be widely accessible. Furthermore, returning the Parthenon statues would set a precedent for returning other artefacts to their land of origin.", "hypothesis": "The only surviving marble statues from the Parthenon are divided between the British Museum and the New Acropolis Museum.", "gold_label": "neutral"}
{"uid": "id_61", "premise": "The debate over the British Museums Parthenon sculptures, also called the Elgin Marbles, has run for nearly two centuries. Marble statues were removed with official permission from the ruins of the Parthenon in 1801 by Lord Elgin, the British Ambassador to the Ottoman Empire. He sold these ancient Greek treasures to the British Museum in 1816, where they have been housed ever since. Today, five million visitors from around the world visit the sculptures, free of charge, at the British Museum. Since gaining independence in 1830, however, the Greek government has argued for their return to Athens. Historically, the Hellenic position centred on ownership, claiming that Lord Elgin bribed authorities to acquire the marbles illegally. The counterargument is that Lord Elgin saved these classical treasures from neglect. Greece no longer disputes the British Museums ownership, but states that the sculptures should be loaned to the New Acropolis Museum in Athens, where they would be reunited with other surviving sculptures and displayed in their proper geographic and cultural context. Despite public sympathy for the return of the Elgin marbles, the British Museum believes that the Parthenon marbles are part of shared world heritage and thus should be widely accessible. Furthermore, returning the Parthenon statues would set a precedent for returning other artefacts to their land of origin.", "hypothesis": "Prior to 1830, Greece was part of the Ottoman Empire.", "gold_label": "neutral"}
{"uid": "id_62", "premise": "The decline in chinas housing and construction market has had a profound knock on effect on chinas steel industry. Due to decreased demand for steel from construction, as huge construction projects around china are reduced to ghost towns by decreased investment, Chinese state owned steel companies have seen their profits drop by almost 96%. The drop in steel prices may be an indicator of things to come; lower steel prices suggest lower predicted g economic growth, and may spell disaster for chinas hopes of continued rapid growth.", "hypothesis": "Decreased steel demand is an effect of chinas construction market decline", "gold_label": "entailment"}
{"uid": "id_63", "premise": "The decline in chinas housing and construction market has had a profound knock on effect on chinas steel industry. Due to decreased demand for steel from construction, as huge construction projects around china are reduced to ghost towns by decreased investment, Chinese state owned steel companies have seen their profits drop by almost 96%. The drop in steel prices may be an indicator of things to come; lower steel prices suggest lower predicted g economic growth, and may spell disaster for chinas hopes of continued rapid growth.", "hypothesis": "Decreased steel company profits is an effect of chinas construction market decline.", "gold_label": "entailment"}
{"uid": "id_64", "premise": "The decline in chinas housing and construction market has had a profound knock on effect on chinas steel industry. Due to decreased demand for steel from construction, as huge construction projects around china are reduced to ghost towns by decreased investment, Chinese state owned steel companies have seen their profits drop by almost 96%. The drop in steel prices may be an indicator of things to come; lower steel prices suggest lower predicted g economic growth, and may spell disaster for chinas hopes of continued rapid growth.", "hypothesis": "Decreased steel exports is an effect of chinas construction market decline.", "gold_label": "neutral"}
{"uid": "id_65", "premise": "The decline in chinas housing and construction market has had a profound knock on effect on chinas steel industry. Due to decreased demand for steel from construction, as huge construction projects around china are reduced to ghost towns by decreased investment, Chinese state owned steel companies have seen their profits drop by almost 96%. The drop in steel prices may be an indicator of things to come; lower steel prices suggest lower predicted g economic growth, and may spell disaster for chinas hopes of continued rapid growth.", "hypothesis": "Decreased steel prices is an effect of chinas construction market decline.", "gold_label": "entailment"}
{"uid": "id_66", "premise": "The democracy index, devised by the Economist intelligence unit measures the state of democracy in 167 countries around the world, 166 of which are sovereign states and 165 are members of the United Nations. In this index there are 4 different groupings which denote a countries level of democracy, at the top is a full democracy, of which many North American and western European countries belong. Next is a flawed democracy, of which many South American and Latin American countries belong. Next are hybrid regimes, of which many Asian and eastern European countries belong. Last, and therefore the least democratic counties are authoritarian regimes, which many north African and middle eastern countries belong.", "hypothesis": "tend to contain hybrid regimes Asian and eastern European countries", "gold_label": "entailment"}
{"uid": "id_67", "premise": "The democratic peace theory holds that liberal democracies never, or rarely, go to war against each other. The first to espouse this idea was the German philosopher Immanuel Kant, who posited that constitutional republics engender peace, because the majority of people will not vote to go to war unless in self-defence. More recently, the democratic peace theory was put forth in 1964 by Dean Babst. Babst carried out the first statistical research to scientifically prove that democracies never or rarely fight each other. Despite an undeniable statistical correlation between democracy and peace, the democratic peace theory is highly debated amongst political scientists. The definitions of democracy and war are one contentious issue. Some opponents of the democratic peace theory point to exceptions, such as the Spanish-American War. However, the main criticism of the theory is that it is based on flawed logic that peace between democracies is not caused by the democratic nature of those states. Furthermore, opponents argue that democracies frequently attack non-democracies, dispelling the notion that democracies are inherently pacifistic. There are several derivatives of the democratic peace theory, including the economic peace theory, which states that increased economic exchange between states helps to avoid conflict.", "hypothesis": "The economic peace theory says that countries are less likely to engage in war if their trade is independent of each other.", "gold_label": "contradiction"}
{"uid": "id_68", "premise": "The democratic peace theory holds that liberal democracies never, or rarely, go to war against each other. The first to espouse this idea was the German philosopher Immanuel Kant, who posited that constitutional republics engender peace, because the majority of people will not vote to go to war unless in self-defence. More recently, the democratic peace theory was put forth in 1964 by Dean Babst. Babst carried out the first statistical research to scientifically prove that democracies never or rarely fight each other. Despite an undeniable statistical correlation between democracy and peace, the democratic peace theory is highly debated amongst political scientists. The definitions of democracy and war are one contentious issue. Some opponents of the democratic peace theory point to exceptions, such as the Spanish-American War. However, the main criticism of the theory is that it is based on flawed logic that peace between democracies is not caused by the democratic nature of those states. Furthermore, opponents argue that democracies frequently attack non-democracies, dispelling the notion that democracies are inherently pacifistic. There are several derivatives of the democratic peace theory, including the economic peace theory, which states that increased economic exchange between states helps to avoid conflict.", "hypothesis": "The definition of peace is divisive amongst political scientists.", "gold_label": "neutral"}
{"uid": "id_69", "premise": "The democratic peace theory holds that liberal democracies never, or rarely, go to war against each other. The first to espouse this idea was the German philosopher Immanuel Kant, who posited that constitutional republics engender peace, because the majority of people will not vote to go to war unless in self-defence. More recently, the democratic peace theory was put forth in 1964 by Dean Babst. Babst carried out the first statistical research to scientifically prove that democracies never or rarely fight each other. Despite an undeniable statistical correlation between democracy and peace, the democratic peace theory is highly debated amongst political scientists. The definitions of democracy and war are one contentious issue. Some opponents of the democratic peace theory point to exceptions, such as the Spanish-American War. However, the main criticism of the theory is that it is based on flawed logic that peace between democracies is not caused by the democratic nature of those states. Furthermore, opponents argue that democracies frequently attack non-democracies, dispelling the notion that democracies are inherently pacifistic. There are several derivatives of the democratic peace theory, including the economic peace theory, which states that increased economic exchange between states helps to avoid conflict.", "hypothesis": "Dean Babst found statistical evidence showing democracies do not fight in wars.", "gold_label": "neutral"}
{"uid": "id_70", "premise": "The democratic peace theory holds that liberal democracies never, or rarely, go to war against each other. The first to espouse this idea was the German philosopher Immanuel Kant, who posited that constitutional republics engender peace, because the majority of people will not vote to go to war unless in self-defence. More recently, the democratic peace theory was put forth in 1964 by Dean Babst. Babst carried out the first statistical research to scientifically prove that democracies never or rarely fight each other. Despite an undeniable statistical correlation between democracy and peace, the democratic peace theory is highly debated amongst political scientists. The definitions of democracy and war are one contentious issue. Some opponents of the democratic peace theory point to exceptions, such as the Spanish-American War. However, the main criticism of the theory is that it is based on flawed logic that peace between democracies is not caused by the democratic nature of those states. Furthermore, opponents argue that democracies frequently attack non-democracies, dispelling the notion that democracies are inherently pacifistic. There are several derivatives of the democratic peace theory, including the economic peace theory, which states that increased economic exchange between states helps to avoid conflict.", "hypothesis": "Immanuel Kants theory about democratic peace was the first to statistically research whether democracies rarely or never fight each other.", "gold_label": "contradiction"}
{"uid": "id_71", "premise": "The democratic peace theory holds that liberal democracies never, or rarely, go to war against each other. The first to espouse this idea was the German philosopher Immanuel Kant, who posited that constitutional republics engender peace, because the majority of people will not vote to go to war unless in self-defence. More recently, the democratic peace theory was put forth in 1964 by Dean Babst. Babst carried out the first statistical research to scientifically prove that democracies never or rarely fight each other. Despite an undeniable statistical correlation between democracy and peace, the democratic peace theory is highly debated amongst political scientists. The definitions of democracy and war are one contentious issue. Some opponents of the democratic peace theory point to exceptions, such as the Spanish-American War. However, the main criticism of the theory is that it is based on flawed logic that peace between democracies is not caused by the democratic nature of those states. Furthermore, opponents argue that democracies frequently attack non-democracies, dispelling the notion that democracies are inherently pacifistic. There are several derivatives of the democratic peace theory, including the economic peace theory, which states that increased economic exchange between states helps to avoid conflict.", "hypothesis": "The premise for the democratic peace theory is the accountability of a democratically elected government to its electorate.", "gold_label": "entailment"}
{"uid": "id_72", "premise": "The dominant mobile network in the UK is Orange. Statistics suggest that, since purchasing T-Mobile, the Orange group provides a service to over 30% of mobile users in the United Kingdom. The second most popular network is O2. This company provides network coverage for an estimated 20% of all mobile users in the UK. O2 has proved to be the fastest growing network. This trend mirrors the range of prices offered by the network, the deals available and the amount of revenue spent on advertising. The smallest network providers in the UK are those which offer mobile services as a side-line to their main business, for example supermarket networks. Such providers are responsible for a marginal section of the total mobile service provided in the UK.", "hypothesis": "Supermarket providers provide 1% of network coverage in the UK.", "gold_label": "neutral"}
{"uid": "id_73", "premise": "The dominant mobile network in the UK is Orange. Statistics suggest that, since purchasing T-Mobile, the Orange group provides a service to over 30% of mobile users in the United Kingdom. The second most popular network is O2. This company provides network coverage for an estimated 20% of all mobile users in the UK. O2 has proved to be the fastest growing network. This trend mirrors the range of prices offered by the network, the deals available and the amount of revenue spent on advertising. The smallest network providers in the UK are those which offer mobile services as a side-line to their main business, for example supermarket networks. Such providers are responsible for a marginal section of the total mobile service provided in the UK.", "hypothesis": "O2 offers the cheapest prices.", "gold_label": "neutral"}
{"uid": "id_74", "premise": "The dominant mobile network in the UK is Orange. Statistics suggest that, since purchasing T-Mobile, the Orange group provides a service to over 30% of mobile users in the United Kingdom. The second most popular network is O2. This company provides network coverage for an estimated 20% of all mobile users in the UK. O2 has proved to be the fastest growing network. This trend mirrors the range of prices offered by the network, the deals available and the amount of revenue spent on advertising. The smallest network providers in the UK are those which offer mobile services as a side-line to their main business, for example supermarket networks. Such providers are responsible for a marginal section of the total mobile service provided in the UK.", "hypothesis": "O2 is the fastest growing network.", "gold_label": "entailment"}
{"uid": "id_75", "premise": "The dominant mobile network in the UK is Orange. Statistics suggest that, since purchasing T-Mobile, the Orange group provides a service to over 30% of mobile users in the United Kingdom. The second most popular network is O2. This company provides network coverage for an estimated 20% of all mobile users in the UK. O2 has proved to be the fastest growing network. This trend mirrors the range of prices offered by the network, the deals available and the amount of revenue spent on advertising. The smallest network providers in the UK are those which offer mobile services as a side-line to their main business, for example supermarket networks. Such providers are responsible for a marginal section of the total mobile service provided in the UK.", "hypothesis": "Since Orange bought T Mobile, its user coverage has almost doubled.", "gold_label": "neutral"}
{"uid": "id_76", "premise": "The dramatic decline of the bee population in the UK has been attributed to a number of causes such as the loss of wild flowers in the countryside. Bees require these wildflowers for food and it has been estimated that 97% of the flower-rich grassland has been lost since the 1930s. Other causes include climate change and pesticides that are toxic to bees. This is particularly problematic in the UK, which has had a 50% reduction in the honey bee population between 1985 and 2005 whilst the rest of Europe has only averaged a 20% reduction during the same time period. This loss of flowers from the British countryside has been caused by agricultural pressures. In order to increase food production, traditional farming methods have been abandoned in favour of techniques that increase productivity. These techniques, however, involve the reduction of wild flowers. Bumblebees are required to pollinate wildflowers and commercial crops. A reduction of wildflower pollination will result in their decline, which will ultimately affect other wildlife as they can be involved in a complex food chain. The commercial crops will need to be pollinated artificially using expensive methods that will ultimately drive up the price of fruits and vegetables. The global economic value of pollination from bees has been estimated at 265 billion annually.", "hypothesis": "Increasing pesticide-free fruit and vegetable growth will slow the decline in bee population", "gold_label": "entailment"}
{"uid": "id_77", "premise": "The dramatic decline of the bee population in the UK has been attributed to a number of causes such as the loss of wild flowers in the countryside. Bees require these wildflowers for food and it has been estimated that 97% of the flower-rich grassland has been lost since the 1930s. Other causes include climate change and pesticides that are toxic to bees. This is particularly problematic in the UK, which has had a 50% reduction in the honey bee population between 1985 and 2005 whilst the rest of Europe has only averaged a 20% reduction during the same time period. This loss of flowers from the British countryside has been caused by agricultural pressures. In order to increase food production, traditional farming methods have been abandoned in favour of techniques that increase productivity. These techniques, however, involve the reduction of wild flowers. Bumblebees are required to pollinate wildflowers and commercial crops. A reduction of wildflower pollination will result in their decline, which will ultimately affect other wildlife as they can be involved in a complex food chain. The commercial crops will need to be pollinated artificially using expensive methods that will ultimately drive up the price of fruits and vegetables. The global economic value of pollination from bees has been estimated at 265 billion annually.", "hypothesis": "Artificial pollination will be capable of replacing bees if it becomes cheap enough", "gold_label": "contradiction"}
{"uid": "id_78", "premise": "The dramatic decline of the bee population in the UK has been attributed to a number of causes such as the loss of wild flowers in the countryside. Bees require these wildflowers for food and it has been estimated that 97% of the flower-rich grassland has been lost since the 1930s. Other causes include climate change and pesticides that are toxic to bees. This is particularly problematic in the UK, which has had a 50% reduction in the honey bee population between 1985 and 2005 whilst the rest of Europe has only averaged a 20% reduction during the same time period. This loss of flowers from the British countryside has been caused by agricultural pressures. In order to increase food production, traditional farming methods have been abandoned in favour of techniques that increase productivity. These techniques, however, involve the reduction of wild flowers. Bumblebees are required to pollinate wildflowers and commercial crops. A reduction of wildflower pollination will result in their decline, which will ultimately affect other wildlife as they can be involved in a complex food chain. The commercial crops will need to be pollinated artificially using expensive methods that will ultimately drive up the price of fruits and vegetables. The global economic value of pollination from bees has been estimated at 265 billion annually.", "hypothesis": "Reverting back to traditional farming methods will decrease the overall production of food", "gold_label": "entailment"}
{"uid": "id_79", "premise": "The dramatic decline of the bee population in the UK has been attributed to a number of causes such as the loss of wild flowers in the countryside. Bees require these wildflowers for food and it has been estimated that 97% of the flower-rich grassland has been lost since the 1930s. Other causes include climate change and pesticides that are toxic to bees. This is particularly problematic in the UK, which has had a 50% reduction in the honey bee population between 1985 and 2005 whilst the rest of Europe has only averaged a 20% reduction during the same time period. This loss of flowers from the British countryside has been caused by agricultural pressures. In order to increase food production, traditional farming methods have been abandoned in favour of techniques that increase productivity. These techniques, however, involve the reduction of wild flowers. Bumblebees are required to pollinate wildflowers and commercial crops. A reduction of wildflower pollination will result in their decline, which will ultimately affect other wildlife as they can be involved in a complex food chain. The commercial crops will need to be pollinated artificially using expensive methods that will ultimately drive up the price of fruits and vegetables. The global economic value of pollination from bees has been estimated at 265 billion annually.", "hypothesis": "The UK is the country with the largest decline in bee population", "gold_label": "neutral"}
{"uid": "id_80", "premise": "The dramatic decline of the bee population in the UK has been attributed to a number of causes such as the loss of wild flowers in the countryside. Bees require these wildflowers for food and it has been estimated that 97% of the flower-rich grassland has been lost since the 1930s. Other causes include climate change and pesticides that are toxic to bees. This is particularly problematic in the UK, which has had a 50% reduction in the honey bee population between 1985 and 2005 whilst the rest of Europe has only averaged a 20% reduction during the same time period. This loss of flowers from the British countryside has been caused by agricultural pressures. In order to increase food production, traditional farming methods have been abandoned in favour of techniques that increase productivity. These techniques, however, involve the reduction of wild flowers. Bumblebees are required to pollinate wildflowers and commercial crops. A reduction of wildflower pollination will result in their decline, which will ultimately affect other wildlife as they can be involved in a complex food chain. The commercial crops will need to be pollinated artificially using expensive methods that will ultimately drive up the price of fruits and vegetables. The global economic value of pollination from bees has been estimated at 265 billion annually.", "hypothesis": "The bee population in the UK has decreased by 97% since the 1930s.", "gold_label": "neutral"}
{"uid": "id_81", "premise": "The early manned missions visited lowlands and plains while the later missions explored highlands. Selecting a suitable site was never going to be easy as even the apparently flattest of locations were found to be on closer inspection potholed from meteorite strikes and plastered with small boulders. The moon is rugged and very mountainous and in the 1960s a number of lunar probes had photographed the moons surface during close orbit passes and even performed soft landings in the search for suitable sites for the manned missions that were to follow. In 1969 Neil Armstrong and Edwin Aldrin in Apollo 11 made the first ever manned lunar landing. The last manned landing was made in 1972 with Apollo 17.", "hypothesis": "When referring to a suitable site in the second sentence it means suitable sites for the landing of manned missions.", "gold_label": "entailment"}
{"uid": "id_82", "premise": "The early manned missions visited lowlands and plains while the later missions explored highlands. Selecting a suitable site was never going to be easy as even the apparently flattest of locations were found to be on closer inspection potholed from meteorite strikes and plastered with small boulders. The moon is rugged and very mountainous and in the 1960s a number of lunar probes had photographed the moons surface during close orbit passes and even performed soft landings in the search for suitable sites for the manned missions that were to follow. In 1969 Neil Armstrong and Edwin Aldrin in Apollo 11 made the first ever manned lunar landing. The last manned landing was made in 1972 with Apollo 17.", "hypothesis": "Apollo 17 visited a mountainous region of the moon.", "gold_label": "neutral"}
{"uid": "id_83", "premise": "The early manned missions visited lowlands and plains while the later missions explored highlands. Selecting a suitable site was never going to be easy as even the apparently flattest of locations were found to be on closer inspection potholed from meteorite strikes and plastered with small boulders. The moon is rugged and very mountainous and in the 1960s a number of lunar probes had photographed the moons surface during close orbit passes and even performed soft landings in the search for suitable sites for the manned missions that were to follow. In 1969 Neil Armstrong and Edwin Aldrin in Apollo 11 made the first ever manned lunar landing. The last manned landing was made in 1972 with Apollo 17.", "hypothesis": "The first lunar landing was made in the 1960s.", "gold_label": "neutral"}
{"uid": "id_84", "premise": "The ecological footprint is a simple way to look at how sustainable people are being. It is based on the idea that all the resources taken from the Earth are finite. It is defined by how much land and water would be required to produce the resources that the population consumes within a year. It has been calculated that there are currently 11.2 billion bio-productive hectares available on the Earth. A study in 2004 has suggested that our ecological footprint is 13.5 billion hectares, meaning that we are using the Earths resources 20% faster than they are being renewed. This will ultimately result in the loss of all the Earths resources. Individual countries can look at their own ecological footprint and compare it to the size of their bio-productive capacity. Some countries are in an ecological deficit - they require more land than their bio-productive capacity to sustain them. Other countries have an ecological reserve, meaning that their bio-productive capacity is greater than their footprint. It can be difficult for individual countries to reduce their ecological footprint. This can either be performed by reducing that countries reliance on unsustainable resources or by increasing the amount of bio-productive land available. It is important, however, that a global effort is made to increase our sustainability.", "hypothesis": "The ecological footprint of a country directly depends on its population.", "gold_label": "contradiction"}
{"uid": "id_85", "premise": "The ecological footprint is a simple way to look at how sustainable people are being. It is based on the idea that all the resources taken from the Earth are finite. It is defined by how much land and water would be required to produce the resources that the population consumes within a year. It has been calculated that there are currently 11.2 billion bio-productive hectares available on the Earth. A study in 2004 has suggested that our ecological footprint is 13.5 billion hectares, meaning that we are using the Earths resources 20% faster than they are being renewed. This will ultimately result in the loss of all the Earths resources. Individual countries can look at their own ecological footprint and compare it to the size of their bio-productive capacity. Some countries are in an ecological deficit - they require more land than their bio-productive capacity to sustain them. Other countries have an ecological reserve, meaning that their bio-productive capacity is greater than their footprint. It can be difficult for individual countries to reduce their ecological footprint. This can either be performed by reducing that countries reliance on unsustainable resources or by increasing the amount of bio-productive land available. It is important, however, that a global effort is made to increase our sustainability.", "hypothesis": "The combined area of the Earths land and water mass is 11.2 billion hectares", "gold_label": "contradiction"}
{"uid": "id_86", "premise": "The ecological footprint is a simple way to look at how sustainable people are being. It is based on the idea that all the resources taken from the Earth are finite. It is defined by how much land and water would be required to produce the resources that the population consumes within a year. It has been calculated that there are currently 11.2 billion bio-productive hectares available on the Earth. A study in 2004 has suggested that our ecological footprint is 13.5 billion hectares, meaning that we are using the Earths resources 20% faster than they are being renewed. This will ultimately result in the loss of all the Earths resources. Individual countries can look at their own ecological footprint and compare it to the size of their bio-productive capacity. Some countries are in an ecological deficit - they require more land than their bio-productive capacity to sustain them. Other countries have an ecological reserve, meaning that their bio-productive capacity is greater than their footprint. It can be difficult for individual countries to reduce their ecological footprint. This can either be performed by reducing that countries reliance on unsustainable resources or by increasing the amount of bio-productive land available. It is important, however, that a global effort is made to increase our sustainability.", "hypothesis": "The ecological footprint can be reduced by using sustainable resources.", "gold_label": "entailment"}
{"uid": "id_87", "premise": "The ecological footprint is a simple way to look at how sustainable people are being. It is based on the idea that all the resources taken from the Earth are finite. It is defined by how much land and water would be required to produce the resources that the population consumes within a year. It has been calculated that there are currently 11.2 billion bio-productive hectares available on the Earth. A study in 2004 has suggested that our ecological footprint is 13.5 billion hectares, meaning that we are using the Earths resources 20% faster than they are being renewed. This will ultimately result in the loss of all the Earths resources. Individual countries can look at their own ecological footprint and compare it to the size of their bio-productive capacity. Some countries are in an ecological deficit - they require more land than their bio-productive capacity to sustain them. Other countries have an ecological reserve, meaning that their bio-productive capacity is greater than their footprint. It can be difficult for individual countries to reduce their ecological footprint. This can either be performed by reducing that countries reliance on unsustainable resources or by increasing the amount of bio-productive land available. It is important, however, that a global effort is made to increase our sustainability.", "hypothesis": "Only the countries with an ecological deficit are able to tackle the global problem of sustainability.", "gold_label": "contradiction"}
{"uid": "id_88", "premise": "The ecological footprint is a simple way to look at how sustainable people are being. It is based on the idea that all the resources taken from the Earth are finite. It is defined by how much land and water would be required to produce the resources that the population consumes within a year. It has been calculated that there are currently 11.2 billion bio-productive hectares available on the Earth. A study in 2004 has suggested that our ecological footprint is 13.5 billion hectares, meaning that we are using the Earths resources 20% faster than they are being renewed. This will ultimately result in the loss of all the Earths resources. Individual countries can look at their own ecological footprint and compare it to the size of their bio-productive capacity. Some countries are in an ecological deficit - they require more land than their bio-productive capacity to sustain them. Other countries have an ecological reserve, meaning that their bio-productive capacity is greater than their footprint. It can be difficult for individual countries to reduce their ecological footprint. This can either be performed by reducing that countries reliance on unsustainable resources or by increasing the amount of bio-productive land available. It is important, however, that a global effort is made to increase our sustainability.", "hypothesis": "The bio-productive capacity of the Earth is fixed.", "gold_label": "contradiction"}
{"uid": "id_89", "premise": "The economic importance of coral reefs A lot of people around the world are dependent, or partly dependent, on coral reefs for their livelihoods. They often live adjacent to the reef, and their livelihood revolves around the direct extraction, processing and sale of reef resources such as shell fish and seaweeds. In addition, their homes are sheltered by the reef from wave action. Reef flats and shallow reef lagoons are accessible on foot, without the need for a boat, and so allow women, children and the elderly to engage directly in manual harvesting, or reef-gleaning. This is a significant factor distinguishing reef-based fisheries from near-shore sea fisheries. Near-shore fisheries are typically the domain of adult males, in particular where they involve the use of boats, with women and children restricted mainly to shore-based activities. However, in a coral-reef fishery the physical accessibility of the reef opens up opportunities for direct participation by women, and consequently increases their independence and the importance of their role in the community. It also provides a place for children to play, and to acquire important skills and knowledge for later in life. For example, in the South West Island of Tobi, in the Pacific Ocean, young boys use simple hand lines with a loop and bait at the end to develop the art of fishing on the reef. Similarly, in the Surin Islands of Thailand, young Moken boys spend much of their time playing, swimming and diving in shallow reef lagoons, and in doing so build crucial skills for their future daily subsistence. Secondary occupations, such as fish processing and marketing activities, are often dominated by women, and offer an important survival strategy for households with access to few other physical assets (such as boats and gear), for elderly women, widows, or the wives of infirm men. On Ulithi Atoll in the western Pacific, women have a distinct role and rights in the distribution of fish catches. This is because the canoes, made from mahogany logs from nearby Yap Island, are obtained through the exchange of cloth made by the women of Ulithi. Small-scale reef fisheries support the involvement of local women traders and their involvement can give them greater control over the household income, and in negotiating for loans or credit. Thus their role is not only important in providing income for their families, it also underpins the economy of the local village. Poor people with little access to land, labour and financial resources are particularly reliant on exploiting natural resources, and consequently they are vulnerable to seasonal changes in availability of those resources. The diversity of coral reef fisheries, combined with their physical accessibility and the protection they provide against bad weather, make them relatively stable compared with other fisheries, or land-based agricultural production. In many places, the reef may even act as a resource bank, used as a means of saving food for future times of need. In Manus, Papua New Guinea, giant clams are collected and held in walled enclosures on the reef, until they are needed during periods of rough weather. In Palau, sea cucumbers are seldom eaten during good weather in an effort to conserve their populations for months during which rough weather prohibits good fishing. Coral reef resources also act as a buffer against seasonal lows in other sectors, particularly agriculture. For example, in coastal communities in northern Mozambique, reef harvests provide key sources of food and cash when agricultural production is low, with the peak in fisheries production coinciding with the period of lowest agricultural stocks. In Papua New Guinea, while agriculture is the primary means of food production, a large proportion of the coastal population engage in sporadic subsistence fishing. In many coral-reef areas, tourism is one of the main industries bringing employment, and in many cases is promoted to provide alternatives to fisheries-based livelihoods, and to ensure that local reef resources are conserved. In the Caribbean alone, tours based on scuba-diving have attracted 20 million people in one year. The upgrading of roads and communications associated with the expansion of tourism may also bring benefits to local communities. However, plans for development must be considered carefully. The ability of the poorer members of the community to access the benefits of tourism is far from guaranteed, and requires development guided by social, cultural and environmental principles. There is growing recognition that sustainability is a key requirement, as encompassed in small-scale eco-tourism activities, for instance. Where tourism development has not been carefully planned, and the needs and priorities of the local community have not been properly recognised, conflict has sometimes arisen between tourism and local, small-scale fishers.", "hypothesis": "In coral reef fisheries, only male traders can apply for finance.", "gold_label": "contradiction"}
{"uid": "id_90", "premise": "The economic importance of coral reefs A lot of people around the world are dependent, or partly dependent, on coral reefs for their livelihoods. They often live adjacent to the reef, and their livelihood revolves around the direct extraction, processing and sale of reef resources such as shell fish and seaweeds. In addition, their homes are sheltered by the reef from wave action. Reef flats and shallow reef lagoons are accessible on foot, without the need for a boat, and so allow women, children and the elderly to engage directly in manual harvesting, or reef-gleaning. This is a significant factor distinguishing reef-based fisheries from near-shore sea fisheries. Near-shore fisheries are typically the domain of adult males, in particular where they involve the use of boats, with women and children restricted mainly to shore-based activities. However, in a coral-reef fishery the physical accessibility of the reef opens up opportunities for direct participation by women, and consequently increases their independence and the importance of their role in the community. It also provides a place for children to play, and to acquire important skills and knowledge for later in life. For example, in the South West Island of Tobi, in the Pacific Ocean, young boys use simple hand lines with a loop and bait at the end to develop the art of fishing on the reef. Similarly, in the Surin Islands of Thailand, young Moken boys spend much of their time playing, swimming and diving in shallow reef lagoons, and in doing so build crucial skills for their future daily subsistence. Secondary occupations, such as fish processing and marketing activities, are often dominated by women, and offer an important survival strategy for households with access to few other physical assets (such as boats and gear), for elderly women, widows, or the wives of infirm men. On Ulithi Atoll in the western Pacific, women have a distinct role and rights in the distribution of fish catches. This is because the canoes, made from mahogany logs from nearby Yap Island, are obtained through the exchange of cloth made by the women of Ulithi. Small-scale reef fisheries support the involvement of local women traders and their involvement can give them greater control over the household income, and in negotiating for loans or credit. Thus their role is not only important in providing income for their families, it also underpins the economy of the local village. Poor people with little access to land, labour and financial resources are particularly reliant on exploiting natural resources, and consequently they are vulnerable to seasonal changes in availability of those resources. The diversity of coral reef fisheries, combined with their physical accessibility and the protection they provide against bad weather, make them relatively stable compared with other fisheries, or land-based agricultural production. In many places, the reef may even act as a resource bank, used as a means of saving food for future times of need. In Manus, Papua New Guinea, giant clams are collected and held in walled enclosures on the reef, until they are needed during periods of rough weather. In Palau, sea cucumbers are seldom eaten during good weather in an effort to conserve their populations for months during which rough weather prohibits good fishing. Coral reef resources also act as a buffer against seasonal lows in other sectors, particularly agriculture. For example, in coastal communities in northern Mozambique, reef harvests provide key sources of food and cash when agricultural production is low, with the peak in fisheries production coinciding with the period of lowest agricultural stocks. In Papua New Guinea, while agriculture is the primary means of food production, a large proportion of the coastal population engage in sporadic subsistence fishing. In many coral-reef areas, tourism is one of the main industries bringing employment, and in many cases is promoted to provide alternatives to fisheries-based livelihoods, and to ensure that local reef resources are conserved. In the Caribbean alone, tours based on scuba-diving have attracted 20 million people in one year. The upgrading of roads and communications associated with the expansion of tourism may also bring benefits to local communities. However, plans for development must be considered carefully. The ability of the poorer members of the community to access the benefits of tourism is far from guaranteed, and requires development guided by social, cultural and environmental principles. There is growing recognition that sustainability is a key requirement, as encompassed in small-scale eco-tourism activities, for instance. Where tourism development has not been carefully planned, and the needs and priorities of the local community have not been properly recognised, conflict has sometimes arisen between tourism and local, small-scale fishers.", "hypothesis": "Involvement in coral-reef-based occupations raises the status of women.", "gold_label": "entailment"}
{"uid": "id_91", "premise": "The economic importance of coral reefs A lot of people around the world are dependent, or partly dependent, on coral reefs for their livelihoods. They often live adjacent to the reef, and their livelihood revolves around the direct extraction, processing and sale of reef resources such as shell fish and seaweeds. In addition, their homes are sheltered by the reef from wave action. Reef flats and shallow reef lagoons are accessible on foot, without the need for a boat, and so allow women, children and the elderly to engage directly in manual harvesting, or reef-gleaning. This is a significant factor distinguishing reef-based fisheries from near-shore sea fisheries. Near-shore fisheries are typically the domain of adult males, in particular where they involve the use of boats, with women and children restricted mainly to shore-based activities. However, in a coral-reef fishery the physical accessibility of the reef opens up opportunities for direct participation by women, and consequently increases their independence and the importance of their role in the community. It also provides a place for children to play, and to acquire important skills and knowledge for later in life. For example, in the South West Island of Tobi, in the Pacific Ocean, young boys use simple hand lines with a loop and bait at the end to develop the art of fishing on the reef. Similarly, in the Surin Islands of Thailand, young Moken boys spend much of their time playing, swimming and diving in shallow reef lagoons, and in doing so build crucial skills for their future daily subsistence. Secondary occupations, such as fish processing and marketing activities, are often dominated by women, and offer an important survival strategy for households with access to few other physical assets (such as boats and gear), for elderly women, widows, or the wives of infirm men. On Ulithi Atoll in the western Pacific, women have a distinct role and rights in the distribution of fish catches. This is because the canoes, made from mahogany logs from nearby Yap Island, are obtained through the exchange of cloth made by the women of Ulithi. Small-scale reef fisheries support the involvement of local women traders and their involvement can give them greater control over the household income, and in negotiating for loans or credit. Thus their role is not only important in providing income for their families, it also underpins the economy of the local village. Poor people with little access to land, labour and financial resources are particularly reliant on exploiting natural resources, and consequently they are vulnerable to seasonal changes in availability of those resources. The diversity of coral reef fisheries, combined with their physical accessibility and the protection they provide against bad weather, make them relatively stable compared with other fisheries, or land-based agricultural production. In many places, the reef may even act as a resource bank, used as a means of saving food for future times of need. In Manus, Papua New Guinea, giant clams are collected and held in walled enclosures on the reef, until they are needed during periods of rough weather. In Palau, sea cucumbers are seldom eaten during good weather in an effort to conserve their populations for months during which rough weather prohibits good fishing. Coral reef resources also act as a buffer against seasonal lows in other sectors, particularly agriculture. For example, in coastal communities in northern Mozambique, reef harvests provide key sources of food and cash when agricultural production is low, with the peak in fisheries production coinciding with the period of lowest agricultural stocks. In Papua New Guinea, while agriculture is the primary means of food production, a large proportion of the coastal population engage in sporadic subsistence fishing. In many coral-reef areas, tourism is one of the main industries bringing employment, and in many cases is promoted to provide alternatives to fisheries-based livelihoods, and to ensure that local reef resources are conserved. In the Caribbean alone, tours based on scuba-diving have attracted 20 million people in one year. The upgrading of roads and communications associated with the expansion of tourism may also bring benefits to local communities. However, plans for development must be considered carefully. The ability of the poorer members of the community to access the benefits of tourism is far from guaranteed, and requires development guided by social, cultural and environmental principles. There is growing recognition that sustainability is a key requirement, as encompassed in small-scale eco-tourism activities, for instance. Where tourism development has not been carefully planned, and the needs and priorities of the local community have not been properly recognised, conflict has sometimes arisen between tourism and local, small-scale fishers.", "hypothesis": "In most places, coral-reef gleaning is normally carried out by men.", "gold_label": "contradiction"}
{"uid": "id_92", "premise": "The economic importance of coral reefs A lot of people around the world are dependent, or partly dependent, on coral reefs for their livelihoods. They often live adjacent to the reef, and their livelihood revolves around the direct extraction, processing and sale of reef resources such as shell fish and seaweeds. In addition, their homes are sheltered by the reef from wave action. Reef flats and shallow reef lagoons are accessible on foot, without the need for a boat, and so allow women, children and the elderly to engage directly in manual harvesting, or reef-gleaning. This is a significant factor distinguishing reef-based fisheries from near-shore sea fisheries. Near-shore fisheries are typically the domain of adult males, in particular where they involve the use of boats, with women and children restricted mainly to shore-based activities. However, in a coral-reef fishery the physical accessibility of the reef opens up opportunities for direct participation by women, and consequently increases their independence and the importance of their role in the community. It also provides a place for children to play, and to acquire important skills and knowledge for later in life. For example, in the South West Island of Tobi, in the Pacific Ocean, young boys use simple hand lines with a loop and bait at the end to develop the art of fishing on the reef. Similarly, in the Surin Islands of Thailand, young Moken boys spend much of their time playing, swimming and diving in shallow reef lagoons, and in doing so build crucial skills for their future daily subsistence. Secondary occupations, such as fish processing and marketing activities, are often dominated by women, and offer an important survival strategy for households with access to few other physical assets (such as boats and gear), for elderly women, widows, or the wives of infirm men. On Ulithi Atoll in the western Pacific, women have a distinct role and rights in the distribution of fish catches. This is because the canoes, made from mahogany logs from nearby Yap Island, are obtained through the exchange of cloth made by the women of Ulithi. Small-scale reef fisheries support the involvement of local women traders and their involvement can give them greater control over the household income, and in negotiating for loans or credit. Thus their role is not only important in providing income for their families, it also underpins the economy of the local village. Poor people with little access to land, labour and financial resources are particularly reliant on exploiting natural resources, and consequently they are vulnerable to seasonal changes in availability of those resources. The diversity of coral reef fisheries, combined with their physical accessibility and the protection they provide against bad weather, make them relatively stable compared with other fisheries, or land-based agricultural production. In many places, the reef may even act as a resource bank, used as a means of saving food for future times of need. In Manus, Papua New Guinea, giant clams are collected and held in walled enclosures on the reef, until they are needed during periods of rough weather. In Palau, sea cucumbers are seldom eaten during good weather in an effort to conserve their populations for months during which rough weather prohibits good fishing. Coral reef resources also act as a buffer against seasonal lows in other sectors, particularly agriculture. For example, in coastal communities in northern Mozambique, reef harvests provide key sources of food and cash when agricultural production is low, with the peak in fisheries production coinciding with the period of lowest agricultural stocks. In Papua New Guinea, while agriculture is the primary means of food production, a large proportion of the coastal population engage in sporadic subsistence fishing. In many coral-reef areas, tourism is one of the main industries bringing employment, and in many cases is promoted to provide alternatives to fisheries-based livelihoods, and to ensure that local reef resources are conserved. In the Caribbean alone, tours based on scuba-diving have attracted 20 million people in one year. The upgrading of roads and communications associated with the expansion of tourism may also bring benefits to local communities. However, plans for development must be considered carefully. The ability of the poorer members of the community to access the benefits of tourism is far from guaranteed, and requires development guided by social, cultural and environmental principles. There is growing recognition that sustainability is a key requirement, as encompassed in small-scale eco-tourism activities, for instance. Where tourism development has not been carefully planned, and the needs and priorities of the local community have not been properly recognised, conflict has sometimes arisen between tourism and local, small-scale fishers.", "hypothesis": "Boats for use by the inhabitants of Ulithi are constructed on Yap Island.", "gold_label": "neutral"}
{"uid": "id_93", "premise": "The economic importance of coral reefs A lot of people around the world are dependent, or partly dependent, on coral reefs for their livelihoods. They often live adjacent to the reef, and their livelihood revolves around the direct extraction, processing and sale of reef resources such as shell fish and seaweeds. In addition, their homes are sheltered by the reef from wave action. Reef flats and shallow reef lagoons are accessible on foot, without the need for a boat, and so allow women, children and the elderly to engage directly in manual harvesting, or reef-gleaning. This is a significant factor distinguishing reef-based fisheries from near-shore sea fisheries. Near-shore fisheries are typically the domain of adult males, in particular where they involve the use of boats, with women and children restricted mainly to shore-based activities. However, in a coral-reef fishery the physical accessibility of the reef opens up opportunities for direct participation by women, and consequently increases their independence and the importance of their role in the community. It also provides a place for children to play, and to acquire important skills and knowledge for later in life. For example, in the South West Island of Tobi, in the Pacific Ocean, young boys use simple hand lines with a loop and bait at the end to develop the art of fishing on the reef. Similarly, in the Surin Islands of Thailand, young Moken boys spend much of their time playing, swimming and diving in shallow reef lagoons, and in doing so build crucial skills for their future daily subsistence. Secondary occupations, such as fish processing and marketing activities, are often dominated by women, and offer an important survival strategy for households with access to few other physical assets (such as boats and gear), for elderly women, widows, or the wives of infirm men. On Ulithi Atoll in the western Pacific, women have a distinct role and rights in the distribution of fish catches. This is because the canoes, made from mahogany logs from nearby Yap Island, are obtained through the exchange of cloth made by the women of Ulithi. Small-scale reef fisheries support the involvement of local women traders and their involvement can give them greater control over the household income, and in negotiating for loans or credit. Thus their role is not only important in providing income for their families, it also underpins the economy of the local village. Poor people with little access to land, labour and financial resources are particularly reliant on exploiting natural resources, and consequently they are vulnerable to seasonal changes in availability of those resources. The diversity of coral reef fisheries, combined with their physical accessibility and the protection they provide against bad weather, make them relatively stable compared with other fisheries, or land-based agricultural production. In many places, the reef may even act as a resource bank, used as a means of saving food for future times of need. In Manus, Papua New Guinea, giant clams are collected and held in walled enclosures on the reef, until they are needed during periods of rough weather. In Palau, sea cucumbers are seldom eaten during good weather in an effort to conserve their populations for months during which rough weather prohibits good fishing. Coral reef resources also act as a buffer against seasonal lows in other sectors, particularly agriculture. For example, in coastal communities in northern Mozambique, reef harvests provide key sources of food and cash when agricultural production is low, with the peak in fisheries production coinciding with the period of lowest agricultural stocks. In Papua New Guinea, while agriculture is the primary means of food production, a large proportion of the coastal population engage in sporadic subsistence fishing. In many coral-reef areas, tourism is one of the main industries bringing employment, and in many cases is promoted to provide alternatives to fisheries-based livelihoods, and to ensure that local reef resources are conserved. In the Caribbean alone, tours based on scuba-diving have attracted 20 million people in one year. The upgrading of roads and communications associated with the expansion of tourism may also bring benefits to local communities. However, plans for development must be considered carefully. The ability of the poorer members of the community to access the benefits of tourism is far from guaranteed, and requires development guided by social, cultural and environmental principles. There is growing recognition that sustainability is a key requirement, as encompassed in small-scale eco-tourism activities, for instance. Where tourism development has not been carefully planned, and the needs and priorities of the local community have not been properly recognised, conflict has sometimes arisen between tourism and local, small-scale fishers.", "hypothesis": "The women of Ulithi Atoll have some control over how fish catches are shared out.", "gold_label": "entailment"}
{"uid": "id_94", "premise": "The economic importance of coral reefs A lot of people around the world are dependent, or partly dependent, on coral reefs for their livelihoods. They often live adjacent to the reef, and their livelihood revolves around the direct extraction, processing and sale of reef resources such as shell fish and seaweeds. In addition, their homes are sheltered by the reef from wave action. Reef flats and shallow reef lagoons are accessible on foot, without the need for a boat, and so allow women, children and the elderly to engage directly in manual harvesting, or reef-gleaning. This is a significant factor distinguishing reef-based fisheries from near-shore sea fisheries. Near-shore fisheries are typically the domain of adult males, in particular where they involve the use of boats, with women and children restricted mainly to shore-based activities. However, in a coral-reef fishery the physical accessibility of the reef opens up opportunities for direct participation by women, and consequently increases their independence and the importance of their role in the community. It also provides a place for children to play, and to acquire important skills and knowledge for later in life. For example, in the South West Island of Tobi, in the Pacific Ocean, young boys use simple hand lines with a loop and bait at the end to develop the art of fishing on the reef. Similarly, in the Surin Islands of Thailand, young Moken boys spend much of their time playing, swimming and diving in shallow reef lagoons, and in doing so build crucial skills for their future daily subsistence. Secondary occupations, such as fish processing and marketing activities, are often dominated by women, and offer an important survival strategy for households with access to few other physical assets (such as boats and gear), for elderly women, widows, or the wives of infirm men. On Ulithi Atoll in the western Pacific, women have a distinct role and rights in the distribution of fish catches. This is because the canoes, made from mahogany logs from nearby Yap Island, are obtained through the exchange of cloth made by the women of Ulithi. Small-scale reef fisheries support the involvement of local women traders and their involvement can give them greater control over the household income, and in negotiating for loans or credit. Thus their role is not only important in providing income for their families, it also underpins the economy of the local village. Poor people with little access to land, labour and financial resources are particularly reliant on exploiting natural resources, and consequently they are vulnerable to seasonal changes in availability of those resources. The diversity of coral reef fisheries, combined with their physical accessibility and the protection they provide against bad weather, make them relatively stable compared with other fisheries, or land-based agricultural production. In many places, the reef may even act as a resource bank, used as a means of saving food for future times of need. In Manus, Papua New Guinea, giant clams are collected and held in walled enclosures on the reef, until they are needed during periods of rough weather. In Palau, sea cucumbers are seldom eaten during good weather in an effort to conserve their populations for months during which rough weather prohibits good fishing. Coral reef resources also act as a buffer against seasonal lows in other sectors, particularly agriculture. For example, in coastal communities in northern Mozambique, reef harvests provide key sources of food and cash when agricultural production is low, with the peak in fisheries production coinciding with the period of lowest agricultural stocks. In Papua New Guinea, while agriculture is the primary means of food production, a large proportion of the coastal population engage in sporadic subsistence fishing. In many coral-reef areas, tourism is one of the main industries bringing employment, and in many cases is promoted to provide alternatives to fisheries-based livelihoods, and to ensure that local reef resources are conserved. In the Caribbean alone, tours based on scuba-diving have attracted 20 million people in one year. The upgrading of roads and communications associated with the expansion of tourism may also bring benefits to local communities. However, plans for development must be considered carefully. The ability of the poorer members of the community to access the benefits of tourism is far from guaranteed, and requires development guided by social, cultural and environmental principles. There is growing recognition that sustainability is a key requirement, as encompassed in small-scale eco-tourism activities, for instance. Where tourism development has not been carefully planned, and the needs and priorities of the local community have not been properly recognised, conflict has sometimes arisen between tourism and local, small-scale fishers.", "hypothesis": "Coral reefs provide a less constant source of income than near-shore seas.", "gold_label": "contradiction"}
{"uid": "id_95", "premise": "The economic importance of coral reefs A lot of people around the world are dependent, or partly dependent, on coral reefs for their livelihoods. They often live adjacent to the reef, and their livelihood revolves around the direct extraction, processing and sale of reef resources such as shell fish and seaweeds. In addition, their homes are sheltered by the reef from wave action. Reef flats and shallow reef lagoons are accessible on foot, without the need for a boat, and so allow women, children and the elderly to engage directly in manual harvesting, or reef-gleaning. This is a significant factor distinguishing reef-based fisheries from near-shore sea fisheries. Near-shore fisheries are typically the domain of adult males, in particular where they involve the use of boats, with women and children restricted mainly to shore-based activities. However, in a coral-reef fishery the physical accessibility of the reef opens up opportunities for direct participation by women, and consequently increases their independence and the importance of their role in the community. It also provides a place for children to play, and to acquire important skills and knowledge for later in life. For example, in the South West Island of Tobi, in the Pacific Ocean, young boys use simple hand lines with a loop and bait at the end to develop the art of fishing on the reef. Similarly, in the Surin Islands of Thailand, young Moken boys spend much of their time playing, swimming and diving in shallow reef lagoons, and in doing so build crucial skills for their future daily subsistence. Secondary occupations, such as fish processing and marketing activities, are often dominated by women, and offer an important survival strategy for households with access to few other physical assets (such as boats and gear), for elderly women, widows, or the wives of infirm men. On Ulithi Atoll in the western Pacific, women have a distinct role and rights in the distribution of fish catches. This is because the canoes, made from mahogany logs from nearby Yap Island, are obtained through the exchange of cloth made by the women of Ulithi. Small-scale reef fisheries support the involvement of local women traders and their involvement can give them greater control over the household income, and in negotiating for loans or credit. Thus their role is not only important in providing income for their families, it also underpins the economy of the local village. Poor people with little access to land, labour and financial resources are particularly reliant on exploiting natural resources, and consequently they are vulnerable to seasonal changes in availability of those resources. The diversity of coral reef fisheries, combined with their physical accessibility and the protection they provide against bad weather, make them relatively stable compared with other fisheries, or land-based agricultural production. In many places, the reef may even act as a resource bank, used as a means of saving food for future times of need. In Manus, Papua New Guinea, giant clams are collected and held in walled enclosures on the reef, until they are needed during periods of rough weather. In Palau, sea cucumbers are seldom eaten during good weather in an effort to conserve their populations for months during which rough weather prohibits good fishing. Coral reef resources also act as a buffer against seasonal lows in other sectors, particularly agriculture. For example, in coastal communities in northern Mozambique, reef harvests provide key sources of food and cash when agricultural production is low, with the peak in fisheries production coinciding with the period of lowest agricultural stocks. In Papua New Guinea, while agriculture is the primary means of food production, a large proportion of the coastal population engage in sporadic subsistence fishing. In many coral-reef areas, tourism is one of the main industries bringing employment, and in many cases is promoted to provide alternatives to fisheries-based livelihoods, and to ensure that local reef resources are conserved. In the Caribbean alone, tours based on scuba-diving have attracted 20 million people in one year. The upgrading of roads and communications associated with the expansion of tourism may also bring benefits to local communities. However, plans for development must be considered carefully. The ability of the poorer members of the community to access the benefits of tourism is far from guaranteed, and requires development guided by social, cultural and environmental principles. There is growing recognition that sustainability is a key requirement, as encompassed in small-scale eco-tourism activities, for instance. Where tourism development has not been carefully planned, and the needs and priorities of the local community have not been properly recognised, conflict has sometimes arisen between tourism and local, small-scale fishers.", "hypothesis": "Coral reefs provide valuable learning opportunities for young children.", "gold_label": "entailment"}
{"uid": "id_96", "premise": "The effects of light on plant and animal species Light is important to organisms for two different reasons. Firstly it is used as a cue for the timing, of daily and seasonal rhythms in both plants and animals, and secondly it is used to assist growth in plants. Breeding in most organisms occurs during a part of the year only, and so a reliable cue is needed to trigger breeding behaviour. Day length is an excellent cue, because it provides a perfectly predictable pattern of change within the year. In the temperate zone in spring, temperatures fluctuate greatly from day to day, but day length increases steadily by a predictable amount. The seasonal impact of day length on physiological responses is called photoperiodism, and the amount of experimental evidence for this phenomenon is considerable. For example, some species of birds' breeding can be induced even in midwinter simply by increasing day length artificially (Wolfson 1964). Other examples of photoperiodism occur in plants. A short-day plant flowers when the day is less than a certain critical length. A long-day plant flowers after a certain critical day length is exceeded. In both cases the critical day length differs from species to species. Plants which flower after a period of vegetative growth, regardless of photoperiod, are known as day-neutral plants. Breeding seasons in animals such as birds have evolved to occupy the part of the year in which offspring have the greatest chances of survival. Before the breeding season begins, food reserves must be built up to support the energy cost of reproduction, and to provide for young birds both when they are in the nest and after fledging. Thus many temperate-zone birds use the increasing day lengths in spring as a cue to begin the nesting cycle, because this is a point when adequate food resources will be assured. The adaptive significance at photoperiodism in plants is also clear. Short-day plants that flower in spring in the temperate zone are adapted to maximizing seedling growth during the growing season. Long-day plants are adapted for situations that require fertilization by insects, or a long period of seed ripening. Short-day plants that flower in the autumn in the temperate zone are able to build up food reserves over the growing season and over winter as seeds. Day-neutral plants have an evolutionary advantage when the connection between the favourable period for reproduction and day length is much less certain. For example, desert annuals germinate, flower and seed whenever suitable rainfall occurs, regardless of the day length. The breeding season of some plants can be delayed to extraordinary lengths. Bamboos are perennial grasses that remain in a vegetative state for many years and then suddenly flower, fruit and die (Evans 1976). Every bamboo of the species Chusquea abietifolio on the island of Jamaica flowered, set seed and died during 1884. The next generation of bamboo flowered and died between 1916 and 1918, which suggests a vegetative cycle of about 31 years. The climatic trigger for this flowering cycle is not yet known, but the adaptive significance is clear. The simultaneous production of masses of bamboo seeds (in some cases lying 12 to 15 centimetres deep on the ground) is more than all the seed-eating animals can cope with at the time, so that some seeds escape being eaten and grow up to form the next generation (Evans 1976). The second reason light is important to organisms is that it is essential for photosynthesis. This is the process by which plants use energy from the sun to convert carbon from soil or water into organic material for growth. The rate of photosynthesis in a plant can be measured by calculating the rate of its uptake of carbon. There is a wide range of photosynthetic responses of plants to variations in light intensity. Some plants reach maximal photosynthesis at one-quarter full sunlight, and others, like sugarcane, never reach a maximum, but continue to increase photosynthesis rate as light intensity rises. Plants in general can be divided into two groups: shade-tolerant species and shade-intolerant species. This classification is commonly used in forestry and horticulture. Shade-tolerant plants have lower photosynthetic rates and hence have lower growth rates than those of shade-intolerant species. Plant species become adapted to living in a certain kind of habitat, and in the process evolve a series of characteristics that prevent them from occupying other habitats. Grime (1966) suggests that light may be one of the major components directing these adaptations. For example, eastern hemlock seedlings are shade-tolerant. They can survive in the forest understory under very low light levels because they have a low photosynthetic rate.", "hypothesis": "Photoperiodism is restricted to certain geographic areas.", "gold_label": "neutral"}
{"uid": "id_97", "premise": "The effects of light on plant and animal species Light is important to organisms for two different reasons. Firstly it is used as a cue for the timing, of daily and seasonal rhythms in both plants and animals, and secondly it is used to assist growth in plants. Breeding in most organisms occurs during a part of the year only, and so a reliable cue is needed to trigger breeding behaviour. Day length is an excellent cue, because it provides a perfectly predictable pattern of change within the year. In the temperate zone in spring, temperatures fluctuate greatly from day to day, but day length increases steadily by a predictable amount. The seasonal impact of day length on physiological responses is called photoperiodism, and the amount of experimental evidence for this phenomenon is considerable. For example, some species of birds' breeding can be induced even in midwinter simply by increasing day length artificially (Wolfson 1964). Other examples of photoperiodism occur in plants. A short-day plant flowers when the day is less than a certain critical length. A long-day plant flowers after a certain critical day length is exceeded. In both cases the critical day length differs from species to species. Plants which flower after a period of vegetative growth, regardless of photoperiod, are known as day-neutral plants. Breeding seasons in animals such as birds have evolved to occupy the part of the year in which offspring have the greatest chances of survival. Before the breeding season begins, food reserves must be built up to support the energy cost of reproduction, and to provide for young birds both when they are in the nest and after fledging. Thus many temperate-zone birds use the increasing day lengths in spring as a cue to begin the nesting cycle, because this is a point when adequate food resources will be assured. The adaptive significance at photoperiodism in plants is also clear. Short-day plants that flower in spring in the temperate zone are adapted to maximizing seedling growth during the growing season. Long-day plants are adapted for situations that require fertilization by insects, or a long period of seed ripening. Short-day plants that flower in the autumn in the temperate zone are able to build up food reserves over the growing season and over winter as seeds. Day-neutral plants have an evolutionary advantage when the connection between the favourable period for reproduction and day length is much less certain. For example, desert annuals germinate, flower and seed whenever suitable rainfall occurs, regardless of the day length. The breeding season of some plants can be delayed to extraordinary lengths. Bamboos are perennial grasses that remain in a vegetative state for many years and then suddenly flower, fruit and die (Evans 1976). Every bamboo of the species Chusquea abietifolio on the island of Jamaica flowered, set seed and died during 1884. The next generation of bamboo flowered and died between 1916 and 1918, which suggests a vegetative cycle of about 31 years. The climatic trigger for this flowering cycle is not yet known, but the adaptive significance is clear. The simultaneous production of masses of bamboo seeds (in some cases lying 12 to 15 centimetres deep on the ground) is more than all the seed-eating animals can cope with at the time, so that some seeds escape being eaten and grow up to form the next generation (Evans 1976). The second reason light is important to organisms is that it is essential for photosynthesis. This is the process by which plants use energy from the sun to convert carbon from soil or water into organic material for growth. The rate of photosynthesis in a plant can be measured by calculating the rate of its uptake of carbon. There is a wide range of photosynthetic responses of plants to variations in light intensity. Some plants reach maximal photosynthesis at one-quarter full sunlight, and others, like sugarcane, never reach a maximum, but continue to increase photosynthesis rate as light intensity rises. Plants in general can be divided into two groups: shade-tolerant species and shade-intolerant species. This classification is commonly used in forestry and horticulture. Shade-tolerant plants have lower photosynthetic rates and hence have lower growth rates than those of shade-intolerant species. Plant species become adapted to living in a certain kind of habitat, and in the process evolve a series of characteristics that prevent them from occupying other habitats. Grime (1966) suggests that light may be one of the major components directing these adaptations. For example, eastern hemlock seedlings are shade-tolerant. They can survive in the forest understory under very low light levels because they have a low photosynthetic rate.", "hypothesis": "Some types of bird can be encouraged to breed out of season.", "gold_label": "entailment"}
{"uid": "id_98", "premise": "The effects of light on plant and animal species Light is important to organisms for two different reasons. Firstly it is used as a cue for the timing, of daily and seasonal rhythms in both plants and animals, and secondly it is used to assist growth in plants. Breeding in most organisms occurs during a part of the year only, and so a reliable cue is needed to trigger breeding behaviour. Day length is an excellent cue, because it provides a perfectly predictable pattern of change within the year. In the temperate zone in spring, temperatures fluctuate greatly from day to day, but day length increases steadily by a predictable amount. The seasonal impact of day length on physiological responses is called photoperiodism, and the amount of experimental evidence for this phenomenon is considerable. For example, some species of birds' breeding can be induced even in midwinter simply by increasing day length artificially (Wolfson 1964). Other examples of photoperiodism occur in plants. A short-day plant flowers when the day is less than a certain critical length. A long-day plant flowers after a certain critical day length is exceeded. In both cases the critical day length differs from species to species. Plants which flower after a period of vegetative growth, regardless of photoperiod, are known as day-neutral plants. Breeding seasons in animals such as birds have evolved to occupy the part of the year in which offspring have the greatest chances of survival. Before the breeding season begins, food reserves must be built up to support the energy cost of reproduction, and to provide for young birds both when they are in the nest and after fledging. Thus many temperate-zone birds use the increasing day lengths in spring as a cue to begin the nesting cycle, because this is a point when adequate food resources will be assured. The adaptive significance at photoperiodism in plants is also clear. Short-day plants that flower in spring in the temperate zone are adapted to maximizing seedling growth during the growing season. Long-day plants are adapted for situations that require fertilization by insects, or a long period of seed ripening. Short-day plants that flower in the autumn in the temperate zone are able to build up food reserves over the growing season and over winter as seeds. Day-neutral plants have an evolutionary advantage when the connection between the favourable period for reproduction and day length is much less certain. For example, desert annuals germinate, flower and seed whenever suitable rainfall occurs, regardless of the day length. The breeding season of some plants can be delayed to extraordinary lengths. Bamboos are perennial grasses that remain in a vegetative state for many years and then suddenly flower, fruit and die (Evans 1976). Every bamboo of the species Chusquea abietifolio on the island of Jamaica flowered, set seed and died during 1884. The next generation of bamboo flowered and died between 1916 and 1918, which suggests a vegetative cycle of about 31 years. The climatic trigger for this flowering cycle is not yet known, but the adaptive significance is clear. The simultaneous production of masses of bamboo seeds (in some cases lying 12 to 15 centimetres deep on the ground) is more than all the seed-eating animals can cope with at the time, so that some seeds escape being eaten and grow up to form the next generation (Evans 1976). The second reason light is important to organisms is that it is essential for photosynthesis. This is the process by which plants use energy from the sun to convert carbon from soil or water into organic material for growth. The rate of photosynthesis in a plant can be measured by calculating the rate of its uptake of carbon. There is a wide range of photosynthetic responses of plants to variations in light intensity. Some plants reach maximal photosynthesis at one-quarter full sunlight, and others, like sugarcane, never reach a maximum, but continue to increase photosynthesis rate as light intensity rises. Plants in general can be divided into two groups: shade-tolerant species and shade-intolerant species. This classification is commonly used in forestry and horticulture. Shade-tolerant plants have lower photosynthetic rates and hence have lower growth rates than those of shade-intolerant species. Plant species become adapted to living in a certain kind of habitat, and in the process evolve a series of characteristics that prevent them from occupying other habitats. Grime (1966) suggests that light may be one of the major components directing these adaptations. For example, eastern hemlock seedlings are shade-tolerant. They can survive in the forest understory under very low light levels because they have a low photosynthetic rate.", "hypothesis": "Scientists have yet to determine the cue for Chusquea abitifolia's seasonal rhythm.", "gold_label": "entailment"}
{"uid": "id_99", "premise": "The effects of light on plant and animal species Light is important to organisms for two different reasons. Firstly it is used as a cue for the timing, of daily and seasonal rhythms in both plants and animals, and secondly it is used to assist growth in plants. Breeding in most organisms occurs during a part of the year only, and so a reliable cue is needed to trigger breeding behaviour. Day length is an excellent cue, because it provides a perfectly predictable pattern of change within the year. In the temperate zone in spring, temperatures fluctuate greatly from day to day, but day length increases steadily by a predictable amount. The seasonal impact of day length on physiological responses is called photoperiodism, and the amount of experimental evidence for this phenomenon is considerable. For example, some species of birds' breeding can be induced even in midwinter simply by increasing day length artificially (Wolfson 1964). Other examples of photoperiodism occur in plants. A short-day plant flowers when the day is less than a certain critical length. A long-day plant flowers after a certain critical day length is exceeded. In both cases the critical day length differs from species to species. Plants which flower after a period of vegetative growth, regardless of photoperiod, are known as day-neutral plants. Breeding seasons in animals such as birds have evolved to occupy the part of the year in which offspring have the greatest chances of survival. Before the breeding season begins, food reserves must be built up to support the energy cost of reproduction, and to provide for young birds both when they are in the nest and after fledging. Thus many temperate-zone birds use the increasing day lengths in spring as a cue to begin the nesting cycle, because this is a point when adequate food resources will be assured. The adaptive significance at photoperiodism in plants is also clear. Short-day plants that flower in spring in the temperate zone are adapted to maximizing seedling growth during the growing season. Long-day plants are adapted for situations that require fertilization by insects, or a long period of seed ripening. Short-day plants that flower in the autumn in the temperate zone are able to build up food reserves over the growing season and over winter as seeds. Day-neutral plants have an evolutionary advantage when the connection between the favourable period for reproduction and day length is much less certain. For example, desert annuals germinate, flower and seed whenever suitable rainfall occurs, regardless of the day length. The breeding season of some plants can be delayed to extraordinary lengths. Bamboos are perennial grasses that remain in a vegetative state for many years and then suddenly flower, fruit and die (Evans 1976). Every bamboo of the species Chusquea abietifolio on the island of Jamaica flowered, set seed and died during 1884. The next generation of bamboo flowered and died between 1916 and 1918, which suggests a vegetative cycle of about 31 years. The climatic trigger for this flowering cycle is not yet known, but the adaptive significance is clear. The simultaneous production of masses of bamboo seeds (in some cases lying 12 to 15 centimetres deep on the ground) is more than all the seed-eating animals can cope with at the time, so that some seeds escape being eaten and grow up to form the next generation (Evans 1976). The second reason light is important to organisms is that it is essential for photosynthesis. This is the process by which plants use energy from the sun to convert carbon from soil or water into organic material for growth. The rate of photosynthesis in a plant can be measured by calculating the rate of its uptake of carbon. There is a wide range of photosynthetic responses of plants to variations in light intensity. Some plants reach maximal photosynthesis at one-quarter full sunlight, and others, like sugarcane, never reach a maximum, but continue to increase photosynthesis rate as light intensity rises. Plants in general can be divided into two groups: shade-tolerant species and shade-intolerant species. This classification is commonly used in forestry and horticulture. Shade-tolerant plants have lower photosynthetic rates and hence have lower growth rates than those of shade-intolerant species. Plant species become adapted to living in a certain kind of habitat, and in the process evolve a series of characteristics that prevent them from occupying other habitats. Grime (1966) suggests that light may be one of the major components directing these adaptations. For example, eastern hemlock seedlings are shade-tolerant. They can survive in the forest understory under very low light levels because they have a low photosynthetic rate.", "hypothesis": "Desert annuals are examples of long-day plants.", "gold_label": "contradiction"}
{"uid": "id_100", "premise": "The effects of light on plant and animal species Light is important to organisms for two different reasons. Firstly it is used as a cue for the timing, of daily and seasonal rhythms in both plants and animals, and secondly it is used to assist growth in plants. Breeding in most organisms occurs during a part of the year only, and so a reliable cue is needed to trigger breeding behaviour. Day length is an excellent cue, because it provides a perfectly predictable pattern of change within the year. In the temperate zone in spring, temperatures fluctuate greatly from day to day, but day length increases steadily by a predictable amount. The seasonal impact of day length on physiological responses is called photoperiodism, and the amount of experimental evidence for this phenomenon is considerable. For example, some species of birds' breeding can be induced even in midwinter simply by increasing day length artificially (Wolfson 1964). Other examples of photoperiodism occur in plants. A short-day plant flowers when the day is less than a certain critical length. A long-day plant flowers after a certain critical day length is exceeded. In both cases the critical day length differs from species to species. Plants which flower after a period of vegetative growth, regardless of photoperiod, are known as day-neutral plants. Breeding seasons in animals such as birds have evolved to occupy the part of the year in which offspring have the greatest chances of survival. Before the breeding season begins, food reserves must be built up to support the energy cost of reproduction, and to provide for young birds both when they are in the nest and after fledging. Thus many temperate-zone birds use the increasing day lengths in spring as a cue to begin the nesting cycle, because this is a point when adequate food resources will be assured. The adaptive significance at photoperiodism in plants is also clear. Short-day plants that flower in spring in the temperate zone are adapted to maximizing seedling growth during the growing season. Long-day plants are adapted for situations that require fertilization by insects, or a long period of seed ripening. Short-day plants that flower in the autumn in the temperate zone are able to build up food reserves over the growing season and over winter as seeds. Day-neutral plants have an evolutionary advantage when the connection between the favourable period for reproduction and day length is much less certain. For example, desert annuals germinate, flower and seed whenever suitable rainfall occurs, regardless of the day length. The breeding season of some plants can be delayed to extraordinary lengths. Bamboos are perennial grasses that remain in a vegetative state for many years and then suddenly flower, fruit and die (Evans 1976). Every bamboo of the species Chusquea abietifolio on the island of Jamaica flowered, set seed and died during 1884. The next generation of bamboo flowered and died between 1916 and 1918, which suggests a vegetative cycle of about 31 years. The climatic trigger for this flowering cycle is not yet known, but the adaptive significance is clear. The simultaneous production of masses of bamboo seeds (in some cases lying 12 to 15 centimetres deep on the ground) is more than all the seed-eating animals can cope with at the time, so that some seeds escape being eaten and grow up to form the next generation (Evans 1976). The second reason light is important to organisms is that it is essential for photosynthesis. This is the process by which plants use energy from the sun to convert carbon from soil or water into organic material for growth. The rate of photosynthesis in a plant can be measured by calculating the rate of its uptake of carbon. There is a wide range of photosynthetic responses of plants to variations in light intensity. Some plants reach maximal photosynthesis at one-quarter full sunlight, and others, like sugarcane, never reach a maximum, but continue to increase photosynthesis rate as light intensity rises. Plants in general can be divided into two groups: shade-tolerant species and shade-intolerant species. This classification is commonly used in forestry and horticulture. Shade-tolerant plants have lower photosynthetic rates and hence have lower growth rates than those of shade-intolerant species. Plant species become adapted to living in a certain kind of habitat, and in the process evolve a series of characteristics that prevent them from occupying other habitats. Grime (1966) suggests that light may be one of the major components directing these adaptations. For example, eastern hemlock seedlings are shade-tolerant. They can survive in the forest understory under very low light levels because they have a low photosynthetic rate.", "hypothesis": "Eastern hemlock is a fast-growing plant.", "gold_label": "contradiction"}
{"uid": "id_101", "premise": "The effects of light on plant and animal species Light is important to organisms for two different reasons. Firstly it is used as a cue for the timing, of daily and seasonal rhythms in both plants and animals, and secondly it is used to assist growth in plants. Breeding in most organisms occurs during a part of the year only, and so a reliable cue is needed to trigger breeding behaviour. Day length is an excellent cue, because it provides a perfectly predictable pattern of change within the year. In the temperate zone in spring, temperatures fluctuate greatly from day to day, but day length increases steadily by a predictable amount. The seasonal impact of day length on physiological responses is called photoperiodism, and the amount of experimental evidence for this phenomenon is considerable. For example, some species of birds' breeding can be induced even in midwinter simply by increasing day length artificially (Wolfson 1964). Other examples of photoperiodism occur in plants. A short-day plant flowers when the day is less than a certain critical length. A long-day plant flowers after a certain critical day length is exceeded. In both cases the critical day length differs from species to species. Plants which flower after a period of vegetative growth, regardless of photoperiod, are known as day-neutral plants. Breeding seasons in animals such as birds have evolved to occupy the part of the year in which offspring have the greatest chances of survival. Before the breeding season begins, food reserves must be built up to support the energy cost of reproduction, and to provide for young birds both when they are in the nest and after fledging. Thus many temperate-zone birds use the increasing day lengths in spring as a cue to begin the nesting cycle, because this is a point when adequate food resources will be assured. The adaptive significance at photoperiodism in plants is also clear. Short-day plants that flower in spring in the temperate zone are adapted to maximizing seedling growth during the growing season. Long-day plants are adapted for situations that require fertilization by insects, or a long period of seed ripening. Short-day plants that flower in the autumn in the temperate zone are able to build up food reserves over the growing season and over winter as seeds. Day-neutral plants have an evolutionary advantage when the connection between the favourable period for reproduction and day length is much less certain. For example, desert annuals germinate, flower and seed whenever suitable rainfall occurs, regardless of the day length. The breeding season of some plants can be delayed to extraordinary lengths. Bamboos are perennial grasses that remain in a vegetative state for many years and then suddenly flower, fruit and die (Evans 1976). Every bamboo of the species Chusquea abietifolio on the island of Jamaica flowered, set seed and died during 1884. The next generation of bamboo flowered and died between 1916 and 1918, which suggests a vegetative cycle of about 31 years. The climatic trigger for this flowering cycle is not yet known, but the adaptive significance is clear. The simultaneous production of masses of bamboo seeds (in some cases lying 12 to 15 centimetres deep on the ground) is more than all the seed-eating animals can cope with at the time, so that some seeds escape being eaten and grow up to form the next generation (Evans 1976). The second reason light is important to organisms is that it is essential for photosynthesis. This is the process by which plants use energy from the sun to convert carbon from soil or water into organic material for growth. The rate of photosynthesis in a plant can be measured by calculating the rate of its uptake of carbon. There is a wide range of photosynthetic responses of plants to variations in light intensity. Some plants reach maximal photosynthesis at one-quarter full sunlight, and others, like sugarcane, never reach a maximum, but continue to increase photosynthesis rate as light intensity rises. Plants in general can be divided into two groups: shade-tolerant species and shade-intolerant species. This classification is commonly used in forestry and horticulture. Shade-tolerant plants have lower photosynthetic rates and hence have lower growth rates than those of shade-intolerant species. Plant species become adapted to living in a certain kind of habitat, and in the process evolve a series of characteristics that prevent them from occupying other habitats. Grime (1966) suggests that light may be one of the major components directing these adaptations. For example, eastern hemlock seedlings are shade-tolerant. They can survive in the forest understory under very low light levels because they have a low photosynthetic rate.", "hypothesis": "There is plenty of scientific evidence to support photoperiodism.", "gold_label": "entailment"}
{"uid": "id_102", "premise": "The effects of light on plant and animal species Light is important to organisms for two different reasons. Firstly it is used as a cue for the timing, of daily and seasonal rhythms in both plants and animals, and secondly it is used to assist growth in plants. Breeding in most organisms occurs during a part of the year only, and so a reliable cue is needed to trigger breeding behaviour. Day length is an excellent cue, because it provides a perfectly predictable pattern of change within the year. In the temperate zone in spring, temperatures fluctuate greatly from day to day, but day length increases steadily by a predictable amount. The seasonal impact of day length on physiological responses is called photoperiodism, and the amount of experimental evidence for this phenomenon is considerable. For example, some species of birds' breeding can be induced even in midwinter simply by increasing day length artificially (Wolfson 1964). Other examples of photoperiodism occur in plants. A short-day plant flowers when the day is less than a certain critical length. A long-day plant flowers after a certain critical day length is exceeded. In both cases the critical day length differs from species to species. Plants which flower after a period of vegetative growth, regardless of photoperiod, are known as day-neutral plants. Breeding seasons in animals such as birds have evolved to occupy the part of the year in which offspring have the greatest chances of survival. Before the breeding season begins, food reserves must be built up to support the energy cost of reproduction, and to provide for young birds both when they are in the nest and after fledging. Thus many temperate-zone birds use the increasing day lengths in spring as a cue to begin the nesting cycle, because this is a point when adequate food resources will be assured. The adaptive significance at photoperiodism in plants is also clear. Short-day plants that flower in spring in the temperate zone are adapted to maximizing seedling growth during the growing season. Long-day plants are adapted for situations that require fertilization by insects, or a long period of seed ripening. Short-day plants that flower in the autumn in the temperate zone are able to build up food reserves over the growing season and over winter as seeds. Day-neutral plants have an evolutionary advantage when the connection between the favourable period for reproduction and day length is much less certain. For example, desert annuals germinate, flower and seed whenever suitable rainfall occurs, regardless of the day length. The breeding season of some plants can be delayed to extraordinary lengths. Bamboos are perennial grasses that remain in a vegetative state for many years and then suddenly flower, fruit and die (Evans 1976). Every bamboo of the species Chusquea abietifolio on the island of Jamaica flowered, set seed and died during 1884. The next generation of bamboo flowered and died between 1916 and 1918, which suggests a vegetative cycle of about 31 years. The climatic trigger for this flowering cycle is not yet known, but the adaptive significance is clear. The simultaneous production of masses of bamboo seeds (in some cases lying 12 to 15 centimetres deep on the ground) is more than all the seed-eating animals can cope with at the time, so that some seeds escape being eaten and grow up to form the next generation (Evans 1976). The second reason light is important to organisms is that it is essential for photosynthesis. This is the process by which plants use energy from the sun to convert carbon from soil or water into organic material for growth. The rate of photosynthesis in a plant can be measured by calculating the rate of its uptake of carbon. There is a wide range of photosynthetic responses of plants to variations in light intensity. Some plants reach maximal photosynthesis at one-quarter full sunlight, and others, like sugarcane, never reach a maximum, but continue to increase photosynthesis rate as light intensity rises. Plants in general can be divided into two groups: shade-tolerant species and shade-intolerant species. This classification is commonly used in forestry and horticulture. Shade-tolerant plants have lower photosynthetic rates and hence have lower growth rates than those of shade-intolerant species. Plant species become adapted to living in a certain kind of habitat, and in the process evolve a series of characteristics that prevent them from occupying other habitats. Grime (1966) suggests that light may be one of the major components directing these adaptations. For example, eastern hemlock seedlings are shade-tolerant. They can survive in the forest understory under very low light levels because they have a low photosynthetic rate.", "hypothesis": "Bamboos flower several times during their life cycle.", "gold_label": "contradiction"}
{"uid": "id_103", "premise": "The effects of smoking have been known for a very long time. The harmful and poisonous chemicals inside tobacco all have negative effects. If an individual smokes long-term they are more likely to suffer from the following: cancer, heart disease, blockage of vessels and so on. Since the 1st of July 2007, the UK government brought out new legislation which prohibited individuals from smoking in public places such as clubs, bars, pubs and restaurants. Many organisations have now incorporated a no smoking policy within staff and customer areas. In order to advertise this policy, posters and pamphlets have been specifically put in staff canteens and customer waiting rooms. Many individuals have put forward their support, either by not smoking in these buildings, or by quitting smoking all together. However, a minority feel that this is an erosion of their freedom of choice.", "hypothesis": "Due to the legislation enforced by the government many organisations now have a no smoking policy", "gold_label": "entailment"}
{"uid": "id_104", "premise": "The effects of smoking have been known for a very long time. The harmful and poisonous chemicals inside tobacco all have negative effects. If an individual smokes long-term they are more likely to suffer from the following: cancer, heart disease, blockage of vessels and so on. Since the 1st of July 2007, the UK government brought out new legislation which prohibited individuals from smoking in public places such as clubs, bars, pubs and restaurants. Many organisations have now incorporated a no smoking policy within staff and customer areas. In order to advertise this policy, posters and pamphlets have been specifically put in staff canteens and customer waiting rooms. Many individuals have put forward their support, either by not smoking in these buildings, or by quitting smoking all together. However, a minority feel that this is an erosion of their freedom of choice.", "hypothesis": "If an individual was to smoke for at least 10 years, they are more likely to suffer from cancer, heart disease, blockage of vessels and so on", "gold_label": "neutral"}
{"uid": "id_105", "premise": "The effects of smoking have been known for a very long time. The harmful and poisonous chemicals inside tobacco all have negative effects. If an individual smokes long-term they are more likely to suffer from the following: cancer, heart disease, blockage of vessels and so on. Since the 1st of July 2007, the UK government brought out new legislation which prohibited individuals from smoking in public places such as clubs, bars, pubs and restaurants. Many organisations have now incorporated a no smoking policy within staff and customer areas. In order to advertise this policy, posters and pamphlets have been specifically put in staff canteens and customer waiting rooms. Many individuals have put forward their support, either by not smoking in these buildings, or by quitting smoking all together. However, a minority feel that this is an erosion of their freedom of choice.", "hypothesis": "All individuals seem to be supporting the no smoking policy", "gold_label": "contradiction"}
{"uid": "id_106", "premise": "The effects of smoking have been known for a very long time. The harmful and poisonous chemicals inside tobacco all have negative effects. If an individual smokes long-term they are more likely to suffer from the following: cancer, heart disease, blockage of vessels and so on. Since the 1st of July 2007, the UK government brought out new legislation which prohibited individuals from smoking in public places such as clubs, bars, pubs and restaurants. Many organisations have now incorporated a no smoking policy within staff and customer areas. In order to advertise this policy, posters and pamphlets have been specifically put in staff canteens and customer waiting rooms. Many individuals have put forward their support, either by not smoking in these buildings, or by quitting smoking all together. However, a minority feel that this is an erosion of their freedom of choice.", "hypothesis": "Due to the enforcement of the no smoking legislation, it will be up to the organisations to comply by the rules", "gold_label": "neutral"}
{"uid": "id_107", "premise": "The effects of spaceflight on astronauts have been an important area of study since the start of manned spaceflight. The effects of weightlessness on the body are believed to be the key problem astronauts face in medium to long term space missions. Short term weightlessness can lead to motion sickness, lethargy and nausea. Long term weightlessness may lead to the loss of bone and muscle mass, disrupted vision and weakened immune system. More research is necessary to limit the effects of weightlessness on astronauts if manned space flight is to continue.", "hypothesis": "Motion sickness is a long term effect of weightlessnes", "gold_label": "contradiction"}
{"uid": "id_108", "premise": "The effects of spaceflight on astronauts have been an important area of study since the start of manned spaceflight. The effects of weightlessness on the body are believed to be the key problem astronauts face in medium to long term space missions. Short term weightlessness can lead to motion sickness, lethargy and nausea. Long term weightlessness may lead to the loss of bone and muscle mass, disrupted vision and weakened immune system. More research is necessary to limit the effects of weightlessness on astronauts if manned space flight is to continue.", "hypothesis": "Nausea is a long term effect of weightlessnes", "gold_label": "contradiction"}
{"uid": "id_109", "premise": "The effects of spaceflight on astronauts have been an important area of study since the start of manned spaceflight. The effects of weightlessness on the body are believed to be the key problem astronauts face in medium to long term space missions. Short term weightlessness can lead to motion sickness, lethargy and nausea. Long term weightlessness may lead to the loss of bone and muscle mass, disrupted vision and weakened immune system. More research is necessary to limit the effects of weightlessness on astronauts if manned space flight is to continue.", "hypothesis": "Disrupted vision is a long term effect of weightlessnes", "gold_label": "entailment"}
{"uid": "id_110", "premise": "The era of mass media is giving way to one of personal and participatory media. Technology has freed people from having to passively consume mass media content. They are beginning to value their own opinions and offer them online alongside those of the supposed experts. They post online ratings for their favourite restaurant, and they contribute entries to collaborative sites offering advice and answers to questions posed on every imagi- nable subject. They are quickly realizing that all too often the views of a rank amateur are as or even more interesting than those of the experts. It is only the beginning of a revolution that will encircle the globe and affect most people as access to the internet becomes even more widespread.", "hypothesis": "The passage presents what can be described as a counter argument or at least an alternative perspective.", "gold_label": "contradiction"}
{"uid": "id_111", "premise": "The era of mass media is giving way to one of personal and participatory media. Technology has freed people from having to passively consume mass media content. They are beginning to value their own opinions and offer them online alongside those of the supposed experts. They post online ratings for their favourite restaurant, and they contribute entries to collaborative sites offering advice and answers to questions posed on every imagi- nable subject. They are quickly realizing that all too often the views of a rank amateur are as or even more interesting than those of the experts. It is only the beginning of a revolution that will encircle the globe and affect most people as access to the internet becomes even more widespread.", "hypothesis": "The subject of how the large traditional media corporations will respond to the challenge of the internet is touched upon in the passage.", "gold_label": "contradiction"}
{"uid": "id_112", "premise": "The era of mass media is giving way to one of personal and participatory media. Technology has freed people from having to passively consume mass media content. They are beginning to value their own opinions and offer them online alongside those of the supposed experts. They post online ratings for their favourite restaurant, and they contribute entries to collaborative sites offering advice and answers to questions posed on every imagi- nable subject. They are quickly realizing that all too often the views of a rank amateur are as or even more interesting than those of the experts. It is only the beginning of a revolution that will encircle the globe and affect most people as access to the internet becomes even more widespread.", "hypothesis": "Not everything posted on the internet is correct and sometimes peoples contributions are misleading.", "gold_label": "neutral"}
{"uid": "id_113", "premise": "The era of mass media is giving way to one of personal and participatory media. Technology has freed people from having to passively consume mass media content. They are beginning to value their own opinions and offer them online alongside those of the supposed experts. They post online ratings for their favourite restaurant, and they contribute entries to collaborative sites offering advice and answers to questions posed on every imagi- nable subject. They are quickly realizing that all too often the views of a rank amateur are as or even more interesting than those of the experts. It is only the beginning of a revolution that will encircle the globe and affect most people as access to the internet becomes even more widespread.", "hypothesis": "The penultimate sentence of the passage illustrates the sort of things that people post online.", "gold_label": "contradiction"}
{"uid": "id_114", "premise": "The era of mass media is giving way to one of personal and participatory media. Technology has freed people from having to passively consume mass media content. They are beginning to value their own opinions and offer them online alongside those of the supposed experts. They post online ratings for their favourite restaurant, and they contribute entries to collaborative sites offering advice and answers to questions posed on every imagi- nable subject. They are quickly realizing that all too often the views of a rank amateur are as or even more interesting than those of the experts. It is only the beginning of a revolution that will encircle the globe and affect most people as access to the internet becomes even more widespread.", "hypothesis": "When the passage was written there was no universal access to the internet.", "gold_label": "entailment"}
{"uid": "id_115", "premise": "The estimated cost to widen both sides of 240 miles of the worlds busiest motorway has been priced at a figure higher than the annual gross domestic product (GDP) of one quarter of the worlds nations. It is a major construction project but with the same sum of money many of the worlds nations fund their entire annual government expenditure, including road building. The rate of inflation for raw materials and therefore for construction is running many times higher than general inflation and given this and the fact that such projects have a record of overrunning their estimates there must exist a real possibility that the scheme will cost even more than the estimate. Construction work has not yet started but the pre-construction phase has begun even if the decision to proceed with the project has still to be made.", "hypothesis": "The sum of one quarter of the worlds nations GDP is less than the estimated cost to widen both sides of a length of the worlds busiest motorway.", "gold_label": "contradiction"}
{"uid": "id_116", "premise": "The estimated cost to widen both sides of 240 miles of the worlds busiest motorway has been priced at a figure higher than the annual gross domestic product (GDP) of one quarter of the worlds nations. It is a major construction project but with the same sum of money many of the worlds nations fund their entire annual government expenditure, including road building. The rate of inflation for raw materials and therefore for construction is running many times higher than general inflation and given this and the fact that such projects have a record of overrunning their estimates there must exist a real possibility that the scheme will cost even more than the estimate. Construction work has not yet started but the pre-construction phase has begun even if the decision to proceed with the project has still to be made.", "hypothesis": "An estimate is not a commitment to spend.", "gold_label": "entailment"}
{"uid": "id_117", "premise": "The estimated cost to widen both sides of 240 miles of the worlds busiest motorway has been priced at a figure higher than the annual gross domestic product (GDP) of one quarter of the worlds nations. It is a major construction project but with the same sum of money many of the worlds nations fund their entire annual government expenditure, including road building. The rate of inflation for raw materials and therefore for construction is running many times higher than general inflation and given this and the fact that such projects have a record of overrunning their estimates there must exist a real possibility that the scheme will cost even more than the estimate. Construction work has not yet started but the pre-construction phase has begun even if the decision to proceed with the project has still to be made.", "hypothesis": "The project involves 480 miles of road building.", "gold_label": "entailment"}
{"uid": "id_118", "premise": "The fashion industry is one of the most profitable sectors of the economy. An example of this can be seen in the reported annual profit of the Arcadia Group. The Group, which owns several high-street chains such as Topshop and Miss Selfridge, reported an annual profit of one hundred and eight million pounds last year. Similar figures have also been reported by leading fashion labels Zara and Urban Outfitters. In this way, the fashion industry continues to grow despite the current economic climate. A key aspect of this is that the reported figures are from high-street companies, which promise up-to-date fashion at prices much more widely available than those of designers.", "hypothesis": "Fashion industry is the most profitable sector of the economy.", "gold_label": "neutral"}
{"uid": "id_119", "premise": "The fashion industry is one of the most profitable sectors of the economy. An example of this can be seen in the reported annual profit of the Arcadia Group. The Group, which owns several high-street chains such as Topshop and Miss Selfridge, reported an annual profit of one hundred and eight million pounds last year. Similar figures have also been reported by leading fashion labels Zara and Urban Outfitters. In this way, the fashion industry continues to grow despite the current economic climate. A key aspect of this is that the reported figures are from high-street companies, which promise up-to-date fashion at prices much more widely available than those of designers.", "hypothesis": "High-street fashion provides a higher standard of products.", "gold_label": "neutral"}
{"uid": "id_120", "premise": "The fashion industry is one of the most profitable sectors of the economy. An example of this can be seen in the reported annual profit of the Arcadia Group. The Group, which owns several high-street chains such as Topshop and Miss Selfridge, reported an annual profit of one hundred and eight million pounds last year. Similar figures have also been reported by leading fashion labels Zara and Urban Outfitters. In this way, the fashion industry continues to grow despite the current economic climate. A key aspect of this is that the reported figures are from high-street companies, which promise up-to-date fashion at prices much more widely available than those of designers.", "hypothesis": "High-street fashion is more financially accessible than designer", "gold_label": "entailment"}
{"uid": "id_121", "premise": "The fashion industry is one of the most profitable sectors of the economy. An example of this can be seen in the reported annual profit of the Arcadia Group. The Group, which owns several high-street chains such as Topshop and Miss Selfridge, reported an annual profit of one hundred and eight million pounds last year. Similar figures have also been reported by leading fashion labels Zara and Urban Outfitters. In this way, the fashion industry continues to grow despite the current economic climate. A key aspect of this is that the reported figures are from high-street companies, which promise up-to-date fashion at prices much more widely available than those of designers.", "hypothesis": "Cheaper fashion labels provide a lower standard of products.", "gold_label": "neutral"}
{"uid": "id_122", "premise": "The first ever low-cost tablet with a three-hour battery which works only with Wi-Fi for accessing the Internet will be a game changer for Indias rural population who have been on the wrong side of the digital divide in the country. Stated Company X, the manufacturers of the tabled on their role in providing access to Internet throughout India.", "hypothesis": "The tablet would not benefit urban population in India as much as the rural population.", "gold_label": "contradiction"}
{"uid": "id_123", "premise": "The first ever low-cost tablet with a three-hour battery which works only with Wi-Fi for accessing the Internet will be a game changer for Indias rural population who have been on the wrong side of the digital divide in the country. Stated Company X, the manufacturers of the tabled on their role in providing access to Internet throughout India.", "hypothesis": "A mere three-hour battery would be grossly insufficient to maximize its benefits.", "gold_label": "contradiction"}
{"uid": "id_124", "premise": "The first ever low-cost tablet with a three-hour battery which works only with Wi-Fi for accessing the Internet will be a game changer for Indias rural population who have been on the wrong side of the digital divide in the country. Stated Company X, the manufacturers of the tabled on their role in providing access to Internet throughout India.", "hypothesis": "Improvement in accessibility to Internet would help education sector the most.", "gold_label": "contradiction"}
{"uid": "id_125", "premise": "The first ever low-cost tablet with a three-hour battery which works only with Wi-Fi for accessing the Internet will be a game changer for Indias rural population who have been on the wrong side of the digital divide in the country. Stated Company X, the manufacturers of the tabled on their role in providing access to Internet throughout India.", "hypothesis": "Wi-Fi connections are already available in rural parts of India.", "gold_label": "entailment"}
{"uid": "id_126", "premise": "The first ever low-cost tablet with a three-hour battery which works only with Wi-Fi for accessing the Internet will be a game changer for Indias rural population who have been on the wrong side of the digital divide in the country. Stated Company X, the manufacturers of the tabled on their role in providing access to Internet throughout India.", "hypothesis": "Other tablets did not have the features such as Wi-Fi connectivity.", "gold_label": "contradiction"}
{"uid": "id_127", "premise": "The first problem with financial statements is that they are in the past; however detailed, they just provide a snap shot of the business at one moment in time. There is also a lack of detail in financial statements, giving little use for the running of a business. Financial statements are provided for legal reasons to meet with accounting regulations and are used largely by city analysts who compute share prices and give advice to shareholders. Accounts often have hidden information and may also be inconsistent it is difficult to compare different companies accounts, despite there being standards, as there is much leeway in these standards.", "hypothesis": "Companies create financial statements as part of their legal obligations.", "gold_label": "entailment"}
{"uid": "id_128", "premise": "The first problem with financial statements is that they are in the past; however detailed, they just provide a snap shot of the business at one moment in time. There is also a lack of detail in financial statements, giving little use for the running of a business. Financial statements are provided for legal reasons to meet with accounting regulations and are used largely by city analysts who compute share prices and give advice to shareholders. Accounts often have hidden information and may also be inconsistent it is difficult to compare different companies accounts, despite there being standards, as there is much leeway in these standards.", "hypothesis": "If account-recording standards were changed, it would be easier to compare the performance of different companies.", "gold_label": "neutral"}
{"uid": "id_129", "premise": "The first problem with financial statements is that they are in the past; however detailed, they just provide a snap shot of the business at one moment in time. There is also a lack of detail in financial statements, giving little use for the running of a business. Financial statements are provided for legal reasons to meet with accounting regulations and are used largely by city analysts who compute share prices and give advice to shareholders. Accounts often have hidden information and may also be inconsistent it is difficult to compare different companies accounts, despite there being standards, as there is much leeway in these standards.", "hypothesis": "Financial statements tell analysts what is going to happen to a business in the future.", "gold_label": "contradiction"}
{"uid": "id_130", "premise": "The first problem with financial statements is that they are in the past; however detailed, they provide just a snap-shot of the business at one moment in time. There is also a lack of detail in financial statements, giving little use in the running of a business. Financial statements are provided for legal reasons to meet with accounting regulations and are used mainly by City analysts who compute share prices and give guidance to shareholders. Accounts often have hidden information and may also be inconsistent; it is difficult to compare different companies accounts, despite there being standards, as there is much leeway in the standards.", "hypothesis": "If account reporting standards were tightened, it would be easier to compare the performance of different companies.", "gold_label": "neutral"}
{"uid": "id_131", "premise": "The first problem with financial statements is that they are in the past; however detailed, they provide just a snap-shot of the business at one moment in time. There is also a lack of detail in financial statements, giving little use in the running of a business. Financial statements are provided for legal reasons to meet with accounting regulations and are used mainly by City analysts who compute share prices and give guidance to shareholders. Accounts often have hidden information and may also be inconsistent; it is difficult to compare different companies accounts, despite there being standards, as there is much leeway in the standards.", "hypothesis": "Companies create financial statements in order to comply with their legal obligations.", "gold_label": "entailment"}
{"uid": "id_132", "premise": "The first problem with financial statements is that they are in the past; however detailed, they provide just a snap-shot of the business at one moment in time. There is also a lack of detail in financial statements, giving little use in the running of a business. Financial statements are provided for legal reasons to meet with accounting regulations and are used mainly by City analysts who compute share prices and give guidance to shareholders. Accounts often have hidden information and may also be inconsistent; it is difficult to compare different companies accounts, despite there being standards, as there is much leeway in the standards.", "hypothesis": "Financial statements are useful for businesses to understand their financial activities.", "gold_label": "contradiction"}
{"uid": "id_133", "premise": "The first salmon farms were in the Atlantic islands but the industry fell into dramatic decline with the value of the farmed fish when the farming method became discredited because of the use of chemicals and concerns over the feed used. Now they are farming cod in the Atlantic isles, only this time they have set rules for fish welfare and are feeding the cod on fish meal produced only from the by-products of fish already caught for human consumption. The enclosure nets in which the fish are grown are cleaned mechanically rather than treated with chemicals to stop them becoming fouled with weed. Cod, unlike salmon, are a gregarious species that naturally shoal and, unlike salmon, they do not need to be treated with insecticide to control fish lice.", "hypothesis": "The cod farmers are taking measures to avoid the mistakes of the salmon farmers.", "gold_label": "entailment"}
{"uid": "id_134", "premise": "The first salmon farms were in the Atlantic islands but the industry fell into dramatic decline with the value of the farmed fish when the farming method became discredited because of the use of chemicals and concerns over the feed used. Now they are farming cod in the Atlantic isles, only this time they have set rules for fish welfare and are feeding the cod on fish meal produced only from the by-products of fish already caught for human consumption. The enclosure nets in which the fish are grown are cleaned mechanically rather than treated with chemicals to stop them becoming fouled with weed. Cod, unlike salmon, are a gregarious species that naturally shoal and, unlike salmon, they do not need to be treated with insecticide to control fish lice.", "hypothesis": "A gregarious species of fish will be happier to swim around a net enclosure with a lot of other fish.", "gold_label": "neutral"}
{"uid": "id_135", "premise": "The first salmon farms were in the Atlantic islands but the industry fell into dramatic decline with the value of the farmed fish when the farming method became discredited because of the use of chemicals and concerns over the feed used. Now they are farming cod in the Atlantic isles, only this time they have set rules for fish welfare and are feeding the cod on fish meal produced only from the by-products of fish already caught for human consumption. The enclosure nets in which the fish are grown are cleaned mechanically rather than treated with chemicals to stop them becoming fouled with weed. Cod, unlike salmon, are a gregarious species that naturally shoal and, unlike salmon, they do not need to be treated with insecticide to control fish lice.", "hypothesis": "Measures are being taken to raise the cod humanely.", "gold_label": "entailment"}
{"uid": "id_136", "premise": "The first time a single German nation existed was in 1871 when Wilhelm the 1st became Emperor and Bismarck Chancellor. The unified Germany became a great economic and military power, and empire, but defeat in the two World Wars led to its break-up in 1945 into East and West Germany. At that time the Berlin Wall was built and served to separate East from West. In 1990 the wall was demolished and Germany was unified once again.", "hypothesis": "The passage suggests two reasons for the break-up of Germany in 1945.", "gold_label": "contradiction"}
{"uid": "id_137", "premise": "The first time a single German nation existed was in 1871 when Wilhelm the 1st became Emperor and Bismarck Chancellor. The unified Germany became a great economic and military power, and empire, but defeat in the two World Wars led to its break-up in 1945 into East and West Germany. At that time the Berlin Wall was built and served to separate East from West. In 1990 the wall was demolished and Germany was unified once again.", "hypothesis": "You can correctly infer from the passage that the Berlin Wall stood for 45 years.", "gold_label": "entailment"}
{"uid": "id_138", "premise": "The first time a single German nation existed was in 1871 when Wilhelm the 1st became Emperor and Bismarck Chancellor. The unified Germany became a great economic and military power, and empire, but defeat in the two World Wars led to its break-up in 1945 into East and West Germany. At that time the Berlin Wall was built and served to separate East from West. In 1990 the wall was demolished and Germany was unified once again.", "hypothesis": "The author may well agree with the statement that a reunified Germany will once again become a great economic and military power.", "gold_label": "neutral"}
{"uid": "id_139", "premise": "The first time a single German nation existed was in 1871 when Wilhelm the 1st became Emperor and Bismarck Chancellor. The unified Germany became a great economic and military power, and empire, but defeat in the two World Wars led to its break-up in 1945 into East and West Germany. At that time the Berlin Wall was built and served to separate East from West. In 1990 the wall was demolished and Germany was unified once again.", "hypothesis": "The Berlin Wall is mentioned in the passage in relation to the countries reunification in 1990.", "gold_label": "entailment"}
{"uid": "id_140", "premise": "The first time a single German nation existed was in 1871 when Wilhelm the 1st became Emperor and Bismarck Chancellor. The unified Germany became a great economic and military power, and empire, but defeat in the two World Wars led to its break-up in 1945 into East and West Germany. At that time the Berlin Wall was built and served to separate East from West. In 1990 the wall was demolished and Germany was unified once again.", "hypothesis": "Germany has been unified as anationon three occasions.", "gold_label": "contradiction"}
{"uid": "id_141", "premise": "The first tranche of sovereign gold bonds that closed on November 20 received an encouraging response despite falling gold prices, suggesting that the scheme may be successful in reducing imports of the metal.", "hypothesis": "The scheme will encourage bulk depositors such as Hindu undivided families and institutions to participate.", "gold_label": "contradiction"}
{"uid": "id_142", "premise": "The first tranche of sovereign gold bonds that closed on November 20 received an encouraging response despite falling gold prices, suggesting that the scheme may be successful in reducing imports of the metal.", "hypothesis": "The positive response to the gold scheme has elicited response from across the country.", "gold_label": "contradiction"}
{"uid": "id_143", "premise": "The first tranche of sovereign gold bonds that closed on November 20 received an encouraging response despite falling gold prices, suggesting that the scheme may be successful in reducing imports of the metal.", "hypothesis": "Investment in gold is considered safe by the people.", "gold_label": "entailment"}
{"uid": "id_144", "premise": "The first tranche of sovereign gold bonds that closed on November 20 received an encouraging response despite falling gold prices, suggesting that the scheme may be successful in reducing imports of the metal.", "hypothesis": "Country imports of gold will fall.", "gold_label": "contradiction"}
{"uid": "id_145", "premise": "The first tranche of sovereign gold bonds that closed on November 20 received an encouraging response despite falling gold prices, suggesting that the scheme may be successful in reducing imports of the metal.", "hypothesis": "Investment in gold is considered to give good returns.", "gold_label": "entailment"}
{"uid": "id_146", "premise": "The following extract is taken from Freuds book Dream Psychology: Psychoanalysis for Beginners In what we may term pre-scientific days, people were in no uncertainty about the interpretation of dreams. When they were recalled after awakening they were regarded as either the friendly or hostile manifestation of some higher powers, demoniacal and divine. With the rise of scientific thought the whole of this expressive mythology was transferred to psychology; today there is but a small minority among educated persons who doubt that the dream is the dreamers own psychical act. But since the downfall of the mythological hypothesis an interpretation of the dream has been wanting. The conditions of its origin; its relationship to our psychical life when we are awake; its independence of disturbances which, during the state of sleep, seem to compel notice; its many peculiarities repugnant to our waking thought; the incongruence between its images and the feelings they engender; then the dreams evanescence, the way in which, on awakening, our thoughts thrust it aside as something bizarre, and our reminiscences mutilating or rejecting itall these and many other problems have for many hundred years demanded answers which up till now could never have been satisfactory. Before all there is the question as to the meaning of the dream, a question that is in itself double-sided. There is, firstly, the psychical significance of the dream, its position with regard to the psychical processes, as to a possible biological function; secondly, has the dream a meaningcan sense be made of each single dream as of other mental syntheses?", "hypothesis": "Human society has never had a hypothesis to explain dreams that has satisfied them.", "gold_label": "contradiction"}
{"uid": "id_147", "premise": "The following extract is taken from Freuds book Dream Psychology: Psychoanalysis for Beginners In what we may term pre-scientific days, people were in no uncertainty about the interpretation of dreams. When they were recalled after awakening they were regarded as either the friendly or hostile manifestation of some higher powers, demoniacal and divine. With the rise of scientific thought the whole of this expressive mythology was transferred to psychology; today there is but a small minority among educated persons who doubt that the dream is the dreamers own psychical act. But since the downfall of the mythological hypothesis an interpretation of the dream has been wanting. The conditions of its origin; its relationship to our psychical life when we are awake; its independence of disturbances which, during the state of sleep, seem to compel notice; its many peculiarities repugnant to our waking thought; the incongruence between its images and the feelings they engender; then the dreams evanescence, the way in which, on awakening, our thoughts thrust it aside as something bizarre, and our reminiscences mutilating or rejecting itall these and many other problems have for many hundred years demanded answers which up till now could never have been satisfactory. Before all there is the question as to the meaning of the dream, a question that is in itself double-sided. There is, firstly, the psychical significance of the dream, its position with regard to the psychical processes, as to a possible biological function; secondly, has the dream a meaningcan sense be made of each single dream as of other mental syntheses?", "hypothesis": "The origin of the dream has been scientifically sourced.", "gold_label": "contradiction"}
{"uid": "id_148", "premise": "The following extract is taken from Freuds book Dream Psychology: Psychoanalysis for Beginners In what we may term pre-scientific days, people were in no uncertainty about the interpretation of dreams. When they were recalled after awakening they were regarded as either the friendly or hostile manifestation of some higher powers, demoniacal and divine. With the rise of scientific thought the whole of this expressive mythology was transferred to psychology; today there is but a small minority among educated persons who doubt that the dream is the dreamers own psychical act. But since the downfall of the mythological hypothesis an interpretation of the dream has been wanting. The conditions of its origin; its relationship to our psychical life when we are awake; its independence of disturbances which, during the state of sleep, seem to compel notice; its many peculiarities repugnant to our waking thought; the incongruence between its images and the feelings they engender; then the dreams evanescence, the way in which, on awakening, our thoughts thrust it aside as something bizarre, and our reminiscences mutilating or rejecting itall these and many other problems have for many hundred years demanded answers which up till now could never have been satisfactory. Before all there is the question as to the meaning of the dream, a question that is in itself double-sided. There is, firstly, the psychical significance of the dream, its position with regard to the psychical processes, as to a possible biological function; secondly, has the dream a meaningcan sense be made of each single dream as of other mental syntheses?", "hypothesis": "A memory of a dream may be untrustworthy.", "gold_label": "entailment"}
{"uid": "id_149", "premise": "The following extract is taken from Freuds book Dream Psychology: Psychoanalysis for Beginners In what we may term pre-scientific days, people were in no uncertainty about the interpretation of dreams. When they were recalled after awakening they were regarded as either the friendly or hostile manifestation of some higher powers, demoniacal and divine. With the rise of scientific thought the whole of this expressive mythology was transferred to psychology; today there is but a small minority among educated persons who doubt that the dream is the dreamers own psychical act. But since the downfall of the mythological hypothesis an interpretation of the dream has been wanting. The conditions of its origin; its relationship to our psychical life when we are awake; its independence of disturbances which, during the state of sleep, seem to compel notice; its many peculiarities repugnant to our waking thought; the incongruence between its images and the feelings they engender; then the dreams evanescence, the way in which, on awakening, our thoughts thrust it aside as something bizarre, and our reminiscences mutilating or rejecting itall these and many other problems have for many hundred years demanded answers which up till now could never have been satisfactory. Before all there is the question as to the meaning of the dream, a question that is in itself double-sided. There is, firstly, the psychical significance of the dream, its position with regard to the psychical processes, as to a possible biological function; secondly, has the dream a meaningcan sense be made of each single dream as of other mental syntheses?", "hypothesis": "The passage wonders about the significance of individual dreams.", "gold_label": "entailment"}
{"uid": "id_150", "premise": "The following extract is taken from Freuds book Dream Psychology: Psychoanalysis for Beginners In what we may term pre-scientific days, people were in no uncertainty about the interpretation of dreams. When they were recalled after awakening they were regarded as either the friendly or hostile manifestation of some higher powers, demoniacal and divine. With the rise of scientific thought the whole of this expressive mythology was transferred to psychology; today there is but a small minority among educated persons who doubt that the dream is the dreamers own psychical act. But since the downfall of the mythological hypothesis an interpretation of the dream has been wanting. The conditions of its origin; its relationship to our psychical life when we are awake; its independence of disturbances which, during the state of sleep, seem to compel notice; its many peculiarities repugnant to our waking thought; the incongruence between its images and the feelings they engender; then the dreams evanescence, the way in which, on awakening, our thoughts thrust it aside as something bizarre, and our reminiscences mutilating or rejecting itall these and many other problems have for many hundred years demanded answers which up till now could never have been satisfactory. Before all there is the question as to the meaning of the dream, a question that is in itself double-sided. There is, firstly, the psychical significance of the dream, its position with regard to the psychical processes, as to a possible biological function; secondly, has the dream a meaningcan sense be made of each single dream as of other mental syntheses?", "hypothesis": "There is a definite link between the waking and dreaming self.", "gold_label": "contradiction"}
{"uid": "id_151", "premise": "The following extract is taken from Freuds book Dream Psychology: Psychoanalysis for Beginners In what we may term pre-scientific days, people were in no uncertainty about the interpretation of dreams. When they were recalled after awakening they were regarded as either the friendly or hostile manifestation of some higher powers, demoniacal and divine. With the rise of scientific thought the whole of this expressive mythology was transferred to psychology; today there is but a small minority among educated persons who doubt that the dream is the dreamers own psychical act. But since the downfall of the mythological hypothesis an interpretation of the dream has been wanting. The conditions of its origin; its relationship to our psychical life when we are awake; its independence of disturbances which, during the state of sleep, seem to compel notice; its many peculiarities repugnant to our waking thought; the incongruence between its images and the feelings they engender; then the dreams evanescence, the way in which, on awakening, our thoughts thrust it aside as something bizarre, and our reminiscences mutilating or rejecting itall these and many other problems have for many hundred years demanded answers which up till now could never have been satisfactory. Before all there is the question as to the meaning of the dream, a question that is in itself double-sided. There is, firstly, the psychical significance of the dream, its position with regard to the psychical processes, as to a possible biological function; secondly, has the dream a meaningcan sense be made of each single dream as of other mental syntheses?", "hypothesis": "Dreams used to be regarded as having a potentially religious quality.", "gold_label": "entailment"}
{"uid": "id_152", "premise": "The following is taken from a book about Norway published in 1909: In a country like Norway, with its vast forests and waste moorlands, it is only natural to find a considerable variety of animals and birds. Some of these are peculiar to Scandinavia. Some, though only occasionally found in the British Isles, are not rare in Norway; whilst others (more especially among the birds) are equally common in both countries. There was a time when the people of England lived in a state of fear and dread of the ravages of wolves and bears, and the Norwegians of the country districts even now have to guard their flocks and herds from these destroyers. Except in the forest tracts of the Far North, however, bears are not numerous, but in some parts, even in the South, they are sufficiently so to be a nuisance, and are ruthlessly hunted down by the farmers. As far as wolves are concerned civilisation is, fortunately, driving them farther afield each year, and only in themost out-of-the-way parts are they ever encountered nowadays. Stories of packs of hungry wolves following in the wake of a sleigh are still told to the children in Norway, but they relate to bygone timeshalf a century or more ago, and such wild excitements no longer enter into the Norsemens lives.", "hypothesis": "The variety of birds and animals to be found in Norway is unique to that country.", "gold_label": "contradiction"}
{"uid": "id_153", "premise": "The following is taken from a book about Norway published in 1909: In a country like Norway, with its vast forests and waste moorlands, it is only natural to find a considerable variety of animals and birds. Some of these are peculiar to Scandinavia. Some, though only occasionally found in the British Isles, are not rare in Norway; whilst others (more especially among the birds) are equally common in both countries. There was a time when the people of England lived in a state of fear and dread of the ravages of wolves and bears, and the Norwegians of the country districts even now have to guard their flocks and herds from these destroyers. Except in the forest tracts of the Far North, however, bears are not numerous, but in some parts, even in the South, they are sufficiently so to be a nuisance, and are ruthlessly hunted down by the farmers. As far as wolves are concerned civilisation is, fortunately, driving them farther afield each year, and only in themost out-of-the-way parts are they ever encountered nowadays. Stories of packs of hungry wolves following in the wake of a sleigh are still told to the children in Norway, but they relate to bygone timeshalf a century or more ago, and such wild excitements no longer enter into the Norsemens lives.", "hypothesis": "England and Norway have similar geographical features.", "gold_label": "contradiction"}
{"uid": "id_154", "premise": "The following is taken from a book about Norway published in 1909: In a country like Norway, with its vast forests and waste moorlands, it is only natural to find a considerable variety of animals and birds. Some of these are peculiar to Scandinavia. Some, though only occasionally found in the British Isles, are not rare in Norway; whilst others (more especially among the birds) are equally common in both countries. There was a time when the people of England lived in a state of fear and dread of the ravages of wolves and bears, and the Norwegians of the country districts even now have to guard their flocks and herds from these destroyers. Except in the forest tracts of the Far North, however, bears are not numerous, but in some parts, even in the South, they are sufficiently so to be a nuisance, and are ruthlessly hunted down by the farmers. As far as wolves are concerned civilisation is, fortunately, driving them farther afield each year, and only in themost out-of-the-way parts are they ever encountered nowadays. Stories of packs of hungry wolves following in the wake of a sleigh are still told to the children in Norway, but they relate to bygone timeshalf a century or more ago, and such wild excitements no longer enter into the Norsemens lives.", "hypothesis": "By having forests, a country is more likely to have a variety of birds and animals.", "gold_label": "entailment"}
{"uid": "id_155", "premise": "The following is taken from a book about Norway published in 1909: In a country like Norway, with its vast forests and waste moorlands, it is only natural to find a considerable variety of animals and birds. Some of these are peculiar to Scandinavia. Some, though only occasionally found in the British Isles, are not rare in Norway; whilst others (more especially among the birds) are equally common in both countries. There was a time when the people of England lived in a state of fear and dread of the ravages of wolves and bears, and the Norwegians of the country districts even now have to guard their flocks and herds from these destroyers. Except in the forest tracts of the Far North, however, bears are not numerous, but in some parts, even in the South, they are sufficiently so to be a nuisance, and are ruthlessly hunted down by the farmers. As far as wolves are concerned civilisation is, fortunately, driving them farther afield each year, and only in themost out-of-the-way parts are they ever encountered nowadays. Stories of packs of hungry wolves following in the wake of a sleigh are still told to the children in Norway, but they relate to bygone timeshalf a century or more ago, and such wild excitements no longer enter into the Norsemens lives.", "hypothesis": "The variety of birds and animals to be found in Norway is common to all European countries.", "gold_label": "contradiction"}
{"uid": "id_156", "premise": "The following passage is found in a book on nature published in 1899: Five women out of every ten who walk the streets of Chicago and other Illinois cities, says a prominent journal, by wearing dead birds upon their hats proclaim themselves as lawbreakers. For the first time in the history of Illinois laws it has been made an offence punishable by fine and imprisonment, or both, to have in possession any dead, harmless bird except game birds, which may be possessed in their proper season. The wearing of a tern, or a gull, a woodpecker, or a jay is an offence against the laws majesty, and any policeman with a mind rigidly bent upon enforcing the law could round up, without a written warrant, a wagon load of the offenders any hour in the day, and carry them off to the lockup. What moral suasion cannot do, a crusade of this sort undoubtedly would. Thanks to the personal influence of the Princess of Wales, the osprey plume, so long a feature of the uniforms of a number of the cavalry regiments of the British army, has been abolished. After Dec. 31, 1899, the osprey plume, by order of Field Marshal Lord Wolseley, is to be replaced by one of ostrich feathers. It was the wearing of these plumes by the officers of all the hussar and rifle regiments, as well as of the Royal Horse Artillery, which so sadly interfered with the crusade inaugurated by the Princess against the use of osprey plumes. The fact that these plumes, to be of any marketable value, have to be torn from the living bird during the nesting season induced the Queen, the Princess of Wales, and other ladies of the royal family to set their faces against the use of both the osprey plume and the aigrette as articles of fashionable wear.", "hypothesis": "Games birds could be possessed by citizens of Illinois all year round.", "gold_label": "contradiction"}
{"uid": "id_157", "premise": "The following passage provides information regarding the most popular type of foods in the United Kingdom. Such information has been compiled by the UK Foods Standards Agency since 1990 as part of an on-going project to encourage consumers to purchase healthier products, such as fruit and vegetables, whole grain foods and foods low in saturated fat. Currently, the most popular types of food in the UK are those which are easy to prepare. Items requiring time consuming preparation continue to suffer comparatively lower sales rates. In this way, the Foods Standards Agency has found that pack items, those containing ready-measured baking ingredients, are more popular than buying fresh ingredients in bulk. Similarly, ready baked items, such as bread and biscuits, continue to sell well.", "hypothesis": "Since 1990, the UK Foods Standards Agency has discouraged the purchase of pack-items", "gold_label": "neutral"}
{"uid": "id_158", "premise": "The following passage provides information regarding the most popular type of foods in the United Kingdom. Such information has been compiled by the UK Foods Standards Agency since 1990 as part of an on-going project to encourage consumers to purchase healthier products, such as fruit and vegetables, whole grain foods and foods low in saturated fat. Currently, the most popular types of food in the UK are those which are easy to prepare. Items requiring time consuming preparation continue to suffer comparatively lower sales rates. In this way, the Foods Standards Agency has found that pack items, those containing ready-measured baking ingredients, are more popular than buying fresh ingredients in bulk. Similarly, ready baked items, such as bread and biscuits, continue to sell well.", "hypothesis": "Since 1990, the UK Foods Standards Agency has encouraged consumers to purchase items with no fat.", "gold_label": "contradiction"}
{"uid": "id_159", "premise": "The following passage provides information regarding the most popular type of foods in the United Kingdom. Such information has been compiled by the UK Foods Standards Agency since 1990 as part of an on-going project to encourage consumers to purchase healthier products, such as fruit and vegetables, whole grain foods and foods low in saturated fat. Currently, the most popular types of food in the UK are those which are easy to prepare. Items requiring time consuming preparation continue to suffer comparatively lower sales rates. In this way, the Foods Standards Agency has found that pack items, those containing ready-measured baking ingredients, are more popular than buying fresh ingredients in bulk. Similarly, ready baked items, such as bread and biscuits, continue to sell well.", "hypothesis": "Since 1990, the UK Foods Standards Agency has encouraged consumers to purchase items that are easy to prepare.", "gold_label": "neutral"}
{"uid": "id_160", "premise": "The following passage provides information regarding the most popular type of foods in the United Kingdom. Such information has been compiled by the UK Foods Standards Agency since 1990 as part of an on-going project to encourage consumers to purchase healthier products, such as fruit and vegetables, whole grain foods and foods low in saturated fat. Currently, the most popular types of food in the UK are those which are easy to prepare. Items requiring time consuming preparation continue to suffer comparatively lower sales rates. In this way, the Foods Standards Agency has found that pack items, those containing ready-measured baking ingredients, are more popular than buying fresh ingredients in bulk. Similarly, ready baked items, such as bread and biscuits, continue to sell well.", "hypothesis": "Since 1990, the UK Foods Standards Agency has encouraged consumers to purchase items such as fruit.", "gold_label": "entailment"}
{"uid": "id_161", "premise": "The frequency of MRSA bemg given as the cause of death on death certificates has been increasng significantly for several years. MRSA 1s an infection-causing bacterium that has developed a resistance to penicillin and many other antibiotics. MRSA infections represent a particular danger for hospital patients with weakened immune systems or open wounds. Scientific trials are testing whether MRSA develops resistance after exposure to new drugs. A research breakthrough would herald a cure for the MRSA threat.", "hypothesis": "MRSA can prove fatal.", "gold_label": "entailment"}
{"uid": "id_162", "premise": "The frequency of MRSA bemg given as the cause of death on death certificates has been increasng significantly for several years. MRSA 1s an infection-causing bacterium that has developed a resistance to penicillin and many other antibiotics. MRSA infections represent a particular danger for hospital patients with weakened immune systems or open wounds. Scientific trials are testing whether MRSA develops resistance after exposure to new drugs. A research breakthrough would herald a cure for the MRSA threat.", "hypothesis": "Further research is bemg conducted to study MRSA.", "gold_label": "entailment"}
{"uid": "id_163", "premise": "The frequency of MRSA bemg given as the cause of death on death certificates has been increasng significantly for several years. MRSA 1s an infection-causing bacterium that has developed a resistance to penicillin and many other antibiotics. MRSA infections represent a particular danger for hospital patients with weakened immune systems or open wounds. Scientific trials are testing whether MRSA develops resistance after exposure to new drugs. A research breakthrough would herald a cure for the MRSA threat.", "hypothesis": "MRSA-related deaths are now more common.", "gold_label": "entailment"}
{"uid": "id_164", "premise": "The frequency of MRSA bemg given as the cause of death on death certificates has been increasng significantly for several years. MRSA 1s an infection-causing bacterium that has developed a resistance to penicillin and many other antibiotics. MRSA infections represent a particular danger for hospital patients with weakened immune systems or open wounds. Scientific trials are testing whether MRSA develops resistance after exposure to new drugs. A research breakthrough would herald a cure for the MRSA threat.", "hypothesis": "MRSA 5s resistant to all antibiotics.", "gold_label": "contradiction"}
{"uid": "id_165", "premise": "The frequency of MRSA bemg given as the cause of death on death certificates has been increasng significantly for several years. MRSA 1s an infection-causing bacterium that has developed a resistance to penicillin and many other antibiotics. MRSA infections represent a particular danger for hospital patients with weakened immune systems or open wounds. Scientific trials are testing whether MRSA develops resistance after exposure to new drugs. A research breakthrough would herald a cure for the MRSA threat.", "hypothesis": "Penicillin is an effective treatment for MRSA.", "gold_label": "contradiction"}
{"uid": "id_166", "premise": "The future never dies? The prospects for humanity and for the world as a whole are somewhere between glorious and dire. It is hard to be much more precise. By glorious I mean that our descendants - all who are born on to this Earth - could live very comfortably and securely, and could continue to do so for as long as the Earth can support life, which should be for a very long time indeed. We should at least be thinking in terms of the next million years. Furthermore, our descendants could continue to enjoy the company of other species - establishing a much better relationship with them than we have now. Other animals need not live in constant fear of us. Many of those fellow species now seem bound to become extinct, but a significant proportion could and should continue to live alongside US. Such a future may seem ideal, and so it is. Yet I do not believe it is fanciful. There is nothing in the physical fabric of the Earth or in our own biology to suggest that this is not possible. Dire means that we human beings could be in deep trouble within the next few centuries, living but also dying in large numbers in political terror and from starvation, while huge numbers of our fellow creatures would simply disappear, leaving only the ones that we find convenient - chickens, cattle - or that we can'tshake off, like flies and mice. I'm taking it to be self-evident that glory is preferable. Our future is not entirely in our own hands because the Earth has its own rules, is part of the solar system and is neither stable nor innately safe. Other planets in the solar system are quite beyond habitation, because their temperature is far too high or too low to be endured, and ours, too, in principle could tip either way. Even relatively unspectacular changes in the atmosphere could do the trick. The core of the Earth is hot, which in many ways is good for living creatures, but every now and again, the molten rock bursts through volcanoes on the surface. Among the biggest volcanic eruptions in recent memory was Mount St Helens, in the USA, which threw out a cubic kilometre of ash - fortunately in an area where very few people live. In 1815, Tambora (in present-day Indonesia) expelled so much ash into the upper atmosphere that climatic effects seriously harmed food production around the world for season after season. Entire civilisations have been destroyed by volcanoes. Yet nothing we have so far experienced shows what volcanoes can really do. Yellowstone National Park in the USA occupies the caldera (the crater formed when a volcano collapses) of an exceedingly ancient volcano of extraordinary magnitude. Modem surveys show that its centre is now rising. Sometime in the next 200 million years, Yellowstone could erupt again, and when it does, the whole world will be transformed. Yellowstone could erupt tomorrow. But there's a very good chance that it will give US another million years, and that surely is enough to be going on with. It seems sensible to assume that this will be the case. The universe at large is dangerous, too: in particular, we share the sky with vast numbers of asteroids, and every now and again, they come into our planet's atmosphere. An asteroid the size of a small island, hitting the Earth at 15,000 kilometres an hour (a relatively modest speed by the standards of heavenly bodies), would strike the ocean bed like a rock in a puddle, send a tidal wave around the world as high as a small mountain and as fast as a jumbo jet, and propel us into an ice age that could last for centuries. There are plans to head off such disasters (including rockets to push approaching asteroids into new trajectories), but in truth it's down to luck. On the other hand, the archaeological and the fossil evidence shows that no truly devastating asteroid has struck since the one that seems to have accounted for the extinction of the dinosaurs 65 million years ago. So again, there seems no immediate reason for despair. The Earth is indeed an uncertain place, in an uncertain universe, but with average luck, it should do us well enough. If the world does become inhospitable in the next few thousand or million years, then it will probably be our own fault. In short, despite the underlying uncertainty, our own future and that of our fellow creatures is very much in our own hands. Given average luck on the geological and the cosmic scale, the difference between glory and disaster will be made, and is being made, by politics. Certain kinds of political systems and strategies would predispose US to long-term survival (and indeed to comfort and security and the pleasure of being alive), while others would take us more and more frenetically towards collapse. The broad point is, though, that we need to look at ourselves - humanity - and at the world in general in a quite new light. Our material problems are fundamentally those of biology. We need to think, and we need our politicians to think, biologically. Do that, and take the ideas seriously, and we are in with a chance. Ignore biology and we and our fellow creatures haven't a hope.", "hypothesis": "If the world becomes uninhabitable, It is most likely to be as a result of a natural disaster.", "gold_label": "contradiction"}
{"uid": "id_167", "premise": "The future never dies? The prospects for humanity and for the world as a whole are somewhere between glorious and dire. It is hard to be much more precise. By glorious I mean that our descendants - all who are born on to this Earth - could live very comfortably and securely, and could continue to do so for as long as the Earth can support life, which should be for a very long time indeed. We should at least be thinking in terms of the next million years. Furthermore, our descendants could continue to enjoy the company of other species - establishing a much better relationship with them than we have now. Other animals need not live in constant fear of us. Many of those fellow species now seem bound to become extinct, but a significant proportion could and should continue to live alongside US. Such a future may seem ideal, and so it is. Yet I do not believe it is fanciful. There is nothing in the physical fabric of the Earth or in our own biology to suggest that this is not possible. Dire means that we human beings could be in deep trouble within the next few centuries, living but also dying in large numbers in political terror and from starvation, while huge numbers of our fellow creatures would simply disappear, leaving only the ones that we find convenient - chickens, cattle - or that we can'tshake off, like flies and mice. I'm taking it to be self-evident that glory is preferable. Our future is not entirely in our own hands because the Earth has its own rules, is part of the solar system and is neither stable nor innately safe. Other planets in the solar system are quite beyond habitation, because their temperature is far too high or too low to be endured, and ours, too, in principle could tip either way. Even relatively unspectacular changes in the atmosphere could do the trick. The core of the Earth is hot, which in many ways is good for living creatures, but every now and again, the molten rock bursts through volcanoes on the surface. Among the biggest volcanic eruptions in recent memory was Mount St Helens, in the USA, which threw out a cubic kilometre of ash - fortunately in an area where very few people live. In 1815, Tambora (in present-day Indonesia) expelled so much ash into the upper atmosphere that climatic effects seriously harmed food production around the world for season after season. Entire civilisations have been destroyed by volcanoes. Yet nothing we have so far experienced shows what volcanoes can really do. Yellowstone National Park in the USA occupies the caldera (the crater formed when a volcano collapses) of an exceedingly ancient volcano of extraordinary magnitude. Modem surveys show that its centre is now rising. Sometime in the next 200 million years, Yellowstone could erupt again, and when it does, the whole world will be transformed. Yellowstone could erupt tomorrow. But there's a very good chance that it will give US another million years, and that surely is enough to be going on with. It seems sensible to assume that this will be the case. The universe at large is dangerous, too: in particular, we share the sky with vast numbers of asteroids, and every now and again, they come into our planet's atmosphere. An asteroid the size of a small island, hitting the Earth at 15,000 kilometres an hour (a relatively modest speed by the standards of heavenly bodies), would strike the ocean bed like a rock in a puddle, send a tidal wave around the world as high as a small mountain and as fast as a jumbo jet, and propel us into an ice age that could last for centuries. There are plans to head off such disasters (including rockets to push approaching asteroids into new trajectories), but in truth it's down to luck. On the other hand, the archaeological and the fossil evidence shows that no truly devastating asteroid has struck since the one that seems to have accounted for the extinction of the dinosaurs 65 million years ago. So again, there seems no immediate reason for despair. The Earth is indeed an uncertain place, in an uncertain universe, but with average luck, it should do us well enough. If the world does become inhospitable in the next few thousand or million years, then it will probably be our own fault. In short, despite the underlying uncertainty, our own future and that of our fellow creatures is very much in our own hands. Given average luck on the geological and the cosmic scale, the difference between glory and disaster will be made, and is being made, by politics. Certain kinds of political systems and strategies would predispose US to long-term survival (and indeed to comfort and security and the pleasure of being alive), while others would take us more and more frenetically towards collapse. The broad point is, though, that we need to look at ourselves - humanity - and at the world in general in a quite new light. Our material problems are fundamentally those of biology. We need to think, and we need our politicians to think, biologically. Do that, and take the ideas seriously, and we are in with a chance. Ignore biology and we and our fellow creatures haven't a hope.", "hypothesis": "It seems predictable that some species will disappear.", "gold_label": "entailment"}
{"uid": "id_168", "premise": "The future never dies? The prospects for humanity and for the world as a whole are somewhere between glorious and dire. It is hard to be much more precise. By glorious I mean that our descendants - all who are born on to this Earth - could live very comfortably and securely, and could continue to do so for as long as the Earth can support life, which should be for a very long time indeed. We should at least be thinking in terms of the next million years. Furthermore, our descendants could continue to enjoy the company of other species - establishing a much better relationship with them than we have now. Other animals need not live in constant fear of us. Many of those fellow species now seem bound to become extinct, but a significant proportion could and should continue to live alongside US. Such a future may seem ideal, and so it is. Yet I do not believe it is fanciful. There is nothing in the physical fabric of the Earth or in our own biology to suggest that this is not possible. Dire means that we human beings could be in deep trouble within the next few centuries, living but also dying in large numbers in political terror and from starvation, while huge numbers of our fellow creatures would simply disappear, leaving only the ones that we find convenient - chickens, cattle - or that we can'tshake off, like flies and mice. I'm taking it to be self-evident that glory is preferable. Our future is not entirely in our own hands because the Earth has its own rules, is part of the solar system and is neither stable nor innately safe. Other planets in the solar system are quite beyond habitation, because their temperature is far too high or too low to be endured, and ours, too, in principle could tip either way. Even relatively unspectacular changes in the atmosphere could do the trick. The core of the Earth is hot, which in many ways is good for living creatures, but every now and again, the molten rock bursts through volcanoes on the surface. Among the biggest volcanic eruptions in recent memory was Mount St Helens, in the USA, which threw out a cubic kilometre of ash - fortunately in an area where very few people live. In 1815, Tambora (in present-day Indonesia) expelled so much ash into the upper atmosphere that climatic effects seriously harmed food production around the world for season after season. Entire civilisations have been destroyed by volcanoes. Yet nothing we have so far experienced shows what volcanoes can really do. Yellowstone National Park in the USA occupies the caldera (the crater formed when a volcano collapses) of an exceedingly ancient volcano of extraordinary magnitude. Modem surveys show that its centre is now rising. Sometime in the next 200 million years, Yellowstone could erupt again, and when it does, the whole world will be transformed. Yellowstone could erupt tomorrow. But there's a very good chance that it will give US another million years, and that surely is enough to be going on with. It seems sensible to assume that this will be the case. The universe at large is dangerous, too: in particular, we share the sky with vast numbers of asteroids, and every now and again, they come into our planet's atmosphere. An asteroid the size of a small island, hitting the Earth at 15,000 kilometres an hour (a relatively modest speed by the standards of heavenly bodies), would strike the ocean bed like a rock in a puddle, send a tidal wave around the world as high as a small mountain and as fast as a jumbo jet, and propel us into an ice age that could last for centuries. There are plans to head off such disasters (including rockets to push approaching asteroids into new trajectories), but in truth it's down to luck. On the other hand, the archaeological and the fossil evidence shows that no truly devastating asteroid has struck since the one that seems to have accounted for the extinction of the dinosaurs 65 million years ago. So again, there seems no immediate reason for despair. The Earth is indeed an uncertain place, in an uncertain universe, but with average luck, it should do us well enough. If the world does become inhospitable in the next few thousand or million years, then it will probably be our own fault. In short, despite the underlying uncertainty, our own future and that of our fellow creatures is very much in our own hands. Given average luck on the geological and the cosmic scale, the difference between glory and disaster will be made, and is being made, by politics. Certain kinds of political systems and strategies would predispose US to long-term survival (and indeed to comfort and security and the pleasure of being alive), while others would take us more and more frenetically towards collapse. The broad point is, though, that we need to look at ourselves - humanity - and at the world in general in a quite new light. Our material problems are fundamentally those of biology. We need to think, and we need our politicians to think, biologically. Do that, and take the ideas seriously, and we are in with a chance. Ignore biology and we and our fellow creatures haven't a hope.", "hypothesis": "The nature of the Earth and human biology make it impossible for human beings to survive another million years,", "gold_label": "contradiction"}
{"uid": "id_169", "premise": "The future never dies? The prospects for humanity and for the world as a whole are somewhere between glorious and dire. It is hard to be much more precise. By glorious I mean that our descendants - all who are born on to this Earth - could live very comfortably and securely, and could continue to do so for as long as the Earth can support life, which should be for a very long time indeed. We should at least be thinking in terms of the next million years. Furthermore, our descendants could continue to enjoy the company of other species - establishing a much better relationship with them than we have now. Other animals need not live in constant fear of us. Many of those fellow species now seem bound to become extinct, but a significant proportion could and should continue to live alongside US. Such a future may seem ideal, and so it is. Yet I do not believe it is fanciful. There is nothing in the physical fabric of the Earth or in our own biology to suggest that this is not possible. Dire means that we human beings could be in deep trouble within the next few centuries, living but also dying in large numbers in political terror and from starvation, while huge numbers of our fellow creatures would simply disappear, leaving only the ones that we find convenient - chickens, cattle - or that we can'tshake off, like flies and mice. I'm taking it to be self-evident that glory is preferable. Our future is not entirely in our own hands because the Earth has its own rules, is part of the solar system and is neither stable nor innately safe. Other planets in the solar system are quite beyond habitation, because their temperature is far too high or too low to be endured, and ours, too, in principle could tip either way. Even relatively unspectacular changes in the atmosphere could do the trick. The core of the Earth is hot, which in many ways is good for living creatures, but every now and again, the molten rock bursts through volcanoes on the surface. Among the biggest volcanic eruptions in recent memory was Mount St Helens, in the USA, which threw out a cubic kilometre of ash - fortunately in an area where very few people live. In 1815, Tambora (in present-day Indonesia) expelled so much ash into the upper atmosphere that climatic effects seriously harmed food production around the world for season after season. Entire civilisations have been destroyed by volcanoes. Yet nothing we have so far experienced shows what volcanoes can really do. Yellowstone National Park in the USA occupies the caldera (the crater formed when a volcano collapses) of an exceedingly ancient volcano of extraordinary magnitude. Modem surveys show that its centre is now rising. Sometime in the next 200 million years, Yellowstone could erupt again, and when it does, the whole world will be transformed. Yellowstone could erupt tomorrow. But there's a very good chance that it will give US another million years, and that surely is enough to be going on with. It seems sensible to assume that this will be the case. The universe at large is dangerous, too: in particular, we share the sky with vast numbers of asteroids, and every now and again, they come into our planet's atmosphere. An asteroid the size of a small island, hitting the Earth at 15,000 kilometres an hour (a relatively modest speed by the standards of heavenly bodies), would strike the ocean bed like a rock in a puddle, send a tidal wave around the world as high as a small mountain and as fast as a jumbo jet, and propel us into an ice age that could last for centuries. There are plans to head off such disasters (including rockets to push approaching asteroids into new trajectories), but in truth it's down to luck. On the other hand, the archaeological and the fossil evidence shows that no truly devastating asteroid has struck since the one that seems to have accounted for the extinction of the dinosaurs 65 million years ago. So again, there seems no immediate reason for despair. The Earth is indeed an uncertain place, in an uncertain universe, but with average luck, it should do us well enough. If the world does become inhospitable in the next few thousand or million years, then it will probably be our own fault. In short, despite the underlying uncertainty, our own future and that of our fellow creatures is very much in our own hands. Given average luck on the geological and the cosmic scale, the difference between glory and disaster will be made, and is being made, by politics. Certain kinds of political systems and strategies would predispose US to long-term survival (and indeed to comfort and security and the pleasure of being alive), while others would take us more and more frenetically towards collapse. The broad point is, though, that we need to look at ourselves - humanity - and at the world in general in a quite new light. Our material problems are fundamentally those of biology. We need to think, and we need our politicians to think, biologically. Do that, and take the ideas seriously, and we are in with a chance. Ignore biology and we and our fellow creatures haven't a hope.", "hypothesis": "Politicians currently in power seem unlikely to change their way of thinking.", "gold_label": "neutral"}
{"uid": "id_170", "premise": "The future never dies? The prospects for humanity and for the world as a whole are somewhere between glorious and dire. It is hard to be much more precise. By glorious I mean that our descendants - all who are born on to this Earth - could live very comfortably and securely, and could continue to do so for as long as the Earth can support life, which should be for a very long time indeed. We should at least be thinking in terms of the next million years. Furthermore, our descendants could continue to enjoy the company of other species - establishing a much better relationship with them than we have now. Other animals need not live in constant fear of us. Many of those fellow species now seem bound to become extinct, but a significant proportion could and should continue to live alongside US. Such a future may seem ideal, and so it is. Yet I do not believe it is fanciful. There is nothing in the physical fabric of the Earth or in our own biology to suggest that this is not possible. Dire means that we human beings could be in deep trouble within the next few centuries, living but also dying in large numbers in political terror and from starvation, while huge numbers of our fellow creatures would simply disappear, leaving only the ones that we find convenient - chickens, cattle - or that we can'tshake off, like flies and mice. I'm taking it to be self-evident that glory is preferable. Our future is not entirely in our own hands because the Earth has its own rules, is part of the solar system and is neither stable nor innately safe. Other planets in the solar system are quite beyond habitation, because their temperature is far too high or too low to be endured, and ours, too, in principle could tip either way. Even relatively unspectacular changes in the atmosphere could do the trick. The core of the Earth is hot, which in many ways is good for living creatures, but every now and again, the molten rock bursts through volcanoes on the surface. Among the biggest volcanic eruptions in recent memory was Mount St Helens, in the USA, which threw out a cubic kilometre of ash - fortunately in an area where very few people live. In 1815, Tambora (in present-day Indonesia) expelled so much ash into the upper atmosphere that climatic effects seriously harmed food production around the world for season after season. Entire civilisations have been destroyed by volcanoes. Yet nothing we have so far experienced shows what volcanoes can really do. Yellowstone National Park in the USA occupies the caldera (the crater formed when a volcano collapses) of an exceedingly ancient volcano of extraordinary magnitude. Modem surveys show that its centre is now rising. Sometime in the next 200 million years, Yellowstone could erupt again, and when it does, the whole world will be transformed. Yellowstone could erupt tomorrow. But there's a very good chance that it will give US another million years, and that surely is enough to be going on with. It seems sensible to assume that this will be the case. The universe at large is dangerous, too: in particular, we share the sky with vast numbers of asteroids, and every now and again, they come into our planet's atmosphere. An asteroid the size of a small island, hitting the Earth at 15,000 kilometres an hour (a relatively modest speed by the standards of heavenly bodies), would strike the ocean bed like a rock in a puddle, send a tidal wave around the world as high as a small mountain and as fast as a jumbo jet, and propel us into an ice age that could last for centuries. There are plans to head off such disasters (including rockets to push approaching asteroids into new trajectories), but in truth it's down to luck. On the other hand, the archaeological and the fossil evidence shows that no truly devastating asteroid has struck since the one that seems to have accounted for the extinction of the dinosaurs 65 million years ago. So again, there seems no immediate reason for despair. The Earth is indeed an uncertain place, in an uncertain universe, but with average luck, it should do us well enough. If the world does become inhospitable in the next few thousand or million years, then it will probably be our own fault. In short, despite the underlying uncertainty, our own future and that of our fellow creatures is very much in our own hands. Given average luck on the geological and the cosmic scale, the difference between glory and disaster will be made, and is being made, by politics. Certain kinds of political systems and strategies would predispose US to long-term survival (and indeed to comfort and security and the pleasure of being alive), while others would take us more and more frenetically towards collapse. The broad point is, though, that we need to look at ourselves - humanity - and at the world in general in a quite new light. Our material problems are fundamentally those of biology. We need to think, and we need our politicians to think, biologically. Do that, and take the ideas seriously, and we are in with a chance. Ignore biology and we and our fellow creatures haven't a hope.", "hypothesis": "There 18 a greater chance of the Earth being hit by small asteroids than by large ones.", "gold_label": "neutral"}
{"uid": "id_171", "premise": "The future never dies? The prospects for humanity and for the world as a whole are somewhere between glorious and dire. It is hard to be much more precise. By glorious I mean that our descendants - all who are born on to this Earth - could live very comfortably and securely, and could continue to do so for as long as the Earth can support life, which should be for a very long time indeed. We should at least be thinking in terms of the next million years. Furthermore, our descendants could continue to enjoy the company of other species - establishing a much better relationship with them than we have now. Other animals need not live in constant fear of us. Many of those fellow species now seem bound to become extinct, but a significant proportion could and should continue to live alongside US. Such a future may seem ideal, and so it is. Yet I do not believe it is fanciful. There is nothing in the physical fabric of the Earth or in our own biology to suggest that this is not possible. Dire means that we human beings could be in deep trouble within the next few centuries, living but also dying in large numbers in political terror and from starvation, while huge numbers of our fellow creatures would simply disappear, leaving only the ones that we find convenient - chickens, cattle - or that we can'tshake off, like flies and mice. I'm taking it to be self-evident that glory is preferable. Our future is not entirely in our own hands because the Earth has its own rules, is part of the solar system and is neither stable nor innately safe. Other planets in the solar system are quite beyond habitation, because their temperature is far too high or too low to be endured, and ours, too, in principle could tip either way. Even relatively unspectacular changes in the atmosphere could do the trick. The core of the Earth is hot, which in many ways is good for living creatures, but every now and again, the molten rock bursts through volcanoes on the surface. Among the biggest volcanic eruptions in recent memory was Mount St Helens, in the USA, which threw out a cubic kilometre of ash - fortunately in an area where very few people live. In 1815, Tambora (in present-day Indonesia) expelled so much ash into the upper atmosphere that climatic effects seriously harmed food production around the world for season after season. Entire civilisations have been destroyed by volcanoes. Yet nothing we have so far experienced shows what volcanoes can really do. Yellowstone National Park in the USA occupies the caldera (the crater formed when a volcano collapses) of an exceedingly ancient volcano of extraordinary magnitude. Modem surveys show that its centre is now rising. Sometime in the next 200 million years, Yellowstone could erupt again, and when it does, the whole world will be transformed. Yellowstone could erupt tomorrow. But there's a very good chance that it will give US another million years, and that surely is enough to be going on with. It seems sensible to assume that this will be the case. The universe at large is dangerous, too: in particular, we share the sky with vast numbers of asteroids, and every now and again, they come into our planet's atmosphere. An asteroid the size of a small island, hitting the Earth at 15,000 kilometres an hour (a relatively modest speed by the standards of heavenly bodies), would strike the ocean bed like a rock in a puddle, send a tidal wave around the world as high as a small mountain and as fast as a jumbo jet, and propel us into an ice age that could last for centuries. There are plans to head off such disasters (including rockets to push approaching asteroids into new trajectories), but in truth it's down to luck. On the other hand, the archaeological and the fossil evidence shows that no truly devastating asteroid has struck since the one that seems to have accounted for the extinction of the dinosaurs 65 million years ago. So again, there seems no immediate reason for despair. The Earth is indeed an uncertain place, in an uncertain universe, but with average luck, it should do us well enough. If the world does become inhospitable in the next few thousand or million years, then it will probably be our own fault. In short, despite the underlying uncertainty, our own future and that of our fellow creatures is very much in our own hands. Given average luck on the geological and the cosmic scale, the difference between glory and disaster will be made, and is being made, by politics. Certain kinds of political systems and strategies would predispose US to long-term survival (and indeed to comfort and security and the pleasure of being alive), while others would take us more and more frenetically towards collapse. The broad point is, though, that we need to look at ourselves - humanity - and at the world in general in a quite new light. Our material problems are fundamentally those of biology. We need to think, and we need our politicians to think, biologically. Do that, and take the ideas seriously, and we are in with a chance. Ignore biology and we and our fellow creatures haven't a hope.", "hypothesis": "An eruption by Yellowstone is likely to be more destructive than previous volcanic eruptions.", "gold_label": "entailment"}
{"uid": "id_172", "premise": "The future of the Worlds Language Of the worlds 6,500 living languages, around half are expected to the out by the end of this century, according to UNESCO. Just 11 are spoken by more than half of the earths population, so it is little wonder that those used by only a few are being left behind as we become a more homogenous, global society. In short, 95 percent of the worlds languages are spoken by only five percent of its populationa remarkable level of linguistic diversity stored in tiny pockets of speakers around the world. Mark Turin, a university professor, has launched WOLP (World Oral Language Project) to prevent the language from the brink of extinction. He is trying to encourage indigenous communities to collaborate with anthropologists around the world to record what he calls oral literature through video cameras, voice recorders and other multimedia tools by awarding grants from a 30,000 pot that the project has secured this year. The idea is to collate this literature in a digital archive that can be accessed on demand and will make the nuts and bolts of lost cultures readily available. For many of these communities, the oral tradition is at the heart of their culture. The stories they tell are creative as well as communicative. Unlike the languages with celebrated written traditions, such as Sanskrit, Hebrew and Ancient Greek, few indigenous communities have recorded their own languages or ever had them recorded until now. The project suggested itself when Turin was teaching in Nepal. He wanted to study for a PhD in endangered languages and, while discussing it with his professor at Leiden University in the Netherlands, was drawn to a map on his tutors wall. The map was full of pins of a variety of colours which represented all the worlds languages that were completely undocumented. At random, Turin chose a pin to document. It happened to belong to the Thangmi tribe, an indigenous community in the hills east of Kathmandu, the capital of Nepal. Many of the choices anthropologists and linguists who work on these traditional field-work projects are quite random, he admits. Continuing his work with the Thangmi community in the 1990s, Turin began to record the language he was hearing, realising that not only was this language and its culture entirely undocumented, it was known to few outside the tiny community. He set about trying to record their language and myth of origins. I wrote 1,000 pages of grammar in English that nobody could usebut I realised that wasnt enough. It wasnt enough for me, it wasnt enough for them. It simply wasnt going to work as something for the community. So then I produced this trilingual word list in Thangmi, Nepali and English. In short, it was the first ever publication of that language. That small dictionary is still sold in local schools for a modest 20 rupees, and used as part of a wider cultural regeneration process to educate children about their heritage and language. The task is no small undertaking: Nepal itself is a country of massive ethnic and linguistic diversity, home to 100 languages from four different language families. Whats more, even fewer ethnic Thangmi speak the Thangmi language. Many of the community members have taken to speaking Nepali, the national language taught in schools and spread through the media, and community elders are dying without passing on their knowledge. Despite Turins enthusiasm for his subject, he is baffled by many linguists refusal to engage in the issue he is working on. Of the 6,500 languages spoken on Earth, many do not have written traditions and many of these spoken forms are endangered, he says. There are more linguists in universities around the world than there are spoken languagesbut most of them arent working on this issue. To me its amazing that in this day and age, we still have an entirely incomplete image of the worlds linguistic diversity. People do PhDs on the apostrophe in French, yet we still dont know how many languages are spoken. When a language becomes endangered, so too does a cultural world view. We want to engage with indigenous people to document their myths and folklore, which can be harder to find funding for if you are based outside Western universities. Yet, despite the struggles facing initiatives such as the World Oral Literature Project, there are historical examples that point to the possibility that language restoration is no mere academic pipe dream. The revival of a modern form of Hebrew in the 19th century is often cited as one of the best proofs that languages long dead, belonging to small communities, can be resurrected and embraced by a large number of people. By the 20th century, Hebrew was well on its way to becoming the main language of the Jewish population of both Ottoman and British Palestine. It is now spoken by more than seven million people in Israel. Yet, despite the difficulties these communities face in saving their languages, Dr Turin believes that the fate of the worlds endangered languages is not sealed, and globalisation is not necessarily the nefarious perpetrator of evil it is often presented to be. I call it the globalisation paradox: on the one hand globalisation and rapid socio-economic change are the things that are eroding and challenging diversity But on the other, globalisation is providing us with new and very exciting tools and facilities to get to places to document those things that globalisation is eroding. Also, the communities at the coal-face of change are excited by what globalisation has to offer. In the meantime, the race is on to collect and protect as many of the languages as possible, so that the Rai Shaman in eastern Nepal and those in the generations that follow him can continue their traditions and have a sense of identity. And it certainly is a race: Turin knows his projects limits and believes it inevitable that a large number of those languages will disappear. We have to be wholly realistic. A project like ours is in no position, and was not designed, to keep languages alive. The only people who can help languages survive are the people in those communities themselves. They need to be reminded that its good to speak their own language and I think we can help them do thatbecoming modem doesnt mean you have to lose your language.", "hypothesis": "Some Nepalese schools lack resources to devote to language teaching.", "gold_label": "neutral"}
{"uid": "id_173", "premise": "The future of the Worlds Language Of the worlds 6,500 living languages, around half are expected to the out by the end of this century, according to UNESCO. Just 11 are spoken by more than half of the earths population, so it is little wonder that those used by only a few are being left behind as we become a more homogenous, global society. In short, 95 percent of the worlds languages are spoken by only five percent of its populationa remarkable level of linguistic diversity stored in tiny pockets of speakers around the world. Mark Turin, a university professor, has launched WOLP (World Oral Language Project) to prevent the language from the brink of extinction. He is trying to encourage indigenous communities to collaborate with anthropologists around the world to record what he calls oral literature through video cameras, voice recorders and other multimedia tools by awarding grants from a 30,000 pot that the project has secured this year. The idea is to collate this literature in a digital archive that can be accessed on demand and will make the nuts and bolts of lost cultures readily available. For many of these communities, the oral tradition is at the heart of their culture. The stories they tell are creative as well as communicative. Unlike the languages with celebrated written traditions, such as Sanskrit, Hebrew and Ancient Greek, few indigenous communities have recorded their own languages or ever had them recorded until now. The project suggested itself when Turin was teaching in Nepal. He wanted to study for a PhD in endangered languages and, while discussing it with his professor at Leiden University in the Netherlands, was drawn to a map on his tutors wall. The map was full of pins of a variety of colours which represented all the worlds languages that were completely undocumented. At random, Turin chose a pin to document. It happened to belong to the Thangmi tribe, an indigenous community in the hills east of Kathmandu, the capital of Nepal. Many of the choices anthropologists and linguists who work on these traditional field-work projects are quite random, he admits. Continuing his work with the Thangmi community in the 1990s, Turin began to record the language he was hearing, realising that not only was this language and its culture entirely undocumented, it was known to few outside the tiny community. He set about trying to record their language and myth of origins. I wrote 1,000 pages of grammar in English that nobody could usebut I realised that wasnt enough. It wasnt enough for me, it wasnt enough for them. It simply wasnt going to work as something for the community. So then I produced this trilingual word list in Thangmi, Nepali and English. In short, it was the first ever publication of that language. That small dictionary is still sold in local schools for a modest 20 rupees, and used as part of a wider cultural regeneration process to educate children about their heritage and language. The task is no small undertaking: Nepal itself is a country of massive ethnic and linguistic diversity, home to 100 languages from four different language families. Whats more, even fewer ethnic Thangmi speak the Thangmi language. Many of the community members have taken to speaking Nepali, the national language taught in schools and spread through the media, and community elders are dying without passing on their knowledge. Despite Turins enthusiasm for his subject, he is baffled by many linguists refusal to engage in the issue he is working on. Of the 6,500 languages spoken on Earth, many do not have written traditions and many of these spoken forms are endangered, he says. There are more linguists in universities around the world than there are spoken languagesbut most of them arent working on this issue. To me its amazing that in this day and age, we still have an entirely incomplete image of the worlds linguistic diversity. People do PhDs on the apostrophe in French, yet we still dont know how many languages are spoken. When a language becomes endangered, so too does a cultural world view. We want to engage with indigenous people to document their myths and folklore, which can be harder to find funding for if you are based outside Western universities. Yet, despite the struggles facing initiatives such as the World Oral Literature Project, there are historical examples that point to the possibility that language restoration is no mere academic pipe dream. The revival of a modern form of Hebrew in the 19th century is often cited as one of the best proofs that languages long dead, belonging to small communities, can be resurrected and embraced by a large number of people. By the 20th century, Hebrew was well on its way to becoming the main language of the Jewish population of both Ottoman and British Palestine. It is now spoken by more than seven million people in Israel. Yet, despite the difficulties these communities face in saving their languages, Dr Turin believes that the fate of the worlds endangered languages is not sealed, and globalisation is not necessarily the nefarious perpetrator of evil it is often presented to be. I call it the globalisation paradox: on the one hand globalisation and rapid socio-economic change are the things that are eroding and challenging diversity But on the other, globalisation is providing us with new and very exciting tools and facilities to get to places to document those things that globalisation is eroding. Also, the communities at the coal-face of change are excited by what globalisation has to offer. In the meantime, the race is on to collect and protect as many of the languages as possible, so that the Rai Shaman in eastern Nepal and those in the generations that follow him can continue their traditions and have a sense of identity. And it certainly is a race: Turin knows his projects limits and believes it inevitable that a large number of those languages will disappear. We have to be wholly realistic. A project like ours is in no position, and was not designed, to keep languages alive. The only people who can help languages survive are the people in those communities themselves. They need to be reminded that its good to speak their own language and I think we can help them do thatbecoming modem doesnt mean you have to lose your language.", "hypothesis": "Turin concluded that the Thangmi language had few similarities with other languages.", "gold_label": "neutral"}
{"uid": "id_174", "premise": "The future of the Worlds Language Of the worlds 6,500 living languages, around half are expected to the out by the end of this century, according to UNESCO. Just 11 are spoken by more than half of the earths population, so it is little wonder that those used by only a few are being left behind as we become a more homogenous, global society. In short, 95 percent of the worlds languages are spoken by only five percent of its populationa remarkable level of linguistic diversity stored in tiny pockets of speakers around the world. Mark Turin, a university professor, has launched WOLP (World Oral Language Project) to prevent the language from the brink of extinction. He is trying to encourage indigenous communities to collaborate with anthropologists around the world to record what he calls oral literature through video cameras, voice recorders and other multimedia tools by awarding grants from a 30,000 pot that the project has secured this year. The idea is to collate this literature in a digital archive that can be accessed on demand and will make the nuts and bolts of lost cultures readily available. For many of these communities, the oral tradition is at the heart of their culture. The stories they tell are creative as well as communicative. Unlike the languages with celebrated written traditions, such as Sanskrit, Hebrew and Ancient Greek, few indigenous communities have recorded their own languages or ever had them recorded until now. The project suggested itself when Turin was teaching in Nepal. He wanted to study for a PhD in endangered languages and, while discussing it with his professor at Leiden University in the Netherlands, was drawn to a map on his tutors wall. The map was full of pins of a variety of colours which represented all the worlds languages that were completely undocumented. At random, Turin chose a pin to document. It happened to belong to the Thangmi tribe, an indigenous community in the hills east of Kathmandu, the capital of Nepal. Many of the choices anthropologists and linguists who work on these traditional field-work projects are quite random, he admits. Continuing his work with the Thangmi community in the 1990s, Turin began to record the language he was hearing, realising that not only was this language and its culture entirely undocumented, it was known to few outside the tiny community. He set about trying to record their language and myth of origins. I wrote 1,000 pages of grammar in English that nobody could usebut I realised that wasnt enough. It wasnt enough for me, it wasnt enough for them. It simply wasnt going to work as something for the community. So then I produced this trilingual word list in Thangmi, Nepali and English. In short, it was the first ever publication of that language. That small dictionary is still sold in local schools for a modest 20 rupees, and used as part of a wider cultural regeneration process to educate children about their heritage and language. The task is no small undertaking: Nepal itself is a country of massive ethnic and linguistic diversity, home to 100 languages from four different language families. Whats more, even fewer ethnic Thangmi speak the Thangmi language. Many of the community members have taken to speaking Nepali, the national language taught in schools and spread through the media, and community elders are dying without passing on their knowledge. Despite Turins enthusiasm for his subject, he is baffled by many linguists refusal to engage in the issue he is working on. Of the 6,500 languages spoken on Earth, many do not have written traditions and many of these spoken forms are endangered, he says. There are more linguists in universities around the world than there are spoken languagesbut most of them arent working on this issue. To me its amazing that in this day and age, we still have an entirely incomplete image of the worlds linguistic diversity. People do PhDs on the apostrophe in French, yet we still dont know how many languages are spoken. When a language becomes endangered, so too does a cultural world view. We want to engage with indigenous people to document their myths and folklore, which can be harder to find funding for if you are based outside Western universities. Yet, despite the struggles facing initiatives such as the World Oral Literature Project, there are historical examples that point to the possibility that language restoration is no mere academic pipe dream. The revival of a modern form of Hebrew in the 19th century is often cited as one of the best proofs that languages long dead, belonging to small communities, can be resurrected and embraced by a large number of people. By the 20th century, Hebrew was well on its way to becoming the main language of the Jewish population of both Ottoman and British Palestine. It is now spoken by more than seven million people in Israel. Yet, despite the difficulties these communities face in saving their languages, Dr Turin believes that the fate of the worlds endangered languages is not sealed, and globalisation is not necessarily the nefarious perpetrator of evil it is often presented to be. I call it the globalisation paradox: on the one hand globalisation and rapid socio-economic change are the things that are eroding and challenging diversity But on the other, globalisation is providing us with new and very exciting tools and facilities to get to places to document those things that globalisation is eroding. Also, the communities at the coal-face of change are excited by what globalisation has to offer. In the meantime, the race is on to collect and protect as many of the languages as possible, so that the Rai Shaman in eastern Nepal and those in the generations that follow him can continue their traditions and have a sense of identity. And it certainly is a race: Turin knows his projects limits and believes it inevitable that a large number of those languages will disappear. We have to be wholly realistic. A project like ours is in no position, and was not designed, to keep languages alive. The only people who can help languages survive are the people in those communities themselves. They need to be reminded that its good to speak their own language and I think we can help them do thatbecoming modem doesnt mean you have to lose your language.", "hypothesis": "Turin argued that anthropologists and linguists usually think carefully before selecting an area to research.", "gold_label": "contradiction"}
{"uid": "id_175", "premise": "The future of the Worlds Language Of the worlds 6,500 living languages, around half are expected to the out by the end of this century, according to UNESCO. Just 11 are spoken by more than half of the earths population, so it is little wonder that those used by only a few are being left behind as we become a more homogenous, global society. In short, 95 percent of the worlds languages are spoken by only five percent of its populationa remarkable level of linguistic diversity stored in tiny pockets of speakers around the world. Mark Turin, a university professor, has launched WOLP (World Oral Language Project) to prevent the language from the brink of extinction. He is trying to encourage indigenous communities to collaborate with anthropologists around the world to record what he calls oral literature through video cameras, voice recorders and other multimedia tools by awarding grants from a 30,000 pot that the project has secured this year. The idea is to collate this literature in a digital archive that can be accessed on demand and will make the nuts and bolts of lost cultures readily available. For many of these communities, the oral tradition is at the heart of their culture. The stories they tell are creative as well as communicative. Unlike the languages with celebrated written traditions, such as Sanskrit, Hebrew and Ancient Greek, few indigenous communities have recorded their own languages or ever had them recorded until now. The project suggested itself when Turin was teaching in Nepal. He wanted to study for a PhD in endangered languages and, while discussing it with his professor at Leiden University in the Netherlands, was drawn to a map on his tutors wall. The map was full of pins of a variety of colours which represented all the worlds languages that were completely undocumented. At random, Turin chose a pin to document. It happened to belong to the Thangmi tribe, an indigenous community in the hills east of Kathmandu, the capital of Nepal. Many of the choices anthropologists and linguists who work on these traditional field-work projects are quite random, he admits. Continuing his work with the Thangmi community in the 1990s, Turin began to record the language he was hearing, realising that not only was this language and its culture entirely undocumented, it was known to few outside the tiny community. He set about trying to record their language and myth of origins. I wrote 1,000 pages of grammar in English that nobody could usebut I realised that wasnt enough. It wasnt enough for me, it wasnt enough for them. It simply wasnt going to work as something for the community. So then I produced this trilingual word list in Thangmi, Nepali and English. In short, it was the first ever publication of that language. That small dictionary is still sold in local schools for a modest 20 rupees, and used as part of a wider cultural regeneration process to educate children about their heritage and language. The task is no small undertaking: Nepal itself is a country of massive ethnic and linguistic diversity, home to 100 languages from four different language families. Whats more, even fewer ethnic Thangmi speak the Thangmi language. Many of the community members have taken to speaking Nepali, the national language taught in schools and spread through the media, and community elders are dying without passing on their knowledge. Despite Turins enthusiasm for his subject, he is baffled by many linguists refusal to engage in the issue he is working on. Of the 6,500 languages spoken on Earth, many do not have written traditions and many of these spoken forms are endangered, he says. There are more linguists in universities around the world than there are spoken languagesbut most of them arent working on this issue. To me its amazing that in this day and age, we still have an entirely incomplete image of the worlds linguistic diversity. People do PhDs on the apostrophe in French, yet we still dont know how many languages are spoken. When a language becomes endangered, so too does a cultural world view. We want to engage with indigenous people to document their myths and folklore, which can be harder to find funding for if you are based outside Western universities. Yet, despite the struggles facing initiatives such as the World Oral Literature Project, there are historical examples that point to the possibility that language restoration is no mere academic pipe dream. The revival of a modern form of Hebrew in the 19th century is often cited as one of the best proofs that languages long dead, belonging to small communities, can be resurrected and embraced by a large number of people. By the 20th century, Hebrew was well on its way to becoming the main language of the Jewish population of both Ottoman and British Palestine. It is now spoken by more than seven million people in Israel. Yet, despite the difficulties these communities face in saving their languages, Dr Turin believes that the fate of the worlds endangered languages is not sealed, and globalisation is not necessarily the nefarious perpetrator of evil it is often presented to be. I call it the globalisation paradox: on the one hand globalisation and rapid socio-economic change are the things that are eroding and challenging diversity But on the other, globalisation is providing us with new and very exciting tools and facilities to get to places to document those things that globalisation is eroding. Also, the communities at the coal-face of change are excited by what globalisation has to offer. In the meantime, the race is on to collect and protect as many of the languages as possible, so that the Rai Shaman in eastern Nepal and those in the generations that follow him can continue their traditions and have a sense of identity. And it certainly is a race: Turin knows his projects limits and believes it inevitable that a large number of those languages will disappear. We have to be wholly realistic. A project like ours is in no position, and was not designed, to keep languages alive. The only people who can help languages survive are the people in those communities themselves. They need to be reminded that its good to speak their own language and I think we can help them do thatbecoming modem doesnt mean you have to lose your language.", "hypothesis": "Turin has written that 1000-page document was inappropriate for Thangmi community;", "gold_label": "entailment"}
{"uid": "id_176", "premise": "The genus of plants called Narcissus, many of the species of which are highly esteemed by the floriculturist and lover of cultivated plants, belongs to the Amaryllis family (Amaryllidace. ) This family includes about seventy genera and over eight hundred species that are mostly native in tropical or semi-tropical countries, though a few are found in temperate climates. Many of the species are sought for ornamental purposes and, on account of their beauty and remarkable odour, they are more prized by many than are the species of the Lily family. In this group is classed the American Aloe (Agave Americana) valued not only for cultivation, but also by the Mexicans on account of the sweet fluid which is yielded by its central bud. This liquid, after fermentation, forms an intoxicating liquor known as pulque. By distillation, this yields a liquid, very similar to rum, called by the Mexicans mescal. The leaves furnish a strong fibre, known as vegetable silk, from which, since remote times, paper has been manufactured. The popular opinion is that this plant flowers but once in a century; hence the name Century Plant is often applied to it, though under proper culture it will blossom more frequently.", "hypothesis": "A genus belongs to a family.25. Members of the Narcissus genus are used for their soothing properties.", "gold_label": "entailment"}
{"uid": "id_177", "premise": "The genus of plants called Narcissus, many of the species of which are highly esteemed by the floriculturist and lover of cultivated plants, belongs to the Amaryllis family (Amaryllidace. ) This family includes about seventy genera and over eight hundred species that are mostly native in tropical or semi-tropical countries, though a few are found in temperate climates. Many of the species are sought for ornamental purposes and, on account of their beauty and remarkable odour, they are more prized by many than are the species of the Lily family. In this group is classed the American Aloe (Agave Americana) valued not only for cultivation, but also by the Mexicans on account of the sweet fluid which is yielded by its central bud. This liquid, after fermentation, forms an intoxicating liquor known as pulque. By distillation, this yields a liquid, very similar to rum, called by the Mexicans mescal. The leaves furnish a strong fibre, known as vegetable silk, from which, since remote times, paper has been manufactured. The popular opinion is that this plant flowers but once in a century; hence the name Century Plant is often applied to it, though under proper culture it will blossom more frequently.", "hypothesis": "The members of the Narcissus genus have a distinctive smell.", "gold_label": "entailment"}
{"uid": "id_178", "premise": "The genus of plants called Narcissus, many of the species of which are highly esteemed by the floriculturist and lover of cultivated plants, belongs to the Amaryllis family (Amaryllidace. ) This family includes about seventy genera and over eight hundred species that are mostly native in tropical or semi-tropical countries, though a few are found in temperate climates. Many of the species are sought for ornamental purposes and, on account of their beauty and remarkable odour, they are more prized by many than are the species of the Lily family. In this group is classed the American Aloe (Agave Americana) valued not only for cultivation, but also by the Mexicans on account of the sweet fluid which is yielded by its central bud. This liquid, after fermentation, forms an intoxicating liquor known as pulque. By distillation, this yields a liquid, very similar to rum, called by the Mexicans mescal. The leaves furnish a strong fibre, known as vegetable silk, from which, since remote times, paper has been manufactured. The popular opinion is that this plant flowers but once in a century; hence the name Century Plant is often applied to it, though under proper culture it will blossom more frequently.", "hypothesis": "Members of the Narcissus genus can be found in all climates.", "gold_label": "contradiction"}
{"uid": "id_179", "premise": "The genus of plants called Narcissus, many of the species of which are highly esteemed by the floriculturist and lover of cultivated plants, belongs to the Amaryllis family (Amaryllidace. ) This family includes about seventy genera and over eight hundred species that are mostly native in tropical or semi-tropical countries, though a few are found in temperate climates. Many of the species are sought for ornamental purposes and, on account of their beauty and remarkable odour, they are more prized by many than are the species of the Lily family. In this group is classed the American Aloe (Agave Americana) valued not only for cultivation, but also by the Mexicans on account of the sweet fluid which is yielded by its central bud. This liquid, after fermentation, forms an intoxicating liquor known as pulque. By distillation, this yields a liquid, very similar to rum, called by the Mexicans mescal. The leaves furnish a strong fibre, known as vegetable silk, from which, since remote times, paper has been manufactured. The popular opinion is that this plant flowers but once in a century; hence the name Century Plant is often applied to it, though under proper culture it will blossom more frequently.", "hypothesis": "The Amaryllis family contains more than six hundred species of Narcissus.", "gold_label": "entailment"}
{"uid": "id_180", "premise": "The genus of plants called Narcissus, many of the species of which are highly esteemed by the floriculturist and lover of cultivated plants, belongs to the Amaryllis family (Amaryllidace. ) This family includes about seventy genera and over eight hundred species that are mostly native in tropical or semi-tropical countries, though a few are found in temperate climates. Many of the species are sought for ornamental purposes and, on account of their beauty and remarkable odour, they are more prized by many than are the species of the Lily family. In this group is classed the American Aloe (Agave Americana) valued not only for cultivation, but also by the Mexicans on account of the sweet fluid which is yielded by its central bud. This liquid, after fermentation, forms an intoxicating liquor known as pulque. By distillation, this yields a liquid, very similar to rum, called by the Mexicans mescal. The leaves furnish a strong fibre, known as vegetable silk, from which, since remote times, paper has been manufactured. The popular opinion is that this plant flowers but once in a century; hence the name Century Plant is often applied to it, though under proper culture it will blossom more frequently.", "hypothesis": "Members of the Narcissus genus are a welcome addition to any household.", "gold_label": "contradiction"}
{"uid": "id_181", "premise": "The genus of plants called Narcissus, many of the species of which are highly esteemed by the floriculturist and lover of cultivated plants, belongs to the Amaryllis family (Amaryllidace. ) This family includes about seventy genera and over eight hundred species that are mostly native in tropical or semi-tropical countries, though a few are found in temperate climates. Many of the species are sought for ornamental purposes and, on account of their beauty and remarkable odour, they are more prized by many than are the species of the Lily family. In this group is classed the American Aloe (Agave Americana) valued not only for cultivation, but also by the Mexicans on account of the sweet fluid which is yielded by its central bud. This liquid, after fermentation, forms an intoxicating liquor known as pulque. By distillation, this yields a liquid, very similar to rum, called by the Mexicans mescal. The leaves furnish a strong fibre, known as vegetable silk, from which, since remote times, paper has been manufactured. The popular opinion is that this plant flowers but once in a century; hence the name Century Plant is often applied to it, though under proper culture it will blossom more frequently.", "hypothesis": "A number are people prefer members of the Narcissus genus over Lilies.", "gold_label": "entailment"}
{"uid": "id_182", "premise": "The genus of plants called Narcissus, many of the species of which are highly esteemed by the floriculturist and lover of cultivated plants, belongs to the Amaryllis family (Amaryllidace. ) This family includes about seventy genera and over eight hundred species that are mostly native in tropical or semi-tropical countries, though a few are found in temperate climates. Many of the species are sought for ornamental purposes and, on account of their beauty and remarkable odour, they are more prized by many than are the species of the Lily family. In this group is classed the American Aloe (Agave Americana) valued not only for cultivation, but also by the Mexicans on account of the sweet fluid which is yielded by its central bud. This liquid, after fermentation, forms an intoxicating liquor known as pulque. By distillation, this yields a liquid, very similar to rum, called by the Mexicans mescal. The leaves furnish a strong fibre, known as vegetable silk, from which, since remote times, paper has been manufactured. The popular opinion is that this plant flowers but once in a century; hence the name Century Plant is often applied to it, though under proper culture it will blossom more frequently.", "hypothesis": "Lilies are famously not as attractive as members of the Narcissus genus.", "gold_label": "contradiction"}
{"uid": "id_183", "premise": "The genus of plants called Narcissus, many of the species of which are highly esteemed by the floriculturist and lover of cultivated plants, belongs to the Amaryllis family (Amaryllidace. ) This family includes about seventy genera and over eight hundred species that are mostly native in tropical or semi-tropical countries, though a few are found in temperate climates. Many of the species are sought for ornamental purposes and, on account of their beauty and remarkable odour, they are more prized by many than are the species of the Lily family. In this group is classed the American Aloe (Agave Americana) valued not only for cultivation, but also by the Mexicans on account of the sweet fluid which is yielded by its central bud. This liquid, after fermentation, forms an intoxicating liquor known as pulque. By distillation, this yields a liquid, very similar to rum, called by the Mexicans mescal. The leaves furnish a strong fibre, known as vegetable silk, from which, since remote times, paper has been manufactured. The popular opinion is that this plant flowers but once in a century; hence the name Century Plant is often applied to it, though under proper culture it will blossom more frequently.", "hypothesis": "Lilies are generally valued less than members of the Narcissus genus.", "gold_label": "contradiction"}
{"uid": "id_184", "premise": "The genus of plants called Narcissus, many of the species of which are highly esteemed by the floriculturist and lover of cultivated plants, belongs to the Amaryllis family (Amaryllidace. ) This family includes about seventy genera and over eight hundred species that are mostly native in tropical or semi-tropical countries, though a few are found in temperate climates. Many of the species are sought for ornamental purposes and, on account of their beauty and remarkable odour, they are more prized by many than are the species of the Lily family. In this group is classed the American Aloe (Agave Americana) valued not only for cultivation, but also by the Mexicans on account of the sweet fluid which is yielded by its central bud. This liquid, after fermentation, forms an intoxicating liquor known as pulque. By distillation, this yields a liquid, very similar to rum, called by the Mexicans mescal. The leaves furnish a strong fibre, known as vegetable silk, from which, since remote times, paper has been manufactured. The popular opinion is that this plant flowers but once in a century; hence the name Century Plant is often applied to it, though under proper culture it will blossom more frequently.", "hypothesis": "American Aloe can be used to make rum.", "gold_label": "entailment"}
{"uid": "id_185", "premise": "The genus of plants called Narcissus, many of the species of which are highly esteemed by the floriculturist and lover of cultivated plants, belongs to the Amaryllis family (Amaryllidace. ) This family includes about seventy genera and over eight hundred species that are mostly native in tropical or semi-tropical countries, though a few are found in temperate climates. Many of the species are sought for ornamental purposes and, on account of their beauty and remarkable odour, they are more prized by many than are the species of the Lily family. In this group is classed the American Aloe (Agave Americana) valued not only for cultivation, but also by the Mexicans on account of the sweet fluid which is yielded by its central bud. This liquid, after fermentation, forms an intoxicating liquor known as pulque. By distillation, this yields a liquid, very similar to rum, called by the Mexicans mescal. The leaves furnish a strong fibre, known as vegetable silk, from which, since remote times, paper has been manufactured. The popular opinion is that this plant flowers but once in a century; hence the name Century Plant is often applied to it, though under proper culture it will blossom more frequently.", "hypothesis": "Agave syrup can be collected by American Aloe.", "gold_label": "contradiction"}
{"uid": "id_186", "premise": "The genus of plants called Narcissus, many of the species of which are highly esteemed by the floriculturist and lover of cultivated plants, belongs to the Amaryllis family (Amaryllidace. ) This family includes about seventy genera and over eight hundred species that are mostly native in tropical or semi-tropical countries, though a few are found in temperate climates. Many of the species are sought for ornamental purposes and, on account of their beauty and remarkable odour, they are more prized by many than are the species of the Lily family. In this group is classed the American Aloe (Agave Americana) valued not only for cultivation, but also by the Mexicans on account of the sweet fluid which is yielded by its central bud. This liquid, after fermentation, forms an intoxicating liquor known as pulque. By distillation, this yields a liquid, very similar to rum, called by the Mexicans mescal. The leaves furnish a strong fibre, known as vegetable silk, from which, since remote times, paper has been manufactured. The popular opinion is that this plant flowers but once in a century; hence the name Century Plant is often applied to it, though under proper culture it will blossom more frequently.", "hypothesis": "The Narcissus genus is named after the mythical character, famed for his beauty.", "gold_label": "contradiction"}
{"uid": "id_187", "premise": "The giant wind turbines on the nearby hill supply the community with 8 million kilowatt hours of electricity each year. Several hundred homeowners have erected solar panels on their roofs to provide most of their summer-time hot water needs. Bio-waste is collected for fermentation to produce methane gas which drives a local generator to augment the towns electricity needs when there is insufficient wind to fully power the turbines. Better insulation has cut the fuel requirements of many homes. Local generation in this isolated, rural community has led to saving on the investment cost of additional transmission lines in the national network. Further efficiencies are gained because the local production of power avoids losses to electrical resistance in the long-distance transmission of power.", "hypothesis": "The motives for this community's investment in the local generation of its energy needs are rising fuel costs and climate worries.", "gold_label": "neutral"}
{"uid": "id_188", "premise": "The giant wind turbines on the nearby hill supply the community with 8 million kilowatt hours of electricity each year. Several hundred homeowners have erected solar panels on their roofs to provide most of their summer-time hot water needs. Bio-waste is collected for fermentation to produce methane gas which drives a local generator to augment the towns electricity needs when there is insufficient wind to fully power the turbines. Better insulation has cut the fuel requirements of many homes. Local generation in this isolated, rural community has led to saving on the investment cost of additional transmission lines in the national network. Further efficiencies are gained because the local production of power avoids losses to electrical resistance in the long-distance transmission of power.", "hypothesis": "When the wind is blowing and the sun is shining, locally generated power accounts for most of this community's energy needs.", "gold_label": "neutral"}
{"uid": "id_189", "premise": "The giant wind turbines on the nearby hill supply the community with 8 million kilowatt hours of electricity each year. Several hundred homeowners have erected solar panels on their roofs to provide most of their summer-time hot water needs. Bio-waste is collected for fermentation to produce methane gas which drives a local generator to augment the towns electricity needs when there is insufficient wind to fully power the turbines. Better insulation has cut the fuel requirements of many homes. Local generation in this isolated, rural community has led to saving on the investment cost of additional transmission lines in the national network. Further efficiencies are gained because the local production of power avoids losses to electrical resistance in the long-distance transmission of power.", "hypothesis": "This isolated rural community is located in a part of the world where the national power network is practically non-existent.", "gold_label": "contradiction"}
{"uid": "id_190", "premise": "The government has decided to disinvest large chunk of its equity in select public sector undertakings for a better fiscal management.", "hypothesis": "The amount generated out of the disinvestment process may reduce substantially the mounting fiscal deficits.", "gold_label": "entailment"}
{"uid": "id_191", "premise": "The government has decided to disinvest large chunk of its equity in select public sector undertakings for a better fiscal management.", "hypothesis": "There will be enough demand in the market for the shares of these undertakings.", "gold_label": "neutral"}
{"uid": "id_192", "premise": "The government has decided to pay compensation to the tune of Rs. 1 lakh to the family members of those who are killed in railway accidents.", "hypothesis": "There may be reduction in incidents of railway accidents in near future.", "gold_label": "neutral"}
{"uid": "id_193", "premise": "The government has decided to pay compensation to the tune of Rs. 1 lakh to the family members of those who are killed in railway accidents.", "hypothesis": "The government has enough funds to meet the expenses due to compensation", "gold_label": "entailment"}
{"uid": "id_194", "premise": "The government has decided to run all commercial vehicles on bio-fuels in order to save the depleting fossil fuel reserves.", "hypothesis": "Sufficient amount of bio-fuels can be produced in the country to run all commercial vehicles. Syndicate Bank (PO)", "gold_label": "neutral"}
{"uid": "id_195", "premise": "The government has decided to run all commercial vehicles on bio-fuels in order to save the depleting fossil fuel reserves.", "hypothesis": "It is possible to switch over from fossil fuels to bio-fuels for vehicles", "gold_label": "entailment"}
{"uid": "id_196", "premise": "The government wants 50 per cent of people aged 18 to 30 to go to university, and many of these new students are expected to study for shorter foundation degrees. These last two years and combine study with hands-on experience while in paid relevant work. Already more than 20,000 people are taking foundation degrees in 1,000 different courses. Self-discipline and strong motivation are critical if the student is to succeed because most foundation degrees are by distance learning and are part-time. While foundation degrees are not for the faint-hearted, they may appeal to many students who currently follow conventional university courses and who leave university with average debts of 30,000 and then have to compete for a graduate-level job against other foundation degree graduates with work-related experience.", "hypothesis": "It can be inferred from the passage that part-time study by distant learning demands a higher level of self-discipline than shown by students on conventional degree courses.", "gold_label": "contradiction"}
{"uid": "id_197", "premise": "The government wants 50 per cent of people aged 18 to 30 to go to university, and many of these new students are expected to study for shorter foundation degrees. These last two years and combine study with hands-on experience while in paid relevant work. Already more than 20,000 people are taking foundation degrees in 1,000 different courses. Self-discipline and strong motivation are critical if the student is to succeed because most foundation degrees are by distance learning and are part-time. While foundation degrees are not for the faint-hearted, they may appeal to many students who currently follow conventional university courses and who leave university with average debts of 30,000 and then have to compete for a graduate-level job against other foundation degree graduates with work-related experience.", "hypothesis": "To undertake a foundation degree does not require one to go to university.", "gold_label": "contradiction"}
{"uid": "id_198", "premise": "The government wants 50 per cent of people aged 18 to 30 to go to university, and many of these new students are expected to study for shorter foundation degrees. These last two years and combine study with hands-on experience while in paid relevant work. Already more than 20,000 people are taking foundation degrees in 1,000 different courses. Self-discipline and strong motivation are critical if the student is to succeed because most foundation degrees are by distance learning and are part-time. While foundation degrees are not for the faint-hearted, they may appeal to many students who currently follow conventional university courses and who leave university with average debts of 30,000 and then have to compete for a graduate-level job against other foundation degree graduates with work-related experience.", "hypothesis": "The case made for doing a foundation degree rather than a conventional degree is purely economic.", "gold_label": "contradiction"}
{"uid": "id_199", "premise": "The growth of intelligence No one doubts that intelligence develops as children grow older. Yet the concept of intelligence has proved both quite difficult to define in unambiguous terms and unexpectedly controversial in some respects. Although, at one level, there seem to be almost as many definitions of intelligence as people who have tried to define it, there is broad agreement on two key features. That is, intelligence involves the capacity not only to learn from experience but also to adapt to ones environment. However, we cannot leave the concept there. Before turning to what is known about the development of intelligence, it is necessary to consider whether we are considering the growth of one or many skills. That question has been tackled in rather different ways by psychometricians and by developmentalists. The former group has examined the issue by determining how childrens abilities on a wide range of tasks intercorrelate, or go together. Statistical techniques have been used to find out whether the patterns are best explained by one broad underlying capacity, general intelligence, or by a set of multiple, relatively separate, special skills in domains such as verbal and visuospatial ability. While it cannot be claimed that everyone agrees on what the results mean, most people now accept that for practical purposes it is reasonable to suppose that both are involved. In brief, the evidence in favour of some kind of general intellectual capacity is that people who are superior (or inferior) on one type of task tend also to be superior (or inferior) on others. Moreover, general measures of intelligence tend to have considerable powers to predict a persons performance on a wide range of tasks requiring special skills. Nevertheless, it is plain that it is not at all uncommon for individuals to be very good at some sorts of task and yet quite poor at some others. Furthermore the influences that affect verbal skills are not quite the same as those that affect other skills. This approach to investigating intelligence is based on the nature of the task involved, but studies of age-related changes show that this is not the only, or necessarily the most important, approach. For instance, some decades ago, Horn and Cattell argued for a differentiation between what they termed fluid and crystallised intelligence. Fluid abilities are best assessed by tests that require mental manipulation of abstract symbols. Crystallised abilities, by contrast, reflect knowledge of the environment in which we live and past experience of similar tasks; they may be assessed by tests of comprehension and information. It seems that fluid abilities peak in early adult life, whereas crystallised abilities increase up to advanced old age. Developmental studies also show that the interconnections between different skills vary with age. Thus in the first year of life an interest in perceptual patterns is a major contributor to cognitive abilities, whereas verbal abilities are more important later on. These findings seemed to suggest a substantial lack of continuity between infancy and middle childhood. However, it is important to realise that the apparent discontinuity will vary according to which of the cognitive skills were assessed in infancy. It has been found that tests of coping with novelty do predict later intelligence. These findings reinforce the view that young childrens intellectual performance needs to be assessed from their interest in and curiosity about the environment, and the extent to which this is applied to new situations, as well as by standardised intelligence testing. These psychometric approaches have focused on childrens increase in cognitive skills as they grow older. Piaget brought about a revolution in the approach to cognitive development through his arguments (backed up by observations) that the focus should be on the thinking processes involved rather than on levels of cognitive achievement. These ideas of Piaget gave rise to an immense body of research and it would be true to say that subsequent thinking has been heavily dependent on his genius in opening up new ways of thinking about cognitive development. Nevertheless, most of his concepts have had to be so radically revised, or rejected, that his theory no longer provides an appropriate basis for thinking about cognitive development. To appreciate why that is so, we need to focus on some rather different elements of Piagets theorising. The first element, which has stood the test of time, is his view that the child is an active agent of learning and of the importance of this activity in cognitive development. Numerous studies have shown how infants actively scan their environment; how they prefer patterned to non-patterned objects, how they choose novel over familiar stimuli, and how they explore their environment as if to see how it works. Childrens questions and comments vividly illustrate the ways in which they are constantly constructing schemes of what they know and trying out their ideas of how to fit new knowledge into those schemes or deciding that the schemes need modification. Moreover, a variety of studies have shown that active experiences have a greater effect on learning than comparable passive experiences. However, a second element concerns the notion that development proceeds through a series of separate stages that have to be gone through step-by-step, in a set order, each of which is characterised by a particular cognitive structure. That has turned out to be a rather misleading way of thinking about cognitive development, although it is not wholly wrong.", "hypothesis": "A surprising number of academics have come to the same conclusion about what the term intelligence means.", "gold_label": "contradiction"}
{"uid": "id_200", "premise": "The growth of intelligence No one doubts that intelligence develops as children grow older. Yet the concept of intelligence has proved both quite difficult to define in unambiguous terms and unexpectedly controversial in some respects. Although, at one level, there seem to be almost as many definitions of intelligence as people who have tried to define it, there is broad agreement on two key features. That is, intelligence involves the capacity not only to learn from experience but also to adapt to ones environment. However, we cannot leave the concept there. Before turning to what is known about the development of intelligence, it is necessary to consider whether we are considering the growth of one or many skills. That question has been tackled in rather different ways by psychometricians and by developmentalists. The former group has examined the issue by determining how childrens abilities on a wide range of tasks intercorrelate, or go together. Statistical techniques have been used to find out whether the patterns are best explained by one broad underlying capacity, general intelligence, or by a set of multiple, relatively separate, special skills in domains such as verbal and visuospatial ability. While it cannot be claimed that everyone agrees on what the results mean, most people now accept that for practical purposes it is reasonable to suppose that both are involved. In brief, the evidence in favour of some kind of general intellectual capacity is that people who are superior (or inferior) on one type of task tend also to be superior (or inferior) on others. Moreover, general measures of intelligence tend to have considerable powers to predict a persons performance on a wide range of tasks requiring special skills. Nevertheless, it is plain that it is not at all uncommon for individuals to be very good at some sorts of task and yet quite poor at some others. Furthermore the influences that affect verbal skills are not quite the same as those that affect other skills. This approach to investigating intelligence is based on the nature of the task involved, but studies of age-related changes show that this is not the only, or necessarily the most important, approach. For instance, some decades ago, Horn and Cattell argued for a differentiation between what they termed fluid and crystallised intelligence. Fluid abilities are best assessed by tests that require mental manipulation of abstract symbols. Crystallised abilities, by contrast, reflect knowledge of the environment in which we live and past experience of similar tasks; they may be assessed by tests of comprehension and information. It seems that fluid abilities peak in early adult life, whereas crystallised abilities increase up to advanced old age. Developmental studies also show that the interconnections between different skills vary with age. Thus in the first year of life an interest in perceptual patterns is a major contributor to cognitive abilities, whereas verbal abilities are more important later on. These findings seemed to suggest a substantial lack of continuity between infancy and middle childhood. However, it is important to realise that the apparent discontinuity will vary according to which of the cognitive skills were assessed in infancy. It has been found that tests of coping with novelty do predict later intelligence. These findings reinforce the view that young childrens intellectual performance needs to be assessed from their interest in and curiosity about the environment, and the extent to which this is applied to new situations, as well as by standardised intelligence testing. These psychometric approaches have focused on childrens increase in cognitive skills as they grow older. Piaget brought about a revolution in the approach to cognitive development through his arguments (backed up by observations) that the focus should be on the thinking processes involved rather than on levels of cognitive achievement. These ideas of Piaget gave rise to an immense body of research and it would be true to say that subsequent thinking has been heavily dependent on his genius in opening up new ways of thinking about cognitive development. Nevertheless, most of his concepts have had to be so radically revised, or rejected, that his theory no longer provides an appropriate basis for thinking about cognitive development. To appreciate why that is so, we need to focus on some rather different elements of Piagets theorising. The first element, which has stood the test of time, is his view that the child is an active agent of learning and of the importance of this activity in cognitive development. Numerous studies have shown how infants actively scan their environment; how they prefer patterned to non-patterned objects, how they choose novel over familiar stimuli, and how they explore their environment as if to see how it works. Childrens questions and comments vividly illustrate the ways in which they are constantly constructing schemes of what they know and trying out their ideas of how to fit new knowledge into those schemes or deciding that the schemes need modification. Moreover, a variety of studies have shown that active experiences have a greater effect on learning than comparable passive experiences. However, a second element concerns the notion that development proceeds through a series of separate stages that have to be gone through step-by-step, in a set order, each of which is characterised by a particular cognitive structure. That has turned out to be a rather misleading way of thinking about cognitive development, although it is not wholly wrong.", "hypothesis": "The elderly perform less well on comprehension tests than young adults.", "gold_label": "contradiction"}
{"uid": "id_201", "premise": "The growth of intelligence No one doubts that intelligence develops as children grow older. Yet the concept of intelligence has proved both quite difficult to define in unambiguous terms and unexpectedly controversial in some respects. Although, at one level, there seem to be almost as many definitions of intelligence as people who have tried to define it, there is broad agreement on two key features. That is, intelligence involves the capacity not only to learn from experience but also to adapt to ones environment. However, we cannot leave the concept there. Before turning to what is known about the development of intelligence, it is necessary to consider whether we are considering the growth of one or many skills. That question has been tackled in rather different ways by psychometricians and by developmentalists. The former group has examined the issue by determining how childrens abilities on a wide range of tasks intercorrelate, or go together. Statistical techniques have been used to find out whether the patterns are best explained by one broad underlying capacity, general intelligence, or by a set of multiple, relatively separate, special skills in domains such as verbal and visuospatial ability. While it cannot be claimed that everyone agrees on what the results mean, most people now accept that for practical purposes it is reasonable to suppose that both are involved. In brief, the evidence in favour of some kind of general intellectual capacity is that people who are superior (or inferior) on one type of task tend also to be superior (or inferior) on others. Moreover, general measures of intelligence tend to have considerable powers to predict a persons performance on a wide range of tasks requiring special skills. Nevertheless, it is plain that it is not at all uncommon for individuals to be very good at some sorts of task and yet quite poor at some others. Furthermore the influences that affect verbal skills are not quite the same as those that affect other skills. This approach to investigating intelligence is based on the nature of the task involved, but studies of age-related changes show that this is not the only, or necessarily the most important, approach. For instance, some decades ago, Horn and Cattell argued for a differentiation between what they termed fluid and crystallised intelligence. Fluid abilities are best assessed by tests that require mental manipulation of abstract symbols. Crystallised abilities, by contrast, reflect knowledge of the environment in which we live and past experience of similar tasks; they may be assessed by tests of comprehension and information. It seems that fluid abilities peak in early adult life, whereas crystallised abilities increase up to advanced old age. Developmental studies also show that the interconnections between different skills vary with age. Thus in the first year of life an interest in perceptual patterns is a major contributor to cognitive abilities, whereas verbal abilities are more important later on. These findings seemed to suggest a substantial lack of continuity between infancy and middle childhood. However, it is important to realise that the apparent discontinuity will vary according to which of the cognitive skills were assessed in infancy. It has been found that tests of coping with novelty do predict later intelligence. These findings reinforce the view that young childrens intellectual performance needs to be assessed from their interest in and curiosity about the environment, and the extent to which this is applied to new situations, as well as by standardised intelligence testing. These psychometric approaches have focused on childrens increase in cognitive skills as they grow older. Piaget brought about a revolution in the approach to cognitive development through his arguments (backed up by observations) that the focus should be on the thinking processes involved rather than on levels of cognitive achievement. These ideas of Piaget gave rise to an immense body of research and it would be true to say that subsequent thinking has been heavily dependent on his genius in opening up new ways of thinking about cognitive development. Nevertheless, most of his concepts have had to be so radically revised, or rejected, that his theory no longer provides an appropriate basis for thinking about cognitive development. To appreciate why that is so, we need to focus on some rather different elements of Piagets theorising. The first element, which has stood the test of time, is his view that the child is an active agent of learning and of the importance of this activity in cognitive development. Numerous studies have shown how infants actively scan their environment; how they prefer patterned to non-patterned objects, how they choose novel over familiar stimuli, and how they explore their environment as if to see how it works. Childrens questions and comments vividly illustrate the ways in which they are constantly constructing schemes of what they know and trying out their ideas of how to fit new knowledge into those schemes or deciding that the schemes need modification. Moreover, a variety of studies have shown that active experiences have a greater effect on learning than comparable passive experiences. However, a second element concerns the notion that development proceeds through a series of separate stages that have to be gone through step-by-step, in a set order, each of which is characterised by a particular cognitive structure. That has turned out to be a rather misleading way of thinking about cognitive development, although it is not wholly wrong.", "hypothesis": "We must take into account which skills are tested when comparing intelligence at different ages.", "gold_label": "entailment"}
{"uid": "id_202", "premise": "The growth of intelligence No one doubts that intelligence develops as children grow older. Yet the concept of intelligence has proved both quite difficult to define in unambiguous terms and unexpectedly controversial in some respects. Although, at one level, there seem to be almost as many definitions of intelligence as people who have tried to define it, there is broad agreement on two key features. That is, intelligence involves the capacity not only to learn from experience but also to adapt to ones environment. However, we cannot leave the concept there. Before turning to what is known about the development of intelligence, it is necessary to consider whether we are considering the growth of one or many skills. That question has been tackled in rather different ways by psychometricians and by developmentalists. The former group has examined the issue by determining how childrens abilities on a wide range of tasks intercorrelate, or go together. Statistical techniques have been used to find out whether the patterns are best explained by one broad underlying capacity, general intelligence, or by a set of multiple, relatively separate, special skills in domains such as verbal and visuospatial ability. While it cannot be claimed that everyone agrees on what the results mean, most people now accept that for practical purposes it is reasonable to suppose that both are involved. In brief, the evidence in favour of some kind of general intellectual capacity is that people who are superior (or inferior) on one type of task tend also to be superior (or inferior) on others. Moreover, general measures of intelligence tend to have considerable powers to predict a persons performance on a wide range of tasks requiring special skills. Nevertheless, it is plain that it is not at all uncommon for individuals to be very good at some sorts of task and yet quite poor at some others. Furthermore the influences that affect verbal skills are not quite the same as those that affect other skills. This approach to investigating intelligence is based on the nature of the task involved, but studies of age-related changes show that this is not the only, or necessarily the most important, approach. For instance, some decades ago, Horn and Cattell argued for a differentiation between what they termed fluid and crystallised intelligence. Fluid abilities are best assessed by tests that require mental manipulation of abstract symbols. Crystallised abilities, by contrast, reflect knowledge of the environment in which we live and past experience of similar tasks; they may be assessed by tests of comprehension and information. It seems that fluid abilities peak in early adult life, whereas crystallised abilities increase up to advanced old age. Developmental studies also show that the interconnections between different skills vary with age. Thus in the first year of life an interest in perceptual patterns is a major contributor to cognitive abilities, whereas verbal abilities are more important later on. These findings seemed to suggest a substantial lack of continuity between infancy and middle childhood. However, it is important to realise that the apparent discontinuity will vary according to which of the cognitive skills were assessed in infancy. It has been found that tests of coping with novelty do predict later intelligence. These findings reinforce the view that young childrens intellectual performance needs to be assessed from their interest in and curiosity about the environment, and the extent to which this is applied to new situations, as well as by standardised intelligence testing. These psychometric approaches have focused on childrens increase in cognitive skills as they grow older. Piaget brought about a revolution in the approach to cognitive development through his arguments (backed up by observations) that the focus should be on the thinking processes involved rather than on levels of cognitive achievement. These ideas of Piaget gave rise to an immense body of research and it would be true to say that subsequent thinking has been heavily dependent on his genius in opening up new ways of thinking about cognitive development. Nevertheless, most of his concepts have had to be so radically revised, or rejected, that his theory no longer provides an appropriate basis for thinking about cognitive development. To appreciate why that is so, we need to focus on some rather different elements of Piagets theorising. The first element, which has stood the test of time, is his view that the child is an active agent of learning and of the importance of this activity in cognitive development. Numerous studies have shown how infants actively scan their environment; how they prefer patterned to non-patterned objects, how they choose novel over familiar stimuli, and how they explore their environment as if to see how it works. Childrens questions and comments vividly illustrate the ways in which they are constantly constructing schemes of what they know and trying out their ideas of how to fit new knowledge into those schemes or deciding that the schemes need modification. Moreover, a variety of studies have shown that active experiences have a greater effect on learning than comparable passive experiences. However, a second element concerns the notion that development proceeds through a series of separate stages that have to be gone through step-by-step, in a set order, each of which is characterised by a particular cognitive structure. That has turned out to be a rather misleading way of thinking about cognitive development, although it is not wholly wrong.", "hypothesis": "Piagets work influenced theoretical studies more than practical research.", "gold_label": "neutral"}
{"uid": "id_203", "premise": "The growth of intelligence No one doubts that intelligence develops as children grow older. Yet the concept of intelligence has proved both quite difficult to define in unambiguous terms and unexpectedly controversial in some respects. Although, at one level, there seem to be almost as many definitions of intelligence as people who have tried to define it, there is broad agreement on two key features. That is, intelligence involves the capacity not only to learn from experience but also to adapt to ones environment. However, we cannot leave the concept there. Before turning to what is known about the development of intelligence, it is necessary to consider whether we are considering the growth of one or many skills. That question has been tackled in rather different ways by psychometricians and by developmentalists. The former group has examined the issue by determining how childrens abilities on a wide range of tasks intercorrelate, or go together. Statistical techniques have been used to find out whether the patterns are best explained by one broad underlying capacity, general intelligence, or by a set of multiple, relatively separate, special skills in domains such as verbal and visuospatial ability. While it cannot be claimed that everyone agrees on what the results mean, most people now accept that for practical purposes it is reasonable to suppose that both are involved. In brief, the evidence in favour of some kind of general intellectual capacity is that people who are superior (or inferior) on one type of task tend also to be superior (or inferior) on others. Moreover, general measures of intelligence tend to have considerable powers to predict a persons performance on a wide range of tasks requiring special skills. Nevertheless, it is plain that it is not at all uncommon for individuals to be very good at some sorts of task and yet quite poor at some others. Furthermore the influences that affect verbal skills are not quite the same as those that affect other skills. This approach to investigating intelligence is based on the nature of the task involved, but studies of age-related changes show that this is not the only, or necessarily the most important, approach. For instance, some decades ago, Horn and Cattell argued for a differentiation between what they termed fluid and crystallised intelligence. Fluid abilities are best assessed by tests that require mental manipulation of abstract symbols. Crystallised abilities, by contrast, reflect knowledge of the environment in which we live and past experience of similar tasks; they may be assessed by tests of comprehension and information. It seems that fluid abilities peak in early adult life, whereas crystallised abilities increase up to advanced old age. Developmental studies also show that the interconnections between different skills vary with age. Thus in the first year of life an interest in perceptual patterns is a major contributor to cognitive abilities, whereas verbal abilities are more important later on. These findings seemed to suggest a substantial lack of continuity between infancy and middle childhood. However, it is important to realise that the apparent discontinuity will vary according to which of the cognitive skills were assessed in infancy. It has been found that tests of coping with novelty do predict later intelligence. These findings reinforce the view that young childrens intellectual performance needs to be assessed from their interest in and curiosity about the environment, and the extent to which this is applied to new situations, as well as by standardised intelligence testing. These psychometric approaches have focused on childrens increase in cognitive skills as they grow older. Piaget brought about a revolution in the approach to cognitive development through his arguments (backed up by observations) that the focus should be on the thinking processes involved rather than on levels of cognitive achievement. These ideas of Piaget gave rise to an immense body of research and it would be true to say that subsequent thinking has been heavily dependent on his genius in opening up new ways of thinking about cognitive development. Nevertheless, most of his concepts have had to be so radically revised, or rejected, that his theory no longer provides an appropriate basis for thinking about cognitive development. To appreciate why that is so, we need to focus on some rather different elements of Piagets theorising. The first element, which has stood the test of time, is his view that the child is an active agent of learning and of the importance of this activity in cognitive development. Numerous studies have shown how infants actively scan their environment; how they prefer patterned to non-patterned objects, how they choose novel over familiar stimuli, and how they explore their environment as if to see how it works. Childrens questions and comments vividly illustrate the ways in which they are constantly constructing schemes of what they know and trying out their ideas of how to fit new knowledge into those schemes or deciding that the schemes need modification. Moreover, a variety of studies have shown that active experiences have a greater effect on learning than comparable passive experiences. However, a second element concerns the notion that development proceeds through a series of separate stages that have to be gone through step-by-step, in a set order, each of which is characterised by a particular cognitive structure. That has turned out to be a rather misleading way of thinking about cognitive development, although it is not wholly wrong.", "hypothesis": "Piagets emphasis on active learning has been discredited by later researchers.", "gold_label": "contradiction"}
{"uid": "id_204", "premise": "The growth of intelligence No one doubts that intelligence develops as children grow older. Yet the concept of intelligence has proved both quite difficult to define in unambiguous terms and unexpectedly controversial in some respects. Although, at one level, there seem to be almost as many definitions of intelligence as people who have tried to define it, there is broad agreement on two key features. That is, intelligence involves the capacity not only to learn from experience but also to adapt to ones environment. However, we cannot leave the concept there. Before turning to what is known about the development of intelligence, it is necessary to consider whether we are considering the growth of one or many skills. That question has been tackled in rather different ways by psychometricians and by developmentalists. The former group has examined the issue by determining how childrens abilities on a wide range of tasks intercorrelate, or go together. Statistical techniques have been used to find out whether the patterns are best explained by one broad underlying capacity, general intelligence, or by a set of multiple, relatively separate, special skills in domains such as verbal and visuospatial ability. While it cannot be claimed that everyone agrees on what the results mean, most people now accept that for practical purposes it is reasonable to suppose that both are involved. In brief, the evidence in favour of some kind of general intellectual capacity is that people who are superior (or inferior) on one type of task tend also to be superior (or inferior) on others. Moreover, general measures of intelligence tend to have considerable powers to predict a persons performance on a wide range of tasks requiring special skills. Nevertheless, it is plain that it is not at all uncommon for individuals to be very good at some sorts of task and yet quite poor at some others. Furthermore the influences that affect verbal skills are not quite the same as those that affect other skills. This approach to investigating intelligence is based on the nature of the task involved, but studies of age-related changes show that this is not the only, or necessarily the most important, approach. For instance, some decades ago, Horn and Cattell argued for a differentiation between what they termed fluid and crystallised intelligence. Fluid abilities are best assessed by tests that require mental manipulation of abstract symbols. Crystallised abilities, by contrast, reflect knowledge of the environment in which we live and past experience of similar tasks; they may be assessed by tests of comprehension and information. It seems that fluid abilities peak in early adult life, whereas crystallised abilities increase up to advanced old age. Developmental studies also show that the interconnections between different skills vary with age. Thus in the first year of life an interest in perceptual patterns is a major contributor to cognitive abilities, whereas verbal abilities are more important later on. These findings seemed to suggest a substantial lack of continuity between infancy and middle childhood. However, it is important to realise that the apparent discontinuity will vary according to which of the cognitive skills were assessed in infancy. It has been found that tests of coping with novelty do predict later intelligence. These findings reinforce the view that young childrens intellectual performance needs to be assessed from their interest in and curiosity about the environment, and the extent to which this is applied to new situations, as well as by standardised intelligence testing. These psychometric approaches have focused on childrens increase in cognitive skills as they grow older. Piaget brought about a revolution in the approach to cognitive development through his arguments (backed up by observations) that the focus should be on the thinking processes involved rather than on levels of cognitive achievement. These ideas of Piaget gave rise to an immense body of research and it would be true to say that subsequent thinking has been heavily dependent on his genius in opening up new ways of thinking about cognitive development. Nevertheless, most of his concepts have had to be so radically revised, or rejected, that his theory no longer provides an appropriate basis for thinking about cognitive development. To appreciate why that is so, we need to focus on some rather different elements of Piagets theorising. The first element, which has stood the test of time, is his view that the child is an active agent of learning and of the importance of this activity in cognitive development. Numerous studies have shown how infants actively scan their environment; how they prefer patterned to non-patterned objects, how they choose novel over familiar stimuli, and how they explore their environment as if to see how it works. Childrens questions and comments vividly illustrate the ways in which they are constantly constructing schemes of what they know and trying out their ideas of how to fit new knowledge into those schemes or deciding that the schemes need modification. Moreover, a variety of studies have shown that active experiences have a greater effect on learning than comparable passive experiences. However, a second element concerns the notion that development proceeds through a series of separate stages that have to be gone through step-by-step, in a set order, each of which is characterised by a particular cognitive structure. That has turned out to be a rather misleading way of thinking about cognitive development, although it is not wholly wrong.", "hypothesis": "A general test of intelligence is unlikely to indicate the level of performance in every type of task.", "gold_label": "entailment"}
{"uid": "id_205", "premise": "The guillotine was a machine used to kill people by chopping off their head. It consists of a heavy blade attached to a frame. When the blade was released, it would fall down under its own weight and chop off the victims head, killing them instantly. It was commonly used in France during the French Revolution as it was the only legal method of execution in order to enact the death penalty. The guillotine was named after a French doctor called Joseph Guillotin. He decided that a more humane way of executing someone was needed as he realised he was unable to get rid of the death penalty. He decided that using an automatic mechanical device for decapitation would be more humane than by a person with an axe. The first guillotine built was then tested on animals to see if the axe would have enough force to decapitate its victim. Before the guillotine was used in execution, the criminal would be hanged. This was seen to be less humane as the victim was supposed to die from the impact of the rope snapping their necks, however this did not happen all the time. The victim could be in agony for up to forty minutes before eventually dying from asphyxiation.", "hypothesis": "Joseph Guillotin agreed with the death penalty.", "gold_label": "contradiction"}
{"uid": "id_206", "premise": "The guillotine was a machine used to kill people by chopping off their head. It consists of a heavy blade attached to a frame. When the blade was released, it would fall down under its own weight and chop off the victims head, killing them instantly. It was commonly used in France during the French Revolution as it was the only legal method of execution in order to enact the death penalty. The guillotine was named after a French doctor called Joseph Guillotin. He decided that a more humane way of executing someone was needed as he realised he was unable to get rid of the death penalty. He decided that using an automatic mechanical device for decapitation would be more humane than by a person with an axe. The first guillotine built was then tested on animals to see if the axe would have enough force to decapitate its victim. Before the guillotine was used in execution, the criminal would be hanged. This was seen to be less humane as the victim was supposed to die from the impact of the rope snapping their necks, however this did not happen all the time. The victim could be in agony for up to forty minutes before eventually dying from asphyxiation.", "hypothesis": "During the French Revolution, hanging was the common form of execution.", "gold_label": "contradiction"}
{"uid": "id_207", "premise": "The guillotine was a machine used to kill people by chopping off their head. It consists of a heavy blade attached to a frame. When the blade was released, it would fall down under its own weight and chop off the victims head, killing them instantly. It was commonly used in France during the French Revolution as it was the only legal method of execution in order to enact the death penalty. The guillotine was named after a French doctor called Joseph Guillotin. He decided that a more humane way of executing someone was needed as he realised he was unable to get rid of the death penalty. He decided that using an automatic mechanical device for decapitation would be more humane than by a person with an axe. The first guillotine built was then tested on animals to see if the axe would have enough force to decapitate its victim. Before the guillotine was used in execution, the criminal would be hanged. This was seen to be less humane as the victim was supposed to die from the impact of the rope snapping their necks, however this did not happen all the time. The victim could be in agony for up to forty minutes before eventually dying from asphyxiation.", "hypothesis": "The guillotine was seen as being more humane as it was automatic with the blade falling through its own weight.", "gold_label": "entailment"}
{"uid": "id_208", "premise": "The guillotine was a machine used to kill people by chopping off their head. It consists of a heavy blade attached to a frame. When the blade was released, it would fall down under its own weight and chop off the victims head, killing them instantly. It was commonly used in France during the French Revolution as it was the only legal method of execution in order to enact the death penalty. The guillotine was named after a French doctor called Joseph Guillotin. He decided that a more humane way of executing someone was needed as he realised he was unable to get rid of the death penalty. He decided that using an automatic mechanical device for decapitation would be more humane than by a person with an axe. The first guillotine built was then tested on animals to see if the axe would have enough force to decapitate its victim. Before the guillotine was used in execution, the criminal would be hanged. This was seen to be less humane as the victim was supposed to die from the impact of the rope snapping their necks, however this did not happen all the time. The victim could be in agony for up to forty minutes before eventually dying from asphyxiation.", "hypothesis": "Hanging usually causes death by asphyxiation.", "gold_label": "contradiction"}
{"uid": "id_209", "premise": "The guillotine was a machine used to kill people by chopping off their head. It consists of a heavy blade attached to a frame. When the blade was released, it would fall down under its own weight and chop off the victims head, killing them instantly. It was commonly used in France during the French Revolution as it was the only legal method of execution in order to enact the death penalty. The guillotine was named after a French doctor called Joseph Guillotin. He decided that a more humane way of executing someone was needed as he realised he was unable to get rid of the death penalty. He decided that using an automatic mechanical device for decapitation would be more humane than by a person with an axe. The first guillotine built was then tested on animals to see if the axe would have enough force to decapitate its victim. Before the guillotine was used in execution, the criminal would be hanged. This was seen to be less humane as the victim was supposed to die from the impact of the rope snapping their necks, however this did not happen all the time. The victim could be in agony for up to forty minutes before eventually dying from asphyxiation.", "hypothesis": "According to the passage, the guillotine was used for execution before the French Revolution.", "gold_label": "neutral"}
{"uid": "id_210", "premise": "The happy planet index is an index of human wellbeing and environmental impact that was introduced by the new economics foundation. The index is designed up challenge the well- established indices of countries development, such as gross domestic product, human development index and quality of life index. Furthermore, it is believed that the notion of sustainable development requires a measure of environment costs in pursuing happiness and health. On this index Costa Rica was ranked the highest in HPI, and Zimbabwe was ranked the lowest in HPI.", "hypothesis": "happy planet index challenges gross domestic product", "gold_label": "entailment"}
{"uid": "id_211", "premise": "The happy planet index is an index of human wellbeing and environmental impact that was introduced by the new economics foundation. The index is designed up challenge the well- established indices of countries development, such as gross domestic product, human development index and quality of life index. Furthermore, it is believed that the notion of sustainable development requires a measure of environment costs in pursuing happiness and health. On this index Costa Rica was ranked the highest in HPI, and Zimbabwe was ranked the lowest in HPI.", "hypothesis": "happy planet index challenges quality of life index", "gold_label": "entailment"}
{"uid": "id_212", "premise": "The happy planet index is an index of human wellbeing and environmental impact that was introduced by the new economics foundation. The index is designed up challenge the well- established indices of countries development, such as gross domestic product, human development index and quality of life index. Furthermore, it is believed that the notion of sustainable development requires a measure of environment costs in pursuing happiness and health. On this index Costa Rica was ranked the highest in HPI, and Zimbabwe was ranked the lowest in HPI.", "hypothesis": "happy planet index challenges human development index.", "gold_label": "entailment"}
{"uid": "id_213", "premise": "The happy planet index is an index of human wellbeing and environmental impact that was introduced by the new economics foundation. The index is designed up challenge the well- established indices of countries development, such as gross domestic product, human development index and quality of life index. Furthermore, it is believed that the notion of sustainable development requires a measure of environment costs in pursuing happiness and health. On this index Costa Rica was ranked the highest in HPI, and Zimbabwe was ranked the lowest in HPI.", "hypothesis": "happy planet index challenges gross national happiness.", "gold_label": "neutral"}
{"uid": "id_214", "premise": "The head of the organization congratulated the entire staff in his speech for their sincere effort to bring down the deficit and urged them to give their best for attaining a more profitable position in future.", "hypothesis": "The employees may get motivated and maintain and if possible enhance their present level of work.", "gold_label": "entailment"}
{"uid": "id_215", "premise": "The head of the organization congratulated the entire staff in his speech for their sincere effort to bring down the deficit and urged them to give their best for attaining a more profitable position in future.", "hypothesis": "The employees may now relax and slow down in their day to day work as there is no immediate threat of huge deficit", "gold_label": "neutral"}
{"uid": "id_216", "premise": "The hidden histories of exploration exhibition We have all heard tales of lone, heroic explorers, but what about the local individuals who guided and protected European explorers in many different parts of the globe? Or the go-betweens including interpreters and traders who translated the needs and demands of explorers into a language that locals could understand? Such questions have received surprisingly little attention in standard histories, where European explorers are usually the heroes, sometimes the villains. The Hidden Histories of Exploration exhibition at Britains Royal Geographical Society in London sets out to present an alternative view, in which exploration is a fundamentally collective experience of work, involving many different people. Many of the most famous examples of explorers said to have been lone travellers say, Mungo Park or David Livingstone in Africa were anything but alone on their travels. They depended on local support of various kinds for food, shelter, protection, information, guidance and solace as well as on other resources from elsewhere. The Royal Geographical Society (RGS) seeks to record this story in its Hidden Histories project, using its astonishingly rich collections. The storage of geographical information was one of the main rationales for the foundation of the RGS in 1830, and the Societys collections now contain more than two million individual items, including books, manuscripts, maps, photographs art-works, artefacts and film a rich storehouse of material reflecting the wide geographical extent of British interest across the globe. In addition to their remarkable scope and range, these collections contain a striking visual record of exploration: the impulse to collect the world is reflected in a large and diverse image archive. For the researcher, this archive can vield many surprises: materials gathered for one purpose say, maps relating to an international boundary dispute or photographs taken on a scientific expedition may today be put to quite different uses In their published narratives, European explorers rarely portrayed themselves as vulnerable or dependent on others, despite the fact that without this support they were quite literally lost. Archival research confirms that Europeans were not merely dependent on the work of porters soldiers translators, cooks, pilots, guides, hunters and collectors: they also relied on local expertise. Such assistance was essential in identifying potential dangers poisonous species, unpredictable rivers, uncharted territories which could mean the difference between life and death. The assistants themselves were usually in a strong bargaining position. In the Amazon, for example access to entire regions would depend on the willingness of local crew members and other assistants to enter areas inhabited by relatively powerful Amerindian groups. In an account of his journey across South America published in 1836, William Smyth thus complained of frequent desertion by his helpers: without them it was impossible to get on. Those providing local support and information to explorers were themselves often not locals. For example, the history of African exploration in the nineteenth century is dominated by the use of Zanzibar as a recruiting station for porters, soldiers and guides who would then travel thousands of miles across the continent. In some accounts, the leading African members of expedition parties the officers or foremen are identified, and their portraits published alongside those of European explorers. The information provided by locals and intermediaries was of potential importance to geographical science. How was this evidence judged? The formal procedures of scientific evaluation provided one framework. Alongside these were more common sense notions of veracity and reliability, religiously-inspired judgments about the authenticity of testimony, and the routine procedures for cross-checking empirical observations developed in many professions. Given explorers need for local information and support, it was in their interests to develop effective working partnerships with knowledgeable intermediaries who could act as brokers in their dealings with local inhabitants. Many of these people acquired far more experience of exploration than most Europeans could hope to attain. Some managed large groups of men and women, piloted the explorers river craft, or undertook mapping work. The tradition was continued with the Everest expeditions in the 1920s and 1930s, which regularly employed the Tibetan interpreter Karma Paul. In Europe, exploration was increasingly thought of as a career; the same might be said of the non-Europeans on whom their expeditions depended. These individuals often forged close working relationships with European explorers. Such partnerships depended on mutual respect, though they were not always easy or intimate, as is particularly clear from the history of the Everest expeditions depicted in the Hidden Histories exhibition. The entire back wall is covered by an enlarged version of a single sheet of photographs of Sherpas taken during the 1936 Everest expedition. The document is a powerful reminder of the manpower on which European mountaineering expeditions depended, and also of the importance of local knowledge and assistance. Transformed from archive to wall display, it tells a powerful story through the medium of individual portraits including Karma Paul, veteran of previous expeditions, and the young Tensing Norgay, 17 years before his successful 1953 ascent. This was a highly charged and transitional moment as the contribution of the Sherpas, depicted here with identity tags round their necks, was beginning to be much more widely recognised. These touching portraits encourage us to see them as agents rather than simply colonial subjects or paid employees. Here is a living history, which looks beyond what we already know about exploration: a larger history in which we come to recognise the contribution of everyone involved.", "hypothesis": "In their publications, European explorers often describe their dependence on their helpers.", "gold_label": "contradiction"}
{"uid": "id_217", "premise": "The hidden histories of exploration exhibition We have all heard tales of lone, heroic explorers, but what about the local individuals who guided and protected European explorers in many different parts of the globe? Or the go-betweens including interpreters and traders who translated the needs and demands of explorers into a language that locals could understand? Such questions have received surprisingly little attention in standard histories, where European explorers are usually the heroes, sometimes the villains. The Hidden Histories of Exploration exhibition at Britains Royal Geographical Society in London sets out to present an alternative view, in which exploration is a fundamentally collective experience of work, involving many different people. Many of the most famous examples of explorers said to have been lone travellers say, Mungo Park or David Livingstone in Africa were anything but alone on their travels. They depended on local support of various kinds for food, shelter, protection, information, guidance and solace as well as on other resources from elsewhere. The Royal Geographical Society (RGS) seeks to record this story in its Hidden Histories project, using its astonishingly rich collections. The storage of geographical information was one of the main rationales for the foundation of the RGS in 1830, and the Societys collections now contain more than two million individual items, including books, manuscripts, maps, photographs art-works, artefacts and film a rich storehouse of material reflecting the wide geographical extent of British interest across the globe. In addition to their remarkable scope and range, these collections contain a striking visual record of exploration: the impulse to collect the world is reflected in a large and diverse image archive. For the researcher, this archive can vield many surprises: materials gathered for one purpose say, maps relating to an international boundary dispute or photographs taken on a scientific expedition may today be put to quite different uses In their published narratives, European explorers rarely portrayed themselves as vulnerable or dependent on others, despite the fact that without this support they were quite literally lost. Archival research confirms that Europeans were not merely dependent on the work of porters soldiers translators, cooks, pilots, guides, hunters and collectors: they also relied on local expertise. Such assistance was essential in identifying potential dangers poisonous species, unpredictable rivers, uncharted territories which could mean the difference between life and death. The assistants themselves were usually in a strong bargaining position. In the Amazon, for example access to entire regions would depend on the willingness of local crew members and other assistants to enter areas inhabited by relatively powerful Amerindian groups. In an account of his journey across South America published in 1836, William Smyth thus complained of frequent desertion by his helpers: without them it was impossible to get on. Those providing local support and information to explorers were themselves often not locals. For example, the history of African exploration in the nineteenth century is dominated by the use of Zanzibar as a recruiting station for porters, soldiers and guides who would then travel thousands of miles across the continent. In some accounts, the leading African members of expedition parties the officers or foremen are identified, and their portraits published alongside those of European explorers. The information provided by locals and intermediaries was of potential importance to geographical science. How was this evidence judged? The formal procedures of scientific evaluation provided one framework. Alongside these were more common sense notions of veracity and reliability, religiously-inspired judgments about the authenticity of testimony, and the routine procedures for cross-checking empirical observations developed in many professions. Given explorers need for local information and support, it was in their interests to develop effective working partnerships with knowledgeable intermediaries who could act as brokers in their dealings with local inhabitants. Many of these people acquired far more experience of exploration than most Europeans could hope to attain. Some managed large groups of men and women, piloted the explorers river craft, or undertook mapping work. The tradition was continued with the Everest expeditions in the 1920s and 1930s, which regularly employed the Tibetan interpreter Karma Paul. In Europe, exploration was increasingly thought of as a career; the same might be said of the non-Europeans on whom their expeditions depended. These individuals often forged close working relationships with European explorers. Such partnerships depended on mutual respect, though they were not always easy or intimate, as is particularly clear from the history of the Everest expeditions depicted in the Hidden Histories exhibition. The entire back wall is covered by an enlarged version of a single sheet of photographs of Sherpas taken during the 1936 Everest expedition. The document is a powerful reminder of the manpower on which European mountaineering expeditions depended, and also of the importance of local knowledge and assistance. Transformed from archive to wall display, it tells a powerful story through the medium of individual portraits including Karma Paul, veteran of previous expeditions, and the young Tensing Norgay, 17 years before his successful 1953 ascent. This was a highly charged and transitional moment as the contribution of the Sherpas, depicted here with identity tags round their necks, was beginning to be much more widely recognised. These touching portraits encourage us to see them as agents rather than simply colonial subjects or paid employees. Here is a living history, which looks beyond what we already know about exploration: a larger history in which we come to recognise the contribution of everyone involved.", "hypothesis": "The Hidden Histories of Exploration exhibition aims to show the wide range of people involved in expeditions.", "gold_label": "entailment"}
{"uid": "id_218", "premise": "The hidden histories of exploration exhibition We have all heard tales of lone, heroic explorers, but what about the local individuals who guided and protected European explorers in many different parts of the globe? Or the go-betweens including interpreters and traders who translated the needs and demands of explorers into a language that locals could understand? Such questions have received surprisingly little attention in standard histories, where European explorers are usually the heroes, sometimes the villains. The Hidden Histories of Exploration exhibition at Britains Royal Geographical Society in London sets out to present an alternative view, in which exploration is a fundamentally collective experience of work, involving many different people. Many of the most famous examples of explorers said to have been lone travellers say, Mungo Park or David Livingstone in Africa were anything but alone on their travels. They depended on local support of various kinds for food, shelter, protection, information, guidance and solace as well as on other resources from elsewhere. The Royal Geographical Society (RGS) seeks to record this story in its Hidden Histories project, using its astonishingly rich collections. The storage of geographical information was one of the main rationales for the foundation of the RGS in 1830, and the Societys collections now contain more than two million individual items, including books, manuscripts, maps, photographs art-works, artefacts and film a rich storehouse of material reflecting the wide geographical extent of British interest across the globe. In addition to their remarkable scope and range, these collections contain a striking visual record of exploration: the impulse to collect the world is reflected in a large and diverse image archive. For the researcher, this archive can vield many surprises: materials gathered for one purpose say, maps relating to an international boundary dispute or photographs taken on a scientific expedition may today be put to quite different uses In their published narratives, European explorers rarely portrayed themselves as vulnerable or dependent on others, despite the fact that without this support they were quite literally lost. Archival research confirms that Europeans were not merely dependent on the work of porters soldiers translators, cooks, pilots, guides, hunters and collectors: they also relied on local expertise. Such assistance was essential in identifying potential dangers poisonous species, unpredictable rivers, uncharted territories which could mean the difference between life and death. The assistants themselves were usually in a strong bargaining position. In the Amazon, for example access to entire regions would depend on the willingness of local crew members and other assistants to enter areas inhabited by relatively powerful Amerindian groups. In an account of his journey across South America published in 1836, William Smyth thus complained of frequent desertion by his helpers: without them it was impossible to get on. Those providing local support and information to explorers were themselves often not locals. For example, the history of African exploration in the nineteenth century is dominated by the use of Zanzibar as a recruiting station for porters, soldiers and guides who would then travel thousands of miles across the continent. In some accounts, the leading African members of expedition parties the officers or foremen are identified, and their portraits published alongside those of European explorers. The information provided by locals and intermediaries was of potential importance to geographical science. How was this evidence judged? The formal procedures of scientific evaluation provided one framework. Alongside these were more common sense notions of veracity and reliability, religiously-inspired judgments about the authenticity of testimony, and the routine procedures for cross-checking empirical observations developed in many professions. Given explorers need for local information and support, it was in their interests to develop effective working partnerships with knowledgeable intermediaries who could act as brokers in their dealings with local inhabitants. Many of these people acquired far more experience of exploration than most Europeans could hope to attain. Some managed large groups of men and women, piloted the explorers river craft, or undertook mapping work. The tradition was continued with the Everest expeditions in the 1920s and 1930s, which regularly employed the Tibetan interpreter Karma Paul. In Europe, exploration was increasingly thought of as a career; the same might be said of the non-Europeans on whom their expeditions depended. These individuals often forged close working relationships with European explorers. Such partnerships depended on mutual respect, though they were not always easy or intimate, as is particularly clear from the history of the Everest expeditions depicted in the Hidden Histories exhibition. The entire back wall is covered by an enlarged version of a single sheet of photographs of Sherpas taken during the 1936 Everest expedition. The document is a powerful reminder of the manpower on which European mountaineering expeditions depended, and also of the importance of local knowledge and assistance. Transformed from archive to wall display, it tells a powerful story through the medium of individual portraits including Karma Paul, veteran of previous expeditions, and the young Tensing Norgay, 17 years before his successful 1953 ascent. This was a highly charged and transitional moment as the contribution of the Sherpas, depicted here with identity tags round their necks, was beginning to be much more widely recognised. These touching portraits encourage us to see them as agents rather than simply colonial subjects or paid employees. Here is a living history, which looks beyond what we already know about exploration: a larger history in which we come to recognise the contribution of everyone involved.", "hypothesis": "The common belief about how Park and Livingstone travelled is accurate.", "gold_label": "contradiction"}
{"uid": "id_219", "premise": "The hidden histories of exploration exhibition We have all heard tales of lone, heroic explorers, but what about the local individuals who guided and protected European explorers in many different parts of the globe? Or the go-betweens including interpreters and traders who translated the needs and demands of explorers into a language that locals could understand? Such questions have received surprisingly little attention in standard histories, where European explorers are usually the heroes, sometimes the villains. The Hidden Histories of Exploration exhibition at Britains Royal Geographical Society in London sets out to present an alternative view, in which exploration is a fundamentally collective experience of work, involving many different people. Many of the most famous examples of explorers said to have been lone travellers say, Mungo Park or David Livingstone in Africa were anything but alone on their travels. They depended on local support of various kinds for food, shelter, protection, information, guidance and solace as well as on other resources from elsewhere. The Royal Geographical Society (RGS) seeks to record this story in its Hidden Histories project, using its astonishingly rich collections. The storage of geographical information was one of the main rationales for the foundation of the RGS in 1830, and the Societys collections now contain more than two million individual items, including books, manuscripts, maps, photographs art-works, artefacts and film a rich storehouse of material reflecting the wide geographical extent of British interest across the globe. In addition to their remarkable scope and range, these collections contain a striking visual record of exploration: the impulse to collect the world is reflected in a large and diverse image archive. For the researcher, this archive can vield many surprises: materials gathered for one purpose say, maps relating to an international boundary dispute or photographs taken on a scientific expedition may today be put to quite different uses In their published narratives, European explorers rarely portrayed themselves as vulnerable or dependent on others, despite the fact that without this support they were quite literally lost. Archival research confirms that Europeans were not merely dependent on the work of porters soldiers translators, cooks, pilots, guides, hunters and collectors: they also relied on local expertise. Such assistance was essential in identifying potential dangers poisonous species, unpredictable rivers, uncharted territories which could mean the difference between life and death. The assistants themselves were usually in a strong bargaining position. In the Amazon, for example access to entire regions would depend on the willingness of local crew members and other assistants to enter areas inhabited by relatively powerful Amerindian groups. In an account of his journey across South America published in 1836, William Smyth thus complained of frequent desertion by his helpers: without them it was impossible to get on. Those providing local support and information to explorers were themselves often not locals. For example, the history of African exploration in the nineteenth century is dominated by the use of Zanzibar as a recruiting station for porters, soldiers and guides who would then travel thousands of miles across the continent. In some accounts, the leading African members of expedition parties the officers or foremen are identified, and their portraits published alongside those of European explorers. The information provided by locals and intermediaries was of potential importance to geographical science. How was this evidence judged? The formal procedures of scientific evaluation provided one framework. Alongside these were more common sense notions of veracity and reliability, religiously-inspired judgments about the authenticity of testimony, and the routine procedures for cross-checking empirical observations developed in many professions. Given explorers need for local information and support, it was in their interests to develop effective working partnerships with knowledgeable intermediaries who could act as brokers in their dealings with local inhabitants. Many of these people acquired far more experience of exploration than most Europeans could hope to attain. Some managed large groups of men and women, piloted the explorers river craft, or undertook mapping work. The tradition was continued with the Everest expeditions in the 1920s and 1930s, which regularly employed the Tibetan interpreter Karma Paul. In Europe, exploration was increasingly thought of as a career; the same might be said of the non-Europeans on whom their expeditions depended. These individuals often forged close working relationships with European explorers. Such partnerships depended on mutual respect, though they were not always easy or intimate, as is particularly clear from the history of the Everest expeditions depicted in the Hidden Histories exhibition. The entire back wall is covered by an enlarged version of a single sheet of photographs of Sherpas taken during the 1936 Everest expedition. The document is a powerful reminder of the manpower on which European mountaineering expeditions depended, and also of the importance of local knowledge and assistance. Transformed from archive to wall display, it tells a powerful story through the medium of individual portraits including Karma Paul, veteran of previous expeditions, and the young Tensing Norgay, 17 years before his successful 1953 ascent. This was a highly charged and transitional moment as the contribution of the Sherpas, depicted here with identity tags round their necks, was beginning to be much more widely recognised. These touching portraits encourage us to see them as agents rather than simply colonial subjects or paid employees. Here is a living history, which looks beyond what we already know about exploration: a larger history in which we come to recognise the contribution of everyone involved.", "hypothesis": "Materials owned by the RGS can be used in ways that were not originally intended.", "gold_label": "entailment"}
{"uid": "id_220", "premise": "The hidden histories of exploration exhibition We have all heard tales of lone, heroic explorers, but what about the local individuals who guided and protected European explorers in many different parts of the globe? Or the go-betweens including interpreters and traders who translated the needs and demands of explorers into a language that locals could understand? Such questions have received surprisingly little attention in standard histories, where European explorers are usually the heroes, sometimes the villains. The Hidden Histories of Exploration exhibition at Britains Royal Geographical Society in London sets out to present an alternative view, in which exploration is a fundamentally collective experience of work, involving many different people. Many of the most famous examples of explorers said to have been lone travellers say, Mungo Park or David Livingstone in Africa were anything but alone on their travels. They depended on local support of various kinds for food, shelter, protection, information, guidance and solace as well as on other resources from elsewhere. The Royal Geographical Society (RGS) seeks to record this story in its Hidden Histories project, using its astonishingly rich collections. The storage of geographical information was one of the main rationales for the foundation of the RGS in 1830, and the Societys collections now contain more than two million individual items, including books, manuscripts, maps, photographs art-works, artefacts and film a rich storehouse of material reflecting the wide geographical extent of British interest across the globe. In addition to their remarkable scope and range, these collections contain a striking visual record of exploration: the impulse to collect the world is reflected in a large and diverse image archive. For the researcher, this archive can vield many surprises: materials gathered for one purpose say, maps relating to an international boundary dispute or photographs taken on a scientific expedition may today be put to quite different uses In their published narratives, European explorers rarely portrayed themselves as vulnerable or dependent on others, despite the fact that without this support they were quite literally lost. Archival research confirms that Europeans were not merely dependent on the work of porters soldiers translators, cooks, pilots, guides, hunters and collectors: they also relied on local expertise. Such assistance was essential in identifying potential dangers poisonous species, unpredictable rivers, uncharted territories which could mean the difference between life and death. The assistants themselves were usually in a strong bargaining position. In the Amazon, for example access to entire regions would depend on the willingness of local crew members and other assistants to enter areas inhabited by relatively powerful Amerindian groups. In an account of his journey across South America published in 1836, William Smyth thus complained of frequent desertion by his helpers: without them it was impossible to get on. Those providing local support and information to explorers were themselves often not locals. For example, the history of African exploration in the nineteenth century is dominated by the use of Zanzibar as a recruiting station for porters, soldiers and guides who would then travel thousands of miles across the continent. In some accounts, the leading African members of expedition parties the officers or foremen are identified, and their portraits published alongside those of European explorers. The information provided by locals and intermediaries was of potential importance to geographical science. How was this evidence judged? The formal procedures of scientific evaluation provided one framework. Alongside these were more common sense notions of veracity and reliability, religiously-inspired judgments about the authenticity of testimony, and the routine procedures for cross-checking empirical observations developed in many professions. Given explorers need for local information and support, it was in their interests to develop effective working partnerships with knowledgeable intermediaries who could act as brokers in their dealings with local inhabitants. Many of these people acquired far more experience of exploration than most Europeans could hope to attain. Some managed large groups of men and women, piloted the explorers river craft, or undertook mapping work. The tradition was continued with the Everest expeditions in the 1920s and 1930s, which regularly employed the Tibetan interpreter Karma Paul. In Europe, exploration was increasingly thought of as a career; the same might be said of the non-Europeans on whom their expeditions depended. These individuals often forged close working relationships with European explorers. Such partnerships depended on mutual respect, though they were not always easy or intimate, as is particularly clear from the history of the Everest expeditions depicted in the Hidden Histories exhibition. The entire back wall is covered by an enlarged version of a single sheet of photographs of Sherpas taken during the 1936 Everest expedition. The document is a powerful reminder of the manpower on which European mountaineering expeditions depended, and also of the importance of local knowledge and assistance. Transformed from archive to wall display, it tells a powerful story through the medium of individual portraits including Karma Paul, veteran of previous expeditions, and the young Tensing Norgay, 17 years before his successful 1953 ascent. This was a highly charged and transitional moment as the contribution of the Sherpas, depicted here with identity tags round their necks, was beginning to be much more widely recognised. These touching portraits encourage us to see them as agents rather than simply colonial subjects or paid employees. Here is a living history, which looks beyond what we already know about exploration: a larger history in which we come to recognise the contribution of everyone involved.", "hypothesis": "Some of the records in the RGS archives are more useful than others.", "gold_label": "neutral"}
{"uid": "id_221", "premise": "The hidden histories of exploration exhibition We have all heard tales of lone, heroic explorers, but what about the local individuals who guided and protected European explorers in many different parts of the globe? Or the go-betweens including interpreters and traders who translated the needs and demands of explorers into a language that locals could understand? Such questions have received surprisingly little attention in standard histories, where European explorers are usually the heroes, sometimes the villains. The Hidden Histories of Exploration exhibition at Britains Royal Geographical Society in London sets out to present an alternative view, in which exploration is a fundamentally collective experience of work, involving many different people. Many of the most famous examples of explorers said to have been lone travellers say, Mungo Park or David Livingstone in Africa were anything but alone on their travels. They depended on local support of various kinds for food, shelter, protection, information, guidance and solace as well as on other resources from elsewhere. The Royal Geographical Society (RGS) seeks to record this story in its Hidden Histories project, using its astonishingly rich collections. The storage of geographical information was one of the main rationales for the foundation of the RGS in 1830, and the Societys collections now contain more than two million individual items, including books, manuscripts, maps, photographs art-works, artefacts and film a rich storehouse of material reflecting the wide geographical extent of British interest across the globe. In addition to their remarkable scope and range, these collections contain a striking visual record of exploration: the impulse to collect the world is reflected in a large and diverse image archive. For the researcher, this archive can vield many surprises: materials gathered for one purpose say, maps relating to an international boundary dispute or photographs taken on a scientific expedition may today be put to quite different uses In their published narratives, European explorers rarely portrayed themselves as vulnerable or dependent on others, despite the fact that without this support they were quite literally lost. Archival research confirms that Europeans were not merely dependent on the work of porters soldiers translators, cooks, pilots, guides, hunters and collectors: they also relied on local expertise. Such assistance was essential in identifying potential dangers poisonous species, unpredictable rivers, uncharted territories which could mean the difference between life and death. The assistants themselves were usually in a strong bargaining position. In the Amazon, for example access to entire regions would depend on the willingness of local crew members and other assistants to enter areas inhabited by relatively powerful Amerindian groups. In an account of his journey across South America published in 1836, William Smyth thus complained of frequent desertion by his helpers: without them it was impossible to get on. Those providing local support and information to explorers were themselves often not locals. For example, the history of African exploration in the nineteenth century is dominated by the use of Zanzibar as a recruiting station for porters, soldiers and guides who would then travel thousands of miles across the continent. In some accounts, the leading African members of expedition parties the officers or foremen are identified, and their portraits published alongside those of European explorers. The information provided by locals and intermediaries was of potential importance to geographical science. How was this evidence judged? The formal procedures of scientific evaluation provided one framework. Alongside these were more common sense notions of veracity and reliability, religiously-inspired judgments about the authenticity of testimony, and the routine procedures for cross-checking empirical observations developed in many professions. Given explorers need for local information and support, it was in their interests to develop effective working partnerships with knowledgeable intermediaries who could act as brokers in their dealings with local inhabitants. Many of these people acquired far more experience of exploration than most Europeans could hope to attain. Some managed large groups of men and women, piloted the explorers river craft, or undertook mapping work. The tradition was continued with the Everest expeditions in the 1920s and 1930s, which regularly employed the Tibetan interpreter Karma Paul. In Europe, exploration was increasingly thought of as a career; the same might be said of the non-Europeans on whom their expeditions depended. These individuals often forged close working relationships with European explorers. Such partnerships depended on mutual respect, though they were not always easy or intimate, as is particularly clear from the history of the Everest expeditions depicted in the Hidden Histories exhibition. The entire back wall is covered by an enlarged version of a single sheet of photographs of Sherpas taken during the 1936 Everest expedition. The document is a powerful reminder of the manpower on which European mountaineering expeditions depended, and also of the importance of local knowledge and assistance. Transformed from archive to wall display, it tells a powerful story through the medium of individual portraits including Karma Paul, veteran of previous expeditions, and the young Tensing Norgay, 17 years before his successful 1953 ascent. This was a highly charged and transitional moment as the contribution of the Sherpas, depicted here with identity tags round their necks, was beginning to be much more widely recognised. These touching portraits encourage us to see them as agents rather than simply colonial subjects or paid employees. Here is a living history, which looks beyond what we already know about exploration: a larger history in which we come to recognise the contribution of everyone involved.", "hypothesis": "Local helpers refused to accompany William Smyth during parts of his journey.", "gold_label": "entailment"}
{"uid": "id_222", "premise": "The hidden histories of exploration exhibition We have all heard tales of lone, heroic explorers, but what about the local individuals who guided and protected European explorers in many different parts of the globe? Or the go-betweens including interpreters and traders who translated the needs and demands of explorers into a language that locals could understand? Such questions have received surprisingly little attention in standard histories, where European explorers are usually the heroes, sometimes the villains. The Hidden Histories of Exploration exhibition at Britains Royal Geographical Society in London sets out to present an alternative view, in which exploration is a fundamentally collective experience of work, involving many different people. Many of the most famous examples of explorers said to have been lone travellers say, Mungo Park or David Livingstone in Africa were anything but alone on their travels. They depended on local support of various kinds for food, shelter, protection, information, guidance and solace as well as on other resources from elsewhere. The Royal Geographical Society (RGS) seeks to record this story in its Hidden Histories project, using its astonishingly rich collections. The storage of geographical information was one of the main rationales for the foundation of the RGS in 1830, and the Societys collections now contain more than two million individual items, including books, manuscripts, maps, photographs art-works, artefacts and film a rich storehouse of material reflecting the wide geographical extent of British interest across the globe. In addition to their remarkable scope and range, these collections contain a striking visual record of exploration: the impulse to collect the world is reflected in a large and diverse image archive. For the researcher, this archive can vield many surprises: materials gathered for one purpose say, maps relating to an international boundary dispute or photographs taken on a scientific expedition may today be put to quite different uses In their published narratives, European explorers rarely portrayed themselves as vulnerable or dependent on others, despite the fact that without this support they were quite literally lost. Archival research confirms that Europeans were not merely dependent on the work of porters soldiers translators, cooks, pilots, guides, hunters and collectors: they also relied on local expertise. Such assistance was essential in identifying potential dangers poisonous species, unpredictable rivers, uncharted territories which could mean the difference between life and death. The assistants themselves were usually in a strong bargaining position. In the Amazon, for example access to entire regions would depend on the willingness of local crew members and other assistants to enter areas inhabited by relatively powerful Amerindian groups. In an account of his journey across South America published in 1836, William Smyth thus complained of frequent desertion by his helpers: without them it was impossible to get on. Those providing local support and information to explorers were themselves often not locals. For example, the history of African exploration in the nineteenth century is dominated by the use of Zanzibar as a recruiting station for porters, soldiers and guides who would then travel thousands of miles across the continent. In some accounts, the leading African members of expedition parties the officers or foremen are identified, and their portraits published alongside those of European explorers. The information provided by locals and intermediaries was of potential importance to geographical science. How was this evidence judged? The formal procedures of scientific evaluation provided one framework. Alongside these were more common sense notions of veracity and reliability, religiously-inspired judgments about the authenticity of testimony, and the routine procedures for cross-checking empirical observations developed in many professions. Given explorers need for local information and support, it was in their interests to develop effective working partnerships with knowledgeable intermediaries who could act as brokers in their dealings with local inhabitants. Many of these people acquired far more experience of exploration than most Europeans could hope to attain. Some managed large groups of men and women, piloted the explorers river craft, or undertook mapping work. The tradition was continued with the Everest expeditions in the 1920s and 1930s, which regularly employed the Tibetan interpreter Karma Paul. In Europe, exploration was increasingly thought of as a career; the same might be said of the non-Europeans on whom their expeditions depended. These individuals often forged close working relationships with European explorers. Such partnerships depended on mutual respect, though they were not always easy or intimate, as is particularly clear from the history of the Everest expeditions depicted in the Hidden Histories exhibition. The entire back wall is covered by an enlarged version of a single sheet of photographs of Sherpas taken during the 1936 Everest expedition. The document is a powerful reminder of the manpower on which European mountaineering expeditions depended, and also of the importance of local knowledge and assistance. Transformed from archive to wall display, it tells a powerful story through the medium of individual portraits including Karma Paul, veteran of previous expeditions, and the young Tensing Norgay, 17 years before his successful 1953 ascent. This was a highly charged and transitional moment as the contribution of the Sherpas, depicted here with identity tags round their necks, was beginning to be much more widely recognised. These touching portraits encourage us to see them as agents rather than simply colonial subjects or paid employees. Here is a living history, which looks beyond what we already know about exploration: a larger history in which we come to recognise the contribution of everyone involved.", "hypothesis": "The RGS has organised a number of exhibitions since it was founded.", "gold_label": "neutral"}
{"uid": "id_223", "premise": "The hippocampus region of the brain usually starts to shrink when we reach the age of 30. This contraction is held to be responsible for age-related memory loss, and the older we get the worse it becomes. The process may be reversible though, as the hippocampus is the only region of the brain in which neurons can grow. New research suggests that the secret to growing them is physical exercise, which raises the possibility of us working out to boost our brain power. Unfortunately, it is not just any sort of exercise that stimulates the growth of neurons and this explains why physically active people suffer the same memory loss as the more sedentary.", "hypothesis": "By saying that contraction of the hippocampus is held to be responsible, the author indicates that there may be disagreement on the point.", "gold_label": "entailment"}
{"uid": "id_224", "premise": "The hippocampus region of the brain usually starts to shrink when we reach the age of 30. This contraction is held to be responsible for age-related memory loss, and the older we get the worse it becomes. The process may be reversible though, as the hippocampus is the only region of the brain in which neurons can grow. New research suggests that the secret to growing them is physical exercise, which raises the possibility of us working out to boost our brain power. Unfortunately, it is not just any sort of exercise that stimulates the growth of neurons and this explains why physically active people suffer the same memory loss as the more sedentary.", "hypothesis": "The intended audience of the passage is the physically inactive rather than the general population.", "gold_label": "contradiction"}
{"uid": "id_225", "premise": "The hippocampus region of the brain usually starts to shrink when we reach the age of 30. This contraction is held to be responsible for age-related memory loss, and the older we get the worse it becomes. The process may be reversible though, as the hippocampus is the only region of the brain in which neurons can grow. New research suggests that the secret to growing them is physical exercise, which raises the possibility of us working out to boost our brain power. Unfortunately, it is not just any sort of exercise that stimulates the growth of neurons and this explains why physically active people suffer the same memory loss as the more sedentary.", "hypothesis": "Researchers have identified the forms of physical exercise that stimulate the growth of neurons in the hippocampus.", "gold_label": "neutral"}
{"uid": "id_226", "premise": "The history of bread and cake starts with Neolithic cooks and marches through time according to ingredient availability, advances in technology, economic conditions, socio- cultural influences, legal rights (Medieval guilds), and evolving taste. The earliest breads were unleavened. Variations in grain, thickness, shape, and texture varied from culture to culture. Archaelogical evidence confirms yeast (both as leavening agent and for brewing ale) was used in Egypt as early as 4000 B. C. Food historians generally cite this date for the discovery of leavened bread and genesis of the brewing industry. There is an alternate theory regarding the invention of brewing. Some historians believe it is possible that brewing began when the first cereal crops were domesticated. Sources generally agree the discovery of the powers of yeast was accidental. \"No one has yet managed to date the origins of beer with any precision, and it is probably an impossible task. Indeed, there are scholars who have theorized that a taste for ale prompted the beginning of agriculture, in which case humans have been brewing for some 10,000 years... Most archaeological evidence, however, suggests that fermentation was being used in one manner or another by around 4000 to 3500 B. C. Some of this evidence-from an ancient Mesopotamian trading outpost called Godin Tepe in present-day Iran- indicates that barley was being fermented at that location around 3500 B. C. Additional evidence recovered at Hacinegi Tepe (a similar site in southern Turkey) also suggest that ancient Mesopotamians were fermenting barley at a very early date.", "hypothesis": "Some historians believe that cereal crops are responsible for the beginning of brewing.", "gold_label": "entailment"}
{"uid": "id_227", "premise": "The history of bread and cake starts with Neolithic cooks and marches through time according to ingredient availability, advances in technology, economic conditions, socio- cultural influences, legal rights (Medieval guilds), and evolving taste. The earliest breads were unleavened. Variations in grain, thickness, shape, and texture varied from culture to culture. Archaelogical evidence confirms yeast (both as leavening agent and for brewing ale) was used in Egypt as early as 4000 B. C. Food historians generally cite this date for the discovery of leavened bread and genesis of the brewing industry. There is an alternate theory regarding the invention of brewing. Some historians believe it is possible that brewing began when the first cereal crops were domesticated. Sources generally agree the discovery of the powers of yeast was accidental. \"No one has yet managed to date the origins of beer with any precision, and it is probably an impossible task. Indeed, there are scholars who have theorized that a taste for ale prompted the beginning of agriculture, in which case humans have been brewing for some 10,000 years... Most archaeological evidence, however, suggests that fermentation was being used in one manner or another by around 4000 to 3500 B. C. Some of this evidence-from an ancient Mesopotamian trading outpost called Godin Tepe in present-day Iran- indicates that barley was being fermented at that location around 3500 B. C. Additional evidence recovered at Hacinegi Tepe (a similar site in southern Turkey) also suggest that ancient Mesopotamians were fermenting barley at a very early date.", "hypothesis": "Hacinegi Tepe is only found in Northern Turkey", "gold_label": "contradiction"}
{"uid": "id_228", "premise": "The history of bread and cake starts with Neolithic cooks and marches through time according to ingredient availability, advances in technology, economic conditions, socio- cultural influences, legal rights (Medieval guilds), and evolving taste. The earliest breads were unleavened. Variations in grain, thickness, shape, and texture varied from culture to culture. Archaelogical evidence confirms yeast (both as leavening agent and for brewing ale) was used in Egypt as early as 4000 B. C. Food historians generally cite this date for the discovery of leavened bread and genesis of the brewing industry. There is an alternate theory regarding the invention of brewing. Some historians believe it is possible that brewing began when the first cereal crops were domesticated. Sources generally agree the discovery of the powers of yeast was accidental. \"No one has yet managed to date the origins of beer with any precision, and it is probably an impossible task. Indeed, there are scholars who have theorized that a taste for ale prompted the beginning of agriculture, in which case humans have been brewing for some 10,000 years... Most archaeological evidence, however, suggests that fermentation was being used in one manner or another by around 4000 to 3500 B. C. Some of this evidence-from an ancient Mesopotamian trading outpost called Godin Tepe in present-day Iran- indicates that barley was being fermented at that location around 3500 B. C. Additional evidence recovered at Hacinegi Tepe (a similar site in southern Turkey) also suggest that ancient Mesopotamians were fermenting barley at a very early date.", "hypothesis": "It can be assumed that yeast was discovered accidentally.", "gold_label": "entailment"}
{"uid": "id_229", "premise": "The history of bread and cake starts with Neolithic cooks and marches through time according to ingredient availability, advances in technology, economic conditions, socio- cultural influences, legal rights (Medieval guilds), and evolving taste. The earliest breads were unleavened. Variations in grain, thickness, shape, and texture varied from culture to culture. Archaelogical evidence confirms yeast (both as leavening agent and for brewing ale) was used in Egypt as early as 4000 B. C. Food historians generally cite this date for the discovery of leavened bread and genesis of the brewing industry. There is an alternate theory regarding the invention of brewing. Some historians believe it is possible that brewing began when the first cereal crops were domesticated. Sources generally agree the discovery of the powers of yeast was accidental. \"No one has yet managed to date the origins of beer with any precision, and it is probably an impossible task. Indeed, there are scholars who have theorized that a taste for ale prompted the beginning of agriculture, in which case humans have been brewing for some 10,000 years... Most archaeological evidence, however, suggests that fermentation was being used in one manner or another by around 4000 to 3500 B. C. Some of this evidence-from an ancient Mesopotamian trading outpost called Godin Tepe in present-day Iran- indicates that barley was being fermented at that location around 3500 B. C. Additional evidence recovered at Hacinegi Tepe (a similar site in southern Turkey) also suggest that ancient Mesopotamians were fermenting barley at a very early date.", "hypothesis": "Yeast was used in 4004 B. C", "gold_label": "neutral"}
{"uid": "id_230", "premise": "The history of the tortoise If you go back far enough, everything lived in the sea. At various points in evolutionary history, enterprising individuals within many different animal groups moved out onto the land, sometimes even to the most parched deserts, taking their own private seawater with them in blood and cellular fluids. In addition to the reptiles, birds, mammals and insects which we see all around us, other groups that have succeeded out of water include scorpions, snails, crustaceans such as woodlice and land crabs, millipedes and centipedes, spiders and various worms. And we mustnt forget the plants, without whose prior invasion of the land none of the other migrations could have happened. Moving from water to land involved a major redesign of every aspect of life, including breathing and reproduction. Nevertheless, a good number of thoroughgoing land animals later turned around, abandoned their hard-earned terrestrial re-tooling, and returned to the water again. Seals have only gone part way back. They show us what the intermediates might have been like, on the way to extreme cases such as whales and dugongs. Whales (including the small whales we call dolphins) and dugongs, with their close cousins the manatees, ceased to be land creatures altogether and reverted to the full marine habits of their remote ancestors. They dont even come ashore to breed. They do, however, still breathe air, having never developed anything equivalent to the gills of their earlier marine incarnation. Turtles went back to the sea a very long time ago and, like all vertebrate returnees to the water, they breathe air. However, they are, in one respect, less fully given back to the water than whales or dugongs, for turtles still lay their eggs on beaches. There is evidence that all modem turtles are descended from a terrestrial ancestor which lived before most of the dinosaurs. There are two key fossils called Proganochelys quenstedti and Palaeochersis talampayensis dating from early dinosaur times, which appear to be close to the ancestry of all modem turtles and tortoises. You might wonder how we can tell whether fossil animals lived on land or in water, especially if only fragments are found. Sometimes its obvious. Ichthyosaurs were reptilian contemporaries of the dinosaurs, with fins and streamlined bodies. The fossils look like dolphins and they surely lived like dolphins, in the water. With turtles it is a little less obvious. One way to tell is by measuring the bones of their forelimbs. Walter Joyce and Jacques Gauthier, at Yale University, obtained three measurements in these particular bones of 71 species of living turtles and tortoises. They used a kind of triangular graph paper to plot the three measurements against one another. All the land tortoise species formed a tight cluster of points in the upper part of the triangle; all the water turtles cluster in the lower part of the triangular graph. There was no overlap, except when they added some species that spend time both in water and on land. Sure enough, these amphibious species show up on the triangular graph approximately half way between the wet cluster of sea turtles and the dry cluster of land tortoises. The next step was to determine where the fossils fell. The bones of P quenstedti and JR talampayensis leave us in no doubt. Their points on the graph are right in the thick of the dry cluster. Both these fossils were dry-land tortoises. They come from the era before our turtles returned to the water. You might think, therefore, that modem land tortoises have probably stayed on land ever since those early terrestrial times, as most mammals did after a few of them went back to the sea. But apparently not. If you draw out the family tree of all modem turtles and tortoises, nearly all the branches are aquatic. Todays land tortoises constitute a single branch, deeply nested among branches consisting of aquatic turtles. This suggests that modem land tortoises have not stayed on land continuously since the time of P. quenstedti and P 30talampayensis. Rather, their ancestors were among those who went back to the water, and they then re- emerged back onto the land in (relatively) more recent times. Tortoises therefore represent a remarkable double return. In common with all mammals, reptiles and birds, their remote ancestors were marine fish and before that various more or less worm-like creatures stretching back, still in the sea, to the primeval bacteria. Later ancestors lived on land and stayed there for a very large number of generations. Later ancestors still evolved back into the water and became sea turtles. And finally they returned yet again to the land as tortoises, some of which now live in the driest of deserts.", "hypothesis": "Turtles were among the first group of animals to migrate back to the sea.", "gold_label": "neutral"}
{"uid": "id_231", "premise": "The history of the tortoise If you go back far enough, everything lived in the sea. At various points in evolutionary history, enterprising individuals within many different animal groups moved out onto the land, sometimes even to the most parched deserts, taking their own private seawater with them in blood and cellular fluids. In addition to the reptiles, birds, mammals and insects which we see all around us, other groups that have succeeded out of water include scorpions, snails, crustaceans such as woodlice and land crabs, millipedes and centipedes, spiders and various worms. And we mustnt forget the plants, without whose prior invasion of the land none of the other migrations could have happened. Moving from water to land involved a major redesign of every aspect of life, including breathing and reproduction. Nevertheless, a good number of thoroughgoing land animals later turned around, abandoned their hard-earned terrestrial re-tooling, and returned to the water again. Seals have only gone part way back. They show us what the intermediates might have been like, on the way to extreme cases such as whales and dugongs. Whales (including the small whales we call dolphins) and dugongs, with their close cousins the manatees, ceased to be land creatures altogether and reverted to the full marine habits of their remote ancestors. They dont even come ashore to breed. They do, however, still breathe air, having never developed anything equivalent to the gills of their earlier marine incarnation. Turtles went back to the sea a very long time ago and, like all vertebrate returnees to the water, they breathe air. However, they are, in one respect, less fully given back to the water than whales or dugongs, for turtles still lay their eggs on beaches. There is evidence that all modem turtles are descended from a terrestrial ancestor which lived before most of the dinosaurs. There are two key fossils called Proganochelys quenstedti and Palaeochersis talampayensis dating from early dinosaur times, which appear to be close to the ancestry of all modem turtles and tortoises. You might wonder how we can tell whether fossil animals lived on land or in water, especially if only fragments are found. Sometimes its obvious. Ichthyosaurs were reptilian contemporaries of the dinosaurs, with fins and streamlined bodies. The fossils look like dolphins and they surely lived like dolphins, in the water. With turtles it is a little less obvious. One way to tell is by measuring the bones of their forelimbs. Walter Joyce and Jacques Gauthier, at Yale University, obtained three measurements in these particular bones of 71 species of living turtles and tortoises. They used a kind of triangular graph paper to plot the three measurements against one another. All the land tortoise species formed a tight cluster of points in the upper part of the triangle; all the water turtles cluster in the lower part of the triangular graph. There was no overlap, except when they added some species that spend time both in water and on land. Sure enough, these amphibious species show up on the triangular graph approximately half way between the wet cluster of sea turtles and the dry cluster of land tortoises. The next step was to determine where the fossils fell. The bones of P quenstedti and JR talampayensis leave us in no doubt. Their points on the graph are right in the thick of the dry cluster. Both these fossils were dry-land tortoises. They come from the era before our turtles returned to the water. You might think, therefore, that modem land tortoises have probably stayed on land ever since those early terrestrial times, as most mammals did after a few of them went back to the sea. But apparently not. If you draw out the family tree of all modem turtles and tortoises, nearly all the branches are aquatic. Todays land tortoises constitute a single branch, deeply nested among branches consisting of aquatic turtles. This suggests that modem land tortoises have not stayed on land continuously since the time of P. quenstedti and P 30talampayensis. Rather, their ancestors were among those who went back to the water, and they then re- emerged back onto the land in (relatively) more recent times. Tortoises therefore represent a remarkable double return. In common with all mammals, reptiles and birds, their remote ancestors were marine fish and before that various more or less worm-like creatures stretching back, still in the sea, to the primeval bacteria. Later ancestors lived on land and stayed there for a very large number of generations. Later ancestors still evolved back into the water and became sea turtles. And finally they returned yet again to the land as tortoises, some of which now live in the driest of deserts.", "hypothesis": "It is always difficult to determine where an animal lived when its fossilised remains are incomplete.", "gold_label": "contradiction"}
{"uid": "id_232", "premise": "The history of the tortoise If you go back far enough, everything lived in the sea. At various points in evolutionary history, enterprising individuals within many different animal groups moved out onto the land, sometimes even to the most parched deserts, taking their own private seawater with them in blood and cellular fluids. In addition to the reptiles, birds, mammals and insects which we see all around us, other groups that have succeeded out of water include scorpions, snails, crustaceans such as woodlice and land crabs, millipedes and centipedes, spiders and various worms. And we mustnt forget the plants, without whose prior invasion of the land none of the other migrations could have happened. Moving from water to land involved a major redesign of every aspect of life, including breathing and reproduction. Nevertheless, a good number of thoroughgoing land animals later turned around, abandoned their hard-earned terrestrial re-tooling, and returned to the water again. Seals have only gone part way back. They show us what the intermediates might have been like, on the way to extreme cases such as whales and dugongs. Whales (including the small whales we call dolphins) and dugongs, with their close cousins the manatees, ceased to be land creatures altogether and reverted to the full marine habits of their remote ancestors. They dont even come ashore to breed. They do, however, still breathe air, having never developed anything equivalent to the gills of their earlier marine incarnation. Turtles went back to the sea a very long time ago and, like all vertebrate returnees to the water, they breathe air. However, they are, in one respect, less fully given back to the water than whales or dugongs, for turtles still lay their eggs on beaches. There is evidence that all modem turtles are descended from a terrestrial ancestor which lived before most of the dinosaurs. There are two key fossils called Proganochelys quenstedti and Palaeochersis talampayensis dating from early dinosaur times, which appear to be close to the ancestry of all modem turtles and tortoises. You might wonder how we can tell whether fossil animals lived on land or in water, especially if only fragments are found. Sometimes its obvious. Ichthyosaurs were reptilian contemporaries of the dinosaurs, with fins and streamlined bodies. The fossils look like dolphins and they surely lived like dolphins, in the water. With turtles it is a little less obvious. One way to tell is by measuring the bones of their forelimbs. Walter Joyce and Jacques Gauthier, at Yale University, obtained three measurements in these particular bones of 71 species of living turtles and tortoises. They used a kind of triangular graph paper to plot the three measurements against one another. All the land tortoise species formed a tight cluster of points in the upper part of the triangle; all the water turtles cluster in the lower part of the triangular graph. There was no overlap, except when they added some species that spend time both in water and on land. Sure enough, these amphibious species show up on the triangular graph approximately half way between the wet cluster of sea turtles and the dry cluster of land tortoises. The next step was to determine where the fossils fell. The bones of P quenstedti and JR talampayensis leave us in no doubt. Their points on the graph are right in the thick of the dry cluster. Both these fossils were dry-land tortoises. They come from the era before our turtles returned to the water. You might think, therefore, that modem land tortoises have probably stayed on land ever since those early terrestrial times, as most mammals did after a few of them went back to the sea. But apparently not. If you draw out the family tree of all modem turtles and tortoises, nearly all the branches are aquatic. Todays land tortoises constitute a single branch, deeply nested among branches consisting of aquatic turtles. This suggests that modem land tortoises have not stayed on land continuously since the time of P. quenstedti and P 30talampayensis. Rather, their ancestors were among those who went back to the water, and they then re- emerged back onto the land in (relatively) more recent times. Tortoises therefore represent a remarkable double return. In common with all mammals, reptiles and birds, their remote ancestors were marine fish and before that various more or less worm-like creatures stretching back, still in the sea, to the primeval bacteria. Later ancestors lived on land and stayed there for a very large number of generations. Later ancestors still evolved back into the water and became sea turtles. And finally they returned yet again to the land as tortoises, some of which now live in the driest of deserts.", "hypothesis": "The habitat of ichthyosaurs can be determined by the appearance of their fossilised remains.", "gold_label": "entailment"}
{"uid": "id_233", "premise": "The history of the tortoise. If you go back far enough, everything lived in the sea. At various points in evolutionary history, enterprising individuals within many different animal groups moved out onto the land, sometimes even to the most parched deserts, taking their own private seawater with them in blood and cellular fluids. In addition to the reptiles, birds, mammals and insects which we see all around us, other groups that have succeeded out of water include scorpions, snails, crustaceans such as woodlice and land crabs, millipedes and centipedes, spiders and various worms. And we mustnt forget the plants, without whose prior invasion of the land none of the other migrations could have happened. Moving from water to land involved a major redesign of every aspect of life, including breathing and reproduction. Nevertheless, a good number of thorough going land animals later turned around, abandoned their hard-earned terrestrial re-tooling, and returned to the water again. Seals have only gone part way back. They show us what the intermediates might have been like, on the way to extreme cases such as whales and dugongs. Whales (including the small whales we call dolphins) and dugongs, with their close cousins the manatees, ceased to be land creatures altogether and reverted to the full marine habits of their remote ancestors. They dont even come ashore to breed. They do, however, still breathe air, having never developed anything equivalent to the gills of their earlier marine incarnation. Turtles went back to the sea a very long time ago and, like all vertebrate returnees to the water, they breathe air. However, they are, in one respect, less fully given back to the water than whales or dugongs, for turtles still lay their eggs on beaches. There is evidence that all modern turtles are descended from a terrestrial ancestor which lived before most of the dinosaurs. There are two key fossils called Proganochelys quenstedti and Plaeochersis talampayensis dating from early dinosaur times, which appear to be close to the ancestry of all modern turtles and tortoises. You might wonder how we can tell whether fossil animals lived on land or in water, especially if only fragments are found. Sometimes its obvious. Ichthyosaurs were reptilian contemporaries of the dinosaurs, with fins and streamlined bodies. The fossils look like dolphins and they surely lived like dolphins, in the water. With turtles it is a little less obvious. One way to tell is by measuring the bones of their forelimbs. Walter Joyce and Jacques Gauthier, at Yale University, obtained three measurements in these particular bones of 71 species of living turtles and tortoises. They used a kind of triangular graph paper to plot the three measurements against one another. All the land tortoise species formed a tight cluster of points in the upper part of the triangle; all the water turtles cluster in the lower part of the triangular graph. There was no overlap, except when they added some species that spend time both in water and on land. Sure enough, these amphibious species show up on the triangular graph approximately half way between the wet cluster of sea turtles and the dry cluster of land tortoises. The next step was to determine where the fossils fell. The bones of P. quenstedti and P. talampayensis leave us in no doubt. Their points on the graph are right in the thick of the dry cluster. Both these fossils were dry-land tortoises. They come from the era before our turtles returned to the water. You might think, therefore, that modern land tortoises have probably stayed on land ever since those early terrestrial times, as most mammals did after a few of them went back to the sea. But apparently not. If you draw out the family three of all modern turtles and tortoises, nearly all the branches are aquatic. Todays land tortoises constitute a single branch, deeply nested among branches consisting of aquatic turtles. This suggests that modern land tortoises have not stayed on land continuously since the time of P. quenstedti and P. talampayensis. Rather, their ancestors were among those who went back to the water, and they then reemerged back onto the land in (relatively) more recent times. Tortoises therefore represent a remarkable double return. In common with all mammals, reptiles and birds, their remote ancestors were marine fish and before that various more or less worm-like creatures stretching back, still in the sea, to the primeval bacteria. Later ancestors lived on land and stayed there for a very large number of generations. Later ancestors still evolved back into the water and became sea turtles. And finally they returned yet again to the land as tortoises, some of which now live in the driest of deserts.", "hypothesis": "Turtles were among the first group of animals to migrate back to the sea.", "gold_label": "neutral"}
{"uid": "id_234", "premise": "The history of the tortoise. If you go back far enough, everything lived in the sea. At various points in evolutionary history, enterprising individuals within many different animal groups moved out onto the land, sometimes even to the most parched deserts, taking their own private seawater with them in blood and cellular fluids. In addition to the reptiles, birds, mammals and insects which we see all around us, other groups that have succeeded out of water include scorpions, snails, crustaceans such as woodlice and land crabs, millipedes and centipedes, spiders and various worms. And we mustnt forget the plants, without whose prior invasion of the land none of the other migrations could have happened. Moving from water to land involved a major redesign of every aspect of life, including breathing and reproduction. Nevertheless, a good number of thorough going land animals later turned around, abandoned their hard-earned terrestrial re-tooling, and returned to the water again. Seals have only gone part way back. They show us what the intermediates might have been like, on the way to extreme cases such as whales and dugongs. Whales (including the small whales we call dolphins) and dugongs, with their close cousins the manatees, ceased to be land creatures altogether and reverted to the full marine habits of their remote ancestors. They dont even come ashore to breed. They do, however, still breathe air, having never developed anything equivalent to the gills of their earlier marine incarnation. Turtles went back to the sea a very long time ago and, like all vertebrate returnees to the water, they breathe air. However, they are, in one respect, less fully given back to the water than whales or dugongs, for turtles still lay their eggs on beaches. There is evidence that all modern turtles are descended from a terrestrial ancestor which lived before most of the dinosaurs. There are two key fossils called Proganochelys quenstedti and Plaeochersis talampayensis dating from early dinosaur times, which appear to be close to the ancestry of all modern turtles and tortoises. You might wonder how we can tell whether fossil animals lived on land or in water, especially if only fragments are found. Sometimes its obvious. Ichthyosaurs were reptilian contemporaries of the dinosaurs, with fins and streamlined bodies. The fossils look like dolphins and they surely lived like dolphins, in the water. With turtles it is a little less obvious. One way to tell is by measuring the bones of their forelimbs. Walter Joyce and Jacques Gauthier, at Yale University, obtained three measurements in these particular bones of 71 species of living turtles and tortoises. They used a kind of triangular graph paper to plot the three measurements against one another. All the land tortoise species formed a tight cluster of points in the upper part of the triangle; all the water turtles cluster in the lower part of the triangular graph. There was no overlap, except when they added some species that spend time both in water and on land. Sure enough, these amphibious species show up on the triangular graph approximately half way between the wet cluster of sea turtles and the dry cluster of land tortoises. The next step was to determine where the fossils fell. The bones of P. quenstedti and P. talampayensis leave us in no doubt. Their points on the graph are right in the thick of the dry cluster. Both these fossils were dry-land tortoises. They come from the era before our turtles returned to the water. You might think, therefore, that modern land tortoises have probably stayed on land ever since those early terrestrial times, as most mammals did after a few of them went back to the sea. But apparently not. If you draw out the family three of all modern turtles and tortoises, nearly all the branches are aquatic. Todays land tortoises constitute a single branch, deeply nested among branches consisting of aquatic turtles. This suggests that modern land tortoises have not stayed on land continuously since the time of P. quenstedti and P. talampayensis. Rather, their ancestors were among those who went back to the water, and they then reemerged back onto the land in (relatively) more recent times. Tortoises therefore represent a remarkable double return. In common with all mammals, reptiles and birds, their remote ancestors were marine fish and before that various more or less worm-like creatures stretching back, still in the sea, to the primeval bacteria. Later ancestors lived on land and stayed there for a very large number of generations. Later ancestors still evolved back into the water and became sea turtles. And finally they returned yet again to the land as tortoises, some of which now live in the driest of deserts.", "hypothesis": "It is always difficult to determine where an animal lived when its fossilised remains are incomplete.", "gold_label": "contradiction"}
{"uid": "id_235", "premise": "The history of the tortoise. If you go back far enough, everything lived in the sea. At various points in evolutionary history, enterprising individuals within many different animal groups moved out onto the land, sometimes even to the most parched deserts, taking their own private seawater with them in blood and cellular fluids. In addition to the reptiles, birds, mammals and insects which we see all around us, other groups that have succeeded out of water include scorpions, snails, crustaceans such as woodlice and land crabs, millipedes and centipedes, spiders and various worms. And we mustnt forget the plants, without whose prior invasion of the land none of the other migrations could have happened. Moving from water to land involved a major redesign of every aspect of life, including breathing and reproduction. Nevertheless, a good number of thorough going land animals later turned around, abandoned their hard-earned terrestrial re-tooling, and returned to the water again. Seals have only gone part way back. They show us what the intermediates might have been like, on the way to extreme cases such as whales and dugongs. Whales (including the small whales we call dolphins) and dugongs, with their close cousins the manatees, ceased to be land creatures altogether and reverted to the full marine habits of their remote ancestors. They dont even come ashore to breed. They do, however, still breathe air, having never developed anything equivalent to the gills of their earlier marine incarnation. Turtles went back to the sea a very long time ago and, like all vertebrate returnees to the water, they breathe air. However, they are, in one respect, less fully given back to the water than whales or dugongs, for turtles still lay their eggs on beaches. There is evidence that all modern turtles are descended from a terrestrial ancestor which lived before most of the dinosaurs. There are two key fossils called Proganochelys quenstedti and Plaeochersis talampayensis dating from early dinosaur times, which appear to be close to the ancestry of all modern turtles and tortoises. You might wonder how we can tell whether fossil animals lived on land or in water, especially if only fragments are found. Sometimes its obvious. Ichthyosaurs were reptilian contemporaries of the dinosaurs, with fins and streamlined bodies. The fossils look like dolphins and they surely lived like dolphins, in the water. With turtles it is a little less obvious. One way to tell is by measuring the bones of their forelimbs. Walter Joyce and Jacques Gauthier, at Yale University, obtained three measurements in these particular bones of 71 species of living turtles and tortoises. They used a kind of triangular graph paper to plot the three measurements against one another. All the land tortoise species formed a tight cluster of points in the upper part of the triangle; all the water turtles cluster in the lower part of the triangular graph. There was no overlap, except when they added some species that spend time both in water and on land. Sure enough, these amphibious species show up on the triangular graph approximately half way between the wet cluster of sea turtles and the dry cluster of land tortoises. The next step was to determine where the fossils fell. The bones of P. quenstedti and P. talampayensis leave us in no doubt. Their points on the graph are right in the thick of the dry cluster. Both these fossils were dry-land tortoises. They come from the era before our turtles returned to the water. You might think, therefore, that modern land tortoises have probably stayed on land ever since those early terrestrial times, as most mammals did after a few of them went back to the sea. But apparently not. If you draw out the family three of all modern turtles and tortoises, nearly all the branches are aquatic. Todays land tortoises constitute a single branch, deeply nested among branches consisting of aquatic turtles. This suggests that modern land tortoises have not stayed on land continuously since the time of P. quenstedti and P. talampayensis. Rather, their ancestors were among those who went back to the water, and they then reemerged back onto the land in (relatively) more recent times. Tortoises therefore represent a remarkable double return. In common with all mammals, reptiles and birds, their remote ancestors were marine fish and before that various more or less worm-like creatures stretching back, still in the sea, to the primeval bacteria. Later ancestors lived on land and stayed there for a very large number of generations. Later ancestors still evolved back into the water and became sea turtles. And finally they returned yet again to the land as tortoises, some of which now live in the driest of deserts.", "hypothesis": "The habitat of ichthyosaurs can be determined by the appearance of their fossilised remains.", "gold_label": "entailment"}
{"uid": "id_236", "premise": "The horse used to be an indispensable part of human life and it was used for transport, war, industry and for fun. In order to support societys dependence on the horse, whole industries grew up around it. There were sectors to breed them, shoe them, saddle them, teach people to ride them, feed them, care for them and finally to dispose of them at the end of their useful lives. The industrial revolution and in particular the invention of the internal combustion engine was the end of the horses central role in peoples lives. Today, it seems there is a further threat to the horse that is causing a drop in its numbers. The American Horse Council (AHC) recently addressed this decline at its national issues forum. Leaders from various stakeholders spoke about the decrease in registered horses and the impact on their segment of the horse industry. There has been an enthusiastic response to the forums discussions. People have been talking about decline in horse numbers for some time, however, this is the first time the issue has been discussed in a comprehensive fashion said AHC president Jay Hickey. It was a very good program and attendees now have a better comprehension of current conditions and what actions are being taken. Tim Capps, Director of the Equine industry program at the University of Louisville, gave the opening address at the forum and tried to pinpoint the reasons for the drop in todays numbers of registered horses. The economy was cited by Capps as the single largest factor, but there are probably several other factors as well. Capps believes the horse industry was in a bubble that peaked about six years ago, which was similar to an earlier bubble in 1980s. The bubble burst and caused the resulting damage to the horse industry. Capps also cites the roles of increasing cost of horse ownership and participation in shows, concerns about welfare, and increased competition for leisure and gambling dollars. In addition, Capps explained that there has been a decline in the number of young horses and registered horses over the last several years that is impacting all breeds and segments of the industry and the leaders of the industry are aware of this decline and are taking actions. Capps also noted that this is not the first such decline in the number of horses, and in previous instances there was later a strong rebound in numbers. Examples of this were most notable during the Great Depression and in the mid 1980s. Capps pointed out the horse industry often parallels the wider economy and current situation closely mirrors the impact of Great Depression had on the industry. In the past, the growth following such declines was often propelled by individuals outside the industry becoming interested and investing in the industry, noted Capps. He believes it will again be important to look beyond current horse industry participants to promote growth in the industry now and in the future. Jim Gagliano, Jockey Club President, reported on the effects of the drop in numbers on the horse racing industry. The thoroughbred foal crop has been declining and is responsible for a drop in number of starts, number of horses in the field, the number of owners, and the number of racing days. This in turn has led to a drop in turnover for all sectors in the industry and makes the industry a less attractive one for new entrants and existing businesses. Forum attendees also heard what actions are being taken by the racing industry. Gagliano said that organisations are working to promote the best races and make better use of social media and online resources to attract a younger demographic and develop new owners. Following up on the need for more and better marketing, Patti Colbert of PCE Enterprises has come up with the Time to Ride initiative. This ambitious national campaign and contest targets the goal of giving 100,000 new people a horse experience in the following calendar year. Colbert reported that Time to Ride had accomplished its initial goal to sign up 1,000 stables, instructors, new participants and others in the horse community to host events. Colbert enthusiastically explained the next step. These hosts will now compete for $100,000 in cash and prizes and several have already hosted their first event. The forum also heard from associated service providers who are also being impacted. Jeff Blea, president of the American Association of Equine Practitioners (AAEP) talked about the impact on the veterinarian community and how fewer horses mean less work for horse vets. Blea additionally spoke about the AAEP programs to help veterinarian create long-term and successful relationships with horse owners and support an increase in horse breeding. The forum has clearly identified that the problem is not only a decline in the number of registered horses, but also a decline in horse owners and people participating in horse activities. However, there is also good news as industry organisations are taking actions both individually and collectively. Hickey, explains why people are not overly worried just yet. The industry also has one great advantage: the enduring appeal of the horse. With continued effort on the part of the entire horse community, the industry will come out of the current economic climate even more robust.", "hypothesis": "The current decline in horse industry is still a reaction to the economic slump in the 1980s.", "gold_label": "contradiction"}
{"uid": "id_237", "premise": "The horse used to be an indispensable part of human life and it was used for transport, war, industry and for fun. In order to support societys dependence on the horse, whole industries grew up around it. There were sectors to breed them, shoe them, saddle them, teach people to ride them, feed them, care for them and finally to dispose of them at the end of their useful lives. The industrial revolution and in particular the invention of the internal combustion engine was the end of the horses central role in peoples lives. Today, it seems there is a further threat to the horse that is causing a drop in its numbers. The American Horse Council (AHC) recently addressed this decline at its national issues forum. Leaders from various stakeholders spoke about the decrease in registered horses and the impact on their segment of the horse industry. There has been an enthusiastic response to the forums discussions. People have been talking about decline in horse numbers for some time, however, this is the first time the issue has been discussed in a comprehensive fashion said AHC president Jay Hickey. It was a very good program and attendees now have a better comprehension of current conditions and what actions are being taken. Tim Capps, Director of the Equine industry program at the University of Louisville, gave the opening address at the forum and tried to pinpoint the reasons for the drop in todays numbers of registered horses. The economy was cited by Capps as the single largest factor, but there are probably several other factors as well. Capps believes the horse industry was in a bubble that peaked about six years ago, which was similar to an earlier bubble in 1980s. The bubble burst and caused the resulting damage to the horse industry. Capps also cites the roles of increasing cost of horse ownership and participation in shows, concerns about welfare, and increased competition for leisure and gambling dollars. In addition, Capps explained that there has been a decline in the number of young horses and registered horses over the last several years that is impacting all breeds and segments of the industry and the leaders of the industry are aware of this decline and are taking actions. Capps also noted that this is not the first such decline in the number of horses, and in previous instances there was later a strong rebound in numbers. Examples of this were most notable during the Great Depression and in the mid 1980s. Capps pointed out the horse industry often parallels the wider economy and current situation closely mirrors the impact of Great Depression had on the industry. In the past, the growth following such declines was often propelled by individuals outside the industry becoming interested and investing in the industry, noted Capps. He believes it will again be important to look beyond current horse industry participants to promote growth in the industry now and in the future. Jim Gagliano, Jockey Club President, reported on the effects of the drop in numbers on the horse racing industry. The thoroughbred foal crop has been declining and is responsible for a drop in number of starts, number of horses in the field, the number of owners, and the number of racing days. This in turn has led to a drop in turnover for all sectors in the industry and makes the industry a less attractive one for new entrants and existing businesses. Forum attendees also heard what actions are being taken by the racing industry. Gagliano said that organisations are working to promote the best races and make better use of social media and online resources to attract a younger demographic and develop new owners. Following up on the need for more and better marketing, Patti Colbert of PCE Enterprises has come up with the Time to Ride initiative. This ambitious national campaign and contest targets the goal of giving 100,000 new people a horse experience in the following calendar year. Colbert reported that Time to Ride had accomplished its initial goal to sign up 1,000 stables, instructors, new participants and others in the horse community to host events. Colbert enthusiastically explained the next step. These hosts will now compete for $100,000 in cash and prizes and several have already hosted their first event. The forum also heard from associated service providers who are also being impacted. Jeff Blea, president of the American Association of Equine Practitioners (AAEP) talked about the impact on the veterinarian community and how fewer horses mean less work for horse vets. Blea additionally spoke about the AAEP programs to help veterinarian create long-term and successful relationships with horse owners and support an increase in horse breeding. The forum has clearly identified that the problem is not only a decline in the number of registered horses, but also a decline in horse owners and people participating in horse activities. However, there is also good news as industry organisations are taking actions both individually and collectively. Hickey, explains why people are not overly worried just yet. The industry also has one great advantage: the enduring appeal of the horse. With continued effort on the part of the entire horse community, the industry will come out of the current economic climate even more robust.", "hypothesis": "The Time to Ride movement has gained political as well as industry support.", "gold_label": "neutral"}
{"uid": "id_238", "premise": "The horse used to be an indispensable part of human life and it was used for transport, war, industry and for fun. In order to support societys dependence on the horse, whole industries grew up around it. There were sectors to breed them, shoe them, saddle them, teach people to ride them, feed them, care for them and finally to dispose of them at the end of their useful lives. The industrial revolution and in particular the invention of the internal combustion engine was the end of the horses central role in peoples lives. Today, it seems there is a further threat to the horse that is causing a drop in its numbers. The American Horse Council (AHC) recently addressed this decline at its national issues forum. Leaders from various stakeholders spoke about the decrease in registered horses and the impact on their segment of the horse industry. There has been an enthusiastic response to the forums discussions. People have been talking about decline in horse numbers for some time, however, this is the first time the issue has been discussed in a comprehensive fashion said AHC president Jay Hickey. It was a very good program and attendees now have a better comprehension of current conditions and what actions are being taken. Tim Capps, Director of the Equine industry program at the University of Louisville, gave the opening address at the forum and tried to pinpoint the reasons for the drop in todays numbers of registered horses. The economy was cited by Capps as the single largest factor, but there are probably several other factors as well. Capps believes the horse industry was in a bubble that peaked about six years ago, which was similar to an earlier bubble in 1980s. The bubble burst and caused the resulting damage to the horse industry. Capps also cites the roles of increasing cost of horse ownership and participation in shows, concerns about welfare, and increased competition for leisure and gambling dollars. In addition, Capps explained that there has been a decline in the number of young horses and registered horses over the last several years that is impacting all breeds and segments of the industry and the leaders of the industry are aware of this decline and are taking actions. Capps also noted that this is not the first such decline in the number of horses, and in previous instances there was later a strong rebound in numbers. Examples of this were most notable during the Great Depression and in the mid 1980s. Capps pointed out the horse industry often parallels the wider economy and current situation closely mirrors the impact of Great Depression had on the industry. In the past, the growth following such declines was often propelled by individuals outside the industry becoming interested and investing in the industry, noted Capps. He believes it will again be important to look beyond current horse industry participants to promote growth in the industry now and in the future. Jim Gagliano, Jockey Club President, reported on the effects of the drop in numbers on the horse racing industry. The thoroughbred foal crop has been declining and is responsible for a drop in number of starts, number of horses in the field, the number of owners, and the number of racing days. This in turn has led to a drop in turnover for all sectors in the industry and makes the industry a less attractive one for new entrants and existing businesses. Forum attendees also heard what actions are being taken by the racing industry. Gagliano said that organisations are working to promote the best races and make better use of social media and online resources to attract a younger demographic and develop new owners. Following up on the need for more and better marketing, Patti Colbert of PCE Enterprises has come up with the Time to Ride initiative. This ambitious national campaign and contest targets the goal of giving 100,000 new people a horse experience in the following calendar year. Colbert reported that Time to Ride had accomplished its initial goal to sign up 1,000 stables, instructors, new participants and others in the horse community to host events. Colbert enthusiastically explained the next step. These hosts will now compete for $100,000 in cash and prizes and several have already hosted their first event. The forum also heard from associated service providers who are also being impacted. Jeff Blea, president of the American Association of Equine Practitioners (AAEP) talked about the impact on the veterinarian community and how fewer horses mean less work for horse vets. Blea additionally spoke about the AAEP programs to help veterinarian create long-term and successful relationships with horse owners and support an increase in horse breeding. The forum has clearly identified that the problem is not only a decline in the number of registered horses, but also a decline in horse owners and people participating in horse activities. However, there is also good news as industry organisations are taking actions both individually and collectively. Hickey, explains why people are not overly worried just yet. The industry also has one great advantage: the enduring appeal of the horse. With continued effort on the part of the entire horse community, the industry will come out of the current economic climate even more robust.", "hypothesis": "The industrial revolution led to increase in numbers of horses required in industry and transportation.", "gold_label": "contradiction"}
{"uid": "id_239", "premise": "The horse used to be an indispensable part of human life and it was used for transport, war, industry and for fun. In order to support societys dependence on the horse, whole industries grew up around it. There were sectors to breed them, shoe them, saddle them, teach people to ride them, feed them, care for them and finally to dispose of them at the end of their useful lives. The industrial revolution and in particular the invention of the internal combustion engine was the end of the horses central role in peoples lives. Today, it seems there is a further threat to the horse that is causing a drop in its numbers. The American Horse Council (AHC) recently addressed this decline at its national issues forum. Leaders from various stakeholders spoke about the decrease in registered horses and the impact on their segment of the horse industry. There has been an enthusiastic response to the forums discussions. People have been talking about decline in horse numbers for some time, however, this is the first time the issue has been discussed in a comprehensive fashion said AHC president Jay Hickey. It was a very good program and attendees now have a better comprehension of current conditions and what actions are being taken. Tim Capps, Director of the Equine industry program at the University of Louisville, gave the opening address at the forum and tried to pinpoint the reasons for the drop in todays numbers of registered horses. The economy was cited by Capps as the single largest factor, but there are probably several other factors as well. Capps believes the horse industry was in a bubble that peaked about six years ago, which was similar to an earlier bubble in 1980s. The bubble burst and caused the resulting damage to the horse industry. Capps also cites the roles of increasing cost of horse ownership and participation in shows, concerns about welfare, and increased competition for leisure and gambling dollars. In addition, Capps explained that there has been a decline in the number of young horses and registered horses over the last several years that is impacting all breeds and segments of the industry and the leaders of the industry are aware of this decline and are taking actions. Capps also noted that this is not the first such decline in the number of horses, and in previous instances there was later a strong rebound in numbers. Examples of this were most notable during the Great Depression and in the mid 1980s. Capps pointed out the horse industry often parallels the wider economy and current situation closely mirrors the impact of Great Depression had on the industry. In the past, the growth following such declines was often propelled by individuals outside the industry becoming interested and investing in the industry, noted Capps. He believes it will again be important to look beyond current horse industry participants to promote growth in the industry now and in the future. Jim Gagliano, Jockey Club President, reported on the effects of the drop in numbers on the horse racing industry. The thoroughbred foal crop has been declining and is responsible for a drop in number of starts, number of horses in the field, the number of owners, and the number of racing days. This in turn has led to a drop in turnover for all sectors in the industry and makes the industry a less attractive one for new entrants and existing businesses. Forum attendees also heard what actions are being taken by the racing industry. Gagliano said that organisations are working to promote the best races and make better use of social media and online resources to attract a younger demographic and develop new owners. Following up on the need for more and better marketing, Patti Colbert of PCE Enterprises has come up with the Time to Ride initiative. This ambitious national campaign and contest targets the goal of giving 100,000 new people a horse experience in the following calendar year. Colbert reported that Time to Ride had accomplished its initial goal to sign up 1,000 stables, instructors, new participants and others in the horse community to host events. Colbert enthusiastically explained the next step. These hosts will now compete for $100,000 in cash and prizes and several have already hosted their first event. The forum also heard from associated service providers who are also being impacted. Jeff Blea, president of the American Association of Equine Practitioners (AAEP) talked about the impact on the veterinarian community and how fewer horses mean less work for horse vets. Blea additionally spoke about the AAEP programs to help veterinarian create long-term and successful relationships with horse owners and support an increase in horse breeding. The forum has clearly identified that the problem is not only a decline in the number of registered horses, but also a decline in horse owners and people participating in horse activities. However, there is also good news as industry organisations are taking actions both individually and collectively. Hickey, explains why people are not overly worried just yet. The industry also has one great advantage: the enduring appeal of the horse. With continued effort on the part of the entire horse community, the industry will come out of the current economic climate even more robust.", "hypothesis": "The horse industry has reacted well to previous drops in the number of horses.", "gold_label": "entailment"}
{"uid": "id_240", "premise": "The hotel is two blocks east of the drugstore. The market is one block west of the hotel.", "hypothesis": "The drugstore is west of the market.", "gold_label": "entailment"}
{"uid": "id_241", "premise": "The hottest month According to the Met Office, the UK had its warmest July day ever on July 1, when temperatures hit 36.7 C near London. There were record heat waves in many countries including Spain, while the African continent had the second-warmest July on record. While the impact of increased levels of carbon dioxide in the atmosphere is a key driver of rising temperatures, another important factor is El Nino. This natural phenomenon, which appears as a large swathe of warm water in the Pacific every few years, is known to push up global temperatures. In recent days there have been reports that this year's El Nino will be particularly intense. As a result, many experts believe that 2015 will be the warmest year on record by some margin. The seas have also been soaking up a large amount of heat, the NOAA said, with record warming in large expanses of the Pacific and Indian Oceans Peter Stott, head of climate monitoring and attribution at the UK Met Office, said: \"A strong El Nino is under way in the tropical Pacific and this, combined with the long-term global warming trend, means there is the potential to see some very warm months throughout this year - as the new figures for July appear to show.", "hypothesis": "2015 might be the hottest year in the history.", "gold_label": "entailment"}
{"uid": "id_242", "premise": "The hottest month According to the Met Office, the UK had its warmest July day ever on July 1, when temperatures hit 36.7 C near London. There were record heat waves in many countries including Spain, while the African continent had the second-warmest July on record. While the impact of increased levels of carbon dioxide in the atmosphere is a key driver of rising temperatures, another important factor is El Nino. This natural phenomenon, which appears as a large swathe of warm water in the Pacific every few years, is known to push up global temperatures. In recent days there have been reports that this year's El Nino will be particularly intense. As a result, many experts believe that 2015 will be the warmest year on record by some margin. The seas have also been soaking up a large amount of heat, the NOAA said, with record warming in large expanses of the Pacific and Indian Oceans Peter Stott, head of climate monitoring and attribution at the UK Met Office, said: \"A strong El Nino is under way in the tropical Pacific and this, combined with the long-term global warming trend, means there is the potential to see some very warm months throughout this year - as the new figures for July appear to show.", "hypothesis": "The year 2015 might very well consist of a number of very warm months.", "gold_label": "entailment"}
{"uid": "id_243", "premise": "The hottest month According to the Met Office, the UK had its warmest July day ever on July 1, when temperatures hit 36.7 C near London. There were record heat waves in many countries including Spain, while the African continent had the second-warmest July on record. While the impact of increased levels of carbon dioxide in the atmosphere is a key driver of rising temperatures, another important factor is El Nino. This natural phenomenon, which appears as a large swathe of warm water in the Pacific every few years, is known to push up global temperatures. In recent days there have been reports that this year's El Nino will be particularly intense. As a result, many experts believe that 2015 will be the warmest year on record by some margin. The seas have also been soaking up a large amount of heat, the NOAA said, with record warming in large expanses of the Pacific and Indian Oceans Peter Stott, head of climate monitoring and attribution at the UK Met Office, said: \"A strong El Nino is under way in the tropical Pacific and this, combined with the long-term global warming trend, means there is the potential to see some very warm months throughout this year - as the new figures for July appear to show.", "hypothesis": "Africa had the warmest July day ever on July 1.", "gold_label": "contradiction"}
{"uid": "id_244", "premise": "The hottest month According to the Met Office, the UK had its warmest July day ever on July 1, when temperatures hit 36.7 C near London. There were record heat waves in many countries including Spain, while the African continent had the second-warmest July on record. While the impact of increased levels of carbon dioxide in the atmosphere is a key driver of rising temperatures, another important factor is El Nino. This natural phenomenon, which appears as a large swathe of warm water in the Pacific every few years, is known to push up global temperatures. In recent days there have been reports that this year's El Nino will be particularly intense. As a result, many experts believe that 2015 will be the warmest year on record by some margin. The seas have also been soaking up a large amount of heat, the NOAA said, with record warming in large expanses of the Pacific and Indian Oceans Peter Stott, head of climate monitoring and attribution at the UK Met Office, said: \"A strong El Nino is under way in the tropical Pacific and this, combined with the long-term global warming trend, means there is the potential to see some very warm months throughout this year - as the new figures for July appear to show.", "hypothesis": "The temperature is rising due to the increased level of carbon dioxide in the atmosphere.", "gold_label": "entailment"}
{"uid": "id_245", "premise": "The hottest month According to the Met Office, the UK had its warmest July day ever on July 1, when temperatures hit 36.7 C near London. There were record heat waves in many countries including Spain, while the African continent had the second-warmest July on record. While the impact of increased levels of carbon dioxide in the atmosphere is a key driver of rising temperatures, another important factor is El Nino. This natural phenomenon, which appears as a large swathe of warm water in the Pacific every few years, is known to push up global temperatures. In recent days there have been reports that this year's El Nino will be particularly intense. As a result, many experts believe that 2015 will be the warmest year on record by some margin. The seas have also been soaking up a large amount of heat, the NOAA said, with record warming in large expanses of the Pacific and Indian Oceans Peter Stott, head of climate monitoring and attribution at the UK Met Office, said: \"A strong El Nino is under way in the tropical Pacific and this, combined with the long-term global warming trend, means there is the potential to see some very warm months throughout this year - as the new figures for July appear to show.", "hypothesis": "Record warming was recorded in various seas, such as Black and Azov Sea.", "gold_label": "neutral"}
{"uid": "id_246", "premise": "The immaculate white porcelain suddenly fell from vogue, to be replaced by painted porcelain. What was to become known as blue and white ware because of its blue coloured designs over a white background, was greatly in demand for the export markets and used the newly discovered and imported Persian cobalt as an underglazing paint. So great was this trade that the plates and dishes decorated with dragons, phoenixes and flowers graced many European homes and featured in contemporary still-life paintings and portraits. In time the style evolved to include red, yellow and green overgrazes applied over blue outlines. Increasingly, designs depicted symbols of well-being such as groups of children, sages or animals. Five timed realistic tests with interpretations of your score 191", "hypothesis": "Persian cobalt gives porcelain a rich emerald-toned green colour.", "gold_label": "contradiction"}
{"uid": "id_247", "premise": "The immaculate white porcelain suddenly fell from vogue, to be replaced by painted porcelain. What was to become known as blue and white ware because of its blue coloured designs over a white background, was greatly in demand for the export markets and used the newly discovered and imported Persian cobalt as an underglazing paint. So great was this trade that the plates and dishes decorated with dragons, phoenixes and flowers graced many European homes and featured in contemporary still-life paintings and portraits. In time the style evolved to include red, yellow and green overgrazes applied over blue outlines. Increasingly, designs depicted symbols of well-being such as groups of children, sages or animals. Five timed realistic tests with interpretations of your score 191", "hypothesis": "It can be deduced from the passage that painted porcelain became more popular than its predecessor.", "gold_label": "contradiction"}
{"uid": "id_248", "premise": "The immaculate white porcelain suddenly fell from vogue, to be replaced by painted porcelain. What was to become known as blue and white ware because of its blue coloured designs over a white background, was greatly in demand for the export markets and used the newly discovered and imported Persian cobalt as an underglazing paint. So great was this trade that the plates and dishes decorated with dragons, phoenixes and flowers graced many European homes and featured in contemporary still-life paintings and portraits. In time the style evolved to include red, yellow and green overgrazes applied over blue outlines. Increasingly, designs depicted symbols of well-being such as groups of children, sages or animals. Five timed realistic tests with interpretations of your score 191", "hypothesis": "The passage describes the development of Chinese ceramics.", "gold_label": "neutral"}
{"uid": "id_249", "premise": "The increasing fragility of the rural economy will be the biggest challenge facing country communities over the next ten years. Agriculture, which accounts for a quarter of rural job, is in decline. Tourism provides no more than half this number of job. The rural manufacturing sector, however, has grown over last ten years. Despite this, it still employs fewer than one in twenty people living in rural area, and is threatened by companies based in industrial areas, which benefit from access to a larger skilled workforce and better transportation networks.", "hypothesis": "Industries based in rural areas benefit from better transport links.", "gold_label": "contradiction"}
{"uid": "id_250", "premise": "The increasing fragility of the rural economy will be the biggest challenge facing country communities over the next ten years. Agriculture, which accounts for a quarter of rural job, is in decline. Tourism provides no more than half this number of job. The rural manufacturing sector, however, has grown over last ten years. Despite this, it still employs fewer than one in twenty people living in rural area, and is threatened by companies based in industrial areas, which benefit from access to a larger skilled workforce and better transportation networks.", "hypothesis": "Manufacturing provides the fewest jobs in the countryside.", "gold_label": "neutral"}
{"uid": "id_251", "premise": "The increasing fragility of the rural economy will be the biggest challenge facing country communities over the next ten years. Agriculture, which accounts for a quarter of rural job, is in decline. Tourism provides no more than half this number of job. The rural manufacturing sector, however, has grown over last ten years. Despite this, it still employs fewer than one in twenty people living in rural area, and is threatened by companies based in industrial areas, which benefit from access to a larger skilled workforce and better transportation networks.", "hypothesis": "The manufacturing sector is likely to be the main source of employment for rural workers in the future.", "gold_label": "neutral"}
{"uid": "id_252", "premise": "The increasing fragility of the rural economy will be the biggest challenge facing country communities over the next ten years. Agriculture, which accounts for a quarter of rural job, is in decline. Tourism provides no more than half this number of job. The rural manufacturing sector, however, has grown over last ten years. Despite this, it still employs fewer than one in twenty people living in rural area, and is threatened by companies based in industrial areas, which benefit from access to a larger skilled workforce and better transportation networks.", "hypothesis": "Industries based in rural areas suffer from poorer transport links.", "gold_label": "entailment"}
{"uid": "id_253", "premise": "The increasing fragility of the rural economy will be the biggest challenge facing country communities over the next ten years. Agriculture, which accounts for a quarter of rural job, is in decline. Tourism provides no more than half this number of job. The rural manufacturing sector, however, has grown over last ten years. Despite this, it still employs fewer than one in twenty people living in rural area, and is threatened by companies based in industrial areas, which benefit from access to a larger skilled workforce and better transportation networks.", "hypothesis": "Manufacturing provides the fewest jobs in the countryside.", "gold_label": "neutral"}
{"uid": "id_254", "premise": "The increasing fragility of the rural economy will be the biggest challenge facing country communities over the next ten years. Agriculture, which accounts for a quarter of rural job, is in decline. Tourism provides no more than half this number of job. The rural manufacturing sector, however, has grown over last ten years. Despite this, it still employs fewer than one in twenty people living in rural area, and is threatened by companies based in industrial areas, which benefit from access to a larger skilled workforce and better transportation networks.", "hypothesis": "Industries based in rural areas suffer from poorer transport links.", "gold_label": "entailment"}
{"uid": "id_255", "premise": "The increasing fragility of the rural economy will be the biggest challenge facing country communities over the next ten years. Agriculture, which accounts for a quarter of rural job, is in decline. Tourism provides no more than half this number of job. The rural manufacturing sector, however, has grown over last ten years. Despite this, it still employs fewer than one in twenty people living in rural area, and is threatened by companies based in industrial areas, which benefit from access to a larger skilled workforce and better transportation networks.", "hypothesis": "The manufacturing sector is likely to be the main source of employment for rural workers in the future.", "gold_label": "neutral"}
{"uid": "id_256", "premise": "The increasing fragility of the rural economy will be the biggest challenge facing country communities over the next ten years. Agriculture, which accounts for a quarter of rural job, is in decline. Tourism provides no more than half this number of job. The rural manufacturing sector, however, has grown over last ten years. Despite this, it still employs fewer than one in twenty people living in rural area, and is threatened by companies based in industrial areas, which benefit from access to a larger skilled workforce and better transportation networks.", "hypothesis": "Industries based in rural areas benefit from better transport links.", "gold_label": "contradiction"}
{"uid": "id_257", "premise": "The indigenous Australians are the native people of Australia, also known as the Aborigines. It is believed that they arrived in Australia 50,000 years ago from South-east Asia. They lived a traditional life, which involved living in wooded areas and hunting animals with spears and boomerangs. This lifestyle would not harm the environment of Australia as they believe that the land, with all of its animals and plants, is sacred. When the British people came to Australia in 1788, there were not many people living in Australia. According to British law, any land could be claimed for the monarchy if they believed that nobody owned it and so they claimed all of the land. It was later agreed by the Australian government in 1976 that the aboriginal people would have the rights to the land where they were originally located if they could prove that they have been living there. Nowadays, many of the 517,000 aboriginal people in Australia have chosen to integrate with the modern ways of life. They live in cities and towns and some of them have acquired professional jobs. Others have decided to maintain their traditional aboriginal way of living. Few have been unfortunate in that they havent been educated enough to benefit from Australian society but have also lost their traditional aboriginal ways.", "hypothesis": "Most Aborigines have received enough education to integrate with Australian culture.", "gold_label": "entailment"}
{"uid": "id_258", "premise": "The indigenous Australians are the native people of Australia, also known as the Aborigines. It is believed that they arrived in Australia 50,000 years ago from South-east Asia. They lived a traditional life, which involved living in wooded areas and hunting animals with spears and boomerangs. This lifestyle would not harm the environment of Australia as they believe that the land, with all of its animals and plants, is sacred. When the British people came to Australia in 1788, there were not many people living in Australia. According to British law, any land could be claimed for the monarchy if they believed that nobody owned it and so they claimed all of the land. It was later agreed by the Australian government in 1976 that the aboriginal people would have the rights to the land where they were originally located if they could prove that they have been living there. Nowadays, many of the 517,000 aboriginal people in Australia have chosen to integrate with the modern ways of life. They live in cities and towns and some of them have acquired professional jobs. Others have decided to maintain their traditional aboriginal way of living. Few have been unfortunate in that they havent been educated enough to benefit from Australian society but have also lost their traditional aboriginal ways.", "hypothesis": "The British people claimed the Australian land because the Aborigines only lived in the wooded areas.", "gold_label": "contradiction"}
{"uid": "id_259", "premise": "The indigenous Australians are the native people of Australia, also known as the Aborigines. It is believed that they arrived in Australia 50,000 years ago from South-east Asia. They lived a traditional life, which involved living in wooded areas and hunting animals with spears and boomerangs. This lifestyle would not harm the environment of Australia as they believe that the land, with all of its animals and plants, is sacred. When the British people came to Australia in 1788, there were not many people living in Australia. According to British law, any land could be claimed for the monarchy if they believed that nobody owned it and so they claimed all of the land. It was later agreed by the Australian government in 1976 that the aboriginal people would have the rights to the land where they were originally located if they could prove that they have been living there. Nowadays, many of the 517,000 aboriginal people in Australia have chosen to integrate with the modern ways of life. They live in cities and towns and some of them have acquired professional jobs. Others have decided to maintain their traditional aboriginal way of living. Few have been unfortunate in that they havent been educated enough to benefit from Australian society but have also lost their traditional aboriginal ways.", "hypothesis": "There are 517,000 Aborigines currently living in the cities and towns of Australia.", "gold_label": "contradiction"}
{"uid": "id_260", "premise": "The indigenous Australians are the native people of Australia, also known as the Aborigines. It is believed that they arrived in Australia 50,000 years ago from South-east Asia. They lived a traditional life, which involved living in wooded areas and hunting animals with spears and boomerangs. This lifestyle would not harm the environment of Australia as they believe that the land, with all of its animals and plants, is sacred. When the British people came to Australia in 1788, there were not many people living in Australia. According to British law, any land could be claimed for the monarchy if they believed that nobody owned it and so they claimed all of the land. It was later agreed by the Australian government in 1976 that the aboriginal people would have the rights to the land where they were originally located if they could prove that they have been living there. Nowadays, many of the 517,000 aboriginal people in Australia have chosen to integrate with the modern ways of life. They live in cities and towns and some of them have acquired professional jobs. Others have decided to maintain their traditional aboriginal way of living. Few have been unfortunate in that they havent been educated enough to benefit from Australian society but have also lost their traditional aboriginal ways.", "hypothesis": "The aboriginal people were able to reclaim all their land in 1976.", "gold_label": "contradiction"}
{"uid": "id_261", "premise": "The indigenous Australians are the native people of Australia, also known as the Aborigines. It is believed that they arrived in Australia 50,000 years ago from South-east Asia. They lived a traditional life, which involved living in wooded areas and hunting animals with spears and boomerangs. This lifestyle would not harm the environment of Australia as they believe that the land, with all of its animals and plants, is sacred. When the British people came to Australia in 1788, there were not many people living in Australia. According to British law, any land could be claimed for the monarchy if they believed that nobody owned it and so they claimed all of the land. It was later agreed by the Australian government in 1976 that the aboriginal people would have the rights to the land where they were originally located if they could prove that they have been living there. Nowadays, many of the 517,000 aboriginal people in Australia have chosen to integrate with the modern ways of life. They live in cities and towns and some of them have acquired professional jobs. Others have decided to maintain their traditional aboriginal way of living. Few have been unfortunate in that they havent been educated enough to benefit from Australian society but have also lost their traditional aboriginal ways.", "hypothesis": "The Aborigine lifestyle is similar to that of the south-east Asians from 50,000 years ago.", "gold_label": "neutral"}
{"uid": "id_262", "premise": "The ineptly titled \"America Invents Act, \" S. 23 and H. R. 1249, currently meandering through Congress is likely to bring woe to small inventors and startup businesses that collectively drive the nation's economy. A key feature of the current patent system is the incentive for inventors to disclose their invention in a patent application in exchange for the possibility that they may achieve a patent grant in return. The subsequent publication of the patent application serves to inform the public about the invention, and thus enables others, including competitors, to build upon it. However, the new law would award the patent to the first person to file a patent application on the invention, rather than the one who is actually the first to invent. Another provision would eliminate the \"grace period\" that has traditionally allowed an inventor to get his invention \"off the ground\" without forgoing the opportunity to patent it.", "hypothesis": "The current patent law fosters inventiveness by encouraging inventors to keep sole claim to the knowledge behind the invention, allowing them to reap all the rewards of his own creativity and effort.", "gold_label": "contradiction"}
{"uid": "id_263", "premise": "The ineptly titled \"America Invents Act, \" S. 23 and H. R. 1249, currently meandering through Congress is likely to bring woe to small inventors and startup businesses that collectively drive the nation's economy. A key feature of the current patent system is the incentive for inventors to disclose their invention in a patent application in exchange for the possibility that they may achieve a patent grant in return. The subsequent publication of the patent application serves to inform the public about the invention, and thus enables others, including competitors, to build upon it. However, the new law would award the patent to the first person to file a patent application on the invention, rather than the one who is actually the first to invent. Another provision would eliminate the \"grace period\" that has traditionally allowed an inventor to get his invention \"off the ground\" without forgoing the opportunity to patent it.", "hypothesis": "The U. S. will lose its innovative edge in the world if the \"American Invents Act\" is passed into law.", "gold_label": "neutral"}
{"uid": "id_264", "premise": "The ineptly titled \"America Invents Act, \" S. 23 and H. R. 1249, currently meandering through Congress is likely to bring woe to small inventors and startup businesses that collectively drive the nation's economy. A key feature of the current patent system is the incentive for inventors to disclose their invention in a patent application in exchange for the possibility that they may achieve a patent grant in return. The subsequent publication of the patent application serves to inform the public about the invention, and thus enables others, including competitors, to build upon it. However, the new law would award the patent to the first person to file a patent application on the invention, rather than the one who is actually the first to invent. Another provision would eliminate the \"grace period\" that has traditionally allowed an inventor to get his invention \"off the ground\" without forgoing the opportunity to patent it.", "hypothesis": "Under the new proposal, inventors may fear that they can't possibly win a race to the patent office and can't properly deliberate their invention with others before filing.", "gold_label": "entailment"}
{"uid": "id_265", "premise": "The internet is a convenient place to search for vast amounts of information and to conduct online shopping. However, it has been noted that there is an increased rate of fraud when individuals have purchased items over the internet. The two most popular types of fraud perpetrated on the internet are Rogue Trading and Identity Fraud. Rogue trading is attempted by dishonest individuals who may advertise their items using false descriptions. There may actually be cases where the items do not even exist. Rogue traders are also deceitful when they purposely advertise items without delivery or transportation rates. These rates are then revealed towards the end of the buying process, by which time the individuals payment details may have been received and it may possibly be too late to cancel the transaction. Identity fraud occurs when fraudulent traders gain access to your personal details, such as your credit card number. In most cases an item is usually delivered, hence the buyer will also have to give details of their address. These two personal details combined usually make it easier for a fraudster to withdraw money from their victims bank account.", "hypothesis": "The internet is always a prudent place to search for information and to shop for goods", "gold_label": "entailment"}
{"uid": "id_266", "premise": "The internet is a convenient place to search for vast amounts of information and to conduct online shopping. However, it has been noted that there is an increased rate of fraud when individuals have purchased items over the internet. The two most popular types of fraud perpetrated on the internet are Rogue Trading and Identity Fraud. Rogue trading is attempted by dishonest individuals who may advertise their items using false descriptions. There may actually be cases where the items do not even exist. Rogue traders are also deceitful when they purposely advertise items without delivery or transportation rates. These rates are then revealed towards the end of the buying process, by which time the individuals payment details may have been received and it may possibly be too late to cancel the transaction. Identity fraud occurs when fraudulent traders gain access to your personal details, such as your credit card number. In most cases an item is usually delivered, hence the buyer will also have to give details of their address. These two personal details combined usually make it easier for a fraudster to withdraw money from their victims bank account.", "hypothesis": "Internet fraud can be divided into two categories: Rogue Trading and Identity Fraud", "gold_label": "contradiction"}
{"uid": "id_267", "premise": "The internet is a convenient place to search for vast amounts of information and to conduct online shopping. However, it has been noted that there is an increased rate of fraud when individuals have purchased items over the internet. The two most popular types of fraud perpetrated on the internet are Rogue Trading and Identity Fraud. Rogue trading is attempted by dishonest individuals who may advertise their items using false descriptions. There may actually be cases where the items do not even exist. Rogue traders are also deceitful when they purposely advertise items without delivery or transportation rates. These rates are then revealed towards the end of the buying process, by which time the individuals payment details may have been received and it may possibly be too late to cancel the transaction. Identity fraud occurs when fraudulent traders gain access to your personal details, such as your credit card number. In most cases an item is usually delivered, hence the buyer will also have to give details of their address. These two personal details combined usually make it easier for a fraudster to withdraw money from their victims bank account.", "hypothesis": "Fraudsters advertising items under false pretences is an illustration of identity deception", "gold_label": "contradiction"}
{"uid": "id_268", "premise": "The internet is a convenient place to search for vast amounts of information and to conduct online shopping. However, it has been noted that there is an increased rate of fraud when individuals have purchased items over the internet. The two most popular types of fraud perpetrated on the internet are Rogue Trading and Identity Fraud. Rogue trading is attempted by dishonest individuals who may advertise their items using false descriptions. There may actually be cases where the items do not even exist. Rogue traders are also deceitful when they purposely advertise items without delivery or transportation rates. These rates are then revealed towards the end of the buying process, by which time the individuals payment details may have been received and it may possibly be too late to cancel the transaction. Identity fraud occurs when fraudulent traders gain access to your personal details, such as your credit card number. In most cases an item is usually delivered, hence the buyer will also have to give details of their address. These two personal details combined usually make it easier for a fraudster to withdraw money from their victims bank account.", "hypothesis": "Fraud is universally prevalent on the internet", "gold_label": "neutral"}
{"uid": "id_269", "premise": "The jet stream is a two-mile-high column of wind and in this part of the world it deter- mines the boundary between the Arctic and Atlantic air. When it moves south, much of northern Europe and North America is subjected to cold air and when it moves north, northern Europe and North America enjoy warmer air. In the spring and autumn the jet stream moves much more than at other times of the year and this largely explains why spring and autumn weather in the northern hemisphere can be so changeable. In a matter of a few days the position of the jet stream can fluctuate and warm and possibly wet spring or autumn weather can suddenly be replaced by cold air and dry, clear skies.", "hypothesis": "It can be inferred from the information provided that in relative terms Arctic air is cold and Atlantic air is warm.", "gold_label": "contradiction"}
{"uid": "id_270", "premise": "The jet stream is a two-mile-high column of wind and in this part of the world it deter- mines the boundary between the Arctic and Atlantic air. When it moves south, much of northern Europe and North America is subjected to cold air and when it moves north, northern Europe and North America enjoy warmer air. In the spring and autumn the jet stream moves much more than at other times of the year and this largely explains why spring and autumn weather in the northern hemisphere can be so changeable. In a matter of a few days the position of the jet stream can fluctuate and warm and possibly wet spring or autumn weather can suddenly be replaced by cold air and dry, clear skies.", "hypothesis": "By this part of the world it implies northern Europe.", "gold_label": "neutral"}
{"uid": "id_271", "premise": "The jet stream is a two-mile-high column of wind and in this part of the world it deter- mines the boundary between the Arctic and Atlantic air. When it moves south, much of northern Europe and North America is subjected to cold air and when it moves north, northern Europe and North America enjoy warmer air. In the spring and autumn the jet stream moves much more than at other times of the year and this largely explains why spring and autumn weather in the northern hemisphere can be so changeable. In a matter of a few days the position of the jet stream can fluctuate and warm and possibly wet spring or autumn weather can suddenly be replaced by cold air and dry, clear skies.", "hypothesis": "If it were in fact untrue that the jet stream was a two-mile-high column of wind then the explanation of why spring and autumn weather in the northern hemisphere is so changeable would be compromised.", "gold_label": "neutral"}
{"uid": "id_272", "premise": "The largest thing in the universe More than ten years ago, while taking the temperature of the universe, astronomers found something odd. They discovered that a patch of sky, spanning the width of 20 moons, was unusually cold. The astronomers were measuring the thermal radiation that bathes the entire universe, a glowing relic of the big bang. To gaze at this cosmic microwave background, or CMB, is to glimpse the primordial1 universe, a time when it was less than 400,000 years old. The CMB blankets the sky, and looks pretty much the same everywhere, existing at a feebly cold temperature of 2.725 kelvins - just a couple degrees warmer than absolute zero. But armed with the newly launched WMAP satellite, the astronomers had set out to probe temperature variations as tiny as one part in 100,000. Born from the quantum froth that was the universe a half-moment after the big bang, those random fluctuations help scientists understand what the cosmos is made of and how it all came to be. And standing out amidst those fluctuations was a cold spot. Over the years, astronomers have come up with all sorts of ideas to explain it, ranging from instrumental error to parallel universes. But now, they're homing in on a prime suspect: an enormous cavern of emptiness called a cosmic supervoid, so big that it might be the largest structure in the universe. According to theory, such a vast void, in which nary a star or galaxy exists, can leave a frigid imprint on the CMB. The answer to the mystery, then, might simply be a whole lot of nothing. Yet puzzles remain, and the case is far from closed. Primordial1 - ancient, existing a very long time.", "hypothesis": "The CMB varies from extremely low to very high temperatures.", "gold_label": "contradiction"}
{"uid": "id_273", "premise": "The largest thing in the universe More than ten years ago, while taking the temperature of the universe, astronomers found something odd. They discovered that a patch of sky, spanning the width of 20 moons, was unusually cold. The astronomers were measuring the thermal radiation that bathes the entire universe, a glowing relic of the big bang. To gaze at this cosmic microwave background, or CMB, is to glimpse the primordial1 universe, a time when it was less than 400,000 years old. The CMB blankets the sky, and looks pretty much the same everywhere, existing at a feebly cold temperature of 2.725 kelvins - just a couple degrees warmer than absolute zero. But armed with the newly launched WMAP satellite, the astronomers had set out to probe temperature variations as tiny as one part in 100,000. Born from the quantum froth that was the universe a half-moment after the big bang, those random fluctuations help scientists understand what the cosmos is made of and how it all came to be. And standing out amidst those fluctuations was a cold spot. Over the years, astronomers have come up with all sorts of ideas to explain it, ranging from instrumental error to parallel universes. But now, they're homing in on a prime suspect: an enormous cavern of emptiness called a cosmic supervoid, so big that it might be the largest structure in the universe. According to theory, such a vast void, in which nary a star or galaxy exists, can leave a frigid imprint on the CMB. The answer to the mystery, then, might simply be a whole lot of nothing. Yet puzzles remain, and the case is far from closed. Primordial1 - ancient, existing a very long time.", "hypothesis": "Investigation of fluctuations of temperature in the space help scientists to understand what the cosmos is made of.", "gold_label": "entailment"}
{"uid": "id_274", "premise": "The largest thing in the universe More than ten years ago, while taking the temperature of the universe, astronomers found something odd. They discovered that a patch of sky, spanning the width of 20 moons, was unusually cold. The astronomers were measuring the thermal radiation that bathes the entire universe, a glowing relic of the big bang. To gaze at this cosmic microwave background, or CMB, is to glimpse the primordial1 universe, a time when it was less than 400,000 years old. The CMB blankets the sky, and looks pretty much the same everywhere, existing at a feebly cold temperature of 2.725 kelvins - just a couple degrees warmer than absolute zero. But armed with the newly launched WMAP satellite, the astronomers had set out to probe temperature variations as tiny as one part in 100,000. Born from the quantum froth that was the universe a half-moment after the big bang, those random fluctuations help scientists understand what the cosmos is made of and how it all came to be. And standing out amidst those fluctuations was a cold spot. Over the years, astronomers have come up with all sorts of ideas to explain it, ranging from instrumental error to parallel universes. But now, they're homing in on a prime suspect: an enormous cavern of emptiness called a cosmic supervoid, so big that it might be the largest structure in the universe. According to theory, such a vast void, in which nary a star or galaxy exists, can leave a frigid imprint on the CMB. The answer to the mystery, then, might simply be a whole lot of nothing. Yet puzzles remain, and the case is far from closed. Primordial1 - ancient, existing a very long time.", "hypothesis": "The CMB is the thermal radiation across the entire universe.", "gold_label": "entailment"}
{"uid": "id_275", "premise": "The largest thing in the universe More than ten years ago, while taking the temperature of the universe, astronomers found something odd. They discovered that a patch of sky, spanning the width of 20 moons, was unusually cold. The astronomers were measuring the thermal radiation that bathes the entire universe, a glowing relic of the big bang. To gaze at this cosmic microwave background, or CMB, is to glimpse the primordial1 universe, a time when it was less than 400,000 years old. The CMB blankets the sky, and looks pretty much the same everywhere, existing at a feebly cold temperature of 2.725 kelvins - just a couple degrees warmer than absolute zero. But armed with the newly launched WMAP satellite, the astronomers had set out to probe temperature variations as tiny as one part in 100,000. Born from the quantum froth that was the universe a half-moment after the big bang, those random fluctuations help scientists understand what the cosmos is made of and how it all came to be. And standing out amidst those fluctuations was a cold spot. Over the years, astronomers have come up with all sorts of ideas to explain it, ranging from instrumental error to parallel universes. But now, they're homing in on a prime suspect: an enormous cavern of emptiness called a cosmic supervoid, so big that it might be the largest structure in the universe. According to theory, such a vast void, in which nary a star or galaxy exists, can leave a frigid imprint on the CMB. The answer to the mystery, then, might simply be a whole lot of nothing. Yet puzzles remain, and the case is far from closed. Primordial1 - ancient, existing a very long time.", "hypothesis": "Astronomers often find something odd on the sky.", "gold_label": "neutral"}
{"uid": "id_276", "premise": "The largest thing in the universe More than ten years ago, while taking the temperature of the universe, astronomers found something odd. They discovered that a patch of sky, spanning the width of 20 moons, was unusually cold. The astronomers were measuring the thermal radiation that bathes the entire universe, a glowing relic of the big bang. To gaze at this cosmic microwave background, or CMB, is to glimpse the primordial1 universe, a time when it was less than 400,000 years old. The CMB blankets the sky, and looks pretty much the same everywhere, existing at a feebly cold temperature of 2.725 kelvins - just a couple degrees warmer than absolute zero. But armed with the newly launched WMAP satellite, the astronomers had set out to probe temperature variations as tiny as one part in 100,000. Born from the quantum froth that was the universe a half-moment after the big bang, those random fluctuations help scientists understand what the cosmos is made of and how it all came to be. And standing out amidst those fluctuations was a cold spot. Over the years, astronomers have come up with all sorts of ideas to explain it, ranging from instrumental error to parallel universes. But now, they're homing in on a prime suspect: an enormous cavern of emptiness called a cosmic supervoid, so big that it might be the largest structure in the universe. According to theory, such a vast void, in which nary a star or galaxy exists, can leave a frigid imprint on the CMB. The answer to the mystery, then, might simply be a whole lot of nothing. Yet puzzles remain, and the case is far from closed. Primordial1 - ancient, existing a very long time.", "hypothesis": "The cosmic supervoid is the largest structure in the universe.", "gold_label": "neutral"}
{"uid": "id_277", "premise": "The law of benefits is a difficult channel, which requires careful sailing or rude boats. It is not the office of a man to receive gifts. How dare you give them? We wish to be self-sustained. We do not quite forgive a forgiver. The hand that feeds us is in some danger of being bitten. We can receive anything from love, for that is a way of receiving it from ourselves (hence the fitness of beautiful, not useful things for a gift); but not from anyone who assumes to bestow. We sometimes hate the meat that we eat, because there seems something of degrading dependence in living by it. He is a good man, who can receive a gift well. We are either glad or sorry at a gift, and both emotions are unbecoming. Some violence, I think, is done, some degradation borne, when I rejoice or grieve at a gift. I am sorry when my independence is invaded, or when a gift comes from such as do not know my spirit, and so the act is not supported; and if the gift pleases me overmuch, then I should be ashamed that the donor should read my heart and see that I love his commodity, and not him. This giving is flat usurpation, and therefore, when the beneficiary is ungrateful, as all beneficiaries hate all Timons, not at all considering the value of the gift, but looking back to the greater store it was taken from, I rather sympathise with the beneficiary than with the anger of my lord, Timon. For, the expectation of gratitude is mean and is continually punished by the total insensibility of the obliged person.", "hypothesis": "The author of this passage does not like to receive gifts.", "gold_label": "contradiction"}
{"uid": "id_278", "premise": "The leaders of a society might argue they have abolished poverty if they ensure that no citizens are homeless or starving. In developed Western societies, few would accept so narrow a definition. They are very likely to add further indicators such as the level of income, the standard of housing, the quality of diet, and access to everyday commodities such as heating, running hot water, a bath and a washing machine. The list soon grows from items essential to support life to include things that a society views as impracticable to be without. It is clear, therefore, that most people do not mean absolute poverty when they use the term, but something much more relative and dependent on the society in which they live. Because for most people poverty is a relative concept, its abolition is much more difficult. Poverty ends up being defined in terms of people who live on a percentage of the median income.", "hypothesis": "Absolute poverty would be cured if the poorest in society were fed, clothed and housed.", "gold_label": "entailment"}
{"uid": "id_279", "premise": "The leaders of a society might argue they have abolished poverty if they ensure that no citizens are homeless or starving. In developed Western societies, few would accept so narrow a definition. They are very likely to add further indicators such as the level of income, the standard of housing, the quality of diet, and access to everyday commodities such as heating, running hot water, a bath and a washing machine. The list soon grows from items essential to support life to include things that a society views as impracticable to be without. It is clear, therefore, that most people do not mean absolute poverty when they use the term, but something much more relative and dependent on the society in which they live. Because for most people poverty is a relative concept, its abolition is much more difficult. Poverty ends up being defined in terms of people who live on a percentage of the median income.", "hypothesis": "If poverty is defined in terms of people who live on a percentage of the median income, then the number of people classed as in poverty could increase not because people are poorer but because they are not becoming richer as fast as the majority in their society.", "gold_label": "entailment"}
{"uid": "id_280", "premise": "The leaders of a society might argue they have abolished poverty if they ensure that no citizens are homeless or starving. In developed Western societies, few would accept so narrow a definition. They are very likely to add further indicators such as the level of income, the standard of housing, the quality of diet, and access to everyday commodities such as heating, running hot water, a bath and a washing machine. The list soon grows from items essential to support life to include things that a society views as impracticable to be without. It is clear, therefore, that most people do not mean absolute poverty when they use the term, but something much more relative and dependent on the society in which they live. Because for most people poverty is a relative concept, its abolition is much more difficult. Poverty ends up being defined in terms of people who live on a percentage of the median income.", "hypothesis": "A hundred years ago people would have included in their definition of poverty many of the items listed in the passage as indicators of poverty in developed Western societies.", "gold_label": "contradiction"}
{"uid": "id_281", "premise": "The legal term double jeopardy refers to a second prosecution of an individual for an offence for which he has already been prosecuted. Double jeopardy is famously prohibited in the Fifth Amendment of the United States constitution, which states that no person shall, be subject for the same offence to be twice put in jeopardy of life or limb. Not only does the double jeopardy doctrine uphold the finality of criminal proceedings, it also protects individuals from the stress of multiple prosecutions. Despite dating back to Roman times, this legal rule is often challenged. Some legal reform advocates believe that a second trial should be permitted if significant new evidence becomes available for example DNA evidence can reveal more using more recent technology. Double jeopardy laws are intended to protect innocent people from continual harassment by the state. They also prevent a defendant from receiving successive trials for the same offence for instance, someone found guilty of murder cannot also be tried for manslaughter for the same act. Some exceptions exist. A new trial is allowed if the original trial is declared a mistrial, or if an appeal against a conviction is successful. The rules also do not restrict a different sovereignty from prosecuting for the same offence. Similarly, in the United States, civil proceedings can be brought against someone who has already been acquitted or convicted of committing the offence.", "hypothesis": "Under double jeopardy rules, someone who has been acquitted of a crime can never be retried for the same offence.", "gold_label": "contradiction"}
{"uid": "id_282", "premise": "The legal term double jeopardy refers to a second prosecution of an individual for an offence for which he has already been prosecuted. Double jeopardy is famously prohibited in the Fifth Amendment of the United States constitution, which states that no person shall, be subject for the same offence to be twice put in jeopardy of life or limb. Not only does the double jeopardy doctrine uphold the finality of criminal proceedings, it also protects individuals from the stress of multiple prosecutions. Despite dating back to Roman times, this legal rule is often challenged. Some legal reform advocates believe that a second trial should be permitted if significant new evidence becomes available for example DNA evidence can reveal more using more recent technology. Double jeopardy laws are intended to protect innocent people from continual harassment by the state. They also prevent a defendant from receiving successive trials for the same offence for instance, someone found guilty of murder cannot also be tried for manslaughter for the same act. Some exceptions exist. A new trial is allowed if the original trial is declared a mistrial, or if an appeal against a conviction is successful. The rules also do not restrict a different sovereignty from prosecuting for the same offence. Similarly, in the United States, civil proceedings can be brought against someone who has already been acquitted or convicted of committing the offence.", "hypothesis": "Double jeopardy laws exist to prevent the government from persecuting innocent individuals.", "gold_label": "entailment"}
{"uid": "id_283", "premise": "The legal term double jeopardy refers to a second prosecution of an individual for an offence for which he has already been prosecuted. Double jeopardy is famously prohibited in the Fifth Amendment of the United States constitution, which states that no person shall, be subject for the same offence to be twice put in jeopardy of life or limb. Not only does the double jeopardy doctrine uphold the finality of criminal proceedings, it also protects individuals from the stress of multiple prosecutions. Despite dating back to Roman times, this legal rule is often challenged. Some legal reform advocates believe that a second trial should be permitted if significant new evidence becomes available for example DNA evidence can reveal more using more recent technology. Double jeopardy laws are intended to protect innocent people from continual harassment by the state. They also prevent a defendant from receiving successive trials for the same offence for instance, someone found guilty of murder cannot also be tried for manslaughter for the same act. Some exceptions exist. A new trial is allowed if the original trial is declared a mistrial, or if an appeal against a conviction is successful. The rules also do not restrict a different sovereignty from prosecuting for the same offence. Similarly, in the United States, civil proceedings can be brought against someone who has already been acquitted or convicted of committing the offence.", "hypothesis": "The double jeopardy rule was first expressed in the Fifth Amendment of the United States constitution.", "gold_label": "contradiction"}
{"uid": "id_284", "premise": "The legal term double jeopardy refers to a second prosecution of an individual for an offence for which he has already been prosecuted. Double jeopardy is famously prohibited in the Fifth Amendment of the United States constitution, which states that no person shall, be subject for the same offence to be twice put in jeopardy of life or limb. Not only does the double jeopardy doctrine uphold the finality of criminal proceedings, it also protects individuals from the stress of multiple prosecutions. Despite dating back to Roman times, this legal rule is often challenged. Some legal reform advocates believe that a second trial should be permitted if significant new evidence becomes available for example DNA evidence can reveal more using more recent technology. Double jeopardy laws are intended to protect innocent people from continual harassment by the state. They also prevent a defendant from receiving successive trials for the same offence for instance, someone found guilty of murder cannot also be tried for manslaughter for the same act. Some exceptions exist. A new trial is allowed if the original trial is declared a mistrial, or if an appeal against a conviction is successful. The rules also do not restrict a different sovereignty from prosecuting for the same offence. Similarly, in the United States, civil proceedings can be brought against someone who has already been acquitted or convicted of committing the offence.", "hypothesis": "New technology can shed new light on old cases.", "gold_label": "entailment"}
{"uid": "id_285", "premise": "The legal term double jeopardy refers to a second prosecution of an individual for an offence for which he has already been prosecuted. Double jeopardy is famously prohibited in the Fifth Amendment of the United States constitution, which states that no person shall, be subject for the same offence to be twice put in jeopardy of life or limb. Not only does the double jeopardy doctrine uphold the finality of criminal proceedings, it also protects individuals from the stress of multiple prosecutions. Despite dating back to Roman times, this legal rule is often challenged. Some legal reform advocates believe that a second trial should be permitted if significant new evidence becomes available for example DNA evidence can reveal more using more recent technology. Double jeopardy laws are intended to protect innocent people from continual harassment by the state. They also prevent a defendant from receiving successive trials for the same offence for instance, someone found guilty of murder cannot also be tried for manslaughter for the same act. Some exceptions exist. A new trial is allowed if the original trial is declared a mistrial, or if an appeal against a conviction is successful. The rules also do not restrict a different sovereignty from prosecuting for the same offence. Similarly, in the United States, civil proceedings can be brought against someone who has already been acquitted or convicted of committing the offence.", "hypothesis": "Criminal and civil proceedings fulfil different objectives in the United States.", "gold_label": "neutral"}
{"uid": "id_286", "premise": "The legislative maternity privileges shape a minimum standard of protection recognised by Parliament. Women and their employers (or their legislative bodies) are able to negotiate and consent to more constructive provision on a voluntary or contractual foundation, if they feel that this would be more beneficial in the long term. Where an employer and employee have agreed diverse provisions, an employee will always be able to declare her statutory rights if these are better than those agreed with her employer, therefore if the employee wishes a term by maternity privileges she is able to do so. This therefore means that an employee will not be obliged to accept maternity arrangements which are not as good as the legislative rights. In order to qualify for Statutory Maternity Pay, an employee will have to be an employed earner, therefore the employee will need to work for an organisation that is liable to pay the employees share of National Insurance contributions. To qualify for Maternity Allowance an employee must be, or have recently been either an employed or self-employed earner. The majority of people, who qualify for leave will also qualify for pay, and vice versa. All employees who are parents to new babies have a right to statutory leave with pay. However, there are a few legal clauses. For instance, the privileges relating to time off for antenatal care, to maternity leave and to protection against detriment or unfair dismissal in connection with maternity leave do not apply to the following groups: members of the police force, MPs, the judiciary and various company directors, or to masters or crew members engaged in share fishing paid solely by how much stock they have caught.", "hypothesis": "The statement is false as it refers to Maternity Allowance instead of Statutory Maternity Pay (where the grounds to qualify are dependant on the employer paying the employees share of National Insurance contributions). Do not make the mistake of assuming different terms mean the same thing. C Men are allowed time off if they are a parent to a new baby", "gold_label": "entailment"}
{"uid": "id_287", "premise": "The legislative maternity privileges shape a minimum standard of protection recognised by Parliament. Women and their employers (or their legislative bodies) are able to negotiate and consent to more constructive provision on a voluntary or contractual foundation, if they feel that this would be more beneficial in the long term. Where an employer and employee have agreed diverse provisions, an employee will always be able to declare her statutory rights if these are better than those agreed with her employer, therefore if the employee wishes a term by maternity privileges she is able to do so. This therefore means that an employee will not be obliged to accept maternity arrangements which are not as good as the legislative rights. In order to qualify for Statutory Maternity Pay, an employee will have to be an employed earner, therefore the employee will need to work for an organisation that is liable to pay the employees share of National Insurance contributions. To qualify for Maternity Allowance an employee must be, or have recently been either an employed or self-employed earner. The majority of people, who qualify for leave will also qualify for pay, and vice versa. All employees who are parents to new babies have a right to statutory leave with pay. However, there are a few legal clauses. For instance, the privileges relating to time off for antenatal care, to maternity leave and to protection against detriment or unfair dismissal in connection with maternity leave do not apply to the following groups: members of the police force, MPs, the judiciary and various company directors, or to masters or crew members engaged in share fishing paid solely by how much stock they have caught.", "hypothesis": "In order for an individual to qualify for maternity allowance, an employee will have to work for an organisation who are liable to pay the employees share of National Insurance contributions", "gold_label": "contradiction"}
{"uid": "id_288", "premise": "The legislative maternity privileges shape a minimum standard of protection recognised by Parliament. Women and their employers (or their legislative bodies) are able to negotiate and consent to more constructive provision on a voluntary or contractual foundation, if they feel that this would be more beneficial in the long term. Where an employer and employee have agreed diverse provisions, an employee will always be able to declare her statutory rights if these are better than those agreed with her employer, therefore if the employee wishes a term by maternity privileges she is able to do so. This therefore means that an employee will not be obliged to accept maternity arrangements which are not as good as the legislative rights. In order to qualify for Statutory Maternity Pay, an employee will have to be an employed earner, therefore the employee will need to work for an organisation that is liable to pay the employees share of National Insurance contributions. To qualify for Maternity Allowance an employee must be, or have recently been either an employed or self-employed earner. The majority of people, who qualify for leave will also qualify for pay, and vice versa. All employees who are parents to new babies have a right to statutory leave with pay. However, there are a few legal clauses. For instance, the privileges relating to time off for antenatal care, to maternity leave and to protection against detriment or unfair dismissal in connection with maternity leave do not apply to the following groups: members of the police force, MPs, the judiciary and various company directors, or to masters or crew members engaged in share fishing paid solely by how much stock they have caught.", "hypothesis": "All women are entitled to legislative maternity privileges", "gold_label": "contradiction"}
{"uid": "id_289", "premise": "The legislative maternity privileges shape a minimum standard of protection recognised by Parliament. Women and their employers (or their legislative bodies) are able to negotiate and consent to more constructive provision on a voluntary or contractual foundation, if they feel that this would be more beneficial in the long term. Where an employer and employee have agreed diverse provisions, an employee will always be able to declare her statutory rights if these are better than those agreed with her employer, therefore if the employee wishes a term by maternity privileges she is able to do so. This therefore means that an employee will not be obliged to accept maternity arrangements which are not as good as the legislative rights. In order to qualify for Statutory Maternity Pay, an employee will have to be an employed earner, therefore the employee will need to work for an organisation that is liable to pay the employees share of National Insurance contributions. To qualify for Maternity Allowance an employee must be, or have recently been either an employed or self-employed earner. The majority of people, who qualify for leave will also qualify for pay, and vice versa. All employees who are parents to new babies have a right to statutory leave with pay. However, there are a few legal clauses. For instance, the privileges relating to time off for antenatal care, to maternity leave and to protection against detriment or unfair dismissal in connection with maternity leave do not apply to the following groups: members of the police force, MPs, the judiciary and various company directors, or to masters or crew members engaged in share fishing paid solely by how much stock they have caught.", "hypothesis": "Men are allowed time off if they are a parent to a new baby", "gold_label": "entailment"}
{"uid": "id_290", "premise": "The legislative maternity privileges shape a minimum standard of protection recognised by Parliament. Women and their employers (or their legislative bodies) are able to negotiate and consent to more constructive provision on a voluntary or contractual foundation, if they feel that this would be more beneficial in the long term. Where an employer and employee have agreed diverse provisions, an employee will always be able to declare her statutory rights if these are better than those agreed with her employer, therefore if the employee wishes a term by maternity privileges she is able to do so. This therefore means that an employee will not be obliged to accept maternity arrangements which are not as good as the legislative rights. In order to qualify for Statutory Maternity Pay, an employee will have to be an employed earner, therefore the employee will need to work for an organisation that is liable to pay the employees share of National Insurance contributions. To qualify for Maternity Allowance an employee must be, or have recently been either an employed or self-employed earner. The majority of people, who qualify for leave will also qualify for pay, and vice versa. All employees who are parents to new babies have a right to statutory leave with pay. However, there are a few legal clauses. For instance, the privileges relating to time off for antenatal care, to maternity leave and to protection against detriment or unfair dismissal in connection with maternity leave do not apply to the following groups: members of the police force, MPs, the judiciary and various company directors, or to masters or crew members engaged in share fishing paid solely by how much stock they have caught.", "hypothesis": "The rights described in the passage above only relate to employees and not those who are unemployed.", "gold_label": "entailment"}
{"uid": "id_291", "premise": "The level of air pollution in London is at a record high, with the level of nitrogen dioxide (NO2) the highest of any EU country. As a result of such high levels of pollution, the UK has received a number of warnings from the EU for its failure to comply with European laws, and may face a possible fine. In addition to this, experts warn that the levels of pollution will affect the weather; leading to periods of storm like weather throughout the summer months and an increase in temperature in the winter. Such pollutants are particularly problematic for those who run in the city on a regular basis; leading to chest pains, a decrease in lung capacity and coughing and other problems.", "hypothesis": "The UK has been fined for the high levels of pollution in London.", "gold_label": "neutral"}
{"uid": "id_292", "premise": "The level of air pollution in London is at a record high, with the level of nitrogen dioxide (NO2) the highest of any EU country. As a result of such high levels of pollution, the UK has received a number of warnings from the EU for its failure to comply with European laws, and may face a possible fine. In addition to this, experts warn that the levels of pollution will affect the weather; leading to periods of storm like weather throughout the summer months and an increase in temperature in the winter. Such pollutants are particularly problematic for those who run in the city on a regular basis; leading to chest pains, a decrease in lung capacity and coughing and other problems.", "hypothesis": "London has the highest level of nitrogen dioxide in Europe.", "gold_label": "entailment"}
{"uid": "id_293", "premise": "The level of air pollution in London is at a record high, with the level of nitrogen dioxide (NO2) the highest of any EU country. As a result of such high levels of pollution, the UK has received a number of warnings from the EU for its failure to comply with European laws, and may face a possible fine. In addition to this, experts warn that the levels of pollution will affect the weather; leading to periods of storm like weather throughout the summer months and an increase in temperature in the winter. Such pollutants are particularly problematic for those who run in the city on a regular basis; leading to chest pains, a decrease in lung capacity and coughing and other problems.", "hypothesis": "Running often in the city does not cause chest pains", "gold_label": "contradiction"}
{"uid": "id_294", "premise": "The level of air pollution in London is at a record high, with the level of nitrogen dioxide (NO2) the highest of any EU country. As a result of such high levels of pollution, the UK has received a number of warnings from the EU for its failure to comply with European laws, and may face a possible fine. In addition to this, experts warn that the levels of pollution will affect the weather; leading to periods of storm like weather throughout the summer months and an increase in temperature in the winter. Such pollutants are particularly problematic for those who run in the city on a regular basis; leading to chest pains, a decrease in lung capacity and coughing and other problems.", "hypothesis": "European laws ban the production of nitrogen dioxide.", "gold_label": "neutral"}
{"uid": "id_295", "premise": "The life and work of Marie Curie Marie Curie is probably the most famous woman scientist who has ever lived. Born Maria Sklodowska in Poland in 1867, she is famous for her work on radioactivity, and was twice a winner of the Nobel Prize. With her husband, Pierre Curie, and Henri Becquerel, she was awarded the 1903 Nobel Prize for Physics, and was then sole winner of the 1911 Nobel Prize for Chemistry. She was the first woman to win a Nobel Prize. From childhood, Marie was remarkable for her prodigious memory, and at the age of 16 won a gold medal on completion of her secondary education. Because her father lost his savings through bad investment, she then had to take work as a teacher. From her earnings she was able to finance her sister Bronia's medical studies in Paris, on the understanding that Bronia would, in turn, later help her to get an education. In 1891 this promise was fulfilled and Marie went to Paris and began to study at the Sorbonne (the University of Paris). She often worked far into the night and lived on little more than bread and butter and tea. She came first in the examination in the physical sciences in 1893, and in 1894 was placed second in the examination in mathematical sciences. It was not until the spring of that year that she was introduced to Pierre Curie. Their marriage in 1895 marked the start of a partnership that was soon to achieve results of world significance. Following Henri Becquerel's discovery in 1896 of a new phenomenon, which Marie later called 'radioactivity', Marie Curie decided to find out if the radioactivity discovered in uranium was to be found in other elements. She discovered that this was true for thorium. Turning her attention to minerals, she found her interest drawn to pitchblende, a mineral whose radioactivity, superior to that of pure uranium, could be explained only by the presence in the ore of small quantities of an unknown substance of very high activity. Pierre Curie joined her in the work that she had undertaken to resolve this problem, and that led to the discovery of the new elements, polonium and radium. While Pierre Curie devoted himself chiefly to the physical study of the new radiations, Marie Curie struggled to obtain pure radium in the metallic state. This was achieved with the help of the chemist Andre-Louis Debierne, one of Pierre Curie's pupils. Based on the results of this research, Marie Curie received her Doctorate of Science, and in 1903 Marie and Pierre shared with Becquerel the Nobel Prize for Physics for the discovery of radioactivity. The births of Marie's two daughters, Irene and Eve, in 1897 and 1904 failed to interrupt her scientific work. She was appointed lecturer in physics at the Ecole Normale Superieure for girls in Sevres, France (1900), and introduced a method of teaching based on experimental demonstrations. In December 1904 she was appointed chief assistant in the laboratory directed by Pierre Curie. The sudden death of her husband in 1906 was a bitter blow to Marie Curie, but was also a turning point in her career: henceforth she was to devote all her energy to completing alone the scientific work that they had undertaken. On May 13, 1906, she was appointed to the professorship that had been left vacant on her husband's death, becoming the first woman to teach at the Sorbonne. In 1911 she was awarded the Nobel Prize for Chemistry for the isolation of a pure form of radium. During World War I, Marie Curie, with the help of her daughter Irene, devoted herself to the development of the use of X-radiography, including the mobile units which came to be known as Little Curies', used for the treatment of wounded soldiers. In 1918 the Radium Institute, whose staff Irene had joined, began to operate in earnest, and became a centre for nuclear physics and chemistry. Marie Curie, now at the highest point of her 36fame and, from 1922, a member of the Academy of Medicine, researched the chemistry of radioactive substances and their medical applications. In 1921, accompanied by her two daughters, Marie Curie made a triumphant journey to the United States to raise funds for research on radium. Women there presented her with a gram of radium for her campaign. Marie also gave lectures in Belgium, Brazil, Spain and Czechoslovakia and, in addition, had the satisfaction of seeing the development of the Curie Foundation in Paris, and the inauguration in 1932 in Warsaw of the Radium Institute, where her sister Bronia became director. One of Marie Curie's outstanding achievements was to have understood the need to accumulateintense radioactive sources, not only to treat illness but also to maintain an abundant supply for research. The existence in Paris at the Radium Institute of a stock of 1.5 grams of radium made a decisive contribution to the success of the experiments undertaken in the years around 1930. This work prepared the way for the discovery of the neutron by Sir James Chadwick and, above all, for the discovery in 1934 by Irene and Frederic Joliot-Curie of artificial radioactivity. A few months after this discovery, Marie Curie died as a result of leukaemia caused by exposure to radiation. She had often carried test tubes containing radioactive isotopes in her pocket, remarking on the pretty blue-green light they gave off. Her contribution to physics had been immense, not only in her own work, the importance of which had been demonstrated by her two Nobel Prizes, but because of her influence on subsequent generations of nuclear physicists and chemists.", "hypothesis": "Marie took over the teaching position her husband had held.", "gold_label": "contradiction"}
{"uid": "id_296", "premise": "The life and work of Marie Curie Marie Curie is probably the most famous woman scientist who has ever lived. Born Maria Sklodowska in Poland in 1867, she is famous for her work on radioactivity, and was twice a winner of the Nobel Prize. With her husband, Pierre Curie, and Henri Becquerel, she was awarded the 1903 Nobel Prize for Physics, and was then sole winner of the 1911 Nobel Prize for Chemistry. She was the first woman to win a Nobel Prize. From childhood, Marie was remarkable for her prodigious memory, and at the age of 16 won a gold medal on completion of her secondary education. Because her father lost his savings through bad investment, she then had to take work as a teacher. From her earnings she was able to finance her sister Bronia's medical studies in Paris, on the understanding that Bronia would, in turn, later help her to get an education. In 1891 this promise was fulfilled and Marie went to Paris and began to study at the Sorbonne (the University of Paris). She often worked far into the night and lived on little more than bread and butter and tea. She came first in the examination in the physical sciences in 1893, and in 1894 was placed second in the examination in mathematical sciences. It was not until the spring of that year that she was introduced to Pierre Curie. Their marriage in 1895 marked the start of a partnership that was soon to achieve results of world significance. Following Henri Becquerel's discovery in 1896 of a new phenomenon, which Marie later called 'radioactivity', Marie Curie decided to find out if the radioactivity discovered in uranium was to be found in other elements. She discovered that this was true for thorium. Turning her attention to minerals, she found her interest drawn to pitchblende, a mineral whose radioactivity, superior to that of pure uranium, could be explained only by the presence in the ore of small quantities of an unknown substance of very high activity. Pierre Curie joined her in the work that she had undertaken to resolve this problem, and that led to the discovery of the new elements, polonium and radium. While Pierre Curie devoted himself chiefly to the physical study of the new radiations, Marie Curie struggled to obtain pure radium in the metallic state. This was achieved with the help of the chemist Andre-Louis Debierne, one of Pierre Curie's pupils. Based on the results of this research, Marie Curie received her Doctorate of Science, and in 1903 Marie and Pierre shared with Becquerel the Nobel Prize for Physics for the discovery of radioactivity. The births of Marie's two daughters, Irene and Eve, in 1897 and 1904 failed to interrupt her scientific work. She was appointed lecturer in physics at the Ecole Normale Superieure for girls in Sevres, France (1900), and introduced a method of teaching based on experimental demonstrations. In December 1904 she was appointed chief assistant in the laboratory directed by Pierre Curie. The sudden death of her husband in 1906 was a bitter blow to Marie Curie, but was also a turning point in her career: henceforth she was to devote all her energy to completing alone the scientific work that they had undertaken. On May 13, 1906, she was appointed to the professorship that had been left vacant on her husband's death, becoming the first woman to teach at the Sorbonne. In 1911 she was awarded the Nobel Prize for Chemistry for the isolation of a pure form of radium. During World War I, Marie Curie, with the help of her daughter Irene, devoted herself to the development of the use of X-radiography, including the mobile units which came to be known as Little Curies', used for the treatment of wounded soldiers. In 1918 the Radium Institute, whose staff Irene had joined, began to operate in earnest, and became a centre for nuclear physics and chemistry. Marie Curie, now at the highest point of her 36fame and, from 1922, a member of the Academy of Medicine, researched the chemistry of radioactive substances and their medical applications. In 1921, accompanied by her two daughters, Marie Curie made a triumphant journey to the United States to raise funds for research on radium. Women there presented her with a gram of radium for her campaign. Marie also gave lectures in Belgium, Brazil, Spain and Czechoslovakia and, in addition, had the satisfaction of seeing the development of the Curie Foundation in Paris, and the inauguration in 1932 in Warsaw of the Radium Institute, where her sister Bronia became director. One of Marie Curie's outstanding achievements was to have understood the need to accumulateintense radioactive sources, not only to treat illness but also to maintain an abundant supply for research. The existence in Paris at the Radium Institute of a stock of 1.5 grams of radium made a decisive contribution to the success of the experiments undertaken in the years around 1930. This work prepared the way for the discovery of the neutron by Sir James Chadwick and, above all, for the discovery in 1934 by Irene and Frederic Joliot-Curie of artificial radioactivity. A few months after this discovery, Marie Curie died as a result of leukaemia caused by exposure to radiation. She had often carried test tubes containing radioactive isotopes in her pocket, remarking on the pretty blue-green light they gave off. Her contribution to physics had been immense, not only in her own work, the importance of which had been demonstrated by her two Nobel Prizes, but because of her influence on subsequent generations of nuclear physicists and chemists.", "hypothesis": "Marie stopped doing research for several years when her children were born.", "gold_label": "entailment"}
{"uid": "id_297", "premise": "The life and work of Marie Curie Marie Curie is probably the most famous woman scientist who has ever lived. Born Maria Sklodowska in Poland in 1867, she is famous for her work on radioactivity, and was twice a winner of the Nobel Prize. With her husband, Pierre Curie, and Henri Becquerel, she was awarded the 1903 Nobel Prize for Physics, and was then sole winner of the 1911 Nobel Prize for Chemistry. She was the first woman to win a Nobel Prize. From childhood, Marie was remarkable for her prodigious memory, and at the age of 16 won a gold medal on completion of her secondary education. Because her father lost his savings through bad investment, she then had to take work as a teacher. From her earnings she was able to finance her sister Bronia's medical studies in Paris, on the understanding that Bronia would, in turn, later help her to get an education. In 1891 this promise was fulfilled and Marie went to Paris and began to study at the Sorbonne (the University of Paris). She often worked far into the night and lived on little more than bread and butter and tea. She came first in the examination in the physical sciences in 1893, and in 1894 was placed second in the examination in mathematical sciences. It was not until the spring of that year that she was introduced to Pierre Curie. Their marriage in 1895 marked the start of a partnership that was soon to achieve results of world significance. Following Henri Becquerel's discovery in 1896 of a new phenomenon, which Marie later called 'radioactivity', Marie Curie decided to find out if the radioactivity discovered in uranium was to be found in other elements. She discovered that this was true for thorium. Turning her attention to minerals, she found her interest drawn to pitchblende, a mineral whose radioactivity, superior to that of pure uranium, could be explained only by the presence in the ore of small quantities of an unknown substance of very high activity. Pierre Curie joined her in the work that she had undertaken to resolve this problem, and that led to the discovery of the new elements, polonium and radium. While Pierre Curie devoted himself chiefly to the physical study of the new radiations, Marie Curie struggled to obtain pure radium in the metallic state. This was achieved with the help of the chemist Andre-Louis Debierne, one of Pierre Curie's pupils. Based on the results of this research, Marie Curie received her Doctorate of Science, and in 1903 Marie and Pierre shared with Becquerel the Nobel Prize for Physics for the discovery of radioactivity. The births of Marie's two daughters, Irene and Eve, in 1897 and 1904 failed to interrupt her scientific work. She was appointed lecturer in physics at the Ecole Normale Superieure for girls in Sevres, France (1900), and introduced a method of teaching based on experimental demonstrations. In December 1904 she was appointed chief assistant in the laboratory directed by Pierre Curie. The sudden death of her husband in 1906 was a bitter blow to Marie Curie, but was also a turning point in her career: henceforth she was to devote all her energy to completing alone the scientific work that they had undertaken. On May 13, 1906, she was appointed to the professorship that had been left vacant on her husband's death, becoming the first woman to teach at the Sorbonne. In 1911 she was awarded the Nobel Prize for Chemistry for the isolation of a pure form of radium. During World War I, Marie Curie, with the help of her daughter Irene, devoted herself to the development of the use of X-radiography, including the mobile units which came to be known as Little Curies', used for the treatment of wounded soldiers. In 1918 the Radium Institute, whose staff Irene had joined, began to operate in earnest, and became a centre for nuclear physics and chemistry. Marie Curie, now at the highest point of her 36fame and, from 1922, a member of the Academy of Medicine, researched the chemistry of radioactive substances and their medical applications. In 1921, accompanied by her two daughters, Marie Curie made a triumphant journey to the United States to raise funds for research on radium. Women there presented her with a gram of radium for her campaign. Marie also gave lectures in Belgium, Brazil, Spain and Czechoslovakia and, in addition, had the satisfaction of seeing the development of the Curie Foundation in Paris, and the inauguration in 1932 in Warsaw of the Radium Institute, where her sister Bronia became director. One of Marie Curie's outstanding achievements was to have understood the need to accumulateintense radioactive sources, not only to treat illness but also to maintain an abundant supply for research. The existence in Paris at the Radium Institute of a stock of 1.5 grams of radium made a decisive contribution to the success of the experiments undertaken in the years around 1930. This work prepared the way for the discovery of the neutron by Sir James Chadwick and, above all, for the discovery in 1934 by Irene and Frederic Joliot-Curie of artificial radioactivity. A few months after this discovery, Marie Curie died as a result of leukaemia caused by exposure to radiation. She had often carried test tubes containing radioactive isotopes in her pocket, remarking on the pretty blue-green light they gave off. Her contribution to physics had been immense, not only in her own work, the importance of which had been demonstrated by her two Nobel Prizes, but because of her influence on subsequent generations of nuclear physicists and chemists.", "hypothesis": "Maries sister Bronia studied the medical uses of radioactivity.", "gold_label": "entailment"}
{"uid": "id_298", "premise": "The life and work of Marie Curie Marie Curie is probably the most famous woman scientist who has ever lived. Born Maria Sklodowska in Poland in 1867, she is famous for her work on radioactivity, and was twice a winner of the Nobel Prize. With her husband, Pierre Curie, and Henri Becquerel, she was awarded the 1903 Nobel Prize for Physics, and was then sole winner of the 1911 Nobel Prize for Chemistry. She was the first woman to win a Nobel Prize. From childhood, Marie was remarkable for her prodigious memory, and at the age of 16 won a gold medal on completion of her secondary education. Because her father lost his savings through bad investment, she then had to take work as a teacher. From her earnings she was able to finance her sister Bronia's medical studies in Paris, on the understanding that Bronia would, in turn, later help her to get an education. In 1891 this promise was fulfilled and Marie went to Paris and began to study at the Sorbonne (the University of Paris). She often worked far into the night and lived on little more than bread and butter and tea. She came first in the examination in the physical sciences in 1893, and in 1894 was placed second in the examination in mathematical sciences. It was not until the spring of that year that she was introduced to Pierre Curie. Their marriage in 1895 marked the start of a partnership that was soon to achieve results of world significance. Following Henri Becquerel's discovery in 1896 of a new phenomenon, which Marie later called 'radioactivity', Marie Curie decided to find out if the radioactivity discovered in uranium was to be found in other elements. She discovered that this was true for thorium. Turning her attention to minerals, she found her interest drawn to pitchblende, a mineral whose radioactivity, superior to that of pure uranium, could be explained only by the presence in the ore of small quantities of an unknown substance of very high activity. Pierre Curie joined her in the work that she had undertaken to resolve this problem, and that led to the discovery of the new elements, polonium and radium. While Pierre Curie devoted himself chiefly to the physical study of the new radiations, Marie Curie struggled to obtain pure radium in the metallic state. This was achieved with the help of the chemist Andre-Louis Debierne, one of Pierre Curie's pupils. Based on the results of this research, Marie Curie received her Doctorate of Science, and in 1903 Marie and Pierre shared with Becquerel the Nobel Prize for Physics for the discovery of radioactivity. The births of Marie's two daughters, Irene and Eve, in 1897 and 1904 failed to interrupt her scientific work. She was appointed lecturer in physics at the Ecole Normale Superieure for girls in Sevres, France (1900), and introduced a method of teaching based on experimental demonstrations. In December 1904 she was appointed chief assistant in the laboratory directed by Pierre Curie. The sudden death of her husband in 1906 was a bitter blow to Marie Curie, but was also a turning point in her career: henceforth she was to devote all her energy to completing alone the scientific work that they had undertaken. On May 13, 1906, she was appointed to the professorship that had been left vacant on her husband's death, becoming the first woman to teach at the Sorbonne. In 1911 she was awarded the Nobel Prize for Chemistry for the isolation of a pure form of radium. During World War I, Marie Curie, with the help of her daughter Irene, devoted herself to the development of the use of X-radiography, including the mobile units which came to be known as Little Curies', used for the treatment of wounded soldiers. In 1918 the Radium Institute, whose staff Irene had joined, began to operate in earnest, and became a centre for nuclear physics and chemistry. Marie Curie, now at the highest point of her 36fame and, from 1922, a member of the Academy of Medicine, researched the chemistry of radioactive substances and their medical applications. In 1921, accompanied by her two daughters, Marie Curie made a triumphant journey to the United States to raise funds for research on radium. Women there presented her with a gram of radium for her campaign. Marie also gave lectures in Belgium, Brazil, Spain and Czechoslovakia and, in addition, had the satisfaction of seeing the development of the Curie Foundation in Paris, and the inauguration in 1932 in Warsaw of the Radium Institute, where her sister Bronia became director. One of Marie Curie's outstanding achievements was to have understood the need to accumulateintense radioactive sources, not only to treat illness but also to maintain an abundant supply for research. The existence in Paris at the Radium Institute of a stock of 1.5 grams of radium made a decisive contribution to the success of the experiments undertaken in the years around 1930. This work prepared the way for the discovery of the neutron by Sir James Chadwick and, above all, for the discovery in 1934 by Irene and Frederic Joliot-Curie of artificial radioactivity. A few months after this discovery, Marie Curie died as a result of leukaemia caused by exposure to radiation. She had often carried test tubes containing radioactive isotopes in her pocket, remarking on the pretty blue-green light they gave off. Her contribution to physics had been immense, not only in her own work, the importance of which had been demonstrated by her two Nobel Prizes, but because of her influence on subsequent generations of nuclear physicists and chemists.", "hypothesis": "Marie Curies husband was a joint winner of both Maries Nobel Prizes.", "gold_label": "contradiction"}
{"uid": "id_299", "premise": "The life and work of Marie Curie Marie Curie is probably the most famous woman scientist who has ever lived. Born Maria Sklodowska in Poland in 1867, she is famous for her work on radioactivity, and was twice a winner of the Nobel Prize. With her husband, Pierre Curie, and Henri Becquerel, she was awarded the 1903 Nobel Prize for Physics, and was then sole winner of the 1911 Nobel Prize for Chemistry. She was the first woman to win a Nobel Prize. From childhood, Marie was remarkable for her prodigious memory, and at the age of 16 won a gold medal on completion of her secondary education. Because her father lost his savings through bad investment, she then had to take work as a teacher. From her earnings she was able to finance her sister Bronia's medical studies in Paris, on the understanding that Bronia would, in turn, later help her to get an education. In 1891 this promise was fulfilled and Marie went to Paris and began to study at the Sorbonne (the University of Paris). She often worked far into the night and lived on little more than bread and butter and tea. She came first in the examination in the physical sciences in 1893, and in 1894 was placed second in the examination in mathematical sciences. It was not until the spring of that year that she was introduced to Pierre Curie. Their marriage in 1895 marked the start of a partnership that was soon to achieve results of world significance. Following Henri Becquerel's discovery in 1896 of a new phenomenon, which Marie later called 'radioactivity', Marie Curie decided to find out if the radioactivity discovered in uranium was to be found in other elements. She discovered that this was true for thorium. Turning her attention to minerals, she found her interest drawn to pitchblende, a mineral whose radioactivity, superior to that of pure uranium, could be explained only by the presence in the ore of small quantities of an unknown substance of very high activity. Pierre Curie joined her in the work that she had undertaken to resolve this problem, and that led to the discovery of the new elements, polonium and radium. While Pierre Curie devoted himself chiefly to the physical study of the new radiations, Marie Curie struggled to obtain pure radium in the metallic state. This was achieved with the help of the chemist Andre-Louis Debierne, one of Pierre Curie's pupils. Based on the results of this research, Marie Curie received her Doctorate of Science, and in 1903 Marie and Pierre shared with Becquerel the Nobel Prize for Physics for the discovery of radioactivity. The births of Marie's two daughters, Irene and Eve, in 1897 and 1904 failed to interrupt her scientific work. She was appointed lecturer in physics at the Ecole Normale Superieure for girls in Sevres, France (1900), and introduced a method of teaching based on experimental demonstrations. In December 1904 she was appointed chief assistant in the laboratory directed by Pierre Curie. The sudden death of her husband in 1906 was a bitter blow to Marie Curie, but was also a turning point in her career: henceforth she was to devote all her energy to completing alone the scientific work that they had undertaken. On May 13, 1906, she was appointed to the professorship that had been left vacant on her husband's death, becoming the first woman to teach at the Sorbonne. In 1911 she was awarded the Nobel Prize for Chemistry for the isolation of a pure form of radium. During World War I, Marie Curie, with the help of her daughter Irene, devoted herself to the development of the use of X-radiography, including the mobile units which came to be known as Little Curies', used for the treatment of wounded soldiers. In 1918 the Radium Institute, whose staff Irene had joined, began to operate in earnest, and became a centre for nuclear physics and chemistry. Marie Curie, now at the highest point of her 36fame and, from 1922, a member of the Academy of Medicine, researched the chemistry of radioactive substances and their medical applications. In 1921, accompanied by her two daughters, Marie Curie made a triumphant journey to the United States to raise funds for research on radium. Women there presented her with a gram of radium for her campaign. Marie also gave lectures in Belgium, Brazil, Spain and Czechoslovakia and, in addition, had the satisfaction of seeing the development of the Curie Foundation in Paris, and the inauguration in 1932 in Warsaw of the Radium Institute, where her sister Bronia became director. One of Marie Curie's outstanding achievements was to have understood the need to accumulateintense radioactive sources, not only to treat illness but also to maintain an abundant supply for research. The existence in Paris at the Radium Institute of a stock of 1.5 grams of radium made a decisive contribution to the success of the experiments undertaken in the years around 1930. This work prepared the way for the discovery of the neutron by Sir James Chadwick and, above all, for the discovery in 1934 by Irene and Frederic Joliot-Curie of artificial radioactivity. A few months after this discovery, Marie Curie died as a result of leukaemia caused by exposure to radiation. She had often carried test tubes containing radioactive isotopes in her pocket, remarking on the pretty blue-green light they gave off. Her contribution to physics had been immense, not only in her own work, the importance of which had been demonstrated by her two Nobel Prizes, but because of her influence on subsequent generations of nuclear physicists and chemists.", "hypothesis": "Marie was able to attend the Sorbonne because of her sisters financial contribution.", "gold_label": "neutral"}
{"uid": "id_300", "premise": "The life and work of Marie Curie Marie Curie is probably the most famous woman scientist who has ever lived. Born Maria Sklodowska in Poland in 1867, she is famous for her work on radioactivity, and was twice a winner of the Nobel Prize. With her husband, Pierre Curie, and Henri Becquerel, she was awarded the 1903 Nobel Prize for Physics, and was then sole winner of the 1911 Nobel Prize for Chemistry. She was the first woman to win a Nobel Prize. From childhood, Marie was remarkable for her prodigious memory, and at the age of 16 won a gold medal on completion of her secondary education. Because her father lost his savings through bad investment, she then had to take work as a teacher. From her earnings she was able to finance her sister Bronia's medical studies in Paris, on the understanding that Bronia would, in turn, later help her to get an education. In 1891 this promise was fulfilled and Marie went to Paris and began to study at the Sorbonne (the University of Paris). She often worked far into the night and lived on little more than bread and butter and tea. She came first in the examination in the physical sciences in 1893, and in 1894 was placed second in the examination in mathematical sciences. It was not until the spring of that year that she was introduced to Pierre Curie. Their marriage in 1895 marked the start of a partnership that was soon to achieve results of world significance. Following Henri Becquerel's discovery in 1896 of a new phenomenon, which Marie later called 'radioactivity', Marie Curie decided to find out if the radioactivity discovered in uranium was to be found in other elements. She discovered that this was true for thorium. Turning her attention to minerals, she found her interest drawn to pitchblende, a mineral whose radioactivity, superior to that of pure uranium, could be explained only by the presence in the ore of small quantities of an unknown substance of very high activity. Pierre Curie joined her in the work that she had undertaken to resolve this problem, and that led to the discovery of the new elements, polonium and radium. While Pierre Curie devoted himself chiefly to the physical study of the new radiations, Marie Curie struggled to obtain pure radium in the metallic state. This was achieved with the help of the chemist Andre-Louis Debierne, one of Pierre Curie's pupils. Based on the results of this research, Marie Curie received her Doctorate of Science, and in 1903 Marie and Pierre shared with Becquerel the Nobel Prize for Physics for the discovery of radioactivity. The births of Marie's two daughters, Irene and Eve, in 1897 and 1904 failed to interrupt her scientific work. She was appointed lecturer in physics at the Ecole Normale Superieure for girls in Sevres, France (1900), and introduced a method of teaching based on experimental demonstrations. In December 1904 she was appointed chief assistant in the laboratory directed by Pierre Curie. The sudden death of her husband in 1906 was a bitter blow to Marie Curie, but was also a turning point in her career: henceforth she was to devote all her energy to completing alone the scientific work that they had undertaken. On May 13, 1906, she was appointed to the professorship that had been left vacant on her husband's death, becoming the first woman to teach at the Sorbonne. In 1911 she was awarded the Nobel Prize for Chemistry for the isolation of a pure form of radium. During World War I, Marie Curie, with the help of her daughter Irene, devoted herself to the development of the use of X-radiography, including the mobile units which came to be known as Little Curies', used for the treatment of wounded soldiers. In 1918 the Radium Institute, whose staff Irene had joined, began to operate in earnest, and became a centre for nuclear physics and chemistry. Marie Curie, now at the highest point of her 36fame and, from 1922, a member of the Academy of Medicine, researched the chemistry of radioactive substances and their medical applications. In 1921, accompanied by her two daughters, Marie Curie made a triumphant journey to the United States to raise funds for research on radium. Women there presented her with a gram of radium for her campaign. Marie also gave lectures in Belgium, Brazil, Spain and Czechoslovakia and, in addition, had the satisfaction of seeing the development of the Curie Foundation in Paris, and the inauguration in 1932 in Warsaw of the Radium Institute, where her sister Bronia became director. One of Marie Curie's outstanding achievements was to have understood the need to accumulateintense radioactive sources, not only to treat illness but also to maintain an abundant supply for research. The existence in Paris at the Radium Institute of a stock of 1.5 grams of radium made a decisive contribution to the success of the experiments undertaken in the years around 1930. This work prepared the way for the discovery of the neutron by Sir James Chadwick and, above all, for the discovery in 1934 by Irene and Frederic Joliot-Curie of artificial radioactivity. A few months after this discovery, Marie Curie died as a result of leukaemia caused by exposure to radiation. She had often carried test tubes containing radioactive isotopes in her pocket, remarking on the pretty blue-green light they gave off. Her contribution to physics had been immense, not only in her own work, the importance of which had been demonstrated by her two Nobel Prizes, but because of her influence on subsequent generations of nuclear physicists and chemists.", "hypothesis": "Marie became interested in science when she was a child.", "gold_label": "contradiction"}
{"uid": "id_301", "premise": "The life and work of Marie Curie Marie Curie is probably the most famous woman scientist who has ever lived. Born Maria Sklodowska in Poland in 1867, she is famous for her work on radioactivity, and was twice a winner of the Nobel Prize. With her husband, Pierre Curie, and Henri Becquerel, she was awarded the 1903 Nobel Prize for Physics, and was then sole winner of the 1911 Nobel Prize for Chemistry. She was the first woman to win a Nobel Prize. From childhood, Marie was remarkable for her prodigious memory, and at the age of 16 won a gold medal on completion of her secondary education. Because her father lost his savings through bad investment, she then had to take work as a teacher. From her earnings she was able to finance her sister Bronias medical studies in Paris, on the understanding that Bronia would, in turn, later help her to get an education. In 1891 this promise was fulfilled and Marie went to Paris and began to study at the Sorbonne (the University of Paris). She often worked far into the night and lived on little more than bread and butter and tea. She came first in the examination in the physical sciences in 1893, and in 1894 was placed second in the examination in mathematical sciences. It was not until the spring of that year that she was introduced to Pierre Curie.", "hypothesis": "Marie was able to attend the Sorbonne because of her sisters financial contribution.", "gold_label": "entailment"}
{"uid": "id_302", "premise": "The life and work of Marie Curie Marie Curie is probably the most famous woman scientist who has ever lived. Born Maria Sklodowska in Poland in 1867, she is famous for her work on radioactivity, and was twice a winner of the Nobel Prize. With her husband, Pierre Curie, and Henri Becquerel, she was awarded the 1903 Nobel Prize for Physics, and was then sole winner of the 1911 Nobel Prize for Chemistry. She was the first woman to win a Nobel Prize. From childhood, Marie was remarkable for her prodigious memory, and at the age of 16 won a gold medal on completion of her secondary education. Because her father lost his savings through bad investment, she then had to take work as a teacher. From her earnings she was able to finance her sister Bronias medical studies in Paris, on the understanding that Bronia would, in turn, later help her to get an education. In 1891 this promise was fulfilled and Marie went to Paris and began to study at the Sorbonne (the University of Paris). She often worked far into the night and lived on little more than bread and butter and tea. She came first in the examination in the physical sciences in 1893, and in 1894 was placed second in the examination in mathematical sciences. It was not until the spring of that year that she was introduced to Pierre Curie.", "hypothesis": "Marie became interested in science when she was a child.", "gold_label": "neutral"}
{"uid": "id_303", "premise": "The life and work of Marie Curie Marie Curie is probably the most famous woman scientist who has ever lived. Born Maria Sklodowska in Poland in 1867, she is famous for her work on radioactivity, and was twice a winner of the Nobel Prize. With her husband, Pierre Curie, and Henri Becquerel, she was awarded the 1903 Nobel Prize for Physics, and was then sole winner of the 1911 Nobel Prize for Chemistry. She was the first woman to win a Nobel Prize. From childhood, Marie was remarkable for her prodigious memory, and at the age of 16 won a gold medal on completion of her secondary education. Because her father lost his savings through bad investment, she then had to take work as a teacher. From her earnings she was able to finance her sister Bronias medical studies in Paris, on the understanding that Bronia would, in turn, later help her to get an education. In 1891 this promise was fulfilled and Marie went to Paris and began to study at the Sorbonne (the University of Paris). She often worked far into the night and lived on little more than bread and butter and tea. She came first in the examination in the physical sciences in 1893, and in 1894 was placed second in the examination in mathematical sciences. It was not until the spring of that year that she was introduced to Pierre Curie.", "hypothesis": "Marie Curies husband was a joint winner of both Maries Nobel Prizes.", "gold_label": "contradiction"}
{"uid": "id_304", "premise": "The life and work of Marie Curie. Marie Curie is probably the most famous woman scientist who has ever lived. Born Maria Sklodowska in Poland in 1867, she is famous for her work on radioactivity, and was twice a winner of the Nobel Prize. With her husband, Pierre Curie, and Henri Becquerel, she was awarded the 1903 Nobel Prize for Physics, and was then sole winner of the 1911 Nobel Prize for Chemistry. She was the first woman to win a Nobel Prize. From childhood, Marie was remarkable for her prodigious memory, and at the age of 16 won a gold medal on completion of her secondary education. Because her father lost his savings through bad investment, she then had to take work as a teacher. Form her earnings she was able to finance her sister Bronias medical studies in Paris, on the understanding that Bronia would, in turn, later help her to get an education. In 1891 this promise was fulfilled and Marie went to Paris and began to study at the Sorbonne (the University of Paris). She often worked far into the night and lived on little more than bread and butter and tea. She came first in the examination in the physical sciences in 1893, and in 1894 was placed second in the examination in mathematical sciences. It was not until the spring of that year that she was introduced to Pierre Curie. Their marriage in 1895 marked the start of a partnership that was soon to achieve results of world significance. Following Henri Becquerels discovery in 1896 of a new phenomenon, which Marie later called radioactivity, Marie Curie decided to find out if the radioactivity discovered in uranium was to be found in other elements. She discovered that this was true for thorium. Turning her attention to minerals, she found her interest drawn to pitchblende, a mineral whose radioactivity, superior to that of pure uranium, could be explained only by the presence in the ore of small quantities of an unknown substance of very high activity. Pierre Curie joined her in the work that she had undertaken to resolve this problem, and that led to the discovery of the new elements, polonium and radium. While Pierre Curie devoted himself chiefly to the physical study of the new radiations, Marie Curie struggled to obtain pure radium in the metallic state. This was achieved with the help of the chemist Andre-Louis Debierne, one of Pierre Curies pupils. Based on the results of this research, Marie Curie received her Doctorate of Science, and in 1903 Marie and Pierre shared with Becquerel the Nobel Prize for Physics for the discovery of radioactivity. The births of Maries two daughters, lrene and Eve, in 1897 and 1904 failed to interrupt her scientific work. She was appointed lecturer in physics at the Ecole Normale Superieure for girls in Sevres, France (1900), and introduced a method of teaching based on experimental demonstrations. In December 1904 she was appointed chief assistant in the laboratory directed by Pierre Curie. The sudden death of her husband in 1906 was a bitter blow to Marie Curie, but was also a turning point in her career: henceforth she was to devote all her energy to completing alone the scientific work that they had undertaken. On May 13, 1906, she was appointed to the professorship that had been left vacant on her husbands death, becoming the first woman to teach at the Sorbonne. In 1911 she was awarded the Noble Prize for Chemistry for the isolation of a pure form of radium. During World War I, Marie Curie, with the help of her daughter Irene, devoted herself to the development of the use of X-radiography, including the mobile units which came to be known as Little Curies, used for the treatment of wounded soldiers. In 1918 the Radium Institute, whose staff Irene had joined, began to operate in earnest, and became a centre for nuclear physics and chemistry. Marie Curie, now at the highest point of her fame and, from 1922, a member of the Academy of Medicine, researched the chemistry of radioactive substances and their medical applications. In 1921, accompanied by her two daughters, Marie Curie made a triumphant journey to the United States to raise funds for research on radium. Women there presented her with a gram of radium for her campaign. Marie also gave lectures in Belgium, Brazil, Spain and Czechoslovakia and, in addition, had the satisfaction of seeing the development of the Curie Foundation in Paris, and the inauguration in 1932 in Warsaw of the Radium Institute, where her sister Bronia became director. One of Marie Curies outstanding achievements was to have understood the need to accumulate intense radioactive sources, not only to treat illness but also to maintain an abundant supply for research. The existence in Paris at the Radium Institute of a stock of 1.5 grams of radium made a decisive contribution to the success of the experiments undertaken in the years around 1930. This work prepared the way for the discovery of the neutron by Sir James Chadwick and, above all, for the discovery in 1934 by lrene and Frederic Joliot Curie of artificial radioactivity. A few months after this discovery, Marie Curie died as a result of leukaemia caused by exposure to radiation. She had often carried test tubes containing radioactive isotopes in her pocket, remarking on the pretty blue-green light they gave off. Her contribution to physics had been immense, not only in her own work, the importance of which had been demonstrated by her two Nobel Prizes, but because of her influence on subsequent generations of nuclear physicists and chemists.", "hypothesis": "Marie was able to attend the Sorbonne because of her sisters financial contribution.", "gold_label": "entailment"}
{"uid": "id_305", "premise": "The life and work of Marie Curie. Marie Curie is probably the most famous woman scientist who has ever lived. Born Maria Sklodowska in Poland in 1867, she is famous for her work on radioactivity, and was twice a winner of the Nobel Prize. With her husband, Pierre Curie, and Henri Becquerel, she was awarded the 1903 Nobel Prize for Physics, and was then sole winner of the 1911 Nobel Prize for Chemistry. She was the first woman to win a Nobel Prize. From childhood, Marie was remarkable for her prodigious memory, and at the age of 16 won a gold medal on completion of her secondary education. Because her father lost his savings through bad investment, she then had to take work as a teacher. Form her earnings she was able to finance her sister Bronias medical studies in Paris, on the understanding that Bronia would, in turn, later help her to get an education. In 1891 this promise was fulfilled and Marie went to Paris and began to study at the Sorbonne (the University of Paris). She often worked far into the night and lived on little more than bread and butter and tea. She came first in the examination in the physical sciences in 1893, and in 1894 was placed second in the examination in mathematical sciences. It was not until the spring of that year that she was introduced to Pierre Curie. Their marriage in 1895 marked the start of a partnership that was soon to achieve results of world significance. Following Henri Becquerels discovery in 1896 of a new phenomenon, which Marie later called radioactivity, Marie Curie decided to find out if the radioactivity discovered in uranium was to be found in other elements. She discovered that this was true for thorium. Turning her attention to minerals, she found her interest drawn to pitchblende, a mineral whose radioactivity, superior to that of pure uranium, could be explained only by the presence in the ore of small quantities of an unknown substance of very high activity. Pierre Curie joined her in the work that she had undertaken to resolve this problem, and that led to the discovery of the new elements, polonium and radium. While Pierre Curie devoted himself chiefly to the physical study of the new radiations, Marie Curie struggled to obtain pure radium in the metallic state. This was achieved with the help of the chemist Andre-Louis Debierne, one of Pierre Curies pupils. Based on the results of this research, Marie Curie received her Doctorate of Science, and in 1903 Marie and Pierre shared with Becquerel the Nobel Prize for Physics for the discovery of radioactivity. The births of Maries two daughters, lrene and Eve, in 1897 and 1904 failed to interrupt her scientific work. She was appointed lecturer in physics at the Ecole Normale Superieure for girls in Sevres, France (1900), and introduced a method of teaching based on experimental demonstrations. In December 1904 she was appointed chief assistant in the laboratory directed by Pierre Curie. The sudden death of her husband in 1906 was a bitter blow to Marie Curie, but was also a turning point in her career: henceforth she was to devote all her energy to completing alone the scientific work that they had undertaken. On May 13, 1906, she was appointed to the professorship that had been left vacant on her husbands death, becoming the first woman to teach at the Sorbonne. In 1911 she was awarded the Noble Prize for Chemistry for the isolation of a pure form of radium. During World War I, Marie Curie, with the help of her daughter Irene, devoted herself to the development of the use of X-radiography, including the mobile units which came to be known as Little Curies, used for the treatment of wounded soldiers. In 1918 the Radium Institute, whose staff Irene had joined, began to operate in earnest, and became a centre for nuclear physics and chemistry. Marie Curie, now at the highest point of her fame and, from 1922, a member of the Academy of Medicine, researched the chemistry of radioactive substances and their medical applications. In 1921, accompanied by her two daughters, Marie Curie made a triumphant journey to the United States to raise funds for research on radium. Women there presented her with a gram of radium for her campaign. Marie also gave lectures in Belgium, Brazil, Spain and Czechoslovakia and, in addition, had the satisfaction of seeing the development of the Curie Foundation in Paris, and the inauguration in 1932 in Warsaw of the Radium Institute, where her sister Bronia became director. One of Marie Curies outstanding achievements was to have understood the need to accumulate intense radioactive sources, not only to treat illness but also to maintain an abundant supply for research. The existence in Paris at the Radium Institute of a stock of 1.5 grams of radium made a decisive contribution to the success of the experiments undertaken in the years around 1930. This work prepared the way for the discovery of the neutron by Sir James Chadwick and, above all, for the discovery in 1934 by lrene and Frederic Joliot Curie of artificial radioactivity. A few months after this discovery, Marie Curie died as a result of leukaemia caused by exposure to radiation. She had often carried test tubes containing radioactive isotopes in her pocket, remarking on the pretty blue-green light they gave off. Her contribution to physics had been immense, not only in her own work, the importance of which had been demonstrated by her two Nobel Prizes, but because of her influence on subsequent generations of nuclear physicists and chemists.", "hypothesis": "Marie became interested in science when she was a child.", "gold_label": "neutral"}
{"uid": "id_306", "premise": "The life and work of Marie Curie. Marie Curie is probably the most famous woman scientist who has ever lived. Born Maria Sklodowska in Poland in 1867, she is famous for her work on radioactivity, and was twice a winner of the Nobel Prize. With her husband, Pierre Curie, and Henri Becquerel, she was awarded the 1903 Nobel Prize for Physics, and was then sole winner of the 1911 Nobel Prize for Chemistry. She was the first woman to win a Nobel Prize. From childhood, Marie was remarkable for her prodigious memory, and at the age of 16 won a gold medal on completion of her secondary education. Because her father lost his savings through bad investment, she then had to take work as a teacher. Form her earnings she was able to finance her sister Bronias medical studies in Paris, on the understanding that Bronia would, in turn, later help her to get an education. In 1891 this promise was fulfilled and Marie went to Paris and began to study at the Sorbonne (the University of Paris). She often worked far into the night and lived on little more than bread and butter and tea. She came first in the examination in the physical sciences in 1893, and in 1894 was placed second in the examination in mathematical sciences. It was not until the spring of that year that she was introduced to Pierre Curie. Their marriage in 1895 marked the start of a partnership that was soon to achieve results of world significance. Following Henri Becquerels discovery in 1896 of a new phenomenon, which Marie later called radioactivity, Marie Curie decided to find out if the radioactivity discovered in uranium was to be found in other elements. She discovered that this was true for thorium. Turning her attention to minerals, she found her interest drawn to pitchblende, a mineral whose radioactivity, superior to that of pure uranium, could be explained only by the presence in the ore of small quantities of an unknown substance of very high activity. Pierre Curie joined her in the work that she had undertaken to resolve this problem, and that led to the discovery of the new elements, polonium and radium. While Pierre Curie devoted himself chiefly to the physical study of the new radiations, Marie Curie struggled to obtain pure radium in the metallic state. This was achieved with the help of the chemist Andre-Louis Debierne, one of Pierre Curies pupils. Based on the results of this research, Marie Curie received her Doctorate of Science, and in 1903 Marie and Pierre shared with Becquerel the Nobel Prize for Physics for the discovery of radioactivity. The births of Maries two daughters, lrene and Eve, in 1897 and 1904 failed to interrupt her scientific work. She was appointed lecturer in physics at the Ecole Normale Superieure for girls in Sevres, France (1900), and introduced a method of teaching based on experimental demonstrations. In December 1904 she was appointed chief assistant in the laboratory directed by Pierre Curie. The sudden death of her husband in 1906 was a bitter blow to Marie Curie, but was also a turning point in her career: henceforth she was to devote all her energy to completing alone the scientific work that they had undertaken. On May 13, 1906, she was appointed to the professorship that had been left vacant on her husbands death, becoming the first woman to teach at the Sorbonne. In 1911 she was awarded the Noble Prize for Chemistry for the isolation of a pure form of radium. During World War I, Marie Curie, with the help of her daughter Irene, devoted herself to the development of the use of X-radiography, including the mobile units which came to be known as Little Curies, used for the treatment of wounded soldiers. In 1918 the Radium Institute, whose staff Irene had joined, began to operate in earnest, and became a centre for nuclear physics and chemistry. Marie Curie, now at the highest point of her fame and, from 1922, a member of the Academy of Medicine, researched the chemistry of radioactive substances and their medical applications. In 1921, accompanied by her two daughters, Marie Curie made a triumphant journey to the United States to raise funds for research on radium. Women there presented her with a gram of radium for her campaign. Marie also gave lectures in Belgium, Brazil, Spain and Czechoslovakia and, in addition, had the satisfaction of seeing the development of the Curie Foundation in Paris, and the inauguration in 1932 in Warsaw of the Radium Institute, where her sister Bronia became director. One of Marie Curies outstanding achievements was to have understood the need to accumulate intense radioactive sources, not only to treat illness but also to maintain an abundant supply for research. The existence in Paris at the Radium Institute of a stock of 1.5 grams of radium made a decisive contribution to the success of the experiments undertaken in the years around 1930. This work prepared the way for the discovery of the neutron by Sir James Chadwick and, above all, for the discovery in 1934 by lrene and Frederic Joliot Curie of artificial radioactivity. A few months after this discovery, Marie Curie died as a result of leukaemia caused by exposure to radiation. She had often carried test tubes containing radioactive isotopes in her pocket, remarking on the pretty blue-green light they gave off. Her contribution to physics had been immense, not only in her own work, the importance of which had been demonstrated by her two Nobel Prizes, but because of her influence on subsequent generations of nuclear physicists and chemists.", "hypothesis": "Marie stopped doing research for several years when her children were born.", "gold_label": "contradiction"}
{"uid": "id_307", "premise": "The life and work of Marie Curie. Marie Curie is probably the most famous woman scientist who has ever lived. Born Maria Sklodowska in Poland in 1867, she is famous for her work on radioactivity, and was twice a winner of the Nobel Prize. With her husband, Pierre Curie, and Henri Becquerel, she was awarded the 1903 Nobel Prize for Physics, and was then sole winner of the 1911 Nobel Prize for Chemistry. She was the first woman to win a Nobel Prize. From childhood, Marie was remarkable for her prodigious memory, and at the age of 16 won a gold medal on completion of her secondary education. Because her father lost his savings through bad investment, she then had to take work as a teacher. Form her earnings she was able to finance her sister Bronias medical studies in Paris, on the understanding that Bronia would, in turn, later help her to get an education. In 1891 this promise was fulfilled and Marie went to Paris and began to study at the Sorbonne (the University of Paris). She often worked far into the night and lived on little more than bread and butter and tea. She came first in the examination in the physical sciences in 1893, and in 1894 was placed second in the examination in mathematical sciences. It was not until the spring of that year that she was introduced to Pierre Curie. Their marriage in 1895 marked the start of a partnership that was soon to achieve results of world significance. Following Henri Becquerels discovery in 1896 of a new phenomenon, which Marie later called radioactivity, Marie Curie decided to find out if the radioactivity discovered in uranium was to be found in other elements. She discovered that this was true for thorium. Turning her attention to minerals, she found her interest drawn to pitchblende, a mineral whose radioactivity, superior to that of pure uranium, could be explained only by the presence in the ore of small quantities of an unknown substance of very high activity. Pierre Curie joined her in the work that she had undertaken to resolve this problem, and that led to the discovery of the new elements, polonium and radium. While Pierre Curie devoted himself chiefly to the physical study of the new radiations, Marie Curie struggled to obtain pure radium in the metallic state. This was achieved with the help of the chemist Andre-Louis Debierne, one of Pierre Curies pupils. Based on the results of this research, Marie Curie received her Doctorate of Science, and in 1903 Marie and Pierre shared with Becquerel the Nobel Prize for Physics for the discovery of radioactivity. The births of Maries two daughters, lrene and Eve, in 1897 and 1904 failed to interrupt her scientific work. She was appointed lecturer in physics at the Ecole Normale Superieure for girls in Sevres, France (1900), and introduced a method of teaching based on experimental demonstrations. In December 1904 she was appointed chief assistant in the laboratory directed by Pierre Curie. The sudden death of her husband in 1906 was a bitter blow to Marie Curie, but was also a turning point in her career: henceforth she was to devote all her energy to completing alone the scientific work that they had undertaken. On May 13, 1906, she was appointed to the professorship that had been left vacant on her husbands death, becoming the first woman to teach at the Sorbonne. In 1911 she was awarded the Noble Prize for Chemistry for the isolation of a pure form of radium. During World War I, Marie Curie, with the help of her daughter Irene, devoted herself to the development of the use of X-radiography, including the mobile units which came to be known as Little Curies, used for the treatment of wounded soldiers. In 1918 the Radium Institute, whose staff Irene had joined, began to operate in earnest, and became a centre for nuclear physics and chemistry. Marie Curie, now at the highest point of her fame and, from 1922, a member of the Academy of Medicine, researched the chemistry of radioactive substances and their medical applications. In 1921, accompanied by her two daughters, Marie Curie made a triumphant journey to the United States to raise funds for research on radium. Women there presented her with a gram of radium for her campaign. Marie also gave lectures in Belgium, Brazil, Spain and Czechoslovakia and, in addition, had the satisfaction of seeing the development of the Curie Foundation in Paris, and the inauguration in 1932 in Warsaw of the Radium Institute, where her sister Bronia became director. One of Marie Curies outstanding achievements was to have understood the need to accumulate intense radioactive sources, not only to treat illness but also to maintain an abundant supply for research. The existence in Paris at the Radium Institute of a stock of 1.5 grams of radium made a decisive contribution to the success of the experiments undertaken in the years around 1930. This work prepared the way for the discovery of the neutron by Sir James Chadwick and, above all, for the discovery in 1934 by lrene and Frederic Joliot Curie of artificial radioactivity. A few months after this discovery, Marie Curie died as a result of leukaemia caused by exposure to radiation. She had often carried test tubes containing radioactive isotopes in her pocket, remarking on the pretty blue-green light they gave off. Her contribution to physics had been immense, not only in her own work, the importance of which had been demonstrated by her two Nobel Prizes, but because of her influence on subsequent generations of nuclear physicists and chemists.", "hypothesis": "Marie Curies husband was a joint winner of both Maries Nobel Prizes.", "gold_label": "contradiction"}
{"uid": "id_308", "premise": "The life and work of Marie Curie. Marie Curie is probably the most famous woman scientist who has ever lived. Born Maria Sklodowska in Poland in 1867, she is famous for her work on radioactivity, and was twice a winner of the Nobel Prize. With her husband, Pierre Curie, and Henri Becquerel, she was awarded the 1903 Nobel Prize for Physics, and was then sole winner of the 1911 Nobel Prize for Chemistry. She was the first woman to win a Nobel Prize. From childhood, Marie was remarkable for her prodigious memory, and at the age of 16 won a gold medal on completion of her secondary education. Because her father lost his savings through bad investment, she then had to take work as a teacher. Form her earnings she was able to finance her sister Bronias medical studies in Paris, on the understanding that Bronia would, in turn, later help her to get an education. In 1891 this promise was fulfilled and Marie went to Paris and began to study at the Sorbonne (the University of Paris). She often worked far into the night and lived on little more than bread and butter and tea. She came first in the examination in the physical sciences in 1893, and in 1894 was placed second in the examination in mathematical sciences. It was not until the spring of that year that she was introduced to Pierre Curie. Their marriage in 1895 marked the start of a partnership that was soon to achieve results of world significance. Following Henri Becquerels discovery in 1896 of a new phenomenon, which Marie later called radioactivity, Marie Curie decided to find out if the radioactivity discovered in uranium was to be found in other elements. She discovered that this was true for thorium. Turning her attention to minerals, she found her interest drawn to pitchblende, a mineral whose radioactivity, superior to that of pure uranium, could be explained only by the presence in the ore of small quantities of an unknown substance of very high activity. Pierre Curie joined her in the work that she had undertaken to resolve this problem, and that led to the discovery of the new elements, polonium and radium. While Pierre Curie devoted himself chiefly to the physical study of the new radiations, Marie Curie struggled to obtain pure radium in the metallic state. This was achieved with the help of the chemist Andre-Louis Debierne, one of Pierre Curies pupils. Based on the results of this research, Marie Curie received her Doctorate of Science, and in 1903 Marie and Pierre shared with Becquerel the Nobel Prize for Physics for the discovery of radioactivity. The births of Maries two daughters, lrene and Eve, in 1897 and 1904 failed to interrupt her scientific work. She was appointed lecturer in physics at the Ecole Normale Superieure for girls in Sevres, France (1900), and introduced a method of teaching based on experimental demonstrations. In December 1904 she was appointed chief assistant in the laboratory directed by Pierre Curie. The sudden death of her husband in 1906 was a bitter blow to Marie Curie, but was also a turning point in her career: henceforth she was to devote all her energy to completing alone the scientific work that they had undertaken. On May 13, 1906, she was appointed to the professorship that had been left vacant on her husbands death, becoming the first woman to teach at the Sorbonne. In 1911 she was awarded the Noble Prize for Chemistry for the isolation of a pure form of radium. During World War I, Marie Curie, with the help of her daughter Irene, devoted herself to the development of the use of X-radiography, including the mobile units which came to be known as Little Curies, used for the treatment of wounded soldiers. In 1918 the Radium Institute, whose staff Irene had joined, began to operate in earnest, and became a centre for nuclear physics and chemistry. Marie Curie, now at the highest point of her fame and, from 1922, a member of the Academy of Medicine, researched the chemistry of radioactive substances and their medical applications. In 1921, accompanied by her two daughters, Marie Curie made a triumphant journey to the United States to raise funds for research on radium. Women there presented her with a gram of radium for her campaign. Marie also gave lectures in Belgium, Brazil, Spain and Czechoslovakia and, in addition, had the satisfaction of seeing the development of the Curie Foundation in Paris, and the inauguration in 1932 in Warsaw of the Radium Institute, where her sister Bronia became director. One of Marie Curies outstanding achievements was to have understood the need to accumulate intense radioactive sources, not only to treat illness but also to maintain an abundant supply for research. The existence in Paris at the Radium Institute of a stock of 1.5 grams of radium made a decisive contribution to the success of the experiments undertaken in the years around 1930. This work prepared the way for the discovery of the neutron by Sir James Chadwick and, above all, for the discovery in 1934 by lrene and Frederic Joliot Curie of artificial radioactivity. A few months after this discovery, Marie Curie died as a result of leukaemia caused by exposure to radiation. She had often carried test tubes containing radioactive isotopes in her pocket, remarking on the pretty blue-green light they gave off. Her contribution to physics had been immense, not only in her own work, the importance of which had been demonstrated by her two Nobel Prizes, but because of her influence on subsequent generations of nuclear physicists and chemists.", "hypothesis": "Marie took over the teaching position her husband had held.", "gold_label": "entailment"}
{"uid": "id_309", "premise": "The life and work of Marie Curie. Marie Curie is probably the most famous woman scientist who has ever lived. Born Maria Sklodowska in Poland in 1867, she is famous for her work on radioactivity, and was twice a winner of the Nobel Prize. With her husband, Pierre Curie, and Henri Becquerel, she was awarded the 1903 Nobel Prize for Physics, and was then sole winner of the 1911 Nobel Prize for Chemistry. She was the first woman to win a Nobel Prize. From childhood, Marie was remarkable for her prodigious memory, and at the age of 16 won a gold medal on completion of her secondary education. Because her father lost his savings through bad investment, she then had to take work as a teacher. Form her earnings she was able to finance her sister Bronias medical studies in Paris, on the understanding that Bronia would, in turn, later help her to get an education. In 1891 this promise was fulfilled and Marie went to Paris and began to study at the Sorbonne (the University of Paris). She often worked far into the night and lived on little more than bread and butter and tea. She came first in the examination in the physical sciences in 1893, and in 1894 was placed second in the examination in mathematical sciences. It was not until the spring of that year that she was introduced to Pierre Curie. Their marriage in 1895 marked the start of a partnership that was soon to achieve results of world significance. Following Henri Becquerels discovery in 1896 of a new phenomenon, which Marie later called radioactivity, Marie Curie decided to find out if the radioactivity discovered in uranium was to be found in other elements. She discovered that this was true for thorium. Turning her attention to minerals, she found her interest drawn to pitchblende, a mineral whose radioactivity, superior to that of pure uranium, could be explained only by the presence in the ore of small quantities of an unknown substance of very high activity. Pierre Curie joined her in the work that she had undertaken to resolve this problem, and that led to the discovery of the new elements, polonium and radium. While Pierre Curie devoted himself chiefly to the physical study of the new radiations, Marie Curie struggled to obtain pure radium in the metallic state. This was achieved with the help of the chemist Andre-Louis Debierne, one of Pierre Curies pupils. Based on the results of this research, Marie Curie received her Doctorate of Science, and in 1903 Marie and Pierre shared with Becquerel the Nobel Prize for Physics for the discovery of radioactivity. The births of Maries two daughters, lrene and Eve, in 1897 and 1904 failed to interrupt her scientific work. She was appointed lecturer in physics at the Ecole Normale Superieure for girls in Sevres, France (1900), and introduced a method of teaching based on experimental demonstrations. In December 1904 she was appointed chief assistant in the laboratory directed by Pierre Curie. The sudden death of her husband in 1906 was a bitter blow to Marie Curie, but was also a turning point in her career: henceforth she was to devote all her energy to completing alone the scientific work that they had undertaken. On May 13, 1906, she was appointed to the professorship that had been left vacant on her husbands death, becoming the first woman to teach at the Sorbonne. In 1911 she was awarded the Noble Prize for Chemistry for the isolation of a pure form of radium. During World War I, Marie Curie, with the help of her daughter Irene, devoted herself to the development of the use of X-radiography, including the mobile units which came to be known as Little Curies, used for the treatment of wounded soldiers. In 1918 the Radium Institute, whose staff Irene had joined, began to operate in earnest, and became a centre for nuclear physics and chemistry. Marie Curie, now at the highest point of her fame and, from 1922, a member of the Academy of Medicine, researched the chemistry of radioactive substances and their medical applications. In 1921, accompanied by her two daughters, Marie Curie made a triumphant journey to the United States to raise funds for research on radium. Women there presented her with a gram of radium for her campaign. Marie also gave lectures in Belgium, Brazil, Spain and Czechoslovakia and, in addition, had the satisfaction of seeing the development of the Curie Foundation in Paris, and the inauguration in 1932 in Warsaw of the Radium Institute, where her sister Bronia became director. One of Marie Curies outstanding achievements was to have understood the need to accumulate intense radioactive sources, not only to treat illness but also to maintain an abundant supply for research. The existence in Paris at the Radium Institute of a stock of 1.5 grams of radium made a decisive contribution to the success of the experiments undertaken in the years around 1930. This work prepared the way for the discovery of the neutron by Sir James Chadwick and, above all, for the discovery in 1934 by lrene and Frederic Joliot Curie of artificial radioactivity. A few months after this discovery, Marie Curie died as a result of leukaemia caused by exposure to radiation. She had often carried test tubes containing radioactive isotopes in her pocket, remarking on the pretty blue-green light they gave off. Her contribution to physics had been immense, not only in her own work, the importance of which had been demonstrated by her two Nobel Prizes, but because of her influence on subsequent generations of nuclear physicists and chemists.", "hypothesis": "Maries sister Bronia studied the medical uses of radioactivity.", "gold_label": "neutral"}
{"uid": "id_310", "premise": "The living wage represents the minimum hourly rate for employment which allows an individual to cover their basic costs of living. This wage is set at 9.15 per hour in London and 7.85 per hour in the rest of the UK. This difference in living wage between London and the rest of the UK is explained by the significant costs associated with living in London. The minimum wage is currently 6.50 for employees aged over 21 and 5.13 for employees aged between 18 and 20. This is lower than the living wage values quoted above and represents the legal minimum wage. It would be illegal for an employer to pay less than these values. Although many employers have agreed to pay a living wage, they are not legally obliged to do so. The introduction of the living wage in companies has been argued to be beneficial for these companies. Many employers found that employees who were paid the living wage were able to work harder with better quality. It has also improved the quality of life for the families of employees as it has allowed those who are parents to spend more time with their children. However, some employers have argued that the introduction of the living wage would force them to fire some workers, forcing others to work harder.", "hypothesis": "Paying someone a living wage will only benefit that individual", "gold_label": "contradiction"}
{"uid": "id_311", "premise": "The living wage represents the minimum hourly rate for employment which allows an individual to cover their basic costs of living. This wage is set at 9.15 per hour in London and 7.85 per hour in the rest of the UK. This difference in living wage between London and the rest of the UK is explained by the significant costs associated with living in London. The minimum wage is currently 6.50 for employees aged over 21 and 5.13 for employees aged between 18 and 20. This is lower than the living wage values quoted above and represents the legal minimum wage. It would be illegal for an employer to pay less than these values. Although many employers have agreed to pay a living wage, they are not legally obliged to do so. The introduction of the living wage in companies has been argued to be beneficial for these companies. Many employers found that employees who were paid the living wage were able to work harder with better quality. It has also improved the quality of life for the families of employees as it has allowed those who are parents to spend more time with their children. However, some employers have argued that the introduction of the living wage would force them to fire some workers, forcing others to work harder.", "hypothesis": "The living cost across UK cities is approximately equal.", "gold_label": "contradiction"}
{"uid": "id_312", "premise": "The living wage represents the minimum hourly rate for employment which allows an individual to cover their basic costs of living. This wage is set at 9.15 per hour in London and 7.85 per hour in the rest of the UK. This difference in living wage between London and the rest of the UK is explained by the significant costs associated with living in London. The minimum wage is currently 6.50 for employees aged over 21 and 5.13 for employees aged between 18 and 20. This is lower than the living wage values quoted above and represents the legal minimum wage. It would be illegal for an employer to pay less than these values. Although many employers have agreed to pay a living wage, they are not legally obliged to do so. The introduction of the living wage in companies has been argued to be beneficial for these companies. Many employers found that employees who were paid the living wage were able to work harder with better quality. It has also improved the quality of life for the families of employees as it has allowed those who are parents to spend more time with their children. However, some employers have argued that the introduction of the living wage would force them to fire some workers, forcing others to work harder.", "hypothesis": "Introducing a living wage would be beneficial for all employees.", "gold_label": "contradiction"}
{"uid": "id_313", "premise": "The living wage represents the minimum hourly rate for employment which allows an individual to cover their basic costs of living. This wage is set at 9.15 per hour in London and 7.85 per hour in the rest of the UK. This difference in living wage between London and the rest of the UK is explained by the significant costs associated with living in London. The minimum wage is currently 6.50 for employees aged over 21 and 5.13 for employees aged between 18 and 20. This is lower than the living wage values quoted above and represents the legal minimum wage. It would be illegal for an employer to pay less than these values. Although many employers have agreed to pay a living wage, they are not legally obliged to do so. The introduction of the living wage in companies has been argued to be beneficial for these companies. Many employers found that employees who were paid the living wage were able to work harder with better quality. It has also improved the quality of life for the families of employees as it has allowed those who are parents to spend more time with their children. However, some employers have argued that the introduction of the living wage would force them to fire some workers, forcing others to work harder.", "hypothesis": "Companies introduce the living wage to avoid the legal complications of underpaying their employees.", "gold_label": "contradiction"}
{"uid": "id_314", "premise": "The living wage represents the minimum hourly rate for employment which allows an individual to cover their basic costs of living. This wage is set at 9.15 per hour in London and 7.85 per hour in the rest of the UK. This difference in living wage between London and the rest of the UK is explained by the significant costs associated with living in London. The minimum wage is currently 6.50 for employees aged over 21 and 5.13 for employees aged between 18 and 20. This is lower than the living wage values quoted above and represents the legal minimum wage. It would be illegal for an employer to pay less than these values. Although many employers have agreed to pay a living wage, they are not legally obliged to do so. The introduction of the living wage in companies has been argued to be beneficial for these companies. Many employers found that employees who were paid the living wage were able to work harder with better quality. It has also improved the quality of life for the families of employees as it has allowed those who are parents to spend more time with their children. However, some employers have argued that the introduction of the living wage would force them to fire some workers, forcing others to work harder.", "hypothesis": "A 24 year old working at minimum wage would be able to live comfortably in Manchester", "gold_label": "contradiction"}
{"uid": "id_315", "premise": "The local citizens group submitted a memorandum to the civic authority for allowing them to convert the vacant plot in the locality into a garden at their on cost.", "hypothesis": "The civic authority may not accede to the request of the local citizen group.", "gold_label": "neutral"}
{"uid": "id_316", "premise": "The local citizens group submitted a memorandum to the civic authority for allowing them to convert the vacant plot in the locality into a garden at their on cost.", "hypothesis": "The local citizen group may be able to gather enough funds to develop the garden", "gold_label": "entailment"}
{"uid": "id_317", "premise": "The location of a shop operated by a charity in an affluent neighborhood could be deemed extremely advantageous because this increases the potential for a continuous supply of highly valuable donations. However, this may be counterbalanced by an exorbitant rent for the property. Of fundamental importance to the success of the shop is a dedicated group of volunteers who should sort through donations promptly to ensure that items are quickly made available for purchase, in order to promote financial prosperity. Volunteers and staff must be vigilant of thieves, to which these shops are particularly susceptible, usually due to a lack of security cameras or bar codes on the item.", "hypothesis": "If the rent for a shop operated by a charity is high, a supply of good quality donations may be compensatory.", "gold_label": "neutral"}
{"uid": "id_318", "premise": "The location of a shop operated by a charity in an affluent neighborhood could be deemed extremely advantageous because this increases the potential for a continuous supply of highly valuable donations. However, this may be counterbalanced by an exorbitant rent for the property. Of fundamental importance to the success of the shop is a dedicated group of volunteers who should sort through donations promptly to ensure that items are quickly made available for purchase, in order to promote financial prosperity. Volunteers and staff must be vigilant of thieves, to which these shops are particularly susceptible, usually due to a lack of security cameras or bar codes on the item.", "hypothesis": "Before the introduction of bar codes and security cameras, shops operated by charitable organizations were as vulnerable to theft as other shops.", "gold_label": "entailment"}
{"uid": "id_319", "premise": "The location of a shop operated by a charity in an affluent neighborhood could be deemed extremely advantageous because this increases the potential for a continuous supply of highly valuable donations. However, this may be counterbalanced by an exorbitant rent for the property. Of fundamental importance to the success of the shop is a dedicated group of volunteers who should sort through donations promptly to ensure that items are quickly made available for purchase, in order to promote financial prosperity. Volunteers and staff must be vigilant of thieves, to which these shops are particularly susceptible, usually due to a lack of security cameras or bar codes on the item.", "hypothesis": "If volunteers do not sort the donations hastily, this could lead to a potential loss in sales.", "gold_label": "entailment"}
{"uid": "id_320", "premise": "The location of a shop operated by a charity in an affluent neighborhood could be deemed extremely advantageous because this increases the potential for a continuous supply of highly valuable donations. However, this may be counterbalanced by an exorbitant rent for the property. Of fundamental importance to the success of the shop is a dedicated group of volunteers who should sort through donations promptly to ensure that items are quickly made available for purchase, in order to promote financial prosperity. Volunteers and staff must be vigilant of thieves, to which these shops are particularly susceptible, usually due to a lack of security cameras or bar codes on the item.", "hypothesis": "An increase in security measures in shops operated by charities will usually encourage individuals from affluent areas to donate more high quality items.", "gold_label": "neutral"}
{"uid": "id_321", "premise": "The location of a shop operated by a charity in an affluent neighborhood could be deemed extremely advantageous because this increases the potential for a continuous supply of highly valuable donations. However, this may be counterbalanced by an exorbitant rent for the property. Of fundamental importance to the success of the shop is a dedicated group of volunteers who should sort through donations promptly to ensure that items are quickly made available for purchase, in order to promote financial prosperity. Volunteers and staff must be vigilant of thieves, to which these shops are particularly susceptible, usually due to a lack of security cameras or bar codes on the item.", "hypothesis": "It is less likely that shops operated by charities which are situated in affluent neighborhoods will have volunteers who are more dedicated, than those in less wealthy neighborhoods.", "gold_label": "neutral"}
{"uid": "id_322", "premise": "The location of a shop operated by a charity in an affluent neighborhood could be deemed extremely advantageous because this increases the potential for a continuous supply of highly valuable donations. However, this may be counterbalanced by an exorbitant rent for the property. Of fundamental importance to the success of the shop is a dedicated group of volunteers who should sort through donations promptly to ensure that items are quickly made available for purchase, in order to promote financial prosperity. Volunteers and staff must be vigilant of thieves, to which these shops are particularly susceptible, usually due to a lack of security cameras or bar codes on the item.", "hypothesis": "The only factor affecting the financial success of a shop operated by a charity is its location.", "gold_label": "contradiction"}
{"uid": "id_323", "premise": "The location of a shop operated by a charity in an affluent neighborhood could be deemed extremely advantageous because this increases the potential for a continuous supply of highly valuable donations. However, this may be counterbalanced by an exorbitant rent for the property. Of fundamental importance to the success of the shop is a dedicated group of volunteers who should sort through donations promptly to ensure that items are quickly made available for purchase, in order to promote financial prosperity. Volunteers and staff must be vigilant of thieves, to which these shops are particularly susceptible, usually due to a lack of security cameras or bar codes on the item.", "hypothesis": "Shops operated by charitable organizations are particularly vulnerable to shoplifter if there are no security cameras or bar codes on items.", "gold_label": "entailment"}
{"uid": "id_324", "premise": "The luxury goods market has seen a sudden slump in sales in China thanks to the emergence of Chinese labels. While Chinas love of Western brands, such as Prada and Louis Vuitton, shows no sign of ending, a new group of smaller luxury Chinese companies is gaining in popularity. Such companies try to promote traditional Chinese values, rather than the exclusivity of Western labels that have been ever popular in China. Feedback for the new rivals has been positive so far, yet they are expected to face an up-hill struggle as Western heavy- weights rise to meet the challenge.", "hypothesis": "Luxury Chinese labels decreased sales of western luxury goods.", "gold_label": "entailment"}
{"uid": "id_325", "premise": "The luxury goods market has seen a sudden slump in sales in China thanks to the emergence of Chinese labels. While Chinas love of Western brands, such as Prada and Louis Vuitton, shows no sign of ending, a new group of smaller luxury Chinese companies is gaining in popularity. Such companies try to promote traditional Chinese values, rather than the exclusivity of Western labels that have been ever popular in China. Feedback for the new rivals has been positive so far, yet they are expected to face an up-hill struggle as Western heavy- weights rise to meet the challenge.", "hypothesis": "The Western market is rising to the challenge of Chinese companies.", "gold_label": "entailment"}
{"uid": "id_326", "premise": "The luxury goods market has seen a sudden slump in sales in China thanks to the emergence of Chinese labels. While Chinas love of Western brands, such as Prada and Louis Vuitton, shows no sign of ending, a new group of smaller luxury Chinese companies is gaining in popularity. Such companies try to promote traditional Chinese values, rather than the exclusivity of Western labels that have been ever popular in China. Feedback for the new rivals has been positive so far, yet they are expected to face an up-hill struggle as Western heavy- weights rise to meet the challenge.", "hypothesis": "Chinese companies are trying to promote traditional values", "gold_label": "entailment"}
{"uid": "id_327", "premise": "The luxury goods market has seen a sudden slump in sales in China thanks to the emergence of Chinese labels. While Chinas love of Western brands, such as Prada and Louis Vuitton, shows no sign of ending, a new group of smaller luxury Chinese companies is gaining in popularity. Such companies try to promote traditional Chinese values, rather than the exclusivity of Western labels that have been ever popular in China. Feedback for the new rivals has been positive so far, yet they are expected to face an up-hill struggle as Western heavy- weights rise to meet the challenge.", "hypothesis": "Chinese companies are emulating the exclusivity of Western luxury goods", "gold_label": "contradiction"}
{"uid": "id_328", "premise": "The main monetary policy objective is to reduce substantially, the import surplus of the coming years while resuming economic growth. Realisation of this goal entails a marked structural change of the economy, which can be brought about by freezing the standard of living (per capita private consumption plus public services) and restricting investments that do not further exports.", "hypothesis": "If people consume less, the economy grows.", "gold_label": "entailment"}
{"uid": "id_329", "premise": "The main monetary policy objective is to reduce substantially, the import surplus of the coming years while resuming economic growth. Realisation of this goal entails a marked structural change of the economy, which can be brought about by freezing the standard of living (per capita private consumption plus public services) and restricting investments that do not further exports.", "hypothesis": "Economic growth will lead to structural changes in the economy.", "gold_label": "contradiction"}
{"uid": "id_330", "premise": "The main monetary policy objective is to reduce substantially, the import surplus of the coming years while resuming economic growth. Realisation of this goal entails a marked structural change of the economy, which can be brought about by freezing the standard of living (per capita private consumption plus public services) and restricting investments that do not further exports.", "hypothesis": "In order to reduce import surplus investment needs to be restricted.", "gold_label": "contradiction"}
{"uid": "id_331", "premise": "The main monetary policy objective is to reduce substantially, the import surplus of the coming years while resuming economic growth. Realisation of this goal entails a marked structural change of the economy, which can be brought about by freezing the standard of living (per capita private consumption plus public services) and restricting investments that do not further exports.", "hypothesis": "People should be persuaded to give up consumption in order to achieve the national good.", "gold_label": "contradiction"}
{"uid": "id_332", "premise": "The majority of Member States have been holding discussions in recent years regarding the introduction of new taxes on the financial sector and the impact they would have on pensions. They recognise that creating additional taxes on the financial sector could be a path to alleviating the problems they now face in relation to pensions and the lack of funds available to run them. However, the reason for such debate relates to the role that the banks and other financial service institutions played in the causes of the crises as well as the current government support offered to the financial sector. There is also a general perception that, as financial activities are generally exempt from VAT, the financial sector is under-taxed currently. One potential new tax rule being considered is that which would introduce a tax on as broad a range of financial transactions as possible. This could include bonds, shares and derivatives as a starting point. Almost all financial institutions would be liable but there would be exemptions for some day to day activities such as mortgages and payment services. An impact assessment of the likely revenue this tax could generate was close to 6 billion Euros per year. That said though, as the tax revenue would be collected on the basis of the principle of residence of the financial institute, one has to consider the possibility that a bank based in the area which is liable could transfer its transactions to a subsidiary outside of the relevant jurisdiction.", "hypothesis": "it is important to find a way to generate extra income to alleviate the problems our pensions face", "gold_label": "entailment"}
{"uid": "id_333", "premise": "The management of XYZ Pvt. Ltd. Asked the workers union to call off strike immediately otherwise the management would be forced to close down the factory.", "hypothesis": "People like a glowing complexion", "gold_label": "entailment"}
{"uid": "id_334", "premise": "The management of XYZ Pvt. Ltd. Asked the workers union to call off strike immediately otherwise the management would be forced to close down the factory.", "hypothesis": "No alternative other than closing down the factory is left for the management of XYZ Pvt. Ltd.", "gold_label": "neutral"}
{"uid": "id_335", "premise": "The management of XYZ Pvt. Ltd. Asked the workers union to call off strike immediately otherwise the management would be forced to close down the factory.", "hypothesis": "Complexion becomes dull in the absence of circulation.", "gold_label": "entailment"}
{"uid": "id_336", "premise": "The management of XYZ Pvt. Ltd. Asked the workers union to call off strike immediately otherwise the management would be forced to close down the factory.", "hypothesis": "Such threat may have some effect on the workers union.", "gold_label": "entailment"}
{"uid": "id_337", "premise": "The medieval period lasted from 1000 to 1500. It was preceded by the Dark Ages. Many towns were formed across Europe during this period as trade and populations increased. Kings ruled and with the leaders of the church they decided state affairs. Most people lived in the countryside and worked on the land. They gave a share of their produce to the local lord in return for protection and as rent. They had to work very hard and for much of their lives lived in abject poverty. Life expectancy for the commoner was much shorter than it is today. As a result of the expansion of trade coins became commonplace.", "hypothesis": "The medieval period lasted for 500 years.", "gold_label": "entailment"}
{"uid": "id_338", "premise": "The medieval period lasted from 1000 to 1500. It was preceded by the Dark Ages. Many towns were formed across Europe during this period as trade and populations increased. Kings ruled and with the leaders of the church they decided state affairs. Most people lived in the countryside and worked on the land. They gave a share of their produce to the local lord in return for protection and as rent. They had to work very hard and for much of their lives lived in abject poverty. Life expectancy for the commoner was much shorter than it is today. As a result of the expansion of trade coins became commonplace.", "hypothesis": "When a harvest failed or was poor the commoner risked starvation.", "gold_label": "neutral"}
{"uid": "id_339", "premise": "The medieval period lasted from 1000 to 1500. It was preceded by the Dark Ages. Many towns were formed across Europe during this period as trade and populations increased. Kings ruled and with the leaders of the church they decided state affairs. Most people lived in the countryside and worked on the land. They gave a share of their produce to the local lord in return for protection and as rent. They had to work very hard and for much of their lives lived in abject poverty. Life expectancy for the commoner was much shorter than it is today. As a result of the expansion of trade coins became commonplace.", "hypothesis": "The Dark Ages followed the medieval period.", "gold_label": "contradiction"}
{"uid": "id_340", "premise": "The medieval period lasted from 1000 to 1500. It was preceded by the Dark Ages. Many towns were formed across Europe during this period as trade and populations increased. Kings ruled and with the leaders of the church they decided state affairs. Most people lived in the countryside and worked on the land. They gave a share of their produce to the local lord in return for protection and as rent. They had to work very hard and for much of their lives lived in abject poverty. Life expectancy for the commoner was much shorter than it is today. As a result of the expansion of trade coins became commonplace.", "hypothesis": "The majority of the population lived in the countryside.", "gold_label": "entailment"}
{"uid": "id_341", "premise": "The megafires of California Drought, housing expansion, and oversupply of tinder make for bigger, hotter fires in the western United States Wildfires are becoming an increasing menace in the western United States, with Southern California being the hardest hit area. There's a reason fire squads battling more frequent blazes in Southern California are having such difficulty containing the flames, despite better preparedness than ever and decades of experience fighting fires fanned by the Santa Ana Winds. The wildfires themselves, experts say, are generally hotter, faster, and spread more erratically than in the past. Megafires, also called siege fires, are the increasingly frequent blazes that burn 500,000 acres or more - 10 times the size of the average forest fire of 20 years ago. Some recent wildfires are among the biggest ever in California in terms of acreage burned, according to state figures and news reports. One explanation for the trend to more superhot fires is that the region, which usually has dry summers, has had significantly below normal precipitation in many recent years. Another reason, experts say, is related to the century- long policy of the US Forest Service to stop wildfires as quickly as possible. The unintentional consequence has been to halt the natural eradication of underbrush, now the primary fuel for megafires. Three other factors contribute to the trend, they add. First is climate change, marked by a 1-degree Fahrenheit rise in average yearly temperature across the western states. Second is fire seasons that on average are 78 days longer than they were 20 years ago. Third is increased construction of homes in wooded areas. We are increasingly building our homes in fire-prone ecosystems, says Dominik Kulakowski, adjunct professor of biology at Clark University Graduate School of Geography in Worcester, Massachusetts. Doing that in many of the forests of the western US is like building homes on the side of an active volcano. ' In California, where population growth has averaged more than 600,000 a year for at least a decade, more residential housing is being built. What once was open space is now residential homes providing fuel to make fires burn with greater intensity, says Terry McHale of the California Department of Forestry firefighters' union. With so much dryness, so many communities to catch fire, so many fronts to fight, it becomes an almost incredible job. ' That said, many experts give California high marks for making progress on preparedness in recent years, after some of the largest fires in state history scorched thousands of acres, burned thousands of homes, and killed numerous people. Stung in the past by criticism of bungling that allowed fires to spread when they might have been contained, personnel are meeting the peculiar challenges of neighborhood - and canyon- hopping fires better than previously, observers say. State promises to provide more up-to-date engines, planes, and helicopters to fight fires have been fulfilled. Firefighters unions that in the past complained of dilapidated equipment, old fire engines, and insufficient blueprints for fire safety are now praising the state's commitment, noting that funding for firefighting has increased, despite huge cuts in many other programs. We are pleased that the current state administration has been very proactive in its support of us, and has come through with budgetary support of the infrastructure needs we have long sought, ' says Mr. McHale of the firefighters union. Besides providing money to upgrade the fire engines that must traverse the mammoth state and wind along serpentine canyon roads, the state has invested in better command-and-control facilities as well as in the 58strategies to run them. In the fire sieges of earlier years, we found that other jurisdictions and states were willing to offer mutual-aid help, but we were not able to communicate adequately with them, says Kim Zagaris, chief of the state's Office of Emergency Services Fire and Rescue Branch. After a commission examined and revamped communications procedures, the statewide response has become far more professional and responsive, he says. There is a sense among both government officials and residents that the speed, dedication, and coordination of firefighters from several states and jurisdictions are resulting in greater efficiency than in past siege fire situations. In recent years, the Southern California region has improved building codes, evacuation procedures, and procurement of new technology. I am extraordinarily impressed by the improvements we have witnessed, says Randy Jacobs, a Southern California- based lawyer who has had to evacuate both his home and business to escape wildfires. Notwithstanding all the damage that will continue to be caused by wildfires, we will no longer suffer the loss of life endured in the past because of the fire prevention and firefighting measures that have been put in place, he says.", "hypothesis": "Personnel in the past have been criticised for mishandling fire containment.", "gold_label": "entailment"}
{"uid": "id_342", "premise": "The megafires of California Drought, housing expansion, and oversupply of tinder make for bigger, hotter fires in the western United States Wildfires are becoming an increasing menace in the western United States, with Southern California being the hardest hit area. There's a reason fire squads battling more frequent blazes in Southern California are having such difficulty containing the flames, despite better preparedness than ever and decades of experience fighting fires fanned by the Santa Ana Winds. The wildfires themselves, experts say, are generally hotter, faster, and spread more erratically than in the past. Megafires, also called siege fires, are the increasingly frequent blazes that burn 500,000 acres or more - 10 times the size of the average forest fire of 20 years ago. Some recent wildfires are among the biggest ever in California in terms of acreage burned, according to state figures and news reports. One explanation for the trend to more superhot fires is that the region, which usually has dry summers, has had significantly below normal precipitation in many recent years. Another reason, experts say, is related to the century- long policy of the US Forest Service to stop wildfires as quickly as possible. The unintentional consequence has been to halt the natural eradication of underbrush, now the primary fuel for megafires. Three other factors contribute to the trend, they add. First is climate change, marked by a 1-degree Fahrenheit rise in average yearly temperature across the western states. Second is fire seasons that on average are 78 days longer than they were 20 years ago. Third is increased construction of homes in wooded areas. We are increasingly building our homes in fire-prone ecosystems, says Dominik Kulakowski, adjunct professor of biology at Clark University Graduate School of Geography in Worcester, Massachusetts. Doing that in many of the forests of the western US is like building homes on the side of an active volcano. ' In California, where population growth has averaged more than 600,000 a year for at least a decade, more residential housing is being built. What once was open space is now residential homes providing fuel to make fires burn with greater intensity, says Terry McHale of the California Department of Forestry firefighters' union. With so much dryness, so many communities to catch fire, so many fronts to fight, it becomes an almost incredible job. ' That said, many experts give California high marks for making progress on preparedness in recent years, after some of the largest fires in state history scorched thousands of acres, burned thousands of homes, and killed numerous people. Stung in the past by criticism of bungling that allowed fires to spread when they might have been contained, personnel are meeting the peculiar challenges of neighborhood - and canyon- hopping fires better than previously, observers say. State promises to provide more up-to-date engines, planes, and helicopters to fight fires have been fulfilled. Firefighters unions that in the past complained of dilapidated equipment, old fire engines, and insufficient blueprints for fire safety are now praising the state's commitment, noting that funding for firefighting has increased, despite huge cuts in many other programs. We are pleased that the current state administration has been very proactive in its support of us, and has come through with budgetary support of the infrastructure needs we have long sought, ' says Mr. McHale of the firefighters union. Besides providing money to upgrade the fire engines that must traverse the mammoth state and wind along serpentine canyon roads, the state has invested in better command-and-control facilities as well as in the 58strategies to run them. In the fire sieges of earlier years, we found that other jurisdictions and states were willing to offer mutual-aid help, but we were not able to communicate adequately with them, says Kim Zagaris, chief of the state's Office of Emergency Services Fire and Rescue Branch. After a commission examined and revamped communications procedures, the statewide response has become far more professional and responsive, he says. There is a sense among both government officials and residents that the speed, dedication, and coordination of firefighters from several states and jurisdictions are resulting in greater efficiency than in past siege fire situations. In recent years, the Southern California region has improved building codes, evacuation procedures, and procurement of new technology. I am extraordinarily impressed by the improvements we have witnessed, says Randy Jacobs, a Southern California- based lawyer who has had to evacuate both his home and business to escape wildfires. Notwithstanding all the damage that will continue to be caused by wildfires, we will no longer suffer the loss of life endured in the past because of the fire prevention and firefighting measures that have been put in place, he says.", "hypothesis": "Many experts believe California has made little progress in readying itself to fight fires.", "gold_label": "contradiction"}
{"uid": "id_343", "premise": "The megafires of California Drought, housing expansion, and oversupply of tinder make for bigger, hotter fires in the western United States Wildfires are becoming an increasing menace in the western United States, with Southern California being the hardest hit area. There's a reason fire squads battling more frequent blazes in Southern California are having such difficulty containing the flames, despite better preparedness than ever and decades of experience fighting fires fanned by the Santa Ana Winds. The wildfires themselves, experts say, are generally hotter, faster, and spread more erratically than in the past. Megafires, also called siege fires, are the increasingly frequent blazes that burn 500,000 acres or more - 10 times the size of the average forest fire of 20 years ago. Some recent wildfires are among the biggest ever in California in terms of acreage burned, according to state figures and news reports. One explanation for the trend to more superhot fires is that the region, which usually has dry summers, has had significantly below normal precipitation in many recent years. Another reason, experts say, is related to the century- long policy of the US Forest Service to stop wildfires as quickly as possible. The unintentional consequence has been to halt the natural eradication of underbrush, now the primary fuel for megafires. Three other factors contribute to the trend, they add. First is climate change, marked by a 1-degree Fahrenheit rise in average yearly temperature across the western states. Second is fire seasons that on average are 78 days longer than they were 20 years ago. Third is increased construction of homes in wooded areas. We are increasingly building our homes in fire-prone ecosystems, says Dominik Kulakowski, adjunct professor of biology at Clark University Graduate School of Geography in Worcester, Massachusetts. Doing that in many of the forests of the western US is like building homes on the side of an active volcano. ' In California, where population growth has averaged more than 600,000 a year for at least a decade, more residential housing is being built. What once was open space is now residential homes providing fuel to make fires burn with greater intensity, says Terry McHale of the California Department of Forestry firefighters' union. With so much dryness, so many communities to catch fire, so many fronts to fight, it becomes an almost incredible job. ' That said, many experts give California high marks for making progress on preparedness in recent years, after some of the largest fires in state history scorched thousands of acres, burned thousands of homes, and killed numerous people. Stung in the past by criticism of bungling that allowed fires to spread when they might have been contained, personnel are meeting the peculiar challenges of neighborhood - and canyon- hopping fires better than previously, observers say. State promises to provide more up-to-date engines, planes, and helicopters to fight fires have been fulfilled. Firefighters unions that in the past complained of dilapidated equipment, old fire engines, and insufficient blueprints for fire safety are now praising the state's commitment, noting that funding for firefighting has increased, despite huge cuts in many other programs. We are pleased that the current state administration has been very proactive in its support of us, and has come through with budgetary support of the infrastructure needs we have long sought, ' says Mr. McHale of the firefighters union. Besides providing money to upgrade the fire engines that must traverse the mammoth state and wind along serpentine canyon roads, the state has invested in better command-and-control facilities as well as in the 58strategies to run them. In the fire sieges of earlier years, we found that other jurisdictions and states were willing to offer mutual-aid help, but we were not able to communicate adequately with them, says Kim Zagaris, chief of the state's Office of Emergency Services Fire and Rescue Branch. After a commission examined and revamped communications procedures, the statewide response has become far more professional and responsive, he says. There is a sense among both government officials and residents that the speed, dedication, and coordination of firefighters from several states and jurisdictions are resulting in greater efficiency than in past siege fire situations. In recent years, the Southern California region has improved building codes, evacuation procedures, and procurement of new technology. I am extraordinarily impressed by the improvements we have witnessed, says Randy Jacobs, a Southern California- based lawyer who has had to evacuate both his home and business to escape wildfires. Notwithstanding all the damage that will continue to be caused by wildfires, we will no longer suffer the loss of life endured in the past because of the fire prevention and firefighting measures that have been put in place, he says.", "hypothesis": "California has replaced a range of firefighting tools.", "gold_label": "entailment"}
{"uid": "id_344", "premise": "The megafires of California Drought, housing expansion, and oversupply of tinder make for bigger, hotter fires in the western United States Wildfires are becoming an increasing menace in the western United States, with Southern California being the hardest hit area. There's a reason fire squads battling more frequent blazes in Southern California are having such difficulty containing the flames, despite better preparedness than ever and decades of experience fighting fires fanned by the Santa Ana Winds. The wildfires themselves, experts say, are generally hotter, faster, and spread more erratically than in the past. Megafires, also called siege fires, are the increasingly frequent blazes that burn 500,000 acres or more - 10 times the size of the average forest fire of 20 years ago. Some recent wildfires are among the biggest ever in California in terms of acreage burned, according to state figures and news reports. One explanation for the trend to more superhot fires is that the region, which usually has dry summers, has had significantly below normal precipitation in many recent years. Another reason, experts say, is related to the century- long policy of the US Forest Service to stop wildfires as quickly as possible. The unintentional consequence has been to halt the natural eradication of underbrush, now the primary fuel for megafires. Three other factors contribute to the trend, they add. First is climate change, marked by a 1-degree Fahrenheit rise in average yearly temperature across the western states. Second is fire seasons that on average are 78 days longer than they were 20 years ago. Third is increased construction of homes in wooded areas. We are increasingly building our homes in fire-prone ecosystems, says Dominik Kulakowski, adjunct professor of biology at Clark University Graduate School of Geography in Worcester, Massachusetts. Doing that in many of the forests of the western US is like building homes on the side of an active volcano. ' In California, where population growth has averaged more than 600,000 a year for at least a decade, more residential housing is being built. What once was open space is now residential homes providing fuel to make fires burn with greater intensity, says Terry McHale of the California Department of Forestry firefighters' union. With so much dryness, so many communities to catch fire, so many fronts to fight, it becomes an almost incredible job. ' That said, many experts give California high marks for making progress on preparedness in recent years, after some of the largest fires in state history scorched thousands of acres, burned thousands of homes, and killed numerous people. Stung in the past by criticism of bungling that allowed fires to spread when they might have been contained, personnel are meeting the peculiar challenges of neighborhood - and canyon- hopping fires better than previously, observers say. State promises to provide more up-to-date engines, planes, and helicopters to fight fires have been fulfilled. Firefighters unions that in the past complained of dilapidated equipment, old fire engines, and insufficient blueprints for fire safety are now praising the state's commitment, noting that funding for firefighting has increased, despite huge cuts in many other programs. We are pleased that the current state administration has been very proactive in its support of us, and has come through with budgetary support of the infrastructure needs we have long sought, ' says Mr. McHale of the firefighters union. Besides providing money to upgrade the fire engines that must traverse the mammoth state and wind along serpentine canyon roads, the state has invested in better command-and-control facilities as well as in the 58strategies to run them. In the fire sieges of earlier years, we found that other jurisdictions and states were willing to offer mutual-aid help, but we were not able to communicate adequately with them, says Kim Zagaris, chief of the state's Office of Emergency Services Fire and Rescue Branch. After a commission examined and revamped communications procedures, the statewide response has become far more professional and responsive, he says. There is a sense among both government officials and residents that the speed, dedication, and coordination of firefighters from several states and jurisdictions are resulting in greater efficiency than in past siege fire situations. In recent years, the Southern California region has improved building codes, evacuation procedures, and procurement of new technology. I am extraordinarily impressed by the improvements we have witnessed, says Randy Jacobs, a Southern California- based lawyer who has had to evacuate both his home and business to escape wildfires. Notwithstanding all the damage that will continue to be caused by wildfires, we will no longer suffer the loss of life endured in the past because of the fire prevention and firefighting measures that have been put in place, he says.", "hypothesis": "The amount of open space in California has diminished over the last ten years.", "gold_label": "entailment"}
{"uid": "id_345", "premise": "The megafires of California Drought, housing expansion, and oversupply of tinder make for bigger, hotter fires in the western United States Wildfires are becoming an increasing menace in the western United States, with Southern California being the hardest hit area. There's a reason fire squads battling more frequent blazes in Southern California are having such difficulty containing the flames, despite better preparedness than ever and decades of experience fighting fires fanned by the Santa Ana Winds. The wildfires themselves, experts say, are generally hotter, faster, and spread more erratically than in the past. Megafires, also called siege fires, are the increasingly frequent blazes that burn 500,000 acres or more - 10 times the size of the average forest fire of 20 years ago. Some recent wildfires are among the biggest ever in California in terms of acreage burned, according to state figures and news reports. One explanation for the trend to more superhot fires is that the region, which usually has dry summers, has had significantly below normal precipitation in many recent years. Another reason, experts say, is related to the century- long policy of the US Forest Service to stop wildfires as quickly as possible. The unintentional consequence has been to halt the natural eradication of underbrush, now the primary fuel for megafires. Three other factors contribute to the trend, they add. First is climate change, marked by a 1-degree Fahrenheit rise in average yearly temperature across the western states. Second is fire seasons that on average are 78 days longer than they were 20 years ago. Third is increased construction of homes in wooded areas. We are increasingly building our homes in fire-prone ecosystems, says Dominik Kulakowski, adjunct professor of biology at Clark University Graduate School of Geography in Worcester, Massachusetts. Doing that in many of the forests of the western US is like building homes on the side of an active volcano. ' In California, where population growth has averaged more than 600,000 a year for at least a decade, more residential housing is being built. What once was open space is now residential homes providing fuel to make fires burn with greater intensity, says Terry McHale of the California Department of Forestry firefighters' union. With so much dryness, so many communities to catch fire, so many fronts to fight, it becomes an almost incredible job. ' That said, many experts give California high marks for making progress on preparedness in recent years, after some of the largest fires in state history scorched thousands of acres, burned thousands of homes, and killed numerous people. Stung in the past by criticism of bungling that allowed fires to spread when they might have been contained, personnel are meeting the peculiar challenges of neighborhood - and canyon- hopping fires better than previously, observers say. State promises to provide more up-to-date engines, planes, and helicopters to fight fires have been fulfilled. Firefighters unions that in the past complained of dilapidated equipment, old fire engines, and insufficient blueprints for fire safety are now praising the state's commitment, noting that funding for firefighting has increased, despite huge cuts in many other programs. We are pleased that the current state administration has been very proactive in its support of us, and has come through with budgetary support of the infrastructure needs we have long sought, ' says Mr. McHale of the firefighters union. Besides providing money to upgrade the fire engines that must traverse the mammoth state and wind along serpentine canyon roads, the state has invested in better command-and-control facilities as well as in the 58strategies to run them. In the fire sieges of earlier years, we found that other jurisdictions and states were willing to offer mutual-aid help, but we were not able to communicate adequately with them, says Kim Zagaris, chief of the state's Office of Emergency Services Fire and Rescue Branch. After a commission examined and revamped communications procedures, the statewide response has become far more professional and responsive, he says. There is a sense among both government officials and residents that the speed, dedication, and coordination of firefighters from several states and jurisdictions are resulting in greater efficiency than in past siege fire situations. In recent years, the Southern California region has improved building codes, evacuation procedures, and procurement of new technology. I am extraordinarily impressed by the improvements we have witnessed, says Randy Jacobs, a Southern California- based lawyer who has had to evacuate both his home and business to escape wildfires. Notwithstanding all the damage that will continue to be caused by wildfires, we will no longer suffer the loss of life endured in the past because of the fire prevention and firefighting measures that have been put in place, he says.", "hypothesis": "More firefighters have been hired to improve fire-fighting capacity.", "gold_label": "neutral"}
{"uid": "id_346", "premise": "The megafires of California Drought, housing expansion, and oversupply of tinder make for bigger, hotter fires in the western United States Wildfires are becoming an increasing menace in the western United States, with Southern California being the hardest hit area. There's a reason fire squads battling more frequent blazes in Southern California are having such difficulty containing the flames, despite better preparedness than ever and decades of experience fighting fires fanned by the Santa Ana Winds. The wildfires themselves, experts say, are generally hotter, faster, and spread more erratically than in the past. Megafires, also called siege fires, are the increasingly frequent blazes that burn 500,000 acres or more - 10 times the size of the average forest fire of 20 years ago. Some recent wildfires are among the biggest ever in California in terms of acreage burned, according to state figures and news reports. One explanation for the trend to more superhot fires is that the region, which usually has dry summers, has had significantly below normal precipitation in many recent years. Another reason, experts say, is related to the century- long policy of the US Forest Service to stop wildfires as quickly as possible. The unintentional consequence has been to halt the natural eradication of underbrush, now the primary fuel for megafires. Three other factors contribute to the trend, they add. First is climate change, marked by a 1-degree Fahrenheit rise in average yearly temperature across the western states. Second is fire seasons that on average are 78 days longer than they were 20 years ago. Third is increased construction of homes in wooded areas. We are increasingly building our homes in fire-prone ecosystems, says Dominik Kulakowski, adjunct professor of biology at Clark University Graduate School of Geography in Worcester, Massachusetts. Doing that in many of the forests of the western US is like building homes on the side of an active volcano. ' In California, where population growth has averaged more than 600,000 a year for at least a decade, more residential housing is being built. What once was open space is now residential homes providing fuel to make fires burn with greater intensity, says Terry McHale of the California Department of Forestry firefighters' union. With so much dryness, so many communities to catch fire, so many fronts to fight, it becomes an almost incredible job. ' That said, many experts give California high marks for making progress on preparedness in recent years, after some of the largest fires in state history scorched thousands of acres, burned thousands of homes, and killed numerous people. Stung in the past by criticism of bungling that allowed fires to spread when they might have been contained, personnel are meeting the peculiar challenges of neighborhood - and canyon- hopping fires better than previously, observers say. State promises to provide more up-to-date engines, planes, and helicopters to fight fires have been fulfilled. Firefighters unions that in the past complained of dilapidated equipment, old fire engines, and insufficient blueprints for fire safety are now praising the state's commitment, noting that funding for firefighting has increased, despite huge cuts in many other programs. We are pleased that the current state administration has been very proactive in its support of us, and has come through with budgetary support of the infrastructure needs we have long sought, ' says Mr. McHale of the firefighters union. Besides providing money to upgrade the fire engines that must traverse the mammoth state and wind along serpentine canyon roads, the state has invested in better command-and-control facilities as well as in the 58strategies to run them. In the fire sieges of earlier years, we found that other jurisdictions and states were willing to offer mutual-aid help, but we were not able to communicate adequately with them, says Kim Zagaris, chief of the state's Office of Emergency Services Fire and Rescue Branch. After a commission examined and revamped communications procedures, the statewide response has become far more professional and responsive, he says. There is a sense among both government officials and residents that the speed, dedication, and coordination of firefighters from several states and jurisdictions are resulting in greater efficiency than in past siege fire situations. In recent years, the Southern California region has improved building codes, evacuation procedures, and procurement of new technology. I am extraordinarily impressed by the improvements we have witnessed, says Randy Jacobs, a Southern California- based lawyer who has had to evacuate both his home and business to escape wildfires. Notwithstanding all the damage that will continue to be caused by wildfires, we will no longer suffer the loss of life endured in the past because of the fire prevention and firefighting measures that have been put in place, he says.", "hypothesis": "Citizens and government groups disapprove of the efforts of different states and agencies working together.", "gold_label": "contradiction"}
{"uid": "id_347", "premise": "The megafires of California Drought, housing expansion, and oversupply of tinder make for bigger, hotter fires in the western United States Wildfires are becoming an increasing menace in the western United States, with Southern California being the hardest hit area. There's a reason fire squads battling more frequent blazes in Southern California are having such difficulty containing the flames, despite better preparedness than ever and decades of experience fighting fires fanned by the Santa Ana Winds. The wildfires themselves, experts say, are generally hotter, faster, and spread more erratically than in the past. Megafires, also called siege fires, are the increasingly frequent blazes that burn 500,000 acres or more - 10 times the size of the average forest fire of 20 years ago. Some recent wildfires are among the biggest ever in California in terms of acreage burned, according to state figures and news reports. One explanation for the trend to more superhot fires is that the region, which usually has dry summers, has had significantly below normal precipitation in many recent years. Another reason, experts say, is related to the century- long policy of the US Forest Service to stop wildfires as quickly as possible. The unintentional consequence has been to halt the natural eradication of underbrush, now the primary fuel for megafires. Three other factors contribute to the trend, they add. First is climate change, marked by a 1-degree Fahrenheit rise in average yearly temperature across the western states. Second is fire seasons that on average are 78 days longer than they were 20 years ago. Third is increased construction of homes in wooded areas. We are increasingly building our homes in fire-prone ecosystems, says Dominik Kulakowski, adjunct professor of biology at Clark University Graduate School of Geography in Worcester, Massachusetts. Doing that in many of the forests of the western US is like building homes on the side of an active volcano. ' In California, where population growth has averaged more than 600,000 a year for at least a decade, more residential housing is being built. What once was open space is now residential homes providing fuel to make fires burn with greater intensity, says Terry McHale of the California Department of Forestry firefighters' union. With so much dryness, so many communities to catch fire, so many fronts to fight, it becomes an almost incredible job. ' That said, many experts give California high marks for making progress on preparedness in recent years, after some of the largest fires in state history scorched thousands of acres, burned thousands of homes, and killed numerous people. Stung in the past by criticism of bungling that allowed fires to spread when they might have been contained, personnel are meeting the peculiar challenges of neighborhood - and canyon- hopping fires better than previously, observers say. State promises to provide more up-to-date engines, planes, and helicopters to fight fires have been fulfilled. Firefighters unions that in the past complained of dilapidated equipment, old fire engines, and insufficient blueprints for fire safety are now praising the state's commitment, noting that funding for firefighting has increased, despite huge cuts in many other programs. We are pleased that the current state administration has been very proactive in its support of us, and has come through with budgetary support of the infrastructure needs we have long sought, ' says Mr. McHale of the firefighters union. Besides providing money to upgrade the fire engines that must traverse the mammoth state and wind along serpentine canyon roads, the state has invested in better command-and-control facilities as well as in the 58strategies to run them. In the fire sieges of earlier years, we found that other jurisdictions and states were willing to offer mutual-aid help, but we were not able to communicate adequately with them, says Kim Zagaris, chief of the state's Office of Emergency Services Fire and Rescue Branch. After a commission examined and revamped communications procedures, the statewide response has become far more professional and responsive, he says. There is a sense among both government officials and residents that the speed, dedication, and coordination of firefighters from several states and jurisdictions are resulting in greater efficiency than in past siege fire situations. In recent years, the Southern California region has improved building codes, evacuation procedures, and procurement of new technology. I am extraordinarily impressed by the improvements we have witnessed, says Randy Jacobs, a Southern California- based lawyer who has had to evacuate both his home and business to escape wildfires. Notwithstanding all the damage that will continue to be caused by wildfires, we will no longer suffer the loss of life endured in the past because of the fire prevention and firefighting measures that have been put in place, he says.", "hypothesis": "Randy Jacobs believes that loss of life from fires will continue at the same levels, despite changes made.", "gold_label": "contradiction"}
{"uid": "id_348", "premise": "The megafires of California. Drought, housing expansion, and oversupply of tinder make for bigger, hotter fires in the western United States Wildfires are becoming an increasing menace in the western United States, with Southern California being the hardest hit area. Theres a reason fire squads battling more frequent blazes in Southern California are having such difficulty containing the flames, despite better preparedness than ever and decades of experience fighting fires fanned by the Santa Ana Winds. The wildfires themselves, experts say, are generally hotter, faster, and spread more erratically than in the past. Megafires, also called siege fires, are the increasingly frequent blazes that burn 500, 000 acres or more 10 times the size of the average forest fire of 20 years ago. Some recent wildfires are among the biggest ever in California in terms of acreage burned, according to state figures and news reports. One explanation for the trend to more superhot fires is that the region, which usually has dry summers, has had significantly below normal precipitation in many recent years. Another reason, experts say, is related to the century-long policy of the US Forest Service to stop wildfires as quickly as possible. The unintentional consequence has been to halt the natural eradication of underbrush, now the primary fuel for megafires. Three other factors contribute to the trend, they add. First is climate change, marked by a 1-degree Fahrenheit rise in average yearly temperature across the western states. Second is fire seasons that on average are 78 days longer than they were 20 years ago. Third is increased construction of homes in wooded areas. We are increasingly building our homes in fire-prone ecosystems, says Dominik Kulakowski, adjunct professor of biology at Clark University Graduate School of Geography in Worcester, Massachusetts. Doing that in many of the forests of the western US is like building homes on the side of an active volcano. In California, where population growth has averaged more than 600, 000 a year for at least a decade, more residential housing is being built. What once was open space is now residential homes providing fuel to make fires burn with greater intensity, says Terry McHale of the California Department of Forestry firefighters union. With so much dryness, so many communities to catch fire, so many fronts to fight, it becomes an almost incredible job. That said, many experts give California high marks for making progress on preparedness in recent years, after some of the largest fires in state history scorched thousands of acres, burned thousands of homes, and killed numerous people. Stung in the past by criticism of bungling that allowed fires to spread when they might have been contained, personnel are meeting the peculiar challenges of neighborhood and canyon- hopping fires better than previously, observers say. State promises to provide more up-to-date engines, planes, and helicopters to fight fires have been fulfilled. Firefighters unions that in the past complained of dilapidated equipment, old fire engines, and insufficient blueprints for fire safety are now praising the states commitment, noting that funding for firefighting has increased, despite huge cuts in many other programs. We are pleased that the current state administration has been very proactive in its support of us, and has come through with budgetary support of the infrastructure needs we have long sought, says Mr. McHale of the firefighters union. Besides providing money to upgrade the fire engines that must traverse the mammoth state and wind along serpentine canyon roads, the state has invested in better command-and-control facilities as well as in the strategies to run them. In the fire sieges of earlier years, we found that other jurisdictions and states were willing to offer mutual-aid help, but we were not able to communicate adequately with them, says Kim Zagaris, chief of the states Office of Emergency Services Fire and Rescue Branch. After a commission examined and revamped communications procedures, the statewide response has become far more professional and responsive, he says. There is a sense among both government officials and residents that the speed, dedication, and coordination of firefighters from several states and jurisdictions are resulting in greater efficiency than in past siege fire situations. In recent years, the Southern California region has improved building codes, evacuation procedures, and procurement of new technology. I am extraordinarily impressed by the improvements we have witnessed, says Randy Jacobs, a Southern California-based lawyer who has had to evacuate both his home and business to escape wildfires. Notwithstanding all the damage that will continue to be caused by wildfires, we will no longer suffer the loss of life endured in the past because of the fire prevention and firefighting measures that have been put in place, he says.", "hypothesis": "Citizens and government groups disapprove of the efforts of different states and agencies working together.", "gold_label": "contradiction"}
{"uid": "id_349", "premise": "The megafires of California. Drought, housing expansion, and oversupply of tinder make for bigger, hotter fires in the western United States Wildfires are becoming an increasing menace in the western United States, with Southern California being the hardest hit area. Theres a reason fire squads battling more frequent blazes in Southern California are having such difficulty containing the flames, despite better preparedness than ever and decades of experience fighting fires fanned by the Santa Ana Winds. The wildfires themselves, experts say, are generally hotter, faster, and spread more erratically than in the past. Megafires, also called siege fires, are the increasingly frequent blazes that burn 500, 000 acres or more 10 times the size of the average forest fire of 20 years ago. Some recent wildfires are among the biggest ever in California in terms of acreage burned, according to state figures and news reports. One explanation for the trend to more superhot fires is that the region, which usually has dry summers, has had significantly below normal precipitation in many recent years. Another reason, experts say, is related to the century-long policy of the US Forest Service to stop wildfires as quickly as possible. The unintentional consequence has been to halt the natural eradication of underbrush, now the primary fuel for megafires. Three other factors contribute to the trend, they add. First is climate change, marked by a 1-degree Fahrenheit rise in average yearly temperature across the western states. Second is fire seasons that on average are 78 days longer than they were 20 years ago. Third is increased construction of homes in wooded areas. We are increasingly building our homes in fire-prone ecosystems, says Dominik Kulakowski, adjunct professor of biology at Clark University Graduate School of Geography in Worcester, Massachusetts. Doing that in many of the forests of the western US is like building homes on the side of an active volcano. In California, where population growth has averaged more than 600, 000 a year for at least a decade, more residential housing is being built. What once was open space is now residential homes providing fuel to make fires burn with greater intensity, says Terry McHale of the California Department of Forestry firefighters union. With so much dryness, so many communities to catch fire, so many fronts to fight, it becomes an almost incredible job. That said, many experts give California high marks for making progress on preparedness in recent years, after some of the largest fires in state history scorched thousands of acres, burned thousands of homes, and killed numerous people. Stung in the past by criticism of bungling that allowed fires to spread when they might have been contained, personnel are meeting the peculiar challenges of neighborhood and canyon- hopping fires better than previously, observers say. State promises to provide more up-to-date engines, planes, and helicopters to fight fires have been fulfilled. Firefighters unions that in the past complained of dilapidated equipment, old fire engines, and insufficient blueprints for fire safety are now praising the states commitment, noting that funding for firefighting has increased, despite huge cuts in many other programs. We are pleased that the current state administration has been very proactive in its support of us, and has come through with budgetary support of the infrastructure needs we have long sought, says Mr. McHale of the firefighters union. Besides providing money to upgrade the fire engines that must traverse the mammoth state and wind along serpentine canyon roads, the state has invested in better command-and-control facilities as well as in the strategies to run them. In the fire sieges of earlier years, we found that other jurisdictions and states were willing to offer mutual-aid help, but we were not able to communicate adequately with them, says Kim Zagaris, chief of the states Office of Emergency Services Fire and Rescue Branch. After a commission examined and revamped communications procedures, the statewide response has become far more professional and responsive, he says. There is a sense among both government officials and residents that the speed, dedication, and coordination of firefighters from several states and jurisdictions are resulting in greater efficiency than in past siege fire situations. In recent years, the Southern California region has improved building codes, evacuation procedures, and procurement of new technology. I am extraordinarily impressed by the improvements we have witnessed, says Randy Jacobs, a Southern California-based lawyer who has had to evacuate both his home and business to escape wildfires. Notwithstanding all the damage that will continue to be caused by wildfires, we will no longer suffer the loss of life endured in the past because of the fire prevention and firefighting measures that have been put in place, he says.", "hypothesis": "More firefighters have been hired to improve fire-fighting capacity.", "gold_label": "neutral"}
{"uid": "id_350", "premise": "The megafires of California. Drought, housing expansion, and oversupply of tinder make for bigger, hotter fires in the western United States Wildfires are becoming an increasing menace in the western United States, with Southern California being the hardest hit area. Theres a reason fire squads battling more frequent blazes in Southern California are having such difficulty containing the flames, despite better preparedness than ever and decades of experience fighting fires fanned by the Santa Ana Winds. The wildfires themselves, experts say, are generally hotter, faster, and spread more erratically than in the past. Megafires, also called siege fires, are the increasingly frequent blazes that burn 500, 000 acres or more 10 times the size of the average forest fire of 20 years ago. Some recent wildfires are among the biggest ever in California in terms of acreage burned, according to state figures and news reports. One explanation for the trend to more superhot fires is that the region, which usually has dry summers, has had significantly below normal precipitation in many recent years. Another reason, experts say, is related to the century-long policy of the US Forest Service to stop wildfires as quickly as possible. The unintentional consequence has been to halt the natural eradication of underbrush, now the primary fuel for megafires. Three other factors contribute to the trend, they add. First is climate change, marked by a 1-degree Fahrenheit rise in average yearly temperature across the western states. Second is fire seasons that on average are 78 days longer than they were 20 years ago. Third is increased construction of homes in wooded areas. We are increasingly building our homes in fire-prone ecosystems, says Dominik Kulakowski, adjunct professor of biology at Clark University Graduate School of Geography in Worcester, Massachusetts. Doing that in many of the forests of the western US is like building homes on the side of an active volcano. In California, where population growth has averaged more than 600, 000 a year for at least a decade, more residential housing is being built. What once was open space is now residential homes providing fuel to make fires burn with greater intensity, says Terry McHale of the California Department of Forestry firefighters union. With so much dryness, so many communities to catch fire, so many fronts to fight, it becomes an almost incredible job. That said, many experts give California high marks for making progress on preparedness in recent years, after some of the largest fires in state history scorched thousands of acres, burned thousands of homes, and killed numerous people. Stung in the past by criticism of bungling that allowed fires to spread when they might have been contained, personnel are meeting the peculiar challenges of neighborhood and canyon- hopping fires better than previously, observers say. State promises to provide more up-to-date engines, planes, and helicopters to fight fires have been fulfilled. Firefighters unions that in the past complained of dilapidated equipment, old fire engines, and insufficient blueprints for fire safety are now praising the states commitment, noting that funding for firefighting has increased, despite huge cuts in many other programs. We are pleased that the current state administration has been very proactive in its support of us, and has come through with budgetary support of the infrastructure needs we have long sought, says Mr. McHale of the firefighters union. Besides providing money to upgrade the fire engines that must traverse the mammoth state and wind along serpentine canyon roads, the state has invested in better command-and-control facilities as well as in the strategies to run them. In the fire sieges of earlier years, we found that other jurisdictions and states were willing to offer mutual-aid help, but we were not able to communicate adequately with them, says Kim Zagaris, chief of the states Office of Emergency Services Fire and Rescue Branch. After a commission examined and revamped communications procedures, the statewide response has become far more professional and responsive, he says. There is a sense among both government officials and residents that the speed, dedication, and coordination of firefighters from several states and jurisdictions are resulting in greater efficiency than in past siege fire situations. In recent years, the Southern California region has improved building codes, evacuation procedures, and procurement of new technology. I am extraordinarily impressed by the improvements we have witnessed, says Randy Jacobs, a Southern California-based lawyer who has had to evacuate both his home and business to escape wildfires. Notwithstanding all the damage that will continue to be caused by wildfires, we will no longer suffer the loss of life endured in the past because of the fire prevention and firefighting measures that have been put in place, he says.", "hypothesis": "Randy Jacobs believes that loss of life from fires will continue at the same levels, despite changes made.", "gold_label": "contradiction"}
{"uid": "id_351", "premise": "The megafires of California. Drought, housing expansion, and oversupply of tinder make for bigger, hotter fires in the western United States Wildfires are becoming an increasing menace in the western United States, with Southern California being the hardest hit area. Theres a reason fire squads battling more frequent blazes in Southern California are having such difficulty containing the flames, despite better preparedness than ever and decades of experience fighting fires fanned by the Santa Ana Winds. The wildfires themselves, experts say, are generally hotter, faster, and spread more erratically than in the past. Megafires, also called siege fires, are the increasingly frequent blazes that burn 500, 000 acres or more 10 times the size of the average forest fire of 20 years ago. Some recent wildfires are among the biggest ever in California in terms of acreage burned, according to state figures and news reports. One explanation for the trend to more superhot fires is that the region, which usually has dry summers, has had significantly below normal precipitation in many recent years. Another reason, experts say, is related to the century-long policy of the US Forest Service to stop wildfires as quickly as possible. The unintentional consequence has been to halt the natural eradication of underbrush, now the primary fuel for megafires. Three other factors contribute to the trend, they add. First is climate change, marked by a 1-degree Fahrenheit rise in average yearly temperature across the western states. Second is fire seasons that on average are 78 days longer than they were 20 years ago. Third is increased construction of homes in wooded areas. We are increasingly building our homes in fire-prone ecosystems, says Dominik Kulakowski, adjunct professor of biology at Clark University Graduate School of Geography in Worcester, Massachusetts. Doing that in many of the forests of the western US is like building homes on the side of an active volcano. In California, where population growth has averaged more than 600, 000 a year for at least a decade, more residential housing is being built. What once was open space is now residential homes providing fuel to make fires burn with greater intensity, says Terry McHale of the California Department of Forestry firefighters union. With so much dryness, so many communities to catch fire, so many fronts to fight, it becomes an almost incredible job. That said, many experts give California high marks for making progress on preparedness in recent years, after some of the largest fires in state history scorched thousands of acres, burned thousands of homes, and killed numerous people. Stung in the past by criticism of bungling that allowed fires to spread when they might have been contained, personnel are meeting the peculiar challenges of neighborhood and canyon- hopping fires better than previously, observers say. State promises to provide more up-to-date engines, planes, and helicopters to fight fires have been fulfilled. Firefighters unions that in the past complained of dilapidated equipment, old fire engines, and insufficient blueprints for fire safety are now praising the states commitment, noting that funding for firefighting has increased, despite huge cuts in many other programs. We are pleased that the current state administration has been very proactive in its support of us, and has come through with budgetary support of the infrastructure needs we have long sought, says Mr. McHale of the firefighters union. Besides providing money to upgrade the fire engines that must traverse the mammoth state and wind along serpentine canyon roads, the state has invested in better command-and-control facilities as well as in the strategies to run them. In the fire sieges of earlier years, we found that other jurisdictions and states were willing to offer mutual-aid help, but we were not able to communicate adequately with them, says Kim Zagaris, chief of the states Office of Emergency Services Fire and Rescue Branch. After a commission examined and revamped communications procedures, the statewide response has become far more professional and responsive, he says. There is a sense among both government officials and residents that the speed, dedication, and coordination of firefighters from several states and jurisdictions are resulting in greater efficiency than in past siege fire situations. In recent years, the Southern California region has improved building codes, evacuation procedures, and procurement of new technology. I am extraordinarily impressed by the improvements we have witnessed, says Randy Jacobs, a Southern California-based lawyer who has had to evacuate both his home and business to escape wildfires. Notwithstanding all the damage that will continue to be caused by wildfires, we will no longer suffer the loss of life endured in the past because of the fire prevention and firefighting measures that have been put in place, he says.", "hypothesis": "California has replaced a range of firefighting tools.", "gold_label": "entailment"}
{"uid": "id_352", "premise": "The megafires of California. Drought, housing expansion, and oversupply of tinder make for bigger, hotter fires in the western United States Wildfires are becoming an increasing menace in the western United States, with Southern California being the hardest hit area. Theres a reason fire squads battling more frequent blazes in Southern California are having such difficulty containing the flames, despite better preparedness than ever and decades of experience fighting fires fanned by the Santa Ana Winds. The wildfires themselves, experts say, are generally hotter, faster, and spread more erratically than in the past. Megafires, also called siege fires, are the increasingly frequent blazes that burn 500, 000 acres or more 10 times the size of the average forest fire of 20 years ago. Some recent wildfires are among the biggest ever in California in terms of acreage burned, according to state figures and news reports. One explanation for the trend to more superhot fires is that the region, which usually has dry summers, has had significantly below normal precipitation in many recent years. Another reason, experts say, is related to the century-long policy of the US Forest Service to stop wildfires as quickly as possible. The unintentional consequence has been to halt the natural eradication of underbrush, now the primary fuel for megafires. Three other factors contribute to the trend, they add. First is climate change, marked by a 1-degree Fahrenheit rise in average yearly temperature across the western states. Second is fire seasons that on average are 78 days longer than they were 20 years ago. Third is increased construction of homes in wooded areas. We are increasingly building our homes in fire-prone ecosystems, says Dominik Kulakowski, adjunct professor of biology at Clark University Graduate School of Geography in Worcester, Massachusetts. Doing that in many of the forests of the western US is like building homes on the side of an active volcano. In California, where population growth has averaged more than 600, 000 a year for at least a decade, more residential housing is being built. What once was open space is now residential homes providing fuel to make fires burn with greater intensity, says Terry McHale of the California Department of Forestry firefighters union. With so much dryness, so many communities to catch fire, so many fronts to fight, it becomes an almost incredible job. That said, many experts give California high marks for making progress on preparedness in recent years, after some of the largest fires in state history scorched thousands of acres, burned thousands of homes, and killed numerous people. Stung in the past by criticism of bungling that allowed fires to spread when they might have been contained, personnel are meeting the peculiar challenges of neighborhood and canyon- hopping fires better than previously, observers say. State promises to provide more up-to-date engines, planes, and helicopters to fight fires have been fulfilled. Firefighters unions that in the past complained of dilapidated equipment, old fire engines, and insufficient blueprints for fire safety are now praising the states commitment, noting that funding for firefighting has increased, despite huge cuts in many other programs. We are pleased that the current state administration has been very proactive in its support of us, and has come through with budgetary support of the infrastructure needs we have long sought, says Mr. McHale of the firefighters union. Besides providing money to upgrade the fire engines that must traverse the mammoth state and wind along serpentine canyon roads, the state has invested in better command-and-control facilities as well as in the strategies to run them. In the fire sieges of earlier years, we found that other jurisdictions and states were willing to offer mutual-aid help, but we were not able to communicate adequately with them, says Kim Zagaris, chief of the states Office of Emergency Services Fire and Rescue Branch. After a commission examined and revamped communications procedures, the statewide response has become far more professional and responsive, he says. There is a sense among both government officials and residents that the speed, dedication, and coordination of firefighters from several states and jurisdictions are resulting in greater efficiency than in past siege fire situations. In recent years, the Southern California region has improved building codes, evacuation procedures, and procurement of new technology. I am extraordinarily impressed by the improvements we have witnessed, says Randy Jacobs, a Southern California-based lawyer who has had to evacuate both his home and business to escape wildfires. Notwithstanding all the damage that will continue to be caused by wildfires, we will no longer suffer the loss of life endured in the past because of the fire prevention and firefighting measures that have been put in place, he says.", "hypothesis": "Many experts believe California has made little progress in readying itself to fight fires.", "gold_label": "contradiction"}
{"uid": "id_353", "premise": "The megafires of California. Drought, housing expansion, and oversupply of tinder make for bigger, hotter fires in the western United States Wildfires are becoming an increasing menace in the western United States, with Southern California being the hardest hit area. Theres a reason fire squads battling more frequent blazes in Southern California are having such difficulty containing the flames, despite better preparedness than ever and decades of experience fighting fires fanned by the Santa Ana Winds. The wildfires themselves, experts say, are generally hotter, faster, and spread more erratically than in the past. Megafires, also called siege fires, are the increasingly frequent blazes that burn 500, 000 acres or more 10 times the size of the average forest fire of 20 years ago. Some recent wildfires are among the biggest ever in California in terms of acreage burned, according to state figures and news reports. One explanation for the trend to more superhot fires is that the region, which usually has dry summers, has had significantly below normal precipitation in many recent years. Another reason, experts say, is related to the century-long policy of the US Forest Service to stop wildfires as quickly as possible. The unintentional consequence has been to halt the natural eradication of underbrush, now the primary fuel for megafires. Three other factors contribute to the trend, they add. First is climate change, marked by a 1-degree Fahrenheit rise in average yearly temperature across the western states. Second is fire seasons that on average are 78 days longer than they were 20 years ago. Third is increased construction of homes in wooded areas. We are increasingly building our homes in fire-prone ecosystems, says Dominik Kulakowski, adjunct professor of biology at Clark University Graduate School of Geography in Worcester, Massachusetts. Doing that in many of the forests of the western US is like building homes on the side of an active volcano. In California, where population growth has averaged more than 600, 000 a year for at least a decade, more residential housing is being built. What once was open space is now residential homes providing fuel to make fires burn with greater intensity, says Terry McHale of the California Department of Forestry firefighters union. With so much dryness, so many communities to catch fire, so many fronts to fight, it becomes an almost incredible job. That said, many experts give California high marks for making progress on preparedness in recent years, after some of the largest fires in state history scorched thousands of acres, burned thousands of homes, and killed numerous people. Stung in the past by criticism of bungling that allowed fires to spread when they might have been contained, personnel are meeting the peculiar challenges of neighborhood and canyon- hopping fires better than previously, observers say. State promises to provide more up-to-date engines, planes, and helicopters to fight fires have been fulfilled. Firefighters unions that in the past complained of dilapidated equipment, old fire engines, and insufficient blueprints for fire safety are now praising the states commitment, noting that funding for firefighting has increased, despite huge cuts in many other programs. We are pleased that the current state administration has been very proactive in its support of us, and has come through with budgetary support of the infrastructure needs we have long sought, says Mr. McHale of the firefighters union. Besides providing money to upgrade the fire engines that must traverse the mammoth state and wind along serpentine canyon roads, the state has invested in better command-and-control facilities as well as in the strategies to run them. In the fire sieges of earlier years, we found that other jurisdictions and states were willing to offer mutual-aid help, but we were not able to communicate adequately with them, says Kim Zagaris, chief of the states Office of Emergency Services Fire and Rescue Branch. After a commission examined and revamped communications procedures, the statewide response has become far more professional and responsive, he says. There is a sense among both government officials and residents that the speed, dedication, and coordination of firefighters from several states and jurisdictions are resulting in greater efficiency than in past siege fire situations. In recent years, the Southern California region has improved building codes, evacuation procedures, and procurement of new technology. I am extraordinarily impressed by the improvements we have witnessed, says Randy Jacobs, a Southern California-based lawyer who has had to evacuate both his home and business to escape wildfires. Notwithstanding all the damage that will continue to be caused by wildfires, we will no longer suffer the loss of life endured in the past because of the fire prevention and firefighting measures that have been put in place, he says.", "hypothesis": "The amount of open space in California has diminished over the last ten years.", "gold_label": "entailment"}
{"uid": "id_354", "premise": "The megafires of California. Drought, housing expansion, and oversupply of tinder make for bigger, hotter fires in the western United States Wildfires are becoming an increasing menace in the western United States, with Southern California being the hardest hit area. Theres a reason fire squads battling more frequent blazes in Southern California are having such difficulty containing the flames, despite better preparedness than ever and decades of experience fighting fires fanned by the Santa Ana Winds. The wildfires themselves, experts say, are generally hotter, faster, and spread more erratically than in the past. Megafires, also called siege fires, are the increasingly frequent blazes that burn 500, 000 acres or more 10 times the size of the average forest fire of 20 years ago. Some recent wildfires are among the biggest ever in California in terms of acreage burned, according to state figures and news reports. One explanation for the trend to more superhot fires is that the region, which usually has dry summers, has had significantly below normal precipitation in many recent years. Another reason, experts say, is related to the century-long policy of the US Forest Service to stop wildfires as quickly as possible. The unintentional consequence has been to halt the natural eradication of underbrush, now the primary fuel for megafires. Three other factors contribute to the trend, they add. First is climate change, marked by a 1-degree Fahrenheit rise in average yearly temperature across the western states. Second is fire seasons that on average are 78 days longer than they were 20 years ago. Third is increased construction of homes in wooded areas. We are increasingly building our homes in fire-prone ecosystems, says Dominik Kulakowski, adjunct professor of biology at Clark University Graduate School of Geography in Worcester, Massachusetts. Doing that in many of the forests of the western US is like building homes on the side of an active volcano. In California, where population growth has averaged more than 600, 000 a year for at least a decade, more residential housing is being built. What once was open space is now residential homes providing fuel to make fires burn with greater intensity, says Terry McHale of the California Department of Forestry firefighters union. With so much dryness, so many communities to catch fire, so many fronts to fight, it becomes an almost incredible job. That said, many experts give California high marks for making progress on preparedness in recent years, after some of the largest fires in state history scorched thousands of acres, burned thousands of homes, and killed numerous people. Stung in the past by criticism of bungling that allowed fires to spread when they might have been contained, personnel are meeting the peculiar challenges of neighborhood and canyon- hopping fires better than previously, observers say. State promises to provide more up-to-date engines, planes, and helicopters to fight fires have been fulfilled. Firefighters unions that in the past complained of dilapidated equipment, old fire engines, and insufficient blueprints for fire safety are now praising the states commitment, noting that funding for firefighting has increased, despite huge cuts in many other programs. We are pleased that the current state administration has been very proactive in its support of us, and has come through with budgetary support of the infrastructure needs we have long sought, says Mr. McHale of the firefighters union. Besides providing money to upgrade the fire engines that must traverse the mammoth state and wind along serpentine canyon roads, the state has invested in better command-and-control facilities as well as in the strategies to run them. In the fire sieges of earlier years, we found that other jurisdictions and states were willing to offer mutual-aid help, but we were not able to communicate adequately with them, says Kim Zagaris, chief of the states Office of Emergency Services Fire and Rescue Branch. After a commission examined and revamped communications procedures, the statewide response has become far more professional and responsive, he says. There is a sense among both government officials and residents that the speed, dedication, and coordination of firefighters from several states and jurisdictions are resulting in greater efficiency than in past siege fire situations. In recent years, the Southern California region has improved building codes, evacuation procedures, and procurement of new technology. I am extraordinarily impressed by the improvements we have witnessed, says Randy Jacobs, a Southern California-based lawyer who has had to evacuate both his home and business to escape wildfires. Notwithstanding all the damage that will continue to be caused by wildfires, we will no longer suffer the loss of life endured in the past because of the fire prevention and firefighting measures that have been put in place, he says.", "hypothesis": "Personnel in the past have been criticised for mishandling fire containment.", "gold_label": "entailment"}
{"uid": "id_355", "premise": "The merger between the Australian owned BHT and British owned Billis has formed a world class leader in the natural resources sector. Financially weaker Billis has brought to the merger its diversified business portfolio and high profitability whilst BHT brought substantial capital and a strong governmental lobby as a leading Australian organisation. Whilst oil, copper, coal and uranium will remain the main products of the newly merged company BHT Billis is looking to penetrate other markets such as additional oils, gases, silver, titanium, other minerals and diamonds.", "hypothesis": "BHT Billis wants to shift business focus from oil, copper, coal and uranium to new markets like gas, silver, titanium, minerals and diamonds.", "gold_label": "contradiction"}
{"uid": "id_356", "premise": "The merger between the Australian owned BHT and British owned Billis has formed a world class leader in the natural resources sector. Financially weaker Billis has brought to the merger its diversified business portfolio and high profitability whilst BHT brought substantial capital and a strong governmental lobby as a leading Australian organisation. Whilst oil, copper, coal and uranium will remain the main products of the newly merged company BHT Billis is looking to penetrate other markets such as additional oils, gases, silver, titanium, other minerals and diamonds.", "hypothesis": "Billis provided the major financial support for the merger.", "gold_label": "contradiction"}
{"uid": "id_357", "premise": "The merger between the Australian owned BHT and British owned Billis has formed a world class leader in the natural resources sector. Financially weaker Billis has brought to the merger its diversified business portfolio and high profitability whilst BHT brought substantial capital and a strong governmental lobby as a leading Australian organisation. Whilst oil, copper, coal and uranium will remain the main products of the newly merged company BHT Billis is looking to penetrate other markets such as additional oils, gases, silver, titanium, other minerals and diamonds.", "hypothesis": "Shareholders should expect greater return on the value of their shares as a result of the merger.", "gold_label": "neutral"}
{"uid": "id_358", "premise": "The merits of single-sex education have long been debated in the United States, where demand for single-sex schools is on the rise. Title IV, a 1972 law prohibiting sex discrimination in education, was amended in 2006, allowing for the establishment of single-sex state schools so long as a co- educational alternative is available. While critics view single-sex schools as discriminatory and inadequate preparation for adult life, advocates claim that children, and particularly girls, benefit from a single-sex education. Some American research shows that girls attending single-sex schools have higher self-esteem, participate more in class, and score higher on aptitude tests than their counterparts in co-educational schools. A 2005 study claimed that both girls and boys attending single-sex schools spent more time on homework and had less disciplinary problems. Single-sex schools subvert stereotypical course-taking patterns and results. Advocates of single-sex schooling argue that educators can teach more effectively by tailoring their tuition to reflect current research about gender-based brain development. Many experts, however, believe that research into single-sex education is inconclusive, and that so long as the education provided is gender-fair, both girls and boys can thrive in a co-educational environment.", "hypothesis": "Critics of single-sex education believe that such schools reinforce pre- existing gender stereotypes.", "gold_label": "neutral"}
{"uid": "id_359", "premise": "The merits of single-sex education have long been debated in the United States, where demand for single-sex schools is on the rise. Title IV, a 1972 law prohibiting sex discrimination in education, was amended in 2006, allowing for the establishment of single-sex state schools so long as a co- educational alternative is available. While critics view single-sex schools as discriminatory and inadequate preparation for adult life, advocates claim that children, and particularly girls, benefit from a single-sex education. Some American research shows that girls attending single-sex schools have higher self-esteem, participate more in class, and score higher on aptitude tests than their counterparts in co-educational schools. A 2005 study claimed that both girls and boys attending single-sex schools spent more time on homework and had less disciplinary problems. Single-sex schools subvert stereotypical course-taking patterns and results. Advocates of single-sex schooling argue that educators can teach more effectively by tailoring their tuition to reflect current research about gender-based brain development. Many experts, however, believe that research into single-sex education is inconclusive, and that so long as the education provided is gender-fair, both girls and boys can thrive in a co-educational environment.", "hypothesis": "Girls who attend single-sex schools perform better in maths and sciences than their counterparts in co-educational schools.", "gold_label": "neutral"}
{"uid": "id_360", "premise": "The merits of single-sex education have long been debated in the United States, where demand for single-sex schools is on the rise. Title IV, a 1972 law prohibiting sex discrimination in education, was amended in 2006, allowing for the establishment of single-sex state schools so long as a co- educational alternative is available. While critics view single-sex schools as discriminatory and inadequate preparation for adult life, advocates claim that children, and particularly girls, benefit from a single-sex education. Some American research shows that girls attending single-sex schools have higher self-esteem, participate more in class, and score higher on aptitude tests than their counterparts in co-educational schools. A 2005 study claimed that both girls and boys attending single-sex schools spent more time on homework and had less disciplinary problems. Single-sex schools subvert stereotypical course-taking patterns and results. Advocates of single-sex schooling argue that educators can teach more effectively by tailoring their tuition to reflect current research about gender-based brain development. Many experts, however, believe that research into single-sex education is inconclusive, and that so long as the education provided is gender-fair, both girls and boys can thrive in a co-educational environment.", "hypothesis": "The trend towards American single-sex state education is a relatively recent phenomenon.", "gold_label": "entailment"}
{"uid": "id_361", "premise": "The merits of single-sex education have long been debated in the United States, where demand for single-sex schools is on the rise. Title IV, a 1972 law prohibiting sex discrimination in education, was amended in 2006, allowing for the establishment of single-sex state schools so long as a co- educational alternative is available. While critics view single-sex schools as discriminatory and inadequate preparation for adult life, advocates claim that children, and particularly girls, benefit from a single-sex education. Some American research shows that girls attending single-sex schools have higher self-esteem, participate more in class, and score higher on aptitude tests than their counterparts in co-educational schools. A 2005 study claimed that both girls and boys attending single-sex schools spent more time on homework and had less disciplinary problems. Single-sex schools subvert stereotypical course-taking patterns and results. Advocates of single-sex schooling argue that educators can teach more effectively by tailoring their tuition to reflect current research about gender-based brain development. Many experts, however, believe that research into single-sex education is inconclusive, and that so long as the education provided is gender-fair, both girls and boys can thrive in a co-educational environment.", "hypothesis": "Proponents of single-sex education believe there are neurological differences between the two genders.", "gold_label": "entailment"}
{"uid": "id_362", "premise": "The merits of single-sex education have long been debated in the United States, where demand for single-sex schools is on the rise. Title IV, a 1972 law prohibiting sex discrimination in education, was amended in 2006, allowing for the establishment of single-sex state schools so long as a co- educational alternative is available. While critics view single-sex schools as discriminatory and inadequate preparation for adult life, advocates claim that children, and particularly girls, benefit from a single-sex education. Some American research shows that girls attending single-sex schools have higher self-esteem, participate more in class, and score higher on aptitude tests than their counterparts in co-educational schools. A 2005 study claimed that both girls and boys attending single-sex schools spent more time on homework and had less disciplinary problems. Single-sex schools subvert stereotypical course-taking patterns and results. Advocates of single-sex schooling argue that educators can teach more effectively by tailoring their tuition to reflect current research about gender-based brain development. Many experts, however, believe that research into single-sex education is inconclusive, and that so long as the education provided is gender-fair, both girls and boys can thrive in a co-educational environment.", "hypothesis": "Whereas girls benefit academically from single-sex education, the only advantage for boys is improved discipline.", "gold_label": "contradiction"}
{"uid": "id_363", "premise": "The ministry of railways has decided to develop 400 identified railway stations under the innovative Swiss Challenge method; it has decided to go ahead with the development of a few stations on its own.", "hypothesis": "Railways has decided to develop stations into commercial hubs along with all the amenities for passengers.", "gold_label": "contradiction"}
{"uid": "id_364", "premise": "The ministry of railways has decided to develop 400 identified railway stations under the innovative Swiss Challenge method; it has decided to go ahead with the development of a few stations on its own.", "hypothesis": "There are several methods to develop a railway station.", "gold_label": "contradiction"}
{"uid": "id_365", "premise": "The ministry of railways has decided to develop 400 identified railway stations under the innovative Swiss Challenge method; it has decided to go ahead with the development of a few stations on its own.", "hypothesis": "Railways has decided to revamp the railway stations with the help of private sector.", "gold_label": "contradiction"}
{"uid": "id_366", "premise": "The ministry of railways has decided to develop 400 identified railway stations under the innovative Swiss Challenge method; it has decided to go ahead with the development of a few stations on its own.", "hypothesis": "Railways has decided to upgrade a few stations with the help of the public sector.", "gold_label": "entailment"}
{"uid": "id_367", "premise": "The model of consumer behavior on which neo-classical demand theory is based implies that consumers are perfectly informed about the price and quality characteristics of the products on offer, and are constantly altering their expenditure patterns in response to price and quality changes, so as to maximize their total utility(satisfaction). This model is unrealistic, as the range of products on offer in modern markets is immense, and no consumer has the knowledge or inclination to acquire the information that would be needed to make choices in this way.", "hypothesis": "Being up to date with product information plays little part in neo-classical demand theory.", "gold_label": "contradiction"}
{"uid": "id_368", "premise": "The model of consumer behavior on which neo-classical demand theory is based implies that consumers are perfectly informed about the price and quality characteristics of the products on offer, and are constantly altering their expenditure patterns in response to price and quality changes, so as to maximize their total utility(satisfaction). This model is unrealistic, as the range of products on offer in modern markets is immense, and no consumer has the knowledge or inclination to acquire the information that would be needed to make choices in this way.", "hypothesis": "Neo-classical demand theory is only one of a number of models of consumer behavior.", "gold_label": "neutral"}
{"uid": "id_369", "premise": "The model of consumer behavior on which neo-classical demand theory is based implies that consumers are perfectly informed about the price and quality characteristics of the products on offer, and are constantly altering their expenditure patterns in response to price and quality changes, so as to maximize their total utility(satisfaction). This model is unrealistic, as the range of products on offer in modern markets is immense, and no consumer has the knowledge or inclination to acquire the information that would be needed to make choices in this way.", "hypothesis": "Maximizing the total utility of a product purchase implies consideration of both price and quality characteristics.", "gold_label": "entailment"}
{"uid": "id_370", "premise": "The model of consumer behavior on which neo-classical demand theory is based implies that consumers are perfectly informed about the price and quality characteristics of the products on offer, and are constantly altering their expenditure patterns in response to price and quality changes, so as to maximize their total utility(satisfaction). This model is unrealistic, as the range of products on offer in modern markets is immense, and no consumer has the knowledge or inclination to acquire the information that would be needed to make choices in this way.", "hypothesis": "There are some consumers who are perfectly informed about the price and quality characteristics of products on offer.", "gold_label": "contradiction"}
{"uid": "id_371", "premise": "The model of consumer behaviour on which neo-classical demand theory is based implies that consumers are perfectly informed about the price and quality characteristics of the products on offer, and are constantly altering their expenditure patterns in response to price and quality changes, so as to maximise their total utility (satisfaction). This model is unrealistic, as the range of products on offer in modern markets is immense, and no consumer has the knowledge or inclination to acquire the information that would be needed to make choices in this way.", "hypothesis": "Being up to date with product information plays little part in neo-classical demand theory.", "gold_label": "contradiction"}
{"uid": "id_372", "premise": "The model of consumer behaviour on which neo-classical demand theory is based implies that consumers are perfectly informed about the price and quality characteristics of the products on offer, and are constantly altering their expenditure patterns in response to price and quality changes, so as to maximise their total utility (satisfaction). This model is unrealistic, as the range of products on offer in modern markets is immense, and no consumer has the knowledge or inclination to acquire the information that would be needed to make choices in this way.", "hypothesis": "Neo-classical demand theory is only one of a number of models of consumer behaviour.", "gold_label": "neutral"}
{"uid": "id_373", "premise": "The model of consumer behaviour on which neo-classical demand theory is based implies that consumers are perfectly informed about the price and quality characteristics of the products on offer, and are constantly altering their expenditure patterns in response to price and quality changes, so as to maximise their total utility (satisfaction). This model is unrealistic, as the range of products on offer in modern markets is immense, and no consumer has the knowledge or inclination to acquire the information that would be needed to make choices in this way.", "hypothesis": "There are some consumers who are perfectly informed about the price and quality characteristics of products on offer.", "gold_label": "contradiction"}
{"uid": "id_374", "premise": "The model of consumer behaviour on which neo-classical demand theory is based implies that consumers are perfectly informed about the price and quality characteristics of the products on offer, and are constantly altering their expenditure patterns in response to price and quality changes, so as to maximise their total utility (satisfaction). This model is unrealistic, as the range of products on offer in modern markets is immense, and no consumer has the knowledge or inclination to acquire the information that would be needed to make choices in this way.", "hypothesis": "Maximising the total utility of a product purchase implies consideration of both price and quality characteristics.", "gold_label": "entailment"}
{"uid": "id_375", "premise": "The most commonly cited reasons for companies to use the internet for recruitment were cost-effectiveness, ease of use and the potential to access a larger number of candidates. In the past year the number of organizations using the internet to fill jobs has risen by almost a third. Now 12 million job seekers are expected to apply online in the UK each year. In the United States 51% of all jobs were advertised online; the UK figure is around 27%, so analysts feel that there is still considerable growth left in the UK market. The age of online recruitment seems to have arrived, but many companies are using it only as one part of a multimedia recruitment strategy.", "hypothesis": "One reason for online recruitments popularity is because it represents good value.", "gold_label": "entailment"}
{"uid": "id_376", "premise": "The most commonly cited reasons for companies to use the internet for recruitment were cost-effectiveness, ease of use and the potential to access a larger number of candidates. In the past year the number of organizations using the internet to fill jobs has risen by almost a third. Now 12 million job seekers are expected to apply online in the UK each year. In the United States 51% of all jobs were advertised online; the UK figure is around 27%, so analysts feel that there is still considerable growth left in the UK market. The age of online recruitment seems to have arrived, but many companies are using it only as one part of a multimedia recruitment strategy.", "hypothesis": "The majority of UK jobs are now advertised on the internet.", "gold_label": "contradiction"}
{"uid": "id_377", "premise": "The most commonly cited reasons for companies to use the internet for recruitment were cost-effectiveness, ease of use and the potential to access a larger number of candidates. In the past year the number of organizations using the internet to fill jobs has risen by almost a third. Now 12 million job seekers are expected to apply online in the UK each year. In the United States 51% of all jobs were advertised online; the UK figure is around 27%, so analysts feel that there is still considerable growth left in the UK market. The age of online recruitment seems to have arrived, but many companies are using it only as one part of a multimedia recruitment strategy.", "hypothesis": "To be sure to access an even larger number of candidates a company must advertise vacancies on the internet as well as through more traditional media.", "gold_label": "neutral"}
{"uid": "id_378", "premise": "The most prevalent neurological condition in the developed world, migraine is characterised by severe, recurrent headaches, with additional symptoms including nausea and sensitivity to light and sound. The frequency and duration of migraine attacks are variable: attacks may occur a few times a year or several times per month, while pain may last between four hours and three days. Approximately one third of sufferers experience an aura a perceptual disturbance occurring before the migraines onset. There are numerous theories on the cause of migraines. The vascular theory posits that migraines are caused by problems with blood vessels in the brain. A more widely held view is that migraines result from low levels of the neurotransmitter serotonin in the brain. Prophylactic drug treatment, which prevents the onset of migraines, has declined in recent years, because of side effects and also improvements in medications treating an actual attack. Whereas older varieties of pain medication are potentially addictive, newer drugs called triptans work by reducing pain information travelling to the brain. Treatment plans typically include avoidance of known migraine triggers, such as diet, alcohol, and stress, as overuse of medication can lead to chronic rebound headaches. Not only do migraines have a debilitating effect on sufferers, they are also bad for the economy, with an estimated 25 million days lost from work every year in the UK alone.", "hypothesis": "The vascular theory has been discredited.", "gold_label": "neutral"}
{"uid": "id_379", "premise": "The most prevalent neurological condition in the developed world, migraine is characterised by severe, recurrent headaches, with additional symptoms including nausea and sensitivity to light and sound. The frequency and duration of migraine attacks are variable: attacks may occur a few times a year or several times per month, while pain may last between four hours and three days. Approximately one third of sufferers experience an aura a perceptual disturbance occurring before the migraines onset. There are numerous theories on the cause of migraines. The vascular theory posits that migraines are caused by problems with blood vessels in the brain. A more widely held view is that migraines result from low levels of the neurotransmitter serotonin in the brain. Prophylactic drug treatment, which prevents the onset of migraines, has declined in recent years, because of side effects and also improvements in medications treating an actual attack. Whereas older varieties of pain medication are potentially addictive, newer drugs called triptans work by reducing pain information travelling to the brain. Treatment plans typically include avoidance of known migraine triggers, such as diet, alcohol, and stress, as overuse of medication can lead to chronic rebound headaches. Not only do migraines have a debilitating effect on sufferers, they are also bad for the economy, with an estimated 25 million days lost from work every year in the UK alone.", "hypothesis": "The passage states that it is not possible to work when suffering from a migraine.", "gold_label": "contradiction"}
{"uid": "id_380", "premise": "The most prevalent neurological condition in the developed world, migraine is characterised by severe, recurrent headaches, with additional symptoms including nausea and sensitivity to light and sound. The frequency and duration of migraine attacks are variable: attacks may occur a few times a year or several times per month, while pain may last between four hours and three days. Approximately one third of sufferers experience an aura a perceptual disturbance occurring before the migraines onset. There are numerous theories on the cause of migraines. The vascular theory posits that migraines are caused by problems with blood vessels in the brain. A more widely held view is that migraines result from low levels of the neurotransmitter serotonin in the brain. Prophylactic drug treatment, which prevents the onset of migraines, has declined in recent years, because of side effects and also improvements in medications treating an actual attack. Whereas older varieties of pain medication are potentially addictive, newer drugs called triptans work by reducing pain information travelling to the brain. Treatment plans typically include avoidance of known migraine triggers, such as diet, alcohol, and stress, as overuse of medication can lead to chronic rebound headaches. Not only do migraines have a debilitating effect on sufferers, they are also bad for the economy, with an estimated 25 million days lost from work every year in the UK alone.", "hypothesis": "One third of migraines are preceded by a heightened sensitivity to light.", "gold_label": "neutral"}
{"uid": "id_381", "premise": "The most prevalent neurological condition in the developed world, migraine is characterised by severe, recurrent headaches, with additional symptoms including nausea and sensitivity to light and sound. The frequency and duration of migraine attacks are variable: attacks may occur a few times a year or several times per month, while pain may last between four hours and three days. Approximately one third of sufferers experience an aura a perceptual disturbance occurring before the migraines onset. There are numerous theories on the cause of migraines. The vascular theory posits that migraines are caused by problems with blood vessels in the brain. A more widely held view is that migraines result from low levels of the neurotransmitter serotonin in the brain. Prophylactic drug treatment, which prevents the onset of migraines, has declined in recent years, because of side effects and also improvements in medications treating an actual attack. Whereas older varieties of pain medication are potentially addictive, newer drugs called triptans work by reducing pain information travelling to the brain. Treatment plans typically include avoidance of known migraine triggers, such as diet, alcohol, and stress, as overuse of medication can lead to chronic rebound headaches. Not only do migraines have a debilitating effect on sufferers, they are also bad for the economy, with an estimated 25 million days lost from work every year in the UK alone.", "hypothesis": "Triptans are a new form of prophylactic drug which are less addictive than older medications.", "gold_label": "contradiction"}
{"uid": "id_382", "premise": "The most prevalent neurological condition in the developed world, migraine is characterised by severe, recurrent headaches, with additional symptoms including nausea and sensitivity to light and sound. The frequency and duration of migraine attacks are variable: attacks may occur a few times a year or several times per month, while pain may last between four hours and three days. Approximately one third of sufferers experience an aura a perceptual disturbance occurring before the migraines onset. There are numerous theories on the cause of migraines. The vascular theory posits that migraines are caused by problems with blood vessels in the brain. A more widely held view is that migraines result from low levels of the neurotransmitter serotonin in the brain. Prophylactic drug treatment, which prevents the onset of migraines, has declined in recent years, because of side effects and also improvements in medications treating an actual attack. Whereas older varieties of pain medication are potentially addictive, newer drugs called triptans work by reducing pain information travelling to the brain. Treatment plans typically include avoidance of known migraine triggers, such as diet, alcohol, and stress, as overuse of medication can lead to chronic rebound headaches. Not only do migraines have a debilitating effect on sufferers, they are also bad for the economy, with an estimated 25 million days lost from work every year in the UK alone.", "hypothesis": "Although the cause of migraines is unknown, serotonin deficiency is the most commonly held theory.", "gold_label": "neutral"}
{"uid": "id_383", "premise": "The music industry continues to be one of the fastest growing sectors of the British economy. This trend can be traced to the large range of medias available, such as concerts and downloads, and the wide ranging target audience. For example, the music industry confidently boasts to be the only form of media enjoyed by both the youngest and oldest individuals in society. In comparison, forms of media, such as gaming, are enjoyed a by a marginal sector of society. However, statistics suggest that not all forms of music are enjoying this boom. Sales figures for operatic music continue to decrease steadily. In this way, it is feared that the dominance of the music industry, catering to popular culture, comes at the expense of long-standing art forms.", "hypothesis": "the music industry the fastest growing sector in the British economy because it caters to a wide target audience.", "gold_label": "entailment"}
{"uid": "id_384", "premise": "The music, film and video game retailer HMV recently reported annual loss of 38.6 million due to declining sales and restructuring costs. The main reason attributed to this decline in sales is the rise of online music and film download websites. Music and film lovers are now able to download songs and film at the click of a button, without requiring a stop at their local HMV or retailer. Only time will tell if the online music and film industry will make HMV, the CD and the DVD obsolete in favour of a fully online entertainment industry.", "hypothesis": "HMVs reported annual loss was 38.6 Million", "gold_label": "entailment"}
{"uid": "id_385", "premise": "The name is a reference to the colour scheme that the Womens Social and Political Union (WSPU) created to give the movement a uniform, nationwide image. By doing so, it became one of the first groups to project a corporate identity, and it is this advanced marketing strategy, along with the other organisational and commercial achievements of the WSPU, to which the exhibition is devoted. The suffragette movement, which campaigned for votes for women in the early twentieth century, is most commonly associated with the Pankhurst family and militant acts of varying degrees of violence. The Museum of London has drawn on its archive collection to convey a fresh picture with its exhibition The Purple, White and Green: Suffragettes in London 1906- Formed in 1903 by the political campaigner Mrs Emmeline Pankhurst and her daughters Christabel and Sylvia, the WSPU began an educated campaign to put womens suffrage on the political agenda. New Zealand, Australia and parts of the United States had already enfranchised women, and growing numbers of their British counterparts wanted the same opportunity. With their slogan Deeds not words, and the introduction of the colour scheme, the WSPU soon brought the movement the cohesion and focus it had previously lacked. Membership grew rapidly as women deserted the many other, less directed, groups and joined it. By 1906 the WSPU headquarters, called the Womens Press Shop, had been established in Charing Cross Road and in spite of limited communications (no radio or television, and minimal use of the telephone) the message had spread around the country, with members and branch officers stretching to as far away as Scotland. The newspapers produced by the WSPU, first Votes for Women and later The Suffragette, played a vital role in this communication. Both were sold throughout the country and proved an invaluable way of informing members of meetings, marches, fund-raising events and the latest news and views on the movement. Equally importantly for a rising political group, the newspaper returned a profit. This was partly becauseReading advertising space was bought in the paper by large department stores such as Selfridges, and jewellers such as Mappin & Webb. These two, together with other like- minded commercial enterprises sympathetic to the cause, had quickly identified a direct way to reach a huge market of women, many with money to spend. The creation of the colour scheme provided another money-making opportunity which the WSPU was quick to exploit. The group began to sell playing cards, board games, Christmas and greeting cards, and countless other goods, all in the purple, white and green colours. In 1906 such merchandising of a corporate identity was a new marketing concept. But the paper and merchandising activities alone did not provide sufficient funds for the WSPU to meet organisational costs, so numerous other fund-raising activities combined to fill the coffers of the war chest. The most notable of these was the Womans Exhibition, which took place in 1909 in a Knightsbridge ice-skating rink, and in 10 days raised the equivalent of 250,000 today. The Museum of Londons exhibition is largely visual, with a huge number of items on show. Against a quiet background hum of street sounds, copies of The Suffragette, campaign banners and photographs are all on display, together with one of Mrs Pankhursts shoes and a number of purple, white and green trinkets. Photographs depict vivid scenes of a suffragettes life: WSPU members on a self- proclaimed monster march, wearing their official uniforms of a white frock decorated with purple, white and green accessories; women selling The Suffragette at street corners, or chalking up pavements with details of a forthcoming meeting. Windows display postcards and greeting cards designed by women artists for the movement, and the quality of the artwork indicates the wealth of resources the WSPU could call on from its talented members. Visitors can watch a short film made up of old newsreels and cinema material which clearly reveals the political mood of the day towards the suffragettes. The programme begins with a short film devised by the antis - those opposed to women having the vote -depicting a suffragette as a fierce harridan bullying her poor, abused husband. Original newsreel footage shows the suffragette Emily Wilding Davison throwing herself under King George Vs horse at a famous race- Although the exhibition officially charts the years 1906 to 1914, graphic display boards outlining the bills of enfranchisement of 1918 and 1928, which gave the adult female populace of Britain the vote, show what was achieved. It demonstrates how advanced the suffragettes were in their thinking, in the marketing of their campaign, and in their work as shrewd and skilful image-builders. It also conveys a sense of the energy and ability the suffragettes brought to their fight for freedom and equality. And it illustrates the intelligence employed by women who were at that time deemed by several politicians to have brains too small to know how to vote.", "hypothesis": "The Museum of London exhibition includes some of the goods sold by the movement.", "gold_label": "entailment"}
{"uid": "id_386", "premise": "The name is a reference to the colour scheme that the Womens Social and Political Union (WSPU) created to give the movement a uniform, nationwide image. By doing so, it became one of the first groups to project a corporate identity, and it is this advanced marketing strategy, along with the other organisational and commercial achievements of the WSPU, to which the exhibition is devoted. The suffragette movement, which campaigned for votes for women in the early twentieth century, is most commonly associated with the Pankhurst family and militant acts of varying degrees of violence. The Museum of London has drawn on its archive collection to convey a fresh picture with its exhibition The Purple, White and Green: Suffragettes in London 1906- Formed in 1903 by the political campaigner Mrs Emmeline Pankhurst and her daughters Christabel and Sylvia, the WSPU began an educated campaign to put womens suffrage on the political agenda. New Zealand, Australia and parts of the United States had already enfranchised women, and growing numbers of their British counterparts wanted the same opportunity. With their slogan Deeds not words, and the introduction of the colour scheme, the WSPU soon brought the movement the cohesion and focus it had previously lacked. Membership grew rapidly as women deserted the many other, less directed, groups and joined it. By 1906 the WSPU headquarters, called the Womens Press Shop, had been established in Charing Cross Road and in spite of limited communications (no radio or television, and minimal use of the telephone) the message had spread around the country, with members and branch officers stretching to as far away as Scotland. The newspapers produced by the WSPU, first Votes for Women and later The Suffragette, played a vital role in this communication. Both were sold throughout the country and proved an invaluable way of informing members of meetings, marches, fund-raising events and the latest news and views on the movement. Equally importantly for a rising political group, the newspaper returned a profit. This was partly becauseReading advertising space was bought in the paper by large department stores such as Selfridges, and jewellers such as Mappin & Webb. These two, together with other like- minded commercial enterprises sympathetic to the cause, had quickly identified a direct way to reach a huge market of women, many with money to spend. The creation of the colour scheme provided another money-making opportunity which the WSPU was quick to exploit. The group began to sell playing cards, board games, Christmas and greeting cards, and countless other goods, all in the purple, white and green colours. In 1906 such merchandising of a corporate identity was a new marketing concept. But the paper and merchandising activities alone did not provide sufficient funds for the WSPU to meet organisational costs, so numerous other fund-raising activities combined to fill the coffers of the war chest. The most notable of these was the Womans Exhibition, which took place in 1909 in a Knightsbridge ice-skating rink, and in 10 days raised the equivalent of 250,000 today. The Museum of Londons exhibition is largely visual, with a huge number of items on show. Against a quiet background hum of street sounds, copies of The Suffragette, campaign banners and photographs are all on display, together with one of Mrs Pankhursts shoes and a number of purple, white and green trinkets. Photographs depict vivid scenes of a suffragettes life: WSPU members on a self- proclaimed monster march, wearing their official uniforms of a white frock decorated with purple, white and green accessories; women selling The Suffragette at street corners, or chalking up pavements with details of a forthcoming meeting. Windows display postcards and greeting cards designed by women artists for the movement, and the quality of the artwork indicates the wealth of resources the WSPU could call on from its talented members. Visitors can watch a short film made up of old newsreels and cinema material which clearly reveals the political mood of the day towards the suffragettes. The programme begins with a short film devised by the antis - those opposed to women having the vote -depicting a suffragette as a fierce harridan bullying her poor, abused husband. Original newsreel footage shows the suffragette Emily Wilding Davison throwing herself under King George Vs horse at a famous race- Although the exhibition officially charts the years 1906 to 1914, graphic display boards outlining the bills of enfranchisement of 1918 and 1928, which gave the adult female populace of Britain the vote, show what was achieved. It demonstrates how advanced the suffragettes were in their thinking, in the marketing of their campaign, and in their work as shrewd and skilful image-builders. It also conveys a sense of the energy and ability the suffragettes brought to their fight for freedom and equality. And it illustrates the intelligence employed by women who were at that time deemed by several politicians to have brains too small to know how to vote.", "hypothesis": "The opponents of the suffragettes made films opposing the movement.", "gold_label": "entailment"}
{"uid": "id_387", "premise": "The name is a reference to the colour scheme that the Womens Social and Political Union (WSPU) created to give the movement a uniform, nationwide image. By doing so, it became one of the first groups to project a corporate identity, and it is this advanced marketing strategy, along with the other organisational and commercial achievements of the WSPU, to which the exhibition is devoted. The suffragette movement, which campaigned for votes for women in the early twentieth century, is most commonly associated with the Pankhurst family and militant acts of varying degrees of violence. The Museum of London has drawn on its archive collection to convey a fresh picture with its exhibition The Purple, White and Green: Suffragettes in London 1906- Formed in 1903 by the political campaigner Mrs Emmeline Pankhurst and her daughters Christabel and Sylvia, the WSPU began an educated campaign to put womens suffrage on the political agenda. New Zealand, Australia and parts of the United States had already enfranchised women, and growing numbers of their British counterparts wanted the same opportunity. With their slogan Deeds not words, and the introduction of the colour scheme, the WSPU soon brought the movement the cohesion and focus it had previously lacked. Membership grew rapidly as women deserted the many other, less directed, groups and joined it. By 1906 the WSPU headquarters, called the Womens Press Shop, had been established in Charing Cross Road and in spite of limited communications (no radio or television, and minimal use of the telephone) the message had spread around the country, with members and branch officers stretching to as far away as Scotland. The newspapers produced by the WSPU, first Votes for Women and later The Suffragette, played a vital role in this communication. Both were sold throughout the country and proved an invaluable way of informing members of meetings, marches, fund-raising events and the latest news and views on the movement. Equally importantly for a rising political group, the newspaper returned a profit. This was partly becauseReading advertising space was bought in the paper by large department stores such as Selfridges, and jewellers such as Mappin & Webb. These two, together with other like- minded commercial enterprises sympathetic to the cause, had quickly identified a direct way to reach a huge market of women, many with money to spend. The creation of the colour scheme provided another money-making opportunity which the WSPU was quick to exploit. The group began to sell playing cards, board games, Christmas and greeting cards, and countless other goods, all in the purple, white and green colours. In 1906 such merchandising of a corporate identity was a new marketing concept. But the paper and merchandising activities alone did not provide sufficient funds for the WSPU to meet organisational costs, so numerous other fund-raising activities combined to fill the coffers of the war chest. The most notable of these was the Womans Exhibition, which took place in 1909 in a Knightsbridge ice-skating rink, and in 10 days raised the equivalent of 250,000 today. The Museum of Londons exhibition is largely visual, with a huge number of items on show. Against a quiet background hum of street sounds, copies of The Suffragette, campaign banners and photographs are all on display, together with one of Mrs Pankhursts shoes and a number of purple, white and green trinkets. Photographs depict vivid scenes of a suffragettes life: WSPU members on a self- proclaimed monster march, wearing their official uniforms of a white frock decorated with purple, white and green accessories; women selling The Suffragette at street corners, or chalking up pavements with details of a forthcoming meeting. Windows display postcards and greeting cards designed by women artists for the movement, and the quality of the artwork indicates the wealth of resources the WSPU could call on from its talented members. Visitors can watch a short film made up of old newsreels and cinema material which clearly reveals the political mood of the day towards the suffragettes. The programme begins with a short film devised by the antis - those opposed to women having the vote -depicting a suffragette as a fierce harridan bullying her poor, abused husband. Original newsreel footage shows the suffragette Emily Wilding Davison throwing herself under King George Vs horse at a famous race- Although the exhibition officially charts the years 1906 to 1914, graphic display boards outlining the bills of enfranchisement of 1918 and 1928, which gave the adult female populace of Britain the vote, show what was achieved. It demonstrates how advanced the suffragettes were in their thinking, in the marketing of their campaign, and in their work as shrewd and skilful image-builders. It also conveys a sense of the energy and ability the suffragettes brought to their fight for freedom and equality. And it illustrates the intelligence employed by women who were at that time deemed by several politicians to have brains too small to know how to vote.", "hypothesis": "The WSPUs newspapers were mainly devoted to society news and gossip.", "gold_label": "contradiction"}
{"uid": "id_388", "premise": "The name is a reference to the colour scheme that the Womens Social and Political Union (WSPU) created to give the movement a uniform, nationwide image. By doing so, it became one of the first groups to project a corporate identity, and it is this advanced marketing strategy, along with the other organisational and commercial achievements of the WSPU, to which the exhibition is devoted. The suffragette movement, which campaigned for votes for women in the early twentieth century, is most commonly associated with the Pankhurst family and militant acts of varying degrees of violence. The Museum of London has drawn on its archive collection to convey a fresh picture with its exhibition The Purple, White and Green: Suffragettes in London 1906- Formed in 1903 by the political campaigner Mrs Emmeline Pankhurst and her daughters Christabel and Sylvia, the WSPU began an educated campaign to put womens suffrage on the political agenda. New Zealand, Australia and parts of the United States had already enfranchised women, and growing numbers of their British counterparts wanted the same opportunity. With their slogan Deeds not words, and the introduction of the colour scheme, the WSPU soon brought the movement the cohesion and focus it had previously lacked. Membership grew rapidly as women deserted the many other, less directed, groups and joined it. By 1906 the WSPU headquarters, called the Womens Press Shop, had been established in Charing Cross Road and in spite of limited communications (no radio or television, and minimal use of the telephone) the message had spread around the country, with members and branch officers stretching to as far away as Scotland. The newspapers produced by the WSPU, first Votes for Women and later The Suffragette, played a vital role in this communication. Both were sold throughout the country and proved an invaluable way of informing members of meetings, marches, fund-raising events and the latest news and views on the movement. Equally importantly for a rising political group, the newspaper returned a profit. This was partly becauseReading advertising space was bought in the paper by large department stores such as Selfridges, and jewellers such as Mappin & Webb. These two, together with other like- minded commercial enterprises sympathetic to the cause, had quickly identified a direct way to reach a huge market of women, many with money to spend. The creation of the colour scheme provided another money-making opportunity which the WSPU was quick to exploit. The group began to sell playing cards, board games, Christmas and greeting cards, and countless other goods, all in the purple, white and green colours. In 1906 such merchandising of a corporate identity was a new marketing concept. But the paper and merchandising activities alone did not provide sufficient funds for the WSPU to meet organisational costs, so numerous other fund-raising activities combined to fill the coffers of the war chest. The most notable of these was the Womans Exhibition, which took place in 1909 in a Knightsbridge ice-skating rink, and in 10 days raised the equivalent of 250,000 today. The Museum of Londons exhibition is largely visual, with a huge number of items on show. Against a quiet background hum of street sounds, copies of The Suffragette, campaign banners and photographs are all on display, together with one of Mrs Pankhursts shoes and a number of purple, white and green trinkets. Photographs depict vivid scenes of a suffragettes life: WSPU members on a self- proclaimed monster march, wearing their official uniforms of a white frock decorated with purple, white and green accessories; women selling The Suffragette at street corners, or chalking up pavements with details of a forthcoming meeting. Windows display postcards and greeting cards designed by women artists for the movement, and the quality of the artwork indicates the wealth of resources the WSPU could call on from its talented members. Visitors can watch a short film made up of old newsreels and cinema material which clearly reveals the political mood of the day towards the suffragettes. The programme begins with a short film devised by the antis - those opposed to women having the vote -depicting a suffragette as a fierce harridan bullying her poor, abused husband. Original newsreel footage shows the suffragette Emily Wilding Davison throwing herself under King George Vs horse at a famous race- Although the exhibition officially charts the years 1906 to 1914, graphic display boards outlining the bills of enfranchisement of 1918 and 1928, which gave the adult female populace of Britain the vote, show what was achieved. It demonstrates how advanced the suffragettes were in their thinking, in the marketing of their campaign, and in their work as shrewd and skilful image-builders. It also conveys a sense of the energy and ability the suffragettes brought to their fight for freedom and equality. And it illustrates the intelligence employed by women who were at that time deemed by several politicians to have brains too small to know how to vote.", "hypothesis": "The Womans Exhibition in 1909 met with great opposition from Parliament.", "gold_label": "neutral"}
{"uid": "id_389", "premise": "The name is a reference to the colour scheme that the Womens Social and Political Union (WSPU) created to give the movement a uniform, nationwide image. By doing so, it became one of the first groups to project a corporate identity, and it is this advanced marketing strategy, along with the other organisational and commercial achievements of the WSPU, to which the exhibition is devoted. The suffragette movement, which campaigned for votes for women in the early twentieth century, is most commonly associated with the Pankhurst family and militant acts of varying degrees of violence. The Museum of London has drawn on its archive collection to convey a fresh picture with its exhibition The Purple, White and Green: Suffragettes in London 1906- Formed in 1903 by the political campaigner Mrs Emmeline Pankhurst and her daughters Christabel and Sylvia, the WSPU began an educated campaign to put womens suffrage on the political agenda. New Zealand, Australia and parts of the United States had already enfranchised women, and growing numbers of their British counterparts wanted the same opportunity. With their slogan Deeds not words, and the introduction of the colour scheme, the WSPU soon brought the movement the cohesion and focus it had previously lacked. Membership grew rapidly as women deserted the many other, less directed, groups and joined it. By 1906 the WSPU headquarters, called the Womens Press Shop, had been established in Charing Cross Road and in spite of limited communications (no radio or television, and minimal use of the telephone) the message had spread around the country, with members and branch officers stretching to as far away as Scotland. The newspapers produced by the WSPU, first Votes for Women and later The Suffragette, played a vital role in this communication. Both were sold throughout the country and proved an invaluable way of informing members of meetings, marches, fund-raising events and the latest news and views on the movement. Equally importantly for a rising political group, the newspaper returned a profit. This was partly becauseReading advertising space was bought in the paper by large department stores such as Selfridges, and jewellers such as Mappin & Webb. These two, together with other like- minded commercial enterprises sympathetic to the cause, had quickly identified a direct way to reach a huge market of women, many with money to spend. The creation of the colour scheme provided another money-making opportunity which the WSPU was quick to exploit. The group began to sell playing cards, board games, Christmas and greeting cards, and countless other goods, all in the purple, white and green colours. In 1906 such merchandising of a corporate identity was a new marketing concept. But the paper and merchandising activities alone did not provide sufficient funds for the WSPU to meet organisational costs, so numerous other fund-raising activities combined to fill the coffers of the war chest. The most notable of these was the Womans Exhibition, which took place in 1909 in a Knightsbridge ice-skating rink, and in 10 days raised the equivalent of 250,000 today. The Museum of Londons exhibition is largely visual, with a huge number of items on show. Against a quiet background hum of street sounds, copies of The Suffragette, campaign banners and photographs are all on display, together with one of Mrs Pankhursts shoes and a number of purple, white and green trinkets. Photographs depict vivid scenes of a suffragettes life: WSPU members on a self- proclaimed monster march, wearing their official uniforms of a white frock decorated with purple, white and green accessories; women selling The Suffragette at street corners, or chalking up pavements with details of a forthcoming meeting. Windows display postcards and greeting cards designed by women artists for the movement, and the quality of the artwork indicates the wealth of resources the WSPU could call on from its talented members. Visitors can watch a short film made up of old newsreels and cinema material which clearly reveals the political mood of the day towards the suffragettes. The programme begins with a short film devised by the antis - those opposed to women having the vote -depicting a suffragette as a fierce harridan bullying her poor, abused husband. Original newsreel footage shows the suffragette Emily Wilding Davison throwing herself under King George Vs horse at a famous race- Although the exhibition officially charts the years 1906 to 1914, graphic display boards outlining the bills of enfranchisement of 1918 and 1928, which gave the adult female populace of Britain the vote, show what was achieved. It demonstrates how advanced the suffragettes were in their thinking, in the marketing of their campaign, and in their work as shrewd and skilful image-builders. It also conveys a sense of the energy and ability the suffragettes brought to their fight for freedom and equality. And it illustrates the intelligence employed by women who were at that time deemed by several politicians to have brains too small to know how to vote.", "hypothesis": "In 1903 women in Australia were still not allowed to vote.", "gold_label": "contradiction"}
{"uid": "id_390", "premise": "The name is a reference to the colour scheme that the Womens Social and Political Union (WSPU) created to give the movement a uniform, nationwide image. By doing so, it became one of the first groups to project a corporate identity, and it is this advanced marketing strategy, along with the other organisational and commercial achievements of the WSPU, to which the exhibition is devoted. The suffragette movement, which campaigned for votes for women in the early twentieth century, is most commonly associated with the Pankhurst family and militant acts of varying degrees of violence. The Museum of London has drawn on its archive collection to convey a fresh picture with its exhibition The Purple, White and Green: Suffragettes in London 1906- Formed in 1903 by the political campaigner Mrs Emmeline Pankhurst and her daughters Christabel and Sylvia, the WSPU began an educated campaign to put womens suffrage on the political agenda. New Zealand, Australia and parts of the United States had already enfranchised women, and growing numbers of their British counterparts wanted the same opportunity. With their slogan Deeds not words, and the introduction of the colour scheme, the WSPU soon brought the movement the cohesion and focus it had previously lacked. Membership grew rapidly as women deserted the many other, less directed, groups and joined it. By 1906 the WSPU headquarters, called the Womens Press Shop, had been established in Charing Cross Road and in spite of limited communications (no radio or television, and minimal use of the telephone) the message had spread around the country, with members and branch officers stretching to as far away as Scotland. The newspapers produced by the WSPU, first Votes for Women and later The Suffragette, played a vital role in this communication. Both were sold throughout the country and proved an invaluable way of informing members of meetings, marches, fund-raising events and the latest news and views on the movement. Equally importantly for a rising political group, the newspaper returned a profit. This was partly becauseReading advertising space was bought in the paper by large department stores such as Selfridges, and jewellers such as Mappin & Webb. These two, together with other like- minded commercial enterprises sympathetic to the cause, had quickly identified a direct way to reach a huge market of women, many with money to spend. The creation of the colour scheme provided another money-making opportunity which the WSPU was quick to exploit. The group began to sell playing cards, board games, Christmas and greeting cards, and countless other goods, all in the purple, white and green colours. In 1906 such merchandising of a corporate identity was a new marketing concept. But the paper and merchandising activities alone did not provide sufficient funds for the WSPU to meet organisational costs, so numerous other fund-raising activities combined to fill the coffers of the war chest. The most notable of these was the Womans Exhibition, which took place in 1909 in a Knightsbridge ice-skating rink, and in 10 days raised the equivalent of 250,000 today. The Museum of Londons exhibition is largely visual, with a huge number of items on show. Against a quiet background hum of street sounds, copies of The Suffragette, campaign banners and photographs are all on display, together with one of Mrs Pankhursts shoes and a number of purple, white and green trinkets. Photographs depict vivid scenes of a suffragettes life: WSPU members on a self- proclaimed monster march, wearing their official uniforms of a white frock decorated with purple, white and green accessories; women selling The Suffragette at street corners, or chalking up pavements with details of a forthcoming meeting. Windows display postcards and greeting cards designed by women artists for the movement, and the quality of the artwork indicates the wealth of resources the WSPU could call on from its talented members. Visitors can watch a short film made up of old newsreels and cinema material which clearly reveals the political mood of the day towards the suffragettes. The programme begins with a short film devised by the antis - those opposed to women having the vote -depicting a suffragette as a fierce harridan bullying her poor, abused husband. Original newsreel footage shows the suffragette Emily Wilding Davison throwing herself under King George Vs horse at a famous race- Although the exhibition officially charts the years 1906 to 1914, graphic display boards outlining the bills of enfranchisement of 1918 and 1928, which gave the adult female populace of Britain the vote, show what was achieved. It demonstrates how advanced the suffragettes were in their thinking, in the marketing of their campaign, and in their work as shrewd and skilful image-builders. It also conveys a sense of the energy and ability the suffragettes brought to their fight for freedom and equality. And it illustrates the intelligence employed by women who were at that time deemed by several politicians to have brains too small to know how to vote.", "hypothesis": "The main organs of communication for the WSPU were its two newspapers.", "gold_label": "entailment"}
{"uid": "id_391", "premise": "The name is a reference to the colour scheme that the Womens Social and Political Union (WSPU) created to give the movement a uniform, nationwide image. By doing so, it became one of the first groups to project a corporate identity, and it is this advanced marketing strategy, along with the other organisational and commercial achievements of the WSPU, to which the exhibition is devoted. The suffragette movement, which campaigned for votes for women in the early twentieth century, is most commonly associated with the Pankhurst family and militant acts of varying degrees of violence. The Museum of London has drawn on its archive collection to convey a fresh picture with its exhibition The Purple, White and Green: Suffragettes in London 1906- Formed in 1903 by the political campaigner Mrs Emmeline Pankhurst and her daughters Christabel and Sylvia, the WSPU began an educated campaign to put womens suffrage on the political agenda. New Zealand, Australia and parts of the United States had already enfranchised women, and growing numbers of their British counterparts wanted the same opportunity. With their slogan Deeds not words, and the introduction of the colour scheme, the WSPU soon brought the movement the cohesion and focus it had previously lacked. Membership grew rapidly as women deserted the many other, less directed, groups and joined it. By 1906 the WSPU headquarters, called the Womens Press Shop, had been established in Charing Cross Road and in spite of limited communications (no radio or television, and minimal use of the telephone) the message had spread around the country, with members and branch officers stretching to as far away as Scotland. The newspapers produced by the WSPU, first Votes for Women and later The Suffragette, played a vital role in this communication. Both were sold throughout the country and proved an invaluable way of informing members of meetings, marches, fund-raising events and the latest news and views on the movement. Equally importantly for a rising political group, the newspaper returned a profit. This was partly becauseReading advertising space was bought in the paper by large department stores such as Selfridges, and jewellers such as Mappin & Webb. These two, together with other like- minded commercial enterprises sympathetic to the cause, had quickly identified a direct way to reach a huge market of women, many with money to spend. The creation of the colour scheme provided another money-making opportunity which the WSPU was quick to exploit. The group began to sell playing cards, board games, Christmas and greeting cards, and countless other goods, all in the purple, white and green colours. In 1906 such merchandising of a corporate identity was a new marketing concept. But the paper and merchandising activities alone did not provide sufficient funds for the WSPU to meet organisational costs, so numerous other fund-raising activities combined to fill the coffers of the war chest. The most notable of these was the Womans Exhibition, which took place in 1909 in a Knightsbridge ice-skating rink, and in 10 days raised the equivalent of 250,000 today. The Museum of Londons exhibition is largely visual, with a huge number of items on show. Against a quiet background hum of street sounds, copies of The Suffragette, campaign banners and photographs are all on display, together with one of Mrs Pankhursts shoes and a number of purple, white and green trinkets. Photographs depict vivid scenes of a suffragettes life: WSPU members on a self- proclaimed monster march, wearing their official uniforms of a white frock decorated with purple, white and green accessories; women selling The Suffragette at street corners, or chalking up pavements with details of a forthcoming meeting. Windows display postcards and greeting cards designed by women artists for the movement, and the quality of the artwork indicates the wealth of resources the WSPU could call on from its talented members. Visitors can watch a short film made up of old newsreels and cinema material which clearly reveals the political mood of the day towards the suffragettes. The programme begins with a short film devised by the antis - those opposed to women having the vote -depicting a suffragette as a fierce harridan bullying her poor, abused husband. Original newsreel footage shows the suffragette Emily Wilding Davison throwing herself under King George Vs horse at a famous race- Although the exhibition officially charts the years 1906 to 1914, graphic display boards outlining the bills of enfranchisement of 1918 and 1928, which gave the adult female populace of Britain the vote, show what was achieved. It demonstrates how advanced the suffragettes were in their thinking, in the marketing of their campaign, and in their work as shrewd and skilful image-builders. It also conveys a sense of the energy and ability the suffragettes brought to their fight for freedom and equality. And it illustrates the intelligence employed by women who were at that time deemed by several politicians to have brains too small to know how to vote.", "hypothesis": "The work of the WSPU was mainly confined to London and the south.", "gold_label": "contradiction"}
{"uid": "id_392", "premise": "The nature of modern humans Recent work in the field of evolutionary anthropology has made it possible to compare modern humans with other related species. Genetic analysis resulted in several new findings. First, despite the length of time for which Homo sapiens and Homo neanderthalensis had developed separately, (24).......................... did take place. Secondly, genes which evolved after modern humans split from Neanderthals are connected with cognitive ability and skeletal (25)......................... The potential for this line of research to shed light on the nature of modern humans was further strengthened when analysis of a (26)...................... led to the discovery of a new human species. The Future of fish The face of the ocean has changed completely since the first commercial fishers cast their nets and hooks over a thousand years ago. Fisheries intensified over the centuries, but even by the nineteenth century it was still felt, justifiably, that the plentiful resources of the sea were for the most part beyond the reach of fishing, and so there was little need to restrict fishing or create protected areas. The twentieth century heralded an escalation in fishing intensity that is unprecedented in the history of the oceans, and modern fishing technologies leave fish no place to hide. Today, the only refuges from fishing are those we deliberately create. Unhappily, the sea trails far behind the land in terms of the area and the quality of protection given. For centuries, as fishing and commerce have expanded, we have held onto the notion that the sea is different from the land. We still view it as a place where people and nations should be free to come and go at will, as well as somewhere that should be free for us to exploit. Perhaps this is why we have been so reluctant to protect the sea. On land, protected areas have proliferated as human populations have grown. Here, compared to the sea, we have made greater headway in our struggle to maintain the richness and variety of wildlife and landscape. Twelve percent of the worlds land is now contained in protected areas, whereas the corresponding figure for the sea is but three-fifths of one percent. Worse still, most marine protected areas allow some fishing to continue. Areas off-limits to all exploitation cover something like one five-thousandth of the total area of the worlds seas. Today, we are belatedly coming to realise that natural refuges from fishing have played a critical role in sustaining fisheries, and maintaining healthy and diverse marine ecosystems. This does not mean that marine reserves can rebuild fisheries on their own other management measures are also required for that. However, places that are off-limits to fishing constitute the last and most important part of our package of reform for fisheries management. They underpin and enhance all our other efforts. There are limits to protection though. Reserves cannot bring back what has died out. We can never resurrect globally extinct species, and restoring locally extinct animals may require reintroductions from elsewhere, if natural dispersal from remaining populations is insufficient. We are also seeing, in cases such as northern cod in Canada, that fishing can shift marine ecosystems into different states, where different mixes of species prevail. In many cases, these species are less desirable, since the prime fishing targets have gone or are much reduced in numbers, and changes may be difficult to reverse, even with a complete moratorium on fishing. The Mediterranean sailed by Ulysses, the legendary king of ancient Greece, supported abundant monk seals, loggerhead turtles and porpoises. Their disappearance through hunting and overfishing has totally restructured food webs, and recovery is likely to be much harder to achieve than their destruction was. This means that the sooner we act to protect marine life, the more certain will be our success. To some people, creating marine reserves is an admission of failure. According to their logic, reserves should not be necessary if we have done our work properly in managing the uses we make of the sea. Many fisheries managers are still wedded to the idea that one day their models will work, and politicians will listen to their advice. Just give the approach time, and success will be theirs. How much time have we got? This approach has been tried and refined for the last 50 years. There have been few successes which to feather the managers caps, but a growing litany of failure. The Common Fisheries Policy, the European Unions instrument for the management of fisheries and aquaculture, exemplifies the worst pitfalls: flawed models, flawed advice, watered-down recommendations from government bureaucrats and then the disregard of much of this advice by politicians. When it all went wrong, as it inevitably had to, Europe sent its boats to other countries in order to obtain fish for far less than they were actually worth. We are squandering the wealth of oceans. If we dont break out of this cycle of failure, humanity will lose a key source of protein, and much more besides. Disrupting natural ecosystem processes, such as water purification, nutrient cycling, and carbon storage, could have ramifications for human life itself. We can go a long way to avoiding this catastrophic mistake with simple common sense management. Marine reserves lie at the heart of the reform. But they will not be sufficient if they are implemented only here and there to shore up the crumbling edifice of the rational fisheries management envisioned by scientists in the 1940s and 1950s. They have to be placed centre stage as a fundamental underpinning for everything we do in the oceans. Reserves are a first resort, not a final resort when all else fails.", "hypothesis": "The re-introduction of certain mammals to the Mediterranean is a straightforward task.", "gold_label": "contradiction"}
{"uid": "id_393", "premise": "The nature of modern humans Recent work in the field of evolutionary anthropology has made it possible to compare modern humans with other related species. Genetic analysis resulted in several new findings. First, despite the length of time for which Homo sapiens and Homo neanderthalensis had developed separately, (24).......................... did take place. Secondly, genes which evolved after modern humans split from Neanderthals are connected with cognitive ability and skeletal (25)......................... The potential for this line of research to shed light on the nature of modern humans was further strengthened when analysis of a (26)...................... led to the discovery of a new human species. The Future of fish The face of the ocean has changed completely since the first commercial fishers cast their nets and hooks over a thousand years ago. Fisheries intensified over the centuries, but even by the nineteenth century it was still felt, justifiably, that the plentiful resources of the sea were for the most part beyond the reach of fishing, and so there was little need to restrict fishing or create protected areas. The twentieth century heralded an escalation in fishing intensity that is unprecedented in the history of the oceans, and modern fishing technologies leave fish no place to hide. Today, the only refuges from fishing are those we deliberately create. Unhappily, the sea trails far behind the land in terms of the area and the quality of protection given. For centuries, as fishing and commerce have expanded, we have held onto the notion that the sea is different from the land. We still view it as a place where people and nations should be free to come and go at will, as well as somewhere that should be free for us to exploit. Perhaps this is why we have been so reluctant to protect the sea. On land, protected areas have proliferated as human populations have grown. Here, compared to the sea, we have made greater headway in our struggle to maintain the richness and variety of wildlife and landscape. Twelve percent of the worlds land is now contained in protected areas, whereas the corresponding figure for the sea is but three-fifths of one percent. Worse still, most marine protected areas allow some fishing to continue. Areas off-limits to all exploitation cover something like one five-thousandth of the total area of the worlds seas. Today, we are belatedly coming to realise that natural refuges from fishing have played a critical role in sustaining fisheries, and maintaining healthy and diverse marine ecosystems. This does not mean that marine reserves can rebuild fisheries on their own other management measures are also required for that. However, places that are off-limits to fishing constitute the last and most important part of our package of reform for fisheries management. They underpin and enhance all our other efforts. There are limits to protection though. Reserves cannot bring back what has died out. We can never resurrect globally extinct species, and restoring locally extinct animals may require reintroductions from elsewhere, if natural dispersal from remaining populations is insufficient. We are also seeing, in cases such as northern cod in Canada, that fishing can shift marine ecosystems into different states, where different mixes of species prevail. In many cases, these species are less desirable, since the prime fishing targets have gone or are much reduced in numbers, and changes may be difficult to reverse, even with a complete moratorium on fishing. The Mediterranean sailed by Ulysses, the legendary king of ancient Greece, supported abundant monk seals, loggerhead turtles and porpoises. Their disappearance through hunting and overfishing has totally restructured food webs, and recovery is likely to be much harder to achieve than their destruction was. This means that the sooner we act to protect marine life, the more certain will be our success. To some people, creating marine reserves is an admission of failure. According to their logic, reserves should not be necessary if we have done our work properly in managing the uses we make of the sea. Many fisheries managers are still wedded to the idea that one day their models will work, and politicians will listen to their advice. Just give the approach time, and success will be theirs. How much time have we got? This approach has been tried and refined for the last 50 years. There have been few successes which to feather the managers caps, but a growing litany of failure. The Common Fisheries Policy, the European Unions instrument for the management of fisheries and aquaculture, exemplifies the worst pitfalls: flawed models, flawed advice, watered-down recommendations from government bureaucrats and then the disregard of much of this advice by politicians. When it all went wrong, as it inevitably had to, Europe sent its boats to other countries in order to obtain fish for far less than they were actually worth. We are squandering the wealth of oceans. If we dont break out of this cycle of failure, humanity will lose a key source of protein, and much more besides. Disrupting natural ecosystem processes, such as water purification, nutrient cycling, and carbon storage, could have ramifications for human life itself. We can go a long way to avoiding this catastrophic mistake with simple common sense management. Marine reserves lie at the heart of the reform. But they will not be sufficient if they are implemented only here and there to shore up the crumbling edifice of the rational fisheries management envisioned by scientists in the 1940s and 1950s. They have to be placed centre stage as a fundamental underpinning for everything we do in the oceans. Reserves are a first resort, not a final resort when all else fails.", "hypothesis": "People should be encouraged to reduce the amount of fish they eat.", "gold_label": "neutral"}
{"uid": "id_394", "premise": "The nature of modern humans Recent work in the field of evolutionary anthropology has made it possible to compare modern humans with other related species. Genetic analysis resulted in several new findings. First, despite the length of time for which Homo sapiens and Homo neanderthalensis had developed separately, (24).......................... did take place. Secondly, genes which evolved after modern humans split from Neanderthals are connected with cognitive ability and skeletal (25)......................... The potential for this line of research to shed light on the nature of modern humans was further strengthened when analysis of a (26)...................... led to the discovery of a new human species. The Future of fish The face of the ocean has changed completely since the first commercial fishers cast their nets and hooks over a thousand years ago. Fisheries intensified over the centuries, but even by the nineteenth century it was still felt, justifiably, that the plentiful resources of the sea were for the most part beyond the reach of fishing, and so there was little need to restrict fishing or create protected areas. The twentieth century heralded an escalation in fishing intensity that is unprecedented in the history of the oceans, and modern fishing technologies leave fish no place to hide. Today, the only refuges from fishing are those we deliberately create. Unhappily, the sea trails far behind the land in terms of the area and the quality of protection given. For centuries, as fishing and commerce have expanded, we have held onto the notion that the sea is different from the land. We still view it as a place where people and nations should be free to come and go at will, as well as somewhere that should be free for us to exploit. Perhaps this is why we have been so reluctant to protect the sea. On land, protected areas have proliferated as human populations have grown. Here, compared to the sea, we have made greater headway in our struggle to maintain the richness and variety of wildlife and landscape. Twelve percent of the worlds land is now contained in protected areas, whereas the corresponding figure for the sea is but three-fifths of one percent. Worse still, most marine protected areas allow some fishing to continue. Areas off-limits to all exploitation cover something like one five-thousandth of the total area of the worlds seas. Today, we are belatedly coming to realise that natural refuges from fishing have played a critical role in sustaining fisheries, and maintaining healthy and diverse marine ecosystems. This does not mean that marine reserves can rebuild fisheries on their own other management measures are also required for that. However, places that are off-limits to fishing constitute the last and most important part of our package of reform for fisheries management. They underpin and enhance all our other efforts. There are limits to protection though. Reserves cannot bring back what has died out. We can never resurrect globally extinct species, and restoring locally extinct animals may require reintroductions from elsewhere, if natural dispersal from remaining populations is insufficient. We are also seeing, in cases such as northern cod in Canada, that fishing can shift marine ecosystems into different states, where different mixes of species prevail. In many cases, these species are less desirable, since the prime fishing targets have gone or are much reduced in numbers, and changes may be difficult to reverse, even with a complete moratorium on fishing. The Mediterranean sailed by Ulysses, the legendary king of ancient Greece, supported abundant monk seals, loggerhead turtles and porpoises. Their disappearance through hunting and overfishing has totally restructured food webs, and recovery is likely to be much harder to achieve than their destruction was. This means that the sooner we act to protect marine life, the more certain will be our success. To some people, creating marine reserves is an admission of failure. According to their logic, reserves should not be necessary if we have done our work properly in managing the uses we make of the sea. Many fisheries managers are still wedded to the idea that one day their models will work, and politicians will listen to their advice. Just give the approach time, and success will be theirs. How much time have we got? This approach has been tried and refined for the last 50 years. There have been few successes which to feather the managers caps, but a growing litany of failure. The Common Fisheries Policy, the European Unions instrument for the management of fisheries and aquaculture, exemplifies the worst pitfalls: flawed models, flawed advice, watered-down recommendations from government bureaucrats and then the disregard of much of this advice by politicians. When it all went wrong, as it inevitably had to, Europe sent its boats to other countries in order to obtain fish for far less than they were actually worth. We are squandering the wealth of oceans. If we dont break out of this cycle of failure, humanity will lose a key source of protein, and much more besides. Disrupting natural ecosystem processes, such as water purification, nutrient cycling, and carbon storage, could have ramifications for human life itself. We can go a long way to avoiding this catastrophic mistake with simple common sense management. Marine reserves lie at the heart of the reform. But they will not be sufficient if they are implemented only here and there to shore up the crumbling edifice of the rational fisheries management envisioned by scientists in the 1940s and 1950s. They have to be placed centre stage as a fundamental underpinning for everything we do in the oceans. Reserves are a first resort, not a final resort when all else fails.", "hypothesis": "Sea fishing is now completely banned in the majority of protected areas.", "gold_label": "contradiction"}
{"uid": "id_395", "premise": "The nature of modern humans Recent work in the field of evolutionary anthropology has made it possible to compare modern humans with other related species. Genetic analysis resulted in several new findings. First, despite the length of time for which Homo sapiens and Homo neanderthalensis had developed separately, (24).......................... did take place. Secondly, genes which evolved after modern humans split from Neanderthals are connected with cognitive ability and skeletal (25)......................... The potential for this line of research to shed light on the nature of modern humans was further strengthened when analysis of a (26)...................... led to the discovery of a new human species. The Future of fish The face of the ocean has changed completely since the first commercial fishers cast their nets and hooks over a thousand years ago. Fisheries intensified over the centuries, but even by the nineteenth century it was still felt, justifiably, that the plentiful resources of the sea were for the most part beyond the reach of fishing, and so there was little need to restrict fishing or create protected areas. The twentieth century heralded an escalation in fishing intensity that is unprecedented in the history of the oceans, and modern fishing technologies leave fish no place to hide. Today, the only refuges from fishing are those we deliberately create. Unhappily, the sea trails far behind the land in terms of the area and the quality of protection given. For centuries, as fishing and commerce have expanded, we have held onto the notion that the sea is different from the land. We still view it as a place where people and nations should be free to come and go at will, as well as somewhere that should be free for us to exploit. Perhaps this is why we have been so reluctant to protect the sea. On land, protected areas have proliferated as human populations have grown. Here, compared to the sea, we have made greater headway in our struggle to maintain the richness and variety of wildlife and landscape. Twelve percent of the worlds land is now contained in protected areas, whereas the corresponding figure for the sea is but three-fifths of one percent. Worse still, most marine protected areas allow some fishing to continue. Areas off-limits to all exploitation cover something like one five-thousandth of the total area of the worlds seas. Today, we are belatedly coming to realise that natural refuges from fishing have played a critical role in sustaining fisheries, and maintaining healthy and diverse marine ecosystems. This does not mean that marine reserves can rebuild fisheries on their own other management measures are also required for that. However, places that are off-limits to fishing constitute the last and most important part of our package of reform for fisheries management. They underpin and enhance all our other efforts. There are limits to protection though. Reserves cannot bring back what has died out. We can never resurrect globally extinct species, and restoring locally extinct animals may require reintroductions from elsewhere, if natural dispersal from remaining populations is insufficient. We are also seeing, in cases such as northern cod in Canada, that fishing can shift marine ecosystems into different states, where different mixes of species prevail. In many cases, these species are less desirable, since the prime fishing targets have gone or are much reduced in numbers, and changes may be difficult to reverse, even with a complete moratorium on fishing. The Mediterranean sailed by Ulysses, the legendary king of ancient Greece, supported abundant monk seals, loggerhead turtles and porpoises. Their disappearance through hunting and overfishing has totally restructured food webs, and recovery is likely to be much harder to achieve than their destruction was. This means that the sooner we act to protect marine life, the more certain will be our success. To some people, creating marine reserves is an admission of failure. According to their logic, reserves should not be necessary if we have done our work properly in managing the uses we make of the sea. Many fisheries managers are still wedded to the idea that one day their models will work, and politicians will listen to their advice. Just give the approach time, and success will be theirs. How much time have we got? This approach has been tried and refined for the last 50 years. There have been few successes which to feather the managers caps, but a growing litany of failure. The Common Fisheries Policy, the European Unions instrument for the management of fisheries and aquaculture, exemplifies the worst pitfalls: flawed models, flawed advice, watered-down recommendations from government bureaucrats and then the disregard of much of this advice by politicians. When it all went wrong, as it inevitably had to, Europe sent its boats to other countries in order to obtain fish for far less than they were actually worth. We are squandering the wealth of oceans. If we dont break out of this cycle of failure, humanity will lose a key source of protein, and much more besides. Disrupting natural ecosystem processes, such as water purification, nutrient cycling, and carbon storage, could have ramifications for human life itself. We can go a long way to avoiding this catastrophic mistake with simple common sense management. Marine reserves lie at the heart of the reform. But they will not be sufficient if they are implemented only here and there to shore up the crumbling edifice of the rational fisheries management envisioned by scientists in the 1940s and 1950s. They have to be placed centre stage as a fundamental underpinning for everything we do in the oceans. Reserves are a first resort, not a final resort when all else fails.", "hypothesis": "In general, open access to the oceans is still regarded as desirable.", "gold_label": "entailment"}
{"uid": "id_396", "premise": "The nature of modern humans Recent work in the field of evolutionary anthropology has made it possible to compare modern humans with other related species. Genetic analysis resulted in several new findings. First, despite the length of time for which Homo sapiens and Homo neanderthalensis had developed separately, (24).......................... did take place. Secondly, genes which evolved after modern humans split from Neanderthals are connected with cognitive ability and skeletal (25)......................... The potential for this line of research to shed light on the nature of modern humans was further strengthened when analysis of a (26)...................... led to the discovery of a new human species. The Future of fish The face of the ocean has changed completely since the first commercial fishers cast their nets and hooks over a thousand years ago. Fisheries intensified over the centuries, but even by the nineteenth century it was still felt, justifiably, that the plentiful resources of the sea were for the most part beyond the reach of fishing, and so there was little need to restrict fishing or create protected areas. The twentieth century heralded an escalation in fishing intensity that is unprecedented in the history of the oceans, and modern fishing technologies leave fish no place to hide. Today, the only refuges from fishing are those we deliberately create. Unhappily, the sea trails far behind the land in terms of the area and the quality of protection given. For centuries, as fishing and commerce have expanded, we have held onto the notion that the sea is different from the land. We still view it as a place where people and nations should be free to come and go at will, as well as somewhere that should be free for us to exploit. Perhaps this is why we have been so reluctant to protect the sea. On land, protected areas have proliferated as human populations have grown. Here, compared to the sea, we have made greater headway in our struggle to maintain the richness and variety of wildlife and landscape. Twelve percent of the worlds land is now contained in protected areas, whereas the corresponding figure for the sea is but three-fifths of one percent. Worse still, most marine protected areas allow some fishing to continue. Areas off-limits to all exploitation cover something like one five-thousandth of the total area of the worlds seas. Today, we are belatedly coming to realise that natural refuges from fishing have played a critical role in sustaining fisheries, and maintaining healthy and diverse marine ecosystems. This does not mean that marine reserves can rebuild fisheries on their own other management measures are also required for that. However, places that are off-limits to fishing constitute the last and most important part of our package of reform for fisheries management. They underpin and enhance all our other efforts. There are limits to protection though. Reserves cannot bring back what has died out. We can never resurrect globally extinct species, and restoring locally extinct animals may require reintroductions from elsewhere, if natural dispersal from remaining populations is insufficient. We are also seeing, in cases such as northern cod in Canada, that fishing can shift marine ecosystems into different states, where different mixes of species prevail. In many cases, these species are less desirable, since the prime fishing targets have gone or are much reduced in numbers, and changes may be difficult to reverse, even with a complete moratorium on fishing. The Mediterranean sailed by Ulysses, the legendary king of ancient Greece, supported abundant monk seals, loggerhead turtles and porpoises. Their disappearance through hunting and overfishing has totally restructured food webs, and recovery is likely to be much harder to achieve than their destruction was. This means that the sooner we act to protect marine life, the more certain will be our success. To some people, creating marine reserves is an admission of failure. According to their logic, reserves should not be necessary if we have done our work properly in managing the uses we make of the sea. Many fisheries managers are still wedded to the idea that one day their models will work, and politicians will listen to their advice. Just give the approach time, and success will be theirs. How much time have we got? This approach has been tried and refined for the last 50 years. There have been few successes which to feather the managers caps, but a growing litany of failure. The Common Fisheries Policy, the European Unions instrument for the management of fisheries and aquaculture, exemplifies the worst pitfalls: flawed models, flawed advice, watered-down recommendations from government bureaucrats and then the disregard of much of this advice by politicians. When it all went wrong, as it inevitably had to, Europe sent its boats to other countries in order to obtain fish for far less than they were actually worth. We are squandering the wealth of oceans. If we dont break out of this cycle of failure, humanity will lose a key source of protein, and much more besides. Disrupting natural ecosystem processes, such as water purification, nutrient cycling, and carbon storage, could have ramifications for human life itself. We can go a long way to avoiding this catastrophic mistake with simple common sense management. Marine reserves lie at the heart of the reform. But they will not be sufficient if they are implemented only here and there to shore up the crumbling edifice of the rational fisheries management envisioned by scientists in the 1940s and 1950s. They have to be placed centre stage as a fundamental underpinning for everything we do in the oceans. Reserves are a first resort, not a final resort when all else fails.", "hypothesis": "It is more than a thousand years since people started to catch fish for commercial use.", "gold_label": "entailment"}
{"uid": "id_397", "premise": "The need for a satisfactory education is more important than ever before. Nowadays, without a qualification from a reputable school or university, the odds of landing that plum job advertised in the paper are considerably shortened. Moreover, one's present level of education could fall well short of future career requirements. It is no secret that competition is the driving force behind the need to obtain increasingly higher qualifications. In the majority of cases, the urge to upgrade is no longer the result of an insatiable thirst for knowledge. The pressure is coming from within the workplace to compete with ever more qualified job applicants, and in many occupations one must now battle with colleagues in the reshuffle for the position one already holds. Striving to become better educated is hardly a new concept. Wealthy parents have always been willing to spend the vast amounts of extra money necessary to send their children to schools with a perceived educational edge. Working adults have long attended night schools and refresher courses. Competition for employment has been around since the curse of working for a living began. Is the present situation so very different to that of the past? The difference now is that the push is universal and from without as well as within. A student at secondary school receiving low grades is no longer as easily accepted by his or her peers as was once the case. Similarly, in the workplace, unless employees are engaged in part-time study, they may be frowned upon by their employers and peers and have difficulty even standing still. In fact, in these cases, the expectation is for careers to go backwards and earning capacity to take an appreciable nosedive. At first glance, the situation would seem to be laudable; a positive response to the exhortation by a former Prime Minister, Bob Hawke, for australia to become the `clever country'. Yet there are serious ramifications according to at least one educational psychologist. Dr Brendan Gatsby has caused some controversy in academic circles by suggesting that a bias towards what he terms `paper' excellence might cause more problems than it is supposed to solve. Gatsby raises a number of issues that affect the individual as well as society in general. Firstly, he believes the extra workload involved is resulting in abnormally high stress levels in both students at secondary school and adults studying after working hours. Secondly, skills which might be more relevant to the undertaking of a sought_after job are being overlooked by employers interviewing candidates without qualifications on paper. These two areas of concern for the individual are causing physical and emotional stress respectively. Gatsby also argues that there are attitudinal changes within society to the exalted role education now plays in determining how the spoils of working life are distributed. Individuals of all ages are being driven by social pressures to achieve academic success solely for monetary considerations instead of for the joy of enlightenment. There is the danger that some universities are becoming degree factories with an attendant drop in standards. Furthermore, our education system may be rewarding doggedness above creativity; the very thing Australians have been encouraged to avoid. But the most undesirable effect of this academic paper chase, Gatsby says, is the disadvantage that `user pays' higher education confers on the poor, who invariably lose out to the more financially favoured. Naturally, although there is agreement that learning can cause stress, Gatsby's comments regarding university standards have been roundly criticised as alarmist by most educationists who point out that, by any standard of measurement, Australia's education system overall, at both secondary and tertiary levels, is equal to that of any in the world.", "hypothesis": "Some parents spend extra on their children's education because of the prestige attached to certain schools", "gold_label": "neutral"}
{"uid": "id_398", "premise": "The need for a satisfactory education is more important than ever before. Nowadays, without a qualification from a reputable school or university, the odds of landing that plum job advertised in the paper are considerably shortened. Moreover, one's present level of education could fall well short of future career requirements. It is no secret that competition is the driving force behind the need to obtain increasingly higher qualifications. In the majority of cases, the urge to upgrade is no longer the result of an insatiable thirst for knowledge. The pressure is coming from within the workplace to compete with ever more qualified job applicants, and in many occupations one must now battle with colleagues in the reshuffle for the position one already holds. Striving to become better educated is hardly a new concept. Wealthy parents have always been willing to spend the vast amounts of extra money necessary to send their children to schools with a perceived educational edge. Working adults have long attended night schools and refresher courses. Competition for employment has been around since the curse of working for a living began. Is the present situation so very different to that of the past? The difference now is that the push is universal and from without as well as within. A student at secondary school receiving low grades is no longer as easily accepted by his or her peers as was once the case. Similarly, in the workplace, unless employees are engaged in part-time study, they may be frowned upon by their employers and peers and have difficulty even standing still. In fact, in these cases, the expectation is for careers to go backwards and earning capacity to take an appreciable nosedive. At first glance, the situation would seem to be laudable; a positive response to the exhortation by a former Prime Minister, Bob Hawke, for australia to become the `clever country'. Yet there are serious ramifications according to at least one educational psychologist. Dr Brendan Gatsby has caused some controversy in academic circles by suggesting that a bias towards what he terms `paper' excellence might cause more problems than it is supposed to solve. Gatsby raises a number of issues that affect the individual as well as society in general. Firstly, he believes the extra workload involved is resulting in abnormally high stress levels in both students at secondary school and adults studying after working hours. Secondly, skills which might be more relevant to the undertaking of a sought_after job are being overlooked by employers interviewing candidates without qualifications on paper. These two areas of concern for the individual are causing physical and emotional stress respectively. Gatsby also argues that there are attitudinal changes within society to the exalted role education now plays in determining how the spoils of working life are distributed. Individuals of all ages are being driven by social pressures to achieve academic success solely for monetary considerations instead of for the joy of enlightenment. There is the danger that some universities are becoming degree factories with an attendant drop in standards. Furthermore, our education system may be rewarding doggedness above creativity; the very thing Australians have been encouraged to avoid. But the most undesirable effect of this academic paper chase, Gatsby says, is the disadvantage that `user pays' higher education confers on the poor, who invariably lose out to the more financially favoured. Naturally, although there is agreement that learning can cause stress, Gatsby's comments regarding university standards have been roundly criticised as alarmist by most educationists who point out that, by any standard of measurement, Australia's education system overall, at both secondary and tertiary levels, is equal to that of any in the world.", "hypothesis": "Employees who do not undertake extra study may find their salary decreased by employers.", "gold_label": "neutral"}
{"uid": "id_399", "premise": "The need for a satisfactory education is more important than ever before. Nowadays, without a qualification from a reputable school or university, the odds of landing that plum job advertised in the paper are considerably shortened. Moreover, one's present level of education could fall well short of future career requirements. It is no secret that competition is the driving force behind the need to obtain increasingly higher qualifications. In the majority of cases, the urge to upgrade is no longer the result of an insatiable thirst for knowledge. The pressure is coming from within the workplace to compete with ever more qualified job applicants, and in many occupations one must now battle with colleagues in the reshuffle for the position one already holds. Striving to become better educated is hardly a new concept. Wealthy parents have always been willing to spend the vast amounts of extra money necessary to send their children to schools with a perceived educational edge. Working adults have long attended night schools and refresher courses. Competition for employment has been around since the curse of working for a living began. Is the present situation so very different to that of the past? The difference now is that the push is universal and from without as well as within. A student at secondary school receiving low grades is no longer as easily accepted by his or her peers as was once the case. Similarly, in the workplace, unless employees are engaged in part-time study, they may be frowned upon by their employers and peers and have difficulty even standing still. In fact, in these cases, the expectation is for careers to go backwards and earning capacity to take an appreciable nosedive. At first glance, the situation would seem to be laudable; a positive response to the exhortation by a former Prime Minister, Bob Hawke, for australia to become the `clever country'. Yet there are serious ramifications according to at least one educational psychologist. Dr Brendan Gatsby has caused some controversy in academic circles by suggesting that a bias towards what he terms `paper' excellence might cause more problems than it is supposed to solve. Gatsby raises a number of issues that affect the individual as well as society in general. Firstly, he believes the extra workload involved is resulting in abnormally high stress levels in both students at secondary school and adults studying after working hours. Secondly, skills which might be more relevant to the undertaking of a sought_after job are being overlooked by employers interviewing candidates without qualifications on paper. These two areas of concern for the individual are causing physical and emotional stress respectively. Gatsby also argues that there are attitudinal changes within society to the exalted role education now plays in determining how the spoils of working life are distributed. Individuals of all ages are being driven by social pressures to achieve academic success solely for monetary considerations instead of for the joy of enlightenment. There is the danger that some universities are becoming degree factories with an attendant drop in standards. Furthermore, our education system may be rewarding doggedness above creativity; the very thing Australians have been encouraged to avoid. But the most undesirable effect of this academic paper chase, Gatsby says, is the disadvantage that `user pays' higher education confers on the poor, who invariably lose out to the more financially favoured. Naturally, although there is agreement that learning can cause stress, Gatsby's comments regarding university standards have been roundly criticised as alarmist by most educationists who point out that, by any standard of measurement, Australia's education system overall, at both secondary and tertiary levels, is equal to that of any in the world.", "hypothesis": "According to the text, students who performed bally at school used to be accepted by their classmates.", "gold_label": "entailment"}
{"uid": "id_400", "premise": "The need for a satisfactory education is more important than ever before. Nowadays, without a qualification from a reputable school or university, the odds of landing that plum job advertised in the paper are considerably shortened. Moreover, one's present level of education could fall well short of future career requirements. It is no secret that competition is the driving force behind the need to obtain increasingly higher qualifications. In the majority of cases, the urge to upgrade is no longer the result of an insatiable thirst for knowledge. The pressure is coming from within the workplace to compete with ever more qualified job applicants, and in many occupations one must now battle with colleagues in the reshuffle for the position one already holds. Striving to become better educated is hardly a new concept. Wealthy parents have always been willing to spend the vast amounts of extra money necessary to send their children to schools with a perceived educational edge. Working adults have long attended night schools and refresher courses. Competition for employment has been around since the curse of working for a living began. Is the present situation so very different to that of the past? The difference now is that the push is universal and from without as well as within. A student at secondary school receiving low grades is no longer as easily accepted by his or her peers as was once the case. Similarly, in the workplace, unless employees are engaged in part-time study, they may be frowned upon by their employers and peers and have difficulty even standing still. In fact, in these cases, the expectation is for careers to go backwards and earning capacity to take an appreciable nosedive. At first glance, the situation would seem to be laudable; a positive response to the exhortation by a former Prime Minister, Bob Hawke, for australia to become the `clever country'. Yet there are serious ramifications according to at least one educational psychologist. Dr Brendan Gatsby has caused some controversy in academic circles by suggesting that a bias towards what he terms `paper' excellence might cause more problems than it is supposed to solve. Gatsby raises a number of issues that affect the individual as well as society in general. Firstly, he believes the extra workload involved is resulting in abnormally high stress levels in both students at secondary school and adults studying after working hours. Secondly, skills which might be more relevant to the undertaking of a sought_after job are being overlooked by employers interviewing candidates without qualifications on paper. These two areas of concern for the individual are causing physical and emotional stress respectively. Gatsby also argues that there are attitudinal changes within society to the exalted role education now plays in determining how the spoils of working life are distributed. Individuals of all ages are being driven by social pressures to achieve academic success solely for monetary considerations instead of for the joy of enlightenment. There is the danger that some universities are becoming degree factories with an attendant drop in standards. Furthermore, our education system may be rewarding doggedness above creativity; the very thing Australians have been encouraged to avoid. But the most undesirable effect of this academic paper chase, Gatsby says, is the disadvantage that `user pays' higher education confers on the poor, who invariably lose out to the more financially favoured. Naturally, although there is agreement that learning can cause stress, Gatsby's comments regarding university standards have been roundly criticised as alarmist by most educationists who point out that, by any standard of measurement, Australia's education system overall, at both secondary and tertiary levels, is equal to that of any in the world.", "hypothesis": "Australians appear to have responded to the call by a former Prime Minister to become better qualified.", "gold_label": "entailment"}
{"uid": "id_401", "premise": "The need for a satisfactory education is more important than ever before. Nowadays, without a qualification from a reputable school or university, the odds of landing that plum job advertised in the paper are considerably shortened. Moreover, one's present level of education could fall well short of future career requirements. It is no secret that competition is the driving force behind the need to obtain increasingly higher qualifications. In the majority of cases, the urge to upgrade is no longer the result of an insatiable thirst for knowledge. The pressure is coming from within the workplace to compete with ever more qualified job applicants, and in many occupations one must now battle with colleagues in the reshuffle for the position one already holds. Striving to become better educated is hardly a new concept. Wealthy parents have always been willing to spend the vast amounts of extra money necessary to send their children to schools with a perceived educational edge. Working adults have long attended night schools and refresher courses. Competition for employment has been around since the curse of working for a living began. Is the present situation so very different to that of the past? The difference now is that the push is universal and from without as well as within. A student at secondary school receiving low grades is no longer as easily accepted by his or her peers as was once the case. Similarly, in the workplace, unless employees are engaged in part-time study, they may be frowned upon by their employers and peers and have difficulty even standing still. In fact, in these cases, the expectation is for careers to go backwards and earning capacity to take an appreciable nosedive. At first glance, the situation would seem to be laudable; a positive response to the exhortation by a former Prime Minister, Bob Hawke, for australia to become the `clever country'. Yet there are serious ramifications according to at least one educational psychologist. Dr Brendan Gatsby has caused some controversy in academic circles by suggesting that a bias towards what he terms `paper' excellence might cause more problems than it is supposed to solve. Gatsby raises a number of issues that affect the individual as well as society in general. Firstly, he believes the extra workload involved is resulting in abnormally high stress levels in both students at secondary school and adults studying after working hours. Secondly, skills which might be more relevant to the undertaking of a sought_after job are being overlooked by employers interviewing candidates without qualifications on paper. These two areas of concern for the individual are causing physical and emotional stress respectively. Gatsby also argues that there are attitudinal changes within society to the exalted role education now plays in determining how the spoils of working life are distributed. Individuals of all ages are being driven by social pressures to achieve academic success solely for monetary considerations instead of for the joy of enlightenment. There is the danger that some universities are becoming degree factories with an attendant drop in standards. Furthermore, our education system may be rewarding doggedness above creativity; the very thing Australians have been encouraged to avoid. But the most undesirable effect of this academic paper chase, Gatsby says, is the disadvantage that `user pays' higher education confers on the poor, who invariably lose out to the more financially favoured. Naturally, although there is agreement that learning can cause stress, Gatsby's comments regarding university standards have been roundly criticised as alarmist by most educationists who point out that, by any standard of measurement, Australia's education system overall, at both secondary and tertiary levels, is equal to that of any in the world.", "hypothesis": "In some jobs, the position you hold must be reapplied for.", "gold_label": "entailment"}
{"uid": "id_402", "premise": "The need for a satisfactory education is more important than ever before. Nowadays, without a qualification from a reputable school or university, the odds of landing that plum job advertised in the paper are considerably shortened. Moreover, one's present level of education could fall well short of future career requirements. It is no secret that competition is the driving force behind the need to obtain increasingly higher qualifications. In the majority of cases, the urge to upgrade is no longer the result of an insatiable thirst for knowledge. The pressure is coming from within the workplace to compete with ever more qualified job applicants, and in many occupations one must now battle with colleagues in the reshuffle for the position one already holds. Striving to become better educated is hardly a new concept. Wealthy parents have always been willing to spend the vast amounts of extra money necessary to send their children to schools with a perceived educational edge. Working adults have long attended night schools and refresher courses. Competition for employment has been around since the curse of working for a living began. Is the present situation so very different to that of the past? The difference now is that the push is universal and from without as well as within. A student at secondary school receiving low grades is no longer as easily accepted by his or her peers as was once the case. Similarly, in the workplace, unless employees are engaged in part-time study, they may be frowned upon by their employers and peers and have difficulty even standing still. In fact, in these cases, the expectation is for careers to go backwards and earning capacity to take an appreciable nosedive. At first glance, the situation would seem to be laudable; a positive response to the exhortation by a former Prime Minister, Bob Hawke, for australia to become the `clever country'. Yet there are serious ramifications according to at least one educational psychologist. Dr Brendan Gatsby has caused some controversy in academic circles by suggesting that a bias towards what he terms `paper' excellence might cause more problems than it is supposed to solve. Gatsby raises a number of issues that affect the individual as well as society in general. Firstly, he believes the extra workload involved is resulting in abnormally high stress levels in both students at secondary school and adults studying after working hours. Secondly, skills which might be more relevant to the undertaking of a sought_after job are being overlooked by employers interviewing candidates without qualifications on paper. These two areas of concern for the individual are causing physical and emotional stress respectively. Gatsby also argues that there are attitudinal changes within society to the exalted role education now plays in determining how the spoils of working life are distributed. Individuals of all ages are being driven by social pressures to achieve academic success solely for monetary considerations instead of for the joy of enlightenment. There is the danger that some universities are becoming degree factories with an attendant drop in standards. Furthermore, our education system may be rewarding doggedness above creativity; the very thing Australians have been encouraged to avoid. But the most undesirable effect of this academic paper chase, Gatsby says, is the disadvantage that `user pays' higher education confers on the poor, who invariably lose out to the more financially favoured. Naturally, although there is agreement that learning can cause stress, Gatsby's comments regarding university standards have been roundly criticised as alarmist by most educationists who point out that, by any standard of measurement, Australia's education system overall, at both secondary and tertiary levels, is equal to that of any in the world.", "hypothesis": "Most people who upgrade their qualifications do so for the joy of learning.", "gold_label": "contradiction"}
{"uid": "id_403", "premise": "The need for a satisfactory education is more important than ever before. Nowadays, without a qualification from a reputable school or university, the odds of landing that plum job advertised in the paper are considerably shortened. Moreover, one's present level of education could fall well short of future career requirements. It is no secret that competition is the driving force behind the need to obtain increasingly higher qualifications. In the majority of cases, the urge to upgrade is no longer the result of an insatiable thirst for knowledge. The pressure is coming from within the workplace to compete with ever more qualified job applicants, and in many occupations one must now battle with colleagues in the reshuffle for the position one already holds. Striving to become better educated is hardly a new concept. Wealthy parents have always been willing to spend the vast amounts of extra money necessary to send their children to schools with a perceived educational edge. Working adults have long attended night schools and refresher courses. Competition for employment has been around since the curse of working for a living began. Is the present situation so very different to that of the past? The difference now is that the push is universal and from without as well as within. A student at secondary school receiving low grades is no longer as easily accepted by his or her peers as was once the case. Similarly, in the workplace, unless employees are engaged in part-time study, they may be frowned upon by their employers and peers and have difficulty even standing still. In fact, in these cases, the expectation is for careers to go backwards and earning capacity to take an appreciable nosedive. At first glance, the situation would seem to be laudable; a positive response to the exhortation by a former Prime Minister, Bob Hawke, for australia to become the `clever country'. Yet there are serious ramifications according to at least one educational psychologist. Dr Brendan Gatsby has caused some controversy in academic circles by suggesting that a bias towards what he terms `paper' excellence might cause more problems than it is supposed to solve. Gatsby raises a number of issues that affect the individual as well as society in general. Firstly, he believes the extra workload involved is resulting in abnormally high stress levels in both students at secondary school and adults studying after working hours. Secondly, skills which might be more relevant to the undertaking of a sought_after job are being overlooked by employers interviewing candidates without qualifications on paper. These two areas of concern for the individual are causing physical and emotional stress respectively. Gatsby also argues that there are attitudinal changes within society to the exalted role education now plays in determining how the spoils of working life are distributed. Individuals of all ages are being driven by social pressures to achieve academic success solely for monetary considerations instead of for the joy of enlightenment. There is the danger that some universities are becoming degree factories with an attendant drop in standards. Furthermore, our education system may be rewarding doggedness above creativity; the very thing Australians have been encouraged to avoid. But the most undesirable effect of this academic paper chase, Gatsby says, is the disadvantage that `user pays' higher education confers on the poor, who invariably lose out to the more financially favoured. Naturally, although there is agreement that learning can cause stress, Gatsby's comments regarding university standards have been roundly criticised as alarmist by most educationists who point out that, by any standard of measurement, Australia's education system overall, at both secondary and tertiary levels, is equal to that of any in the world.", "hypothesis": "It is impossible these days to get a good job without a qualification from a respected institution.", "gold_label": "contradiction"}
{"uid": "id_404", "premise": "The need for a satisfactory education is more important than ever before. Nowadays, without a qualification from a reputable school or university, the odds of landing that plum job advertised in the paper are considerably shortened. Moreover, one's present level of education could fall well short of future career requirements. It is no secret that competition is the driving force behind the need to obtain increasingly higher qualifications. In the majority of cases, the urge to upgrade is no longer the result of an insatiable thirst for knowledge. The pressure is coming from within the workplace to compete with ever more qualified job applicants, and in many occupations one must now battle with colleagues in the reshuffle for the position one already holds. Striving to become better educated is hardly a new concept. Wealthy parents have always been willing to spend the vast amounts of extra money necessary to send their children to schools with a perceived educational edge. Working adults have long attended night schools and refresher courses. Competition for employment has been around since the curse of working for a living began. Is the present situation so very different to that of the past? The difference now is that the push is universal and from without as well as within. A student at secondary school receiving low grades is no longer as easily accepted by his or her peers as was once the case. Similarly, in the workplace, unless employees are engaged in part-time study, they may be frowned upon by their employers and peers and have difficulty even standing still. In fact, in these cases, the expectation is for careers to go backwards and earning capacity to take an appreciable nosedive. At first glance, the situation would seem to be laudable; a positive response to the exhortation by a former Prime Minister, Bob Hawke, for australia to become the `clever country'. Yet there are serious ramifications according to at least one educational psychologist. Dr Brendan Gatsby has caused some controversy in academic circles by suggesting that a bias towards what he terms `paper' excellence might cause more problems than it is supposed to solve. Gatsby raises a number of issues that affect the individual as well as society in general. Firstly, he believes the extra workload involved is resulting in abnormally high stress levels in both students at secondary school and adults studying after working hours. Secondly, skills which might be more relevant to the undertaking of a sought_after job are being overlooked by employers interviewing candidates without qualifications on paper. These two areas of concern for the individual are causing physical and emotional stress respectively. Gatsby also argues that there are attitudinal changes within society to the exalted role education now plays in determining how the spoils of working life are distributed. Individuals of all ages are being driven by social pressures to achieve academic success solely for monetary considerations instead of for the joy of enlightenment. There is the danger that some universities are becoming degree factories with an attendant drop in standards. Furthermore, our education system may be rewarding doggedness above creativity; the very thing Australians have been encouraged to avoid. But the most undesirable effect of this academic paper chase, Gatsby says, is the disadvantage that `user pays' higher education confers on the poor, who invariably lose out to the more financially favoured. Naturally, although there is agreement that learning can cause stress, Gatsby's comments regarding university standards have been roundly criticised as alarmist by most educationists who point out that, by any standard of measurement, Australia's education system overall, at both secondary and tertiary levels, is equal to that of any in the world.", "hypothesis": "Australia's education system is equal to any in the world in the opinion of most educationists.", "gold_label": "entailment"}
{"uid": "id_405", "premise": "The new health and safety regulations state that helmets should be worn and fastened and the head torch operating at all times whilst working within the mine. The use of other safety devices would be prioritised according to the previous depth regulations and in accordance to the mine's security engineer daily instructions. On dates of detonations maximal safety wear should be implemented inside as well as within a 500 meters external diameter outside the mine with no exception.", "hypothesis": "The new health and safety regulations are more demanding than the previous ones.", "gold_label": "neutral"}
{"uid": "id_406", "premise": "The new health and safety regulations state that helmets should be worn and fastened and the head torch operating at all times whilst working within the mine. The use of other safety devices would be prioritised according to the previous depth regulations and in accordance to the mine's security engineer daily instructions. On dates of detonations maximal safety wear should be implemented inside as well as within a 500 meters external diameter outside the mine with no exception.", "hypothesis": "The mine's security engineer is the only source of authority to decide which safety gear is worn by miners.", "gold_label": "contradiction"}
{"uid": "id_407", "premise": "The new health and safety regulations state that helmets should be worn and fastened and the head torch operating at all times whilst working within the mine. The use of other safety devices would be prioritised according to the previous depth regulations and in accordance to the mine's security engineer daily instructions. On dates of detonations maximal safety wear should be implemented inside as well as within a 500 meters external diameter outside the mine with no exception.", "hypothesis": "Miners working on the upper surface of the mine, near the mine's entrance, are not ever expected to wear safety devices other than a helmet and a head torch.", "gold_label": "contradiction"}
{"uid": "id_408", "premise": "The new sports club at Dolchem was vandalized on Friday evening after the boy scouts had finished their weekly meeting in the new hall. Damages are expected to be over 4,000. It is also known that: The Parish Council was in debt after the construction of the new sports club. Local teenagers opposed the proposal to charge people to use the clubs facilities. The boy scouts have abandoned the old village hall where they used to have their meetings. There is a high level of youth unemployment in Dolchem. Witnesses saw a group of five youths running away from the club at 21.30 on Friday. Spray cans were used on the club walls, liquid paint and faeces were deposited on the floor and windows were smashed.", "hypothesis": "Five young men were seen running away from the club at 21.30 on Friday.", "gold_label": "neutral"}
{"uid": "id_409", "premise": "The new sports club at Dolchem was vandalized on Friday evening after the boy scouts had finished their weekly meeting in the new hall. Damages are expected to be over 4,000. It is also known that: The Parish Council was in debt after the construction of the new sports club. Local teenagers opposed the proposal to charge people to use the clubs facilities. The boy scouts have abandoned the old village hall where they used to have their meetings. There is a high level of youth unemployment in Dolchem. Witnesses saw a group of five youths running away from the club at 21.30 on Friday. Spray cans were used on the club walls, liquid paint and faeces were deposited on the floor and windows were smashed.", "hypothesis": "The boy scouts are willing to pay to use the new club.", "gold_label": "neutral"}
{"uid": "id_410", "premise": "The new sports club at Dolchem was vandalized on Friday evening after the boy scouts had finished their weekly meeting in the new hall. Damages are expected to be over 4,000. It is also known that: The Parish Council was in debt after the construction of the new sports club. Local teenagers opposed the proposal to charge people to use the clubs facilities. The boy scouts have abandoned the old village hall where they used to have their meetings. There is a high level of youth unemployment in Dolchem. Witnesses saw a group of five youths running away from the club at 21.30 on Friday. Spray cans were used on the club walls, liquid paint and faeces were deposited on the floor and windows were smashed.", "hypothesis": "The youth of Dolchem had a motive to vandalize the new sports club.", "gold_label": "neutral"}
{"uid": "id_411", "premise": "The new sports club at Dolchem was vandalized on Friday evening after the boy scouts had finished their weekly meeting in the new hall. Damages are expected to be over 4,000. It is also known that: The Parish Council was in debt after the construction of the new sports club. Local teenagers opposed the proposal to charge people to use the clubs facilities. The boy scouts have abandoned the old village hall where they used to have their meetings. There is a high level of youth unemployment in Dolchem. Witnesses saw a group of five youths running away from the club at 21.30 on Friday. Spray cans were used on the club walls, liquid paint and faeces were deposited on the floor and windows were smashed.", "hypothesis": "The Parish Council had profited from the construction of the new sports club.", "gold_label": "contradiction"}
{"uid": "id_412", "premise": "The new sports club at Dolchem was vandalized on Friday evening after the boy scouts had finished their weekly meeting in the new hall. Damages are expected to be over 4,000. It is also known that: The Parish Council was in debt after the construction of the new sports club. Local teenagers opposed the proposal to charge people to use the clubs facilities. The boy scouts have abandoned the old village hall where they used to have their meetings. There is a high level of youth unemployment in Dolchem. Witnesses saw a group of five youths running away from the club at 21.30 on Friday. Spray cans were used on the club walls, liquid paint and faeces were deposited on the floor and windows were smashed.", "hypothesis": "The idea of charging people to use the new sports facilities had caused some opposition amongst the younger members of the community.", "gold_label": "entailment"}
{"uid": "id_413", "premise": "The newly deployed ground-based mid-course missile defence system comprises 10 interceptor missiles, each of which is intended to collide in outer space with an incoming hostile missile. So far in field trials the system has successfully intercepted target missiles in five out of eight flight tests. Critics say that these trials prove very little. Live tests are very expensive, take a great deal of organization and are usually limited by concerns over safety (you really do not want one of these missiles going astray and crashing into a city centre, for example). For these reasons, a lot of the development programme has relied on models and simulations rather than real flight tests. Both critics and supporters of the programme accept that these models do a far better job of predicting the performance of system components than of predicting the performance of the system overall.", "hypothesis": "Simulation and theoretical models cannot capture all the variables that can occur in a real missile engagement.", "gold_label": "neutral"}
{"uid": "id_414", "premise": "The newly deployed ground-based mid-course missile defence system comprises 10 interceptor missiles, each of which is intended to collide in outer space with an incoming hostile missile. So far in field trials the system has successfully intercepted target missiles in five out of eight flight tests. Critics say that these trials prove very little. Live tests are very expensive, take a great deal of organization and are usually limited by concerns over safety (you really do not want one of these missiles going astray and crashing into a city centre, for example). For these reasons, a lot of the development programme has relied on models and simulations rather than real flight tests. Both critics and supporters of the programme accept that these models do a far better job of predicting the performance of system components than of predicting the performance of the system overall.", "hypothesis": "So far only eight tests have been conducted.", "gold_label": "contradiction"}
{"uid": "id_415", "premise": "The newly deployed ground-based mid-course missile defence system comprises 10 interceptor missiles, each of which is intended to collide in outer space with an incoming hostile missile. So far in field trials the system has successfully intercepted target missiles in five out of eight flight tests. Critics say that these trials prove very little. Live tests are very expensive, take a great deal of organization and are usually limited by concerns over safety (you really do not want one of these missiles going astray and crashing into a city centre, for example). For these reasons, a lot of the development programme has relied on models and simulations rather than real flight tests. Both critics and supporters of the programme accept that these models do a far better job of predicting the performance of system components than of predicting the performance of the system overall.", "hypothesis": "The primary verification tool for the efficiency of the missile defence system has been virtual.", "gold_label": "entailment"}
{"uid": "id_416", "premise": "The number of very young children with diabetes has risen dramatically in the past 20 years. The number of children under 5 who have the type 1 form of the condition has increased fivefold. This dramatic increase is either the symptom of a marked improvement in diagnosis, or because more genetically suscep- tible children are surviving birth and infancy, or it suggests that the environment in which we raise our children has become more dangerous for their future health. The exact cause is unknown, but it is believed to be at least in part inherited. The chances of a child developing type 1 diabetes remains low, but the recent increase is too great to be explained by genetic factors alone. It may be that we are exposing our children to something new and that is the cause, or that we have reduced exposure to something that was preventing it previously.", "hypothesis": "A plausible explanation of the increase could be that the principal age at which the condition is diagnosed has become lower.", "gold_label": "entailment"}
{"uid": "id_417", "premise": "The number of very young children with diabetes has risen dramatically in the past 20 years. The number of children under 5 who have the type 1 form of the condition has increased fivefold. This dramatic increase is either the symptom of a marked improvement in diagnosis, or because more genetically suscep- tible children are surviving birth and infancy, or it suggests that the environment in which we raise our children has become more dangerous for their future health. The exact cause is unknown, but it is believed to be at least in part inherited. The chances of a child developing type 1 diabetes remains low, but the recent increase is too great to be explained by genetic factors alone. It may be that we are exposing our children to something new and that is the cause, or that we have reduced exposure to something that was preventing it previously.", "hypothesis": "It is reasonable to conclude from the passage that five times as many young children develop diabetes now than did 20 years ago.", "gold_label": "contradiction"}
{"uid": "id_418", "premise": "The number of very young children with diabetes has risen dramatically in the past 20 years. The number of children under 5 who have the type 1 form of the condition has increased fivefold. This dramatic increase is either the symptom of a marked improvement in diagnosis, or because more genetically suscep- tible children are surviving birth and infancy, or it suggests that the environment in which we raise our children has become more dangerous for their future health. The exact cause is unknown, but it is believed to be at least in part inherited. The chances of a child developing type 1 diabetes remains low, but the recent increase is too great to be explained by genetic factors alone. It may be that we are exposing our children to something new and that is the cause, or that we have reduced exposure to something that was preventing it previously.", "hypothesis": "If the cause is environmental, then the author would agree that we must be exposing our children to something new and dangerous to their health.", "gold_label": "contradiction"}
{"uid": "id_419", "premise": "The outlook for Irelands economy looked bleak at the end of 2011, as the Central Statistics Office (CSO) announced that the nations economy had shrunk by three percent. Economists suggest that this is the result of the Irish governments austerity measures, which have knocked consumer confidence and reduced spending. Not all parts of the Irish economy have suffered, however, as agricultural exports are up by ten percent. The worst affected industry is that of construction, which recorded a record drop of twenty-five percent.", "hypothesis": "The construction industry of the Irish economy has been worst hit", "gold_label": "entailment"}
{"uid": "id_420", "premise": "The outsourcing of jobs to India from Europe and America has evolved from giving them relatively low-skilled work to passing on highly skilled roles. Multinationals have decreased the number of employees in Europe and America that undertake engineering design, science and software writing and instead now employ tens of thousands of skilled Indian workers in these challenging roles. Some are establishing second headquarters in the country because they have so many senior executives working on key projects there. The shift is in part due to it being easier in India to fill highly skilled, English-speaking positions and because, for the time being anyway, the wages for these roles are notably lower than wages in Europe and America. But it is also because companies want to position their businesses where they believe the future lies. India is one of the worlds three biggest pools of highly skilled English-speaking labour and some commentators believe that as many as 30 million European and American skilled jobs are at risk of being moved.", "hypothesis": "The case that many more skilled jobs will be moved to India would be strengthened if even more than 30 million European and American jobs were at risk of moving.", "gold_label": "neutral"}
{"uid": "id_421", "premise": "The outsourcing of jobs to India from Europe and America has evolved from giving them relatively low-skilled work to passing on highly skilled roles. Multinationals have decreased the number of employees in Europe and America that undertake engineering design, science and software writing and instead now employ tens of thousands of skilled Indian workers in these challenging roles. Some are establishing second headquarters in the country because they have so many senior executives working on key projects there. The shift is in part due to it being easier in India to fill highly skilled, English-speaking positions and because, for the time being anyway, the wages for these roles are notably lower than wages in Europe and America. But it is also because companies want to position their businesses where they believe the future lies. India is one of the worlds three biggest pools of highly skilled English-speaking labour and some commentators believe that as many as 30 million European and American skilled jobs are at risk of being moved.", "hypothesis": "The claim that American and European jobs are being lost to India because Indian workers are prepared to work harder than their American and European counter- parts can be rebutted.", "gold_label": "contradiction"}
{"uid": "id_422", "premise": "The outsourcing of jobs to India from Europe and America has evolved from giving them relatively low-skilled work to passing on highly skilled roles. Multinationals have decreased the number of employees in Europe and America that undertake engineering design, science and software writing and instead now employ tens of thousands of skilled Indian workers in these challenging roles. Some are establishing second headquarters in the country because they have so many senior executives working on key projects there. The shift is in part due to it being easier in India to fill highly skilled, English-speaking positions and because, for the time being anyway, the wages for these roles are notably lower than wages in Europe and America. But it is also because companies want to position their businesses where they believe the future lies. India is one of the worlds three biggest pools of highly skilled English-speaking labour and some commentators believe that as many as 30 million European and American skilled jobs are at risk of being moved.", "hypothesis": "Three rationales for the outsourcing to India are portrayed.", "gold_label": "entailment"}
{"uid": "id_423", "premise": "The passage denies that 20,000,000 homes at the point of writing wasted at least a slice of bread a day.", "hypothesis": "Responsibility lies with the person who keeps the house.", "gold_label": "entailment"}
{"uid": "id_424", "premise": "The passage denies that 20,000,000 homes at the point of writing wasted at least a slice of bread a day.", "hypothesis": "The government has taken responsibility for public waste.", "gold_label": "contradiction"}
{"uid": "id_425", "premise": "The passage denies that 20,000,000 homes at the point of writing wasted at least a slice of bread a day.", "hypothesis": "The government should do more to inform the public about waste.", "gold_label": "contradiction"}
{"uid": "id_426", "premise": "The passage denies that 20,000,000 homes at the point of writing wasted at least a slice of bread a day.", "hypothesis": "The writer has received much criticism for his views.", "gold_label": "contradiction"}
{"uid": "id_427", "premise": "The passage denies that 20,000,000 homes at the point of writing wasted at least a slice of bread a day.", "hypothesis": "According to the above passage, a slice of bread is an unimportant thing.", "gold_label": "contradiction"}
{"uid": "id_428", "premise": "The passage details circumstances where a clients confidentiality might be broken by all the mentioned professions.", "hypothesis": "All professions have a confidentiality code but some are stricter than others.", "gold_label": "neutral"}
{"uid": "id_429", "premise": "The passage details circumstances where a clients confidentiality might be broken by all the mentioned professions.", "hypothesis": "The passage states that a doctor can be prosecuted if he or she does not report a patient who has suffered gunshot wounds.", "gold_label": "contradiction"}
{"uid": "id_430", "premise": "The people of ancient Egypt emerged as one of the first Western civilisations. Sustained by the River Nile and protected by vast deserts, the Egyptians lived in comparative security, prosperity and peace for thousands of years. When such conditions exist, the civilisation and its arts usually flourish. To this day, many of the Egyptian artistic creations display the wealth, splendour and talent of this great civilisation. Ancient Egypt has been called a land of temples and tombs. For centuries people have been filled with wonder at the ingenuity of the Egyptians, whose impressive works have withstood the ravages of time so well. Had it not been for the long-lasting nature of their monuments and carved inscriptions in the form of hieroglyphics, much evidence of their activities would have vanished from all historical records. In about 3000 BC, Upper and Lower Egypt were united under the first pharaoh, and generally from that time until the invasion by Alexander the Great in 332 BC, Egypt prospered as a nation of skilful craftsmen and artists. The Egyptians were an industrious, highly civilised and deeply religious people, who obediently accepted the supreme authority of their pharaohs. The people were content to serve and work for the state in return for a secure livelihood. They considered this earthly life to be a segment in a great cycle, at the end of which everything would be returned to its original form. The richer and more important the person, the more careful and elaborate would be his or her burial, and the stronger and safer the tomb in which they would be buried. The burial of the dead in the ground was not considered sufficiently safe for kings, queens and court officials, so sunken, sealed tombs were ingeniously constructed to protect personal treasures, food and instructions for the safe conduct of the soul after death. The design of these tombs developed into the stepped pyramid, and finally into the square pyramid that we know today. There are about 80 ancient pyramids in Egypt. The Great Pyramid at Giza, which King Cheops built as his tomb 5000 years ago, holds most interest. It stands with two other pyramids on a slight rise overlooking the River Nile. At the centre of the pyramid is the Kings Chamber and leading down from there is a long narrow area known as the Grand Gallery. The pyramid covers 13 acres and contains 2,300,000 blocks of limestone, each weighing an average of 1.5 tons. Its pyramidal form has a perfectly square base with sides of 756 feet and a height of 481 feet. Situated directly below the Kings Chamber is the Queens Chamber and there are two air channels leading upwards from the centre of the pyramid to the outside. Originally the exterior was covered in highly polished limestone slabs, all of which have been stolen over the years. It is estimated that a total of 100,000 men laboured for 20 years to build this gigantic structure, and although architecturally unimportant in design, it has aroused the curiosity of millions of people because of the uncanny accuracy of its measurements and proportions. It reveals the remarkable ingenuity and the great organising ability of the ancient Egyptians. Near these pyramids stands the Great Sphinx, the origin and purpose of which constitutes one of the worlds most famous puzzles. Shaped from an outcrop of stone in the form of a humanheaded lion, the face is possibly a portrait of King Khafra, the son of Cheops, who was buried in the second largest pyramid. The Sphinx is one of the biggest statues ever made. The Egyptian people showed reverence towards natural objects such as the lotus flower, the scarab beetle, the falcon, the lion, the sun and the River Nile. All these subjects and many more were used symbolically and conventionally as motifs in low-relief carving and painting. It was the custom of the Egyptians to depict the various parts of the human figure, usually in the most characteristic positions. The head was shown in profile except for the eye, which was represented from the front, the shoulders and a portion of the arms were portrayed from the front, while the hips and legs were side views. Wall decoration showed little or no attempt to indicate depth or perspective, except by placing distant objects above near things. It was essentially two-dimensional, and relative size indicated the status of the person, so the pharaoh was the largest figure in the composition. Egyptian art is characterised by a passion for permanence, a desire to impress by size, and a determination to make each item serve its function without much regard for the whole. It is obvious that art among these people reached a very high level and the strong influence of Egyptian art can be seen in the work of nearby civilisations. The fortunate discovery and subsequent deciphering in 1822 of the Rosetta Stone, which showed the same laws inscribed both in Egyptian hieroglyphics and the Egyptian demotic, or popular version of their language, as well as the Greek language, eventually gave the key to the meaning of Egyptian inscriptions, and therefore the significance of much Egyptian art.", "hypothesis": "Egyptian carvings were often based on things found in nature.", "gold_label": "entailment"}
{"uid": "id_431", "premise": "The people of ancient Egypt emerged as one of the first Western civilisations. Sustained by the River Nile and protected by vast deserts, the Egyptians lived in comparative security, prosperity and peace for thousands of years. When such conditions exist, the civilisation and its arts usually flourish. To this day, many of the Egyptian artistic creations display the wealth, splendour and talent of this great civilisation. Ancient Egypt has been called a land of temples and tombs. For centuries people have been filled with wonder at the ingenuity of the Egyptians, whose impressive works have withstood the ravages of time so well. Had it not been for the long-lasting nature of their monuments and carved inscriptions in the form of hieroglyphics, much evidence of their activities would have vanished from all historical records. In about 3000 BC, Upper and Lower Egypt were united under the first pharaoh, and generally from that time until the invasion by Alexander the Great in 332 BC, Egypt prospered as a nation of skilful craftsmen and artists. The Egyptians were an industrious, highly civilised and deeply religious people, who obediently accepted the supreme authority of their pharaohs. The people were content to serve and work for the state in return for a secure livelihood. They considered this earthly life to be a segment in a great cycle, at the end of which everything would be returned to its original form. The richer and more important the person, the more careful and elaborate would be his or her burial, and the stronger and safer the tomb in which they would be buried. The burial of the dead in the ground was not considered sufficiently safe for kings, queens and court officials, so sunken, sealed tombs were ingeniously constructed to protect personal treasures, food and instructions for the safe conduct of the soul after death. The design of these tombs developed into the stepped pyramid, and finally into the square pyramid that we know today. There are about 80 ancient pyramids in Egypt. The Great Pyramid at Giza, which King Cheops built as his tomb 5000 years ago, holds most interest. It stands with two other pyramids on a slight rise overlooking the River Nile. At the centre of the pyramid is the Kings Chamber and leading down from there is a long narrow area known as the Grand Gallery. The pyramid covers 13 acres and contains 2,300,000 blocks of limestone, each weighing an average of 1.5 tons. Its pyramidal form has a perfectly square base with sides of 756 feet and a height of 481 feet. Situated directly below the Kings Chamber is the Queens Chamber and there are two air channels leading upwards from the centre of the pyramid to the outside. Originally the exterior was covered in highly polished limestone slabs, all of which have been stolen over the years. It is estimated that a total of 100,000 men laboured for 20 years to build this gigantic structure, and although architecturally unimportant in design, it has aroused the curiosity of millions of people because of the uncanny accuracy of its measurements and proportions. It reveals the remarkable ingenuity and the great organising ability of the ancient Egyptians. Near these pyramids stands the Great Sphinx, the origin and purpose of which constitutes one of the worlds most famous puzzles. Shaped from an outcrop of stone in the form of a humanheaded lion, the face is possibly a portrait of King Khafra, the son of Cheops, who was buried in the second largest pyramid. The Sphinx is one of the biggest statues ever made. The Egyptian people showed reverence towards natural objects such as the lotus flower, the scarab beetle, the falcon, the lion, the sun and the River Nile. All these subjects and many more were used symbolically and conventionally as motifs in low-relief carving and painting. It was the custom of the Egyptians to depict the various parts of the human figure, usually in the most characteristic positions. The head was shown in profile except for the eye, which was represented from the front, the shoulders and a portion of the arms were portrayed from the front, while the hips and legs were side views. Wall decoration showed little or no attempt to indicate depth or perspective, except by placing distant objects above near things. It was essentially two-dimensional, and relative size indicated the status of the person, so the pharaoh was the largest figure in the composition. Egyptian art is characterised by a passion for permanence, a desire to impress by size, and a determination to make each item serve its function without much regard for the whole. It is obvious that art among these people reached a very high level and the strong influence of Egyptian art can be seen in the work of nearby civilisations. The fortunate discovery and subsequent deciphering in 1822 of the Rosetta Stone, which showed the same laws inscribed both in Egyptian hieroglyphics and the Egyptian demotic, or popular version of their language, as well as the Greek language, eventually gave the key to the meaning of Egyptian inscriptions, and therefore the significance of much Egyptian art.", "hypothesis": "Important characters in Egyptian carvings were bigger than less important characters.", "gold_label": "entailment"}
{"uid": "id_432", "premise": "The people of ancient Egypt emerged as one of the first Western civilisations. Sustained by the River Nile and protected by vast deserts, the Egyptians lived in comparative security, prosperity and peace for thousands of years. When such conditions exist, the civilisation and its arts usually flourish. To this day, many of the Egyptian artistic creations display the wealth, splendour and talent of this great civilisation. Ancient Egypt has been called a land of temples and tombs. For centuries people have been filled with wonder at the ingenuity of the Egyptians, whose impressive works have withstood the ravages of time so well. Had it not been for the long-lasting nature of their monuments and carved inscriptions in the form of hieroglyphics, much evidence of their activities would have vanished from all historical records. In about 3000 BC, Upper and Lower Egypt were united under the first pharaoh, and generally from that time until the invasion by Alexander the Great in 332 BC, Egypt prospered as a nation of skilful craftsmen and artists. The Egyptians were an industrious, highly civilised and deeply religious people, who obediently accepted the supreme authority of their pharaohs. The people were content to serve and work for the state in return for a secure livelihood. They considered this earthly life to be a segment in a great cycle, at the end of which everything would be returned to its original form. The richer and more important the person, the more careful and elaborate would be his or her burial, and the stronger and safer the tomb in which they would be buried. The burial of the dead in the ground was not considered sufficiently safe for kings, queens and court officials, so sunken, sealed tombs were ingeniously constructed to protect personal treasures, food and instructions for the safe conduct of the soul after death. The design of these tombs developed into the stepped pyramid, and finally into the square pyramid that we know today. There are about 80 ancient pyramids in Egypt. The Great Pyramid at Giza, which King Cheops built as his tomb 5000 years ago, holds most interest. It stands with two other pyramids on a slight rise overlooking the River Nile. At the centre of the pyramid is the Kings Chamber and leading down from there is a long narrow area known as the Grand Gallery. The pyramid covers 13 acres and contains 2,300,000 blocks of limestone, each weighing an average of 1.5 tons. Its pyramidal form has a perfectly square base with sides of 756 feet and a height of 481 feet. Situated directly below the Kings Chamber is the Queens Chamber and there are two air channels leading upwards from the centre of the pyramid to the outside. Originally the exterior was covered in highly polished limestone slabs, all of which have been stolen over the years. It is estimated that a total of 100,000 men laboured for 20 years to build this gigantic structure, and although architecturally unimportant in design, it has aroused the curiosity of millions of people because of the uncanny accuracy of its measurements and proportions. It reveals the remarkable ingenuity and the great organising ability of the ancient Egyptians. Near these pyramids stands the Great Sphinx, the origin and purpose of which constitutes one of the worlds most famous puzzles. Shaped from an outcrop of stone in the form of a humanheaded lion, the face is possibly a portrait of King Khafra, the son of Cheops, who was buried in the second largest pyramid. The Sphinx is one of the biggest statues ever made. The Egyptian people showed reverence towards natural objects such as the lotus flower, the scarab beetle, the falcon, the lion, the sun and the River Nile. All these subjects and many more were used symbolically and conventionally as motifs in low-relief carving and painting. It was the custom of the Egyptians to depict the various parts of the human figure, usually in the most characteristic positions. The head was shown in profile except for the eye, which was represented from the front, the shoulders and a portion of the arms were portrayed from the front, while the hips and legs were side views. Wall decoration showed little or no attempt to indicate depth or perspective, except by placing distant objects above near things. It was essentially two-dimensional, and relative size indicated the status of the person, so the pharaoh was the largest figure in the composition. Egyptian art is characterised by a passion for permanence, a desire to impress by size, and a determination to make each item serve its function without much regard for the whole. It is obvious that art among these people reached a very high level and the strong influence of Egyptian art can be seen in the work of nearby civilisations. The fortunate discovery and subsequent deciphering in 1822 of the Rosetta Stone, which showed the same laws inscribed both in Egyptian hieroglyphics and the Egyptian demotic, or popular version of their language, as well as the Greek language, eventually gave the key to the meaning of Egyptian inscriptions, and therefore the significance of much Egyptian art.", "hypothesis": "Egyptian art was greatly influenced by the art of neighbouring cultures.", "gold_label": "contradiction"}
{"uid": "id_433", "premise": "The people of ancient Egypt emerged as one of the first Western civilisations. Sustained by the River Nile and protected by vast deserts, the Egyptians lived in comparative security, prosperity and peace for thousands of years. When such conditions exist, the civilisation and its arts usually flourish. To this day, many of the Egyptian artistic creations display the wealth, splendour and talent of this great civilisation. Ancient Egypt has been called a land of temples and tombs. For centuries people have been filled with wonder at the ingenuity of the Egyptians, whose impressive works have withstood the ravages of time so well. Had it not been for the long-lasting nature of their monuments and carved inscriptions in the form of hieroglyphics, much evidence of their activities would have vanished from all historical records. In about 3000 BC, Upper and Lower Egypt were united under the first pharaoh, and generally from that time until the invasion by Alexander the Great in 332 BC, Egypt prospered as a nation of skilful craftsmen and artists. The Egyptians were an industrious, highly civilised and deeply religious people, who obediently accepted the supreme authority of their pharaohs. The people were content to serve and work for the state in return for a secure livelihood. They considered this earthly life to be a segment in a great cycle, at the end of which everything would be returned to its original form. The richer and more important the person, the more careful and elaborate would be his or her burial, and the stronger and safer the tomb in which they would be buried. The burial of the dead in the ground was not considered sufficiently safe for kings, queens and court officials, so sunken, sealed tombs were ingeniously constructed to protect personal treasures, food and instructions for the safe conduct of the soul after death. The design of these tombs developed into the stepped pyramid, and finally into the square pyramid that we know today. There are about 80 ancient pyramids in Egypt. The Great Pyramid at Giza, which King Cheops built as his tomb 5000 years ago, holds most interest. It stands with two other pyramids on a slight rise overlooking the River Nile. At the centre of the pyramid is the Kings Chamber and leading down from there is a long narrow area known as the Grand Gallery. The pyramid covers 13 acres and contains 2,300,000 blocks of limestone, each weighing an average of 1.5 tons. Its pyramidal form has a perfectly square base with sides of 756 feet and a height of 481 feet. Situated directly below the Kings Chamber is the Queens Chamber and there are two air channels leading upwards from the centre of the pyramid to the outside. Originally the exterior was covered in highly polished limestone slabs, all of which have been stolen over the years. It is estimated that a total of 100,000 men laboured for 20 years to build this gigantic structure, and although architecturally unimportant in design, it has aroused the curiosity of millions of people because of the uncanny accuracy of its measurements and proportions. It reveals the remarkable ingenuity and the great organising ability of the ancient Egyptians. Near these pyramids stands the Great Sphinx, the origin and purpose of which constitutes one of the worlds most famous puzzles. Shaped from an outcrop of stone in the form of a humanheaded lion, the face is possibly a portrait of King Khafra, the son of Cheops, who was buried in the second largest pyramid. The Sphinx is one of the biggest statues ever made. The Egyptian people showed reverence towards natural objects such as the lotus flower, the scarab beetle, the falcon, the lion, the sun and the River Nile. All these subjects and many more were used symbolically and conventionally as motifs in low-relief carving and painting. It was the custom of the Egyptians to depict the various parts of the human figure, usually in the most characteristic positions. The head was shown in profile except for the eye, which was represented from the front, the shoulders and a portion of the arms were portrayed from the front, while the hips and legs were side views. Wall decoration showed little or no attempt to indicate depth or perspective, except by placing distant objects above near things. It was essentially two-dimensional, and relative size indicated the status of the person, so the pharaoh was the largest figure in the composition. Egyptian art is characterised by a passion for permanence, a desire to impress by size, and a determination to make each item serve its function without much regard for the whole. It is obvious that art among these people reached a very high level and the strong influence of Egyptian art can be seen in the work of nearby civilisations. The fortunate discovery and subsequent deciphering in 1822 of the Rosetta Stone, which showed the same laws inscribed both in Egyptian hieroglyphics and the Egyptian demotic, or popular version of their language, as well as the Greek language, eventually gave the key to the meaning of Egyptian inscriptions, and therefore the significance of much Egyptian art.", "hypothesis": "The surface of the Great Pyramid is covered in polished limestone slabs.", "gold_label": "contradiction"}
{"uid": "id_434", "premise": "The people of ancient Egypt emerged as one of the first Western civilisations. Sustained by the River Nile and protected by vast deserts, the Egyptians lived in comparative security, prosperity and peace for thousands of years. When such conditions exist, the civilisation and its arts usually flourish. To this day, many of the Egyptian artistic creations display the wealth, splendour and talent of this great civilisation. Ancient Egypt has been called a land of temples and tombs. For centuries people have been filled with wonder at the ingenuity of the Egyptians, whose impressive works have withstood the ravages of time so well. Had it not been for the long-lasting nature of their monuments and carved inscriptions in the form of hieroglyphics, much evidence of their activities would have vanished from all historical records. In about 3000 BC, Upper and Lower Egypt were united under the first pharaoh, and generally from that time until the invasion by Alexander the Great in 332 BC, Egypt prospered as a nation of skilful craftsmen and artists. The Egyptians were an industrious, highly civilised and deeply religious people, who obediently accepted the supreme authority of their pharaohs. The people were content to serve and work for the state in return for a secure livelihood. They considered this earthly life to be a segment in a great cycle, at the end of which everything would be returned to its original form. The richer and more important the person, the more careful and elaborate would be his or her burial, and the stronger and safer the tomb in which they would be buried. The burial of the dead in the ground was not considered sufficiently safe for kings, queens and court officials, so sunken, sealed tombs were ingeniously constructed to protect personal treasures, food and instructions for the safe conduct of the soul after death. The design of these tombs developed into the stepped pyramid, and finally into the square pyramid that we know today. There are about 80 ancient pyramids in Egypt. The Great Pyramid at Giza, which King Cheops built as his tomb 5000 years ago, holds most interest. It stands with two other pyramids on a slight rise overlooking the River Nile. At the centre of the pyramid is the Kings Chamber and leading down from there is a long narrow area known as the Grand Gallery. The pyramid covers 13 acres and contains 2,300,000 blocks of limestone, each weighing an average of 1.5 tons. Its pyramidal form has a perfectly square base with sides of 756 feet and a height of 481 feet. Situated directly below the Kings Chamber is the Queens Chamber and there are two air channels leading upwards from the centre of the pyramid to the outside. Originally the exterior was covered in highly polished limestone slabs, all of which have been stolen over the years. It is estimated that a total of 100,000 men laboured for 20 years to build this gigantic structure, and although architecturally unimportant in design, it has aroused the curiosity of millions of people because of the uncanny accuracy of its measurements and proportions. It reveals the remarkable ingenuity and the great organising ability of the ancient Egyptians. Near these pyramids stands the Great Sphinx, the origin and purpose of which constitutes one of the worlds most famous puzzles. Shaped from an outcrop of stone in the form of a humanheaded lion, the face is possibly a portrait of King Khafra, the son of Cheops, who was buried in the second largest pyramid. The Sphinx is one of the biggest statues ever made. The Egyptian people showed reverence towards natural objects such as the lotus flower, the scarab beetle, the falcon, the lion, the sun and the River Nile. All these subjects and many more were used symbolically and conventionally as motifs in low-relief carving and painting. It was the custom of the Egyptians to depict the various parts of the human figure, usually in the most characteristic positions. The head was shown in profile except for the eye, which was represented from the front, the shoulders and a portion of the arms were portrayed from the front, while the hips and legs were side views. Wall decoration showed little or no attempt to indicate depth or perspective, except by placing distant objects above near things. It was essentially two-dimensional, and relative size indicated the status of the person, so the pharaoh was the largest figure in the composition. Egyptian art is characterised by a passion for permanence, a desire to impress by size, and a determination to make each item serve its function without much regard for the whole. It is obvious that art among these people reached a very high level and the strong influence of Egyptian art can be seen in the work of nearby civilisations. The fortunate discovery and subsequent deciphering in 1822 of the Rosetta Stone, which showed the same laws inscribed both in Egyptian hieroglyphics and the Egyptian demotic, or popular version of their language, as well as the Greek language, eventually gave the key to the meaning of Egyptian inscriptions, and therefore the significance of much Egyptian art.", "hypothesis": "King Khafra died before King Cheops.", "gold_label": "neutral"}
{"uid": "id_435", "premise": "The peoples republic of china has enjoyed a rapidly growing economy for decades, with chinas export market the key factor in its economic success. However recently economic growth, import and export growth have been declining and are at their lowest rates since the late 2000 economic crisis. These may be indications of a slowing economy, which could spell disaster for the Peoples Republic, which have set their sights at competing with America for economic superpower status. It is possible that the increase in living standards and wages throughout china has increased the prices of its exports, making them less financially desirable. Only time will tell if the worlds second largest economy still has the steam to maintain high rates of growth.", "hypothesis": "Increase in wages is the suggested reason for chinas slowed growth", "gold_label": "entailment"}
{"uid": "id_436", "premise": "The phenomenon of bottled water has given rise to the creation of a billion pound industry. The cost of bottled water can be up to 10,000 times higher than that of tap water. However, a reported 53 billion gallons of bottled water are consumed each year. This is a shocking figure, when considering the fact that much bottled water is actually from municipal water sources; in other words, taps. In addition, the process of bottling and transporting the water can have detrimental effects on the environment. Last year over 16 million barrels of oil were used in the production of bottled water. This is enough oil to fuel over half a million cars for an entire year. Finally, statistics suggest that only one in six plastic water bottles are recycled. In this way, the bottled water industry can be seen as not only overly expensive for consumers, but also as damaging for the environment.", "hypothesis": "Bottled water can be up to 10,000 times higher than the cost of tap water.", "gold_label": "entailment"}
{"uid": "id_437", "premise": "The phenomenon of bottled water has given rise to the creation of a billion pound industry. The cost of bottled water can be up to 10,000 times higher than that of tap water. However, a reported 53 billion gallons of bottled water are consumed each year. This is a shocking figure, when considering the fact that much bottled water is actually from municipal water sources; in other words, taps. In addition, the process of bottling and transporting the water can have detrimental effects on the environment. Last year over 16 million barrels of oil were used in the production of bottled water. This is enough oil to fuel over half a million cars for an entire year. Finally, statistics suggest that only one in six plastic water bottles are recycled. In this way, the bottled water industry can be seen as not only overly expensive for consumers, but also as damaging for the environment.", "hypothesis": "Bottled water is 10,000 times higher than the cost of tap water.", "gold_label": "contradiction"}
{"uid": "id_438", "premise": "The phenomenon of bottled water has given rise to the creation of a billion pound industry. The cost of bottled water can be up to 10,000 times higher than that of tap water. However, a reported 53 billion gallons of bottled water are consumed each year. This is a shocking figure, when considering the fact that much bottled water is actually from municipal water sources; in other words, taps. In addition, the process of bottling and transporting the water can have detrimental effects on the environment. Last year over 16 million barrels of oil were used in the production of bottled water. This is enough oil to fuel over half a million cars for an entire year. Finally, statistics suggest that only one in six plastic water bottles are recycled. In this way, the bottled water industry can be seen as not only overly expensive for consumers, but also as damaging for the environment.", "hypothesis": "The bottled water industry may have a negative effect on the environment.", "gold_label": "entailment"}
{"uid": "id_439", "premise": "The phenomenon of bottled water has given rise to the creation of a billion pound industry. The cost of bottled water can be up to 10,000 times higher than that of tap water. However, a reported 53 billion gallons of bottled water are consumed each year. This is a shocking figure, when considering the fact that much bottled water is actually from municipal water sources; in other words, taps. In addition, the process of bottling and transporting the water can have detrimental effects on the environment. Last year over 16 million barrels of oil were used in the production of bottled water. This is enough oil to fuel over half a million cars for an entire year. Finally, statistics suggest that only one in six plastic water bottles are recycled. In this way, the bottled water industry can be seen as not only overly expensive for consumers, but also as damaging for the environment.", "hypothesis": "The oil from last years production of bottled water could fuel 500,000 cars", "gold_label": "entailment"}
{"uid": "id_440", "premise": "The polar bear is the worlds largest land carnivore and also the largest species of bear, along with the Kodiak bear. The polar bear is on average twice as large as the Siberian tiger and adult males weigh between 350-700kg in the wild. Adult females are roughly half the size, weighing between 150-250kg. Polar bears are insulated with up to 10 cm of blubber, which causes them to overheat at temperatures above 10 C. Unlike brown bears, polar bears are unlikely to become obese in captivity, likely due to warm conditions in most zoos. Polar bears are excellent swimmers and individuals have been seen on open arctic waters as far as 300 km from land.", "hypothesis": "The polar bears blubber is an adaption to their cold arctic climate.", "gold_label": "neutral"}
{"uid": "id_441", "premise": "The polar bear is the worlds largest land carnivore and also the largest species of bear, along with the Kodiak bear. The polar bear is on average twice as large as the Siberian tiger and adult males weigh between 350-700kg in the wild. Adult females are roughly half the size, weighing between 150-250kg. Polar bears are insulated with up to 10 cm of blubber, which causes them to overheat at temperatures above 10 C. Unlike brown bears, polar bears are unlikely to become obese in captivity, likely due to warm conditions in most zoos. Polar bears are excellent swimmers and individuals have been seen on open arctic waters as far as 300 km from land.", "hypothesis": "On average, the Kodiak bear is twice the size of the Siberian tiger.", "gold_label": "entailment"}
{"uid": "id_442", "premise": "The polar bear is the worlds largest land carnivore and also the largest species of bear, along with the Kodiak bear. The polar bear is on average twice as large as the Siberian tiger and adult males weigh between 350-700kg in the wild. Adult females are roughly half the size, weighing between 150-250kg. Polar bears are insulated with up to 10 cm of blubber, which causes them to overheat at temperatures above 10 C. Unlike brown bears, polar bears are unlikely to become obese in captivity, likely due to warm conditions in most zoos. Polar bears are excellent swimmers and individuals have been seen on open arctic waters as far as 300 km from land.", "hypothesis": "The Polar bear spends more time in water than on land.", "gold_label": "neutral"}
{"uid": "id_443", "premise": "The polar bear is the worlds largest land carnivore and also the largest species of bear, along with the Kodiak bear. The polar bear is on average twice as large as the Siberian tiger and adult males weigh between 350-700kg in the wild. Adult females are roughly half the size, weighing between 150-250kg. Polar bears are insulated with up to 10 cm of blubber, which causes them to overheat at temperatures above 10 C. Unlike brown bears, polar bears are unlikely to become obese in captivity, likely due to warm conditions in most zoos. Polar bears are excellent swimmers and individuals have been seen on open arctic waters as far as 300 km from land.", "hypothesis": "The Kodiak bear is the worlds largest carnivore.", "gold_label": "neutral"}
{"uid": "id_444", "premise": "The polar bear is the worlds largest land carnivore and also the largest species of bear, along with the Kodiak bear. The polar bear is on average twice as large as the Siberian tiger and adult males weigh between 350-700kg in the wild. Adult females are roughly half the size, weighing between 150-250kg. Polar bears are insulated with up to 10 cm of blubber, which causes them to overheat at temperatures above 10 C. Unlike brown bears, polar bears are unlikely to become obese in captivity, likely due to warm conditions in most zoos. Polar bears are excellent swimmers and individuals have been seen on open arctic waters as far as 300 km from land.", "hypothesis": "Polar bears in captivity are much larger than those in the wild.", "gold_label": "neutral"}
{"uid": "id_445", "premise": "The police are looking for a man aged about 30 who is suspected of committing an assault on a pair of senior citizens outside their home in Chapel Street, Northwell. The alleged assault occurred shortly after 23.00 hours on Thursday 8 July when the couple, Monica and Albert Smart, were returning home from a social evening at their local Community Centre. The following facts are also known: Monica and Albert Smith are both aged over 65 and have recently retired. An unknown assailant snatched and ran off with Monicas handbag, but Albert refused to hand over his wallet despite being threatened by the thief. After the attack, Albert was taken to the A&E Department of City Hospital suffering from severe shock, but was later allowed to return home. Bill James aged 32, an unemployed neighbour of the Smarts, was visited by debt collectors on the day of the assault.", "hypothesis": "The police are looking for Bill James who is under suspicion for committing the assault on Albert and Monica Smart.", "gold_label": "neutral"}
{"uid": "id_446", "premise": "The police are looking for a man aged about 30 who is suspected of committing an assault on a pair of senior citizens outside their home in Chapel Street, Northwell. The alleged assault occurred shortly after 23.00 hours on Thursday 8 July when the couple, Monica and Albert Smart, were returning home from a social evening at their local Community Centre. The following facts are also known: Monica and Albert Smith are both aged over 65 and have recently retired. An unknown assailant snatched and ran off with Monicas handbag, but Albert refused to hand over his wallet despite being threatened by the thief. After the attack, Albert was taken to the A&E Department of City Hospital suffering from severe shock, but was later allowed to return home. Bill James aged 32, an unemployed neighbour of the Smarts, was visited by debt collectors on the day of the assault.", "hypothesis": "Bill James, a neighbour of Mr and Mrs Smart, is currently experiencing financial difficulties.", "gold_label": "entailment"}
{"uid": "id_447", "premise": "The police are looking for a man aged about 30 who is suspected of committing an assault on a pair of senior citizens outside their home in Chapel Street, Northwell. The alleged assault occurred shortly after 23.00 hours on Thursday 8 July when the couple, Monica and Albert Smart, were returning home from a social evening at their local Community Centre. The following facts are also known: Monica and Albert Smith are both aged over 65 and have recently retired. An unknown assailant snatched and ran off with Monicas handbag, but Albert refused to hand over his wallet despite being threatened by the thief. After the attack, Albert was taken to the A&E Department of City Hospital suffering from severe shock, but was later allowed to return home. Bill James aged 32, an unemployed neighbour of the Smarts, was visited by debt collectors on the day of the assault.", "hypothesis": "Mr and Mrs Smart are long-term residents of Chapel Street, Northwell.", "gold_label": "neutral"}
{"uid": "id_448", "premise": "The police are looking for a man aged about 30 who is suspected of committing an assault on a pair of senior citizens outside their home in Chapel Street, Northwell. The alleged assault occurred shortly after 23.00 hours on Thursday 8 July when the couple, Monica and Albert Smart, were returning home from a social evening at their local Community Centre. The following facts are also known: Monica and Albert Smith are both aged over 65 and have recently retired. An unknown assailant snatched and ran off with Monicas handbag, but Albert refused to hand over his wallet despite being threatened by the thief. After the attack, Albert was taken to the A&E Department of City Hospital suffering from severe shock, but was later allowed to return home. Bill James aged 32, an unemployed neighbour of the Smarts, was visited by debt collectors on the day of the assault.", "hypothesis": "Albert Smart resisted the thiefs attempts to steal his wallet, and was taken to the hospital afterwards to have his injuries treated.", "gold_label": "contradiction"}
{"uid": "id_449", "premise": "The police are looking for a man aged about 30 who is suspected of committing an assault on a pair of senior citizens outside their home in Chapel Street, Northwell. The alleged assault occurred shortly after 23.00 hours on Thursday 8 July when the couple, Monica and Albert Smart, were returning home from a social evening at their local Community Centre. The following facts are also known: Monica and Albert Smith are both aged over 65 and have recently retired. An unknown assailant snatched and ran off with Monicas handbag, but Albert refused to hand over his wallet despite being threatened by the thief. After the attack, Albert was taken to the A&E Department of City Hospital suffering from severe shock, but was later allowed to return home. Bill James aged 32, an unemployed neighbour of the Smarts, was visited by debt collectors on the day of the assault.", "hypothesis": "Theft was the prime motive for the attack on Monica and Albert Smart, a pair of recently retired senior citizens.", "gold_label": "entailment"}
{"uid": "id_450", "premise": "The police report that they have obtained CCTV images of a robbery that took place at a mini-supermarket in a suburb of Littleton. The recordings show that three masked men entered the store in North Road as the duty manager Debra Mooney and her assistants were preparing to close down at about 23.50 BST on Friday 20 April. The following facts are also known: Two of the men jumped over the counter and grabbed a quantity of cash from the tills. The other man threatened the staff with what appeared to be a kitchen knife. None of the staff was injured in the incident but they were badly shaken by the experience. Bret Desmond, the brother of one of the assistants, was recently released from prison after serving a sentence for robbery. The owner of a nearby hardware store had reported to the police that a set of kitchen knives had been stolen from his shop on the afternoon of Friday 20 April.", "hypothesis": "The knife used in the robbery at the mini-supermarket had been stolen from a local hardware shop earlier that day.", "gold_label": "neutral"}
{"uid": "id_451", "premise": "The police report that they have obtained CCTV images of a robbery that took place at a mini-supermarket in a suburb of Littleton. The recordings show that three masked men entered the store in North Road as the duty manager Debra Mooney and her assistants were preparing to close down at about 23.50 BST on Friday 20 April. The following facts are also known: Two of the men jumped over the counter and grabbed a quantity of cash from the tills. The other man threatened the staff with what appeared to be a kitchen knife. None of the staff was injured in the incident but they were badly shaken by the experience. Bret Desmond, the brother of one of the assistants, was recently released from prison after serving a sentence for robbery. The owner of a nearby hardware store had reported to the police that a set of kitchen knives had been stolen from his shop on the afternoon of Friday 20 April.", "hypothesis": "The raid on the mini-supermarket took place shortly before midnight on the last Friday in April.", "gold_label": "contradiction"}
{"uid": "id_452", "premise": "The police report that they have obtained CCTV images of a robbery that took place at a mini-supermarket in a suburb of Littleton. The recordings show that three masked men entered the store in North Road as the duty manager Debra Mooney and her assistants were preparing to close down at about 23.50 BST on Friday 20 April. The following facts are also known: Two of the men jumped over the counter and grabbed a quantity of cash from the tills. The other man threatened the staff with what appeared to be a kitchen knife. None of the staff was injured in the incident but they were badly shaken by the experience. Bret Desmond, the brother of one of the assistants, was recently released from prison after serving a sentence for robbery. The owner of a nearby hardware store had reported to the police that a set of kitchen knives had been stolen from his shop on the afternoon of Friday 20 April.", "hypothesis": "The duty manager Debra Mooney and her assistants were subjected to physical violence during the course of the incident.", "gold_label": "contradiction"}
{"uid": "id_453", "premise": "The police report that they have obtained CCTV images of a robbery that took place at a mini-supermarket in a suburb of Littleton. The recordings show that three masked men entered the store in North Road as the duty manager Debra Mooney and her assistants were preparing to close down at about 23.50 BST on Friday 20 April. The following facts are also known: Two of the men jumped over the counter and grabbed a quantity of cash from the tills. The other man threatened the staff with what appeared to be a kitchen knife. None of the staff was injured in the incident but they were badly shaken by the experience. Bret Desmond, the brother of one of the assistants, was recently released from prison after serving a sentence for robbery. The owner of a nearby hardware store had reported to the police that a set of kitchen knives had been stolen from his shop on the afternoon of Friday 20 April.", "hypothesis": "The CCTV images will enable the police to identify the three men who committed the robbery at the store.", "gold_label": "neutral"}
{"uid": "id_454", "premise": "The police report that they have obtained CCTV images of a robbery that took place at a mini-supermarket in a suburb of Littleton. The recordings show that three masked men entered the store in North Road as the duty manager Debra Mooney and her assistants were preparing to close down at about 23.50 BST on Friday 20 April. The following facts are also known: Two of the men jumped over the counter and grabbed a quantity of cash from the tills. The other man threatened the staff with what appeared to be a kitchen knife. None of the staff was injured in the incident but they were badly shaken by the experience. Bret Desmond, the brother of one of the assistants, was recently released from prison after serving a sentence for robbery. The owner of a nearby hardware store had reported to the police that a set of kitchen knives had been stolen from his shop on the afternoon of Friday 20 April.", "hypothesis": "Bret Desmond, the brother of one of the assistants at the store, has a criminal record.", "gold_label": "entailment"}
{"uid": "id_455", "premise": "The politics of pessimism Newspaper headlines and TV or radio news bulletins would have us believe erroneously that a new age has come upon us, the Age of Cassandra. People are being assailed not just with contemporary doom, or past gloom, but with prophecies of disasters about to befall. The dawn of the new millennium has now passed; the earth is still intact, and the fin de siecle Jeremiahs have now gone off to configure a new date for the apocalypse. It can, I believe, be said with some certainty that the doom-mongers will never run out of business. Human nature has an inclination for pessimism and anxiety, with each age having its demagogues, foretelling doom or dragging it in their wake. But what makes the modern age so different is that the catastrophes are more in your face, Their assault on our senses is relentless. Whether it be sub-conscious or not, this is a situation not lost on politicians. They play upon peoples propensity for unease, turning it into a very effective political tool. Deluding the general public All too often, when politicians want to change the status quo, they take advantage of peoples fears of the unknown and their uncertainties about the future. For example, details about a new policy may be leaked to the press. Of course, the worst case scenario is presented in all its depressing detail. When the general public reacts in horror, the government appears to cave in. And then accepting some of the suggestions from their critics, ministers water down their proposals. This allows the government to get what It wants, while at the same time fooling the public into believing that they have got one over on the government. Or even that they have some say in the making of policy. There are several principles at play here. And both are rather simple: unsettle people and then play on their fears; and second, people must be given an opportunity to make a contribution, however insignificant, in a given situation; otherwise, they become dissatisfied, not fearful or anxious. A similar ruse, at a local level, will further illustrate how easily peoples base fears are exploited. A common practice is to give people a number of options, say in a housing development, ranging from no change to radical transformation of an area. The aim is to persuade people to agree significant modifications, which may involve disruption to their lives, and possibly extra expenditure. The individuals, fearful of the worst possible outcome, plump for the middle course. And this, incidentally, is invariably the option favoured by the authorities. Everything is achieved under the guise of market research, but it is obviously a blatant exercise in the manipulation of peoples fears. Fear and survival Fear and anxieties about the future affect us still. People are wracked with self-doubt and low self-esteem. In the struggle to exist and advance in life, a seemingly endless string, of obstacles is encountered, so many, in fact, that any accomplishment seems surprising. liven when people do succeed they are still nagged by uncertainty. Not surprisingly, feelings like doubt, fear, anxiety and pessimism are usually associated with failure. Yet, if properly harnessed, they are the driving force behind success, the very engines of genius. if things turn out well for a long time, there is a further anxiety: that of constantly waiting for something to go wrong. People then find themselves propitiating the gods: not walking on lines on the pavements, performing rituals before public performances, wearing particular clothes and colours so that they can blame the ritual not themselves when things go wrong, But surely the real terror cornea when success continues uninterrupted for such a long period of time that we forget what failure is like! We crave for and are fed a daily diet of anxiety, Horror films and disaster movies have an increasing appeal. Nostradamus pops his head up now and again. And other would-be prophets make a brief appearance, predicting the demise of human kind. Perhaps, this is all just a vestige of the hardships of early man our attempt to recreate the struggles of a past age, as its becomes more and more comfortable. Mankind cannot live by contentment alone. And so, a world awash with anxieties and pessimism has been created. Being optimistic is you struggle. Hut survival dictates that mankind remain ever sanguine.", "hypothesis": "People perform certain rituals to try to avoid failure.", "gold_label": "entailment"}
{"uid": "id_456", "premise": "The politics of pessimism Newspaper headlines and TV or radio news bulletins would have us believe erroneously that a new age has come upon us, the Age of Cassandra. People are being assailed not just with contemporary doom, or past gloom, but with prophecies of disasters about to befall. The dawn of the new millennium has now passed; the earth is still intact, and the fin de siecle Jeremiahs have now gone off to configure a new date for the apocalypse. It can, I believe, be said with some certainty that the doom-mongers will never run out of business. Human nature has an inclination for pessimism and anxiety, with each age having its demagogues, foretelling doom or dragging it in their wake. But what makes the modern age so different is that the catastrophes are more in your face, Their assault on our senses is relentless. Whether it be sub-conscious or not, this is a situation not lost on politicians. They play upon peoples propensity for unease, turning it into a very effective political tool. Deluding the general public All too often, when politicians want to change the status quo, they take advantage of peoples fears of the unknown and their uncertainties about the future. For example, details about a new policy may be leaked to the press. Of course, the worst case scenario is presented in all its depressing detail. When the general public reacts in horror, the government appears to cave in. And then accepting some of the suggestions from their critics, ministers water down their proposals. This allows the government to get what It wants, while at the same time fooling the public into believing that they have got one over on the government. Or even that they have some say in the making of policy. There are several principles at play here. And both are rather simple: unsettle people and then play on their fears; and second, people must be given an opportunity to make a contribution, however insignificant, in a given situation; otherwise, they become dissatisfied, not fearful or anxious. A similar ruse, at a local level, will further illustrate how easily peoples base fears are exploited. A common practice is to give people a number of options, say in a housing development, ranging from no change to radical transformation of an area. The aim is to persuade people to agree significant modifications, which may involve disruption to their lives, and possibly extra expenditure. The individuals, fearful of the worst possible outcome, plump for the middle course. And this, incidentally, is invariably the option favoured by the authorities. Everything is achieved under the guise of market research, but it is obviously a blatant exercise in the manipulation of peoples fears. Fear and survival Fear and anxieties about the future affect us still. People are wracked with self-doubt and low self-esteem. In the struggle to exist and advance in life, a seemingly endless string, of obstacles is encountered, so many, in fact, that any accomplishment seems surprising. liven when people do succeed they are still nagged by uncertainty. Not surprisingly, feelings like doubt, fear, anxiety and pessimism are usually associated with failure. Yet, if properly harnessed, they are the driving force behind success, the very engines of genius. if things turn out well for a long time, there is a further anxiety: that of constantly waiting for something to go wrong. People then find themselves propitiating the gods: not walking on lines on the pavements, performing rituals before public performances, wearing particular clothes and colours so that they can blame the ritual not themselves when things go wrong, But surely the real terror cornea when success continues uninterrupted for such a long period of time that we forget what failure is like! We crave for and are fed a daily diet of anxiety, Horror films and disaster movies have an increasing appeal. Nostradamus pops his head up now and again. And other would-be prophets make a brief appearance, predicting the demise of human kind. Perhaps, this is all just a vestige of the hardships of early man our attempt to recreate the struggles of a past age, as its becomes more and more comfortable. Mankind cannot live by contentment alone. And so, a world awash with anxieties and pessimism has been created. Being optimistic is you struggle. Hut survival dictates that mankind remain ever sanguine.", "hypothesis": "The complex relationship between failure and success needs to be addressed carefully.", "gold_label": "neutral"}
{"uid": "id_457", "premise": "The politics of pessimism Newspaper headlines and TV or radio news bulletins would have us believe erroneously that a new age has come upon us, the Age of Cassandra. People are being assailed not just with contemporary doom, or past gloom, but with prophecies of disasters about to befall. The dawn of the new millennium has now passed; the earth is still intact, and the fin de siecle Jeremiahs have now gone off to configure a new date for the apocalypse. It can, I believe, be said with some certainty that the doom-mongers will never run out of business. Human nature has an inclination for pessimism and anxiety, with each age having its demagogues, foretelling doom or dragging it in their wake. But what makes the modern age so different is that the catastrophes are more in your face, Their assault on our senses is relentless. Whether it be sub-conscious or not, this is a situation not lost on politicians. They play upon peoples propensity for unease, turning it into a very effective political tool. Deluding the general public All too often, when politicians want to change the status quo, they take advantage of peoples fears of the unknown and their uncertainties about the future. For example, details about a new policy may be leaked to the press. Of course, the worst case scenario is presented in all its depressing detail. When the general public reacts in horror, the government appears to cave in. And then accepting some of the suggestions from their critics, ministers water down their proposals. This allows the government to get what It wants, while at the same time fooling the public into believing that they have got one over on the government. Or even that they have some say in the making of policy. There are several principles at play here. And both are rather simple: unsettle people and then play on their fears; and second, people must be given an opportunity to make a contribution, however insignificant, in a given situation; otherwise, they become dissatisfied, not fearful or anxious. A similar ruse, at a local level, will further illustrate how easily peoples base fears are exploited. A common practice is to give people a number of options, say in a housing development, ranging from no change to radical transformation of an area. The aim is to persuade people to agree significant modifications, which may involve disruption to their lives, and possibly extra expenditure. The individuals, fearful of the worst possible outcome, plump for the middle course. And this, incidentally, is invariably the option favoured by the authorities. Everything is achieved under the guise of market research, but it is obviously a blatant exercise in the manipulation of peoples fears. Fear and survival Fear and anxieties about the future affect us still. People are wracked with self-doubt and low self-esteem. In the struggle to exist and advance in life, a seemingly endless string, of obstacles is encountered, so many, in fact, that any accomplishment seems surprising. liven when people do succeed they are still nagged by uncertainty. Not surprisingly, feelings like doubt, fear, anxiety and pessimism are usually associated with failure. Yet, if properly harnessed, they are the driving force behind success, the very engines of genius. if things turn out well for a long time, there is a further anxiety: that of constantly waiting for something to go wrong. People then find themselves propitiating the gods: not walking on lines on the pavements, performing rituals before public performances, wearing particular clothes and colours so that they can blame the ritual not themselves when things go wrong, But surely the real terror cornea when success continues uninterrupted for such a long period of time that we forget what failure is like! We crave for and are fed a daily diet of anxiety, Horror films and disaster movies have an increasing appeal. Nostradamus pops his head up now and again. And other would-be prophets make a brief appearance, predicting the demise of human kind. Perhaps, this is all just a vestige of the hardships of early man our attempt to recreate the struggles of a past age, as its becomes more and more comfortable. Mankind cannot live by contentment alone. And so, a world awash with anxieties and pessimism has been created. Being optimistic is you struggle. Hut survival dictates that mankind remain ever sanguine.", "hypothesis": "The writer believes that Nostradamus and certain other prophets are right about their predictions for the end of the human race.", "gold_label": "neutral"}
{"uid": "id_458", "premise": "The politics of pessimism Newspaper headlines and TV or radio news bulletins would have us believe erroneously that a new age has come upon us, the Age of Cassandra. People are being assailed not just with contemporary doom, or past gloom, but with prophecies of disasters about to befall. The dawn of the new millennium has now passed; the earth is still intact, and the fin de siecle Jeremiahs have now gone off to configure a new date for the apocalypse. It can, I believe, be said with some certainty that the doom-mongers will never run out of business. Human nature has an inclination for pessimism and anxiety, with each age having its demagogues, foretelling doom or dragging it in their wake. But what makes the modern age so different is that the catastrophes are more in your face, Their assault on our senses is relentless. Whether it be sub-conscious or not, this is a situation not lost on politicians. They play upon peoples propensity for unease, turning it into a very effective political tool. Deluding the general public All too often, when politicians want to change the status quo, they take advantage of peoples fears of the unknown and their uncertainties about the future. For example, details about a new policy may be leaked to the press. Of course, the worst case scenario is presented in all its depressing detail. When the general public reacts in horror, the government appears to cave in. And then accepting some of the suggestions from their critics, ministers water down their proposals. This allows the government to get what It wants, while at the same time fooling the public into believing that they have got one over on the government. Or even that they have some say in the making of policy. There are several principles at play here. And both are rather simple: unsettle people and then play on their fears; and second, people must be given an opportunity to make a contribution, however insignificant, in a given situation; otherwise, they become dissatisfied, not fearful or anxious. A similar ruse, at a local level, will further illustrate how easily peoples base fears are exploited. A common practice is to give people a number of options, say in a housing development, ranging from no change to radical transformation of an area. The aim is to persuade people to agree significant modifications, which may involve disruption to their lives, and possibly extra expenditure. The individuals, fearful of the worst possible outcome, plump for the middle course. And this, incidentally, is invariably the option favoured by the authorities. Everything is achieved under the guise of market research, but it is obviously a blatant exercise in the manipulation of peoples fears. Fear and survival Fear and anxieties about the future affect us still. People are wracked with self-doubt and low self-esteem. In the struggle to exist and advance in life, a seemingly endless string, of obstacles is encountered, so many, in fact, that any accomplishment seems surprising. liven when people do succeed they are still nagged by uncertainty. Not surprisingly, feelings like doubt, fear, anxiety and pessimism are usually associated with failure. Yet, if properly harnessed, they are the driving force behind success, the very engines of genius. if things turn out well for a long time, there is a further anxiety: that of constantly waiting for something to go wrong. People then find themselves propitiating the gods: not walking on lines on the pavements, performing rituals before public performances, wearing particular clothes and colours so that they can blame the ritual not themselves when things go wrong, But surely the real terror cornea when success continues uninterrupted for such a long period of time that we forget what failure is like! We crave for and are fed a daily diet of anxiety, Horror films and disaster movies have an increasing appeal. Nostradamus pops his head up now and again. And other would-be prophets make a brief appearance, predicting the demise of human kind. Perhaps, this is all just a vestige of the hardships of early man our attempt to recreate the struggles of a past age, as its becomes more and more comfortable. Mankind cannot live by contentment alone. And so, a world awash with anxieties and pessimism has been created. Being optimistic is you struggle. Hut survival dictates that mankind remain ever sanguine.", "hypothesis": "Anxiety in daily life is what we want.", "gold_label": "entailment"}
{"uid": "id_459", "premise": "The population of the United Kingdom is ageing. It has increased from 55.9 million in 1971 to 60.2 million in 2005. That is almost an eight percent increase. However, this change is not spread out evenly across all age groups. In the last thirty or so years, the population aged 65 or over has increased from 13 percent to 16 percent. Within this age group the proportion of the population aged 65 and over and 85 and over increased from 7 percent in the 1970s to 12 percent in 2005. However, the percentage of the population living under the age of 16 has declined from 25 percent in 1971 to 19 percent in 2005. Over the last thirty years, the mean age of the UK population increased from 34.1 years in 1971 to 38.8 in 2005. This ageing is principally due to fertility, although in recent times there has been a decrease in mortality rates, with particular emphasis on older ages.", "hypothesis": "There were more older people than younger people living in 2005", "gold_label": "contradiction"}
{"uid": "id_460", "premise": "The population of the United Kingdom is ageing. It has increased from 55.9 million in 1971 to 60.2 million in 2005. That is almost an eight percent increase. However, this change is not spread out evenly across all age groups. In the last thirty or so years, the population aged 65 or over has increased from 13 percent to 16 percent. Within this age group the proportion of the population aged 65 and over and 85 and over increased from 7 percent in the 1970s to 12 percent in 2005. However, the percentage of the population living under the age of 16 has declined from 25 percent in 1971 to 19 percent in 2005. Over the last thirty years, the mean age of the UK population increased from 34.1 years in 1971 to 38.8 in 2005. This ageing is principally due to fertility, although in recent times there has been a decrease in mortality rates, with particular emphasis on older ages.", "hypothesis": "There has been a population increase of 4.3 million from the 1970s to 2005", "gold_label": "entailment"}
{"uid": "id_461", "premise": "The population of the United Kingdom is ageing. It has increased from 55.9 million in 1971 to 60.2 million in 2005. That is almost an eight percent increase. However, this change is not spread out evenly across all age groups. In the last thirty or so years, the population aged 65 or over has increased from 13 percent to 16 percent. Within this age group the proportion of the population aged 65 and over and 85 and over increased from 7 percent in the 1970s to 12 percent in 2005. However, the percentage of the population living under the age of 16 has declined from 25 percent in 1971 to 19 percent in 2005. Over the last thirty years, the mean age of the UK population increased from 34.1 years in 1971 to 38.8 in 2005. This ageing is principally due to fertility, although in recent times there has been a decrease in mortality rates, with particular emphasis on older ages.", "hypothesis": "Due to the enforcement of the no smoking legislation, it will be up to the organisations to comply by the rules", "gold_label": "neutral"}
{"uid": "id_462", "premise": "The population of the United Kingdom is ageing. It has increased from 55.9 million in 1971 to 60.2 million in 2005. That is almost an eight percent increase. However, this change is not spread out evenly across all age groups. In the last thirty or so years, the population aged 65 or over has increased from 13 percent to 16 percent. Within this age group the proportion of the population aged 65 and over and 85 and over increased from 7 percent in the 1970s to 12 percent in 2005. However, the percentage of the population living under the age of 16 has declined from 25 percent in 1971 to 19 percent in 2005. Over the last thirty years, the mean age of the UK population increased from 34.1 years in 1971 to 38.8 in 2005. This ageing is principally due to fertility, although in recent times there has been a decrease in mortality rates, with particular emphasis on older ages.", "hypothesis": "All individuals seem to be supporting the no smoking policy", "gold_label": "contradiction"}
{"uid": "id_463", "premise": "The population of the United Kingdom is ageing. It has increased from 55.9 million in 1971 to 60.2 million in 2005. That is almost an eight percent increase. However, this change is not spread out evenly across all age groups. In the last thirty or so years, the population aged 65 or over has increased from 13 percent to 16 percent. Within this age group the proportion of the population aged 65 and over and 85 and over increased from 7 percent in the 1970s to 12 percent in 2005. However, the percentage of the population living under the age of 16 has declined from 25 percent in 1971 to 19 percent in 2005. Over the last thirty years, the mean age of the UK population increased from 34.1 years in 1971 to 38.8 in 2005. This ageing is principally due to fertility, although in recent times there has been a decrease in mortality rates, with particular emphasis on older ages.", "hypothesis": "If an individual was to smoke for at least 10 years, they are more likely to suffer from cancer, heart disease, blockage of vessels and so on", "gold_label": "neutral"}
{"uid": "id_464", "premise": "The population of the United Kingdom is ageing. It has increased from 55.9 million in 1971 to 60.2 million in 2005. That is almost an eight percent increase. However, this change is not spread out evenly across all age groups. In the last thirty or so years, the population aged 65 or over has increased from 13 percent to 16 percent. Within this age group the proportion of the population aged 65 and over and 85 and over increased from 7 percent in the 1970s to 12 percent in 2005. However, the percentage of the population living under the age of 16 has declined from 25 percent in 1971 to 19 percent in 2005. Over the last thirty years, the mean age of the UK population increased from 34.1 years in 1971 to 38.8 in 2005. This ageing is principally due to fertility, although in recent times there has been a decrease in mortality rates, with particular emphasis on older ages.", "hypothesis": "Due to the legislation enforced by the government many organisations now have a no smoking policy", "gold_label": "entailment"}
{"uid": "id_465", "premise": "The population of the United Kingdom is ageing. It has increased from 55.9 million in 1971 to 60.2 million in 2005. That is almost an eight percent increase. However, this change is not spread out evenly across all age groups. In the last thirty or so years, the population aged 65 or over has increased from 13 percent to 16 percent. Within this age group the proportion of the population aged 65 and over and 85 and over increased from 7 percent in the 1970s to 12 percent in 2005. However, the percentage of the population living under the age of 16 has declined from 25 percent in 1971 to 19 percent in 2005. Over the last thirty years, the mean age of the UK population increased from 34.1 years in 1971 to 38.8 in 2005. This ageing is principally due to fertility, although in recent times there has been a decrease in mortality rates, with particular emphasis on older ages.", "hypothesis": "Younger people are living much longer as they now have healthy lifestyles", "gold_label": "neutral"}
{"uid": "id_466", "premise": "The population of the United Kingdom is ageing. It has increased from 55.9 million in 1971 to 60.2 million in 2005. That is almost an eight percent increase. However, this change is not spread out evenly across all age groups. In the last thirty or so years, the population aged 65 or over has increased from 13 percent to 16 percent. Within this age group the proportion of the population aged 65 and over and 85 and over increased from 7 percent in the 1970s to 12 percent in 2005. However, the percentage of the population living under the age of 16 has declined from 25 percent in 1971 to 19 percent in 2005. Over the last thirty years, the mean age of the UK population increased from 34.1 years in 1971 to 38.8 in 2005. This ageing is principally due to fertility, although in recent times there has been a decrease in mortality rates, with particular emphasis on older ages.", "hypothesis": "Over the last three decades there has been a decrease in the population aged 65 and over", "gold_label": "contradiction"}
{"uid": "id_467", "premise": "The power of play Virtually every child, the world over, plays. The drive to play is so intense that children will do so in any circumstances, for instance when they have no real toys, or when parents do not actively encourage the behavior. In the eyes of a young child, running, pretending, and building are fun. Researchers and educators know that these playful activities benefit the development of the whole child across social, cognitive, physical, and emotional domains. Indeed, play is such an instrumental component to healthy child development that the United Nations High Commission on Human Rights (1989) recognized play as a fundamental right of every child. Yet, while experts continue to expound a powerful argument for the importance of play in children's lives, the actual time children spend playing continues to decrease. Today, children play eight hours less each week than their counterparts did two decades ago (Elkind 2008). Under pressure of rising academic standards, play is being replaced by test preparation in kindergartens and grade schools, and parents who aim to give their preschoolers a leg up are led to believe that flashcards and educational 'toys' are the path to success. Our society has created a false dichotomy between play and learning. Through play, children learn to regulate their behavior, lay the foundations for later learning in science and mathematics, figure out the complex negotiations of social relationships, build a repertoire of creative problem-solving skills, and so much more. There is also an important role for adults in guiding children through playful learning opportunities. Full consensus on a formal definition of play continues to elude the researchers and theorists who study it. Definitions range from discrete descriptions of various types of play such as physical, construction, language, or symbolic play (Miller & Almon 2009), to lists of broad criteria, based on observations and attitudes, that are meant to capture the essence of all play behaviors (e. g. Rubin et al. 1983). A majority of the contemporary definitions of play focus on several key criteria. The founder of the National Institute for Play, Stuart Brown, has described play as 'anything that spontaneously is done for its own sake'. More specifically, he says it 'appears purposeless, produces pleasure and joy, and leads one to the next stage of mastery' (as quoted in Tippett 2008). Similarly, Miller and Almon (2009) say that play includes 'activities that are freely chosen and directed by children and arise from intrinsic motivation'. Often, play is defined along a continuum as more or less playful using the following set of behavioral and dispositional criteria (e. g. Rubin et al. 1983): Play is pleasurable: Children must enjoy the activity or it is not play. It is intrinsically motivated: Children engage in play simply for the satisfaction the behavior itself brings. It has no extrinsically motivated function or goal. Play is process oriented: When children play, the means are more important than the ends. It is freely chosen, spontaneous and voluntary. If a child is pressured, they will likely not think of the activity as play. Play is actively engaged: Players must be physically and/or mentally involved in the activity. Play is non-literal. It involves make-believe. According to this view, children's playful behaviors can range in degree from 0% to 100% playful. Rubin and colleagues did not assign greater weight to any one dimension in determining playfulness; however, other researchers have suggested that process orientation and a lack of obvious functional purpose may be the most important aspects of play (e. g. Pellegrini 2009). From the perspective of a continuum, play can thus blend with other motives and attitudes that are less playful, such as work. Unlike play, work is typically not viewed as enjoyable and it is extrinsically motivated (i. e. it is goal oriented). Researcher Joan Goodman (1994) suggested that hybrid forms of work and play are not a detriment to learning; rather, they can provide optimal contexts for learning. For example, a child may be engaged in a difficult, goal-directed activity set up by their teacher, but they may still be actively engaged and intrinsically motivated. At this mid-point between play and work, the child's motivation, coupled with guidance from an adult, can create robust opportunities for playful learning. Critically, recent research supports the idea that adults can facilitate children's learning while maintaining a playful approach in interactions known as 'guided play' (Fisher et al. 2011). The adult's role in play varies as a function of their educational goals and the child's developmental level (Hirsch-Pasek et al. 2009). Guided play takes two forms. At a very basic level, adults can enrich the child's environment by providing objects or experiences that promote aspects of a curriculum. In the more direct form of guided play, parents or other adults can support children's play by joining in the fun as a co-player, raising thoughtful questions, commenting on children's discoveries, or encouraging further exploration or new facets to the child's activity. Although playful learning can be somewhat structured, it must also be child-centered (Nicolopolou et al. 2006). Play should stem from the child's own desire. Both free and guided play are essential elements in a child-centered approach to playful learning. Intrinsically motivated free play provides the child with true autonomy, while guided play is an avenue through which parents and educators can provide more targeted learning experiences. In either case, play should be actively engaged, it should be predominantly child-directed, and it must be fun.", "hypothesis": "Work and play differ in terms of whether or not they have a target.", "gold_label": "entailment"}
{"uid": "id_468", "premise": "The power of play Virtually every child, the world over, plays. The drive to play is so intense that children will do so in any circumstances, for instance when they have no real toys, or when parents do not actively encourage the behavior. In the eyes of a young child, running, pretending, and building are fun. Researchers and educators know that these playful activities benefit the development of the whole child across social, cognitive, physical, and emotional domains. Indeed, play is such an instrumental component to healthy child development that the United Nations High Commission on Human Rights (1989) recognized play as a fundamental right of every child. Yet, while experts continue to expound a powerful argument for the importance of play in children's lives, the actual time children spend playing continues to decrease. Today, children play eight hours less each week than their counterparts did two decades ago (Elkind 2008). Under pressure of rising academic standards, play is being replaced by test preparation in kindergartens and grade schools, and parents who aim to give their preschoolers a leg up are led to believe that flashcards and educational 'toys' are the path to success. Our society has created a false dichotomy between play and learning. Through play, children learn to regulate their behavior, lay the foundations for later learning in science and mathematics, figure out the complex negotiations of social relationships, build a repertoire of creative problem-solving skills, and so much more. There is also an important role for adults in guiding children through playful learning opportunities. Full consensus on a formal definition of play continues to elude the researchers and theorists who study it. Definitions range from discrete descriptions of various types of play such as physical, construction, language, or symbolic play (Miller & Almon 2009), to lists of broad criteria, based on observations and attitudes, that are meant to capture the essence of all play behaviors (e. g. Rubin et al. 1983). A majority of the contemporary definitions of play focus on several key criteria. The founder of the National Institute for Play, Stuart Brown, has described play as 'anything that spontaneously is done for its own sake'. More specifically, he says it 'appears purposeless, produces pleasure and joy, and leads one to the next stage of mastery' (as quoted in Tippett 2008). Similarly, Miller and Almon (2009) say that play includes 'activities that are freely chosen and directed by children and arise from intrinsic motivation'. Often, play is defined along a continuum as more or less playful using the following set of behavioral and dispositional criteria (e. g. Rubin et al. 1983): Play is pleasurable: Children must enjoy the activity or it is not play. It is intrinsically motivated: Children engage in play simply for the satisfaction the behavior itself brings. It has no extrinsically motivated function or goal. Play is process oriented: When children play, the means are more important than the ends. It is freely chosen, spontaneous and voluntary. If a child is pressured, they will likely not think of the activity as play. Play is actively engaged: Players must be physically and/or mentally involved in the activity. Play is non-literal. It involves make-believe. According to this view, children's playful behaviors can range in degree from 0% to 100% playful. Rubin and colleagues did not assign greater weight to any one dimension in determining playfulness; however, other researchers have suggested that process orientation and a lack of obvious functional purpose may be the most important aspects of play (e. g. Pellegrini 2009). From the perspective of a continuum, play can thus blend with other motives and attitudes that are less playful, such as work. Unlike play, work is typically not viewed as enjoyable and it is extrinsically motivated (i. e. it is goal oriented). Researcher Joan Goodman (1994) suggested that hybrid forms of work and play are not a detriment to learning; rather, they can provide optimal contexts for learning. For example, a child may be engaged in a difficult, goal-directed activity set up by their teacher, but they may still be actively engaged and intrinsically motivated. At this mid-point between play and work, the child's motivation, coupled with guidance from an adult, can create robust opportunities for playful learning. Critically, recent research supports the idea that adults can facilitate children's learning while maintaining a playful approach in interactions known as 'guided play' (Fisher et al. 2011). The adult's role in play varies as a function of their educational goals and the child's developmental level (Hirsch-Pasek et al. 2009). Guided play takes two forms. At a very basic level, adults can enrich the child's environment by providing objects or experiences that promote aspects of a curriculum. In the more direct form of guided play, parents or other adults can support children's play by joining in the fun as a co-player, raising thoughtful questions, commenting on children's discoveries, or encouraging further exploration or new facets to the child's activity. Although playful learning can be somewhat structured, it must also be child-centered (Nicolopolou et al. 2006). Play should stem from the child's own desire. Both free and guided play are essential elements in a child-centered approach to playful learning. Intrinsically motivated free play provides the child with true autonomy, while guided play is an avenue through which parents and educators can provide more targeted learning experiences. In either case, play should be actively engaged, it should be predominantly child-directed, and it must be fun.", "hypothesis": "Researchers have agreed on a definition of play.", "gold_label": "contradiction"}
{"uid": "id_469", "premise": "The power of play Virtually every child, the world over, plays. The drive to play is so intense that children will do so in any circumstances, for instance when they have no real toys, or when parents do not actively encourage the behavior. In the eyes of a young child, running, pretending, and building are fun. Researchers and educators know that these playful activities benefit the development of the whole child across social, cognitive, physical, and emotional domains. Indeed, play is such an instrumental component to healthy child development that the United Nations High Commission on Human Rights (1989) recognized play as a fundamental right of every child. Yet, while experts continue to expound a powerful argument for the importance of play in children's lives, the actual time children spend playing continues to decrease. Today, children play eight hours less each week than their counterparts did two decades ago (Elkind 2008). Under pressure of rising academic standards, play is being replaced by test preparation in kindergartens and grade schools, and parents who aim to give their preschoolers a leg up are led to believe that flashcards and educational 'toys' are the path to success. Our society has created a false dichotomy between play and learning. Through play, children learn to regulate their behavior, lay the foundations for later learning in science and mathematics, figure out the complex negotiations of social relationships, build a repertoire of creative problem-solving skills, and so much more. There is also an important role for adults in guiding children through playful learning opportunities. Full consensus on a formal definition of play continues to elude the researchers and theorists who study it. Definitions range from discrete descriptions of various types of play such as physical, construction, language, or symbolic play (Miller & Almon 2009), to lists of broad criteria, based on observations and attitudes, that are meant to capture the essence of all play behaviors (e. g. Rubin et al. 1983). A majority of the contemporary definitions of play focus on several key criteria. The founder of the National Institute for Play, Stuart Brown, has described play as 'anything that spontaneously is done for its own sake'. More specifically, he says it 'appears purposeless, produces pleasure and joy, and leads one to the next stage of mastery' (as quoted in Tippett 2008). Similarly, Miller and Almon (2009) say that play includes 'activities that are freely chosen and directed by children and arise from intrinsic motivation'. Often, play is defined along a continuum as more or less playful using the following set of behavioral and dispositional criteria (e. g. Rubin et al. 1983): Play is pleasurable: Children must enjoy the activity or it is not play. It is intrinsically motivated: Children engage in play simply for the satisfaction the behavior itself brings. It has no extrinsically motivated function or goal. Play is process oriented: When children play, the means are more important than the ends. It is freely chosen, spontaneous and voluntary. If a child is pressured, they will likely not think of the activity as play. Play is actively engaged: Players must be physically and/or mentally involved in the activity. Play is non-literal. It involves make-believe. According to this view, children's playful behaviors can range in degree from 0% to 100% playful. Rubin and colleagues did not assign greater weight to any one dimension in determining playfulness; however, other researchers have suggested that process orientation and a lack of obvious functional purpose may be the most important aspects of play (e. g. Pellegrini 2009). From the perspective of a continuum, play can thus blend with other motives and attitudes that are less playful, such as work. Unlike play, work is typically not viewed as enjoyable and it is extrinsically motivated (i. e. it is goal oriented). Researcher Joan Goodman (1994) suggested that hybrid forms of work and play are not a detriment to learning; rather, they can provide optimal contexts for learning. For example, a child may be engaged in a difficult, goal-directed activity set up by their teacher, but they may still be actively engaged and intrinsically motivated. At this mid-point between play and work, the child's motivation, coupled with guidance from an adult, can create robust opportunities for playful learning. Critically, recent research supports the idea that adults can facilitate children's learning while maintaining a playful approach in interactions known as 'guided play' (Fisher et al. 2011). The adult's role in play varies as a function of their educational goals and the child's developmental level (Hirsch-Pasek et al. 2009). Guided play takes two forms. At a very basic level, adults can enrich the child's environment by providing objects or experiences that promote aspects of a curriculum. In the more direct form of guided play, parents or other adults can support children's play by joining in the fun as a co-player, raising thoughtful questions, commenting on children's discoveries, or encouraging further exploration or new facets to the child's activity. Although playful learning can be somewhat structured, it must also be child-centered (Nicolopolou et al. 2006). Play should stem from the child's own desire. Both free and guided play are essential elements in a child-centered approach to playful learning. Intrinsically motivated free play provides the child with true autonomy, while guided play is an avenue through which parents and educators can provide more targeted learning experiences. In either case, play should be actively engaged, it should be predominantly child-directed, and it must be fun.", "hypothesis": "Play helps children to develop their artistic talents.", "gold_label": "neutral"}
{"uid": "id_470", "premise": "The power of play Virtually every child, the world over, plays. The drive to play is so intense that children will do so in any circumstances, for instance when they have no real toys, or when parents do not actively encourage the behavior. In the eyes of a young child, running, pretending, and building are fun. Researchers and educators know that these playful activities benefit the development of the whole child across social, cognitive, physical, and emotional domains. Indeed, play is such an instrumental component to healthy child development that the United Nations High Commission on Human Rights (1989) recognized play as a fundamental right of every child. Yet, while experts continue to expound a powerful argument for the importance of play in children's lives, the actual time children spend playing continues to decrease. Today, children play eight hours less each week than their counterparts did two decades ago (Elkind 2008). Under pressure of rising academic standards, play is being replaced by test preparation in kindergartens and grade schools, and parents who aim to give their preschoolers a leg up are led to believe that flashcards and educational 'toys' are the path to success. Our society has created a false dichotomy between play and learning. Through play, children learn to regulate their behavior, lay the foundations for later learning in science and mathematics, figure out the complex negotiations of social relationships, build a repertoire of creative problem-solving skills, and so much more. There is also an important role for adults in guiding children through playful learning opportunities. Full consensus on a formal definition of play continues to elude the researchers and theorists who study it. Definitions range from discrete descriptions of various types of play such as physical, construction, language, or symbolic play (Miller & Almon 2009), to lists of broad criteria, based on observations and attitudes, that are meant to capture the essence of all play behaviors (e. g. Rubin et al. 1983). A majority of the contemporary definitions of play focus on several key criteria. The founder of the National Institute for Play, Stuart Brown, has described play as 'anything that spontaneously is done for its own sake'. More specifically, he says it 'appears purposeless, produces pleasure and joy, and leads one to the next stage of mastery' (as quoted in Tippett 2008). Similarly, Miller and Almon (2009) say that play includes 'activities that are freely chosen and directed by children and arise from intrinsic motivation'. Often, play is defined along a continuum as more or less playful using the following set of behavioral and dispositional criteria (e. g. Rubin et al. 1983): Play is pleasurable: Children must enjoy the activity or it is not play. It is intrinsically motivated: Children engage in play simply for the satisfaction the behavior itself brings. It has no extrinsically motivated function or goal. Play is process oriented: When children play, the means are more important than the ends. It is freely chosen, spontaneous and voluntary. If a child is pressured, they will likely not think of the activity as play. Play is actively engaged: Players must be physically and/or mentally involved in the activity. Play is non-literal. It involves make-believe. According to this view, children's playful behaviors can range in degree from 0% to 100% playful. Rubin and colleagues did not assign greater weight to any one dimension in determining playfulness; however, other researchers have suggested that process orientation and a lack of obvious functional purpose may be the most important aspects of play (e. g. Pellegrini 2009). From the perspective of a continuum, play can thus blend with other motives and attitudes that are less playful, such as work. Unlike play, work is typically not viewed as enjoyable and it is extrinsically motivated (i. e. it is goal oriented). Researcher Joan Goodman (1994) suggested that hybrid forms of work and play are not a detriment to learning; rather, they can provide optimal contexts for learning. For example, a child may be engaged in a difficult, goal-directed activity set up by their teacher, but they may still be actively engaged and intrinsically motivated. At this mid-point between play and work, the child's motivation, coupled with guidance from an adult, can create robust opportunities for playful learning. Critically, recent research supports the idea that adults can facilitate children's learning while maintaining a playful approach in interactions known as 'guided play' (Fisher et al. 2011). The adult's role in play varies as a function of their educational goals and the child's developmental level (Hirsch-Pasek et al. 2009). Guided play takes two forms. At a very basic level, adults can enrich the child's environment by providing objects or experiences that promote aspects of a curriculum. In the more direct form of guided play, parents or other adults can support children's play by joining in the fun as a co-player, raising thoughtful questions, commenting on children's discoveries, or encouraging further exploration or new facets to the child's activity. Although playful learning can be somewhat structured, it must also be child-centered (Nicolopolou et al. 2006). Play should stem from the child's own desire. Both free and guided play are essential elements in a child-centered approach to playful learning. Intrinsically motivated free play provides the child with true autonomy, while guided play is an avenue through which parents and educators can provide more targeted learning experiences. In either case, play should be actively engaged, it should be predominantly child-directed, and it must be fun.", "hypothesis": "It is a mistake to treat play and learning as separate types of activities.", "gold_label": "entailment"}
{"uid": "id_471", "premise": "The power of play Virtually every child, the world over, plays. The drive to play is so intense that children will do so in any circumstances, for instance when they have no real toys, or when parents do not actively encourage the behavior. In the eyes of a young child, running, pretending, and building are fun. Researchers and educators know that these playful activities benefit the development of the whole child across social, cognitive, physical, and emotional domains. Indeed, play is such an instrumental component to healthy child development that the United Nations High Commission on Human Rights (1989) recognized play as a fundamental right of every child. Yet, while experts continue to expound a powerful argument for the importance of play in children's lives, the actual time children spend playing continues to decrease. Today, children play eight hours less each week than their counterparts did two decades ago (Elkind 2008). Under pressure of rising academic standards, play is being replaced by test preparation in kindergartens and grade schools, and parents who aim to give their preschoolers a leg up are led to believe that flashcards and educational 'toys' are the path to success. Our society has created a false dichotomy between play and learning. Through play, children learn to regulate their behavior, lay the foundations for later learning in science and mathematics, figure out the complex negotiations of social relationships, build a repertoire of creative problem-solving skills, and so much more. There is also an important role for adults in guiding children through playful learning opportunities. Full consensus on a formal definition of play continues to elude the researchers and theorists who study it. Definitions range from discrete descriptions of various types of play such as physical, construction, language, or symbolic play (Miller & Almon 2009), to lists of broad criteria, based on observations and attitudes, that are meant to capture the essence of all play behaviors (e. g. Rubin et al. 1983). A majority of the contemporary definitions of play focus on several key criteria. The founder of the National Institute for Play, Stuart Brown, has described play as 'anything that spontaneously is done for its own sake'. More specifically, he says it 'appears purposeless, produces pleasure and joy, and leads one to the next stage of mastery' (as quoted in Tippett 2008). Similarly, Miller and Almon (2009) say that play includes 'activities that are freely chosen and directed by children and arise from intrinsic motivation'. Often, play is defined along a continuum as more or less playful using the following set of behavioral and dispositional criteria (e. g. Rubin et al. 1983): Play is pleasurable: Children must enjoy the activity or it is not play. It is intrinsically motivated: Children engage in play simply for the satisfaction the behavior itself brings. It has no extrinsically motivated function or goal. Play is process oriented: When children play, the means are more important than the ends. It is freely chosen, spontaneous and voluntary. If a child is pressured, they will likely not think of the activity as play. Play is actively engaged: Players must be physically and/or mentally involved in the activity. Play is non-literal. It involves make-believe. According to this view, children's playful behaviors can range in degree from 0% to 100% playful. Rubin and colleagues did not assign greater weight to any one dimension in determining playfulness; however, other researchers have suggested that process orientation and a lack of obvious functional purpose may be the most important aspects of play (e. g. Pellegrini 2009). From the perspective of a continuum, play can thus blend with other motives and attitudes that are less playful, such as work. Unlike play, work is typically not viewed as enjoyable and it is extrinsically motivated (i. e. it is goal oriented). Researcher Joan Goodman (1994) suggested that hybrid forms of work and play are not a detriment to learning; rather, they can provide optimal contexts for learning. For example, a child may be engaged in a difficult, goal-directed activity set up by their teacher, but they may still be actively engaged and intrinsically motivated. At this mid-point between play and work, the child's motivation, coupled with guidance from an adult, can create robust opportunities for playful learning. Critically, recent research supports the idea that adults can facilitate children's learning while maintaining a playful approach in interactions known as 'guided play' (Fisher et al. 2011). The adult's role in play varies as a function of their educational goals and the child's developmental level (Hirsch-Pasek et al. 2009). Guided play takes two forms. At a very basic level, adults can enrich the child's environment by providing objects or experiences that promote aspects of a curriculum. In the more direct form of guided play, parents or other adults can support children's play by joining in the fun as a co-player, raising thoughtful questions, commenting on children's discoveries, or encouraging further exploration or new facets to the child's activity. Although playful learning can be somewhat structured, it must also be child-centered (Nicolopolou et al. 2006). Play should stem from the child's own desire. Both free and guided play are essential elements in a child-centered approach to playful learning. Intrinsically motivated free play provides the child with true autonomy, while guided play is an avenue through which parents and educators can provide more targeted learning experiences. In either case, play should be actively engaged, it should be predominantly child-directed, and it must be fun.", "hypothesis": "Children need toys in order to play.", "gold_label": "contradiction"}
{"uid": "id_472", "premise": "The price of gold has increased by almost thirty-five percent across the globe over the last year. As a result, previously abandoned gold mines, which were once seen as financially unviable, have been re-opened. An example of this can be seen at the southern Indian state of Karnataka, where companies are re-opening gold mines as even low grade ore becomes valuable. India is currently the largest consumer of gold globally; however, the majority of this demand is currently met by import. Commentators question whether this trend will continue as more and more abandoned mines are re-opened.", "hypothesis": "The majority of Indias demand for gold is met by import", "gold_label": "entailment"}
{"uid": "id_473", "premise": "The price of gold has increased by almost thirty-five percent across the globe over the last year. As a result, previously abandoned gold mines, which were once seen as financially unviable, have been re-opened. An example of this can be seen at the southern Indian state of Karnataka, where companies are re-opening gold mines as even low grade ore becomes valuable. India is currently the largest consumer of gold globally; however, the majority of this demand is currently met by import. Commentators question whether this trend will continue as more and more abandoned mines are re-opened.", "hypothesis": "Indias demand for imported old is increasing", "gold_label": "neutral"}
{"uid": "id_474", "premise": "The price of gold has increased by almost thirty-five percent across the globe over the last year. As a result, previously abandoned gold mines, which were once seen as financially unviable, have been re-opened. An example of this can be seen at the southern Indian state of Karnataka, where companies are re-opening gold mines as even low grade ore becomes valuable. India is currently the largest consumer of gold globally; however, the majority of this demand is currently met by import. Commentators question whether this trend will continue as more and more abandoned mines are re-opened.", "hypothesis": "Indias demand for gold is increasing", "gold_label": "contradiction"}
{"uid": "id_475", "premise": "The prime minister described climate change as the greatest long- term challenge facing the human race. In 1997 he committed Britain to cutting emissions of carbon dioxide by 20 per cent, with 2010 set as the date by which this reduction was to be achieved. This target was beyond the Kyoto target to reduce emis- sions and was self-imposed. Unfortunately, after initial success, progress towards the target slowed then stopped, and since 2002 carbon dioxide emissions have risen slightly. In 2005 the government admitted the obvious by conceding that the 20 per cent by 2010 target would not be realized. Some of the reasons are beyond the governments control. Very high prices for natural gas have in recent years meant that energy companies are switching to burning more and dirtier coal. Economic growth has exceeded expectations and resulted in higher than forecast levels of emissions. The government must also take a share of the blame. There has been a whole raft of reports, recommendations and policies directed at countering the causes of climate change. However, few of these initiatives are aimed at cutting emissions or providing incentives to change polluting behaviour. Instead, they largely fall into the category of raising awareness.", "hypothesis": "The passage states that emissions would be lower than the current level if the British government had adopted more radical policies to counter carbon emissions.", "gold_label": "contradiction"}
{"uid": "id_476", "premise": "The prime minister described climate change as the greatest long- term challenge facing the human race. In 1997 he committed Britain to cutting emissions of carbon dioxide by 20 per cent, with 2010 set as the date by which this reduction was to be achieved. This target was beyond the Kyoto target to reduce emis- sions and was self-imposed. Unfortunately, after initial success, progress towards the target slowed then stopped, and since 2002 carbon dioxide emissions have risen slightly. In 2005 the government admitted the obvious by conceding that the 20 per cent by 2010 target would not be realized. Some of the reasons are beyond the governments control. Very high prices for natural gas have in recent years meant that energy companies are switching to burning more and dirtier coal. Economic growth has exceeded expectations and resulted in higher than forecast levels of emissions. The government must also take a share of the blame. There has been a whole raft of reports, recommendations and policies directed at countering the causes of climate change. However, few of these initiatives are aimed at cutting emissions or providing incentives to change polluting behaviour. Instead, they largely fall into the category of raising awareness.", "hypothesis": "The passage follows events chronologically.", "gold_label": "entailment"}
{"uid": "id_477", "premise": "The prime minister described climate change as the greatest long- term challenge facing the human race. In 1997 he committed Britain to cutting emissions of carbon dioxide by 20 per cent, with 2010 set as the date by which this reduction was to be achieved. This target was beyond the Kyoto target to reduce emis- sions and was self-imposed. Unfortunately, after initial success, progress towards the target slowed then stopped, and since 2002 carbon dioxide emissions have risen slightly. In 2005 the government admitted the obvious by conceding that the 20 per cent by 2010 target would not be realized. Some of the reasons are beyond the governments control. Very high prices for natural gas have in recent years meant that energy companies are switching to burning more and dirtier coal. Economic growth has exceeded expectations and resulted in higher than forecast levels of emissions. The government must also take a share of the blame. There has been a whole raft of reports, recommendations and policies directed at countering the causes of climate change. However, few of these initiatives are aimed at cutting emissions or providing incentives to change polluting behaviour. Instead, they largely fall into the category of raising awareness.", "hypothesis": "Britain will fail to realize its self-imposed target of a 20 per cent reduction by 2010 but will achieve the lower Kyoto target.", "gold_label": "neutral"}
{"uid": "id_478", "premise": "The prime minister recently announced a new plan to kick-start social recovery and troubleshoot dysfunctional families. Under this scheme, the government plans to invest 450 million into families; providing more case workers, probation officers and social workers. While forty percent of the total bill is expected to be provided by central government, the remaining sixty percent is to be provided by local councils. Those in opposition appear sceptical as to the worth of the scheme, highlighting that the funding must be gained by cuts to other key areas. In this way, the prime minister has been accused of taking with one hand while giving with the other.", "hypothesis": "The author means the scheme will be detrimental to families when he refers to the proposed scheme as taking with one hand while giving with the other", "gold_label": "neutral"}
{"uid": "id_479", "premise": "The prime minister recently announced a new plan to kick-start social recovery and troubleshoot dysfunctional families. Under this scheme, the government plans to invest 450 million into families; providing more case workers, probation officers and social workers. While forty percent of the total bill is expected to be provided by central government, the remaining sixty percent is to be provided by local councils. Those in opposition appear sceptical as to the worth of the scheme, highlighting that the funding must be gained by cuts to other key areas. In this way, the prime minister has been accused of taking with one hand while giving with the other.", "hypothesis": "The author means funding for the scheme may come from other areas when he refers to the proposed scheme as taking with one hand while giving with the other", "gold_label": "entailment"}
{"uid": "id_480", "premise": "The prime minister recently announced a new plan to kick-start social recovery and troubleshoot dysfunctional families. Under this scheme, the government plans to invest 450 million into families; providing more case workers, probation officers and social workers. While forty percent of the total bill is expected to be provided by central government, the remaining sixty percent is to be provided by local councils. Those in opposition appear sceptical as to the worth of the scheme, highlighting that the funding must be gained by cuts to other key areas. In this way, the prime minister has been accused of taking with one hand while giving with the other.", "hypothesis": "The author means that only local government will be giving funds, when he refers to the proposed scheme as taking with one hand while giving with the other", "gold_label": "contradiction"}
{"uid": "id_481", "premise": "The prime minister recently announced a new plan to kick-start social recovery and troubleshoot dysfunctional families. Under this scheme, the government plans to invest 450 million into families; providing more case workers, probation officers and social workers. While forty percent of the total bill is expected to be provided by central government, the remaining sixty percent is to be provided by local councils. Those in opposition appear sceptical as to the worth of the scheme, highlighting that the funding must be gained by cuts to other key areas. In this way, the prime minister has been accused of taking with one hand while giving with the other.", "hypothesis": "The author means that funds will come from companies when he refers to the proposed scheme as taking with one hand while giving with the other", "gold_label": "neutral"}
{"uid": "id_482", "premise": "The principal instructed all the teachers to be careful in class because some students may disturb other students.", "hypothesis": "The students will welcome the decision of Principal.", "gold_label": "entailment"}
{"uid": "id_483", "premise": "The principal instructed all the teachers to be careful in class because some students may disturb other students.", "hypothesis": "The teachers will handle the situation properly and they will point out the naughty students", "gold_label": "entailment"}
{"uid": "id_484", "premise": "The problem is not so great with hydroelectric schemes in temperate regions. But, before more hydropower schemes are built in tropical zones, the United Nations wants experts to examine the emissions produced by existing schemes and to recommend ways in which they can be made more environmentally friendly. A lot of the tropical hydropower plants were created by flooding forests, and as drowned plants and trees rot millions of tons of greenhouse gases are released. Despite burning no fossil fuels, the greenhouse emissions from these hydropower plants are higher than comparable fossil fuel-burning power plants. The most polluting hydropower installations are those that were created by the flooding of vast areas of carbon-rich land. These are usually shallow reservoirs, and over the first 10 years of their life it is estimated that they generate four times more greenhouse gases than equivalent modern coal-burning power stations to produce the same power output.", "hypothesis": "You can infer that the United Nations does not think that using the movement of flowing water to drive turbines to generate electricity is necessarily a green source, even though it does not burn fossil fuels.", "gold_label": "entailment"}
{"uid": "id_485", "premise": "The problem is not so great with hydroelectric schemes in temperate regions. But, before more hydropower schemes are built in tropical zones, the United Nations wants experts to examine the emissions produced by existing schemes and to recommend ways in which they can be made more environmentally friendly. A lot of the tropical hydropower plants were created by flooding forests, and as drowned plants and trees rot millions of tons of greenhouse gases are released. Despite burning no fossil fuels, the greenhouse emissions from these hydropower plants are higher than comparable fossil fuel-burning power plants. The most polluting hydropower installations are those that were created by the flooding of vast areas of carbon-rich land. These are usually shallow reservoirs, and over the first 10 years of their life it is estimated that they generate four times more greenhouse gases than equivalent modern coal-burning power stations to produce the same power output.", "hypothesis": "The greenhouse gas that is largely responsible for the problem is methane, produced as the lush vegetation flooded by tropical reservoirs rots.", "gold_label": "neutral"}
{"uid": "id_486", "premise": "The problem is not so great with hydroelectric schemes in temperate regions. But, before more hydropower schemes are built in tropical zones, the United Nations wants experts to examine the emissions produced by existing schemes and to recommend ways in which they can be made more environmentally friendly. A lot of the tropical hydropower plants were created by flooding forests, and as drowned plants and trees rot millions of tons of greenhouse gases are released. Despite burning no fossil fuels, the greenhouse emissions from these hydropower plants are higher than comparable fossil fuel-burning power plants. The most polluting hydropower installations are those that were created by the flooding of vast areas of carbon-rich land. These are usually shallow reservoirs, and over the first 10 years of their life it is estimated that they generate four times more greenhouse gases than equivalent modern coal-burning power stations to produce the same power output.", "hypothesis": "The problem is not so great from hydroelectric schemes in temperate regions because the cooler temperatures mean that much less greenhouse gases are produced.", "gold_label": "neutral"}
{"uid": "id_487", "premise": "The problem with the notion of technology is that there are various meanings of the term. It no longer has a precise and limited meaning, but rather a vague and expansive one. The term is used to describe not only instruments and machines but also skills, methods and procedures, among other things. Some commentators have argued that technology is a factor that determines key facets of organisations. However, others have argued that there is no cause and effect relationship between adoption of the technologies and the structural and performance outcomes that may be associated with them.", "hypothesis": "When people talk about technology they are always referring to machines, such as computers.", "gold_label": "contradiction"}
{"uid": "id_488", "premise": "The problem with the notion of technology is that there are various meanings of the term. It no longer has a precise and limited meaning, but rather a vague and expansive one. The term is used to describe not only instruments and machines but also skills, methods and procedures, among other things. Some commentators have argued that technology is a factor that determines key facets of organisations. However, others have argued that there is no cause and effect relationship between adoption of the technologies and the structural and performance outcomes that may be associated with them.", "hypothesis": "Everyone agrees with the single definition of technology.", "gold_label": "contradiction"}
{"uid": "id_489", "premise": "The problem with the notion of technology is that there are various meanings of the term. It no longer has a precise and limited meaning, but rather a vague and expansive one. The term is used to describe not only instruments and machines but also skills, methods and procedures, among other things. Some commentators have argued that technology is a factor that determines key facets of organisations. However, others have argued that there is no cause and effect relationship between adoption of the technologies and the structural and performance outcomes that may be associated with them.", "hypothesis": "Some people have argued that technology is a determining factor in a number of key areas of an organisation.", "gold_label": "entailment"}
{"uid": "id_490", "premise": "The product X that you have asked for is not with us but can be made available against firm order form you", "hypothesis": "The product X is not in great demand", "gold_label": "entailment"}
{"uid": "id_491", "premise": "The product X that you have asked for is not with us but can be made available against firm order form you", "hypothesis": "The product X is out of stock as new model is coming up.", "gold_label": "neutral"}
{"uid": "id_492", "premise": "The production of organic food products supplied in food stores continues to increase considerably with demand particularly high in Europe and North America. Health awareness and higher standards of living are both enhancing consumption and the market is likely to triple over the next decade. The organic food industry is facing the challenge of how it will cope with the forecasted future demand.", "hypothesis": "Food stores in Europe and North America have increased their production of organic food products, due to an increased demand.", "gold_label": "neutral"}
{"uid": "id_493", "premise": "The production of organic food products supplied in food stores continues to increase considerably with demand particularly high in Europe and North America. Health awareness and higher standards of living are both enhancing consumption and the market is likely to triple over the next decade. The organic food industry is facing the challenge of how it will cope with the forecasted future demand.", "hypothesis": "Organic food production is the fastest growing field in the food industry.", "gold_label": "neutral"}
{"uid": "id_494", "premise": "The production of organic food products supplied in food stores continues to increase considerably with demand particularly high in Europe and North America. Health awareness and higher standards of living are both enhancing consumption and the market is likely to triple over the next decade. The organic food industry is facing the challenge of how it will cope with the forecasted future demand.", "hypothesis": "The main cause of enhanced organic food consumption is the higher general standard of living.", "gold_label": "neutral"}
{"uid": "id_495", "premise": "The project of the road construction (work) has crossed its first deadline as far as pre-monsoon road work are concerned. In the major city the road works are given great emphasis and these are the places where road work has been completed.", "hypothesis": "It takes several hours travelling via these roads.", "gold_label": "contradiction"}
{"uid": "id_496", "premise": "The project of the road construction (work) has crossed its first deadline as far as pre-monsoon road work are concerned. In the major city the road works are given great emphasis and these are the places where road work has been completed.", "hypothesis": "The work of the road is going on", "gold_label": "entailment"}
{"uid": "id_497", "premise": "The project of the road construction (work) has crossed its first deadline as far as pre-monsoon road work are concerned. In the major city the road works are given great emphasis and these are the places where road work has been completed.", "hypothesis": "They will start the road works well in advance", "gold_label": "contradiction"}
{"uid": "id_498", "premise": "The project of the road construction (work) has crossed its first deadline as far as pre-monsoon road work are concerned. In the major city the road works are given great emphasis and these are the places where road work has been completed.", "hypothesis": "To start the work of the road one has to go through a lot of tiresome paperwork before starting the repair work which delays the whole work of the road.", "gold_label": "contradiction"}
{"uid": "id_499", "premise": "The project was ambitious in its size, complexity, triparty nature, and in its pioneering of the Private Finance Initiative. This difficulty was unavoidable and contributed to the projects failure. However, a more prudent estimation of the unknown difficulties and timescales would have enabled the Department to better prepare for the project, and increase its chance of success. In December 1997 XSoft indicated they needed more time to complete the project, which should have been inevitable. If the Department knew from the start how long the project would take, it is questionable whether they would have considered inception; especially considering the implications of delay on overall profitability for the venture.", "hypothesis": "XSoft witheld information from the Department regarding how long the project would take.", "gold_label": "neutral"}
{"uid": "id_500", "premise": "The project was ambitious in its size, complexity, triparty nature, and in its pioneering of the Private Finance Initiative. This difficulty was unavoidable and contributed to the projects failure. However, a more prudent estimation of the unknown difficulties and timescales would have enabled the Department to better prepare for the project, and increase its chance of success. In December 1997 XSoft indicated they needed more time to complete the project, which should have been inevitable. If the Department knew from the start how long the project would take, it is questionable whether they would have considered inception; especially considering the implications of delay on overall profitability for the venture.", "hypothesis": "If more care had been put into estimating the difficulties, it is less likely the project would have failed.", "gold_label": "entailment"}
{"uid": "id_501", "premise": "The project was ambitious in its size, complexity, triparty nature, and in its pioneering of the Private Finance Initiative. This difficulty was unavoidable and contributed to the projects failure. However, a more prudent estimation of the unknown difficulties and timescales would have enabled the Department to better prepare for the project, and increase its chance of success. In December 1997 XSoft indicated they needed more time to complete the project, which should have been inevitable. If the Department knew from the start how long the project would take, it is questionable whether they would have considered inception; especially considering the implications of delay on overall profitability for the venture.", "hypothesis": "The Departments profits were dependent upon how long the project took.", "gold_label": "entailment"}
{"uid": "id_502", "premise": "The project was ambitious in its size, complexity, triparty nature, and in its pioneering of the Private Finance Initiative. This difficulty was unavoidable and contributed to the projects failure. However, a more thorough estimate of the unknown difficulties and timescales would have enabled the Department to better prepare for the project, and increase its chance of success. In December 1997 XSoft indicated they needed time to complete the project, which should have been inevitable. If the Department knew from the start how long the project would take, it is questionable whether they would have considered inception, especially considering the implications of delay on the overall profitability for the venture.", "hypothesis": "If more care had been put into estimating the difficulties, it is less likely the project would have failed.", "gold_label": "entailment"}
{"uid": "id_503", "premise": "The project was ambitious in its size, complexity, triparty nature, and in its pioneering of the Private Finance Initiative. This difficulty was unavoidable and contributed to the projects failure. However, a more thorough estimate of the unknown difficulties and timescales would have enabled the Department to better prepare for the project, and increase its chance of success. In December 1997 XSoft indicated they needed time to complete the project, which should have been inevitable. If the Department knew from the start how long the project would take, it is questionable whether they would have considered inception, especially considering the implications of delay on the overall profitability for the venture.", "hypothesis": "XSoft withheld information from the Department regarding how long the project would take.", "gold_label": "neutral"}
{"uid": "id_504", "premise": "The project was ambitious in its size, complexity, triparty nature, and in its pioneering of the Private Finance Initiative. This difficulty was unavoidable and contributed to the projects failure. However, a more thorough estimate of the unknown difficulties and timescales would have enabled the Department to better prepare for the project, and increase its chance of success. In December 1997 XSoft indicated they needed time to complete the project, which should have been inevitable. If the Department knew from the start how long the project would take, it is questionable whether they would have considered inception, especially considering the implications of delay on the overall profitability for the venture.", "hypothesis": "The Departments profits were dependent upon how long the project took.", "gold_label": "entailment"}
{"uid": "id_505", "premise": "The prospect of accepting negative feedback about ourselves elicits conflict, as we need to assess the immediate emotional costs of negative information about ourselves against the long-term benefits of gaining useful feedback. Studies have confirmed what most managers seem to have known already, that the mood we in whilst receiving feedback often influences the relative weight people assign to emotional costs versus the informational benefits of receiving negative feedback. The studies that have been carried out have demonstrated that positive moods can function as a buffer and therefore enable people affected in this way to both accept, as well as better handle, the emotional costs of negative self-related information.", "hypothesis": "Accepting negative feedback involves a trade; off between short; term and long; term costs and benefits.", "gold_label": "entailment"}
{"uid": "id_506", "premise": "The prospect of accepting negative feedback about ourselves elicits conflict, as we need to assess the immediate emotional costs of negative information about ourselves against the long-term benefits of gaining useful feedback. Studies have confirmed what most managers seem to have known already, that the mood we in whilst receiving feedback often influences the relative weight people assign to emotional costs versus the informational benefits of receiving negative feedback. The studies that have been carried out have demonstrated that positive moods can function as a buffer and therefore enable people affected in this way to both accept, as well as better handle, the emotional costs of negative self-related information.", "hypothesis": "An individuals mood will have no effect on how negative feedback is received.", "gold_label": "contradiction"}
{"uid": "id_507", "premise": "The prospect of accepting negative feedback about ourselves elicits conflict, as we need to assess the immediate emotional costs of negative information about ourselves against the long-term benefits of gaining useful feedback. Studies have confirmed what most managers seem to have known already, that the mood we in whilst receiving feedback often influences the relative weight people assign to emotional costs versus the informational benefits of receiving negative feedback. The studies that have been carried out have demonstrated that positive moods can function as a buffer and therefore enable people affected in this way to both accept, as well as better handle, the emotional costs of negative self-related information.", "hypothesis": "A positive mood enhances the perception of there being long-term benefits associated with receiving negative feedback.", "gold_label": "neutral"}
{"uid": "id_508", "premise": "The prospect of accepting negative feedback about ourselves elicits conflict, as we need to assess the immediate emotional costs of negative information about ourselves against the long-term benefits of gaining useful feedback. Studies have confirmed what most managers seem to have known already, that the mood we in whilst receiving feedback often influences the relative weight people assign to emotional costs versus the informational benefits of receiving negative feedback. The studies that have been carried out have demonstrated that positive moods can function as a buffer and therefore enable people affected in this way to both accept, as well as better handle, the emotional costs of negative self-related information.", "hypothesis": "Accepting negative feedback involves a trade-off between short-term and long-term costs and benefits.", "gold_label": "entailment"}
{"uid": "id_509", "premise": "The prospect of accepting negative feedback about ourselves elicits conflict, as we need to assess the immediate emotional costs of negative information about ourselves against the long-term benefits of gaining useful feedback. Studies have confirmed what most managers seem to have known already, that the mood we in whilst receiving feedback often influences the relative weight people assign to emotional costs versus the informational benefits of receiving negative feedback. The studies that have been carried out have demonstrated that positive moods can function as a buffer and therefore enable people affected in this way to both accept, as well as better handle, the emotional costs of negative self-related information.", "hypothesis": "Managers are increasingly taking employees moods into consideration when providing them with negative feedback regarding their performance.", "gold_label": "neutral"}
{"uid": "id_510", "premise": "The prudence rule, which is sometimes known as conservatism, arises out of the need to make a number of estimates in preparing periodic accounts. Managers and owners are often naturally over-optimistic about future events. As a result, there is a tendency to be too confident about the future, and not to be altogether realistic about the organisation s prospects. There may, for example, be undue optimism over the credit-worthiness of new customers. Insufficient allowance may therefore be made for the possibility of bad debt. In turn, this might have the effect of overstating profit.", "hypothesis": "Accountants should avoid making estimates when preparing periodic accounts.", "gold_label": "neutral"}
{"uid": "id_511", "premise": "The prudence rule, which is sometimes known as conservatism, arises out of the need to make a number of estimates in preparing periodic accounts. Managers and owners are often naturally over-optimistic about future events. As a result, there is a tendency to be too confident about the future, and not to be altogether realistic about the organisation s prospects. There may, for example, be undue optimism over the credit-worthiness of new customers. Insufficient allowance may therefore be made for the possibility of bad debt. In turn, this might have the effect of overstating profit.", "hypothesis": "Most new customers are credit-worthy.", "gold_label": "neutral"}
{"uid": "id_512", "premise": "The prudence rule, which is sometimes known as conservatism, arises out of the need to make a number of estimates in preparing periodic accounts. Managers and owners are often naturally over-optimistic about future events. As a result, there is a tendency to be too confident about the future, and not to be altogether realistic about the organisation s prospects. There may, for example, be undue optimism over the credit-worthiness of new customers. Insufficient allowance may therefore be made for the possibility of bad debt. In turn, this might have the effect of overstating profit.", "hypothesis": "Managers or owners are not often good judges of their customers willingness or ability to pay.", "gold_label": "entailment"}
{"uid": "id_513", "premise": "The prudence rule, which is sometimes known as conservatism, arises out of the need to make a number of estimates in preparing periodic accounts. Managers and owners are often naturally over-optimistic about future events. As a result, there is a tendency to be too confident about the future, and not to be altogether realistic about the organisation s prospects. There may, for example, be undue optimism over the credit-worthiness of new customers. Insufficient allowance may therefore be made for the possibility of bad debt. In turn, this might have the effect of overstating profit.", "hypothesis": "The prudence rule prevents bad debt from arising.", "gold_label": "contradiction"}
{"uid": "id_514", "premise": "The prudence rule, which is sometimes known as conservatism, arises out of the need to make a number of estimates in preparing periodic accounts. Managers and owners are often naturally over-optimistic about future events. As a result, there is a tendency to be too confident about the future, and not to be altogether realistic about the organizations prospects. There may, for example, be undue optimism over the credit-worthiness of new customers. Insufficient allowance may therefore be made for the possibility of bad debt. In turn, this might have the effect of overstating profit.", "hypothesis": "Most new customers are credit-worthy.", "gold_label": "neutral"}
{"uid": "id_515", "premise": "The prudence rule, which is sometimes known as conservatism, arises out of the need to make a number of estimates in preparing periodic accounts. Managers and owners are often naturally over-optimistic about future events. As a result, there is a tendency to be too confident about the future, and not to be altogether realistic about the organizations prospects. There may, for example, be undue optimism over the credit-worthiness of new customers. Insufficient allowance may therefore be made for the possibility of bad debt. In turn, this might have the effect of overstating profit.", "hypothesis": "managers or owners are not often good judges of their customers willingness or ability to pay.", "gold_label": "entailment"}
{"uid": "id_516", "premise": "The prudence rule, which is sometimes known as conservatism, arises out of the need to make a number of estimates in preparing periodic accounts. Managers and owners are often naturally over-optimistic about future events. As a result, there is a tendency to be too confident about the future, and not to be altogether realistic about the organizations prospects. There may, for example, be undue optimism over the credit-worthiness of new customers. Insufficient allowance may therefore be made for the possibility of bad debt. In turn, this might have the effect of overstating profit.", "hypothesis": "The prudence rule prevents bad debt from arising.", "gold_label": "contradiction"}
{"uid": "id_517", "premise": "The prudence rule, which is sometimes known as conservatism, arises out of the need to make a number of estimates in preparing periodic accounts. Managers and owners are often naturally over-optimistic about future events. As a result, there is a tendency to be too confident about the future, and not to be altogether realistic about the organizations prospects. There may, for example, be undue optimism over the credit-worthiness of new customers. Insufficient allowance may therefore be made for the possibility of bad debt. In turn, this might have the effect of overstating profit.", "hypothesis": "Accountants should avoid making estimates when preparing periodic account.", "gold_label": "neutral"}
{"uid": "id_518", "premise": "The psychology of innovation Why are so few companies truly innovative? Innovation is key to business survival, and companies put substantial resources into inspiring employees to develop new ideas. There are, nevertheless, people working in luxurious, state-of-the-art centres designed to stimulate innovation who find that their environment doesnt make them feel at all creative. And there are those who dont have a budget, or much space, but who innovate successfully. For Robert B. Cialdini, Professor of Psychology at Arizona State University, one reason that companies dont succeed as often as they should is that innovation starts with recruitment. Research shows that the fit between an employees values and a companys values makes a difference to what contribution they make and whether, two years after they join, theyre still at the company. Studies at Harvard Business School show that, although some individuals may be more creative than others, almost every individual can be creative in the right circumstances. One of the most famous photographs in the story of rocknroll emphasises Ciaidinis views. The 1956 picture of singers Elvis Presley, Carl Perkins, Johnny Cash and Jerry Lee Lewis jamming at a piano in Sun Studios in Memphis tells a hidden story. Suns million-dollar quartet could have been a quintet. Missing from the picture is Roy Orbison a greater natural singer than Lewis, Perkins or Cash. Sam Phillips, who owned Sun, wanted to revolutionise popular music with songs that fused black and white music, and country and blues. Presley, Cash, Perkins and Lewis instinctively understood Phillipss ambition and believed in it. Orbison wasnt inspired by the goal, and only ever achieved one hit with the Sun label. The value fit matters, says Cialdini, because innovation is, in part, a process of change, and under that pressure we, as a species, behave differently, When things change, we are hard-wired to play it safe. Managers should therefore adopt an approach that appears counterintuitive -they should explain what stands to be lost if the company fails to seize a particular opportunity. Studies show that we invariably take more gambles when threatened with a loss than when offered a reward. Managing innovation is a delicate art. Its easy for a company to be pulled in conflicting directions as the marketing, product development, and finance departments each get different feedback from different sets of people. And without a system which ensures collaborative exchanges within the company, its also easy for small pockets of innovation to disappear. Innovation is a contact sport. You cant brief people just by saying, Were going in this direction and Im going to take you with me. Cialdini believes that this follow-the-leader syndrome, is dangerous, not least because it encourages bosses to go it alone. Its been scientifically proven that three people will be better than one at solving problems, even if that one person is the smartest person in the field. To prove his point, Cialdini cites an interview with molecular biologist James Watson. Watson, together with Francis Crick, discovered the structure of DNA, the genetic information carrier of all living organisms. When asked how they had cracked the code ahead of an array of highly accomplished rival investigators, he said something that stunned me. He said he and Crick had succeeded because they were aware that they werent the most intelligent of the scientists pursuing the answer. The smartest scientist was called Rosalind Franklin who, Watson said, was so intelligent she rarely sought advice. Teamwork taps into one of the basic drivers of human behaviour. The principle of social proof is so pervasive that we dont even recognise it, says Cialdini. If your project is being resisted, for example, by a group of veteran employees, ask another old-timer to speak up for it. Cialdini is not alone in advocating this strategy. Research shows that peer power, used horizontally not vertically, is much more powerful than any bosss speech. 76Writing, visualising and prototyping can stimulate the flow of new ideas. Cialdini cites scores of research papers and historical events that prove that even something as simple as writing deepens every individuals engagement in the project. It is, he says, the reason why all those competitions on breakfast cereal packets encouraged us to write in saying, in no more than 10 words: I like Kelloggs Com Flakes because... . The very act of writing makes us more likely to believe it. Authority doesnt have to inhibit innovation but it often does. The wrong kind of leadership will lead to what Cialdini calls captainitis, the regrettable tendency of team members to opt out of team responsibilities that are properly their. He calls it captainitis because, he says, crew members of multipilot aircraft exhibit a sometimes deadly passivity when the flight captain makes a clearly wrong-headed decision. This behaviour is not, he says, unique to air travel, but can happen in any workplace where the leader is overbearing. At the other end of the scale is the 1980s Memphis design collective, a group of young designers for whom the only rule was that there were no rule. This environment encouraged a free interchange of ideas, which led to more creativity with form, function, colour and materials that revolutionised attitudes to furniture design. Many theorists believe the ideal boss should lead from behind, taking pride in collective accomplishment and giving credit where it is due. Cialdini says: Leaders should encourage everyone to contribute and simultaneously assure all concerned that every recommendation is important to making the right decision and will be given full attention The frustrating thing about innovation is that there are many approaches, but no magic formula. However, a manager who wants to create a truly innovative culture can make their job a lot easier by recognising these psychological realities.", "hypothesis": "A managers approval of an idea is more persuasive than that of a colleague.", "gold_label": "contradiction"}
{"uid": "id_519", "premise": "The psychology of innovation Why are so few companies truly innovative? Innovation is key to business survival, and companies put substantial resources into inspiring employees to develop new ideas. There are, nevertheless, people working in luxurious, state-of-the-art centres designed to stimulate innovation who find that their environment doesnt make them feel at all creative. And there are those who dont have a budget, or much space, but who innovate successfully. For Robert B. Cialdini, Professor of Psychology at Arizona State University, one reason that companies dont succeed as often as they should is that innovation starts with recruitment. Research shows that the fit between an employees values and a companys values makes a difference to what contribution they make and whether, two years after they join, theyre still at the company. Studies at Harvard Business School show that, although some individuals may be more creative than others, almost every individual can be creative in the right circumstances. One of the most famous photographs in the story of rocknroll emphasises Ciaidinis views. The 1956 picture of singers Elvis Presley, Carl Perkins, Johnny Cash and Jerry Lee Lewis jamming at a piano in Sun Studios in Memphis tells a hidden story. Suns million-dollar quartet could have been a quintet. Missing from the picture is Roy Orbison a greater natural singer than Lewis, Perkins or Cash. Sam Phillips, who owned Sun, wanted to revolutionise popular music with songs that fused black and white music, and country and blues. Presley, Cash, Perkins and Lewis instinctively understood Phillipss ambition and believed in it. Orbison wasnt inspired by the goal, and only ever achieved one hit with the Sun label. The value fit matters, says Cialdini, because innovation is, in part, a process of change, and under that pressure we, as a species, behave differently, When things change, we are hard-wired to play it safe. Managers should therefore adopt an approach that appears counterintuitive -they should explain what stands to be lost if the company fails to seize a particular opportunity. Studies show that we invariably take more gambles when threatened with a loss than when offered a reward. Managing innovation is a delicate art. Its easy for a company to be pulled in conflicting directions as the marketing, product development, and finance departments each get different feedback from different sets of people. And without a system which ensures collaborative exchanges within the company, its also easy for small pockets of innovation to disappear. Innovation is a contact sport. You cant brief people just by saying, Were going in this direction and Im going to take you with me. Cialdini believes that this follow-the-leader syndrome, is dangerous, not least because it encourages bosses to go it alone. Its been scientifically proven that three people will be better than one at solving problems, even if that one person is the smartest person in the field. To prove his point, Cialdini cites an interview with molecular biologist James Watson. Watson, together with Francis Crick, discovered the structure of DNA, the genetic information carrier of all living organisms. When asked how they had cracked the code ahead of an array of highly accomplished rival investigators, he said something that stunned me. He said he and Crick had succeeded because they were aware that they werent the most intelligent of the scientists pursuing the answer. The smartest scientist was called Rosalind Franklin who, Watson said, was so intelligent she rarely sought advice. Teamwork taps into one of the basic drivers of human behaviour. The principle of social proof is so pervasive that we dont even recognise it, says Cialdini. If your project is being resisted, for example, by a group of veteran employees, ask another old-timer to speak up for it. Cialdini is not alone in advocating this strategy. Research shows that peer power, used horizontally not vertically, is much more powerful than any bosss speech. 76Writing, visualising and prototyping can stimulate the flow of new ideas. Cialdini cites scores of research papers and historical events that prove that even something as simple as writing deepens every individuals engagement in the project. It is, he says, the reason why all those competitions on breakfast cereal packets encouraged us to write in saying, in no more than 10 words: I like Kelloggs Com Flakes because... . The very act of writing makes us more likely to believe it. Authority doesnt have to inhibit innovation but it often does. The wrong kind of leadership will lead to what Cialdini calls captainitis, the regrettable tendency of team members to opt out of team responsibilities that are properly their. He calls it captainitis because, he says, crew members of multipilot aircraft exhibit a sometimes deadly passivity when the flight captain makes a clearly wrong-headed decision. This behaviour is not, he says, unique to air travel, but can happen in any workplace where the leader is overbearing. At the other end of the scale is the 1980s Memphis design collective, a group of young designers for whom the only rule was that there were no rule. This environment encouraged a free interchange of ideas, which led to more creativity with form, function, colour and materials that revolutionised attitudes to furniture design. Many theorists believe the ideal boss should lead from behind, taking pride in collective accomplishment and giving credit where it is due. Cialdini says: Leaders should encourage everyone to contribute and simultaneously assure all concerned that every recommendation is important to making the right decision and will be given full attention The frustrating thing about innovation is that there are many approaches, but no magic formula. However, a manager who wants to create a truly innovative culture can make their job a lot easier by recognising these psychological realities.", "hypothesis": "The physical surroundings in which a person works play a key role in determining their creativity.", "gold_label": "contradiction"}
{"uid": "id_520", "premise": "The psychology of innovation Why are so few companies truly innovative? Innovation is key to business survival, and companies put substantial resources into inspiring employees to develop new ideas. There are, nevertheless, people working in luxurious, state-of-the-art centres designed to stimulate innovation who find that their environment doesnt make them feel at all creative. And there are those who dont have a budget, or much space, but who innovate successfully. For Robert B. Cialdini, Professor of Psychology at Arizona State University, one reason that companies dont succeed as often as they should is that innovation starts with recruitment. Research shows that the fit between an employees values and a companys values makes a difference to what contribution they make and whether, two years after they join, theyre still at the company. Studies at Harvard Business School show that, although some individuals may be more creative than others, almost every individual can be creative in the right circumstances. One of the most famous photographs in the story of rocknroll emphasises Ciaidinis views. The 1956 picture of singers Elvis Presley, Carl Perkins, Johnny Cash and Jerry Lee Lewis jamming at a piano in Sun Studios in Memphis tells a hidden story. Suns million-dollar quartet could have been a quintet. Missing from the picture is Roy Orbison a greater natural singer than Lewis, Perkins or Cash. Sam Phillips, who owned Sun, wanted to revolutionise popular music with songs that fused black and white music, and country and blues. Presley, Cash, Perkins and Lewis instinctively understood Phillipss ambition and believed in it. Orbison wasnt inspired by the goal, and only ever achieved one hit with the Sun label. The value fit matters, says Cialdini, because innovation is, in part, a process of change, and under that pressure we, as a species, behave differently, When things change, we are hard-wired to play it safe. Managers should therefore adopt an approach that appears counterintuitive -they should explain what stands to be lost if the company fails to seize a particular opportunity. Studies show that we invariably take more gambles when threatened with a loss than when offered a reward. Managing innovation is a delicate art. Its easy for a company to be pulled in conflicting directions as the marketing, product development, and finance departments each get different feedback from different sets of people. And without a system which ensures collaborative exchanges within the company, its also easy for small pockets of innovation to disappear. Innovation is a contact sport. You cant brief people just by saying, Were going in this direction and Im going to take you with me. Cialdini believes that this follow-the-leader syndrome, is dangerous, not least because it encourages bosses to go it alone. Its been scientifically proven that three people will be better than one at solving problems, even if that one person is the smartest person in the field. To prove his point, Cialdini cites an interview with molecular biologist James Watson. Watson, together with Francis Crick, discovered the structure of DNA, the genetic information carrier of all living organisms. When asked how they had cracked the code ahead of an array of highly accomplished rival investigators, he said something that stunned me. He said he and Crick had succeeded because they were aware that they werent the most intelligent of the scientists pursuing the answer. The smartest scientist was called Rosalind Franklin who, Watson said, was so intelligent she rarely sought advice. Teamwork taps into one of the basic drivers of human behaviour. The principle of social proof is so pervasive that we dont even recognise it, says Cialdini. If your project is being resisted, for example, by a group of veteran employees, ask another old-timer to speak up for it. Cialdini is not alone in advocating this strategy. Research shows that peer power, used horizontally not vertically, is much more powerful than any bosss speech. 76Writing, visualising and prototyping can stimulate the flow of new ideas. Cialdini cites scores of research papers and historical events that prove that even something as simple as writing deepens every individuals engagement in the project. It is, he says, the reason why all those competitions on breakfast cereal packets encouraged us to write in saying, in no more than 10 words: I like Kelloggs Com Flakes because... . The very act of writing makes us more likely to believe it. Authority doesnt have to inhibit innovation but it often does. The wrong kind of leadership will lead to what Cialdini calls captainitis, the regrettable tendency of team members to opt out of team responsibilities that are properly their. He calls it captainitis because, he says, crew members of multipilot aircraft exhibit a sometimes deadly passivity when the flight captain makes a clearly wrong-headed decision. This behaviour is not, he says, unique to air travel, but can happen in any workplace where the leader is overbearing. At the other end of the scale is the 1980s Memphis design collective, a group of young designers for whom the only rule was that there were no rule. This environment encouraged a free interchange of ideas, which led to more creativity with form, function, colour and materials that revolutionised attitudes to furniture design. Many theorists believe the ideal boss should lead from behind, taking pride in collective accomplishment and giving credit where it is due. Cialdini says: Leaders should encourage everyone to contribute and simultaneously assure all concerned that every recommendation is important to making the right decision and will be given full attention The frustrating thing about innovation is that there are many approaches, but no magic formula. However, a manager who wants to create a truly innovative culture can make their job a lot easier by recognising these psychological realities.", "hypothesis": "It is easier for smaller companies to be innovative.", "gold_label": "neutral"}
{"uid": "id_521", "premise": "The psychology of innovation Why are so few companies truly innovative? Innovation is key to business survival, and companies put substantial resources into inspiring employees to develop new ideas. There are, nevertheless, people working in luxurious, state-of-the-art centres designed to stimulate innovation who find that their environment doesnt make them feel at all creative. And there are those who dont have a budget, or much space, but who innovate successfully. For Robert B. Cialdini, Professor of Psychology at Arizona State University, one reason that companies dont succeed as often as they should is that innovation starts with recruitment. Research shows that the fit between an employees values and a companys values makes a difference to what contribution they make and whether, two years after they join, theyre still at the company. Studies at Harvard Business School show that, although some individuals may be more creative than others, almost every individual can be creative in the right circumstances. One of the most famous photographs in the story of rocknroll emphasises Ciaidinis views. The 1956 picture of singers Elvis Presley, Carl Perkins, Johnny Cash and Jerry Lee Lewis jamming at a piano in Sun Studios in Memphis tells a hidden story. Suns million-dollar quartet could have been a quintet. Missing from the picture is Roy Orbison a greater natural singer than Lewis, Perkins or Cash. Sam Phillips, who owned Sun, wanted to revolutionise popular music with songs that fused black and white music, and country and blues. Presley, Cash, Perkins and Lewis instinctively understood Phillipss ambition and believed in it. Orbison wasnt inspired by the goal, and only ever achieved one hit with the Sun label. The value fit matters, says Cialdini, because innovation is, in part, a process of change, and under that pressure we, as a species, behave differently, When things change, we are hard-wired to play it safe. Managers should therefore adopt an approach that appears counterintuitive -they should explain what stands to be lost if the company fails to seize a particular opportunity. Studies show that we invariably take more gambles when threatened with a loss than when offered a reward. Managing innovation is a delicate art. Its easy for a company to be pulled in conflicting directions as the marketing, product development, and finance departments each get different feedback from different sets of people. And without a system which ensures collaborative exchanges within the company, its also easy for small pockets of innovation to disappear. Innovation is a contact sport. You cant brief people just by saying, Were going in this direction and Im going to take you with me. Cialdini believes that this follow-the-leader syndrome, is dangerous, not least because it encourages bosses to go it alone. Its been scientifically proven that three people will be better than one at solving problems, even if that one person is the smartest person in the field. To prove his point, Cialdini cites an interview with molecular biologist James Watson. Watson, together with Francis Crick, discovered the structure of DNA, the genetic information carrier of all living organisms. When asked how they had cracked the code ahead of an array of highly accomplished rival investigators, he said something that stunned me. He said he and Crick had succeeded because they were aware that they werent the most intelligent of the scientists pursuing the answer. The smartest scientist was called Rosalind Franklin who, Watson said, was so intelligent she rarely sought advice. Teamwork taps into one of the basic drivers of human behaviour. The principle of social proof is so pervasive that we dont even recognise it, says Cialdini. If your project is being resisted, for example, by a group of veteran employees, ask another old-timer to speak up for it. Cialdini is not alone in advocating this strategy. Research shows that peer power, used horizontally not vertically, is much more powerful than any bosss speech. 76Writing, visualising and prototyping can stimulate the flow of new ideas. Cialdini cites scores of research papers and historical events that prove that even something as simple as writing deepens every individuals engagement in the project. It is, he says, the reason why all those competitions on breakfast cereal packets encouraged us to write in saying, in no more than 10 words: I like Kelloggs Com Flakes because... . The very act of writing makes us more likely to believe it. Authority doesnt have to inhibit innovation but it often does. The wrong kind of leadership will lead to what Cialdini calls captainitis, the regrettable tendency of team members to opt out of team responsibilities that are properly their. He calls it captainitis because, he says, crew members of multipilot aircraft exhibit a sometimes deadly passivity when the flight captain makes a clearly wrong-headed decision. This behaviour is not, he says, unique to air travel, but can happen in any workplace where the leader is overbearing. At the other end of the scale is the 1980s Memphis design collective, a group of young designers for whom the only rule was that there were no rule. This environment encouraged a free interchange of ideas, which led to more creativity with form, function, colour and materials that revolutionised attitudes to furniture design. Many theorists believe the ideal boss should lead from behind, taking pride in collective accomplishment and giving credit where it is due. Cialdini says: Leaders should encourage everyone to contribute and simultaneously assure all concerned that every recommendation is important to making the right decision and will be given full attention The frustrating thing about innovation is that there are many approaches, but no magic formula. However, a manager who wants to create a truly innovative culture can make their job a lot easier by recognising these psychological realities.", "hypothesis": "Most people have the potential to be creative.", "gold_label": "entailment"}
{"uid": "id_522", "premise": "The psychology of innovation Why are so few companies truly innovative? Innovation is key to business survival, and companies put substantial resources into inspiring employees to develop new ideas. There are, nevertheless, people working in luxurious, state-of-the-art centres designed to stimulate innovation who find that their environment doesnt make them feel at all creative. And there are those who dont have a budget, or much space, but who innovate successfully. For Robert B. Cialdini, Professor of Psychology at Arizona State University, one reason that companies dont succeed as often as they should is that innovation starts with recruitment. Research shows that the fit between an employees values and a companys values makes a difference to what contribution they make and whether, two years after they join, theyre still at the company. Studies at Harvard Business School show that, although some individuals may be more creative than others, almost every individual can be creative in the right circumstances. One of the most famous photographs in the story of rocknroll emphasises Ciaidinis views. The 1956 picture of singers Elvis Presley, Carl Perkins, Johnny Cash and Jerry Lee Lewis jamming at a piano in Sun Studios in Memphis tells a hidden story. Suns million-dollar quartet could have been a quintet. Missing from the picture is Roy Orbison a greater natural singer than Lewis, Perkins or Cash. Sam Phillips, who owned Sun, wanted to revolutionise popular music with songs that fused black and white music, and country and blues. Presley, Cash, Perkins and Lewis instinctively understood Phillipss ambition and believed in it. Orbison wasnt inspired by the goal, and only ever achieved one hit with the Sun label. The value fit matters, says Cialdini, because innovation is, in part, a process of change, and under that pressure we, as a species, behave differently, When things change, we are hard-wired to play it safe. Managers should therefore adopt an approach that appears counterintuitive -they should explain what stands to be lost if the company fails to seize a particular opportunity. Studies show that we invariably take more gambles when threatened with a loss than when offered a reward. Managing innovation is a delicate art. Its easy for a company to be pulled in conflicting directions as the marketing, product development, and finance departments each get different feedback from different sets of people. And without a system which ensures collaborative exchanges within the company, its also easy for small pockets of innovation to disappear. Innovation is a contact sport. You cant brief people just by saying, Were going in this direction and Im going to take you with me. Cialdini believes that this follow-the-leader syndrome, is dangerous, not least because it encourages bosses to go it alone. Its been scientifically proven that three people will be better than one at solving problems, even if that one person is the smartest person in the field. To prove his point, Cialdini cites an interview with molecular biologist James Watson. Watson, together with Francis Crick, discovered the structure of DNA, the genetic information carrier of all living organisms. When asked how they had cracked the code ahead of an array of highly accomplished rival investigators, he said something that stunned me. He said he and Crick had succeeded because they were aware that they werent the most intelligent of the scientists pursuing the answer. The smartest scientist was called Rosalind Franklin who, Watson said, was so intelligent she rarely sought advice. Teamwork taps into one of the basic drivers of human behaviour. The principle of social proof is so pervasive that we dont even recognise it, says Cialdini. If your project is being resisted, for example, by a group of veteran employees, ask another old-timer to speak up for it. Cialdini is not alone in advocating this strategy. Research shows that peer power, used horizontally not vertically, is much more powerful than any bosss speech. 76Writing, visualising and prototyping can stimulate the flow of new ideas. Cialdini cites scores of research papers and historical events that prove that even something as simple as writing deepens every individuals engagement in the project. It is, he says, the reason why all those competitions on breakfast cereal packets encouraged us to write in saying, in no more than 10 words: I like Kelloggs Com Flakes because... . The very act of writing makes us more likely to believe it. Authority doesnt have to inhibit innovation but it often does. The wrong kind of leadership will lead to what Cialdini calls captainitis, the regrettable tendency of team members to opt out of team responsibilities that are properly their. He calls it captainitis because, he says, crew members of multipilot aircraft exhibit a sometimes deadly passivity when the flight captain makes a clearly wrong-headed decision. This behaviour is not, he says, unique to air travel, but can happen in any workplace where the leader is overbearing. At the other end of the scale is the 1980s Memphis design collective, a group of young designers for whom the only rule was that there were no rule. This environment encouraged a free interchange of ideas, which led to more creativity with form, function, colour and materials that revolutionised attitudes to furniture design. Many theorists believe the ideal boss should lead from behind, taking pride in collective accomplishment and giving credit where it is due. Cialdini says: Leaders should encourage everyone to contribute and simultaneously assure all concerned that every recommendation is important to making the right decision and will be given full attention The frustrating thing about innovation is that there are many approaches, but no magic formula. However, a manager who wants to create a truly innovative culture can make their job a lot easier by recognising these psychological realities.", "hypothesis": "Teams work best when their members are of equally matched intelligence.", "gold_label": "neutral"}
{"uid": "id_523", "premise": "The psychology of innovation Why are so few companies truly innovative? Innovation is key to business survival, and companies put substantial resources into inspiring employees to develop new ideas. There are, nevertheless, people working in luxurious, state-of-the-art centres designed to stimulate innovation who find that their environment doesnt make them feel at all creative. And there are those who dont have a budget, or much space, but who innovate successfully. For Robert B. Cialdini, Professor of Psychology at Arizona State University, one reason that companies dont succeed as often as they should is that innovation starts with recruitment. Research shows that the fit between an employees values and a companys values makes a difference to what contribution they make and whether, two years after they join, theyre still at the company. Studies at Harvard Business School show that, although some individuals may be more creative than others, almost every individual can be creative in the right circumstances. One of the most famous photographs in the story of rocknroll emphasises Ciaidinis views. The 1956 picture of singers Elvis Presley, Carl Perkins, Johnny Cash and Jerry Lee Lewis jamming at a piano in Sun Studios in Memphis tells a hidden story. Suns million-dollar quartet could have been a quintet. Missing from the picture is Roy Orbison, a greater natural singer than Lewis, Perkins or Cash. Sam Phillips, who owned Sun, wanted to revolutionise popular music with songs that fused black and white music, and country and blues. Presley, Cash, Perkins and Lewis instinctively understood Phillipss ambition and believed in it. Orbison wasnt inspired by the goal, and only ever achieved one hit with the Sun label. The value fit matters, says Cialdini, because innovation is, in part, a process of change, and under that pressure we, as a species, behave differently, When things change, we are hard-wired to play it safe. Managers should therefore adopt an approach that appears counter? intuitive they should explain what stands to be lost if the company fails to seize a particular opportunity. Studies show that we invariably take more gambles when threatened with a loss than when offered a reward. Managing innovation is a delicate art. Its easy for a company to be pulled in conflicting directions as the marketing, product development, and finance departments each get different feedback from different sets of people. And without a system which ensures collaborative exchanges within the company, it's also easy for small pockets of innovation to disappear. Innovation is a contact sport. You cant brief people just by saying, Were going in this direction and Im going to take you with me. Cialdini believes that this follow-the-leader syndrome is dangerous, not least because it encourages bosses to go it alone. It's been scientifically proven that three people will be better than one at solving problems, even if that one person is the smartest person in the field. To prove his point, Cialdini cites an interview with molecular biologist James Watson. Watson, together with Francis Crick, discovered the structure of DNA, the genetic information carrier of all living organisms. When asked how they had cracked the code ahead of an array of highly accomplished rival investigators, he said something that stunned me. He said he and Crick had succeeded because they were aware that they werent the most intelligent of the scientists pursuing the answer. The smartest scientist was called Rosalind Franklin who, Watson said, was so intelligent she rarely sought advice. Teamwork taps into one of the basic drivers of human behaviour. The principle of social proof is so pervasive that we don't even recognise it, says Cialdini. If your project is being resisted, for example, by a group of veteran employees, ask another old-timer to speak up for it. Cialdini is not alone in advocating this strategy. Research shows that peer power, used horizontally not vertically, is much more powerful than any boss's speech. Writing, visualising and prototyping can stimulate the flow of new ideas. Cialdini cites scores of research papers and historical events that prove that even something as simple as writing deepens every individuals engagement in the project. It is, he says, the reason why all those competitions on breakfast cereal packets encouraged us to write in saying, in no more than 10 words: I like Kelloggs Com Flakes because... . The very act of writing makes us more likely to believe it. Authority doesnt have to inhibit innovation but it often does. The wrong kind of leadership will lead to what Cialdini calls captainitis, the regrettable tendency of team members to opt out of team responsibilities that are properly theirs. He calls it captainitis because, he says, crew members of multipilot aircraft exhibit a sometimes deadly passivity when the flight captain makes a clearly wrong-headed decision. This behaviour is not, he says, unique to air travel, but can happen in any workplace where the leader is overbearing. At the other end of the scale is the 1980s Memphis design collective, a group of young designers for whom the only rule was that there were no rules. This environment encouraged a free interchange of ideas, which led to more creativity with form, function, colour and materials that revolutionised attitudes to furniture design. Many theorists believe the ideal boss should lead from behind, taking pride in collective accomplishment and giving credit where it is due. Cialdini says: Leaders should encourage everyone to contribute and simultaneously assure all concerned that every recommendation is important to making the right decision and will be given full attention. The frustrating thing about innovation is that there are many approaches, but no magic formula. However, a manager who wants to create a truly innovative culture can make their job a lot easier by recognising these psychological realities.", "hypothesis": "It is easier for smaller companies to be innovative.", "gold_label": "neutral"}
{"uid": "id_524", "premise": "The psychology of innovation Why are so few companies truly innovative? Innovation is key to business survival, and companies put substantial resources into inspiring employees to develop new ideas. There are, nevertheless, people working in luxurious, state-of-the-art centres designed to stimulate innovation who find that their environment doesnt make them feel at all creative. And there are those who dont have a budget, or much space, but who innovate successfully. For Robert B. Cialdini, Professor of Psychology at Arizona State University, one reason that companies dont succeed as often as they should is that innovation starts with recruitment. Research shows that the fit between an employees values and a companys values makes a difference to what contribution they make and whether, two years after they join, theyre still at the company. Studies at Harvard Business School show that, although some individuals may be more creative than others, almost every individual can be creative in the right circumstances. One of the most famous photographs in the story of rocknroll emphasises Ciaidinis views. The 1956 picture of singers Elvis Presley, Carl Perkins, Johnny Cash and Jerry Lee Lewis jamming at a piano in Sun Studios in Memphis tells a hidden story. Suns million-dollar quartet could have been a quintet. Missing from the picture is Roy Orbison, a greater natural singer than Lewis, Perkins or Cash. Sam Phillips, who owned Sun, wanted to revolutionise popular music with songs that fused black and white music, and country and blues. Presley, Cash, Perkins and Lewis instinctively understood Phillipss ambition and believed in it. Orbison wasnt inspired by the goal, and only ever achieved one hit with the Sun label. The value fit matters, says Cialdini, because innovation is, in part, a process of change, and under that pressure we, as a species, behave differently, When things change, we are hard-wired to play it safe. Managers should therefore adopt an approach that appears counter? intuitive they should explain what stands to be lost if the company fails to seize a particular opportunity. Studies show that we invariably take more gambles when threatened with a loss than when offered a reward. Managing innovation is a delicate art. Its easy for a company to be pulled in conflicting directions as the marketing, product development, and finance departments each get different feedback from different sets of people. And without a system which ensures collaborative exchanges within the company, it's also easy for small pockets of innovation to disappear. Innovation is a contact sport. You cant brief people just by saying, Were going in this direction and Im going to take you with me. Cialdini believes that this follow-the-leader syndrome is dangerous, not least because it encourages bosses to go it alone. It's been scientifically proven that three people will be better than one at solving problems, even if that one person is the smartest person in the field. To prove his point, Cialdini cites an interview with molecular biologist James Watson. Watson, together with Francis Crick, discovered the structure of DNA, the genetic information carrier of all living organisms. When asked how they had cracked the code ahead of an array of highly accomplished rival investigators, he said something that stunned me. He said he and Crick had succeeded because they were aware that they werent the most intelligent of the scientists pursuing the answer. The smartest scientist was called Rosalind Franklin who, Watson said, was so intelligent she rarely sought advice. Teamwork taps into one of the basic drivers of human behaviour. The principle of social proof is so pervasive that we don't even recognise it, says Cialdini. If your project is being resisted, for example, by a group of veteran employees, ask another old-timer to speak up for it. Cialdini is not alone in advocating this strategy. Research shows that peer power, used horizontally not vertically, is much more powerful than any boss's speech. Writing, visualising and prototyping can stimulate the flow of new ideas. Cialdini cites scores of research papers and historical events that prove that even something as simple as writing deepens every individuals engagement in the project. It is, he says, the reason why all those competitions on breakfast cereal packets encouraged us to write in saying, in no more than 10 words: I like Kelloggs Com Flakes because... . The very act of writing makes us more likely to believe it. Authority doesnt have to inhibit innovation but it often does. The wrong kind of leadership will lead to what Cialdini calls captainitis, the regrettable tendency of team members to opt out of team responsibilities that are properly theirs. He calls it captainitis because, he says, crew members of multipilot aircraft exhibit a sometimes deadly passivity when the flight captain makes a clearly wrong-headed decision. This behaviour is not, he says, unique to air travel, but can happen in any workplace where the leader is overbearing. At the other end of the scale is the 1980s Memphis design collective, a group of young designers for whom the only rule was that there were no rules. This environment encouraged a free interchange of ideas, which led to more creativity with form, function, colour and materials that revolutionised attitudes to furniture design. Many theorists believe the ideal boss should lead from behind, taking pride in collective accomplishment and giving credit where it is due. Cialdini says: Leaders should encourage everyone to contribute and simultaneously assure all concerned that every recommendation is important to making the right decision and will be given full attention. The frustrating thing about innovation is that there are many approaches, but no magic formula. However, a manager who wants to create a truly innovative culture can make their job a lot easier by recognising these psychological realities.", "hypothesis": "The physical surroundings in which a person works play a key role in determining their creativity.", "gold_label": "contradiction"}
{"uid": "id_525", "premise": "The psychology of innovation Why are so few companies truly innovative? Innovation is key to business survival, and companies put substantial resources into inspiring employees to develop new ideas. There are, nevertheless, people working in luxurious, state-of-the-art centres designed to stimulate innovation who find that their environment doesnt make them feel at all creative. And there are those who dont have a budget, or much space, but who innovate successfully. For Robert B. Cialdini, Professor of Psychology at Arizona State University, one reason that companies dont succeed as often as they should is that innovation starts with recruitment. Research shows that the fit between an employees values and a companys values makes a difference to what contribution they make and whether, two years after they join, theyre still at the company. Studies at Harvard Business School show that, although some individuals may be more creative than others, almost every individual can be creative in the right circumstances. One of the most famous photographs in the story of rocknroll emphasises Ciaidinis views. The 1956 picture of singers Elvis Presley, Carl Perkins, Johnny Cash and Jerry Lee Lewis jamming at a piano in Sun Studios in Memphis tells a hidden story. Suns million-dollar quartet could have been a quintet. Missing from the picture is Roy Orbison, a greater natural singer than Lewis, Perkins or Cash. Sam Phillips, who owned Sun, wanted to revolutionise popular music with songs that fused black and white music, and country and blues. Presley, Cash, Perkins and Lewis instinctively understood Phillipss ambition and believed in it. Orbison wasnt inspired by the goal, and only ever achieved one hit with the Sun label. The value fit matters, says Cialdini, because innovation is, in part, a process of change, and under that pressure we, as a species, behave differently, When things change, we are hard-wired to play it safe. Managers should therefore adopt an approach that appears counter? intuitive they should explain what stands to be lost if the company fails to seize a particular opportunity. Studies show that we invariably take more gambles when threatened with a loss than when offered a reward. Managing innovation is a delicate art. Its easy for a company to be pulled in conflicting directions as the marketing, product development, and finance departments each get different feedback from different sets of people. And without a system which ensures collaborative exchanges within the company, it's also easy for small pockets of innovation to disappear. Innovation is a contact sport. You cant brief people just by saying, Were going in this direction and Im going to take you with me. Cialdini believes that this follow-the-leader syndrome is dangerous, not least because it encourages bosses to go it alone. It's been scientifically proven that three people will be better than one at solving problems, even if that one person is the smartest person in the field. To prove his point, Cialdini cites an interview with molecular biologist James Watson. Watson, together with Francis Crick, discovered the structure of DNA, the genetic information carrier of all living organisms. When asked how they had cracked the code ahead of an array of highly accomplished rival investigators, he said something that stunned me. He said he and Crick had succeeded because they were aware that they werent the most intelligent of the scientists pursuing the answer. The smartest scientist was called Rosalind Franklin who, Watson said, was so intelligent she rarely sought advice. Teamwork taps into one of the basic drivers of human behaviour. The principle of social proof is so pervasive that we don't even recognise it, says Cialdini. If your project is being resisted, for example, by a group of veteran employees, ask another old-timer to speak up for it. Cialdini is not alone in advocating this strategy. Research shows that peer power, used horizontally not vertically, is much more powerful than any boss's speech. Writing, visualising and prototyping can stimulate the flow of new ideas. Cialdini cites scores of research papers and historical events that prove that even something as simple as writing deepens every individuals engagement in the project. It is, he says, the reason why all those competitions on breakfast cereal packets encouraged us to write in saying, in no more than 10 words: I like Kelloggs Com Flakes because... . The very act of writing makes us more likely to believe it. Authority doesnt have to inhibit innovation but it often does. The wrong kind of leadership will lead to what Cialdini calls captainitis, the regrettable tendency of team members to opt out of team responsibilities that are properly theirs. He calls it captainitis because, he says, crew members of multipilot aircraft exhibit a sometimes deadly passivity when the flight captain makes a clearly wrong-headed decision. This behaviour is not, he says, unique to air travel, but can happen in any workplace where the leader is overbearing. At the other end of the scale is the 1980s Memphis design collective, a group of young designers for whom the only rule was that there were no rules. This environment encouraged a free interchange of ideas, which led to more creativity with form, function, colour and materials that revolutionised attitudes to furniture design. Many theorists believe the ideal boss should lead from behind, taking pride in collective accomplishment and giving credit where it is due. Cialdini says: Leaders should encourage everyone to contribute and simultaneously assure all concerned that every recommendation is important to making the right decision and will be given full attention. The frustrating thing about innovation is that there are many approaches, but no magic formula. However, a manager who wants to create a truly innovative culture can make their job a lot easier by recognising these psychological realities.", "hypothesis": "Most people have the potential to be creative.", "gold_label": "entailment"}
{"uid": "id_526", "premise": "The psychology of innovation Why are so few companies truly innovative? Innovation is key to business survival, and companies put substantial resources into inspiring employees to develop new ideas. There are, nevertheless, people working in luxurious, state-of-the-art centres designed to stimulate innovation who find that their environment doesnt make them feel at all creative. And there are those who dont have a budget, or much space, but who innovate successfully. For Robert B. Cialdini, Professor of Psychology at Arizona State University, one reason that companies dont succeed as often as they should is that innovation starts with recruitment. Research shows that the fit between an employees values and a companys values makes a difference to what contribution they make and whether, two years after they join, theyre still at the company. Studies at Harvard Business School show that, although some individuals may be more creative than others, almost every individual can be creative in the right circumstances. One of the most famous photographs in the story of rocknroll emphasises Ciaidinis views. The 1956 picture of singers Elvis Presley, Carl Perkins, Johnny Cash and Jerry Lee Lewis jamming at a piano in Sun Studios in Memphis tells a hidden story. Suns million-dollar quartet could have been a quintet. Missing from the picture is Roy Orbison, a greater natural singer than Lewis, Perkins or Cash. Sam Phillips, who owned Sun, wanted to revolutionise popular music with songs that fused black and white music, and country and blues. Presley, Cash, Perkins and Lewis instinctively understood Phillipss ambition and believed in it. Orbison wasnt inspired by the goal, and only ever achieved one hit with the Sun label. The value fit matters, says Cialdini, because innovation is, in part, a process of change, and under that pressure we, as a species, behave differently, When things change, we are hard-wired to play it safe. Managers should therefore adopt an approach that appears counter? intuitive they should explain what stands to be lost if the company fails to seize a particular opportunity. Studies show that we invariably take more gambles when threatened with a loss than when offered a reward. Managing innovation is a delicate art. Its easy for a company to be pulled in conflicting directions as the marketing, product development, and finance departments each get different feedback from different sets of people. And without a system which ensures collaborative exchanges within the company, it's also easy for small pockets of innovation to disappear. Innovation is a contact sport. You cant brief people just by saying, Were going in this direction and Im going to take you with me. Cialdini believes that this follow-the-leader syndrome is dangerous, not least because it encourages bosses to go it alone. It's been scientifically proven that three people will be better than one at solving problems, even if that one person is the smartest person in the field. To prove his point, Cialdini cites an interview with molecular biologist James Watson. Watson, together with Francis Crick, discovered the structure of DNA, the genetic information carrier of all living organisms. When asked how they had cracked the code ahead of an array of highly accomplished rival investigators, he said something that stunned me. He said he and Crick had succeeded because they were aware that they werent the most intelligent of the scientists pursuing the answer. The smartest scientist was called Rosalind Franklin who, Watson said, was so intelligent she rarely sought advice. Teamwork taps into one of the basic drivers of human behaviour. The principle of social proof is so pervasive that we don't even recognise it, says Cialdini. If your project is being resisted, for example, by a group of veteran employees, ask another old-timer to speak up for it. Cialdini is not alone in advocating this strategy. Research shows that peer power, used horizontally not vertically, is much more powerful than any boss's speech. Writing, visualising and prototyping can stimulate the flow of new ideas. Cialdini cites scores of research papers and historical events that prove that even something as simple as writing deepens every individuals engagement in the project. It is, he says, the reason why all those competitions on breakfast cereal packets encouraged us to write in saying, in no more than 10 words: I like Kelloggs Com Flakes because... . The very act of writing makes us more likely to believe it. Authority doesnt have to inhibit innovation but it often does. The wrong kind of leadership will lead to what Cialdini calls captainitis, the regrettable tendency of team members to opt out of team responsibilities that are properly theirs. He calls it captainitis because, he says, crew members of multipilot aircraft exhibit a sometimes deadly passivity when the flight captain makes a clearly wrong-headed decision. This behaviour is not, he says, unique to air travel, but can happen in any workplace where the leader is overbearing. At the other end of the scale is the 1980s Memphis design collective, a group of young designers for whom the only rule was that there were no rules. This environment encouraged a free interchange of ideas, which led to more creativity with form, function, colour and materials that revolutionised attitudes to furniture design. Many theorists believe the ideal boss should lead from behind, taking pride in collective accomplishment and giving credit where it is due. Cialdini says: Leaders should encourage everyone to contribute and simultaneously assure all concerned that every recommendation is important to making the right decision and will be given full attention. The frustrating thing about innovation is that there are many approaches, but no magic formula. However, a manager who wants to create a truly innovative culture can make their job a lot easier by recognising these psychological realities.", "hypothesis": "A managers approval of an idea is more persuasive than that of a colleague.", "gold_label": "contradiction"}
{"uid": "id_527", "premise": "The psychology of innovation Why are so few companies truly innovative? Innovation is key to business survival, and companies put substantial resources into inspiring employees to develop new ideas. There are, nevertheless, people working in luxurious, state-of-the-art centres designed to stimulate innovation who find that their environment doesnt make them feel at all creative. And there are those who dont have a budget, or much space, but who innovate successfully. For Robert B. Cialdini, Professor of Psychology at Arizona State University, one reason that companies dont succeed as often as they should is that innovation starts with recruitment. Research shows that the fit between an employees values and a companys values makes a difference to what contribution they make and whether, two years after they join, theyre still at the company. Studies at Harvard Business School show that, although some individuals may be more creative than others, almost every individual can be creative in the right circumstances. One of the most famous photographs in the story of rocknroll emphasises Ciaidinis views. The 1956 picture of singers Elvis Presley, Carl Perkins, Johnny Cash and Jerry Lee Lewis jamming at a piano in Sun Studios in Memphis tells a hidden story. Suns million-dollar quartet could have been a quintet. Missing from the picture is Roy Orbison, a greater natural singer than Lewis, Perkins or Cash. Sam Phillips, who owned Sun, wanted to revolutionise popular music with songs that fused black and white music, and country and blues. Presley, Cash, Perkins and Lewis instinctively understood Phillipss ambition and believed in it. Orbison wasnt inspired by the goal, and only ever achieved one hit with the Sun label. The value fit matters, says Cialdini, because innovation is, in part, a process of change, and under that pressure we, as a species, behave differently, When things change, we are hard-wired to play it safe. Managers should therefore adopt an approach that appears counter? intuitive they should explain what stands to be lost if the company fails to seize a particular opportunity. Studies show that we invariably take more gambles when threatened with a loss than when offered a reward. Managing innovation is a delicate art. Its easy for a company to be pulled in conflicting directions as the marketing, product development, and finance departments each get different feedback from different sets of people. And without a system which ensures collaborative exchanges within the company, it's also easy for small pockets of innovation to disappear. Innovation is a contact sport. You cant brief people just by saying, Were going in this direction and Im going to take you with me. Cialdini believes that this follow-the-leader syndrome is dangerous, not least because it encourages bosses to go it alone. It's been scientifically proven that three people will be better than one at solving problems, even if that one person is the smartest person in the field. To prove his point, Cialdini cites an interview with molecular biologist James Watson. Watson, together with Francis Crick, discovered the structure of DNA, the genetic information carrier of all living organisms. When asked how they had cracked the code ahead of an array of highly accomplished rival investigators, he said something that stunned me. He said he and Crick had succeeded because they were aware that they werent the most intelligent of the scientists pursuing the answer. The smartest scientist was called Rosalind Franklin who, Watson said, was so intelligent she rarely sought advice. Teamwork taps into one of the basic drivers of human behaviour. The principle of social proof is so pervasive that we don't even recognise it, says Cialdini. If your project is being resisted, for example, by a group of veteran employees, ask another old-timer to speak up for it. Cialdini is not alone in advocating this strategy. Research shows that peer power, used horizontally not vertically, is much more powerful than any boss's speech. Writing, visualising and prototyping can stimulate the flow of new ideas. Cialdini cites scores of research papers and historical events that prove that even something as simple as writing deepens every individuals engagement in the project. It is, he says, the reason why all those competitions on breakfast cereal packets encouraged us to write in saying, in no more than 10 words: I like Kelloggs Com Flakes because... . The very act of writing makes us more likely to believe it. Authority doesnt have to inhibit innovation but it often does. The wrong kind of leadership will lead to what Cialdini calls captainitis, the regrettable tendency of team members to opt out of team responsibilities that are properly theirs. He calls it captainitis because, he says, crew members of multipilot aircraft exhibit a sometimes deadly passivity when the flight captain makes a clearly wrong-headed decision. This behaviour is not, he says, unique to air travel, but can happen in any workplace where the leader is overbearing. At the other end of the scale is the 1980s Memphis design collective, a group of young designers for whom the only rule was that there were no rules. This environment encouraged a free interchange of ideas, which led to more creativity with form, function, colour and materials that revolutionised attitudes to furniture design. Many theorists believe the ideal boss should lead from behind, taking pride in collective accomplishment and giving credit where it is due. Cialdini says: Leaders should encourage everyone to contribute and simultaneously assure all concerned that every recommendation is important to making the right decision and will be given full attention. The frustrating thing about innovation is that there are many approaches, but no magic formula. However, a manager who wants to create a truly innovative culture can make their job a lot easier by recognising these psychological realities.", "hypothesis": "Teams work best when their members are of equally matched intelligence.", "gold_label": "neutral"}
{"uid": "id_528", "premise": "The radio audience measurement society is considering whether its quarterly figures for audience numbers should be released earlier to all radio companies but it is concerned to avoid share-price-sensitive information being leaked to the markets. The current situation involves the commercial stations receiving the results 12 hours later than the public channels. A number of commercial stations have questioned this practice, arguing that they too would like to receive the information earlier so that they could prepare press releases before the markets open. The issue has become significant because the commercial stations share prices tend to move sharply in the hours before the figures are released.", "hypothesis": "The passage author fails to present a case for the status quo.", "gold_label": "contradiction"}
{"uid": "id_529", "premise": "The radio audience measurement society is considering whether its quarterly figures for audience numbers should be released earlier to all radio companies but it is concerned to avoid share-price-sensitive information being leaked to the markets. The current situation involves the commercial stations receiving the results 12 hours later than the public channels. A number of commercial stations have questioned this practice, arguing that they too would like to receive the information earlier so that they could prepare press releases before the markets open. The issue has become significant because the commercial stations share prices tend to move sharply in the hours before the figures are released.", "hypothesis": "The commercial stations share price will go down if the figures show a fall in audience numbers.", "gold_label": "contradiction"}
{"uid": "id_530", "premise": "The radio audience measurement society is considering whether its quarterly figures for audience numbers should be released earlier to all radio companies but it is concerned to avoid share-price-sensitive information being leaked to the markets. The current situation involves the commercial stations receiving the results 12 hours later than the public channels. A number of commercial stations have questioned this practice, arguing that they too would like to receive the information earlier so that they could prepare press releases before the markets open. The issue has become significant because the commercial stations share prices tend to move sharply in the hours before the figures are released.", "hypothesis": "An alternative proposal would involve neither type of organization receiving the information early.", "gold_label": "entailment"}
{"uid": "id_531", "premise": "The reason that is most commonly quoted for nationalisation of foreign companies is a change in governance. Nationalisation tends to cover a wide range of industries and is not selective to the country of ownership of the foreign company.", "hypothesis": "Sharing ownership with local nationals will forestall takeovers by foreign governments.", "gold_label": "contradiction"}
{"uid": "id_532", "premise": "The reason that is most commonly quoted for nationalisation of foreign companies is a change in governance. Nationalisation tends to cover a wide range of industries and is not selective to the country of ownership of the foreign company.", "hypothesis": "Some critical industries are more likely to be nationalised than others which might not be so critical.", "gold_label": "contradiction"}
{"uid": "id_533", "premise": "The reason that is most commonly quoted for nationalisation of foreign companies is a change in governance. Nationalisation tends to cover a wide range of industries and is not selective to the country of ownership of the foreign company.", "hypothesis": "The process of nationalisation is not limited to any particular industry or country.", "gold_label": "entailment"}
{"uid": "id_534", "premise": "The reason that is most commonly quoted for nationalisation of foreign companies is a change in governance. Nationalisation tends to cover a wide range of industries and is not selective to the country of ownership of the foreign company.", "hypothesis": "Nationalisation of businesses is so widespread as to cause concern at the international level.", "gold_label": "contradiction"}
{"uid": "id_535", "premise": "The refectory opens at 6:30 a. m. to serve breakfast which must be ordered by 9:30 a. m. Lunch is served between 11:45 a. m. and 2:30 p. m. Dinner is served between 6:00 p. m. and 8:30 p. m. Guests can be accommodated at lunchtimes and dinnertimes provided that 24 hours notice has been given. Vegetarian options are always available but vegans should notify the catering coordinator at the beginning of each term as should anyone with special dietary requirements. This includes nut, gluten and soybean allergies etc.", "hypothesis": "You can order lunch at 9:45 a. m. if you wish.", "gold_label": "neutral"}
{"uid": "id_536", "premise": "The refectory opens at 6:30 a. m. to serve breakfast which must be ordered by 9:30 a. m. Lunch is served between 11:45 a. m. and 2:30 p. m. Dinner is served between 6:00 p. m. and 8:30 p. m. Guests can be accommodated at lunchtimes and dinnertimes provided that 24 hours notice has been given. Vegetarian options are always available but vegans should notify the catering coordinator at the beginning of each term as should anyone with special dietary requirements. This includes nut, gluten and soybean allergies etc.", "hypothesis": "Someone allergic to eggs should notify the catering coordinator.", "gold_label": "neutral"}
{"uid": "id_537", "premise": "The refectory opens at 6:30 a. m. to serve breakfast which must be ordered by 9:30 a. m. Lunch is served between 11:45 a. m. and 2:30 p. m. Dinner is served between 6:00 p. m. and 8:30 p. m. Guests can be accommodated at lunchtimes and dinnertimes provided that 24 hours notice has been given. Vegetarian options are always available but vegans should notify the catering coordinator at the beginning of each term as should anyone with special dietary requirements. This includes nut, gluten and soybean allergies etc.", "hypothesis": "Vegetarians should notify the catering coordinator.", "gold_label": "contradiction"}
{"uid": "id_538", "premise": "The refectory opens at 6:30 a. m. to serve breakfast which must be ordered by 9:30 a. m. Lunch is served between 11:45 a. m. and 2:30 p. m. Dinner is served between 6:00 p. m. and 8:30 p. m. Guests can be accommodated at lunchtimes and dinnertimes provided that 24 hours notice has been given. Vegetarian options are always available but vegans should notify the catering coordinator at the beginning of each term as should anyone with special dietary requirements. This includes nut, gluten and soybean allergies etc.", "hypothesis": "Dinner can be ordered before 6:00 p. m.", "gold_label": "neutral"}
{"uid": "id_539", "premise": "The refectory opens at 6:30 a. m. to serve breakfast which must be ordered by 9:30 a. m. Lunch is served between 11:45 a. m. and 2:30 p. m. Dinner is served between 6:00 p. m. and 8:30 p. m. Guests can be accommodated at lunchtimes and dinnertimes provided that 24 hours notice has been given. Vegetarian options are always available but vegans should notify the catering coordinator at the beginning of each term as should anyone with special dietary requirements. This includes nut, gluten and soybean allergies etc.", "hypothesis": "Guests cannot be accommodated at breakfast time.", "gold_label": "entailment"}
{"uid": "id_540", "premise": "The right of those working in the public sector to strike is controversial. Many private sector workers are of the opinion that the cost to tax payers and delays or closures in services outweighs any benefit that may be achieved through industrial action. In addition to this, employers have been criticised for their inability to prevent their workers from striking; it is the responsibility of employers to provide for the continual smooth running of public services, many of which provide a vital aspect of day to day life. An example of this can be seen in the transport industry, where severe delays can have a knock-on effect on the functioning of other industries. Unions should be encouraged to find a less disruptive way of settling disputes.", "hypothesis": "Delays or closures in services, such as public transport is a problem caused by industrial action", "gold_label": "entailment"}
{"uid": "id_541", "premise": "The right of those working in the public sector to strike splits opinion. Many private sector workers are of the opinion that the cost to tax payers and the consequences of delays or closures in services outweighs any benefit that may be achieved through industrial action. In addition to this, public sector employers have been criticised for their inability to prevent their workers from striking since it is the responsibility of government to provide for the continual smooth running of public services, many of which provide a vital aspect of day to day life. An example of this can be seen in the transport industry, where severe delays can have a knock-on effect on the functioning of other industries, both public and private. Unions should be encouraged to find a less disruptive way of settling disputes, and it is said by some that unions in the public sector shouldnt exist at all. But then how does the voice of the employee get heard if there is no union, or at least none which gets taken seriously?", "hypothesis": "Some strikes are not disruptive to the economy.", "gold_label": "neutral"}
{"uid": "id_542", "premise": "The right of those working in the public sector to strike splits opinion. Many private sector workers are of the opinion that the cost to tax payers and the consequences of delays or closures in services outweighs any benefit that may be achieved through industrial action. In addition to this, public sector employers have been criticised for their inability to prevent their workers from striking since it is the responsibility of government to provide for the continual smooth running of public services, many of which provide a vital aspect of day to day life. An example of this can be seen in the transport industry, where severe delays can have a knock-on effect on the functioning of other industries, both public and private. Unions should be encouraged to find a less disruptive way of settling disputes, and it is said by some that unions in the public sector shouldnt exist at all. But then how does the voice of the employee get heard if there is no union, or at least none which gets taken seriously?", "hypothesis": "Government has a responsibility to deliver uninterrupted public services.", "gold_label": "entailment"}
{"uid": "id_543", "premise": "The right of those working in the public sector to strike splits opinion. Many private sector workers are of the opinion that the cost to tax payers and the consequences of delays or closures in services outweighs any benefit that may be achieved through industrial action. In addition to this, public sector employers have been criticised for their inability to prevent their workers from striking since it is the responsibility of government to provide for the continual smooth running of public services, many of which provide a vital aspect of day to day life. An example of this can be seen in the transport industry, where severe delays can have a knock-on effect on the functioning of other industries, both public and private. Unions should be encouraged to find a less disruptive way of settling disputes, and it is said by some that unions in the public sector shouldnt exist at all. But then how does the voice of the employee get heard if there is no union, or at least none which gets taken seriously?", "hypothesis": "There is general consensus that all employees should have the right to strike.", "gold_label": "contradiction"}
{"uid": "id_544", "premise": "The rise and fall in the annual gross income of Britains biggest supermarkets is well documented. For this reason it came as no surprise to many when Tescos annual figures represented a loss this quarter. Official figures suggest that a price-cutting campaign by Britains biggest retailer failed to plug the losses, as Tesco made its fourth quarterly loss in a row. Commentators suggest that the fall in sales is a result of the current economic climate, with shoppers not only spending less on clothing and electronic items, but also on their weekly food shops. However, this view is controversial as smaller competitors, such as Sainsburys and Morrisons, continue to make a profit.", "hypothesis": "Competitors, such as Sainsburys and Morrisons continue to make a profit on clothing and electrical items.", "gold_label": "neutral"}
{"uid": "id_545", "premise": "The rise and fall in the annual gross income of Britains biggest supermarkets is well documented. For this reason it came as no surprise to many when Tescos annual figures represented a loss this quarter. Official figures suggest that a price-cutting campaign by Britains biggest retailer failed to plug the losses, as Tesco made its fourth quarterly loss in a row. Commentators suggest that the fall in sales is a result of the current economic climate, with shoppers not only spending less on clothing and electronic items, but also on their weekly food shops. However, this view is controversial as smaller competitors, such as Sainsburys and Morrisons, continue to make a profit.", "hypothesis": "Competitors, such as Sainsburys and Morrisons continually made a loss in the last four quarters.", "gold_label": "contradiction"}
{"uid": "id_546", "premise": "The rise and fall in the annual gross income of Britains biggest supermarkets is well documented. For this reason it came as no surprise to many when Tescos annual figures represented a loss this quarter. Official figures suggest that a price-cutting campaign by Britains biggest retailer failed to plug the losses, as Tesco made its fourth quarterly loss in a row. Commentators suggest that the fall in sales is a result of the current economic climate, with shoppers not only spending less on clothing and electronic items, but also on their weekly food shops. However, this view is controversial as smaller competitors, such as Sainsburys and Morrisons, continue to make a profit.", "hypothesis": "Competitors, such as Sainsburys and Morrisons continually pose a threat to Tesco.", "gold_label": "neutral"}
{"uid": "id_547", "premise": "The rise and fall in the annual gross income of Britains biggest supermarkets is well documented. For this reason it came as no surprise to many when Tescos annual figures represented a loss this quarter. Official figures suggest that a price-cutting campaign by Britains biggest retailer failed to plug the losses, as Tesco made its fourth quarterly loss in a row. Commentators suggest that the fall in sales is a result of the current economic climate, with shoppers not only spending less on clothing and electronic items, but also on their weekly food shops. However, this view is controversial as smaller competitors, such as Sainsburys and Morrisons, continue to make a profit.", "hypothesis": "Competitors, such as Sainsburys and Morrisons continue to make a profit, despite the economic downturn.", "gold_label": "entailment"}
{"uid": "id_548", "premise": "The rise of agribots The next time you stand at the supermarket checkout, spare a thought for the farmers who helped fill your shopping basket as life is hard for them right now. This, in turn, inevitably means bigger grocery bills for consumers, and greater hardship for the millions in countries where food shortages are a matter of life and death. Worse, studies suggest that the world will need twice as much food by 2050. Yet while farmers must squeeze more out of the land, they must also address the necessity of reducing their impact on the soil, waterways and atmosphere. All this means rethinking how agriculture is practiced, and taking automation to a whole new level. On the new model farms of the future, precision will be key. Why dose a whole field with chemicals if you can spray only where they are needed? Each plant could get exactly the right amount of everything, no more or less, an approach that could slash chemical use and improve yields in one move. But this is easier said than done; the largest farms in Europe and the U. S. can cover thousands of acres. Thats why automation is key to precision farming. Specifically, say agricultural engineers, precision farming needs robot farmers. One day, we might see fields with agribots (agricultural robots) that can identify individual seedlings and encourage them along with drops of fertilizer. Other machines would distinguish problem weeds from crops and eliminate them with shots from high-power lasers or a microdot of pesticide. These machines will also be able to identify and harvest all kinds of vegetables. More than a century of mechanization has already turned farming into an industrial-scale activity in much of the world, with farms that grow cereals being the most heavily automated. But a variety of other crops, including oranges and tomatoes destined to become processed foods, are also picked mechanically, albeit to a slightly lesser extent. Yet the next wave of autonomous farm machinery is already at work. You probably havent even noticed, for these robots are disguised as tractors. Many are self-steering, use GPS to cross a field, and can even talk to their implements a plough or sprayer, for example. And the implements can talk back, telling the tractor that its going too fast or needs to move to the left. This kind of communication is also being developed in other farm vehicles. A new system allows a combine harvester, say, to send a call over to a tractor- trailer so the driver can unload the grain as and when necessary. However, when fully autonomous systems take to the field, theyll look nothing like tractors. With their enormous size and weight, todays farm machines have significant downsides: they compact the soil, reducing porosity and killing beneficial life, meaning crops dont grow so well. Simon Blackmore, who researches agricultural technology at Harper Adams University College in England believes that fleets of lightweight autonomous robots have the potential to solve this problem and that replacing brute force with precision is key. A seed only needs one cubic centimeter of soil to grow. If we cultivate just that we only put tiny amounts of energy in and the plants still grow nicely. There is another reason why automation may be the way forward according to Eldert van Henten, a robotics researcher at Wageningen University in the Netherlands. While the population is growing and needs to be fed, a rapidly shrinking number of people are willing to work in agriculture, he points out. Other researchers such as Linda Calvin, an economist at the U. S. Department of Agriculture, and Philip Martin at the University of California, Davis, have studied trends in mechanization to predict how US farms might fare. Calvin and Martin have observed how rising employment costs have led to the adoption of labour-saving farm technology in the past, citing the raisin industry as an example. In 2000, a bumper harvest crashed prices and, with profits squeezed, farmers looked for a solution. With labour one of their biggest costs 42 percent of production expenses on U. S. farms, on average they started using a mechanical harvester adapted from a machine used by wine makers. By 2007, almost half of Californias raisins were mechanically harvested and a labour force once numbering 50,000 had shrunk to 30,000. As well as having an impact on the job market, the widespread adoption of agribots might bring changes at the supermarket. Lewis Holloway, who studies agriculture at the University of Hull, UK, says that robotic milking is likely to influence the genetics of dairy herds as farmers opt for robot-friendly cows, with udder shape, and even attitudes, suited to automated milking. Similarly, he says, its conceivable that agribots could influence what fruit or vegetable varieties get to the shops, since farmers may prefer to grow those with, say, leaf shapes that are easier for their robots to discriminate from weeds. Almost inevitably, these machines will eventually alter the landscape, too. The real tipping point for robot agriculture will come when farms are being designed with agribots in mind, says Salah Sukkarieh, a robotics researcher at the Australian Center for Field Robotics, Sydney. This could mean a return to smaller fields, with crops planted in grids rather than rows and fruit trees pruned into two-dimensional shapes to make harvesting easier. This alien terrain tended by robots is still a while away, he says but it will happen.", "hypothesis": "Governments should do more to ensure that food is generally affordable.", "gold_label": "neutral"}
{"uid": "id_549", "premise": "The rise of agribots The next time you stand at the supermarket checkout, spare a thought for the farmers who helped fill your shopping basket as life is hard for them right now. This, in turn, inevitably means bigger grocery bills for consumers, and greater hardship for the millions in countries where food shortages are a matter of life and death. Worse, studies suggest that the world will need twice as much food by 2050. Yet while farmers must squeeze more out of the land, they must also address the necessity of reducing their impact on the soil, waterways and atmosphere. All this means rethinking how agriculture is practiced, and taking automation to a whole new level. On the new model farms of the future, precision will be key. Why dose a whole field with chemicals if you can spray only where they are needed? Each plant could get exactly the right amount of everything, no more or less, an approach that could slash chemical use and improve yields in one move. But this is easier said than done; the largest farms in Europe and the U. S. can cover thousands of acres. Thats why automation is key to precision farming. Specifically, say agricultural engineers, precision farming needs robot farmers. One day, we might see fields with agribots (agricultural robots) that can identify individual seedlings and encourage them along with drops of fertilizer. Other machines would distinguish problem weeds from crops and eliminate them with shots from high-power lasers or a microdot of pesticide. These machines will also be able to identify and harvest all kinds of vegetables. More than a century of mechanization has already turned farming into an industrial-scale activity in much of the world, with farms that grow cereals being the most heavily automated. But a variety of other crops, including oranges and tomatoes destined to become processed foods, are also picked mechanically, albeit to a slightly lesser extent. Yet the next wave of autonomous farm machinery is already at work. You probably havent even noticed, for these robots are disguised as tractors. Many are self-steering, use GPS to cross a field, and can even talk to their implements a plough or sprayer, for example. And the implements can talk back, telling the tractor that its going too fast or needs to move to the left. This kind of communication is also being developed in other farm vehicles. A new system allows a combine harvester, say, to send a call over to a tractor- trailer so the driver can unload the grain as and when necessary. However, when fully autonomous systems take to the field, theyll look nothing like tractors. With their enormous size and weight, todays farm machines have significant downsides: they compact the soil, reducing porosity and killing beneficial life, meaning crops dont grow so well. Simon Blackmore, who researches agricultural technology at Harper Adams University College in England believes that fleets of lightweight autonomous robots have the potential to solve this problem and that replacing brute force with precision is key. A seed only needs one cubic centimeter of soil to grow. If we cultivate just that we only put tiny amounts of energy in and the plants still grow nicely. There is another reason why automation may be the way forward according to Eldert van Henten, a robotics researcher at Wageningen University in the Netherlands. While the population is growing and needs to be fed, a rapidly shrinking number of people are willing to work in agriculture, he points out. Other researchers such as Linda Calvin, an economist at the U. S. Department of Agriculture, and Philip Martin at the University of California, Davis, have studied trends in mechanization to predict how US farms might fare. Calvin and Martin have observed how rising employment costs have led to the adoption of labour-saving farm technology in the past, citing the raisin industry as an example. In 2000, a bumper harvest crashed prices and, with profits squeezed, farmers looked for a solution. With labour one of their biggest costs 42 percent of production expenses on U. S. farms, on average they started using a mechanical harvester adapted from a machine used by wine makers. By 2007, almost half of Californias raisins were mechanically harvested and a labour force once numbering 50,000 had shrunk to 30,000. As well as having an impact on the job market, the widespread adoption of agribots might bring changes at the supermarket. Lewis Holloway, who studies agriculture at the University of Hull, UK, says that robotic milking is likely to influence the genetics of dairy herds as farmers opt for robot-friendly cows, with udder shape, and even attitudes, suited to automated milking. Similarly, he says, its conceivable that agribots could influence what fruit or vegetable varieties get to the shops, since farmers may prefer to grow those with, say, leaf shapes that are easier for their robots to discriminate from weeds. Almost inevitably, these machines will eventually alter the landscape, too. The real tipping point for robot agriculture will come when farms are being designed with agribots in mind, says Salah Sukkarieh, a robotics researcher at the Australian Center for Field Robotics, Sydney. This could mean a return to smaller fields, with crops planted in grids rather than rows and fruit trees pruned into two-dimensional shapes to make harvesting easier. This alien terrain tended by robots is still a while away, he says but it will happen.", "hypothesis": "Farmers need to reduce the harm they do to the environment.", "gold_label": "entailment"}
{"uid": "id_550", "premise": "The rise of agribots The next time you stand at the supermarket checkout, spare a thought for the farmers who helped fill your shopping basket as life is hard for them right now. This, in turn, inevitably means bigger grocery bills for consumers, and greater hardship for the millions in countries where food shortages are a matter of life and death. Worse, studies suggest that the world will need twice as much food by 2050. Yet while farmers must squeeze more out of the land, they must also address the necessity of reducing their impact on the soil, waterways and atmosphere. All this means rethinking how agriculture is practiced, and taking automation to a whole new level. On the new model farms of the future, precision will be key. Why dose a whole field with chemicals if you can spray only where they are needed? Each plant could get exactly the right amount of everything, no more or less, an approach that could slash chemical use and improve yields in one move. But this is easier said than done; the largest farms in Europe and the U. S. can cover thousands of acres. Thats why automation is key to precision farming. Specifically, say agricultural engineers, precision farming needs robot farmers. One day, we might see fields with agribots (agricultural robots) that can identify individual seedlings and encourage them along with drops of fertilizer. Other machines would distinguish problem weeds from crops and eliminate them with shots from high-power lasers or a microdot of pesticide. These machines will also be able to identify and harvest all kinds of vegetables. More than a century of mechanization has already turned farming into an industrial-scale activity in much of the world, with farms that grow cereals being the most heavily automated. But a variety of other crops, including oranges and tomatoes destined to become processed foods, are also picked mechanically, albeit to a slightly lesser extent. Yet the next wave of autonomous farm machinery is already at work. You probably havent even noticed, for these robots are disguised as tractors. Many are self-steering, use GPS to cross a field, and can even talk to their implements a plough or sprayer, for example. And the implements can talk back, telling the tractor that its going too fast or needs to move to the left. This kind of communication is also being developed in other farm vehicles. A new system allows a combine harvester, say, to send a call over to a tractor- trailer so the driver can unload the grain as and when necessary. However, when fully autonomous systems take to the field, theyll look nothing like tractors. With their enormous size and weight, todays farm machines have significant downsides: they compact the soil, reducing porosity and killing beneficial life, meaning crops dont grow so well. Simon Blackmore, who researches agricultural technology at Harper Adams University College in England believes that fleets of lightweight autonomous robots have the potential to solve this problem and that replacing brute force with precision is key. A seed only needs one cubic centimeter of soil to grow. If we cultivate just that we only put tiny amounts of energy in and the plants still grow nicely. There is another reason why automation may be the way forward according to Eldert van Henten, a robotics researcher at Wageningen University in the Netherlands. While the population is growing and needs to be fed, a rapidly shrinking number of people are willing to work in agriculture, he points out. Other researchers such as Linda Calvin, an economist at the U. S. Department of Agriculture, and Philip Martin at the University of California, Davis, have studied trends in mechanization to predict how US farms might fare. Calvin and Martin have observed how rising employment costs have led to the adoption of labour-saving farm technology in the past, citing the raisin industry as an example. In 2000, a bumper harvest crashed prices and, with profits squeezed, farmers looked for a solution. With labour one of their biggest costs 42 percent of production expenses on U. S. farms, on average they started using a mechanical harvester adapted from a machine used by wine makers. By 2007, almost half of Californias raisins were mechanically harvested and a labour force once numbering 50,000 had shrunk to 30,000. As well as having an impact on the job market, the widespread adoption of agribots might bring changes at the supermarket. Lewis Holloway, who studies agriculture at the University of Hull, UK, says that robotic milking is likely to influence the genetics of dairy herds as farmers opt for robot-friendly cows, with udder shape, and even attitudes, suited to automated milking. Similarly, he says, its conceivable that agribots could influence what fruit or vegetable varieties get to the shops, since farmers may prefer to grow those with, say, leaf shapes that are easier for their robots to discriminate from weeds. Almost inevitably, these machines will eventually alter the landscape, too. The real tipping point for robot agriculture will come when farms are being designed with agribots in mind, says Salah Sukkarieh, a robotics researcher at the Australian Center for Field Robotics, Sydney. This could mean a return to smaller fields, with crops planted in grids rather than rows and fruit trees pruned into two-dimensional shapes to make harvesting easier. This alien terrain tended by robots is still a while away, he says but it will happen.", "hypothesis": "In the future, farmers are likely to increase their dependency on chemicals.", "gold_label": "contradiction"}
{"uid": "id_551", "premise": "The rise of agribots The next time you stand at the supermarket checkout, spare a thought for the farmers who helped fill your shopping basket as life is hard for them right now. This, in turn, inevitably means bigger grocery bills for consumers, and greater hardship for the millions in countries where food shortages are a matter of life and death. Worse, studies suggest that the world will need twice as much food by 2050. Yet while farmers must squeeze more out of the land, they must also address the necessity of reducing their impact on the soil, waterways and atmosphere. All this means rethinking how agriculture is practiced, and taking automation to a whole new level. On the new model farms of the future, precision will be key. Why dose a whole field with chemicals if you can spray only where they are needed? Each plant could get exactly the right amount of everything, no more or less, an approach that could slash chemical use and improve yields in one move. But this is easier said than done; the largest farms in Europe and the U. S. can cover thousands of acres. Thats why automation is key to precision farming. Specifically, say agricultural engineers, precision farming needs robot farmers. One day, we might see fields with agribots (agricultural robots) that can identify individual seedlings and encourage them along with drops of fertilizer. Other machines would distinguish problem weeds from crops and eliminate them with shots from high-power lasers or a microdot of pesticide. These machines will also be able to identify and harvest all kinds of vegetables. More than a century of mechanization has already turned farming into an industrial-scale activity in much of the world, with farms that grow cereals being the most heavily automated. But a variety of other crops, including oranges and tomatoes destined to become processed foods, are also picked mechanically, albeit to a slightly lesser extent. Yet the next wave of autonomous farm machinery is already at work. You probably havent even noticed, for these robots are disguised as tractors. Many are self-steering, use GPS to cross a field, and can even talk to their implements a plough or sprayer, for example. And the implements can talk back, telling the tractor that its going too fast or needs to move to the left. This kind of communication is also being developed in other farm vehicles. A new system allows a combine harvester, say, to send a call over to a tractor- trailer so the driver can unload the grain as and when necessary. However, when fully autonomous systems take to the field, theyll look nothing like tractors. With their enormous size and weight, todays farm machines have significant downsides: they compact the soil, reducing porosity and killing beneficial life, meaning crops dont grow so well. Simon Blackmore, who researches agricultural technology at Harper Adams University College in England believes that fleets of lightweight autonomous robots have the potential to solve this problem and that replacing brute force with precision is key. A seed only needs one cubic centimeter of soil to grow. If we cultivate just that we only put tiny amounts of energy in and the plants still grow nicely. There is another reason why automation may be the way forward according to Eldert van Henten, a robotics researcher at Wageningen University in the Netherlands. While the population is growing and needs to be fed, a rapidly shrinking number of people are willing to work in agriculture, he points out. Other researchers such as Linda Calvin, an economist at the U. S. Department of Agriculture, and Philip Martin at the University of California, Davis, have studied trends in mechanization to predict how US farms might fare. Calvin and Martin have observed how rising employment costs have led to the adoption of labour-saving farm technology in the past, citing the raisin industry as an example. In 2000, a bumper harvest crashed prices and, with profits squeezed, farmers looked for a solution. With labour one of their biggest costs 42 percent of production expenses on U. S. farms, on average they started using a mechanical harvester adapted from a machine used by wine makers. By 2007, almost half of Californias raisins were mechanically harvested and a labour force once numbering 50,000 had shrunk to 30,000. As well as having an impact on the job market, the widespread adoption of agribots might bring changes at the supermarket. Lewis Holloway, who studies agriculture at the University of Hull, UK, says that robotic milking is likely to influence the genetics of dairy herds as farmers opt for robot-friendly cows, with udder shape, and even attitudes, suited to automated milking. Similarly, he says, its conceivable that agribots could influence what fruit or vegetable varieties get to the shops, since farmers may prefer to grow those with, say, leaf shapes that are easier for their robots to discriminate from weeds. Almost inevitably, these machines will eventually alter the landscape, too. The real tipping point for robot agriculture will come when farms are being designed with agribots in mind, says Salah Sukkarieh, a robotics researcher at the Australian Center for Field Robotics, Sydney. This could mean a return to smaller fields, with crops planted in grids rather than rows and fruit trees pruned into two-dimensional shapes to make harvesting easier. This alien terrain tended by robots is still a while away, he says but it will happen.", "hypothesis": "Farms in Europe and the US may find it hard to adapt to precision farming.", "gold_label": "neutral"}
{"uid": "id_552", "premise": "The school authorities have decided to increase the number of students in each classroom to seventy from the next academic session to bridge the gap between the income and the expenditure to a large extent.", "hypothesis": "The income generated by way of fees of the additional students will be sufficient enough to bridge the gap", "gold_label": "entailment"}
{"uid": "id_553", "premise": "The school authorities have decided to increase the number of students in each classroom to seventy from the next academic session to bridge the gap between the income and the expenditure to a large extent.", "hypothesis": "The school will get all the additional students in each class from the next academic session.", "gold_label": "neutral"}
{"uid": "id_554", "premise": "The school authority has decided to increase the number of students in each classroom to seventy from the next academic session to bridge the gap between income and expenditure to a largest extent.", "hypothesis": "The income generated by way of fees of the additional students will be sufficient enough to bridge the gap.", "gold_label": "entailment"}
{"uid": "id_555", "premise": "The school authority has decided to increase the number of students in each classroom to seventy from the next academic session to bridge the gap between income and expenditure to a largest extent.", "hypothesis": "The school will get all the additional students in each class from the next academic session. Canara Bank", "gold_label": "entailment"}
{"uid": "id_556", "premise": "The science of laterality the study of mental functions and the side of the brain from which they originate was advanced recently by research that found that around 30 per cent of dogs were either left- or right-pawed and the remainder were ambidex- trous. The research became of commercial interest when it was realized that the dogs that showed no preference for left or right were more likely to react badly to loud noises such as fireworks or thunderstorms. Such behaviour makes a dog unsuitable for a career sniffing out drugs or guiding the blind. As things stand, one in every two dogs fails the training programmes for these roles because of an intolerance of loud noise.", "hypothesis": "The case made in the passage would be strengthened if an intolerance to loud noise were manifest in dogs before they began training for careers as guides for the blind or to sniff out drugs.", "gold_label": "contradiction"}
{"uid": "id_557", "premise": "The science of laterality the study of mental functions and the side of the brain from which they originate was advanced recently by research that found that around 30 per cent of dogs were either left- or right-pawed and the remainder were ambidex- trous. The research became of commercial interest when it was realized that the dogs that showed no preference for left or right were more likely to react badly to loud noises such as fireworks or thunderstorms. Such behaviour makes a dog unsuitable for a career sniffing out drugs or guiding the blind. As things stand, one in every two dogs fails the training programmes for these roles because of an intolerance of loud noise.", "hypothesis": "The commercial interest mentioned in the passage can be taken to relate to a hope that a test of paw preference will improve the selection process by which dogs are chosen for these careers.", "gold_label": "entailment"}
{"uid": "id_558", "premise": "The science of laterality the study of mental functions and the side of the brain from which they originate was advanced recently by research that found that around 30 per cent of dogs were either left- or right-pawed and the remainder were ambidex- trous. The research became of commercial interest when it was realized that the dogs that showed no preference for left or right were more likely to react badly to loud noises such as fireworks or thunderstorms. Such behaviour makes a dog unsuitable for a career sniffing out drugs or guiding the blind. As things stand, one in every two dogs fails the training programmes for these roles because of an intolerance of loud noise.", "hypothesis": "In relation to dogs, the term ambidextrous can be taken to mean that they showed no preference as to which paw they use.", "gold_label": "entailment"}
{"uid": "id_559", "premise": "The secret of staying young Pheidole dentata, a native ant of the south-eastern U. S. , isn't immortal. But scientists have found that it doesn't seem to show any signs of aging. Old worker ants can do everything just as well as the youngsters, and their brains appear just as sharp. 'We get a picture that these ants really don't decline, ' says Ysabel Giraldo, who studied the ants for her doctoral thesis at Boston University. Such age-defying feats are rare in the animal kingdom. Naked mole rats can live for almost 30 years and stay fit for nearly their entire lives. They can still reproduce even when old, and they never get cancer. But the vast majority of animals deteriorate with age just like people do. Like the naked mole rat, ants are social creatures that usually live in highly organised colonies. 'It's this social complexity that makes P. dentata useful for studying aging in people, ' says Giraldo, now at the California Institute of Technology. Humans are also highly social, a trait that has been connected to healthier aging. By contrast, most animal studies of aging use mice, worms or fruit flies, which all lead much more isolated lives. In the lab, P. dentata worker ants typically live for around 140 days. Giraldo focused on ants at four age ranges: 20 to 22 days, 45 to 47 days, 95 to 97 days and 120 to 122 days. Unlike all previous studies, which only estimated how old the ants were, her work tracked the ants from the time the pupae became adults, so she knew their exact ages. Then she put them through a range of tests. Giraldo watched how well the ants took care of the young of the colony, recording how often each ant attended to, carried and fed them. She compared how well 20-day-old and 95-day-old ants followed the telltale scent that the insects usually leave to mark a trail to food. She tested how ants responded to light and also measured how active they were by counting how often ants in a small dish walked across a line. And she experimented with how ants react to live prey: a tethered fruit fly. Giraldo expected the older ants to perform poorly in all these tasks. But the elderly insects were all good caretakers and trail-followersthe 95-day-old ants could track the scent even longer than their younger counterparts. They all responded to light well, and the older ants were more active. And when it came to reacting to prey, the older ants attacked the poor fruit fly just as aggressively as the young ones did, flaring their mandibles or pulling at the fly's legs. Then Giraldo compared the brains of 20-day-old and 95-day-old ants, identifying any cells that were close to death. She saw no major differences with age, nor was there any difference in the location of the dying cells, showing that age didn't seem to affect specific brain functions. Ants and other insects have structures in their brains called mushroom bodies, which are important for processing information, learning and memory. She also wanted to see if aging affects the density of synaptic complexes within these structuresregions where neurons come together. Again, the answer was no. What was more, the old ants didn't experience any drop in the levels of either serotonin or dopaminebrain chemicals whose decline often coincides with aging. In humans, for example, a decrease in serotonin has been linked to Alzheimer's disease. 'This is the first time anyone has looked at both behavioral and neural changes in these ants so thoroughly, ' says Giraldo, who recently published the findings in the Proceedings of the Royal Society B. Scientists have looked at some similar aspects in bees, but the results of recent bee studies were mixedsome studies showed age-related declines, which biologists call senescence, and others didn't. 'For now, the study raises more questions than it answers, ' Giraldo says, 'including how P. dentata stays in such good shape. ' Also, if the ants don't deteriorate with age, why do they die at all? Out in the wild, the ants probably don't live for a full 140 days thanks to predators, disease and just being in an environment that's much harsher than the comforts of the lab. 'The lucky ants that do live into old age may suffer a steep decline just before dying, ' Giraldo says, but she can't say for sure because her study wasn't designed to follow an ant's final moments. 'It will be important to extend these findings to other species of social insects, ' says Gene E. Robinson, an entomologist at the University of Illinois at Urbana-Champaign. This ant might be unique, or it might represent a broader pattern among other social bugs with possible clues to the science of aging in larger animals. Either way, it seems that for these ants, age really doesn't matter.", "hypothesis": "The ants in Giraldo's experiments behaved as she had predicted that they would.", "gold_label": "contradiction"}
{"uid": "id_560", "premise": "The secret of staying young Pheidole dentata, a native ant of the south-eastern U. S. , isn't immortal. But scientists have found that it doesn't seem to show any signs of aging. Old worker ants can do everything just as well as the youngsters, and their brains appear just as sharp. 'We get a picture that these ants really don't decline, ' says Ysabel Giraldo, who studied the ants for her doctoral thesis at Boston University. Such age-defying feats are rare in the animal kingdom. Naked mole rats can live for almost 30 years and stay fit for nearly their entire lives. They can still reproduce even when old, and they never get cancer. But the vast majority of animals deteriorate with age just like people do. Like the naked mole rat, ants are social creatures that usually live in highly organised colonies. 'It's this social complexity that makes P. dentata useful for studying aging in people, ' says Giraldo, now at the California Institute of Technology. Humans are also highly social, a trait that has been connected to healthier aging. By contrast, most animal studies of aging use mice, worms or fruit flies, which all lead much more isolated lives. In the lab, P. dentata worker ants typically live for around 140 days. Giraldo focused on ants at four age ranges: 20 to 22 days, 45 to 47 days, 95 to 97 days and 120 to 122 days. Unlike all previous studies, which only estimated how old the ants were, her work tracked the ants from the time the pupae became adults, so she knew their exact ages. Then she put them through a range of tests. Giraldo watched how well the ants took care of the young of the colony, recording how often each ant attended to, carried and fed them. She compared how well 20-day-old and 95-day-old ants followed the telltale scent that the insects usually leave to mark a trail to food. She tested how ants responded to light and also measured how active they were by counting how often ants in a small dish walked across a line. And she experimented with how ants react to live prey: a tethered fruit fly. Giraldo expected the older ants to perform poorly in all these tasks. But the elderly insects were all good caretakers and trail-followersthe 95-day-old ants could track the scent even longer than their younger counterparts. They all responded to light well, and the older ants were more active. And when it came to reacting to prey, the older ants attacked the poor fruit fly just as aggressively as the young ones did, flaring their mandibles or pulling at the fly's legs. Then Giraldo compared the brains of 20-day-old and 95-day-old ants, identifying any cells that were close to death. She saw no major differences with age, nor was there any difference in the location of the dying cells, showing that age didn't seem to affect specific brain functions. Ants and other insects have structures in their brains called mushroom bodies, which are important for processing information, learning and memory. She also wanted to see if aging affects the density of synaptic complexes within these structuresregions where neurons come together. Again, the answer was no. What was more, the old ants didn't experience any drop in the levels of either serotonin or dopaminebrain chemicals whose decline often coincides with aging. In humans, for example, a decrease in serotonin has been linked to Alzheimer's disease. 'This is the first time anyone has looked at both behavioral and neural changes in these ants so thoroughly, ' says Giraldo, who recently published the findings in the Proceedings of the Royal Society B. Scientists have looked at some similar aspects in bees, but the results of recent bee studies were mixedsome studies showed age-related declines, which biologists call senescence, and others didn't. 'For now, the study raises more questions than it answers, ' Giraldo says, 'including how P. dentata stays in such good shape. ' Also, if the ants don't deteriorate with age, why do they die at all? Out in the wild, the ants probably don't live for a full 140 days thanks to predators, disease and just being in an environment that's much harsher than the comforts of the lab. 'The lucky ants that do live into old age may suffer a steep decline just before dying, ' Giraldo says, but she can't say for sure because her study wasn't designed to follow an ant's final moments. 'It will be important to extend these findings to other species of social insects, ' says Gene E. Robinson, an entomologist at the University of Illinois at Urbana-Champaign. This ant might be unique, or it might represent a broader pattern among other social bugs with possible clues to the science of aging in larger animals. Either way, it seems that for these ants, age really doesn't matter.", "hypothesis": "Ysabel Giraldo was the first person to study Pheidole dentata ants using precise data about the insects' ages.", "gold_label": "entailment"}
{"uid": "id_561", "premise": "The secret of staying young Pheidole dentata, a native ant of the south-eastern U. S. , isn't immortal. But scientists have found that it doesn't seem to show any signs of aging. Old worker ants can do everything just as well as the youngsters, and their brains appear just as sharp. 'We get a picture that these ants really don't decline, ' says Ysabel Giraldo, who studied the ants for her doctoral thesis at Boston University. Such age-defying feats are rare in the animal kingdom. Naked mole rats can live for almost 30 years and stay fit for nearly their entire lives. They can still reproduce even when old, and they never get cancer. But the vast majority of animals deteriorate with age just like people do. Like the naked mole rat, ants are social creatures that usually live in highly organised colonies. 'It's this social complexity that makes P. dentata useful for studying aging in people, ' says Giraldo, now at the California Institute of Technology. Humans are also highly social, a trait that has been connected to healthier aging. By contrast, most animal studies of aging use mice, worms or fruit flies, which all lead much more isolated lives. In the lab, P. dentata worker ants typically live for around 140 days. Giraldo focused on ants at four age ranges: 20 to 22 days, 45 to 47 days, 95 to 97 days and 120 to 122 days. Unlike all previous studies, which only estimated how old the ants were, her work tracked the ants from the time the pupae became adults, so she knew their exact ages. Then she put them through a range of tests. Giraldo watched how well the ants took care of the young of the colony, recording how often each ant attended to, carried and fed them. She compared how well 20-day-old and 95-day-old ants followed the telltale scent that the insects usually leave to mark a trail to food. She tested how ants responded to light and also measured how active they were by counting how often ants in a small dish walked across a line. And she experimented with how ants react to live prey: a tethered fruit fly. Giraldo expected the older ants to perform poorly in all these tasks. But the elderly insects were all good caretakers and trail-followersthe 95-day-old ants could track the scent even longer than their younger counterparts. They all responded to light well, and the older ants were more active. And when it came to reacting to prey, the older ants attacked the poor fruit fly just as aggressively as the young ones did, flaring their mandibles or pulling at the fly's legs. Then Giraldo compared the brains of 20-day-old and 95-day-old ants, identifying any cells that were close to death. She saw no major differences with age, nor was there any difference in the location of the dying cells, showing that age didn't seem to affect specific brain functions. Ants and other insects have structures in their brains called mushroom bodies, which are important for processing information, learning and memory. She also wanted to see if aging affects the density of synaptic complexes within these structuresregions where neurons come together. Again, the answer was no. What was more, the old ants didn't experience any drop in the levels of either serotonin or dopaminebrain chemicals whose decline often coincides with aging. In humans, for example, a decrease in serotonin has been linked to Alzheimer's disease. 'This is the first time anyone has looked at both behavioral and neural changes in these ants so thoroughly, ' says Giraldo, who recently published the findings in the Proceedings of the Royal Society B. Scientists have looked at some similar aspects in bees, but the results of recent bee studies were mixedsome studies showed age-related declines, which biologists call senescence, and others didn't. 'For now, the study raises more questions than it answers, ' Giraldo says, 'including how P. dentata stays in such good shape. ' Also, if the ants don't deteriorate with age, why do they die at all? Out in the wild, the ants probably don't live for a full 140 days thanks to predators, disease and just being in an environment that's much harsher than the comforts of the lab. 'The lucky ants that do live into old age may suffer a steep decline just before dying, ' Giraldo says, but she can't say for sure because her study wasn't designed to follow an ant's final moments. 'It will be important to extend these findings to other species of social insects, ' says Gene E. Robinson, an entomologist at the University of Illinois at Urbana-Champaign. This ant might be unique, or it might represent a broader pattern among other social bugs with possible clues to the science of aging in larger animals. Either way, it seems that for these ants, age really doesn't matter.", "hypothesis": "Pheidole dentata ants are the only known animals which remain active for almost their whole lives.", "gold_label": "contradiction"}
{"uid": "id_562", "premise": "The secret of staying young Pheidole dentata, a native ant of the south-eastern U. S. , isn't immortal. But scientists have found that it doesn't seem to show any signs of aging. Old worker ants can do everything just as well as the youngsters, and their brains appear just as sharp. 'We get a picture that these ants really don't decline, ' says Ysabel Giraldo, who studied the ants for her doctoral thesis at Boston University. Such age-defying feats are rare in the animal kingdom. Naked mole rats can live for almost 30 years and stay fit for nearly their entire lives. They can still reproduce even when old, and they never get cancer. But the vast majority of animals deteriorate with age just like people do. Like the naked mole rat, ants are social creatures that usually live in highly organised colonies. 'It's this social complexity that makes P. dentata useful for studying aging in people, ' says Giraldo, now at the California Institute of Technology. Humans are also highly social, a trait that has been connected to healthier aging. By contrast, most animal studies of aging use mice, worms or fruit flies, which all lead much more isolated lives. In the lab, P. dentata worker ants typically live for around 140 days. Giraldo focused on ants at four age ranges: 20 to 22 days, 45 to 47 days, 95 to 97 days and 120 to 122 days. Unlike all previous studies, which only estimated how old the ants were, her work tracked the ants from the time the pupae became adults, so she knew their exact ages. Then she put them through a range of tests. Giraldo watched how well the ants took care of the young of the colony, recording how often each ant attended to, carried and fed them. She compared how well 20-day-old and 95-day-old ants followed the telltale scent that the insects usually leave to mark a trail to food. She tested how ants responded to light and also measured how active they were by counting how often ants in a small dish walked across a line. And she experimented with how ants react to live prey: a tethered fruit fly. Giraldo expected the older ants to perform poorly in all these tasks. But the elderly insects were all good caretakers and trail-followersthe 95-day-old ants could track the scent even longer than their younger counterparts. They all responded to light well, and the older ants were more active. And when it came to reacting to prey, the older ants attacked the poor fruit fly just as aggressively as the young ones did, flaring their mandibles or pulling at the fly's legs. Then Giraldo compared the brains of 20-day-old and 95-day-old ants, identifying any cells that were close to death. She saw no major differences with age, nor was there any difference in the location of the dying cells, showing that age didn't seem to affect specific brain functions. Ants and other insects have structures in their brains called mushroom bodies, which are important for processing information, learning and memory. She also wanted to see if aging affects the density of synaptic complexes within these structuresregions where neurons come together. Again, the answer was no. What was more, the old ants didn't experience any drop in the levels of either serotonin or dopaminebrain chemicals whose decline often coincides with aging. In humans, for example, a decrease in serotonin has been linked to Alzheimer's disease. 'This is the first time anyone has looked at both behavioral and neural changes in these ants so thoroughly, ' says Giraldo, who recently published the findings in the Proceedings of the Royal Society B. Scientists have looked at some similar aspects in bees, but the results of recent bee studies were mixedsome studies showed age-related declines, which biologists call senescence, and others didn't. 'For now, the study raises more questions than it answers, ' Giraldo says, 'including how P. dentata stays in such good shape. ' Also, if the ants don't deteriorate with age, why do they die at all? Out in the wild, the ants probably don't live for a full 140 days thanks to predators, disease and just being in an environment that's much harsher than the comforts of the lab. 'The lucky ants that do live into old age may suffer a steep decline just before dying, ' Giraldo says, but she can't say for sure because her study wasn't designed to follow an ant's final moments. 'It will be important to extend these findings to other species of social insects, ' says Gene E. Robinson, an entomologist at the University of Illinois at Urbana-Champaign. This ant might be unique, or it might represent a broader pattern among other social bugs with possible clues to the science of aging in larger animals. Either way, it seems that for these ants, age really doesn't matter.", "hypothesis": "The recent studies of bees used different methods of measuring age-related decline.", "gold_label": "neutral"}
{"uid": "id_563", "premise": "The secret of staying young Pheidole dentata, a native ant of the south-eastern U. S. , isn't immortal. But scientists have found that it doesn't seem to show any signs of aging. Old worker ants can do everything just as well as the youngsters, and their brains appear just as sharp. 'We get a picture that these ants really don't decline, ' says Ysabel Giraldo, who studied the ants for her doctoral thesis at Boston University. Such age-defying feats are rare in the animal kingdom. Naked mole rats can live for almost 30 years and stay fit for nearly their entire lives. They can still reproduce even when old, and they never get cancer. But the vast majority of animals deteriorate with age just like people do. Like the naked mole rat, ants are social creatures that usually live in highly organised colonies. 'It's this social complexity that makes P. dentata useful for studying aging in people, ' says Giraldo, now at the California Institute of Technology. Humans are also highly social, a trait that has been connected to healthier aging. By contrast, most animal studies of aging use mice, worms or fruit flies, which all lead much more isolated lives. In the lab, P. dentata worker ants typically live for around 140 days. Giraldo focused on ants at four age ranges: 20 to 22 days, 45 to 47 days, 95 to 97 days and 120 to 122 days. Unlike all previous studies, which only estimated how old the ants were, her work tracked the ants from the time the pupae became adults, so she knew their exact ages. Then she put them through a range of tests. Giraldo watched how well the ants took care of the young of the colony, recording how often each ant attended to, carried and fed them. She compared how well 20-day-old and 95-day-old ants followed the telltale scent that the insects usually leave to mark a trail to food. She tested how ants responded to light and also measured how active they were by counting how often ants in a small dish walked across a line. And she experimented with how ants react to live prey: a tethered fruit fly. Giraldo expected the older ants to perform poorly in all these tasks. But the elderly insects were all good caretakers and trail-followersthe 95-day-old ants could track the scent even longer than their younger counterparts. They all responded to light well, and the older ants were more active. And when it came to reacting to prey, the older ants attacked the poor fruit fly just as aggressively as the young ones did, flaring their mandibles or pulling at the fly's legs. Then Giraldo compared the brains of 20-day-old and 95-day-old ants, identifying any cells that were close to death. She saw no major differences with age, nor was there any difference in the location of the dying cells, showing that age didn't seem to affect specific brain functions. Ants and other insects have structures in their brains called mushroom bodies, which are important for processing information, learning and memory. She also wanted to see if aging affects the density of synaptic complexes within these structuresregions where neurons come together. Again, the answer was no. What was more, the old ants didn't experience any drop in the levels of either serotonin or dopaminebrain chemicals whose decline often coincides with aging. In humans, for example, a decrease in serotonin has been linked to Alzheimer's disease. 'This is the first time anyone has looked at both behavioral and neural changes in these ants so thoroughly, ' says Giraldo, who recently published the findings in the Proceedings of the Royal Society B. Scientists have looked at some similar aspects in bees, but the results of recent bee studies were mixedsome studies showed age-related declines, which biologists call senescence, and others didn't. 'For now, the study raises more questions than it answers, ' Giraldo says, 'including how P. dentata stays in such good shape. ' Also, if the ants don't deteriorate with age, why do they die at all? Out in the wild, the ants probably don't live for a full 140 days thanks to predators, disease and just being in an environment that's much harsher than the comforts of the lab. 'The lucky ants that do live into old age may suffer a steep decline just before dying, ' Giraldo says, but she can't say for sure because her study wasn't designed to follow an ant's final moments. 'It will be important to extend these findings to other species of social insects, ' says Gene E. Robinson, an entomologist at the University of Illinois at Urbana-Champaign. This ant might be unique, or it might represent a broader pattern among other social bugs with possible clues to the science of aging in larger animals. Either way, it seems that for these ants, age really doesn't matter.", "hypothesis": "Pheidole dentata ants kept in laboratory conditions tend to live longer lives.", "gold_label": "entailment"}
{"uid": "id_564", "premise": "The secret of the Yawn A. When a scientist began to study yawning in the 1980s, it was difficult to convince some of his research students of the merits of \"yawning science. \" Although it may appear quirky, his decision to study yawning was a logical extension to human beings of my research in developmental neuroscience, reported in such papers as \"Wing-flapping during Development and Evolution. \" As a neurobehavioral problem, there is not much difference between the wing- flapping of birds and the face-and body-flapping of human yawners. B. Yawning is an ancient, primitive act. Humans do it even before they are born, opening wide in the womb. Some snakes unhinge then jaws to do it. One species of penguins yawns as part of mating. Only now are researchers beginning to understand why we yawn, when we yawn and why we yawn back. A professor of cognitive neuroscience at Drexel Universityin Philadelphia, Steven Platek, studies the act of contagious yawning, something done only by people and other primates. C. In his first experiment, he used a psychological test to rank people on then empathic feelings. He found that participants who did not score high on compassion did not yawn back. \"We literally had people saying, 'Why am I looking at people yawning? \" 1 Professor Platek said. \"It just had no effect. \" D. For his second experiment, he put 10 students in an magnetic resonance imaging machine as they watched video tapes of people yawning. When the students watched the videos, the part of the brain which reacted was the part scientists believe controls empathy - the posterior cingulate, in the brain's middle rear. \" I don't know if it's necessarily that nice people yawn more, but I think it's a good indicator of a state of mind, \" said Professor Platek. \"It's also a good indicator if you're empathizing with me and paying attention. \" E. His third experiment is studying yawning in those with brain disorders, such as autism and schizophrenia, in which victims have difficulty connecting emotionally with others. A psychology professor at the University of Maryland, Robert Provine, is one of the few other researchers into yawning. He found the basic yawn lasts about six seconds and they come in bouts with an interval of about 68 seconds. Men and women yawn or half- yawn equally often, but men are significantly less likely to cover then mouths which may indicate complex distinction in genders. \" A watched yawner never yawns, \" Professor Provine said. However, the physical root of yawning remains a mystery. Some researchers say it's coordinated within the lypothal of the brain, the area that also controls breathing. F. Yawning and stretching also share properties and may be performed together as parts of a global motor complex. But they do notalways co-occur people usually yawn when we stretch, but we don't always stretch when we yawn, especially before bedtime. Studies by J. I. P, G. H. A. Visser and H. F. Prechtl in the early 1980s, charting movement in the developing fetus using ultrasound, observed not just yawning but a link between yawning and stretching as early as the end of the first prenatal trimester G. The most extraordinary demonstration of the yawn-stretch linkage occurs in many people paralyzed on one side of their body because of brain damage caused by a stroke. The prominent British neurologist Sir Francis Walshe noted in 1923 that when these hemiplegics yawn, they are startled and mystified to observe that then otherwise paralyzed arm rises and flexes automatically in what neurologists term an \"associated response. \" Yawning apparently activates undamaged, unconsciously controlled connections between the brain and the cord motor system innervating the paralyzed limb. It is not known whether the associated response is a positive prognosis for recovery, nor whether yawning is therapeutic for reinnervation or prevention of muscular atrophy. H. Clinical neurology offers other surprises. Some patients with \"locked-in\" syndrome, who are almost totally deprived of the ability to move voluntarily, can yawn normally. The neural circuits for spontaneous yawning must exist in the brain stem near other respiratory and vasomotor centers, because yawning is performed by anencephalic who possess only the medulla oblongata. The multiplicity of stimuli of contagious yawning, by contrast, implicates many higher brain regions.", "hypothesis": "Yawning can show an affirmative impact on the recovery from brain damage brought by a stroke.", "gold_label": "neutral"}
{"uid": "id_565", "premise": "The secret of the Yawn A. When a scientist began to study yawning in the 1980s, it was difficult to convince some of his research students of the merits of \"yawning science. \" Although it may appear quirky, his decision to study yawning was a logical extension to human beings of my research in developmental neuroscience, reported in such papers as \"Wing-flapping during Development and Evolution. \" As a neurobehavioral problem, there is not much difference between the wing- flapping of birds and the face-and body-flapping of human yawners. B. Yawning is an ancient, primitive act. Humans do it even before they are born, opening wide in the womb. Some snakes unhinge then jaws to do it. One species of penguins yawns as part of mating. Only now are researchers beginning to understand why we yawn, when we yawn and why we yawn back. A professor of cognitive neuroscience at Drexel Universityin Philadelphia, Steven Platek, studies the act of contagious yawning, something done only by people and other primates. C. In his first experiment, he used a psychological test to rank people on then empathic feelings. He found that participants who did not score high on compassion did not yawn back. \"We literally had people saying, 'Why am I looking at people yawning? \" 1 Professor Platek said. \"It just had no effect. \" D. For his second experiment, he put 10 students in an magnetic resonance imaging machine as they watched video tapes of people yawning. When the students watched the videos, the part of the brain which reacted was the part scientists believe controls empathy - the posterior cingulate, in the brain's middle rear. \" I don't know if it's necessarily that nice people yawn more, but I think it's a good indicator of a state of mind, \" said Professor Platek. \"It's also a good indicator if you're empathizing with me and paying attention. \" E. His third experiment is studying yawning in those with brain disorders, such as autism and schizophrenia, in which victims have difficulty connecting emotionally with others. A psychology professor at the University of Maryland, Robert Provine, is one of the few other researchers into yawning. He found the basic yawn lasts about six seconds and they come in bouts with an interval of about 68 seconds. Men and women yawn or half- yawn equally often, but men are significantly less likely to cover then mouths which may indicate complex distinction in genders. \" A watched yawner never yawns, \" Professor Provine said. However, the physical root of yawning remains a mystery. Some researchers say it's coordinated within the lypothal of the brain, the area that also controls breathing. F. Yawning and stretching also share properties and may be performed together as parts of a global motor complex. But they do notalways co-occur people usually yawn when we stretch, but we don't always stretch when we yawn, especially before bedtime. Studies by J. I. P, G. H. A. Visser and H. F. Prechtl in the early 1980s, charting movement in the developing fetus using ultrasound, observed not just yawning but a link between yawning and stretching as early as the end of the first prenatal trimester G. The most extraordinary demonstration of the yawn-stretch linkage occurs in many people paralyzed on one side of their body because of brain damage caused by a stroke. The prominent British neurologist Sir Francis Walshe noted in 1923 that when these hemiplegics yawn, they are startled and mystified to observe that then otherwise paralyzed arm rises and flexes automatically in what neurologists term an \"associated response. \" Yawning apparently activates undamaged, unconsciously controlled connections between the brain and the cord motor system innervating the paralyzed limb. It is not known whether the associated response is a positive prognosis for recovery, nor whether yawning is therapeutic for reinnervation or prevention of muscular atrophy. H. Clinical neurology offers other surprises. Some patients with \"locked-in\" syndrome, who are almost totally deprived of the ability to move voluntarily, can yawn normally. The neural circuits for spontaneous yawning must exist in the brain stem near other respiratory and vasomotor centers, because yawning is performed by anencephalic who possess only the medulla oblongata. The multiplicity of stimuli of contagious yawning, by contrast, implicates many higher brain regions.", "hypothesis": "Some results from certain experiment indicate the link between yawning and compassion.", "gold_label": "contradiction"}
{"uid": "id_566", "premise": "The secret of the Yawn A. When a scientist began to study yawning in the 1980s, it was difficult to convince some of his research students of the merits of \"yawning science. \" Although it may appear quirky, his decision to study yawning was a logical extension to human beings of my research in developmental neuroscience, reported in such papers as \"Wing-flapping during Development and Evolution. \" As a neurobehavioral problem, there is not much difference between the wing- flapping of birds and the face-and body-flapping of human yawners. B. Yawning is an ancient, primitive act. Humans do it even before they are born, opening wide in the womb. Some snakes unhinge then jaws to do it. One species of penguins yawns as part of mating. Only now are researchers beginning to understand why we yawn, when we yawn and why we yawn back. A professor of cognitive neuroscience at Drexel Universityin Philadelphia, Steven Platek, studies the act of contagious yawning, something done only by people and other primates. C. In his first experiment, he used a psychological test to rank people on then empathic feelings. He found that participants who did not score high on compassion did not yawn back. \"We literally had people saying, 'Why am I looking at people yawning? \" 1 Professor Platek said. \"It just had no effect. \" D. For his second experiment, he put 10 students in an magnetic resonance imaging machine as they watched video tapes of people yawning. When the students watched the videos, the part of the brain which reacted was the part scientists believe controls empathy - the posterior cingulate, in the brain's middle rear. \" I don't know if it's necessarily that nice people yawn more, but I think it's a good indicator of a state of mind, \" said Professor Platek. \"It's also a good indicator if you're empathizing with me and paying attention. \" E. His third experiment is studying yawning in those with brain disorders, such as autism and schizophrenia, in which victims have difficulty connecting emotionally with others. A psychology professor at the University of Maryland, Robert Provine, is one of the few other researchers into yawning. He found the basic yawn lasts about six seconds and they come in bouts with an interval of about 68 seconds. Men and women yawn or half- yawn equally often, but men are significantly less likely to cover then mouths which may indicate complex distinction in genders. \" A watched yawner never yawns, \" Professor Provine said. However, the physical root of yawning remains a mystery. Some researchers say it's coordinated within the lypothal of the brain, the area that also controls breathing. F. Yawning and stretching also share properties and may be performed together as parts of a global motor complex. But they do notalways co-occur people usually yawn when we stretch, but we don't always stretch when we yawn, especially before bedtime. Studies by J. I. P, G. H. A. Visser and H. F. Prechtl in the early 1980s, charting movement in the developing fetus using ultrasound, observed not just yawning but a link between yawning and stretching as early as the end of the first prenatal trimester G. The most extraordinary demonstration of the yawn-stretch linkage occurs in many people paralyzed on one side of their body because of brain damage caused by a stroke. The prominent British neurologist Sir Francis Walshe noted in 1923 that when these hemiplegics yawn, they are startled and mystified to observe that then otherwise paralyzed arm rises and flexes automatically in what neurologists term an \"associated response. \" Yawning apparently activates undamaged, unconsciously controlled connections between the brain and the cord motor system innervating the paralyzed limb. It is not known whether the associated response is a positive prognosis for recovery, nor whether yawning is therapeutic for reinnervation or prevention of muscular atrophy. H. Clinical neurology offers other surprises. Some patients with \"locked-in\" syndrome, who are almost totally deprived of the ability to move voluntarily, can yawn normally. The neural circuits for spontaneous yawning must exist in the brain stem near other respiratory and vasomotor centers, because yawning is performed by anencephalic who possess only the medulla oblongata. The multiplicity of stimuli of contagious yawning, by contrast, implicates many higher brain regions.", "hypothesis": "Several students in Plateks experiment did not comprehend why then tutor ask them to yawn back.", "gold_label": "entailment"}
{"uid": "id_567", "premise": "The secret to success in business is entrepreneurial spirit at all levels of the company. Employees who are identified as entrepreneurs in their own right are more motivated their own financial success becomes integrated with the company's. Those who are oriented towards personal entrepreneurship will work long hours to develop their own tried-and-tested business practices and strategies, contributing as willing partners to the achievements of the company as a whole. Orientation and value-formation training can induce this kind of thinking in new staff recruits, inculcating the notion of how quickly it is possible to achieve financial security through hard work and innovative business approaches, combined with the impression that to miss out on opportunities for such rapid economic and social advancement would be at best unwise and at worst catastrophic.", "hypothesis": "New staff members can be indoctrinated with the virtues of entrepreneurship.", "gold_label": "entailment"}
{"uid": "id_568", "premise": "The secret to success in business is entrepreneurial spirit at all levels of the company. Employees who are identified as entrepreneurs in their own right are more motivated their own financial success becomes integrated with the company's. Those who are oriented towards personal entrepreneurship will work long hours to develop their own tried-and-tested business practices and strategies, contributing as willing partners to the achievements of the company as a whole. Orientation and value-formation training can induce this kind of thinking in new staff recruits, inculcating the notion of how quickly it is possible to achieve financial security through hard work and innovative business approaches, combined with the impression that to miss out on opportunities for such rapid economic and social advancement would be at best unwise and at worst catastrophic.", "hypothesis": "Employees encouraged to think of themselves as entrepreneurs work fewer hours than other staff members.", "gold_label": "neutral"}
{"uid": "id_569", "premise": "The secret to success in business is entrepreneurial spirit at all levels of the company. Employees who are identified as entrepreneurs in their own right are more motivated their own financial success becomes integrated with the company's. Those who are oriented towards personal entrepreneurship will work long hours to develop their own tried-and-tested business practices and strategies, contributing as willing partners to the achievements of the company as a whole. Orientation and value-formation training can induce this kind of thinking in new staff recruits, inculcating the notion of how quickly it is possible to achieve financial security through hard work and innovative business approaches, combined with the impression that to miss out on opportunities for such rapid economic and social advancement would be at best unwise and at worst catastrophic.", "hypothesis": "Employees instilled with the idea of personal entrepreneurship will be less willing to contribute to the success of the company as a whole.", "gold_label": "contradiction"}
{"uid": "id_570", "premise": "The significant role of mother tongue language in education One consequence of population mobility is an increasing diversity within schools. To illustrate, in the city of Toronto in Canada, 58% of kindergarten pupils come from homes where English is not language of communication. Schools in Europe and North America have experienced this diversity for years, but educational policies and practices vary widely between countries and even within countries. Some political parties and groups search for ways to solve the problem of diverse communities and their integration in schools and society. They see few positive consequences for the host society and worry that diversity threaten the identity of the host society . Consequently, they promote unfortunate educational policies that will make the problem disappear. If students retain their culture and language, they are viewed as less capable of identifying with the mainstream culture and learning the mainstream language of the society. The challenge for educators and policy-makers is to shape the evolution of national identity in such a way that the rights of all citizens (including school children) are respected, and the cultural, linguistic, and economic resources of the nation are maximized. To waste the resources of the nation by discouraging children from developing their mother tongues is quite simply unintelligent from the point of view of national self-interest. A first step in Providing an appropriate education for culturally and linguistically diverse children is to examine what the existing research says about the role of childrens mother tongues in their educational development. In fact, the research is very clear. When children continue to develop their abilities in two or more languages throughout their primary school, they gain a deeper understanding of language and how to use it effectively. They have more practice in processing language, especially when they develop literacy in both. More than 150 research studies conducted during the past 35 years strongly support what Goethe, the famous eighteenth-century German philosopher, once said: that the person who knows only one language does not truly know that language. Research suggests that bilingual children may also develop more flexibility in their thinking as a result of processing information through two different languages. The level of development of childrens mother tongue is a strong predictor of their second language development. Children who come to school with a solid foundation in their mother tongue develop stronger literacy abilities in the school language. When parents and other caregivers (e. g. grandparents) are able to spend time with their children and tell stories or discuss issues with them in a way that develops their mother tongue, children come to school well-prepared to learn the school language and succeed educationally. Childrens knowledge and skills transfer across languages from the mother tongue to the school language. Transfer across languages can be two-way: both languages nurture each other when the educational environment permits children access to both languages. Some educators and parents are suspicious of mother tongue-based teaching programs because they worry that they take time away from the majority language. For example, in a bilingual program where 50% of the time is spent teaching through childrens home language and 50% through the majority language, surely childrens wont progress as far in the letter? One of the most strongly established findings of educational research, however, is that well-implemented bilingual programs can promote literacy and subject- matter knowledge in a minority language without any negative effects on childrens development in the majority language. Within Europe, the Foyer program in Belgium, which develops childrens speaking and literacy abilities in three languages (their mother tongue, Dutch and French), most clearly illustrates the benefits of bilingual and trilingual education (see Cummins, 2000). It is easy to understand how this happens. When children are learning through a minority language, they are learning concepts and intellectual skills too. Pupils who know how to tell the time in their mother tongue understand the concept of telling time. In order to tell time in the majority language they do not need to re-learn the concept. Similarly, at more advanced stages, there is transfer across languages in other skills such as knowing how to distinguish the main idea from the supporting details of a written passage or story, and distinguishing fact from opinion, Studies of secondary school pupils are providing interesting findings in this area, and it would be worth extending this research. Many people marvel at how quickly bilingual children seem to pick up conversational skills in the majority language at school (although it takes much longer for them to catch up to native speakers in academic language skills). However, educators are often much less aware of how quickly children can lose their ability to use their mother tongue, even in the home context. The extent and rapidity of language loss will vary according to the concentration of families from a particular linguistic group in the neighborhood. Where the mother tongue is used extensively in the community, then language loss among young children will be less. However, where language communities are not concentrated in particular neighborhoods, children can lose their ability to communicate in their mother tongue within 2-3 years of starting school. They may retain receptive skills in the language but they will use the majority language in speaking with their peers and siblings and in responding to their parents. By the time children become adolescents, the linguistic division between parents and children has become an emotional chasm. Pupils frequently become alienated from the cultures of both home and school with predictable results.", "hypothesis": "the foyer Program is to be accepted by the French education system.", "gold_label": "contradiction"}
{"uid": "id_571", "premise": "The significant role of mother tongue language in education One consequence of population mobility is an increasing diversity within schools. To illustrate, in the city of Toronto in Canada, 58% of kindergarten pupils come from homes where English is not language of communication. Schools in Europe and North America have experienced this diversity for years, but educational policies and practices vary widely between countries and even within countries. Some political parties and groups search for ways to solve the problem of diverse communities and their integration in schools and society. They see few positive consequences for the host society and worry that diversity threaten the identity of the host society . Consequently, they promote unfortunate educational policies that will make the problem disappear. If students retain their culture and language, they are viewed as less capable of identifying with the mainstream culture and learning the mainstream language of the society. The challenge for educators and policy-makers is to shape the evolution of national identity in such a way that the rights of all citizens (including school children) are respected, and the cultural, linguistic, and economic resources of the nation are maximized. To waste the resources of the nation by discouraging children from developing their mother tongues is quite simply unintelligent from the point of view of national self-interest. A first step in Providing an appropriate education for culturally and linguistically diverse children is to examine what the existing research says about the role of childrens mother tongues in their educational development. In fact, the research is very clear. When children continue to develop their abilities in two or more languages throughout their primary school, they gain a deeper understanding of language and how to use it effectively. They have more practice in processing language, especially when they develop literacy in both. More than 150 research studies conducted during the past 35 years strongly support what Goethe, the famous eighteenth-century German philosopher, once said: that the person who knows only one language does not truly know that language. Research suggests that bilingual children may also develop more flexibility in their thinking as a result of processing information through two different languages. The level of development of childrens mother tongue is a strong predictor of their second language development. Children who come to school with a solid foundation in their mother tongue develop stronger literacy abilities in the school language. When parents and other caregivers (e. g. grandparents) are able to spend time with their children and tell stories or discuss issues with them in a way that develops their mother tongue, children come to school well-prepared to learn the school language and succeed educationally. Childrens knowledge and skills transfer across languages from the mother tongue to the school language. Transfer across languages can be two-way: both languages nurture each other when the educational environment permits children access to both languages. Some educators and parents are suspicious of mother tongue-based teaching programs because they worry that they take time away from the majority language. For example, in a bilingual program where 50% of the time is spent teaching through childrens home language and 50% through the majority language, surely childrens wont progress as far in the letter? One of the most strongly established findings of educational research, however, is that well-implemented bilingual programs can promote literacy and subject- matter knowledge in a minority language without any negative effects on childrens development in the majority language. Within Europe, the Foyer program in Belgium, which develops childrens speaking and literacy abilities in three languages (their mother tongue, Dutch and French), most clearly illustrates the benefits of bilingual and trilingual education (see Cummins, 2000). It is easy to understand how this happens. When children are learning through a minority language, they are learning concepts and intellectual skills too. Pupils who know how to tell the time in their mother tongue understand the concept of telling time. In order to tell time in the majority language they do not need to re-learn the concept. Similarly, at more advanced stages, there is transfer across languages in other skills such as knowing how to distinguish the main idea from the supporting details of a written passage or story, and distinguishing fact from opinion, Studies of secondary school pupils are providing interesting findings in this area, and it would be worth extending this research. Many people marvel at how quickly bilingual children seem to pick up conversational skills in the majority language at school (although it takes much longer for them to catch up to native speakers in academic language skills). However, educators are often much less aware of how quickly children can lose their ability to use their mother tongue, even in the home context. The extent and rapidity of language loss will vary according to the concentration of families from a particular linguistic group in the neighborhood. Where the mother tongue is used extensively in the community, then language loss among young children will be less. However, where language communities are not concentrated in particular neighborhoods, children can lose their ability to communicate in their mother tongue within 2-3 years of starting school. They may retain receptive skills in the language but they will use the majority language in speaking with their peers and siblings and in responding to their parents. By the time children become adolescents, the linguistic division between parents and children has become an emotional chasm. Pupils frequently become alienated from the cultures of both home and school with predictable results.", "hypothesis": "Research proves that learning the host country language at school can have an adverse effect on a childs mother tongue.", "gold_label": "neutral"}
{"uid": "id_572", "premise": "The significant role of mother tongue language in education One consequence of population mobility is an increasing diversity within schools. To illustrate, in the city of Toronto in Canada, 58% of kindergarten pupils come from homes where English is not language of communication. Schools in Europe and North America have experienced this diversity for years, but educational policies and practices vary widely between countries and even within countries. Some political parties and groups search for ways to solve the problem of diverse communities and their integration in schools and society. They see few positive consequences for the host society and worry that diversity threaten the identity of the host society . Consequently, they promote unfortunate educational policies that will make the problem disappear. If students retain their culture and language, they are viewed as less capable of identifying with the mainstream culture and learning the mainstream language of the society. The challenge for educators and policy-makers is to shape the evolution of national identity in such a way that the rights of all citizens (including school children) are respected, and the cultural, linguistic, and economic resources of the nation are maximized. To waste the resources of the nation by discouraging children from developing their mother tongues is quite simply unintelligent from the point of view of national self-interest. A first step in Providing an appropriate education for culturally and linguistically diverse children is to examine what the existing research says about the role of childrens mother tongues in their educational development. In fact, the research is very clear. When children continue to develop their abilities in two or more languages throughout their primary school, they gain a deeper understanding of language and how to use it effectively. They have more practice in processing language, especially when they develop literacy in both. More than 150 research studies conducted during the past 35 years strongly support what Goethe, the famous eighteenth-century German philosopher, once said: that the person who knows only one language does not truly know that language. Research suggests that bilingual children may also develop more flexibility in their thinking as a result of processing information through two different languages. The level of development of childrens mother tongue is a strong predictor of their second language development. Children who come to school with a solid foundation in their mother tongue develop stronger literacy abilities in the school language. When parents and other caregivers (e. g. grandparents) are able to spend time with their children and tell stories or discuss issues with them in a way that develops their mother tongue, children come to school well-prepared to learn the school language and succeed educationally. Childrens knowledge and skills transfer across languages from the mother tongue to the school language. Transfer across languages can be two-way: both languages nurture each other when the educational environment permits children access to both languages. Some educators and parents are suspicious of mother tongue-based teaching programs because they worry that they take time away from the majority language. For example, in a bilingual program where 50% of the time is spent teaching through childrens home language and 50% through the majority language, surely childrens wont progress as far in the letter? One of the most strongly established findings of educational research, however, is that well-implemented bilingual programs can promote literacy and subject- matter knowledge in a minority language without any negative effects on childrens development in the majority language. Within Europe, the Foyer program in Belgium, which develops childrens speaking and literacy abilities in three languages (their mother tongue, Dutch and French), most clearly illustrates the benefits of bilingual and trilingual education (see Cummins, 2000). It is easy to understand how this happens. When children are learning through a minority language, they are learning concepts and intellectual skills too. Pupils who know how to tell the time in their mother tongue understand the concept of telling time. In order to tell time in the majority language they do not need to re-learn the concept. Similarly, at more advanced stages, there is transfer across languages in other skills such as knowing how to distinguish the main idea from the supporting details of a written passage or story, and distinguishing fact from opinion, Studies of secondary school pupils are providing interesting findings in this area, and it would be worth extending this research. Many people marvel at how quickly bilingual children seem to pick up conversational skills in the majority language at school (although it takes much longer for them to catch up to native speakers in academic language skills). However, educators are often much less aware of how quickly children can lose their ability to use their mother tongue, even in the home context. The extent and rapidity of language loss will vary according to the concentration of families from a particular linguistic group in the neighborhood. Where the mother tongue is used extensively in the community, then language loss among young children will be less. However, where language communities are not concentrated in particular neighborhoods, children can lose their ability to communicate in their mother tongue within 2-3 years of starting school. They may retain receptive skills in the language but they will use the majority language in speaking with their peers and siblings and in responding to their parents. By the time children become adolescents, the linguistic division between parents and children has become an emotional chasm. Pupils frequently become alienated from the cultures of both home and school with predictable results.", "hypothesis": "Less than half the children who attend kindergarten in Toronto have English as their Mother tongue.", "gold_label": "entailment"}
{"uid": "id_573", "premise": "The significant role of mother tongue language in education One consequence of population mobility is an increasing diversity within schools. To illustrate, in the city of Toronto in Canada, 58% of kindergarten pupils come from homes where English is not language of communication. Schools in Europe and North America have experienced this diversity for years, but educational policies and practices vary widely between countries and even within countries. Some political parties and groups search for ways to solve the problem of diverse communities and their integration in schools and society. They see few positive consequences for the host society and worry that diversity threaten the identity of the host society . Consequently, they promote unfortunate educational policies that will make the problem disappear. If students retain their culture and language, they are viewed as less capable of identifying with the mainstream culture and learning the mainstream language of the society. The challenge for educators and policy-makers is to shape the evolution of national identity in such a way that the rights of all citizens (including school children) are respected, and the cultural, linguistic, and economic resources of the nation are maximized. To waste the resources of the nation by discouraging children from developing their mother tongues is quite simply unintelligent from the point of view of national self-interest. A first step in Providing an appropriate education for culturally and linguistically diverse children is to examine what the existing research says about the role of childrens mother tongues in their educational development. In fact, the research is very clear. When children continue to develop their abilities in two or more languages throughout their primary school, they gain a deeper understanding of language and how to use it effectively. They have more practice in processing language, especially when they develop literacy in both. More than 150 research studies conducted during the past 35 years strongly support what Goethe, the famous eighteenth-century German philosopher, once said: that the person who knows only one language does not truly know that language. Research suggests that bilingual children may also develop more flexibility in their thinking as a result of processing information through two different languages. The level of development of childrens mother tongue is a strong predictor of their second language development. Children who come to school with a solid foundation in their mother tongue develop stronger literacy abilities in the school language. When parents and other caregivers (e. g. grandparents) are able to spend time with their children and tell stories or discuss issues with them in a way that develops their mother tongue, children come to school well-prepared to learn the school language and succeed educationally. Childrens knowledge and skills transfer across languages from the mother tongue to the school language. Transfer across languages can be two-way: both languages nurture each other when the educational environment permits children access to both languages. Some educators and parents are suspicious of mother tongue-based teaching programs because they worry that they take time away from the majority language. For example, in a bilingual program where 50% of the time is spent teaching through childrens home language and 50% through the majority language, surely childrens wont progress as far in the letter? One of the most strongly established findings of educational research, however, is that well-implemented bilingual programs can promote literacy and subject- matter knowledge in a minority language without any negative effects on childrens development in the majority language. Within Europe, the Foyer program in Belgium, which develops childrens speaking and literacy abilities in three languages (their mother tongue, Dutch and French), most clearly illustrates the benefits of bilingual and trilingual education (see Cummins, 2000). It is easy to understand how this happens. When children are learning through a minority language, they are learning concepts and intellectual skills too. Pupils who know how to tell the time in their mother tongue understand the concept of telling time. In order to tell time in the majority language they do not need to re-learn the concept. Similarly, at more advanced stages, there is transfer across languages in other skills such as knowing how to distinguish the main idea from the supporting details of a written passage or story, and distinguishing fact from opinion, Studies of secondary school pupils are providing interesting findings in this area, and it would be worth extending this research. Many people marvel at how quickly bilingual children seem to pick up conversational skills in the majority language at school (although it takes much longer for them to catch up to native speakers in academic language skills). However, educators are often much less aware of how quickly children can lose their ability to use their mother tongue, even in the home context. The extent and rapidity of language loss will vary according to the concentration of families from a particular linguistic group in the neighborhood. Where the mother tongue is used extensively in the community, then language loss among young children will be less. However, where language communities are not concentrated in particular neighborhoods, children can lose their ability to communicate in their mother tongue within 2-3 years of starting school. They may retain receptive skills in the language but they will use the majority language in speaking with their peers and siblings and in responding to their parents. By the time children become adolescents, the linguistic division between parents and children has become an emotional chasm. Pupils frequently become alienated from the cultures of both home and school with predictable results.", "hypothesis": "Bilingual children are taught to tell the time earlier than monolingual children.", "gold_label": "neutral"}
{"uid": "id_574", "premise": "The significant role of mother tongue language in education One consequence of population mobility is an increasing diversity within schools. To illustrate, in the city of Toronto in Canada, 58% of kindergarten pupils come from homes where English is not language of communication. Schools in Europe and North America have experienced this diversity for years, but educational policies and practices vary widely between countries and even within countries. Some political parties and groups search for ways to solve the problem of diverse communities and their integration in schools and society. They see few positive consequences for the host society and worry that diversity threaten the identity of the host society . Consequently, they promote unfortunate educational policies that will make the problem disappear. If students retain their culture and language, they are viewed as less capable of identifying with the mainstream culture and learning the mainstream language of the society. The challenge for educators and policy-makers is to shape the evolution of national identity in such a way that the rights of all citizens (including school children) are respected, and the cultural, linguistic, and economic resources of the nation are maximized. To waste the resources of the nation by discouraging children from developing their mother tongues is quite simply unintelligent from the point of view of national self-interest. A first step in Providing an appropriate education for culturally and linguistically diverse children is to examine what the existing research says about the role of childrens mother tongues in their educational development. In fact, the research is very clear. When children continue to develop their abilities in two or more languages throughout their primary school, they gain a deeper understanding of language and how to use it effectively. They have more practice in processing language, especially when they develop literacy in both. More than 150 research studies conducted during the past 35 years strongly support what Goethe, the famous eighteenth-century German philosopher, once said: that the person who knows only one language does not truly know that language. Research suggests that bilingual children may also develop more flexibility in their thinking as a result of processing information through two different languages. The level of development of childrens mother tongue is a strong predictor of their second language development. Children who come to school with a solid foundation in their mother tongue develop stronger literacy abilities in the school language. When parents and other caregivers (e. g. grandparents) are able to spend time with their children and tell stories or discuss issues with them in a way that develops their mother tongue, children come to school well-prepared to learn the school language and succeed educationally. Childrens knowledge and skills transfer across languages from the mother tongue to the school language. Transfer across languages can be two-way: both languages nurture each other when the educational environment permits children access to both languages. Some educators and parents are suspicious of mother tongue-based teaching programs because they worry that they take time away from the majority language. For example, in a bilingual program where 50% of the time is spent teaching through childrens home language and 50% through the majority language, surely childrens wont progress as far in the letter? One of the most strongly established findings of educational research, however, is that well-implemented bilingual programs can promote literacy and subject- matter knowledge in a minority language without any negative effects on childrens development in the majority language. Within Europe, the Foyer program in Belgium, which develops childrens speaking and literacy abilities in three languages (their mother tongue, Dutch and French), most clearly illustrates the benefits of bilingual and trilingual education (see Cummins, 2000). It is easy to understand how this happens. When children are learning through a minority language, they are learning concepts and intellectual skills too. Pupils who know how to tell the time in their mother tongue understand the concept of telling time. In order to tell time in the majority language they do not need to re-learn the concept. Similarly, at more advanced stages, there is transfer across languages in other skills such as knowing how to distinguish the main idea from the supporting details of a written passage or story, and distinguishing fact from opinion, Studies of secondary school pupils are providing interesting findings in this area, and it would be worth extending this research. Many people marvel at how quickly bilingual children seem to pick up conversational skills in the majority language at school (although it takes much longer for them to catch up to native speakers in academic language skills). However, educators are often much less aware of how quickly children can lose their ability to use their mother tongue, even in the home context. The extent and rapidity of language loss will vary according to the concentration of families from a particular linguistic group in the neighborhood. Where the mother tongue is used extensively in the community, then language loss among young children will be less. However, where language communities are not concentrated in particular neighborhoods, children can lose their ability to communicate in their mother tongue within 2-3 years of starting school. They may retain receptive skills in the language but they will use the majority language in speaking with their peers and siblings and in responding to their parents. By the time children become adolescents, the linguistic division between parents and children has become an emotional chasm. Pupils frequently become alienated from the cultures of both home and school with predictable results.", "hypothesis": "Bilingual children can eventually apply reading comprehension strategies acquired in one language when reading in the other.", "gold_label": "entailment"}
{"uid": "id_575", "premise": "The slow development of the innovative universal home remote control system is rather surprising following high expectations this system has raised a decade ago when it was first presented. Whilst having a prototype ready that impressively controlled most of the home electrical appliances using a single, simple and user friendly device, when manufactured in a production line many faults have occurred that were not discovered by the manufacturer quality control systems. The result was devastating. Thousands of these systems were returned by furious clients who paid substantial sums only to find that this luxurious device fails to reliably operate designated appliances and some also activated the wrong electrical device resulting in serious damages. The disastrous launch of the product into the market was largely the fault of line managers who did not commit themselves to ensure the excellence and quality of their work as well as senior managers who have failed to closely monitor the production activities and have focused merely on marketing and P. R.", "hypothesis": "After the disastrous start, the universal home remote control system is now gaining momentum.", "gold_label": "neutral"}
{"uid": "id_576", "premise": "The slow development of the innovative universal home remote control system is rather surprising following high expectations this system has raised a decade ago when it was first presented. Whilst having a prototype ready that impressively controlled most of the home electrical appliances using a single, simple and user friendly device, when manufactured in a production line many faults have occurred that were not discovered by the manufacturer quality control systems. The result was devastating. Thousands of these systems were returned by furious clients who paid substantial sums only to find that this luxurious device fails to reliably operate designated appliances and some also activated the wrong electrical device resulting in serious damages. The disastrous launch of the product into the market was largely the fault of line managers who did not commit themselves to ensure the excellence and quality of their work as well as senior managers who have failed to closely monitor the production activities and have focused merely on marketing and P. R.", "hypothesis": "Failure of the universal home remote control system was a direct result of a fault causing activation of wrong electrical devices.", "gold_label": "contradiction"}
{"uid": "id_577", "premise": "The slow development of the innovative universal home remote control system is rather surprising following high expectations this system has raised a decade ago when it was first presented. Whilst having a prototype ready that impressively controlled most of the home electrical appliances using a single, simple and user friendly device, when manufactured in a production line many faults have occurred that were not discovered by the manufacturer quality control systems. The result was devastating. Thousands of these systems were returned by furious clients who paid substantial sums only to find that this luxurious device fails to reliably operate designated appliances and some also activated the wrong electrical device resulting in serious damages. The disastrous launch of the product into the market was largely the fault of line managers who did not commit themselves to ensure the excellence and quality of their work as well as senior managers who have failed to closely monitor the production activities and have focused merely on marketing and P. R.", "hypothesis": "The initial product to reach the market was a reliable, simple and user-friendly device.", "gold_label": "contradiction"}
{"uid": "id_578", "premise": "The social determinants of health are factors in which people are born, grow, live, work and age. These factors depend on the social distribution of resources and can affect the life expectancy and quality of life that people have. These factors refer to the social context that people live in and include characteristics such as level of education, culture, stress and socioeconomic conditions as well as many others. It can be difficult to see how some of these factors may affect somebodys health but it is likely to involve a combination of multiple factors. A number of mechanisms acting together have been described to explain why someone with a poor diet would have a lower life expectancy. One such mechanism is as follows: This individual would be more likely to be malnourished which would weaken their immune system. This would ultimately increase their likelihood of suffering from infections. Recurrent infections would place strain on the body, which could eventually result in organ failure. On average, the life expectancy in the most deprived areas can be up to 10 years lower than in the least deprived areas. Many of these health inequalities are avoidable. Understanding how these social determinants affect the health of a population will allow us to improve its care. Knowledge of how social policies impact health can better allow us to monitor changes in health care, and is allowing us to reduce the gaps between those with a more disadvantaged social background from those with a privileged background.", "hypothesis": "The effects of the social determinants of health are principally measured by life expectancy.", "gold_label": "contradiction"}
{"uid": "id_579", "premise": "The social determinants of health are factors in which people are born, grow, live, work and age. These factors depend on the social distribution of resources and can affect the life expectancy and quality of life that people have. These factors refer to the social context that people live in and include characteristics such as level of education, culture, stress and socioeconomic conditions as well as many others. It can be difficult to see how some of these factors may affect somebodys health but it is likely to involve a combination of multiple factors. A number of mechanisms acting together have been described to explain why someone with a poor diet would have a lower life expectancy. One such mechanism is as follows: This individual would be more likely to be malnourished which would weaken their immune system. This would ultimately increase their likelihood of suffering from infections. Recurrent infections would place strain on the body, which could eventually result in organ failure. On average, the life expectancy in the most deprived areas can be up to 10 years lower than in the least deprived areas. Many of these health inequalities are avoidable. Understanding how these social determinants affect the health of a population will allow us to improve its care. Knowledge of how social policies impact health can better allow us to monitor changes in health care, and is allowing us to reduce the gaps between those with a more disadvantaged social background from those with a privileged background.", "hypothesis": "The health impact of poor diet can be avoided completely by using multivitamins that supplement the immune system.", "gold_label": "contradiction"}
{"uid": "id_580", "premise": "The social determinants of health are factors in which people are born, grow, live, work and age. These factors depend on the social distribution of resources and can affect the life expectancy and quality of life that people have. These factors refer to the social context that people live in and include characteristics such as level of education, culture, stress and socioeconomic conditions as well as many others. It can be difficult to see how some of these factors may affect somebodys health but it is likely to involve a combination of multiple factors. A number of mechanisms acting together have been described to explain why someone with a poor diet would have a lower life expectancy. One such mechanism is as follows: This individual would be more likely to be malnourished which would weaken their immune system. This would ultimately increase their likelihood of suffering from infections. Recurrent infections would place strain on the body, which could eventually result in organ failure. On average, the life expectancy in the most deprived areas can be up to 10 years lower than in the least deprived areas. Many of these health inequalities are avoidable. Understanding how these social determinants affect the health of a population will allow us to improve its care. Knowledge of how social policies impact health can better allow us to monitor changes in health care, and is allowing us to reduce the gaps between those with a more disadvantaged social background from those with a privileged background.", "hypothesis": "Nothing can be done to improve the health care of the poor in comparison to the rich.", "gold_label": "contradiction"}
{"uid": "id_581", "premise": "The social determinants of health are factors in which people are born, grow, live, work and age. These factors depend on the social distribution of resources and can affect the life expectancy and quality of life that people have. These factors refer to the social context that people live in and include characteristics such as level of education, culture, stress and socioeconomic conditions as well as many others. It can be difficult to see how some of these factors may affect somebodys health but it is likely to involve a combination of multiple factors. A number of mechanisms acting together have been described to explain why someone with a poor diet would have a lower life expectancy. One such mechanism is as follows: This individual would be more likely to be malnourished which would weaken their immune system. This would ultimately increase their likelihood of suffering from infections. Recurrent infections would place strain on the body, which could eventually result in organ failure. On average, the life expectancy in the most deprived areas can be up to 10 years lower than in the least deprived areas. Many of these health inequalities are avoidable. Understanding how these social determinants affect the health of a population will allow us to improve its care. Knowledge of how social policies impact health can better allow us to monitor changes in health care, and is allowing us to reduce the gaps between those with a more disadvantaged social background from those with a privileged background.", "hypothesis": "Alan lives in a less deprived area than Henry so Alan will live longer thanHenry.", "gold_label": "neutral"}
{"uid": "id_582", "premise": "The social determinants of health are factors in which people are born, grow, live, work and age. These factors depend on the social distribution of resources and can affect the life expectancy and quality of life that people have. These factors refer to the social context that people live in and include characteristics such as level of education, culture, stress and socioeconomic conditions as well as many others. It can be difficult to see how some of these factors may affect somebodys health but it is likely to involve a combination of multiple factors. A number of mechanisms acting together have been described to explain why someone with a poor diet would have a lower life expectancy. One such mechanism is as follows: This individual would be more likely to be malnourished which would weaken their immune system. This would ultimately increase their likelihood of suffering from infections. Recurrent infections would place strain on the body, which could eventually result in organ failure. On average, the life expectancy in the most deprived areas can be up to 10 years lower than in the least deprived areas. Many of these health inequalities are avoidable. Understanding how these social determinants affect the health of a population will allow us to improve its care. Knowledge of how social policies impact health can better allow us to monitor changes in health care, and is allowing us to reduce the gaps between those with a more disadvantaged social background from those with a privileged background.", "hypothesis": "Dropping out of school can have an effect on an individuals health.", "gold_label": "entailment"}
{"uid": "id_583", "premise": "The software tools of research are typically more abundant than hardware tools in the social sciences. Software is usually thought of as meaning computer programs that tell the hardware what to do, but any tool not related to a physical device can be considered software. Included in this category are published tests and questionnaires. Often researchers want to gather information related to a general area such as personality or intelligence. For these instances, the use of a standardized test may be the best choice. With already published tests you can be sure of both validity and reliability and can save a lot of time that might otherwise be spent on test construction. Standardized tests can be classified into five main categories: achievement, aptitude, interest, personality, and intelligence. Achievement tests are designed specifically to measure an individuals previously learned knowledge or ability. They are available for many topic areas related to psychology, education, business, and other fields. Achievement tests require that prior learning take place and that this learning be demonstrated in order to pass. Aptitude tests attempt to predict an individuals performance in some activity at some point in the future. They do not require any specific prior learning although basic knowledge related to reading and writing is usually required and some preparation, such as studying up on math formulas or sentence structure, can be helpful. A well-known example of this type is the Scholastic Achievement Test (SAT), designed to predict future college performance. Interest inventories also require only general knowledge but no preparation is needed. These tests look at an individuals subjective interests in order to make predictions about some future behavior or activity. Perhaps the most used interest inventory is the Strong Interest Inventory, which compares interests related to specific careers in order to help guide an individuals career path. Endorsed interests are compared with the interests of successful individuals in various fields and predictions are made regarding the test-takers fit with the various career fields. Typically designed to assess and diagnose personality and mental health related disorders, personality tests are used extensively by psychologists in clinical, educational, and business related settings. By far the most widely used test of this type is the Minnesota Multiphasic Personality Inventory, Second Edition (MMPI-2), which compares an individuals responses on a series of true-false items to those suffering from various mental disorders such as depression, schizophrenia, and anxiety. The theory behind the test argues that if you endorse items similar to the items endorsed by those with depression, for example, then the chances that you are also depressed increases. Intelligence tests could be classified as aptitude tests since they are sometimes used to predict future performance. They could also be classified as personality tests since they can be used to diagnose disorders such as learning disabilities and mental retardation. However, because of their limited scope, we will place them in their own category. The purpose of an intelligence test is to attain a summary score or intelligence quotient (IQ) of an individuals intellectual ability. Scores are compared to each other and can be broken down into different subcategories depending on the intelligence test used. The most commonly used tests of this type are the Wechsler Scales, including the Wechsler Adult Intelligence Scale (WAIS), the Wechsler Intelligence Scale for Children (WISC), and the Wechsler Preschool and Primary Scale of Intelligence (WPPSI). Self-response questionnaires are a great way to gather large amounts of information in a relatively short amount of time. A questionnaire, similar to a survey you might see on a web page, allows subjects to respond to questions, rate responses, or offer opinions. Their responses can then be used to place them in specific categories or groups or can be compared to other subjects for data analysis. A concern with self-report, however, is the accuracy of the responses. Unlike direct observation, there is no way of knowing if the subject has told the truth or whether or not the question was understood as intended. There are several different methods for gathering information on a questionnaire or survey, including a Likert scale, the Thurstone technique, and the semantic differential. The Likert scale is a popular method used in surveys because it allows the researcher to quantify opinion based items. Questions are typically grouped together and rated or responded to based on a five-point scale. This scale typically ranges in order from one extreme to the other, such as (1) very interested; (2) somewhat interested; (3) unsure; (4) not very interested; and (5) not interested at all. Items that might be rated with this scale representing the subjects level of interest could include a list of careers or academic majors, for example.", "hypothesis": "The Likert Scale ensures greater accuracy than other techniques.", "gold_label": "neutral"}
{"uid": "id_584", "premise": "The software tools of research are typically more abundant than hardware tools in the social sciences. Software is usually thought of as meaning computer programs that tell the hardware what to do, but any tool not related to a physical device can be considered software. Included in this category are published tests and questionnaires. Often researchers want to gather information related to a general area such as personality or intelligence. For these instances, the use of a standardized test may be the best choice. With already published tests you can be sure of both validity and reliability and can save a lot of time that might otherwise be spent on test construction. Standardized tests can be classified into five main categories: achievement, aptitude, interest, personality, and intelligence. Achievement tests are designed specifically to measure an individuals previously learned knowledge or ability. They are available for many topic areas related to psychology, education, business, and other fields. Achievement tests require that prior learning take place and that this learning be demonstrated in order to pass. Aptitude tests attempt to predict an individuals performance in some activity at some point in the future. They do not require any specific prior learning although basic knowledge related to reading and writing is usually required and some preparation, such as studying up on math formulas or sentence structure, can be helpful. A well-known example of this type is the Scholastic Achievement Test (SAT), designed to predict future college performance. Interest inventories also require only general knowledge but no preparation is needed. These tests look at an individuals subjective interests in order to make predictions about some future behavior or activity. Perhaps the most used interest inventory is the Strong Interest Inventory, which compares interests related to specific careers in order to help guide an individuals career path. Endorsed interests are compared with the interests of successful individuals in various fields and predictions are made regarding the test-takers fit with the various career fields. Typically designed to assess and diagnose personality and mental health related disorders, personality tests are used extensively by psychologists in clinical, educational, and business related settings. By far the most widely used test of this type is the Minnesota Multiphasic Personality Inventory, Second Edition (MMPI-2), which compares an individuals responses on a series of true-false items to those suffering from various mental disorders such as depression, schizophrenia, and anxiety. The theory behind the test argues that if you endorse items similar to the items endorsed by those with depression, for example, then the chances that you are also depressed increases. Intelligence tests could be classified as aptitude tests since they are sometimes used to predict future performance. They could also be classified as personality tests since they can be used to diagnose disorders such as learning disabilities and mental retardation. However, because of their limited scope, we will place them in their own category. The purpose of an intelligence test is to attain a summary score or intelligence quotient (IQ) of an individuals intellectual ability. Scores are compared to each other and can be broken down into different subcategories depending on the intelligence test used. The most commonly used tests of this type are the Wechsler Scales, including the Wechsler Adult Intelligence Scale (WAIS), the Wechsler Intelligence Scale for Children (WISC), and the Wechsler Preschool and Primary Scale of Intelligence (WPPSI). Self-response questionnaires are a great way to gather large amounts of information in a relatively short amount of time. A questionnaire, similar to a survey you might see on a web page, allows subjects to respond to questions, rate responses, or offer opinions. Their responses can then be used to place them in specific categories or groups or can be compared to other subjects for data analysis. A concern with self-report, however, is the accuracy of the responses. Unlike direct observation, there is no way of knowing if the subject has told the truth or whether or not the question was understood as intended. There are several different methods for gathering information on a questionnaire or survey, including a Likert scale, the Thurstone technique, and the semantic differential. The Likert scale is a popular method used in surveys because it allows the researcher to quantify opinion based items. Questions are typically grouped together and rated or responded to based on a five-point scale. This scale typically ranges in order from one extreme to the other, such as (1) very interested; (2) somewhat interested; (3) unsure; (4) not very interested; and (5) not interested at all. Items that might be rated with this scale representing the subjects level of interest could include a list of careers or academic majors, for example.", "hypothesis": "The Wechsler Scales are the only type of intelligence test now used.", "gold_label": "contradiction"}
{"uid": "id_585", "premise": "The software tools of research are typically more abundant than hardware tools in the social sciences. Software is usually thought of as meaning computer programs that tell the hardware what to do, but any tool not related to a physical device can be considered software. Included in this category are published tests and questionnaires. Often researchers want to gather information related to a general area such as personality or intelligence. For these instances, the use of a standardized test may be the best choice. With already published tests you can be sure of both validity and reliability and can save a lot of time that might otherwise be spent on test construction. Standardized tests can be classified into five main categories: achievement, aptitude, interest, personality, and intelligence. Achievement tests are designed specifically to measure an individuals previously learned knowledge or ability. They are available for many topic areas related to psychology, education, business, and other fields. Achievement tests require that prior learning take place and that this learning be demonstrated in order to pass. Aptitude tests attempt to predict an individuals performance in some activity at some point in the future. They do not require any specific prior learning although basic knowledge related to reading and writing is usually required and some preparation, such as studying up on math formulas or sentence structure, can be helpful. A well-known example of this type is the Scholastic Achievement Test (SAT), designed to predict future college performance. Interest inventories also require only general knowledge but no preparation is needed. These tests look at an individuals subjective interests in order to make predictions about some future behavior or activity. Perhaps the most used interest inventory is the Strong Interest Inventory, which compares interests related to specific careers in order to help guide an individuals career path. Endorsed interests are compared with the interests of successful individuals in various fields and predictions are made regarding the test-takers fit with the various career fields. Typically designed to assess and diagnose personality and mental health related disorders, personality tests are used extensively by psychologists in clinical, educational, and business related settings. By far the most widely used test of this type is the Minnesota Multiphasic Personality Inventory, Second Edition (MMPI-2), which compares an individuals responses on a series of true-false items to those suffering from various mental disorders such as depression, schizophrenia, and anxiety. The theory behind the test argues that if you endorse items similar to the items endorsed by those with depression, for example, then the chances that you are also depressed increases. Intelligence tests could be classified as aptitude tests since they are sometimes used to predict future performance. They could also be classified as personality tests since they can be used to diagnose disorders such as learning disabilities and mental retardation. However, because of their limited scope, we will place them in their own category. The purpose of an intelligence test is to attain a summary score or intelligence quotient (IQ) of an individuals intellectual ability. Scores are compared to each other and can be broken down into different subcategories depending on the intelligence test used. The most commonly used tests of this type are the Wechsler Scales, including the Wechsler Adult Intelligence Scale (WAIS), the Wechsler Intelligence Scale for Children (WISC), and the Wechsler Preschool and Primary Scale of Intelligence (WPPSI). Self-response questionnaires are a great way to gather large amounts of information in a relatively short amount of time. A questionnaire, similar to a survey you might see on a web page, allows subjects to respond to questions, rate responses, or offer opinions. Their responses can then be used to place them in specific categories or groups or can be compared to other subjects for data analysis. A concern with self-report, however, is the accuracy of the responses. Unlike direct observation, there is no way of knowing if the subject has told the truth or whether or not the question was understood as intended. There are several different methods for gathering information on a questionnaire or survey, including a Likert scale, the Thurstone technique, and the semantic differential. The Likert scale is a popular method used in surveys because it allows the researcher to quantify opinion based items. Questions are typically grouped together and rated or responded to based on a five-point scale. This scale typically ranges in order from one extreme to the other, such as (1) very interested; (2) somewhat interested; (3) unsure; (4) not very interested; and (5) not interested at all. Items that might be rated with this scale representing the subjects level of interest could include a list of careers or academic majors, for example.", "hypothesis": "Where large quantities of data need to be collected fairly quickly self-response questionnaires work well.", "gold_label": "entailment"}
{"uid": "id_586", "premise": "The space race was a competition between the Soviet Union and the United States to show off their technological superiority and economic power. It took place during the Cold War when there was a tense relationship between these nations. As the technology used in space exploration could also have military applications, both nations had many scientists and technicians involved. In 1957, the USSR launched the first artificial satellite into the Earths orbit, named Sputnik. The launch of this satellite was one of the first steps towards space exploration. The Americans were worried that the Soviets could use similar technology to launch nuclear warheads. This prompted urgency within the Americans, leading President Eisenhower to found NASA, and so began the space race. The Soviets took another step forward in April 1961 when they sent the first person into space, a cosmonaut named Yuri Gagarin. This prompted President John F. Kennedy to make the unexpected claim that the US would beat the Soviets to land a man on the moon and that they would do so before the end of the decade. This led to the foundation of Project Apollo, a programme designed to do this. In 1969, Neil Armstrong and Buzz Aldrin set off for the moon on the Apollo 11 space mission and became the first astronauts to walk on the moon. Neil Armstrong famously said one small step for man, one giant leap for mankind. This lunar landing led the US to win the space race that started with Sputniks launch in 1957.", "hypothesis": "The United States began their attempts at space exploration when the Soviets launched Sputnik.", "gold_label": "neutral"}
{"uid": "id_587", "premise": "The space race was a competition between the Soviet Union and the United States to show off their technological superiority and economic power. It took place during the Cold War when there was a tense relationship between these nations. As the technology used in space exploration could also have military applications, both nations had many scientists and technicians involved. In 1957, the USSR launched the first artificial satellite into the Earths orbit, named Sputnik. The launch of this satellite was one of the first steps towards space exploration. The Americans were worried that the Soviets could use similar technology to launch nuclear warheads. This prompted urgency within the Americans, leading President Eisenhower to found NASA, and so began the space race. The Soviets took another step forward in April 1961 when they sent the first person into space, a cosmonaut named Yuri Gagarin. This prompted President John F. Kennedy to make the unexpected claim that the US would beat the Soviets to land a man on the moon and that they would do so before the end of the decade. This led to the foundation of Project Apollo, a programme designed to do this. In 1969, Neil Armstrong and Buzz Aldrin set off for the moon on the Apollo 11 space mission and became the first astronauts to walk on the moon. Neil Armstrong famously said one small step for man, one giant leap for mankind. This lunar landing led the US to win the space race that started with Sputniks launch in 1957.", "hypothesis": "Yuri Gagarin did not become the first man on the moon because the Soviet technology could not handle the conditions on the moon.", "gold_label": "neutral"}
{"uid": "id_588", "premise": "The space race was a competition between the Soviet Union and the United States to show off their technological superiority and economic power. It took place during the Cold War when there was a tense relationship between these nations. As the technology used in space exploration could also have military applications, both nations had many scientists and technicians involved. In 1957, the USSR launched the first artificial satellite into the Earths orbit, named Sputnik. The launch of this satellite was one of the first steps towards space exploration. The Americans were worried that the Soviets could use similar technology to launch nuclear warheads. This prompted urgency within the Americans, leading President Eisenhower to found NASA, and so began the space race. The Soviets took another step forward in April 1961 when they sent the first person into space, a cosmonaut named Yuri Gagarin. This prompted President John F. Kennedy to make the unexpected claim that the US would beat the Soviets to land a man on the moon and that they would do so before the end of the decade. This led to the foundation of Project Apollo, a programme designed to do this. In 1969, Neil Armstrong and Buzz Aldrin set off for the moon on the Apollo 11 space mission and became the first astronauts to walk on the moon. Neil Armstrong famously said one small step for man, one giant leap for mankind. This lunar landing led the US to win the space race that started with Sputniks launch in 1957.", "hypothesis": "Project Apollo was founded in order for the United States to defeat the Soviet Union in the Cold War.", "gold_label": "contradiction"}
{"uid": "id_589", "premise": "The space race was a competition between the Soviet Union and the United States to show off their technological superiority and economic power. It took place during the Cold War when there was a tense relationship between these nations. As the technology used in space exploration could also have military applications, both nations had many scientists and technicians involved. In 1957, the USSR launched the first artificial satellite into the Earths orbit, named Sputnik. The launch of this satellite was one of the first steps towards space exploration. The Americans were worried that the Soviets could use similar technology to launch nuclear warheads. This prompted urgency within the Americans, leading President Eisenhower to found NASA, and so began the space race. The Soviets took another step forward in April 1961 when they sent the first person into space, a cosmonaut named Yuri Gagarin. This prompted President John F. Kennedy to make the unexpected claim that the US would beat the Soviets to land a man on the moon and that they would do so before the end of the decade. This led to the foundation of Project Apollo, a programme designed to do this. In 1969, Neil Armstrong and Buzz Aldrin set off for the moon on the Apollo 11 space mission and became the first astronauts to walk on the moon. Neil Armstrong famously said one small step for man, one giant leap for mankind. This lunar landing led the US to win the space race that started with Sputniks launch in 1957.", "hypothesis": "The Soviet Union were mainly concerned with launching satellites into space for a military advantage over the United States.", "gold_label": "contradiction"}
{"uid": "id_590", "premise": "The space race was a competition between the Soviet Union and the United States to show off their technological superiority and economic power. It took place during the Cold War when there was a tense relationship between these nations. As the technology used in space exploration could also have military applications, both nations had many scientists and technicians involved. In 1957, the USSR launched the first artificial satellite into the Earths orbit, named Sputnik. The launch of this satellite was one of the first steps towards space exploration. The Americans were worried that the Soviets could use similar technology to launch nuclear warheads. This prompted urgency within the Americans, leading President Eisenhower to found NASA, and so began the space race. The Soviets took another step forward in April 1961 when they sent the first person into space, a cosmonaut named Yuri Gagarin. This prompted President John F. Kennedy to make the unexpected claim that the US would beat the Soviets to land a man on the moon and that they would do so before the end of the decade. This led to the foundation of Project Apollo, a programme designed to do this. In 1969, Neil Armstrong and Buzz Aldrin set off for the moon on the Apollo 11 space mission and became the first astronauts to walk on the moon. Neil Armstrong famously said one small step for man, one giant leap for mankind. This lunar landing led the US to win the space race that started with Sputniks launch in 1957.", "hypothesis": "The United States were losing the space race when John F. Kennedy said they would land a man on the moon.", "gold_label": "entailment"}
{"uid": "id_591", "premise": "The state government has decided to appoint four thousand primary school teachers during the next financial year.", "hypothesis": "The eligible candidates may not be interested to apply as the Government may not finally appoint such a largest number of primary school teachers.", "gold_label": "neutral"}
{"uid": "id_592", "premise": "The state government has decided to appoint four thousand primary school teachers during the next financial year.", "hypothesis": "There are enough school in the state to accommodate four thousand primary school teachers.", "gold_label": "entailment"}
{"uid": "id_593", "premise": "The story of Romeo and Juliet, the 'star-cross'd lovers', is one of the most popular of all time, and has been told in several different versions. Best known is the play Romeo and Juliet, which nearly everyone reads in school and which introduced such famous lines as 'What's in a name? That which we call a rose by any other name would smell as sweet. ' Written and first performed in the 1590s, this highly poetical work of English theatre is set in Italy, where the legend of Romeo and Juliet and their warring families originates. In the 18th century, the actor and producer David Garrick adapted the original play to remove material considered indecent. Among other changes, he changed references to Rosaline, Romeo's girlfriend at the start of the play, to references to Juliet, so that Romeo already knows and loves Juliet at the start of the play, and the theme is faithfulness rather than love at first sight. The original text was restored in the 19th century, with a sensational production at Sadler'S Wells Theatre, London, starring the American sisters Charlotte and Susan Cushman as Romeo and Juliet. 'Gender-bending' is part of the play's tradition: in its early days, men played all the roles. By all accounts Charlotte Cushman was entirely convincing as Romeo. After seeing the Cushmans at Sadler's Wells, Queen Victoria noted in her journal that 'no-one would ever have imagined she was a woman. ' In the 20th century, Romeo and Juliet took to the screen in a series of films, including Franco Zeffirelli's 1968 Technicolor epic, which was the first to cast unknown teenagers as the leads and to feature a controversial nude wedding scene, and Baz Luhrmann's 1996 version for the MTV generation, with a soundtrack of pop hits and gun battles instead of sword fights. The most popular film version of Romeo and Juliet is West Side Story, in which the Jets and the Sharks, rival gangs in New York City, replace the feuding Montages and Capulets, and Romeo and Juliet become Tony and Maria. West Side Story also changes the ending so that one of the central couple survives; this version won 10 Academy Awards in 1961, making it the most acclaimed film adaptation of Romeo and Juliet to date. Who knows what twist on Romeo and Juliet we'll see next?", "hypothesis": "Shakespeare wrote Romeo and Juliet", "gold_label": "neutral"}
{"uid": "id_594", "premise": "The story of Romeo and Juliet, the 'star-cross'd lovers', is one of the most popular of all time, and has been told in several different versions. Best known is the play Romeo and Juliet, which nearly everyone reads in school and which introduced such famous lines as 'What's in a name? That which we call a rose by any other name would smell as sweet. ' Written and first performed in the 1590s, this highly poetical work of English theatre is set in Italy, where the legend of Romeo and Juliet and their warring families originates. In the 18th century, the actor and producer David Garrick adapted the original play to remove material considered indecent. Among other changes, he changed references to Rosaline, Romeo's girlfriend at the start of the play, to references to Juliet, so that Romeo already knows and loves Juliet at the start of the play, and the theme is faithfulness rather than love at first sight. The original text was restored in the 19th century, with a sensational production at Sadler'S Wells Theatre, London, starring the American sisters Charlotte and Susan Cushman as Romeo and Juliet. 'Gender-bending' is part of the play's tradition: in its early days, men played all the roles. By all accounts Charlotte Cushman was entirely convincing as Romeo. After seeing the Cushmans at Sadler's Wells, Queen Victoria noted in her journal that 'no-one would ever have imagined she was a woman. ' In the 20th century, Romeo and Juliet took to the screen in a series of films, including Franco Zeffirelli's 1968 Technicolor epic, which was the first to cast unknown teenagers as the leads and to feature a controversial nude wedding scene, and Baz Luhrmann's 1996 version for the MTV generation, with a soundtrack of pop hits and gun battles instead of sword fights. The most popular film version of Romeo and Juliet is West Side Story, in which the Jets and the Sharks, rival gangs in New York City, replace the feuding Montages and Capulets, and Romeo and Juliet become Tony and Maria. West Side Story also changes the ending so that one of the central couple survives; this version won 10 Academy Awards in 1961, making it the most acclaimed film adaptation of Romeo and Juliet to date. Who knows what twist on Romeo and Juliet we'll see next?", "hypothesis": "Susan Cushman played Juliet.", "gold_label": "entailment"}
{"uid": "id_595", "premise": "The story of Romeo and Juliet, the 'star-cross'd lovers', is one of the most popular of all time, and has been told in several different versions. Best known is the play Romeo and Juliet, which nearly everyone reads in school and which introduced such famous lines as 'What's in a name? That which we call a rose by any other name would smell as sweet. ' Written and first performed in the 1590s, this highly poetical work of English theatre is set in Italy, where the legend of Romeo and Juliet and their warring families originates. In the 18th century, the actor and producer David Garrick adapted the original play to remove material considered indecent. Among other changes, he changed references to Rosaline, Romeo's girlfriend at the start of the play, to references to Juliet, so that Romeo already knows and loves Juliet at the start of the play, and the theme is faithfulness rather than love at first sight. The original text was restored in the 19th century, with a sensational production at Sadler'S Wells Theatre, London, starring the American sisters Charlotte and Susan Cushman as Romeo and Juliet. 'Gender-bending' is part of the play's tradition: in its early days, men played all the roles. By all accounts Charlotte Cushman was entirely convincing as Romeo. After seeing the Cushmans at Sadler's Wells, Queen Victoria noted in her journal that 'no-one would ever have imagined she was a woman. ' In the 20th century, Romeo and Juliet took to the screen in a series of films, including Franco Zeffirelli's 1968 Technicolor epic, which was the first to cast unknown teenagers as the leads and to feature a controversial nude wedding scene, and Baz Luhrmann's 1996 version for the MTV generation, with a soundtrack of pop hits and gun battles instead of sword fights. The most popular film version of Romeo and Juliet is West Side Story, in which the Jets and the Sharks, rival gangs in New York City, replace the feuding Montages and Capulets, and Romeo and Juliet become Tony and Maria. West Side Story also changes the ending so that one of the central couple survives; this version won 10 Academy Awards in 1961, making it the most acclaimed film adaptation of Romeo and Juliet to date. Who knows what twist on Romeo and Juliet we'll see next?", "hypothesis": "Zeffirellimade the only film that cast unknown teenagers as Romeo and Juliet", "gold_label": "neutral"}
{"uid": "id_596", "premise": "The story of Romeo and Juliet, the 'star-cross'd lovers', is one of the most popular of all time, and has been told in several different versions. Best known is the play Romeo and Juliet, which nearly everyone reads in school and which introduced such famous lines as 'What's in a name? That which we call a rose by any other name would smell as sweet. ' Written and first performed in the 1590s, this highly poetical work of English theatre is set in Italy, where the legend of Romeo and Juliet and their warring families originates. In the 18th century, the actor and producer David Garrick adapted the original play to remove material considered indecent. Among other changes, he changed references to Rosaline, Romeo's girlfriend at the start of the play, to references to Juliet, so that Romeo already knows and loves Juliet at the start of the play, and the theme is faithfulness rather than love at first sight. The original text was restored in the 19th century, with a sensational production at Sadler'S Wells Theatre, London, starring the American sisters Charlotte and Susan Cushman as Romeo and Juliet. 'Gender-bending' is part of the play's tradition: in its early days, men played all the roles. By all accounts Charlotte Cushman was entirely convincing as Romeo. After seeing the Cushmans at Sadler's Wells, Queen Victoria noted in her journal that 'no-one would ever have imagined she was a woman. ' In the 20th century, Romeo and Juliet took to the screen in a series of films, including Franco Zeffirelli's 1968 Technicolor epic, which was the first to cast unknown teenagers as the leads and to feature a controversial nude wedding scene, and Baz Luhrmann's 1996 version for the MTV generation, with a soundtrack of pop hits and gun battles instead of sword fights. The most popular film version of Romeo and Juliet is West Side Story, in which the Jets and the Sharks, rival gangs in New York City, replace the feuding Montages and Capulets, and Romeo and Juliet become Tony and Maria. West Side Story also changes the ending so that one of the central couple survives; this version won 10 Academy Awards in 1961, making it the most acclaimed film adaptation of Romeo and Juliet to date. Who knows what twist on Romeo and Juliet we'll see next?", "hypothesis": "Queen Victoria never went to the theatre.", "gold_label": "contradiction"}
{"uid": "id_597", "premise": "The style that individual managers choose to adopt depends in no small part on how they regard their subordinates. At one extreme, some will assume that the average employee has an inherent dislike of work and will avoid it if they can. They believe employees need to be controlled, directed, offered rewards or threatened with punishments to get them to make adequate efforts towards the achievement of organisational goals. On the other hand, some will take the view that, according to the conditions, work can be a source of satisfaction or dissatisfaction. Employees are not seen as naturally passive, or resistant to organisational objectives, but have been made so by experience. The most significant reward that can be offered employees is the satisfaction of their need for personal growth and self-development.", "hypothesis": "Using rewards and punishments is a necessary part of organisational life.", "gold_label": "contradiction"}
{"uid": "id_598", "premise": "The style that individual managers choose to adopt depends in no small part on how they regard their subordinates. At one extreme, some will assume that the average employee has an inherent dislike of work and will avoid it if they can. They believe employees need to be controlled, directed, offered rewards or threatened with punishments to get them to make adequate efforts towards the achievement of organizational goals. On the other hand, some will take the view that, according to the conditions, work can be a source of satisfaction or dissatisfaction. Employees are not seen as naturally passive, or resistant to organizational objectives, but have been made so by experience. The most significant reward that can be offered employees is the satisfaction of their need for personal growth and self-development.", "hypothesis": "Using rewards and punishments is a necessary part of organizational life.", "gold_label": "contradiction"}
{"uid": "id_599", "premise": "The temperature on Monday was lower than on Tuesday. The temperature on Wednesday was lower than on Tuesday.", "hypothesis": "The temperature on Monday was higher than on Wednesday.", "gold_label": "neutral"}
{"uid": "id_600", "premise": "The terrestrial coconut crab is the world largest living land arthropod. The coconut crab is a true crab, weighing up to 4kg, with a leg span of more than 3 feet. The coconut crab is a typical example of island gigantism, increasing in size due to the lack of predators on islands home to coconut crabs.", "hypothesis": "The coconut crab may weigh over 3.5kg.", "gold_label": "entailment"}
{"uid": "id_601", "premise": "The terrestrial coconut crab is the world largest living land arthropod. The coconut crab is a true crab, weighing up to 4kg, with a leg span of more than 3 feet. The coconut crab is a typical example of island gigantism, increasing in size due to the lack of predators on islands home to coconut crabs.", "hypothesis": "Attacks from predators have led to the increased size of the coconut crab.", "gold_label": "neutral"}
{"uid": "id_602", "premise": "The terrestrial coconut crab is the world largest living land arthropod. The coconut crab is a true crab, weighing up to 4kg, with a leg span of more than 3 feet. The coconut crab is a typical example of island gigantism, increasing in size due to the lack of predators on islands home to coconut crabs.", "hypothesis": "The coconut crab is the worlds largest species of crab.", "gold_label": "neutral"}
{"uid": "id_603", "premise": "The theory goes that everything around us is built up of tiny particles called atoms. Some materials are made up of only one type of atom; these are called elements. An example is hydrogen. Others are made up of different sorts of atom bonded together into molecules. These are called compounds. Water, for example, is a compound made up of molecules that contain two hydrogen atoms and one oxygen atom. The force which holds atoms together is called bonds. Atoms are made up of even smaller particles such as neutrons, electrons and protons. Neutrons and protons are made up of even smaller particles. These have been called quarks and gluons. The search is on for the particles that make up quarks.", "hypothesis": "The atom is the smallest particle of matter.", "gold_label": "contradiction"}
{"uid": "id_604", "premise": "The theory goes that everything around us is built up of tiny particles called atoms. Some materials are made up of only one type of atom; these are called elements. An example is hydrogen. Others are made up of different sorts of atom bonded together into molecules. These are called compounds. Water, for example, is a compound made up of molecules that contain two hydrogen atoms and one oxygen atom. The force which holds atoms together is called bonds. Atoms are made up of even smaller particles such as neutrons, electrons and protons. Neutrons and protons are made up of even smaller particles. These have been called quarks and gluons. The search is on for the particles that make up quarks.", "hypothesis": "All substances are made up of elements.", "gold_label": "contradiction"}
{"uid": "id_605", "premise": "The theory goes that everything around us is built up of tiny particles called atoms. Some materials are made up of only one type of atom; these are called elements. An example is hydrogen. Others are made up of different sorts of atom bonded together into molecules. These are called compounds. Water, for example, is a compound made up of molecules that contain two hydrogen atoms and one oxygen atom. The force which holds atoms together is called bonds. Atoms are made up of even smaller particles such as neutrons, electrons and protons. Neutrons and protons are made up of even smaller particles. These have been called quarks and gluons. The search is on for the particles that make up quarks.", "hypothesis": "A molecule is a cluster of atoms held together by bonds.", "gold_label": "neutral"}
{"uid": "id_606", "premise": "The theory goes that everything around us is built up of tiny particles called atoms. Some materials are made up of only one type of atom; these are called elements. An example is hydrogen. Others are made up of different sorts of atom bonded together into molecules. These are called compounds. Water, for example, is a compound made up of molecules that contain two hydrogen atoms and one oxygen atom. The force which holds atoms together is called bonds. Atoms are made up of even smaller particles such as neutrons, electrons and protons. Neutrons and protons are made up of even smaller particles. These have been called quarks and gluons. The search is on for the particles that make up quarks.", "hypothesis": "Neutrons are made up of quarks and gluons.", "gold_label": "entailment"}
{"uid": "id_607", "premise": "The theory goes that everything around us is built up of tiny particles called atoms. Some materials are made up of only one type of atom; these are called elements. An example is hydrogen. Others are made up of different sorts of atom bonded together into molecules. These are called compounds. Water, for example, is a compound made up of molecules that contain two hydrogen atoms and one oxygen atom. The force which holds atoms together is called bonds. Atoms are made up of even smaller particles such as neutrons, electrons and protons. Neutrons and protons are made up of even smaller particles. These have been called quarks and gluons. The search is on for the particles that make up quarks.", "hypothesis": "It can be inferred from the passage that molecules are made up of neutrons, electrons and protons.", "gold_label": "entailment"}
{"uid": "id_608", "premise": "The town of Newport is further west than the town of Flatpeak, although not so far west as the town of Daybridge.", "hypothesis": "Daybridge is the furthest east town.", "gold_label": "entailment"}
{"uid": "id_609", "premise": "The traditional view, that gaining a degree will provide long-term employment security, has been questioned. The traditional story goes that to get ahead in society, one must spend three to four years and, in most cases, accumulate debt along the way. To leave school with no further education is to gain an unsatisfying career with little potential. However, it can be questioned whether this pattern provides a valid representation of contemporary society. With the rise of tuition fees, the average student debt is at an all time high. In addition, there is even greater competition for graduate jobs. The Chronicle of Higher Education notes that between 2007 and 2009 the number of students going to university increased by 20% in the USA, 60% in Europe and almost 200% in Asia. With these increases in competition, it is little wonder that the traditional path is being questioned.", "hypothesis": "There has been a decrease in the number of people going to university", "gold_label": "contradiction"}
{"uid": "id_610", "premise": "The traditional view, that gaining a degree will provide long-term employment security, has been questioned. The traditional story goes that to get ahead in society, one must spend three to four years and, in most cases, accumulate debt along the way. To leave school with no further education is to gain an unsatisfying career with little potential. However, it can be questioned whether this pattern provides a valid representation of contemporary society. With the rise of tuition fees, the average student debt is at an all time high. In addition, there is even greater competition for graduate jobs. The Chronicle of Higher Education notes that between 2007 and 2009 the number of students going to university increased by 20% in the USA, 60% in Europe and almost 200% in Asia. With these increases in competition, it is little wonder that the traditional path is being questioned.", "hypothesis": "The average student debt is at an all-time high.", "gold_label": "entailment"}
{"uid": "id_611", "premise": "The traditional view, that gaining a degree will provide long-term employment security, has been questioned. The traditional story goes that to get ahead in society, one must spend three to four years and, in most cases, accumulate debt along the way. To leave school with no further education is to gain an unsatisfying career with little potential. However, it can be questioned whether this pattern provides a valid representation of contemporary society. With the rise of tuition fees, the average student debt is at an all time high. In addition, there is even greater competition for graduate jobs. The Chronicle of Higher Education notes that between 2007 and 2009 the number of students going to university increased by 20% in the USA, 60% in Europe and almost 200% in Asia. With these increases in competition, it is little wonder that the traditional path is being questioned.", "hypothesis": "There has been an increase in the number of people going to university", "gold_label": "entailment"}
{"uid": "id_612", "premise": "The traditional view, that gaining a degree will provide long-term employment security, has been questioned. The traditional story goes that to get ahead in society, one must spend three to four years and, in most cases, accumulate debt along the way. To leave school with no further education is to gain an unsatisfying career with little potential. However, it can be questioned whether this pattern provides a valid representation of contemporary society. With the rise of tuition fees, the average student debt is at an all time high. In addition, there is even greater competition for graduate jobs. The Chronicle of Higher Education notes that between 2007 and 2009 the number of students going to university increased by 20% in the USA, 60% in Europe and almost 200% in Asia. With these increases in competition, it is little wonder that the traditional path is being questioned.", "hypothesis": "The traditional university educational path is being questioned", "gold_label": "entailment"}
{"uid": "id_613", "premise": "The training budget is currently administered centrally. As part of a cost-cutting exercise the Board of Directors have voted unanimously in favour of the proposal that individual departments will have control of this process. This means that from the next financial year, all managers will have control of, and responsibility for, their department training budget. As a safeguard against possible falls in quality, the following rules must be observed. Firstly, all contracts for provision of training must go out to competitive tender. A minimum of three quotes must be obtained for each individual contract. These quotes must be documented and retained at the respective departments for the duration of the contract. Secondly, the award of contracts will normally be made solely on price. Procurement will consider written justifications where managers wish to award the contract to a higher quote. Finally, all suppliers must hold quality awards that are appropriate to the relevant industry.", "hypothesis": "Obtaining two quotes for a contract will not be acceptable", "gold_label": "entailment"}
{"uid": "id_614", "premise": "The training budget is currently administered centrally. As part of a cost-cutting exercise the Board of Directors have voted unanimously in favour of the proposal that individual departments will have control of this process. This means that from the next financial year, all managers will have control of, and responsibility for, their department training budget. As a safeguard against possible falls in quality, the following rules must be observed. Firstly, all contracts for provision of training must go out to competitive tender. A minimum of three quotes must be obtained for each individual contract. These quotes must be documented and retained at the respective departments for the duration of the contract. Secondly, the award of contracts will normally be made solely on price. Procurement will consider written justifications where managers wish to award the contract to a higher quote. Finally, all suppliers must hold quality awards that are appropriate to the relevant industry.", "hypothesis": "Managers are likely to be against the proposal", "gold_label": "neutral"}
{"uid": "id_615", "premise": "The training budget is currently administered centrally. As part of a cost-cutting exercise the Board of Directors have voted unanimously in favour of the proposal that individual departments will have control of this process. This means that from the next financial year, all managers will have control of, and responsibility for, their department training budget. As a safeguard against possible falls in quality, the following rules must be observed. Firstly, all contracts for provision of training must go out to competitive tender. A minimum of three quotes must be obtained for each individual contract. These quotes must be documented and retained at the respective departments for the duration of the contract. Secondly, the award of contracts will normally be made solely on price. Procurement will consider written justifications where managers wish to award the contract to a higher quote. Finally, all suppliers must hold quality awards that are appropriate to the relevant industry.", "hypothesis": "The lowest quote should normally be awarded the contract", "gold_label": "entailment"}
{"uid": "id_616", "premise": "The training budget is currently administered centrally. As part of a cost-cutting exercise the Board of Directors have voted unanimously in favour of the proposal that individual departments will have control of this process. This means that from the next financial year, all managers will have control of, and responsibility for, their department training budget. As a safeguard against possible falls in quality, the following rules must be observed. Firstly, all contracts for provision of training must go out to competitive tender. A minimum of three quotes must be obtained for each individual contract. These quotes must be documented and retained at the respective departments for the duration of the contract. Secondly, the award of contracts will normally be made solely on price. Procurement will consider written justifications where managers wish to award the contract to a higher quote. Finally, all suppliers must hold quality awards that are appropriate to the relevant industry.", "hypothesis": "Some of the Board of Directors were against the proposal.", "gold_label": "contradiction"}
{"uid": "id_617", "premise": "The trove of fossils at Zhucheng, China, is probably the largest single deposit of dinosaur bones in the world. While the massive quarry has given rise to nine new species of dinosaurs, the event that killed the species is still a mystery. One researcher thinks a landslide ripped the dinosaurs apart and mixed up their bones; another suspects the animals were dead and decomposing when their skeletons were swept to this spot by a massive flood or mud flow. Discoveries in Liaoning and Xinjiang are also helping scientists unravel the evolution of modern-day birds, a lineage that one Chinese palaeontologist believes begins with dinosaurs. One of his most recent discoveries, the chicken-size Xiaotingia zhengi, is giving scientists cause to rethink the classification of the Archaeopteryx, long considered the oldest-known bird. The Xiaotingia zhengi, they argue, provides evidence that both species were, in fact, feathered dinosaurs, not full-fledged birds.", "hypothesis": "The trove of fossils found in Liaoning and Xinjiang is of less importance than that found in Zhucheng.", "gold_label": "neutral"}
{"uid": "id_618", "premise": "The trove of fossils at Zhucheng, China, is probably the largest single deposit of dinosaur bones in the world. While the massive quarry has given rise to nine new species of dinosaurs, the event that killed the species is still a mystery. One researcher thinks a landslide ripped the dinosaurs apart and mixed up their bones; another suspects the animals were dead and decomposing when their skeletons were swept to this spot by a massive flood or mud flow. Discoveries in Liaoning and Xinjiang are also helping scientists unravel the evolution of modern-day birds, a lineage that one Chinese palaeontologist believes begins with dinosaurs. One of his most recent discoveries, the chicken-size Xiaotingia zhengi, is giving scientists cause to rethink the classification of the Archaeopteryx, long considered the oldest-known bird. The Xiaotingia zhengi, they argue, provides evidence that both species were, in fact, feathered dinosaurs, not full-fledged birds.", "hypothesis": "Documented knowledge of the lineage of birds should now be adjusted, to include Xiaotingia zhengi as the oldest-known bird.", "gold_label": "contradiction"}
{"uid": "id_619", "premise": "The trove of fossils at Zhucheng, China, is probably the largest single deposit of dinosaur bones in the world. While the massive quarry has given rise to nine new species of dinosaurs, the event that killed the species is still a mystery. One researcher thinks a landslide ripped the dinosaurs apart and mixed up their bones; another suspects the animals were dead and decomposing when their skeletons were swept to this spot by a massive flood or mud flow. Discoveries in Liaoning and Xinjiang are also helping scientists unravel the evolution of modern-day birds, a lineage that one Chinese palaeontologist believes begins with dinosaurs. One of his most recent discoveries, the chicken-size Xiaotingia zhengi, is giving scientists cause to rethink the classification of the Archaeopteryx, long considered the oldest-known bird. The Xiaotingia zhengi, they argue, provides evidence that both species were, in fact, feathered dinosaurs, not full-fledged birds.", "hypothesis": "The two researchers agree that a natural catastrophe was involved in the appearance of dinosaur bones at Zhucheng.", "gold_label": "entailment"}
{"uid": "id_620", "premise": "The typical share-save scheme is a regular savings plan that gives employees the opportunity to purchase shares in 3.5 or 7 years time, should they choose to exercise the purchase option, at a discounted price fixed before the saving period starts. In addition to potential financial gains, the employee also has the opportunity to participate in future company development through the acquisition of shares. The employee does not have to pay income tax on any gains made on the exercise of the option to buy shares, though there may be a liability to capital gains tax if the shares are sold and the resulting gains cause that particular employees level of capital gains liability to exceed the annual exempt amount.", "hypothesis": "Employees do not automatically have to pay Capital Gains Tax as a consequence of participating in share-save scheme.", "gold_label": "entailment"}
{"uid": "id_621", "premise": "The typical share-save scheme is a regular savings plan that gives employees the opportunity to purchase shares in 3.5 or 7 years time, should they choose to exercise the purchase option, at a discounted price fixed before the saving period starts. In addition to potential financial gains, the employee also has the opportunity to participate in future company development through the acquisition of shares. The employee does not have to pay income tax on any gains made on the exercise of the option to buy shares, though there may be a liability to capital gains tax if the shares are sold and the resulting gains cause that particular employees level of capital gains liability to exceed the annual exempt amount.", "hypothesis": "Employees usually exercise the option to sell their shares at the end of the saving period.", "gold_label": "neutral"}
{"uid": "id_622", "premise": "The typical share-save scheme is a regular savings plan that gives employees the opportunity to purchase shares in 3.5 or 7 years time, should they choose to exercise the purchase option, at a discounted price fixed before the saving period starts. In addition to potential financial gains, the employee also has the opportunity to participate in future company development through the acquisition of shares. The employee does not have to pay income tax on any gains made on the exercise of the option to buy shares, though there may be a liability to capital gains tax if the shares are sold and the resulting gains cause that particular employees level of capital gains liability to exceed the annual exempt amount.", "hypothesis": "Individuals who sell shares generate no potential tax liability.", "gold_label": "contradiction"}
{"uid": "id_623", "premise": "The typical share-save scheme is a regular savings plan that gives employees the opportunity to purchase shares in 3.5 or 7 years time, should they choose to exercise the purchase option, at a discounted price fixed before the saving period starts. In addition to potential financial gains, the employee also has the opportunity to participate in future company development through the acquisition of shares. The employee does not have to pay income tax on any gains made on the exercise of the option to buy shares, though there may be a liability to capital gains tax if the shares are sold and the resulting gains cause that particular employees level of capital gains liability to exceed the annual exempt amount.", "hypothesis": "Employees do not automatically have to pay Capital Gains Tax as a consequence of participating in share; save scheme.", "gold_label": "entailment"}
{"uid": "id_624", "premise": "The vast majority of citizens believe that the official statistics produced by governments are subject to political interference. They accuse opposition parties and pressure groups of the same interference and all three of using figures in wildly misleading ways to support their particular take on policy. The only difference is that governments are accused of using the figures to make the best possible case, opposition parties of taking the least favourable interpretation and pressure groups of selecting only the figures that prove their case. The media are considered just as guilty. Bad news is much more newsworthy than good news and people complain that we hear little other than a stream of stories suggesting that life is awful and getting worse. No wonder public trust in official data is at an all time low.", "hypothesis": "In the passage, governments in particular are subjected to criticism.", "gold_label": "contradiction"}
{"uid": "id_625", "premise": "The vast majority of citizens believe that the official statistics produced by governments are subject to political interference. They accuse opposition parties and pressure groups of the same interference and all three of using figures in wildly misleading ways to support their particular take on policy. The only difference is that governments are accused of using the figures to make the best possible case, opposition parties of taking the least favourable interpretation and pressure groups of selecting only the figures that prove their case. The media are considered just as guilty. Bad news is much more newsworthy than good news and people complain that we hear little other than a stream of stories suggesting that life is awful and getting worse. No wonder public trust in official data is at an all time low.", "hypothesis": "It can be inferred from the passage that good news is not news worthy.", "gold_label": "contradiction"}
{"uid": "id_626", "premise": "The vast majority of citizens believe that the official statistics produced by governments are subject to political interference. They accuse opposition parties and pressure groups of the same interference and all three of using figures in wildly misleading ways to support their particular take on policy. The only difference is that governments are accused of using the figures to make the best possible case, opposition parties of taking the least favourable interpretation and pressure groups of selecting only the figures that prove their case. The media are considered just as guilty. Bad news is much more newsworthy than good news and people complain that we hear little other than a stream of stories suggesting that life is awful and getting worse. No wonder public trust in official data is at an all time low.", "hypothesis": "You cannot tell from the passage if the author agrees with the vast majority of citizens.", "gold_label": "entailment"}
{"uid": "id_627", "premise": "The vast majority of citizens believe that the official statistics produced by governments are subject to political interference. They accuse opposition parties and pressure groups of the same interference and all three of using figures in wildly misleading ways to support their particular take on policy. The only difference is that governments are accused of using the figures to make the best possible case, opposition parties of taking the least favourable interpretation and pressure groups of selecting only the figures that prove their case. The media are considered just as guilty. Bad news is much more newsworthy than good news and people complain that we hear little other than a stream of stories suggesting that life is awful and getting worse. No wonder public trust in official data is at an all time low.", "hypothesis": "Public trust in governments, opposition parties, pressure groups and the media is at an all time low.", "gold_label": "neutral"}
{"uid": "id_628", "premise": "The vast majority of citizens believe that the official statistics produced by governments are subject to political interference. They accuse opposition parties and pressure groups of the same interference and all three of using figures in wildly misleading ways to support their particular take on policy. The only difference is that governments are accused of using the figures to make the best possible case, opposition parties of taking the least favourable interpretation and pressure groups of selecting only the figures that prove their case. The media are considered just as guilty. Bad news is much more newsworthy than good news and people complain that we hear little other than a stream of stories suggesting that life is awful and getting worse. No wonder public trust in official data is at an all time low.", "hypothesis": "The term all time low means that public trust in official data has never been lower but may have been as low before.", "gold_label": "contradiction"}
{"uid": "id_629", "premise": "The way in which information is taught can vary greatly across cultures and time periods. Entering a British primary school classroom from the early 1900s, for example, one gains a sense of austerity, discipline, and a rigid way of teaching. Desks are typically seated apart from one another, with straight-backed wooden chairs that face directly to the teacher and the chalkboard. In the present day, British classrooms look very different. Desks are often grouped together so that students face each other rather than the teacher, and a large floor area is typically set aside for the class to come together for group discussion and learning. Traditionally, it was felt that teachers should be in firm control of the learning process, and that the teachers task was to prepare and present material for students to understand. Within this approach, the relationship students have with their teachers is not considered important, nor is the relationship students have with each other in the classroom. A students participation in class is likely to be minimal, aside from asking questions directed at the teacher, or responding to questions that the teacher has directed at the student. This style encourages students to develop respect for positions of power as a source of control and discipline. It is frequently described as the formal authority model of teaching. A less rigid form of teacher-centred education is the demonstrator model. This maintains the formal authority models notion of the teacher as a flashlight who illuminates the material for his or her class to learn, but emphasises a more individualized approach to form. The demonstrator acts as both a role model and a guide, demonstrating skills and processes and then helping students develop and apply these independently. Instructors who are drawn to the demonstrator style are generally confident that their own way of performing a task represents a good base model, but they are sensitive to differing learning styles and expect to provide students with help on an individual basis. Many education researchers argue for student-centred learning instead, and suggest that the learning process is more successful when students are in control. Within the student-centred paradigm, the delegator style is popular. The delegator teacher maintains general authority, but they delegate much of the responsibility for learning to the class as a way for students to become independent thinkers who take pride in their own work. Students are often encouraged to work on their own or in groups, and if the delegator style is implemented successfully, they will build not only a working knowledge of course specific topics, but also self-discipline and the ability to co-ordinate group work and interpersonal roles. Another style that emphasises student-centred education is the facilitator mode of learning. Here, while a set of specific curriculum demands is already in place, students are encouraged to take the initiative for creating ways to meet these learning requirements together. The teacher typically designs activities that encourage active learning, group collaboration, and problem solving, and students are encouraged to process and apply the course content in creative and original ways. Whereas the delegator style emphasises content and the responsibility students can have for generating and directing their own knowledge base, the facilitator style emphasises form and the fluid and diverse possibilities that are available in the process of learning. Until the 1960s, formal authority was common in almost all Western schools and universities. As a professor would enter a university lecture theatre, a student would be expected to rush up, take his bag to the desk, and pull out the chair for the professor to sit down on. This style has become outmoded over time. Now at university, students and professors typically have more relaxed, collegiate relationships, address each other on a first name basis, and acknowledge that students have much to contribute in class. Teacher-centred education has a lingering appeal in the form of the demonstrator style, however, which remains useful in subjects where skills must be demonstrated to an external standard and the learning process remains fixed in the earlier years of education. A student of mathematics, sewing or metalwork will likely be familiar with the demonstrator style. At the highest levels of education, however, the demonstrator approach must be abandoned in all fields as students are required to produce innovative work that makes unique contributions to knowledge. Thesis and doctoral students lead their own research in facilitation with supervisors. The delegator style is valuable when the course is likely to lead students to careers that require group projects. Often, someone who has a high level of expertise in a particular field does not make for the best employee because they have not learnt to apply their abilities in a co-ordinated manner. The delegator style confronts this problem by recognizing that interpersonal communication is not just a means to learning but an important skill set in itself. The facilitator model is probably the most creative model, and is, therefore, not suited to subjects where the practical component necessitates a careful and highly disciplined manner, such as training to be a medical practitioner. It may, however, suit more experimental and theoretical fields ranging from English, music, and the social sciences to science and medical research that takes place in research labs. In these areas, mistakes in form are important and valuable aspects of the learning and development process. Overall, a clear evolution has taken place in the West from a rigid, dogmatic, and teacher- dominated way of learning to a flexible, creative, and student-centred approach. Nevertheless, different subjects, ages, and skill levels suit different styles of teaching, and it is unlikely that there will ever be one recommended approach for everyone.", "hypothesis": "The formal authority model remains popular in educational institutions of the West", "gold_label": "contradiction"}
{"uid": "id_630", "premise": "The way in which information is taught can vary greatly across cultures and time periods. Entering a British primary school classroom from the early 1900s, for example, one gains a sense of austerity, discipline, and a rigid way of teaching. Desks are typically seated apart from one another, with straight-backed wooden chairs that face directly to the teacher and the chalkboard. In the present day, British classrooms look very different. Desks are often grouped together so that students face each other rather than the teacher, and a large floor area is typically set aside for the class to come together for group discussion and learning. Traditionally, it was felt that teachers should be in firm control of the learning process, and that the teachers task was to prepare and present material for students to understand. Within this approach, the relationship students have with their teachers is not considered important, nor is the relationship students have with each other in the classroom. A students participation in class is likely to be minimal, aside from asking questions directed at the teacher, or responding to questions that the teacher has directed at the student. This style encourages students to develop respect for positions of power as a source of control and discipline. It is frequently described as the formal authority model of teaching. A less rigid form of teacher-centred education is the demonstrator model. This maintains the formal authority models notion of the teacher as a flashlight who illuminates the material for his or her class to learn, but emphasises a more individualized approach to form. The demonstrator acts as both a role model and a guide, demonstrating skills and processes and then helping students develop and apply these independently. Instructors who are drawn to the demonstrator style are generally confident that their own way of performing a task represents a good base model, but they are sensitive to differing learning styles and expect to provide students with help on an individual basis. Many education researchers argue for student-centred learning instead, and suggest that the learning process is more successful when students are in control. Within the student-centred paradigm, the delegator style is popular. The delegator teacher maintains general authority, but they delegate much of the responsibility for learning to the class as a way for students to become independent thinkers who take pride in their own work. Students are often encouraged to work on their own or in groups, and if the delegator style is implemented successfully, they will build not only a working knowledge of course specific topics, but also self-discipline and the ability to co-ordinate group work and interpersonal roles. Another style that emphasises student-centred education is the facilitator mode of learning. Here, while a set of specific curriculum demands is already in place, students are encouraged to take the initiative for creating ways to meet these learning requirements together. The teacher typically designs activities that encourage active learning, group collaboration, and problem solving, and students are encouraged to process and apply the course content in creative and original ways. Whereas the delegator style emphasises content and the responsibility students can have for generating and directing their own knowledge base, the facilitator style emphasises form and the fluid and diverse possibilities that are available in the process of learning. Until the 1960s, formal authority was common in almost all Western schools and universities. As a professor would enter a university lecture theatre, a student would be expected to rush up, take his bag to the desk, and pull out the chair for the professor to sit down on. This style has become outmoded over time. Now at university, students and professors typically have more relaxed, collegiate relationships, address each other on a first name basis, and acknowledge that students have much to contribute in class. Teacher-centred education has a lingering appeal in the form of the demonstrator style, however, which remains useful in subjects where skills must be demonstrated to an external standard and the learning process remains fixed in the earlier years of education. A student of mathematics, sewing or metalwork will likely be familiar with the demonstrator style. At the highest levels of education, however, the demonstrator approach must be abandoned in all fields as students are required to produce innovative work that makes unique contributions to knowledge. Thesis and doctoral students lead their own research in facilitation with supervisors. The delegator style is valuable when the course is likely to lead students to careers that require group projects. Often, someone who has a high level of expertise in a particular field does not make for the best employee because they have not learnt to apply their abilities in a co-ordinated manner. The delegator style confronts this problem by recognizing that interpersonal communication is not just a means to learning but an important skill set in itself. The facilitator model is probably the most creative model, and is, therefore, not suited to subjects where the practical component necessitates a careful and highly disciplined manner, such as training to be a medical practitioner. It may, however, suit more experimental and theoretical fields ranging from English, music, and the social sciences to science and medical research that takes place in research labs. In these areas, mistakes in form are important and valuable aspects of the learning and development process. Overall, a clear evolution has taken place in the West from a rigid, dogmatic, and teacher- dominated way of learning to a flexible, creative, and student-centred approach. Nevertheless, different subjects, ages, and skill levels suit different styles of teaching, and it is unlikely that there will ever be one recommended approach for everyone.", "hypothesis": "The demonstrator model is never used at tertiary level.", "gold_label": "neutral"}
{"uid": "id_631", "premise": "The way in which information is taught can vary greatly across cultures and time periods. Entering a British primary school classroom from the early 1900s, for example, one gains a sense of austerity, discipline, and a rigid way of teaching. Desks are typically seated apart from one another, with straight-backed wooden chairs that face directly to the teacher and the chalkboard. In the present day, British classrooms look very different. Desks are often grouped together so that students face each other rather than the teacher, and a large floor area is typically set aside for the class to come together for group discussion and learning. Traditionally, it was felt that teachers should be in firm control of the learning process, and that the teachers task was to prepare and present material for students to understand. Within this approach, the relationship students have with their teachers is not considered important, nor is the relationship students have with each other in the classroom. A students participation in class is likely to be minimal, aside from asking questions directed at the teacher, or responding to questions that the teacher has directed at the student. This style encourages students to develop respect for positions of power as a source of control and discipline. It is frequently described as the formal authority model of teaching. A less rigid form of teacher-centred education is the demonstrator model. This maintains the formal authority models notion of the teacher as a flashlight who illuminates the material for his or her class to learn, but emphasises a more individualized approach to form. The demonstrator acts as both a role model and a guide, demonstrating skills and processes and then helping students develop and apply these independently. Instructors who are drawn to the demonstrator style are generally confident that their own way of performing a task represents a good base model, but they are sensitive to differing learning styles and expect to provide students with help on an individual basis. Many education researchers argue for student-centred learning instead, and suggest that the learning process is more successful when students are in control. Within the student-centred paradigm, the delegator style is popular. The delegator teacher maintains general authority, but they delegate much of the responsibility for learning to the class as a way for students to become independent thinkers who take pride in their own work. Students are often encouraged to work on their own or in groups, and if the delegator style is implemented successfully, they will build not only a working knowledge of course specific topics, but also self-discipline and the ability to co-ordinate group work and interpersonal roles. Another style that emphasises student-centred education is the facilitator mode of learning. Here, while a set of specific curriculum demands is already in place, students are encouraged to take the initiative for creating ways to meet these learning requirements together. The teacher typically designs activities that encourage active learning, group collaboration, and problem solving, and students are encouraged to process and apply the course content in creative and original ways. Whereas the delegator style emphasises content and the responsibility students can have for generating and directing their own knowledge base, the facilitator style emphasises form and the fluid and diverse possibilities that are available in the process of learning. Until the 1960s, formal authority was common in almost all Western schools and universities. As a professor would enter a university lecture theatre, a student would be expected to rush up, take his bag to the desk, and pull out the chair for the professor to sit down on. This style has become outmoded over time. Now at university, students and professors typically have more relaxed, collegiate relationships, address each other on a first name basis, and acknowledge that students have much to contribute in class. Teacher-centred education has a lingering appeal in the form of the demonstrator style, however, which remains useful in subjects where skills must be demonstrated to an external standard and the learning process remains fixed in the earlier years of education. A student of mathematics, sewing or metalwork will likely be familiar with the demonstrator style. At the highest levels of education, however, the demonstrator approach must be abandoned in all fields as students are required to produce innovative work that makes unique contributions to knowledge. Thesis and doctoral students lead their own research in facilitation with supervisors. The delegator style is valuable when the course is likely to lead students to careers that require group projects. Often, someone who has a high level of expertise in a particular field does not make for the best employee because they have not learnt to apply their abilities in a co-ordinated manner. The delegator style confronts this problem by recognizing that interpersonal communication is not just a means to learning but an important skill set in itself. The facilitator model is probably the most creative model, and is, therefore, not suited to subjects where the practical component necessitates a careful and highly disciplined manner, such as training to be a medical practitioner. It may, however, suit more experimental and theoretical fields ranging from English, music, and the social sciences to science and medical research that takes place in research labs. In these areas, mistakes in form are important and valuable aspects of the learning and development process. Overall, a clear evolution has taken place in the West from a rigid, dogmatic, and teacher- dominated way of learning to a flexible, creative, and student-centred approach. Nevertheless, different subjects, ages, and skill levels suit different styles of teaching, and it is unlikely that there will ever be one recommended approach for everyone.", "hypothesis": "Graduates of delegator style teaching are good communicators.", "gold_label": "entailment"}
{"uid": "id_632", "premise": "The way in which information is taught can vary greatly across cultures and time periods. Entering a British primary school classroom from the early 1900s, for example, one gains a sense of austerity, discipline, and a rigid way of teaching. Desks are typically seated apart from one another, with straight-backed wooden chairs that face directly to the teacher and the chalkboard. In the present day, British classrooms look very different. Desks are often grouped together so that students face each other rather than the teacher, and a large floor area is typically set aside for the class to come together for group discussion and learning. Traditionally, it was felt that teachers should be in firm control of the learning process, and that the teachers task was to prepare and present material for students to understand. Within this approach, the relationship students have with their teachers is not considered important, nor is the relationship students have with each other in the classroom. A students participation in class is likely to be minimal, aside from asking questions directed at the teacher, or responding to questions that the teacher has directed at the student. This style encourages students to develop respect for positions of power as a source of control and discipline. It is frequently described as the formal authority model of teaching. A less rigid form of teacher-centred education is the demonstrator model. This maintains the formal authority models notion of the teacher as a flashlight who illuminates the material for his or her class to learn, but emphasises a more individualized approach to form. The demonstrator acts as both a role model and a guide, demonstrating skills and processes and then helping students develop and apply these independently. Instructors who are drawn to the demonstrator style are generally confident that their own way of performing a task represents a good base model, but they are sensitive to differing learning styles and expect to provide students with help on an individual basis. Many education researchers argue for student-centred learning instead, and suggest that the learning process is more successful when students are in control. Within the student-centred paradigm, the delegator style is popular. The delegator teacher maintains general authority, but they delegate much of the responsibility for learning to the class as a way for students to become independent thinkers who take pride in their own work. Students are often encouraged to work on their own or in groups, and if the delegator style is implemented successfully, they will build not only a working knowledge of course specific topics, but also self-discipline and the ability to co-ordinate group work and interpersonal roles. Another style that emphasises student-centred education is the facilitator mode of learning. Here, while a set of specific curriculum demands is already in place, students are encouraged to take the initiative for creating ways to meet these learning requirements together. The teacher typically designs activities that encourage active learning, group collaboration, and problem solving, and students are encouraged to process and apply the course content in creative and original ways. Whereas the delegator style emphasises content and the responsibility students can have for generating and directing their own knowledge base, the facilitator style emphasises form and the fluid and diverse possibilities that are available in the process of learning. Until the 1960s, formal authority was common in almost all Western schools and universities. As a professor would enter a university lecture theatre, a student would be expected to rush up, take his bag to the desk, and pull out the chair for the professor to sit down on. This style has become outmoded over time. Now at university, students and professors typically have more relaxed, collegiate relationships, address each other on a first name basis, and acknowledge that students have much to contribute in class. Teacher-centred education has a lingering appeal in the form of the demonstrator style, however, which remains useful in subjects where skills must be demonstrated to an external standard and the learning process remains fixed in the earlier years of education. A student of mathematics, sewing or metalwork will likely be familiar with the demonstrator style. At the highest levels of education, however, the demonstrator approach must be abandoned in all fields as students are required to produce innovative work that makes unique contributions to knowledge. Thesis and doctoral students lead their own research in facilitation with supervisors. The delegator style is valuable when the course is likely to lead students to careers that require group projects. Often, someone who has a high level of expertise in a particular field does not make for the best employee because they have not learnt to apply their abilities in a co-ordinated manner. The delegator style confronts this problem by recognizing that interpersonal communication is not just a means to learning but an important skill set in itself. The facilitator model is probably the most creative model, and is, therefore, not suited to subjects where the practical component necessitates a careful and highly disciplined manner, such as training to be a medical practitioner. It may, however, suit more experimental and theoretical fields ranging from English, music, and the social sciences to science and medical research that takes place in research labs. In these areas, mistakes in form are important and valuable aspects of the learning and development process. Overall, a clear evolution has taken place in the West from a rigid, dogmatic, and teacher- dominated way of learning to a flexible, creative, and student-centred approach. Nevertheless, different subjects, ages, and skill levels suit different styles of teaching, and it is unlikely that there will ever be one recommended approach for everyone.", "hypothesis": "The facilitator style is not appropriate in the field of medicine.", "gold_label": "contradiction"}
{"uid": "id_633", "premise": "The way we use the words 'procedure' and 'process' tells us something about how theydiffer. We tend to start and stop processes. We implement procedures and commenceand complete them. We process information. We do not procedure information, but weemploy a procedure to process information. We have operational processes and theremay be operational procedures. In this context, the operational process comprises theresources, people, plant and machinery, and the operational procedure contains theinstructions on how to operate. We have process interrupts but not procedure interrupts, because processes are perceived as continuous and run until physical intervention. Inour bodies we have processes, not procedures. The reproductive process, the digestiveprocess and the respiratory process are certainly continuous and stop only when anintervention takes place. They may require human intervention in which a surgeon mayemploy procedures to effect a repair.", "hypothesis": "The procedures in our bodies are continuous.", "gold_label": "contradiction"}
{"uid": "id_634", "premise": "The way we use the words 'procedure' and 'process' tells us something about how theydiffer. We tend to start and stop processes. We implement procedures and commenceand complete them. We process information. We do not procedure information, but weemploy a procedure to process information. We have operational processes and theremay be operational procedures. In this context, the operational process comprises theresources, people, plant and machinery, and the operational procedure contains theinstructions on how to operate. We have process interrupts but not procedure interrupts, because processes are perceived as continuous and run until physical intervention. Inour bodies we have processes, not procedures. The reproductive process, the digestiveprocess and the respiratory process are certainly continuous and stop only when anintervention takes place. They may require human intervention in which a surgeon mayemploy procedures to effect a repair.", "hypothesis": "Although the two words sound similar, 'procedure' and 'process' cannot both be used in the same situations.", "gold_label": "contradiction"}
{"uid": "id_635", "premise": "The way we use the words 'procedure' and 'process' tells us something about how theydiffer. We tend to start and stop processes. We implement procedures and commenceand complete them. We process information. We do not procedure information, but weemploy a procedure to process information. We have operational processes and theremay be operational procedures. In this context, the operational process comprises theresources, people, plant and machinery, and the operational procedure contains theinstructions on how to operate. We have process interrupts but not procedure interrupts, because processes are perceived as continuous and run until physical intervention. Inour bodies we have processes, not procedures. The reproductive process, the digestiveprocess and the respiratory process are certainly continuous and stop only when anintervention takes place. They may require human intervention in which a surgeon mayemploy procedures to effect a repair.", "hypothesis": "Procedure and process are both required elements in the way we analyze information.", "gold_label": "entailment"}
{"uid": "id_636", "premise": "The way we use the words 'procedure' and 'process' tells us something about how theydiffer. We tend to start and stop processes. We implement procedures and commenceand complete them. We process information. We do not procedure information, but weemploy a procedure to process information. We have operational processes and theremay be operational procedures. In this context, the operational process comprises theresources, people, plant and machinery, and the operational procedure contains theinstructions on how to operate. We have process interrupts but not procedure interrupts, because processes are perceived as continuous and run until physical intervention. Inour bodies we have processes, not procedures. The reproductive process, the digestiveprocess and the respiratory process are certainly continuous and stop only when anintervention takes place. They may require human intervention in which a surgeon mayemploy procedures to effect a repair.", "hypothesis": "Procedures, as opposed to processes, are perceived as continuous, which is why we have process interrupts but not procedure interrupts.", "gold_label": "contradiction"}
{"uid": "id_637", "premise": "The words efficiency and effectiveness are often considered synonymous, along with terms like competency, productivity and proficiency erroneously so. In order to distinguish between effectiveness and efficiency, we must first define these terms. Effectiveness is doing the right thing, i. e. conducting the right activities and applying the best strategies needed for competitive advantage. From a process viewpoint, it is producing the required outputs and outcomes; in other words - meeting objectives. Efficiency is doing the thing right it defines whether processes are completed while using the least amount of resources in the shortest time possible. These simple definitions point to a clear distinction that has substantial implications for businesses large and small that arise from the inherent difficulty in balancing both efficiency and effectiveness.", "hypothesis": "Businesses face challenges attaining both effectiveness and efficiency.", "gold_label": "entailment"}
{"uid": "id_638", "premise": "The words efficiency and effectiveness are often considered synonymous, along with terms like competency, productivity and proficiency erroneously so. In order to distinguish between effectiveness and efficiency, we must first define these terms. Effectiveness is doing the right thing, i. e. conducting the right activities and applying the best strategies needed for competitive advantage. From a process viewpoint, it is producing the required outputs and outcomes; in other words - meeting objectives. Efficiency is doing the thing right it defines whether processes are completed while using the least amount of resources in the shortest time possible. These simple definitions point to a clear distinction that has substantial implications for businesses large and small that arise from the inherent difficulty in balancing both efficiency and effectiveness.", "hypothesis": "If you meet objectives using excessive resources then you are 'doing the thing right but not 'doing the right thing.", "gold_label": "contradiction"}
{"uid": "id_639", "premise": "The words efficiency and effectiveness are often considered synonymous, along with terms like competency, productivity and proficiency erroneously so. In order to distinguish between effectiveness and efficiency, we must first define these terms. Effectiveness is doing the right thing, i. e. conducting the right activities and applying the best strategies needed for competitive advantage. From a process viewpoint, it is producing the required outputs and outcomes; in other words - meeting objectives. Efficiency is doing the thing right it defines whether processes are completed while using the least amount of resources in the shortest time possible. These simple definitions point to a clear distinction that has substantial implications for businesses large and small that arise from the inherent difficulty in balancing both efficiency and effectiveness.", "hypothesis": "A manager who aspires to be efficient must make sure processes are completed within minimal time and resources.", "gold_label": "entailment"}
{"uid": "id_640", "premise": "The world is our oyster Independent travel is on the increase and while package holidays which offer an all inclusive price for transport, accommodation and often even food are financially attractive to many, according to tourism analyst Thomas Cooper, an increasing number of people now prefer a less-tailored holiday and the freedom to make spur of the moment decisions and changes to their intended plan. Internet based information sites about backpacking destinations are prolific and publications aimed at independent travellers on a budget exist for almost every destination imaginable. Some people, particularly first-time backpackers, may elect to travel with a friend or acquaintance; however, a large percentage of backpackers travel alone, assured by the knowledge that they are likely to meet, with ease, a number of like-minded individuals throughout their journey and staying in their backpacker accommodation. Alan Park, who has travelled extensively through Europe, Australasia and several other parts of the globe, says most accommodation establishments aimed at the backpacker market are designed with communal kitchens, dormitories and entertainment areas which lend themselves to allowing residents to socialize with ease and quickly breakdown barriers with strangers that may usually exist in day to day life. Many backpackers of European origin are attracted to the Southern Hemisphere, Australia being a major destination of choice. Cooper attributes this high level of interest to the possibilities of legal working holiday visas for many nationalities and consequent short-term work opportunities making extended travel financially feasible, in addition to the attractive climate and outback appeal. Australia also has the reputation of being a relatively safe destination, with a warm and jovial population and its size and contrast between locations is alluring to many. University student Rebecca Thompson, who has just returned from a twelve month overseas trip, says that the cosmopolitan and modern nature of Australian cities such as Sydney and Melbourne contrasted with the rugged outback appeal of Western Australia and the Northern Territory, or the marine paradise of the Great Barrier Reef offer sufficient variation to attract a wide base of visitors. Sydney based travel consultant Brad Connor advises that it is also possible to obtain bargain deals on internal flights within this massive island when purchasing an international ticket, highly recommended, he says, for those who do not have the luxury of a long length of time, in order to ensure that key spots can be visited. Equal in popularity to Australia, for the backpacking market is South East Asia and Rebecca Thompson says that, in her experience, the majority of travellers on extended trips to Australasia also include a visit to one or more South East Asia destinations in their itinerary. Thailand, in particular, has a long tourism history and well-established service industry. It is often considered one of the more accessible Asian destinations for the novice European backpacker due to its reasonable prices, large volume of Western visitors and well established backpacker trails. Brian Johnson, who is currently employed by the British Consulate in Bangkok, believes that the welcoming nature and level of English spoken by Thais involved in the tourism industry has also impacted positively on the destinations overseas image. Thai food is delicious and now fairly familiar to those outside the country and while precautions such as drinking bottled water and washing of fruit and vegetables should be practiced, generally standards of accommodation and restaurants are high. Thomas Cooper says Thailands attractions are wide ranging, encompassing idyllic beaches, an insight into Buddhist culture and impressive ancient temples, mountain trekking, a vibrant nightlife and for bargain hunters bustling night markets and bazaars. South East Asia neighbour, Vietnam, alongside its rapidly developing economy has also over recent years established a solid tourism industry, the majority of visitors entering and exiting by plane via its urban centres Ho Chi Minh (formerly Saigon) in the south and Hanoi in the north. Vietnam offers incredible vistas and contrasts of rugged mountain areas, lush green rice paddies, crystal clear waters and dense forest areas. Alan Park, who spent a month travelling independently around the country, says bus and rail networks allow visitors to travel from centre to centre relatively inexpensively, though he does not recommend these forms of transport to visitors on a short time-frame as the pace is unhurried. The list of potentially safe and enjoyable backpacking destinations is endless. Technology and transport developments over recent time have resulted in more areas of the world becoming increasingly accessible, it is now possible to keep in regular contact with friends and family back home via email or even mobile phone, providing added reassurance to those concerned about travelling and their worried parents. Brian Johnson says friends, family and acquaintances who have previously travelled to the destination of choice are a useful source of first-hand advice and information and Simon Hartwell of the Backpackers Association adds travellers are advised to ensure that they are aware of visa requirements for their destination and are urged to seek medical advice regarding any necessary vaccinations or medical precautions. It is always wise to be as well informed as possible prior to embarking on a trip. The youth of today are undoubtedly becoming more adventurous, which Hartwell ascribes to higher disposable income in the developed world than were available to previous generations and also the fact that we can more easily familiarise ourselves with the unknown via the internet and other communication methods. Many travellers, particularly experienced backpackers, are keen to experience more obscure destinations well off the well-trodden backpacker trail.", "hypothesis": "Train travel in Vietnam can be too time-consuming for short visits.", "gold_label": "entailment"}
{"uid": "id_641", "premise": "The world is our oyster Independent travel is on the increase and while package holidays which offer an all inclusive price for transport, accommodation and often even food are financially attractive to many, according to tourism analyst Thomas Cooper, an increasing number of people now prefer a less-tailored holiday and the freedom to make spur of the moment decisions and changes to their intended plan. Internet based information sites about backpacking destinations are prolific and publications aimed at independent travellers on a budget exist for almost every destination imaginable. Some people, particularly first-time backpackers, may elect to travel with a friend or acquaintance; however, a large percentage of backpackers travel alone, assured by the knowledge that they are likely to meet, with ease, a number of like-minded individuals throughout their journey and staying in their backpacker accommodation. Alan Park, who has travelled extensively through Europe, Australasia and several other parts of the globe, says most accommodation establishments aimed at the backpacker market are designed with communal kitchens, dormitories and entertainment areas which lend themselves to allowing residents to socialize with ease and quickly breakdown barriers with strangers that may usually exist in day to day life. Many backpackers of European origin are attracted to the Southern Hemisphere, Australia being a major destination of choice. Cooper attributes this high level of interest to the possibilities of legal working holiday visas for many nationalities and consequent short-term work opportunities making extended travel financially feasible, in addition to the attractive climate and outback appeal. Australia also has the reputation of being a relatively safe destination, with a warm and jovial population and its size and contrast between locations is alluring to many. University student Rebecca Thompson, who has just returned from a twelve month overseas trip, says that the cosmopolitan and modern nature of Australian cities such as Sydney and Melbourne contrasted with the rugged outback appeal of Western Australia and the Northern Territory, or the marine paradise of the Great Barrier Reef offer sufficient variation to attract a wide base of visitors. Sydney based travel consultant Brad Connor advises that it is also possible to obtain bargain deals on internal flights within this massive island when purchasing an international ticket, highly recommended, he says, for those who do not have the luxury of a long length of time, in order to ensure that key spots can be visited. Equal in popularity to Australia, for the backpacking market is South East Asia and Rebecca Thompson says that, in her experience, the majority of travellers on extended trips to Australasia also include a visit to one or more South East Asia destinations in their itinerary. Thailand, in particular, has a long tourism history and well-established service industry. It is often considered one of the more accessible Asian destinations for the novice European backpacker due to its reasonable prices, large volume of Western visitors and well established backpacker trails. Brian Johnson, who is currently employed by the British Consulate in Bangkok, believes that the welcoming nature and level of English spoken by Thais involved in the tourism industry has also impacted positively on the destinations overseas image. Thai food is delicious and now fairly familiar to those outside the country and while precautions such as drinking bottled water and washing of fruit and vegetables should be practiced, generally standards of accommodation and restaurants are high. Thomas Cooper says Thailands attractions are wide ranging, encompassing idyllic beaches, an insight into Buddhist culture and impressive ancient temples, mountain trekking, a vibrant nightlife and for bargain hunters bustling night markets and bazaars. South East Asia neighbour, Vietnam, alongside its rapidly developing economy has also over recent years established a solid tourism industry, the majority of visitors entering and exiting by plane via its urban centres Ho Chi Minh (formerly Saigon) in the south and Hanoi in the north. Vietnam offers incredible vistas and contrasts of rugged mountain areas, lush green rice paddies, crystal clear waters and dense forest areas. Alan Park, who spent a month travelling independently around the country, says bus and rail networks allow visitors to travel from centre to centre relatively inexpensively, though he does not recommend these forms of transport to visitors on a short time-frame as the pace is unhurried. The list of potentially safe and enjoyable backpacking destinations is endless. Technology and transport developments over recent time have resulted in more areas of the world becoming increasingly accessible, it is now possible to keep in regular contact with friends and family back home via email or even mobile phone, providing added reassurance to those concerned about travelling and their worried parents. Brian Johnson says friends, family and acquaintances who have previously travelled to the destination of choice are a useful source of first-hand advice and information and Simon Hartwell of the Backpackers Association adds travellers are advised to ensure that they are aware of visa requirements for their destination and are urged to seek medical advice regarding any necessary vaccinations or medical precautions. It is always wise to be as well informed as possible prior to embarking on a trip. The youth of today are undoubtedly becoming more adventurous, which Hartwell ascribes to higher disposable income in the developed world than were available to previous generations and also the fact that we can more easily familiarise ourselves with the unknown via the internet and other communication methods. Many travellers, particularly experienced backpackers, are keen to experience more obscure destinations well off the well-trodden backpacker trail.", "hypothesis": "Travelling by plane to other domestic destinations in Australia is cheaper than other forms of transport.", "gold_label": "neutral"}
{"uid": "id_642", "premise": "The world is our oyster Independent travel is on the increase and while package holidays which offer an all inclusive price for transport, accommodation and often even food are financially attractive to many, according to tourism analyst Thomas Cooper, an increasing number of people now prefer a less-tailored holiday and the freedom to make spur of the moment decisions and changes to their intended plan. Internet based information sites about backpacking destinations are prolific and publications aimed at independent travellers on a budget exist for almost every destination imaginable. Some people, particularly first-time backpackers, may elect to travel with a friend or acquaintance; however, a large percentage of backpackers travel alone, assured by the knowledge that they are likely to meet, with ease, a number of like-minded individuals throughout their journey and staying in their backpacker accommodation. Alan Park, who has travelled extensively through Europe, Australasia and several other parts of the globe, says most accommodation establishments aimed at the backpacker market are designed with communal kitchens, dormitories and entertainment areas which lend themselves to allowing residents to socialize with ease and quickly breakdown barriers with strangers that may usually exist in day to day life. Many backpackers of European origin are attracted to the Southern Hemisphere, Australia being a major destination of choice. Cooper attributes this high level of interest to the possibilities of legal working holiday visas for many nationalities and consequent short-term work opportunities making extended travel financially feasible, in addition to the attractive climate and outback appeal. Australia also has the reputation of being a relatively safe destination, with a warm and jovial population and its size and contrast between locations is alluring to many. University student Rebecca Thompson, who has just returned from a twelve month overseas trip, says that the cosmopolitan and modern nature of Australian cities such as Sydney and Melbourne contrasted with the rugged outback appeal of Western Australia and the Northern Territory, or the marine paradise of the Great Barrier Reef offer sufficient variation to attract a wide base of visitors. Sydney based travel consultant Brad Connor advises that it is also possible to obtain bargain deals on internal flights within this massive island when purchasing an international ticket, highly recommended, he says, for those who do not have the luxury of a long length of time, in order to ensure that key spots can be visited. Equal in popularity to Australia, for the backpacking market is South East Asia and Rebecca Thompson says that, in her experience, the majority of travellers on extended trips to Australasia also include a visit to one or more South East Asia destinations in their itinerary. Thailand, in particular, has a long tourism history and well-established service industry. It is often considered one of the more accessible Asian destinations for the novice European backpacker due to its reasonable prices, large volume of Western visitors and well established backpacker trails. Brian Johnson, who is currently employed by the British Consulate in Bangkok, believes that the welcoming nature and level of English spoken by Thais involved in the tourism industry has also impacted positively on the destinations overseas image. Thai food is delicious and now fairly familiar to those outside the country and while precautions such as drinking bottled water and washing of fruit and vegetables should be practiced, generally standards of accommodation and restaurants are high. Thomas Cooper says Thailands attractions are wide ranging, encompassing idyllic beaches, an insight into Buddhist culture and impressive ancient temples, mountain trekking, a vibrant nightlife and for bargain hunters bustling night markets and bazaars. South East Asia neighbour, Vietnam, alongside its rapidly developing economy has also over recent years established a solid tourism industry, the majority of visitors entering and exiting by plane via its urban centres Ho Chi Minh (formerly Saigon) in the south and Hanoi in the north. Vietnam offers incredible vistas and contrasts of rugged mountain areas, lush green rice paddies, crystal clear waters and dense forest areas. Alan Park, who spent a month travelling independently around the country, says bus and rail networks allow visitors to travel from centre to centre relatively inexpensively, though he does not recommend these forms of transport to visitors on a short time-frame as the pace is unhurried. The list of potentially safe and enjoyable backpacking destinations is endless. Technology and transport developments over recent time have resulted in more areas of the world becoming increasingly accessible, it is now possible to keep in regular contact with friends and family back home via email or even mobile phone, providing added reassurance to those concerned about travelling and their worried parents. Brian Johnson says friends, family and acquaintances who have previously travelled to the destination of choice are a useful source of first-hand advice and information and Simon Hartwell of the Backpackers Association adds travellers are advised to ensure that they are aware of visa requirements for their destination and are urged to seek medical advice regarding any necessary vaccinations or medical precautions. It is always wise to be as well informed as possible prior to embarking on a trip. The youth of today are undoubtedly becoming more adventurous, which Hartwell ascribes to higher disposable income in the developed world than were available to previous generations and also the fact that we can more easily familiarise ourselves with the unknown via the internet and other communication methods. Many travellers, particularly experienced backpackers, are keen to experience more obscure destinations well off the well-trodden backpacker trail.", "hypothesis": "Interaction with others is generally more difficult when travelling alone than in normal life situations.", "gold_label": "contradiction"}
{"uid": "id_643", "premise": "The world is our oyster Independent travel is on the increase and while package holidays which offer an all inclusive price for transport, accommodation and often even food are financially attractive to many, according to tourism analyst Thomas Cooper, an increasing number of people now prefer a less-tailored holiday and the freedom to make spur of the moment decisions and changes to their intended plan. Internet based information sites about backpacking destinations are prolific and publications aimed at independent travellers on a budget exist for almost every destination imaginable. Some people, particularly first-time backpackers, may elect to travel with a friend or acquaintance; however, a large percentage of backpackers travel alone, assured by the knowledge that they are likely to meet, with ease, a number of like-minded individuals throughout their journey and staying in their backpacker accommodation. Alan Park, who has travelled extensively through Europe, Australasia and several other parts of the globe, says most accommodation establishments aimed at the backpacker market are designed with communal kitchens, dormitories and entertainment areas which lend themselves to allowing residents to socialize with ease and quickly breakdown barriers with strangers that may usually exist in day to day life. Many backpackers of European origin are attracted to the Southern Hemisphere, Australia being a major destination of choice. Cooper attributes this high level of interest to the possibilities of legal working holiday visas for many nationalities and consequent short-term work opportunities making extended travel financially feasible, in addition to the attractive climate and outback appeal. Australia also has the reputation of being a relatively safe destination, with a warm and jovial population and its size and contrast between locations is alluring to many. University student Rebecca Thompson, who has just returned from a twelve month overseas trip, says that the cosmopolitan and modern nature of Australian cities such as Sydney and Melbourne contrasted with the rugged outback appeal of Western Australia and the Northern Territory, or the marine paradise of the Great Barrier Reef offer sufficient variation to attract a wide base of visitors. Sydney based travel consultant Brad Connor advises that it is also possible to obtain bargain deals on internal flights within this massive island when purchasing an international ticket, highly recommended, he says, for those who do not have the luxury of a long length of time, in order to ensure that key spots can be visited. Equal in popularity to Australia, for the backpacking market is South East Asia and Rebecca Thompson says that, in her experience, the majority of travellers on extended trips to Australasia also include a visit to one or more South East Asia destinations in their itinerary. Thailand, in particular, has a long tourism history and well-established service industry. It is often considered one of the more accessible Asian destinations for the novice European backpacker due to its reasonable prices, large volume of Western visitors and well established backpacker trails. Brian Johnson, who is currently employed by the British Consulate in Bangkok, believes that the welcoming nature and level of English spoken by Thais involved in the tourism industry has also impacted positively on the destinations overseas image. Thai food is delicious and now fairly familiar to those outside the country and while precautions such as drinking bottled water and washing of fruit and vegetables should be practiced, generally standards of accommodation and restaurants are high. Thomas Cooper says Thailands attractions are wide ranging, encompassing idyllic beaches, an insight into Buddhist culture and impressive ancient temples, mountain trekking, a vibrant nightlife and for bargain hunters bustling night markets and bazaars. South East Asia neighbour, Vietnam, alongside its rapidly developing economy has also over recent years established a solid tourism industry, the majority of visitors entering and exiting by plane via its urban centres Ho Chi Minh (formerly Saigon) in the south and Hanoi in the north. Vietnam offers incredible vistas and contrasts of rugged mountain areas, lush green rice paddies, crystal clear waters and dense forest areas. Alan Park, who spent a month travelling independently around the country, says bus and rail networks allow visitors to travel from centre to centre relatively inexpensively, though he does not recommend these forms of transport to visitors on a short time-frame as the pace is unhurried. The list of potentially safe and enjoyable backpacking destinations is endless. Technology and transport developments over recent time have resulted in more areas of the world becoming increasingly accessible, it is now possible to keep in regular contact with friends and family back home via email or even mobile phone, providing added reassurance to those concerned about travelling and their worried parents. Brian Johnson says friends, family and acquaintances who have previously travelled to the destination of choice are a useful source of first-hand advice and information and Simon Hartwell of the Backpackers Association adds travellers are advised to ensure that they are aware of visa requirements for their destination and are urged to seek medical advice regarding any necessary vaccinations or medical precautions. It is always wise to be as well informed as possible prior to embarking on a trip. The youth of today are undoubtedly becoming more adventurous, which Hartwell ascribes to higher disposable income in the developed world than were available to previous generations and also the fact that we can more easily familiarise ourselves with the unknown via the internet and other communication methods. Many travellers, particularly experienced backpackers, are keen to experience more obscure destinations well off the well-trodden backpacker trail.", "hypothesis": "Experienced backpackers rarely travel to destinations such as Australia.", "gold_label": "neutral"}
{"uid": "id_644", "premise": "The world trade organisation (WTO) is an organisation headquartered in Switzerland, tasked with supervising and liberalising international trade between nations. The WTO is comprised entirely of 159 member states, and 25 observer states, with 14 states being neither members nor observers. Accession to membership involves an application, which involves becoming an observer state prior to accession. Iran is currently the largest non-member economy and Tajikistan being the organisations newest member.", "hypothesis": "There are more member nations of the world trade organisation than there are non-member nations.", "gold_label": "entailment"}
{"uid": "id_645", "premise": "The world trade organisation (WTO) is an organisation headquartered in Switzerland, tasked with supervising and liberalising international trade between nations. The WTO is comprised entirely of 159 member states, and 25 observer states, with 14 states being neither members nor observers. Accession to membership involves an application, which involves becoming an observer state prior to accession. Iran is currently the largest non-member economy and Tajikistan being the organisations newest member.", "hypothesis": "Tajikistan was an observer state before becoming a member.", "gold_label": "entailment"}
{"uid": "id_646", "premise": "The world trade organisation (WTO) is an organisation headquartered in Switzerland, tasked with supervising and liberalising international trade between nations. The WTO is comprised entirely of 159 member states, and 25 observer states, with 14 states being neither members nor observers. Accession to membership involves an application, which involves becoming an observer state prior to accession. Iran is currently the largest non-member economy and Tajikistan being the organisations newest member.", "hypothesis": "Switzerland is a member of the world trade organisation.", "gold_label": "neutral"}
{"uid": "id_647", "premise": "The world trade organisation (WTO) is an organisation headquartered in Switzerland, tasked with supervising and liberalising international trade between nations. The WTO is comprised entirely of 159 member states, and 25 observer states, with 14 states being neither members nor observers. Accession to membership involves an application, which involves becoming an observer state prior to accession. Iran is currently the largest non-member economy and Tajikistan being the organisations newest member.", "hypothesis": "Iran is unaffiliated with the world trade organisation.", "gold_label": "neutral"}
{"uid": "id_648", "premise": "The worlds major religions are Islam, Christianity, Hinduism, Buddhism, Judaism and Sikhism. The oldest is Hinduism which is believed to have been worshipped for at least 5,000 years. Religion provides a sense of community, a shared set of values that shape daily life, a definition of the meaning of life and a set of beliefs as to how the world began and what happens after death. Except for Buddhism the major religions all identify a supreme god and define the way in which followers commune with that god. Religions have sacred texts, for example in Sikhism the text is called the Adi Granth, and religions have revered places for communal worship. In Judaism the synagogue is the place for communal prayer and religious learning. All religion involves ceremony and festivals and observances at points in a religious calendar and at significant stages in the life of its prophet or prophets and the lives of its followers. For example, followers of the Christian faith celebrate baptism, the rite of a persons entry into the faith, and Muslims celebrate important events in the life of the Prophet, including his birthday.", "hypothesis": "Providing an explanation of what happens after death is attributed to all major religions except for Buddhism.", "gold_label": "contradiction"}
{"uid": "id_649", "premise": "The worlds major religions are Islam, Christianity, Hinduism, Buddhism, Judaism and Sikhism. The oldest is Hinduism which is believed to have been worshipped for at least 5,000 years. Religion provides a sense of community, a shared set of values that shape daily life, a definition of the meaning of life and a set of beliefs as to how the world began and what happens after death. Except for Buddhism the major religions all identify a supreme god and define the way in which followers commune with that god. Religions have sacred texts, for example in Sikhism the text is called the Adi Granth, and religions have revered places for communal worship. In Judaism the synagogue is the place for communal prayer and religious learning. All religion involves ceremony and festivals and observances at points in a religious calendar and at significant stages in the life of its prophet or prophets and the lives of its followers. For example, followers of the Christian faith celebrate baptism, the rite of a persons entry into the faith, and Muslims celebrate important events in the life of the Prophet, including his birthday.", "hypothesis": "The passage is illustrated with specific details from five of the six major religions of the world.", "gold_label": "entailment"}
{"uid": "id_650", "premise": "The worlds major religions are Islam, Christianity, Hinduism, Buddhism, Judaism and Sikhism. The oldest is Hinduism which is believed to have been worshipped for at least 5,000 years. Religion provides a sense of community, a shared set of values that shape daily life, a definition of the meaning of life and a set of beliefs as to how the world began and what happens after death. Except for Buddhism the major religions all identify a supreme god and define the way in which followers commune with that god. Religions have sacred texts, for example in Sikhism the text is called the Adi Granth, and religions have revered places for communal worship. In Judaism the synagogue is the place for communal prayer and religious learning. All religion involves ceremony and festivals and observances at points in a religious calendar and at significant stages in the life of its prophet or prophets and the lives of its followers. For example, followers of the Christian faith celebrate baptism, the rite of a persons entry into the faith, and Muslims celebrate important events in the life of the Prophet, including his birthday.", "hypothesis": "The main theme of the passage is an examination of the ceremonies, festivals and observances of the worlds major religions and the lives of the prophet or prophets and the followers.", "gold_label": "contradiction"}
{"uid": "id_651", "premise": "The worlds population is determined by the balance between the birth rate and the death rate. The population of a particular area can also increase or decrease due to migration. It will increase when the number of immigrants exceeds the number of emigrants and decrease when the number of emigrants exceeds the number of immigrants. The make-up of a population by its age and sex and its life-expectancy will also have implications for the population size and its expected future growth or decline.", "hypothesis": "The population of a particular area will decrease if the number of immigrants is higher than the number of emigrants.", "gold_label": "contradiction"}
{"uid": "id_652", "premise": "The worlds population is determined by the balance between the birth rate and the death rate. The population of a particular area can also increase or decrease due to migration. It will increase when the number of immigrants exceeds the number of emigrants and decrease when the number of emigrants exceeds the number of immigrants. The make-up of a population by its age and sex and its life-expectancy will also have implications for the population size and its expected future growth or decline.", "hypothesis": "The worlds population overall will not be affected by immigration or emigration.", "gold_label": "entailment"}
{"uid": "id_653", "premise": "The worlds population is determined by the balance between the birth rate and the death rate. The population of a particular area can also increase or decrease due to migration. It will increase when the number of immigrants exceeds the number of emigrants and decrease when the number of emigrants exceeds the number of immigrants. The make-up of a population by its age and sex and its life-expectancy will also have implications for the population size and its expected future growth or decline.", "hypothesis": "A higher birth rate will mean a growing world population.", "gold_label": "contradiction"}
{"uid": "id_654", "premise": "The worlds population is determined by the balance between the birth rate and the death rate. The population of a particular area can also increase or decrease due to migration. It will increase when the number of immigrants exceeds the number of emigrants and decrease when the number of emigrants exceeds the number of immigrants. The make-up of a population by its age and sex and its life-expectancy will also have implications for the population size and its expected future growth or decline.", "hypothesis": "The worlds population will continue to grow.", "gold_label": "neutral"}
{"uid": "id_655", "premise": "The worlds population is expected to increase to more than 10 billion by 2050. Having a child in the developed world has a greater environmental impact than having a child in the developing world. Likewise having a large family in the developed world has a far greater environmental impact than having a large family in the developing world. This is because a child born into the developed world is much more likely to go on to have a high carbon dioxide emission lifestyle given that they are more likely to take regular flights, drive cars, live in a large energy-hungry home and so on. This has led some campaigners to argue that families in the developed world should think far more seriously about the environmental consequences of having children and should elect or be encouraged to have fewer.", "hypothesis": "If it were the case that all of the worlds future population growth was projected to occur in the developing world and that the population of most developed countries would have fallen if it wasn't for immigration, then the case made for smaller families in the developed world would be weakened.", "gold_label": "contradiction"}
{"uid": "id_656", "premise": "The worlds population is expected to increase to more than 10 billion by 2050. Having a child in the developed world has a greater environmental impact than having a child in the developing world. Likewise having a large family in the developed world has a far greater environmental impact than having a large family in the developing world. This is because a child born into the developed world is much more likely to go on to have a high carbon dioxide emission lifestyle given that they are more likely to take regular flights, drive cars, live in a large energy-hungry home and so on. This has led some campaigners to argue that families in the developed world should think far more seriously about the environmental consequences of having children and should elect or be encouraged to have fewer.", "hypothesis": "If families living in the developing world were to have fewer children then they too would make a major cut in their families future carbon dioxide output.", "gold_label": "neutral"}
{"uid": "id_657", "premise": "The worlds population is growing by about 70 million people a year but the increase is uneven, with some nations populations growing rapidly and others decreasing. Among the industrialized nations, only the United States will experience significant growth by 2050, while Europe is expected to have 60 million fewer people than today. Britain is predicted to grow faster than any other European industrialized country, reaching a population of 65 million in the next 25 years. By then it will have overtaken France to become Europes second most populous country.", "hypothesis": "Britain is currently the third most populous European country.", "gold_label": "neutral"}
{"uid": "id_658", "premise": "The worlds population is growing by about 70 million people a year but the increase is uneven, with some nations populations growing rapidly and others decreasing. Among the industrialized nations, only the United States will experience significant growth by 2050, while Europe is expected to have 60 million fewer people than today. Britain is predicted to grow faster than any other European industrialized country, reaching a population of 65 million in the next 25 years. By then it will have overtaken France to become Europes second most populous country.", "hypothesis": "In all but one case the nations due to experience significant growth in their populations are not industrial.", "gold_label": "entailment"}
{"uid": "id_659", "premise": "The worlds population is growing by about 70 million people a year but the increase is uneven, with some nations populations growing rapidly and others decreasing. Among the industrialized nations, only the United States will experience significant growth by 2050, while Europe is expected to have 60 million fewer people than today. Britain is predicted to grow faster than any other European industrialized country, reaching a population of 65 million in the next 25 years. By then it will have overtaken France to become Europes second most populous country.", "hypothesis": "Britain is not expected to experience significant population growth by 2050.", "gold_label": "entailment"}
{"uid": "id_660", "premise": "The year 2003 marked a substantial shift in the working conditions of international long-distance call centre staff. This resulted from newly developed telecommunication technology as well as the change in working hours which put higher strain on employees. The typical working hours have changed dramatically to suit trans-Atlantic time zones. Throughout a shift, staff need to function dynamically and answer calls enthusiastically during unconventional hours. The late working hours has likewise caused some loss to the human interaction in the workplace in the call centre", "hypothesis": "Social interaction amongst call centre staff is higher when working regular hours.", "gold_label": "entailment"}
{"uid": "id_661", "premise": "The year 2003 marked a substantial shift in the working conditions of international long-distance call centre staff. This resulted from newly developed telecommunication technology as well as the change in working hours which put higher strain on employees. The typical working hours have changed dramatically to suit trans-Atlantic time zones. Throughout a shift, staff need to function dynamically and answer calls enthusiastically during unconventional hours. The late working hours has likewise caused some loss to the human interaction in the workplace in the call centre", "hypothesis": "Call centre employees have to answer incoming calls much more enthusiastically than in the past.", "gold_label": "neutral"}
{"uid": "id_662", "premise": "The year 2003 marked a substantial shift in the working conditions of international long-distance call centre staff. This resulted from newly developed telecommunication technology as well as the change in working hours which put higher strain on employees. The typical working hours have changed dramatically to suit trans-Atlantic time zones. Throughout a shift, staff need to function dynamically and answer calls enthusiastically during unconventional hours. The late working hours has likewise caused some loss to the human interaction in the workplace in the call centre", "hypothesis": "Call centre staff now have a more strenuous workload.", "gold_label": "neutral"}
{"uid": "id_663", "premise": "The year 2003 marked a substantial shift in the working conditions of international long-distance call centre staff. This resulted from newly developed telecommunication technology as well as the change in working hours which put higher strain on employees. The typical working hours have changed dramatically to suit trans-Atlantic time zones. Throughout a shift, staff need to function dynamically and answer calls enthusiastically during unconventional hours. The late working hours has likewise caused some loss to the human interaction in the workplace in the call centre", "hypothesis": "International long-distance call centre employees have had to change their working hours.", "gold_label": "entailment"}
{"uid": "id_664", "premise": "Theft by Check occurs when a person issues or passes a check with the intent of depriving the owner of property or service available in exchange for the check (1) knowing he or she does not have an account at the financial institution printed on the check or (2) knowing there is an open account at this institution but there isn't enough money to make payment on the check.", "hypothesis": "Leo closed out his account at Junction Bank three months ago. He still has checks left from that account, so he uses one to pay for his new stereo. This situation is the best example of Theft by Check.", "gold_label": "entailment"}
{"uid": "id_665", "premise": "Theft by Check occurs when a person issues or passes a check with the intent of depriving the owner of property or service available in exchange for the check (1) knowing he or she does not have an account at the financial institution printed on the check or (2) knowing there is an open account at this institution but there isn't enough money to make payment on the check.", "hypothesis": "Jacob closed his account today but has left enough money forthe rent check he wrote two days ago in that account to clear the bank. This situation is the best example of Theft by Check.", "gold_label": "contradiction"}
{"uid": "id_666", "premise": "Theft by Check occurs when a person issues or passes a check with the intent of depriving the owner of property or service available in exchange for the check (1) knowing he or she does not have an account at the financial institution printed on the check or (2) knowing there is an open account at this institution but there isn't enough money to make payment on the check.", "hypothesis": "Perla writes a check at the Gypsy Diner. The Diner calls her two days later and tells her that her bank returned it for insufficient funds. She drives to the diner and gives them cash to cover the check. This situation is the best example of Theft by Check.", "gold_label": "contradiction"}
{"uid": "id_667", "premise": "Theft by Check occurs when a person issues or passes a check with the intent of depriving the owner of property or service available in exchange for the check (1) knowing he or she does not have an account at the financial institution printed on the check or (2) knowing there is an open account at this institution but there isn't enough money to make payment on the check.", "hypothesis": "Xena writes a check to the Posey Patrol for flowers for her mother's birthday. The check bounces. The bank notifies her that it covered the check anyway but that her account will be charged $15 for this service. This situation is the best example of Theft by Check.", "gold_label": "contradiction"}
{"uid": "id_668", "premise": "Theory or Practice? What is the point of research carried out by biz schools? Students go to universities and other academic institutions to prepare for their future. We pay tuition and struggle through classes in the hopes that we can find a fulfilling and exciting career. But the choice of your university has a large influence on your future. How can you know which university will prepare you the best for your future? Like other academic institutions, business schools are judged by the quality of the research carried out by their faculties. Professors must both teach students and also produce original research in their own field. The quality of this research is assessed by academic publications. At the same time, universities have another responsibility to equip their students for the real world, however that is defined. Most students learning from professors will not go into academics themselvesso how do academics best prepare them for their future careers, whatever that may be? Whether academic research actually produces anything that is useful to the practice of business, or even whether it is its job to do so, are questions that can provoke vigorous arguments on campus. The debate, which first flared during the 1950s, was reignited in August, when AACSB International. the most widely recognised global accrediting agency for business schools, announced it would consider changing the way it evaluates research. The news followed rather damning criticism in 2002 from Jeffrey Pfefler. a Stanford professor, and Christina Fong of Washington University, which questioned whether business education in its current guise was sustainable. The study found that traditional modes of academia were not adequately preparing students for the kind of careers they faced in current times. The most controversial recommendation in AACSBs draft report (which was sent round to administrators for their comment) is that the schools should be required to demonstrate the value of their faculties research not simply by listing its citations in journals, but by demonstrating the impact it has in the professional world. New qualifiers, such as average incomes, student placement in top firms and business collaborations would now be considered just as important as academic publications. AACSB justifies its stance by saying that it wants schools and faculty to play to their strengths, whether they be in pedagogy, in the research of practical applications, or in scholarly endeavor. Traditionally, universities operate in a pyramid structure. Everyone enters and stays in an attempt to be successful in their academic field. A psychology professor must publish competitive research in the top neuroscience journals. A Cultural Studies professor must send graduate students on new field research expeditions to be taken seriously. This research is the core of a universitys output. And research of any kind is expensiveAACSB points out that business schools in America alone spend more than $320m a year on it. So it seems legitimate to ask for, what purpose it is undertaken? If a school chose to specialise in professional outputs rather than academic outputs, it could use such a large sum of money and redirect it into more fruitful programs. For example, if a business school wanted a larger presence of employees at top financial firms, this money may be better spent on a career center which focuses on building the skills of students, rather than paying for more high-level research to be done through the effort of faculty. A change in evaluation could also open the door to inviting more professionals from different fields to teach as adjuncts. Students could take accredited courses from people who are currently working in their dream field. The AACSB insists that universities answer the question as to why research is the most critical component of traditional education. On one level, the question is simple to answer. Research in business schools, as anywhere else, is about expanding the boundaries of knowledge; it thrives on answering unasked questions. Surely this pursuit of knowledge is still important to the university system. Our society progresses because we learn how to do things in new ways, a process which depends heavily on research and academics. But one cannot ignore the other obvious practical uses of research publications. Research is also about cementing schools and professors reputations. Schools gain kudos from their faculties record of publication: which journals publish them, and how often. In some cases, such as with government-funded schools in Britain, it can affect how much money they receive. For professors, the mantra is often publish or perish. Their careers depend on being seen in the right journals. But at a certain point, one has to wonder whether this research is being done for the benefit of the university or for the students the university aims to teach. Greater publications will attract greater funding, which will in turn be spent on better publications. Students seeking to enter professions out of academia find this cycle frustrating, and often see their professors as being part of the Ivory Tower of academia, operating in a self-contained community that has little influence on the outside world. The research is almost universally unread by real-world managers. Part of the trouble is that the journals labour under a similar ethos. They publish more than 20,000 articles each year. Most of the research is highly quantitative, hypothesis-driven and esoteric. As a result, it is almost universally unread by real-world managers. Much of the research criticises other published research. A paper in a 2006 issue of Strategy & Leadership commented that research is not designed with managers needs in mind, nor is it communicated in the journals they read. For the most part, it has become a self-referential closed system irrelevant to corporate performance. The AACSB demands that this segregation must change for the future of higher education. If students must invest thousands of dollars for an education as part of their career path, the academics which serve the students should be more fully incorporated into the professional world. This means that universities must focus on other strengths outside of research, such as professional networks, technology skills, and connections with top business firms around the world. Though many universities resisted the report, todays world continues to change. The universities which prepare students for our changing future have little choice but to change with new trends and new standards.", "hypothesis": "The debate about the usefulness of academic research for business practices is a recent one.", "gold_label": "contradiction"}
{"uid": "id_669", "premise": "Theory or Practice? What is the point of research carried out by biz schools? Students go to universities and other academic institutions to prepare for their future. We pay tuition and struggle through classes in the hopes that we can find a fulfilling and exciting career. But the choice of your university has a large influence on your future. How can you know which university will prepare you the best for your future? Like other academic institutions, business schools are judged by the quality of the research carried out by their faculties. Professors must both teach students and also produce original research in their own field. The quality of this research is assessed by academic publications. At the same time, universities have another responsibility to equip their students for the real world, however that is defined. Most students learning from professors will not go into academics themselvesso how do academics best prepare them for their future careers, whatever that may be? Whether academic research actually produces anything that is useful to the practice of business, or even whether it is its job to do so, are questions that can provoke vigorous arguments on campus. The debate, which first flared during the 1950s, was reignited in August, when AACSB International. the most widely recognised global accrediting agency for business schools, announced it would consider changing the way it evaluates research. The news followed rather damning criticism in 2002 from Jeffrey Pfefler. a Stanford professor, and Christina Fong of Washington University, which questioned whether business education in its current guise was sustainable. The study found that traditional modes of academia were not adequately preparing students for the kind of careers they faced in current times. The most controversial recommendation in AACSBs draft report (which was sent round to administrators for their comment) is that the schools should be required to demonstrate the value of their faculties research not simply by listing its citations in journals, but by demonstrating the impact it has in the professional world. New qualifiers, such as average incomes, student placement in top firms and business collaborations would now be considered just as important as academic publications. AACSB justifies its stance by saying that it wants schools and faculty to play to their strengths, whether they be in pedagogy, in the research of practical applications, or in scholarly endeavor. Traditionally, universities operate in a pyramid structure. Everyone enters and stays in an attempt to be successful in their academic field. A psychology professor must publish competitive research in the top neuroscience journals. A Cultural Studies professor must send graduate students on new field research expeditions to be taken seriously. This research is the core of a universitys output. And research of any kind is expensiveAACSB points out that business schools in America alone spend more than $320m a year on it. So it seems legitimate to ask for, what purpose it is undertaken? If a school chose to specialise in professional outputs rather than academic outputs, it could use such a large sum of money and redirect it into more fruitful programs. For example, if a business school wanted a larger presence of employees at top financial firms, this money may be better spent on a career center which focuses on building the skills of students, rather than paying for more high-level research to be done through the effort of faculty. A change in evaluation could also open the door to inviting more professionals from different fields to teach as adjuncts. Students could take accredited courses from people who are currently working in their dream field. The AACSB insists that universities answer the question as to why research is the most critical component of traditional education. On one level, the question is simple to answer. Research in business schools, as anywhere else, is about expanding the boundaries of knowledge; it thrives on answering unasked questions. Surely this pursuit of knowledge is still important to the university system. Our society progresses because we learn how to do things in new ways, a process which depends heavily on research and academics. But one cannot ignore the other obvious practical uses of research publications. Research is also about cementing schools and professors reputations. Schools gain kudos from their faculties record of publication: which journals publish them, and how often. In some cases, such as with government-funded schools in Britain, it can affect how much money they receive. For professors, the mantra is often publish or perish. Their careers depend on being seen in the right journals. But at a certain point, one has to wonder whether this research is being done for the benefit of the university or for the students the university aims to teach. Greater publications will attract greater funding, which will in turn be spent on better publications. Students seeking to enter professions out of academia find this cycle frustrating, and often see their professors as being part of the Ivory Tower of academia, operating in a self-contained community that has little influence on the outside world. The research is almost universally unread by real-world managers. Part of the trouble is that the journals labour under a similar ethos. They publish more than 20,000 articles each year. Most of the research is highly quantitative, hypothesis-driven and esoteric. As a result, it is almost universally unread by real-world managers. Much of the research criticises other published research. A paper in a 2006 issue of Strategy & Leadership commented that research is not designed with managers needs in mind, nor is it communicated in the journals they read. For the most part, it has become a self-referential closed system irrelevant to corporate performance. The AACSB demands that this segregation must change for the future of higher education. If students must invest thousands of dollars for an education as part of their career path, the academics which serve the students should be more fully incorporated into the professional world. This means that universities must focus on other strengths outside of research, such as professional networks, technology skills, and connections with top business firms around the world. Though many universities resisted the report, todays world continues to change. The universities which prepare students for our changing future have little choice but to change with new trends and new standards.", "hypothesis": "AACSBs draft report was not reviewed externally.", "gold_label": "contradiction"}
{"uid": "id_670", "premise": "Theory or Practice? What is the point of research carried out by biz schools? Students go to universities and other academic institutions to prepare for their future. We pay tuition and struggle through classes in the hopes that we can find a fulfilling and exciting career. But the choice of your university has a large influence on your future. How can you know which university will prepare you the best for your future? Like other academic institutions, business schools are judged by the quality of the research carried out by their faculties. Professors must both teach students and also produce original research in their own field. The quality of this research is assessed by academic publications. At the same time, universities have another responsibility to equip their students for the real world, however that is defined. Most students learning from professors will not go into academics themselvesso how do academics best prepare them for their future careers, whatever that may be? Whether academic research actually produces anything that is useful to the practice of business, or even whether it is its job to do so, are questions that can provoke vigorous arguments on campus. The debate, which first flared during the 1950s, was reignited in August, when AACSB International. the most widely recognised global accrediting agency for business schools, announced it would consider changing the way it evaluates research. The news followed rather damning criticism in 2002 from Jeffrey Pfefler. a Stanford professor, and Christina Fong of Washington University, which questioned whether business education in its current guise was sustainable. The study found that traditional modes of academia were not adequately preparing students for the kind of careers they faced in current times. The most controversial recommendation in AACSBs draft report (which was sent round to administrators for their comment) is that the schools should be required to demonstrate the value of their faculties research not simply by listing its citations in journals, but by demonstrating the impact it has in the professional world. New qualifiers, such as average incomes, student placement in top firms and business collaborations would now be considered just as important as academic publications. AACSB justifies its stance by saying that it wants schools and faculty to play to their strengths, whether they be in pedagogy, in the research of practical applications, or in scholarly endeavor. Traditionally, universities operate in a pyramid structure. Everyone enters and stays in an attempt to be successful in their academic field. A psychology professor must publish competitive research in the top neuroscience journals. A Cultural Studies professor must send graduate students on new field research expeditions to be taken seriously. This research is the core of a universitys output. And research of any kind is expensiveAACSB points out that business schools in America alone spend more than $320m a year on it. So it seems legitimate to ask for, what purpose it is undertaken? If a school chose to specialise in professional outputs rather than academic outputs, it could use such a large sum of money and redirect it into more fruitful programs. For example, if a business school wanted a larger presence of employees at top financial firms, this money may be better spent on a career center which focuses on building the skills of students, rather than paying for more high-level research to be done through the effort of faculty. A change in evaluation could also open the door to inviting more professionals from different fields to teach as adjuncts. Students could take accredited courses from people who are currently working in their dream field. The AACSB insists that universities answer the question as to why research is the most critical component of traditional education. On one level, the question is simple to answer. Research in business schools, as anywhere else, is about expanding the boundaries of knowledge; it thrives on answering unasked questions. Surely this pursuit of knowledge is still important to the university system. Our society progresses because we learn how to do things in new ways, a process which depends heavily on research and academics. But one cannot ignore the other obvious practical uses of research publications. Research is also about cementing schools and professors reputations. Schools gain kudos from their faculties record of publication: which journals publish them, and how often. In some cases, such as with government-funded schools in Britain, it can affect how much money they receive. For professors, the mantra is often publish or perish. Their careers depend on being seen in the right journals. But at a certain point, one has to wonder whether this research is being done for the benefit of the university or for the students the university aims to teach. Greater publications will attract greater funding, which will in turn be spent on better publications. Students seeking to enter professions out of academia find this cycle frustrating, and often see their professors as being part of the Ivory Tower of academia, operating in a self-contained community that has little influence on the outside world. The research is almost universally unread by real-world managers. Part of the trouble is that the journals labour under a similar ethos. They publish more than 20,000 articles each year. Most of the research is highly quantitative, hypothesis-driven and esoteric. As a result, it is almost universally unread by real-world managers. Much of the research criticises other published research. A paper in a 2006 issue of Strategy & Leadership commented that research is not designed with managers needs in mind, nor is it communicated in the journals they read. For the most part, it has become a self-referential closed system irrelevant to corporate performance. The AACSB demands that this segregation must change for the future of higher education. If students must invest thousands of dollars for an education as part of their career path, the academics which serve the students should be more fully incorporated into the professional world. This means that universities must focus on other strengths outside of research, such as professional networks, technology skills, and connections with top business firms around the world. Though many universities resisted the report, todays world continues to change. The universities which prepare students for our changing future have little choice but to change with new trends and new standards.", "hypothesis": "Greater publications benefit professors and students as well.", "gold_label": "contradiction"}
{"uid": "id_671", "premise": "Theory or Practice? What is the point of research carried out by biz schools? Students go to universities and other academic institutions to prepare for their future. We pay tuition and struggle through classes in the hopes that we can find a fulfilling and exciting career. But the choice of your university has a large influence on your future. How can you know which university will prepare you the best for your future? Like other academic institutions, business schools are judged by the quality of the research carried out by their faculties. Professors must both teach students and also produce original research in their own field. The quality of this research is assessed by academic publications. At the same time, universities have another responsibility to equip their students for the real world, however that is defined. Most students learning from professors will not go into academics themselvesso how do academics best prepare them for their future careers, whatever that may be? Whether academic research actually produces anything that is useful to the practice of business, or even whether it is its job to do so, are questions that can provoke vigorous arguments on campus. The debate, which first flared during the 1950s, was reignited in August, when AACSB International. the most widely recognised global accrediting agency for business schools, announced it would consider changing the way it evaluates research. The news followed rather damning criticism in 2002 from Jeffrey Pfefler. a Stanford professor, and Christina Fong of Washington University, which questioned whether business education in its current guise was sustainable. The study found that traditional modes of academia were not adequately preparing students for the kind of careers they faced in current times. The most controversial recommendation in AACSBs draft report (which was sent round to administrators for their comment) is that the schools should be required to demonstrate the value of their faculties research not simply by listing its citations in journals, but by demonstrating the impact it has in the professional world. New qualifiers, such as average incomes, student placement in top firms and business collaborations would now be considered just as important as academic publications. AACSB justifies its stance by saying that it wants schools and faculty to play to their strengths, whether they be in pedagogy, in the research of practical applications, or in scholarly endeavor. Traditionally, universities operate in a pyramid structure. Everyone enters and stays in an attempt to be successful in their academic field. A psychology professor must publish competitive research in the top neuroscience journals. A Cultural Studies professor must send graduate students on new field research expeditions to be taken seriously. This research is the core of a universitys output. And research of any kind is expensiveAACSB points out that business schools in America alone spend more than $320m a year on it. So it seems legitimate to ask for, what purpose it is undertaken? If a school chose to specialise in professional outputs rather than academic outputs, it could use such a large sum of money and redirect it into more fruitful programs. For example, if a business school wanted a larger presence of employees at top financial firms, this money may be better spent on a career center which focuses on building the skills of students, rather than paying for more high-level research to be done through the effort of faculty. A change in evaluation could also open the door to inviting more professionals from different fields to teach as adjuncts. Students could take accredited courses from people who are currently working in their dream field. The AACSB insists that universities answer the question as to why research is the most critical component of traditional education. On one level, the question is simple to answer. Research in business schools, as anywhere else, is about expanding the boundaries of knowledge; it thrives on answering unasked questions. Surely this pursuit of knowledge is still important to the university system. Our society progresses because we learn how to do things in new ways, a process which depends heavily on research and academics. But one cannot ignore the other obvious practical uses of research publications. Research is also about cementing schools and professors reputations. Schools gain kudos from their faculties record of publication: which journals publish them, and how often. In some cases, such as with government-funded schools in Britain, it can affect how much money they receive. For professors, the mantra is often publish or perish. Their careers depend on being seen in the right journals. But at a certain point, one has to wonder whether this research is being done for the benefit of the university or for the students the university aims to teach. Greater publications will attract greater funding, which will in turn be spent on better publications. Students seeking to enter professions out of academia find this cycle frustrating, and often see their professors as being part of the Ivory Tower of academia, operating in a self-contained community that has little influence on the outside world. The research is almost universally unread by real-world managers. Part of the trouble is that the journals labour under a similar ethos. They publish more than 20,000 articles each year. Most of the research is highly quantitative, hypothesis-driven and esoteric. As a result, it is almost universally unread by real-world managers. Much of the research criticises other published research. A paper in a 2006 issue of Strategy & Leadership commented that research is not designed with managers needs in mind, nor is it communicated in the journals they read. For the most part, it has become a self-referential closed system irrelevant to corporate performance. The AACSB demands that this segregation must change for the future of higher education. If students must invest thousands of dollars for an education as part of their career path, the academics which serve the students should be more fully incorporated into the professional world. This means that universities must focus on other strengths outside of research, such as professional networks, technology skills, and connections with top business firms around the world. Though many universities resisted the report, todays world continues to change. The universities which prepare students for our changing future have little choice but to change with new trends and new standards.", "hypothesis": "Business schools in the US spend more than 320 million dollars yearly on research.", "gold_label": "entailment"}
{"uid": "id_672", "premise": "Theory or Practice? What is the point of research carried out by biz schools? Students go to universities and other academic institutions to prepare for their future. We pay tuition and struggle through classes in the hopes that we can find a fulfilling and exciting career. But the choice of your university has a large influence on your future. How can you know which university will prepare you the best for your future? Like other academic institutions, business schools are judged by the quality of the research carried out by their faculties. Professors must both teach students and also produce original research in their own field. The quality of this research is assessed by academic publications. At the same time, universities have another responsibility to equip their students for the real world, however that is defined. Most students learning from professors will not go into academics themselvesso how do academics best prepare them for their future careers, whatever that may be? Whether academic research actually produces anything that is useful to the practice of business, or even whether it is its job to do so, are questions that can provoke vigorous arguments on campus. The debate, which first flared during the 1950s, was reignited in August, when AACSB International. the most widely recognised global accrediting agency for business schools, announced it would consider changing the way it evaluates research. The news followed rather damning criticism in 2002 from Jeffrey Pfefler. a Stanford professor, and Christina Fong of Washington University, which questioned whether business education in its current guise was sustainable. The study found that traditional modes of academia were not adequately preparing students for the kind of careers they faced in current times. The most controversial recommendation in AACSBs draft report (which was sent round to administrators for their comment) is that the schools should be required to demonstrate the value of their faculties research not simply by listing its citations in journals, but by demonstrating the impact it has in the professional world. New qualifiers, such as average incomes, student placement in top firms and business collaborations would now be considered just as important as academic publications. AACSB justifies its stance by saying that it wants schools and faculty to play to their strengths, whether they be in pedagogy, in the research of practical applications, or in scholarly endeavor. Traditionally, universities operate in a pyramid structure. Everyone enters and stays in an attempt to be successful in their academic field. A psychology professor must publish competitive research in the top neuroscience journals. A Cultural Studies professor must send graduate students on new field research expeditions to be taken seriously. This research is the core of a universitys output. And research of any kind is expensiveAACSB points out that business schools in America alone spend more than $320m a year on it. So it seems legitimate to ask for, what purpose it is undertaken? If a school chose to specialise in professional outputs rather than academic outputs, it could use such a large sum of money and redirect it into more fruitful programs. For example, if a business school wanted a larger presence of employees at top financial firms, this money may be better spent on a career center which focuses on building the skills of students, rather than paying for more high-level research to be done through the effort of faculty. A change in evaluation could also open the door to inviting more professionals from different fields to teach as adjuncts. Students could take accredited courses from people who are currently working in their dream field. The AACSB insists that universities answer the question as to why research is the most critical component of traditional education. On one level, the question is simple to answer. Research in business schools, as anywhere else, is about expanding the boundaries of knowledge; it thrives on answering unasked questions. Surely this pursuit of knowledge is still important to the university system. Our society progresses because we learn how to do things in new ways, a process which depends heavily on research and academics. But one cannot ignore the other obvious practical uses of research publications. Research is also about cementing schools and professors reputations. Schools gain kudos from their faculties record of publication: which journals publish them, and how often. In some cases, such as with government-funded schools in Britain, it can affect how much money they receive. For professors, the mantra is often publish or perish. Their careers depend on being seen in the right journals. But at a certain point, one has to wonder whether this research is being done for the benefit of the university or for the students the university aims to teach. Greater publications will attract greater funding, which will in turn be spent on better publications. Students seeking to enter professions out of academia find this cycle frustrating, and often see their professors as being part of the Ivory Tower of academia, operating in a self-contained community that has little influence on the outside world. The research is almost universally unread by real-world managers. Part of the trouble is that the journals labour under a similar ethos. They publish more than 20,000 articles each year. Most of the research is highly quantitative, hypothesis-driven and esoteric. As a result, it is almost universally unread by real-world managers. Much of the research criticises other published research. A paper in a 2006 issue of Strategy & Leadership commented that research is not designed with managers needs in mind, nor is it communicated in the journals they read. For the most part, it has become a self-referential closed system irrelevant to corporate performance. The AACSB demands that this segregation must change for the future of higher education. If students must invest thousands of dollars for an education as part of their career path, the academics which serve the students should be more fully incorporated into the professional world. This means that universities must focus on other strengths outside of research, such as professional networks, technology skills, and connections with top business firms around the world. Though many universities resisted the report, todays world continues to change. The universities which prepare students for our changing future have little choice but to change with new trends and new standards.", "hypothesis": "Many universities pursue professional outputs.", "gold_label": "neutral"}
{"uid": "id_673", "premise": "There are 150,000 criminals who have been convicted, have served a period in prison and been released early to be supervised in the community by the governments probation service. A small proportion while on probation commit further offences, including very serious crimes. Offenders on probation have been convicted of over 100 murders and a further 37 have been convicted of attempted murder. Critics point to the current auto- matic early release scheme that allows offenders to walk free after completing only a small fraction of their full sentence, as the cause of the current situation. The probation service responds by pointing out that any offending by people under their supervision is of great concern, but that the incidence of offenders who commit serious offences while on probation is low, with only 0.2 per cent of offenders being convicted of very serious crimes while on probation.", "hypothesis": "In the context of the passage, the term very serious crime can be taken to mean murder or attempted murder.", "gold_label": "contradiction"}
{"uid": "id_674", "premise": "There are 150,000 criminals who have been convicted, have served a period in prison and been released early to be supervised in the community by the governments probation service. A small proportion while on probation commit further offences, including very serious crimes. Offenders on probation have been convicted of over 100 murders and a further 37 have been convicted of attempted murder. Critics point to the current auto- matic early release scheme that allows offenders to walk free after completing only a small fraction of their full sentence, as the cause of the current situation. The probation service responds by pointing out that any offending by people under their supervision is of great concern, but that the incidence of offenders who commit serious offences while on probation is low, with only 0.2 per cent of offenders being convicted of very serious crimes while on probation.", "hypothesis": "Whatever the probation service might say, 100 murders would not have occurred if it were not for the early release scheme.", "gold_label": "neutral"}
{"uid": "id_675", "premise": "There are 150,000 criminals who have been convicted, have served a period in prison and been released early to be supervised in the community by the governments probation service. A small proportion while on probation commit further offences, including very serious crimes. Offenders on probation have been convicted of over 100 murders and a further 37 have been convicted of attempted murder. Critics point to the current auto- matic early release scheme that allows offenders to walk free after completing only a small fraction of their full sentence, as the cause of the current situation. The probation service responds by pointing out that any offending by people under their supervision is of great concern, but that the incidence of offenders who commit serious offences while on probation is low, with only 0.2 per cent of offenders being convicted of very serious crimes while on probation.", "hypothesis": "A premise of the passage is that the probation service is failing to properly supervise dangerous criminals.", "gold_label": "contradiction"}
{"uid": "id_676", "premise": "There are 562 federally recognized American Indian tribes, with a total of 1.7 million members. Additionally, there are hundreds of groups seeking federal recognition - or sovereignty - though less than ten percent will successfully achieve this status. Federally recognized tribes have the right to self-government, and are also eligible for federal assistance programmes. Exempt from state and local jurisdiction, tribes may enforce their own laws, request tax breaks and control regulatory activities. There are however limitations to their sovereignty including, amongst others, the ability to make war and create currency. Historically, tribes were granted federal recognition through treaties or by executive order. Since 1978 however, this has been replaced by a lengthy and stringent regulatory process which requires tribes applying for federal recognition to fulfill seven criteria, such as anthropological and historical evidence. One of the complications regarding federal recognition is the legal definition of \"Indian\". Previously, racial criteria, tribal records and personal affidavits were used to classify American Indians. Since the 1970s, however, there has been a shift to the use of a political definition - requiring membership in a federally recognized tribe in order to qualify for benefits, such as loans and educational grants. This definition, however, excludes many individuals of Native American heritage who are not tribal members.", "hypothesis": "There are only two exemptions to a federally recognized tribes powers of self-government.", "gold_label": "contradiction"}
{"uid": "id_677", "premise": "There are 562 federally recognized American Indian tribes, with a total of 1.7 million members. Additionally, there are hundreds of groups seeking federal recognition - or sovereignty - though less than ten percent will successfully achieve this status. Federally recognized tribes have the right to self-government, and are also eligible for federal assistance programmes. Exempt from state and local jurisdiction, tribes may enforce their own laws, request tax breaks and control regulatory activities. There are however limitations to their sovereignty including, amongst others, the ability to make war and create currency. Historically, tribes were granted federal recognition through treaties or by executive order. Since 1978 however, this has been replaced by a lengthy and stringent regulatory process which requires tribes applying for federal recognition to fulfill seven criteria, such as anthropological and historical evidence. One of the complications regarding federal recognition is the legal definition of \"Indian\". Previously, racial criteria, tribal records and personal affidavits were used to classify American Indians. Since the 1970s, however, there has been a shift to the use of a political definition - requiring membership in a federally recognized tribe in order to qualify for benefits, such as loans and educational grants. This definition, however, excludes many individuals of Native American heritage who are not tribal members.", "hypothesis": "A large number of people who identify themselves as American Indians do not fulfil the legal definition.", "gold_label": "entailment"}
{"uid": "id_678", "premise": "There are 562 federally recognized American Indian tribes, with a total of 1.7 million members. Additionally, there are hundreds of groups seeking federal recognition - or sovereignty - though less than ten percent will successfully achieve this status. Federally recognized tribes have the right to self-government, and are also eligible for federal assistance programmes. Exempt from state and local jurisdiction, tribes may enforce their own laws, request tax breaks and control regulatory activities. There are however limitations to their sovereignty including, amongst others, the ability to make war and create currency. Historically, tribes were granted federal recognition through treaties or by executive order. Since 1978 however, this has been replaced by a lengthy and stringent regulatory process which requires tribes applying for federal recognition to fulfill seven criteria, such as anthropological and historical evidence. One of the complications regarding federal recognition is the legal definition of \"Indian\". Previously, racial criteria, tribal records and personal affidavits were used to classify American Indians. Since the 1970s, however, there has been a shift to the use of a political definition - requiring membership in a federally recognized tribe in order to qualify for benefits, such as loans and educational grants. This definition, however, excludes many individuals of Native American heritage who are not tribal members.", "hypothesis": "Demand for federal recognition is high because it is a prerequisite for benefit programmes.", "gold_label": "neutral"}
{"uid": "id_679", "premise": "There are 562 federally recognized American Indian tribes, with a total of 1.7 million members. Additionally, there are hundreds of groups seeking federal recognition - or sovereignty - though less than ten percent will successfully achieve this status. Federally recognized tribes have the right to self-government, and are also eligible for federal assistance programmes. Exempt from state and local jurisdiction, tribes may enforce their own laws, request tax breaks and control regulatory activities. There are however limitations to their sovereignty including, amongst others, the ability to make war and create currency. Historically, tribes were granted federal recognition through treaties or by executive order. Since 1978 however, this has been replaced by a lengthy and stringent regulatory process which requires tribes applying for federal recognition to fulfill seven criteria, such as anthropological and historical evidence. One of the complications regarding federal recognition is the legal definition of \"Indian\". Previously, racial criteria, tribal records and personal affidavits were used to classify American Indians. Since the 1970s, however, there has been a shift to the use of a political definition - requiring membership in a federally recognized tribe in order to qualify for benefits, such as loans and educational grants. This definition, however, excludes many individuals of Native American heritage who are not tribal members.", "hypothesis": "Federally recognized tribes are not subject to state laws and do not pay taxes.", "gold_label": "contradiction"}
{"uid": "id_680", "premise": "There are 562 federally recognized American Indian tribes, with a total of 1.7 million members. Additionally, there are hundreds of groups seeking federal recognition - or sovereignty - though less than ten percent will successfully achieve this status. Federally recognized tribes have the right to self-government, and are also eligible for federal assistance programmes. Exempt from state and local jurisdiction, tribes may enforce their own laws, request tax breaks and control regulatory activities. There are however limitations to their sovereignty including, amongst others, the ability to make war and create currency. Historically, tribes were granted federal recognition through treaties or by executive order. Since 1978 however, this has been replaced by a lengthy and stringent regulatory process which requires tribes applying for federal recognition to fulfill seven criteria, such as anthropological and historical evidence. One of the complications regarding federal recognition is the legal definition of \"Indian\". Previously, racial criteria, tribal records and personal affidavits were used to classify American Indians. Since the 1970s, however, there has been a shift to the use of a political definition - requiring membership in a federally recognized tribe in order to qualify for benefits, such as loans and educational grants. This definition, however, excludes many individuals of Native American heritage who are not tribal members.", "hypothesis": "Since 1978 it has become harder for a tribe to achieve federally recognized status.", "gold_label": "neutral"}
{"uid": "id_681", "premise": "There are a number of ways in which economic recession can impact a business, beside the most obvious factor of reduced consumer spending and a resultant decrease in sales. Recession also leads to a rise in inflation, which increases a business's expenditure. These factors in turn act both to reduce competition, through less stable businesses closing down, and simultaneously also to increase it, as remaining ones compete more aggressively to stay afloat. The combined effect of these factors can lead both to fluctuating sales, and an unstable working environment tensions within the business may rise as employees are denied expected pay increases, or have to be let go to compensate for falling profits. Employers and employees alike must be flexible, and make every effort to adapt to new and less predictable economic conditions, to have the best chance of survival.", "hypothesis": "Flexible businesses which adapt to new economic conditions will survive a recession.", "gold_label": "neutral"}
{"uid": "id_682", "premise": "There are a number of ways in which economic recession can impact a business, beside the most obvious factor of reduced consumer spending and a resultant decrease in sales. Recession also leads to a rise in inflation, which increases a business's expenditure. These factors in turn act both to reduce competition, through less stable businesses closing down, and simultaneously also to increase it, as remaining ones compete more aggressively to stay afloat. The combined effect of these factors can lead both to fluctuating sales, and an unstable working environment tensions within the business may rise as employees are denied expected pay increases, or have to be let go to compensate for falling profits. Employers and employees alike must be flexible, and make every effort to adapt to new and less predictable economic conditions, to have the best chance of survival.", "hypothesis": "Reduced consumer spending leads to a rise in inflation.", "gold_label": "neutral"}
{"uid": "id_683", "premise": "There are a number of ways in which economic recession can impact a business, beside the most obvious factor of reduced consumer spending and a resultant decrease in sales. Recession also leads to a rise in inflation, which increases a business's expenditure. These factors in turn act both to reduce competition, through less stable businesses closing down, and simultaneously also to increase it, as remaining ones compete more aggressively to stay afloat. The combined effect of these factors can lead both to fluctuating sales, and an unstable working environment tensions within the business may rise as employees are denied expected pay increases, or have to be let go to compensate for falling profits. Employers and employees alike must be flexible, and make every effort to adapt to new and less predictable economic conditions, to have the best chance of survival.", "hypothesis": "Recession, via decreased sales and increased operating costs, can both reduce and increase competition in business.", "gold_label": "entailment"}
{"uid": "id_684", "premise": "There are many comic tropes a comedian or group of comedians may want to employ in their set or act, but for the purpose of this extract we shall focus on the device of the call-back. A call-back is a reference made to a previous joke, in a different context: for example, a comedian may make the joke why did the chicken cross the road? To get to the other side early on in his or her set, and then later on may reference this again by telling an anecdote and saying so then I crossed the road - oh, look, theres a chicken! Strange, I could have sworn he was over there a moment ago. Though the call-back may appear to simply rely on the idea that repetition is inherently funny, it actually has several desirable effects. Firstly, it means that one joke can provide more than one laugh, as the memory of the previous joke encourages renewed chuckling, and so the original quips comic potential is increased. It also builds up a relationship between comedian and audience, as it builds up a sense of familiarity with the speaker and his or her subject matter, and this bond also may encourage more laughter - the second joke creates the same feeling as an in-joke. If used at the end of a set - as a call-back often is - it gives a sense of completion, and also may lead to the ending of the act culminating in the largest laugh. In TV, a call-back often refers to a joke made in a previous episode.", "hypothesis": "Repetition is inherently funny.", "gold_label": "neutral"}
{"uid": "id_685", "premise": "There are many comic tropes a comedian or group of comedians may want to employ in their set or act, but for the purpose of this extract we shall focus on the device of the call-back. A call-back is a reference made to a previous joke, in a different context: for example, a comedian may make the joke why did the chicken cross the road? To get to the other side early on in his or her set, and then later on may reference this again by telling an anecdote and saying so then I crossed the road - oh, look, theres a chicken! Strange, I could have sworn he was over there a moment ago. Though the call-back may appear to simply rely on the idea that repetition is inherently funny, it actually has several desirable effects. Firstly, it means that one joke can provide more than one laugh, as the memory of the previous joke encourages renewed chuckling, and so the original quips comic potential is increased. It also builds up a relationship between comedian and audience, as it builds up a sense of familiarity with the speaker and his or her subject matter, and this bond also may encourage more laughter - the second joke creates the same feeling as an in-joke. If used at the end of a set - as a call-back often is - it gives a sense of completion, and also may lead to the ending of the act culminating in the largest laugh. In TV, a call-back often refers to a joke made in a previous episode.", "hypothesis": "A call-back is an especially important trope to consider.", "gold_label": "neutral"}
{"uid": "id_686", "premise": "There are many comic tropes a comedian or group of comedians may want to employ in their set or act, but for the purpose of this extract we shall focus on the device of the call-back. A call-back is a reference made to a previous joke, in a different context: for example, a comedian may make the joke why did the chicken cross the road? To get to the other side early on in his or her set, and then later on may reference this again by telling an anecdote and saying so then I crossed the road - oh, look, theres a chicken! Strange, I could have sworn he was over there a moment ago. Though the call-back may appear to simply rely on the idea that repetition is inherently funny, it actually has several desirable effects. Firstly, it means that one joke can provide more than one laugh, as the memory of the previous joke encourages renewed chuckling, and so the original quips comic potential is increased. It also builds up a relationship between comedian and audience, as it builds up a sense of familiarity with the speaker and his or her subject matter, and this bond also may encourage more laughter - the second joke creates the same feeling as an in-joke. If used at the end of a set - as a call-back often is - it gives a sense of completion, and also may lead to the ending of the act culminating in the largest laugh. In TV, a call-back often refers to a joke made in a previous episode.", "hypothesis": "A call-back creates unity through disparate TV episodes.", "gold_label": "neutral"}
{"uid": "id_687", "premise": "There are many comic tropes a comedian or group of comedians may want to employ in their set or act, but for the purpose of this extract we shall focus on the device of the call-back. A call-back is a reference made to a previous joke, in a different context: for example, a comedian may make the joke why did the chicken cross the road? To get to the other side early on in his or her set, and then later on may reference this again by telling an anecdote and saying so then I crossed the road - oh, look, theres a chicken! Strange, I could have sworn he was over there a moment ago. Though the call-back may appear to simply rely on the idea that repetition is inherently funny, it actually has several desirable effects. Firstly, it means that one joke can provide more than one laugh, as the memory of the previous joke encourages renewed chuckling, and so the original quips comic potential is increased. It also builds up a relationship between comedian and audience, as it builds up a sense of familiarity with the speaker and his or her subject matter, and this bond also may encourage more laughter - the second joke creates the same feeling as an in-joke. If used at the end of a set - as a call-back often is - it gives a sense of completion, and also may lead to the ending of the act culminating in the largest laugh. In TV, a call-back often refers to a joke made in a previous episode.", "hypothesis": "A call-back can be a useful addition to an individual comedians set.", "gold_label": "entailment"}
{"uid": "id_688", "premise": "There are many comic tropes a comedian or group of comedians may want to employ in their set or act, but for the purpose of this extract we shall focus on the device of the call-back. A call-back is a reference made to a previous joke, in a different context: for example, a comedian may make the joke why did the chicken cross the road? To get to the other side early on in his or her set, and then later on may reference this again by telling an anecdote and saying so then I crossed the road - oh, look, theres a chicken! Strange, I could have sworn he was over there a moment ago. Though the call-back may appear to simply rely on the idea that repetition is inherently funny, it actually has several desirable effects. Firstly, it means that one joke can provide more than one laugh, as the memory of the previous joke encourages renewed chuckling, and so the original quips comic potential is increased. It also builds up a relationship between comedian and audience, as it builds up a sense of familiarity with the speaker and his or her subject matter, and this bond also may encourage more laughter - the second joke creates the same feeling as an in-joke. If used at the end of a set - as a call-back often is - it gives a sense of completion, and also may lead to the ending of the act culminating in the largest laugh. In TV, a call-back often refers to a joke made in a previous episode.", "hypothesis": "For a call-back to work, the original joke has to be significantly funny.", "gold_label": "neutral"}
{"uid": "id_689", "premise": "There are many comic tropes a comedian or group of comedians may want to employ in their set or act, but for the purpose of this extract we shall focus on the device of the call-back. A call-back is a reference made to a previous joke, in a different context: for example, a comedian may make the joke why did the chicken cross the road? To get to the other side early on in his or her set, and then later on may reference this again by telling an anecdote and saying so then I crossed the road - oh, look, theres a chicken! Strange, I could have sworn he was over there a moment ago. Though the call-back may appear to simply rely on the idea that repetition is inherently funny, it actually has several desirable effects. Firstly, it means that one joke can provide more than one laugh, as the memory of the previous joke encourages renewed chuckling, and so the original quips comic potential is increased. It also builds up a relationship between comedian and audience, as it builds up a sense of familiarity with the speaker and his or her subject matter, and this bond also may encourage more laughter - the second joke creates the same feeling as an in-joke. If used at the end of a set - as a call-back often is - it gives a sense of completion, and also may lead to the ending of the act culminating in the largest laugh. In TV, a call-back often refers to a joke made in a previous episode.", "hypothesis": "A call-back is used to create a sense of the circle having fully come to pass.", "gold_label": "neutral"}
{"uid": "id_690", "premise": "There are many comic tropes a comedian or group of comedians may want to employ in their set or act, but for the purpose of this extract we shall focus on the device of the call-back. A call-back is a reference made to a previous joke, in a different context: for example, a comedian may make the joke why did the chicken cross the road? To get to the other side early on in his or her set, and then later on may reference this again by telling an anecdote and saying so then I crossed the road - oh, look, theres a chicken! Strange, I could have sworn he was over there a moment ago. Though the call-back may appear to simply rely on the idea that repetition is inherently funny, it actually has several desirable effects. Firstly, it means that one joke can provide more than one laugh, as the memory of the previous joke encourages renewed chuckling, and so the original quips comic potential is increased. It also builds up a relationship between comedian and audience, as it builds up a sense of familiarity with the speaker and his or her subject matter, and this bond also may encourage more laughter - the second joke creates the same feeling as an in-joke. If used at the end of a set - as a call-back often is - it gives a sense of completion, and also may lead to the ending of the act culminating in the largest laugh. In TV, a call-back often refers to a joke made in a previous episode.", "hypothesis": "A call-back cannot be used in an un-comic setting.", "gold_label": "neutral"}
{"uid": "id_691", "premise": "There are now several million cars in the UK using satellite navigation (satnav) systems. These mcreasingly popular satnav systems mean that motorists no longer have to read maps while they are driving. There are two other major advantages: reduced journey time and reduced mileage (and thus fucl consumption) on unfamihar routes. System improvements have made these devices much more features. Although some safety surveys highlight the dangers of operating dashboard devices while driving, research conducted by one satnav manufacturer showed that nearly 70 per cent of drivers felt calmer and more focused on the road when using a satnav system.", "hypothesis": "Early satnav systems were less accurate than modern ones.", "gold_label": "entailment"}
{"uid": "id_692", "premise": "There are now several million cars in the UK using satellite navigation (satnav) systems. These mcreasingly popular satnav systems mean that motorists no longer have to read maps while they are driving. There are two other major advantages: reduced journey time and reduced mileage (and thus fucl consumption) on unfamihar routes. System improvements have made these devices much more features. Although some safety surveys highlight the dangers of operating dashboard devices while driving, research conducted by one satnav manufacturer showed that nearly 70 per cent of drivers felt calmer and more focused on the road when using a satnav system.", "hypothesis": "The passage suggests that a satnav system can make navigation more efficient.", "gold_label": "entailment"}
{"uid": "id_693", "premise": "There are now several million cars in the UK using satellite navigation (satnav) systems. These mcreasingly popular satnav systems mean that motorists no longer have to read maps while they are driving. There are two other major advantages: reduced journey time and reduced mileage (and thus fucl consumption) on unfamihar routes. System improvements have made these devices much more features. Although some safety surveys highlight the dangers of operating dashboard devices while driving, research conducted by one satnav manufacturer showed that nearly 70 per cent of drivers felt calmer and more focused on the road when using a satnav system.", "hypothesis": "Satellite navigation systems are useful for those people who cant read maps.", "gold_label": "entailment"}
{"uid": "id_694", "premise": "There are now several million cars in the UK using satellite navigation (satnav) systems. These mcreasingly popular satnav systems mean that motorists no longer have to read maps while they are driving. There are two other major advantages: reduced journey time and reduced mileage (and thus fucl consumption) on unfamihar routes. System improvements have made these devices much more features. Although some safety surveys highlight the dangers of operating dashboard devices while driving, research conducted by one satnav manufacturer showed that nearly 70 per cent of drivers felt calmer and more focused on the road when using a satnav system.", "hypothesis": "Controversy remains about the effects that satnav systems have on driver concentration.", "gold_label": "entailment"}
{"uid": "id_695", "premise": "There are now several million cars in the UK using satellite navigation (satnav) systems. These mcreasingly popular satnav systems mean that motorists no longer have to read maps while they are driving. There are two other major advantages: reduced journey time and reduced mileage (and thus fucl consumption) on unfamihar routes. System improvements have made these devices much more features. Although some safety surveys highlight the dangers of operating dashboard devices while driving, research conducted by one satnav manufacturer showed that nearly 70 per cent of drivers felt calmer and more focused on the road when using a satnav system.", "hypothesis": "Most drivers feel calmer when using a satnav system.", "gold_label": "entailment"}
{"uid": "id_696", "premise": "There are seven species of deer living wild in Britain. The Red Deer and the Roe Deer are native species. Fallow Deer were introduced by the Romans and, since the seventeenth century, have been joined by three other non-native species: Sika, Muntjac and Chinese Water Deer the ancestors of which have escaped from parks. In addition, a herd of Reindeer was established in Scotland in 1952. Most of the Red Deer in Britain are found in Scotland, but there are significant wild populations in south-west and north-west England, East Anglia and the north Midlands. Red deer can interbreed with the introduced Japanese Sika deer and in some areas, hybrids are common.", "hypothesis": "Red Deer can interbreed with Fallow Deer.", "gold_label": "neutral"}
{"uid": "id_697", "premise": "There are seven species of deer living wild in Britain. The Red Deer and the Roe Deer are native species. Fallow Deer were introduced by the Romans and, since the seventeenth century, have been joined by three other non-native species: Sika, Muntjac and Chinese Water Deer the ancestors of which have escaped from parks. In addition, a herd of Reindeer was established in Scotland in 1952. Most of the Red Deer in Britain are found in Scotland, but there are significant wild populations in south-west and north-west England, East Anglia and the north Midlands. Red deer can interbreed with the introduced Japanese Sika deer and in some areas, hybrids are common.", "hypothesis": "The Fallow Deer is not native to Britain.", "gold_label": "entailment"}
{"uid": "id_698", "premise": "There are seven species of deer living wild in Britain. The Red Deer and the Roe Deer are native species. Fallow Deer were introduced by the Romans and, since the seventeenth century, have been joined by three other non-native species: Sika, Muntjac and Chinese Water Deer the ancestors of which have escaped from parks. In addition, a herd of Reindeer was established in Scotland in 1952. Most of the Red Deer in Britain are found in Scotland, but there are significant wild populations in south-west and north-west England, East Anglia and the north Midlands. Red deer can interbreed with the introduced Japanese Sika deer and in some areas, hybrids are common.", "hypothesis": "There are no Reindeer in England.", "gold_label": "neutral"}
{"uid": "id_699", "premise": "There are seven species of deer living wild in Britain. The Red Deer and the Roe Deer are native species. Fallow Deer were introduced by the Romans and, since the seventeenth century, have been joined by three other non-native species: Sika, Muntjac and Chinese Water Deer the ancestors of which have escaped from parks. In addition, a herd of Reindeer was established in Scotland in 1952. Most of the Red Deer in Britain are found in Scotland, but there are significant wild populations in south-west and north-west England, East Anglia and the north Midlands. Red deer can interbreed with the introduced Japanese Sika deer and in some areas, hybrids are common.", "hypothesis": "All of the Red Deer in Britain are found in Scotland.", "gold_label": "contradiction"}
{"uid": "id_700", "premise": "There are seven species of deer living wild in Britain. The Red Deer and the Roe Deer are native species. Fallow Deer were introduced by the Romans and, since the seventeenth century, have been joined by three other non-native species: Sika, Muntjac and Chinese Water Deer the ancestors of which have escaped from parks. In addition, a herd of Reindeer was established in Scotland in 1952. Most of the Red Deer in Britain are found in Scotland, but there are significant wild populations in south-west and north-west England, East Anglia and the north Midlands. Red deer can interbreed with the introduced Japanese Sika deer and in some areas, hybrids are common.", "hypothesis": "All of the Muntjac in England have escaped from parks.", "gold_label": "contradiction"}
{"uid": "id_701", "premise": "There are several forms of public transport in the UK. Statistics suggest that forms of public transport are becoming increasingly popular, due to relatively cheap cost when compared to private transport. In addition to this, public transport is often quicker and more reliable, especially when travelling in busy cities, such as London. One reason why public transport is increasingly popular in London is the ease in which people can travel around the city centre. Services such as the Underground provide the opportunity to beat traffic congestion and negate the need for often costly parking. In addition, the regularity of such services is popular. However, public transport is often less popular in less densely populated areas. A possible reason for this is that services tend to be less regular, making public transport a less practical option.", "hypothesis": "Public transport can be cheaper and more practical in busy cities.", "gold_label": "entailment"}
{"uid": "id_702", "premise": "There are several forms of public transport in the UK. Statistics suggest that forms of public transport are becoming increasingly popular, due to relatively cheap cost when compared to private transport. In addition to this, public transport is often quicker and more reliable, especially when travelling in busy cities, such as London. One reason why public transport is increasingly popular in London is the ease in which people can travel around the city centre. Services such as the Underground provide the opportunity to beat traffic congestion and negate the need for often costly parking. In addition, the regularity of such services is popular. However, public transport is often less popular in less densely populated areas. A possible reason for this is that services tend to be less regular, making public transport a less practical option.", "hypothesis": "Public transport is often safer than parking in busy cities.", "gold_label": "neutral"}
{"uid": "id_703", "premise": "There are several forms of public transport in the UK. Statistics suggest that forms of public transport are becoming increasingly popular, due to relatively cheap cost when compared to private transport. In addition to this, public transport is often quicker and more reliable, especially when travelling in busy cities, such as London. One reason why public transport is increasingly popular in London is the ease in which people can travel around the city centre. Services such as the Underground provide the opportunity to beat traffic congestion and negate the need for often costly parking. In addition, the regularity of such services is popular. However, public transport is often less popular in less densely populated areas. A possible reason for this is that services tend to be less regular, making public transport a less practical option.", "hypothesis": "Public transport offers less regular services and can be unpractical.", "gold_label": "contradiction"}
{"uid": "id_704", "premise": "There are several forms of public transport in the UK. Statistics suggest that forms of public transport are becoming increasingly popular, due to relatively cheap cost when compared to private transport. In addition to this, public transport is often quicker and more reliable, especially when travelling in busy cities, such as London. One reason why public transport is increasingly popular in London is the ease in which people can travel around the city centre. Services such as the Underground provide the opportunity to beat traffic congestion and negate the need for often costly parking. In addition, the regularity of such services is popular. However, public transport is often less popular in less densely populated areas. A possible reason for this is that services tend to be less regular, making public transport a less practical option.", "hypothesis": "Public transport is more entertaining than private transport.", "gold_label": "neutral"}
{"uid": "id_705", "premise": "There are several possible reasons behind the participation in professional trade fairs - it can be an excellent sales platform providing an exposure to relevant customers and distributors as it is one of those rare occasions where customers actively seek specific products; it can be an image building expenditure aiming at strengthening a company's profile within a sector by showing novel products and a lucrative stall design; and it can be a good way to gauge your competition by accessing vital information about other products and to generally assess the direction the sector is heading. Trade fairs are extremely expensive especially as there are a number of important ones to attend every year globally and this often creates a financial burden on the minor \"players\". In many occasions the direct business impact does not seem to justify the enormous costs but as one senior manufacturer recently said \"if you're not there you don't exist\".", "hypothesis": "Professional trade fairs do not boost sales or strengthen a company's profile.", "gold_label": "contradiction"}
{"uid": "id_706", "premise": "There are several possible reasons behind the participation in professional trade fairs - it can be an excellent sales platform providing an exposure to relevant customers and distributors as it is one of those rare occasions where customers actively seek specific products; it can be an image building expenditure aiming at strengthening a company's profile within a sector by showing novel products and a lucrative stall design; and it can be a good way to gauge your competition by accessing vital information about other products and to generally assess the direction the sector is heading. Trade fairs are extremely expensive especially as there are a number of important ones to attend every year globally and this often creates a financial burden on the minor \"players\". In many occasions the direct business impact does not seem to justify the enormous costs but as one senior manufacturer recently said \"if you're not there you don't exist\".", "hypothesis": "Minor players may benefit from attending professional trade fairs.", "gold_label": "entailment"}
{"uid": "id_707", "premise": "There are several possible reasons behind the participation in professional trade fairs - it can be an excellent sales platform providing an exposure to relevant customers and distributors as it is one of those rare occasions where customers actively seek specific products; it can be an image building expenditure aiming at strengthening a company's profile within a sector by showing novel products and a lucrative stall design; and it can be a good way to gauge your competition by accessing vital information about other products and to generally assess the direction the sector is heading. Trade fairs are extremely expensive especially as there are a number of important ones to attend every year globally and this often creates a financial burden on the minor \"players\". In many occasions the direct business impact does not seem to justify the enormous costs but as one senior manufacturer recently said \"if you're not there you don't exist\".", "hypothesis": "The financial payback of participating in trade fairs justifies the cost.", "gold_label": "neutral"}
{"uid": "id_708", "premise": "There are several thousand patients waiting for organ transplants in the UK. This urgent need has led to a government review of how best to increase organ donation rates. The introduction of presumed consent as found in other European countries has now been put forward as a possible solution. Such a drastic and controversial change, whereby donating organs would become the default option, would require a new legal framework. Among many other proposals, the governments review recommended establishing the following: locally adapted national policies for organ donation; a best practice framework; and a national organisation to coordinate transplants.", "hypothesis": "Implementing presumed consent would necessitate new legislation.", "gold_label": "entailment"}
{"uid": "id_709", "premise": "There are several thousand patients waiting for organ transplants in the UK. This urgent need has led to a government review of how best to increase organ donation rates. The introduction of presumed consent as found in other European countries has now been put forward as a possible solution. Such a drastic and controversial change, whereby donating organs would become the default option, would require a new legal framework. Among many other proposals, the governments review recommended establishing the following: locally adapted national policies for organ donation; a best practice framework; and a national organisation to coordinate transplants.", "hypothesis": "Presumed consent means that donating your bodily organs 1s the standard option.", "gold_label": "entailment"}
{"uid": "id_710", "premise": "There are several thousand patients waiting for organ transplants in the UK. This urgent need has led to a government review of how best to increase organ donation rates. The introduction of presumed consent as found in other European countries has now been put forward as a possible solution. Such a drastic and controversial change, whereby donating organs would become the default option, would require a new legal framework. Among many other proposals, the governments review recommended establishing the following: locally adapted national policies for organ donation; a best practice framework; and a national organisation to coordinate transplants.", "hypothesis": "One recommendation was to introduce a standard national policy for all hospitals.", "gold_label": "contradiction"}
{"uid": "id_711", "premise": "There are several thousand patients waiting for organ transplants in the UK. This urgent need has led to a government review of how best to increase organ donation rates. The introduction of presumed consent as found in other European countries has now been put forward as a possible solution. Such a drastic and controversial change, whereby donating organs would become the default option, would require a new legal framework. Among many other proposals, the governments review recommended establishing the following: locally adapted national policies for organ donation; a best practice framework; and a national organisation to coordinate transplants.", "hypothesis": "Presumed consent was not proposed in the governments recommendations because it lacks popular support.", "gold_label": "contradiction"}
{"uid": "id_712", "premise": "There are several thousand patients waiting for organ transplants in the UK. This urgent need has led to a government review of how best to increase organ donation rates. The introduction of presumed consent as found in other European countries has now been put forward as a possible solution. Such a drastic and controversial change, whereby donating organs would become the default option, would require a new legal framework. Among many other proposals, the governments review recommended establishing the following: locally adapted national policies for organ donation; a best practice framework; and a national organisation to coordinate transplants.", "hypothesis": "The number of patients waiting for transplants led to the governments review of the current situation.", "gold_label": "entailment"}
{"uid": "id_713", "premise": "There are statistics which suggest that in some of the most underdeveloped countries almost one half of the population is aged between 10 and 19. These countries have experienced a much smaller decrease in birth rates than has been seen in more developed countries. Charities and other agencies are calling for additional funds to be made available to provide improved education for these young people as well as easier access to contraception. Aside from this is also a global increase in the number of people aged 65 or older. In the next 50 years, 95% of this increase will happen in developing countries like India, while in countries such as Japan, Germany and Italy the percentage of the population aged 65 or more is set to rise to 40%. Increases in the numbers of the very young and the very old place stress on societies, and governments may find it difficult to cope with the demands of an increasing number of dependent elderly citizens in addition to providing healthcare and education for the young.", "hypothesis": "The world as a whole is seeing more people over the age of 65.", "gold_label": "entailment"}
{"uid": "id_714", "premise": "There are statistics which suggest that in some of the most underdeveloped countries almost one half of the population is aged between 10 and 19. These countries have experienced a much smaller decrease in birth rates than has been seen in more developed countries. Charities and other agencies are calling for additional funds to be made available to provide improved education for these young people as well as easier access to contraception. Aside from this is also a global increase in the number of people aged 65 or older. In the next 50 years, 95% of this increase will happen in developing countries like India, while in countries such as Japan, Germany and Italy the percentage of the population aged 65 or more is set to rise to 40%. Increases in the numbers of the very young and the very old place stress on societies, and governments may find it difficult to cope with the demands of an increasing number of dependent elderly citizens in addition to providing healthcare and education for the young.", "hypothesis": "The percent of the population under the age of 19 is higher in developing countries than it is in developed countries.", "gold_label": "neutral"}
{"uid": "id_715", "premise": "There are statistics which suggest that in some of the most underdeveloped countries almost one half of the population is aged between 10 and 19. These countries have experienced a much smaller decrease in birth rates than has been seen in more developed countries. Charities and other agencies are calling for additional funds to be made available to provide improved education for these young people as well as easier access to contraception. Aside from this is also a global increase in the number of people aged 65 or older. In the next 50 years, 95% of this increase will happen in developing countries like India, while in countries such as Japan, Germany and Italy the percentage of the population aged 65 or more is set to rise to 40%. Increases in the numbers of the very young and the very old place stress on societies, and governments may find it difficult to cope with the demands of an increasing number of dependent elderly citizens in addition to providing healthcare and education for the young.", "hypothesis": "Declines in birth rates are not limited to developed countries.", "gold_label": "entailment"}
{"uid": "id_716", "premise": "There has been a remarkable increase in the air traffic in India during the past few years.", "hypothesis": "Large number of people are able to afford air travel now.", "gold_label": "entailment"}
{"uid": "id_717", "premise": "There has been a remarkable increase in the air traffic in India during the past few years.", "hypothesis": "Travelling by air has become a status symbol now", "gold_label": "neutral"}
{"uid": "id_718", "premise": "There has been a sudden increase in the occurrence of attempts by confidence tricksters to extract money from elderly people under false pretences. This has caused the police to issue warnings to senior citizens not to let strangers into their homes. So far the police have estab- lished the following facts: Mr Froode gave 75 to a dark-haired young man posing as a representative of an insurance company. Mr Grace paid 80 to a smartly dressed 30-year-old woman who claimed that she was a financial adviser. A man who tried to trick 27-year-old Ms Dodds into paying a deposit of 100 towards the cost of a new front door was the driver of a silver grey BMW. Over a two-day period a confidence trickster has contacted more than 400 households. All of the names and addresses given by the confidence tricksters have been found to be false.", "hypothesis": "The potential victims all lived in a closely-knit neighbourhood.", "gold_label": "neutral"}
{"uid": "id_719", "premise": "There has been a sudden increase in the occurrence of attempts by confidence tricksters to extract money from elderly people under false pretences. This has caused the police to issue warnings to senior citizens not to let strangers into their homes. So far the police have estab- lished the following facts: Mr Froode gave 75 to a dark-haired young man posing as a representative of an insurance company. Mr Grace paid 80 to a smartly dressed 30-year-old woman who claimed that she was a financial adviser. A man who tried to trick 27-year-old Ms Dodds into paying a deposit of 100 towards the cost of a new front door was the driver of a silver grey BMW. Over a two-day period a confidence trickster has contacted more than 400 households. All of the names and addresses given by the confidence tricksters have been found to be false.", "hypothesis": "The confidence trickster was a transvestite.", "gold_label": "neutral"}
{"uid": "id_720", "premise": "There has been a sudden increase in the occurrence of attempts by confidence tricksters to extract money from elderly people under false pretences. This has caused the police to issue warnings to senior citizens not to let strangers into their homes. So far the police have estab- lished the following facts: Mr Froode gave 75 to a dark-haired young man posing as a representative of an insurance company. Mr Grace paid 80 to a smartly dressed 30-year-old woman who claimed that she was a financial adviser. A man who tried to trick 27-year-old Ms Dodds into paying a deposit of 100 towards the cost of a new front door was the driver of a silver grey BMW. Over a two-day period a confidence trickster has contacted more than 400 households. All of the names and addresses given by the confidence tricksters have been found to be false.", "hypothesis": "Several confidence tricksters, both male and female, were working together.", "gold_label": "neutral"}
{"uid": "id_721", "premise": "There has been a sudden increase in the occurrence of attempts by confidence tricksters to extract money from elderly people under false pretences. This has caused the police to issue warnings to senior citizens not to let strangers into their homes. So far the police have estab- lished the following facts: Mr Froode gave 75 to a dark-haired young man posing as a representative of an insurance company. Mr Grace paid 80 to a smartly dressed 30-year-old woman who claimed that she was a financial adviser. A man who tried to trick 27-year-old Ms Dodds into paying a deposit of 100 towards the cost of a new front door was the driver of a silver grey BMW. Over a two-day period a confidence trickster has contacted more than 400 households. All of the names and addresses given by the confidence tricksters have been found to be false.", "hypothesis": "The confidence tricksters only approached old-age pensioners.", "gold_label": "contradiction"}
{"uid": "id_722", "premise": "There has been a sudden increase in the occurrence of attempts by confidence tricksters to extract money from elderly people under false pretences. This has caused the police to issue warnings to senior citizens not to let strangers into their homes. So far the police have estab- lished the following facts: Mr Froode gave 75 to a dark-haired young man posing as a representative of an insurance company. Mr Grace paid 80 to a smartly dressed 30-year-old woman who claimed that she was a financial adviser. A man who tried to trick 27-year-old Ms Dodds into paying a deposit of 100 towards the cost of a new front door was the driver of a silver grey BMW. Over a two-day period a confidence trickster has contacted more than 400 households. All of the names and addresses given by the confidence tricksters have been found to be false.", "hypothesis": "The confidence tricksters may have contacted people first by telephone.", "gold_label": "entailment"}
{"uid": "id_723", "premise": "There is a great concern in Europe and North America about declining standards of literacy in schools. In Britain, the fact that 30 per cent of 16 year olds have a reading age of 14 or less has helped to prompt massive educational changes. The development of literacy has far-reaching effects on general intellectual development and thus anything which impedes the development of literacy is a serious matter for us all. So the hunt is on for the cause of the decline in literacy. The search so far has focused on socio-economic factors, or the effectiveness of 'traditional' versus 'modern' teaching techniques. The fruitless search for the cause of the increase in illiteracy is a tragic example of the saying They can't see the wood for the trees. When teachers use picture books, they are simply continuing a long-established tradition that is accepted without question. And for the past two decades, illustrations in reading primers have become impoverished - sometimes to the point of extinction. Amazingly, there is virtually no empirical evidence to support the use of illustrations in teaching reading. On the contrary, a great deal of empirical evidence shows that pictures interfere in a damaging way with all aspect of learning to read. Despite this, from North America to the Antipodes, the first books that many school children receive are totally without text. A teacher's main concern is to help young beginner readers to develop not only the ability to recognise words, but the skills necessary to understand what these words mean. Even if a child is able to read aloud fluently, he or she may not be able to understand much of it; this is called barking at text. The teacher's task of improving comprehension is made harder by influences outside the classroom. But the adverse effects of such things as television, video games, or limited language experiences at home, can be offset by experiencing rich language at school. Instead, it is unusual for a book of 30 or more pages to have only one sentence full of repetitive phrases. The artwork is often marvellous, but the pictures make the language redundant, and the children have no need to imagine anything when they read such books. Looking at a picture actively prevents children younger than nine from creating a mental image, and can make it difficult for older children. In order to learn how to comprehend, they need to practise making their own meaning in response to text. They need to have their innate powers of imagination trained. As they grow older, many children turn aside from books without pictures, and it is a situation made more serious as our culture becomes more visual. It is hard to wean children off picture books when pictures have played a major part throughout their formative reading experiences, and when there is competition for their attention from so many other sources of entertainment. The least intelligent are most vulnerable, but tests show that even intelligent children are being affected. The response of educators has been to extend the use of pictures in books and to simplify the language, even at senior levels. The Universities of Oxford and Cambridge recently held joint conferences to disease the noticeably rapid decline in literacy among their undergraduates. Pictures are also used to help motivate children to read because they are beautiful and eye-catching. But motivation to read should be provided by listening to stories well read, where children imagine in response to the story. Then, as they start to read, they have this experience to help them understand the language. If we present pictures to save children the trouble of developing these creative skills, then I think we are making a great mistake. Academic journals ranging from educational research, psychology, language learning, psycholinguistics, and so on cite experiments which demonstrate how detrimental pictures are for beginner readers. Here is a brief selection: The research results of the Canadian educationalist Dale Willows were clear and consistent: pictures affected speed and accuracy and the closer the pictures were to the words, the slower and more inaccurate the child's reading became. She claims that when children come to a word they already know, then the pictures are unnecessary and distracting. If they do not know a word and look to the picture for a clue to its meaning, they may well be misled by aspects of the pictures which are not closely related to the meaning of the word they are trying to understand. Jay Samuels, an American psychologist, found that poor readers given no pictures learnt significantly more words than those learning to read with books with pictures. He examined the work of other researchers who had reported problems with the use of pictures and who found that a word without a picture was superior to a word plus a picture. When children were given words and pictures, those who seemed to ignore the pictures and pointed at the words learnt more words than the children who pointed at the pictures, but they still learnt fewer words than the children who had no illustrated stimuli at all.", "hypothesis": "Teachers aim to teach both word recognition and word meaning.", "gold_label": "entailment"}
{"uid": "id_724", "premise": "There is a great concern in Europe and North America about declining standards of literacy in schools. In Britain, the fact that 30 per cent of 16 year olds have a reading age of 14 or less has helped to prompt massive educational changes. The development of literacy has far-reaching effects on general intellectual development and thus anything which impedes the development of literacy is a serious matter for us all. So the hunt is on for the cause of the decline in literacy. The search so far has focused on socio-economic factors, or the effectiveness of 'traditional' versus 'modern' teaching techniques. The fruitless search for the cause of the increase in illiteracy is a tragic example of the saying They can't see the wood for the trees. When teachers use picture books, they are simply continuing a long-established tradition that is accepted without question. And for the past two decades, illustrations in reading primers have become impoverished - sometimes to the point of extinction. Amazingly, there is virtually no empirical evidence to support the use of illustrations in teaching reading. On the contrary, a great deal of empirical evidence shows that pictures interfere in a damaging way with all aspect of learning to read. Despite this, from North America to the Antipodes, the first books that many school children receive are totally without text. A teacher's main concern is to help young beginner readers to develop not only the ability to recognise words, but the skills necessary to understand what these words mean. Even if a child is able to read aloud fluently, he or she may not be able to understand much of it; this is called barking at text. The teacher's task of improving comprehension is made harder by influences outside the classroom. But the adverse effects of such things as television, video games, or limited language experiences at home, can be offset by experiencing rich language at school. Instead, it is unusual for a book of 30 or more pages to have only one sentence full of repetitive phrases. The artwork is often marvellous, but the pictures make the language redundant, and the children have no need to imagine anything when they read such books. Looking at a picture actively prevents children younger than nine from creating a mental image, and can make it difficult for older children. In order to learn how to comprehend, they need to practise making their own meaning in response to text. They need to have their innate powers of imagination trained. As they grow older, many children turn aside from books without pictures, and it is a situation made more serious as our culture becomes more visual. It is hard to wean children off picture books when pictures have played a major part throughout their formative reading experiences, and when there is competition for their attention from so many other sources of entertainment. The least intelligent are most vulnerable, but tests show that even intelligent children are being affected. The response of educators has been to extend the use of pictures in books and to simplify the language, even at senior levels. The Universities of Oxford and Cambridge recently held joint conferences to disease the noticeably rapid decline in literacy among their undergraduates. Pictures are also used to help motivate children to read because they are beautiful and eye-catching. But motivation to read should be provided by listening to stories well read, where children imagine in response to the story. Then, as they start to read, they have this experience to help them understand the language. If we present pictures to save children the trouble of developing these creative skills, then I think we are making a great mistake. Academic journals ranging from educational research, psychology, language learning, psycholinguistics, and so on cite experiments which demonstrate how detrimental pictures are for beginner readers. Here is a brief selection: The research results of the Canadian educationalist Dale Willows were clear and consistent: pictures affected speed and accuracy and the closer the pictures were to the words, the slower and more inaccurate the child's reading became. She claims that when children come to a word they already know, then the pictures are unnecessary and distracting. If they do not know a word and look to the picture for a clue to its meaning, they may well be misled by aspects of the pictures which are not closely related to the meaning of the word they are trying to understand. Jay Samuels, an American psychologist, found that poor readers given no pictures learnt significantly more words than those learning to read with books with pictures. He examined the work of other researchers who had reported problems with the use of pictures and who found that a word without a picture was superior to a word plus a picture. When children were given words and pictures, those who seemed to ignore the pictures and pointed at the words learnt more words than the children who pointed at the pictures, but they still learnt fewer words than the children who had no illustrated stimuli at all.", "hypothesis": "It is traditionally accepted that children's books should contain few pictures.", "gold_label": "contradiction"}
{"uid": "id_725", "premise": "There is a great concern in Europe and North America about declining standards of literacy in schools. In Britain, the fact that 30 per cent of 16 year olds have a reading age of 14 or less has helped to prompt massive educational changes. The development of literacy has far-reaching effects on general intellectual development and thus anything which impedes the development of literacy is a serious matter for us all. So the hunt is on for the cause of the decline in literacy. The search so far has focused on socio-economic factors, or the effectiveness of 'traditional' versus 'modern' teaching techniques. The fruitless search for the cause of the increase in illiteracy is a tragic example of the saying They can't see the wood for the trees. When teachers use picture books, they are simply continuing a long-established tradition that is accepted without question. And for the past two decades, illustrations in reading primers have become impoverished - sometimes to the point of extinction. Amazingly, there is virtually no empirical evidence to support the use of illustrations in teaching reading. On the contrary, a great deal of empirical evidence shows that pictures interfere in a damaging way with all aspect of learning to read. Despite this, from North America to the Antipodes, the first books that many school children receive are totally without text. A teacher's main concern is to help young beginner readers to develop not only the ability to recognise words, but the skills necessary to understand what these words mean. Even if a child is able to read aloud fluently, he or she may not be able to understand much of it; this is called barking at text. The teacher's task of improving comprehension is made harder by influences outside the classroom. But the adverse effects of such things as television, video games, or limited language experiences at home, can be offset by experiencing rich language at school. Instead, it is unusual for a book of 30 or more pages to have only one sentence full of repetitive phrases. The artwork is often marvellous, but the pictures make the language redundant, and the children have no need to imagine anything when they read such books. Looking at a picture actively prevents children younger than nine from creating a mental image, and can make it difficult for older children. In order to learn how to comprehend, they need to practise making their own meaning in response to text. They need to have their innate powers of imagination trained. As they grow older, many children turn aside from books without pictures, and it is a situation made more serious as our culture becomes more visual. It is hard to wean children off picture books when pictures have played a major part throughout their formative reading experiences, and when there is competition for their attention from so many other sources of entertainment. The least intelligent are most vulnerable, but tests show that even intelligent children are being affected. The response of educators has been to extend the use of pictures in books and to simplify the language, even at senior levels. The Universities of Oxford and Cambridge recently held joint conferences to disease the noticeably rapid decline in literacy among their undergraduates. Pictures are also used to help motivate children to read because they are beautiful and eye-catching. But motivation to read should be provided by listening to stories well read, where children imagine in response to the story. Then, as they start to read, they have this experience to help them understand the language. If we present pictures to save children the trouble of developing these creative skills, then I think we are making a great mistake. Academic journals ranging from educational research, psychology, language learning, psycholinguistics, and so on cite experiments which demonstrate how detrimental pictures are for beginner readers. Here is a brief selection: The research results of the Canadian educationalist Dale Willows were clear and consistent: pictures affected speed and accuracy and the closer the pictures were to the words, the slower and more inaccurate the child's reading became. She claims that when children come to a word they already know, then the pictures are unnecessary and distracting. If they do not know a word and look to the picture for a clue to its meaning, they may well be misled by aspects of the pictures which are not closely related to the meaning of the word they are trying to understand. Jay Samuels, an American psychologist, found that poor readers given no pictures learnt significantly more words than those learning to read with books with pictures. He examined the work of other researchers who had reported problems with the use of pictures and who found that a word without a picture was superior to a word plus a picture. When children were given words and pictures, those who seemed to ignore the pictures and pointed at the words learnt more words than the children who pointed at the pictures, but they still learnt fewer words than the children who had no illustrated stimuli at all.", "hypothesis": "Older readers are having difficulty in adjusting to texts without pictures.", "gold_label": "entailment"}
{"uid": "id_726", "premise": "There is a great concern in Europe and North America about declining standards of literacy in schools. In Britain, the fact that 30 per cent of 16 year olds have a reading age of 14 or less has helped to prompt massive educational changes. The development of literacy has far-reaching effects on general intellectual development and thus anything which impedes the development of literacy is a serious matter for us all. So the hunt is on for the cause of the decline in literacy. The search so far has focused on socio-economic factors, or the effectiveness of 'traditional' versus 'modern' teaching techniques. The fruitless search for the cause of the increase in illiteracy is a tragic example of the saying They can't see the wood for the trees. When teachers use picture books, they are simply continuing a long-established tradition that is accepted without question. And for the past two decades, illustrations in reading primers have become impoverished - sometimes to the point of extinction. Amazingly, there is virtually no empirical evidence to support the use of illustrations in teaching reading. On the contrary, a great deal of empirical evidence shows that pictures interfere in a damaging way with all aspect of learning to read. Despite this, from North America to the Antipodes, the first books that many school children receive are totally without text. A teacher's main concern is to help young beginner readers to develop not only the ability to recognise words, but the skills necessary to understand what these words mean. Even if a child is able to read aloud fluently, he or she may not be able to understand much of it; this is called barking at text. The teacher's task of improving comprehension is made harder by influences outside the classroom. But the adverse effects of such things as television, video games, or limited language experiences at home, can be offset by experiencing rich language at school. Instead, it is unusual for a book of 30 or more pages to have only one sentence full of repetitive phrases. The artwork is often marvellous, but the pictures make the language redundant, and the children have no need to imagine anything when they read such books. Looking at a picture actively prevents children younger than nine from creating a mental image, and can make it difficult for older children. In order to learn how to comprehend, they need to practise making their own meaning in response to text. They need to have their innate powers of imagination trained. As they grow older, many children turn aside from books without pictures, and it is a situation made more serious as our culture becomes more visual. It is hard to wean children off picture books when pictures have played a major part throughout their formative reading experiences, and when there is competition for their attention from so many other sources of entertainment. The least intelligent are most vulnerable, but tests show that even intelligent children are being affected. The response of educators has been to extend the use of pictures in books and to simplify the language, even at senior levels. The Universities of Oxford and Cambridge recently held joint conferences to disease the noticeably rapid decline in literacy among their undergraduates. Pictures are also used to help motivate children to read because they are beautiful and eye-catching. But motivation to read should be provided by listening to stories well read, where children imagine in response to the story. Then, as they start to read, they have this experience to help them understand the language. If we present pictures to save children the trouble of developing these creative skills, then I think we are making a great mistake. Academic journals ranging from educational research, psychology, language learning, psycholinguistics, and so on cite experiments which demonstrate how detrimental pictures are for beginner readers. Here is a brief selection: The research results of the Canadian educationalist Dale Willows were clear and consistent: pictures affected speed and accuracy and the closer the pictures were to the words, the slower and more inaccurate the child's reading became. She claims that when children come to a word they already know, then the pictures are unnecessary and distracting. If they do not know a word and look to the picture for a clue to its meaning, they may well be misled by aspects of the pictures which are not closely related to the meaning of the word they are trying to understand. Jay Samuels, an American psychologist, found that poor readers given no pictures learnt significantly more words than those learning to read with books with pictures. He examined the work of other researchers who had reported problems with the use of pictures and who found that a word without a picture was superior to a word plus a picture. When children were given words and pictures, those who seemed to ignore the pictures and pointed at the words learnt more words than the children who pointed at the pictures, but they still learnt fewer words than the children who had no illustrated stimuli at all.", "hypothesis": "Literacy has improved as a result of recent academic conferences.", "gold_label": "neutral"}
{"uid": "id_727", "premise": "There is a marked discrepancy between what managers see as the causes of absence from work, and the reasons given by employees. Many organisations are now suffering from being too streamlined. By reducing staff levels to such an extent, even minimal levels of absenteeism put remaining employees under intolerable pressure. In due course this may spread stress-related absence or other problems across the organisation.", "hypothesis": "Managers and staff disagree about the reasons for absenteeism from work", "gold_label": "entailment"}
{"uid": "id_728", "premise": "There is no doubt that vegetarian food can be healthier than a traditional diet indeed, research has demonstrated that vegetarians are less likely to suffer from heart disease and obesity than those who eat meat. One long-standing concern about a vegetarian lifestyle is the risk of failing to take in enough protein. However, historical calculations as to the amount of protein needed for a healthy lifestyle have recently been shown to overestimate the quantities needed, and if vegetarian select their food carefully they should be able to meet their protein needs.", "hypothesis": "A balanced diet is more likely to promote health than any particular food or food group in isolation.", "gold_label": "neutral"}
{"uid": "id_729", "premise": "There is no doubt that vegetarian food can be healthier than a traditional diet indeed, research has demonstrated that vegetarians are less likely to suffer from heart disease and obesity than those who eat meat. One long-standing concern about a vegetarian lifestyle is the risk of failing to take in enough protein. However, historical calculations as to the amount of protein needed for a healthy lifestyle have recently been shown to overestimate the quantities needed, and if vegetarian select their food carefully they should be able to meet their protein needs.", "hypothesis": "Too much protein in the diet can lead to heart disease.", "gold_label": "neutral"}
{"uid": "id_730", "premise": "There is no doubt that vegetarian food can be healthier than a traditional diet indeed, research has demonstrated that vegetarians are less likely to suffer from heart disease and obesity than those who eat meat. One long-standing concern about a vegetarian lifestyle is the risk of failing to take in enough protein. However, historical calculations as to the amount of protein needed for a healthy lifestyle have recently been shown to overestimate the quantities needed, and if vegetarian select their food carefully they should be able to meet their protein needs.", "hypothesis": "Over time the recommendations as to what constitutes a healthy balanced diet have changed.", "gold_label": "neutral"}
{"uid": "id_731", "premise": "There is no single pivotal moment that could be separated out from any other as the conception of the suburban lifestyle; from the early 1800s, various types of suburban development have sprung up and evolved in their own localised ways, from the streetcar suburbs of New York to the dormitory towns outside of London. It is William Levitt, however, who is generally regarded as the father of modem suburbia. During World War II, Levitt served in the United States Navy where he developed expertise in the mass construction of military housing, a process that he streamlined using uniform and interchangeable parts. In 1947, the budding developer used this utilitarian knowledge to begin work with his father and architect brother constructing a planned community on Long Island, New York. With an emphasis on speed, efficiency, and cost-effective production, the Levitts were soon able to produce over 30 units a day. William Levitt correctly predicted the demand for affordable, private, quiet, and comfortable homes from returning GIs after World War II and with the baby boom starting to kick in. All the original lots sold out in a matter of days, and by 1951, nearly 18,000 homes in the area had been constructed by the Levitt fit Sons Company. Levittown quickly became the prototype of mass- produced housing, spurring the construction of similar projects in Pennsylvania, New Jersey, and even Puerto Rico, followed by a new industry, and soon a new way of life and a new ideal for the American family. One of the major criticisms of suburbia is that it can lead to isolation and social dislocation. With properties spread out over great swathes of land, sealed off from one another by bushes, fences and trees, the emphasis of suburban life is placed squarely on privacy rather than community. In the densely populated urban settlements that predated suburbs (and that are still the predominant way of life for some people), activities such as childcare and household chores as well as sources of emotional and moral support were widely socialised. This insured that any one family would be able to draw on a pool of social resources from their neighbours, building cohabitants and family on nearby streets. Suburbia breaks these networks down into individual and nuclear family units resulting in an increase in anti-social behaviour even amongst the wealthy. Teens from wealthy suburban families, for example, are more likely to smoke, drink alcohol, and use drugs than their poorer urban peers, and are also more likely to experience depression and anxiety. Another major problem with the suburban lifestyle is its damaging ecological impact. The comparison of leafy, quiet, and low-density suburbs with life in the concrete towers of sooty, congested urban conurbations is actually quite misleading; as it turns out, if you want to be kind to the natural environment, the key is to stay away from it. Suburbia fails the environmental friendliness test on a number of counts. Firstly, due to their low population density, suburbs consume natural land at a much higher rate than high-density row housing or apartment buildings. Secondly, they encourage the use of personal motor vehicles, often at a rate of one per family member, at the expense of public transport. It is also much less efficient to provide electricity and water to individual suburban houses instead of individual units in an apartment building. In his comparison of urban and suburban pollution, Edward L. Glaeser concluded that we need to build more sky towers especially in California. Virtually everywhere, he found cities to be cleaner than suburbs. And the difference in carbon dioxide emissions between high-density cities and their suburbs (for example, in New York) was the highest. Urban residents of New York can claim on average to produce nearly 15,000 pounds of carbon dioxide less than their suburban peers. Another negative aspect of suburban life is its stifling conformity and monotony of social experience. It was not just the nuts and bolts and the concrete foundations of suburban houses that got replicated street upon street, block upon block, and suburb upon suburb; it was everything from the shops and cultural life to peoples hopes, dreams, and aspirations. Suburbia gave birth to the strip mall, a retail establishment that is typically composed of a collection of national or global chain stores, all stocked with a centrally dictated, homogenous array of products. The isolation and lack of interaction in suburbs has also encouraged the popularity of television, a passively receptive medium for the viewer that, in the early days at least, offered an extremely limited scope of cultural exposure compared with the wealth of experiences available in the inner city. Meanwhile, much of the inner-city public sphere has been lost with suburban flight. The public sphere is the area of social life in which people come together to freely discuss and identify social problems. In the city, this has traditionally occurred around newsstands, in coffee houses, salons, theatres, meeting halls, and so on. Suburbia has not found a way to replace this special type of social experience, however. Social meeting points in the suburbs tend to be based exclusively around specific interests such as sports or cultural clubs, with no broad forms of daily social interaction. These points do not suggest the idea of suburbia itself is flawed, but that it has not been executed in a way that takes into account the full spectrum of human needs and desires. This likely reflects the hasty, thrown-together nature of early suburban development. With the baby boom rippling across Western countries and demand for family-friendly housing skyrocketing, developers and city planners were unable to develop sophisticated models. Now, however, we should take time to consider what has gone wrong and how we can reconfigure the suburb. How can we imbue suburban life with the lost sphere of public discussion and debate? How can people maintain their sought after privacy without sacrificing a sense of community? How can we use new technologies to make suburbs environmentally friendly? These are questions for which the developers of tomorrow will have to find answers, lest the dream of suburbia become the nightmare of disturbia.", "hypothesis": "Television has not tended to offer the same diversity as urban cultural outlets.", "gold_label": "entailment"}
{"uid": "id_732", "premise": "There is no single pivotal moment that could be separated out from any other as the conception of the suburban lifestyle; from the early 1800s, various types of suburban development have sprung up and evolved in their own localised ways, from the streetcar suburbs of New York to the dormitory towns outside of London. It is William Levitt, however, who is generally regarded as the father of modem suburbia. During World War II, Levitt served in the United States Navy where he developed expertise in the mass construction of military housing, a process that he streamlined using uniform and interchangeable parts. In 1947, the budding developer used this utilitarian knowledge to begin work with his father and architect brother constructing a planned community on Long Island, New York. With an emphasis on speed, efficiency, and cost-effective production, the Levitts were soon able to produce over 30 units a day. William Levitt correctly predicted the demand for affordable, private, quiet, and comfortable homes from returning GIs after World War II and with the baby boom starting to kick in. All the original lots sold out in a matter of days, and by 1951, nearly 18,000 homes in the area had been constructed by the Levitt fit Sons Company. Levittown quickly became the prototype of mass- produced housing, spurring the construction of similar projects in Pennsylvania, New Jersey, and even Puerto Rico, followed by a new industry, and soon a new way of life and a new ideal for the American family. One of the major criticisms of suburbia is that it can lead to isolation and social dislocation. With properties spread out over great swathes of land, sealed off from one another by bushes, fences and trees, the emphasis of suburban life is placed squarely on privacy rather than community. In the densely populated urban settlements that predated suburbs (and that are still the predominant way of life for some people), activities such as childcare and household chores as well as sources of emotional and moral support were widely socialised. This insured that any one family would be able to draw on a pool of social resources from their neighbours, building cohabitants and family on nearby streets. Suburbia breaks these networks down into individual and nuclear family units resulting in an increase in anti-social behaviour even amongst the wealthy. Teens from wealthy suburban families, for example, are more likely to smoke, drink alcohol, and use drugs than their poorer urban peers, and are also more likely to experience depression and anxiety. Another major problem with the suburban lifestyle is its damaging ecological impact. The comparison of leafy, quiet, and low-density suburbs with life in the concrete towers of sooty, congested urban conurbations is actually quite misleading; as it turns out, if you want to be kind to the natural environment, the key is to stay away from it. Suburbia fails the environmental friendliness test on a number of counts. Firstly, due to their low population density, suburbs consume natural land at a much higher rate than high-density row housing or apartment buildings. Secondly, they encourage the use of personal motor vehicles, often at a rate of one per family member, at the expense of public transport. It is also much less efficient to provide electricity and water to individual suburban houses instead of individual units in an apartment building. In his comparison of urban and suburban pollution, Edward L. Glaeser concluded that we need to build more sky towers especially in California. Virtually everywhere, he found cities to be cleaner than suburbs. And the difference in carbon dioxide emissions between high-density cities and their suburbs (for example, in New York) was the highest. Urban residents of New York can claim on average to produce nearly 15,000 pounds of carbon dioxide less than their suburban peers. Another negative aspect of suburban life is its stifling conformity and monotony of social experience. It was not just the nuts and bolts and the concrete foundations of suburban houses that got replicated street upon street, block upon block, and suburb upon suburb; it was everything from the shops and cultural life to peoples hopes, dreams, and aspirations. Suburbia gave birth to the strip mall, a retail establishment that is typically composed of a collection of national or global chain stores, all stocked with a centrally dictated, homogenous array of products. The isolation and lack of interaction in suburbs has also encouraged the popularity of television, a passively receptive medium for the viewer that, in the early days at least, offered an extremely limited scope of cultural exposure compared with the wealth of experiences available in the inner city. Meanwhile, much of the inner-city public sphere has been lost with suburban flight. The public sphere is the area of social life in which people come together to freely discuss and identify social problems. In the city, this has traditionally occurred around newsstands, in coffee houses, salons, theatres, meeting halls, and so on. Suburbia has not found a way to replace this special type of social experience, however. Social meeting points in the suburbs tend to be based exclusively around specific interests such as sports or cultural clubs, with no broad forms of daily social interaction. These points do not suggest the idea of suburbia itself is flawed, but that it has not been executed in a way that takes into account the full spectrum of human needs and desires. This likely reflects the hasty, thrown-together nature of early suburban development. With the baby boom rippling across Western countries and demand for family-friendly housing skyrocketing, developers and city planners were unable to develop sophisticated models. Now, however, we should take time to consider what has gone wrong and how we can reconfigure the suburb. How can we imbue suburban life with the lost sphere of public discussion and debate? How can people maintain their sought after privacy without sacrificing a sense of community? How can we use new technologies to make suburbs environmentally friendly? These are questions for which the developers of tomorrow will have to find answers, lest the dream of suburbia become the nightmare of disturbia.", "hypothesis": "There is not much variety amongst the goods at a strip mall.", "gold_label": "entailment"}
{"uid": "id_733", "premise": "There is no single pivotal moment that could be separated out from any other as the conception of the suburban lifestyle; from the early 1800s, various types of suburban development have sprung up and evolved in their own localised ways, from the streetcar suburbs of New York to the dormitory towns outside of London. It is William Levitt, however, who is generally regarded as the father of modem suburbia. During World War II, Levitt served in the United States Navy where he developed expertise in the mass construction of military housing, a process that he streamlined using uniform and interchangeable parts. In 1947, the budding developer used this utilitarian knowledge to begin work with his father and architect brother constructing a planned community on Long Island, New York. With an emphasis on speed, efficiency, and cost-effective production, the Levitts were soon able to produce over 30 units a day. William Levitt correctly predicted the demand for affordable, private, quiet, and comfortable homes from returning GIs after World War II and with the baby boom starting to kick in. All the original lots sold out in a matter of days, and by 1951, nearly 18,000 homes in the area had been constructed by the Levitt fit Sons Company. Levittown quickly became the prototype of mass- produced housing, spurring the construction of similar projects in Pennsylvania, New Jersey, and even Puerto Rico, followed by a new industry, and soon a new way of life and a new ideal for the American family. One of the major criticisms of suburbia is that it can lead to isolation and social dislocation. With properties spread out over great swathes of land, sealed off from one another by bushes, fences and trees, the emphasis of suburban life is placed squarely on privacy rather than community. In the densely populated urban settlements that predated suburbs (and that are still the predominant way of life for some people), activities such as childcare and household chores as well as sources of emotional and moral support were widely socialised. This insured that any one family would be able to draw on a pool of social resources from their neighbours, building cohabitants and family on nearby streets. Suburbia breaks these networks down into individual and nuclear family units resulting in an increase in anti-social behaviour even amongst the wealthy. Teens from wealthy suburban families, for example, are more likely to smoke, drink alcohol, and use drugs than their poorer urban peers, and are also more likely to experience depression and anxiety. Another major problem with the suburban lifestyle is its damaging ecological impact. The comparison of leafy, quiet, and low-density suburbs with life in the concrete towers of sooty, congested urban conurbations is actually quite misleading; as it turns out, if you want to be kind to the natural environment, the key is to stay away from it. Suburbia fails the environmental friendliness test on a number of counts. Firstly, due to their low population density, suburbs consume natural land at a much higher rate than high-density row housing or apartment buildings. Secondly, they encourage the use of personal motor vehicles, often at a rate of one per family member, at the expense of public transport. It is also much less efficient to provide electricity and water to individual suburban houses instead of individual units in an apartment building. In his comparison of urban and suburban pollution, Edward L. Glaeser concluded that we need to build more sky towers especially in California. Virtually everywhere, he found cities to be cleaner than suburbs. And the difference in carbon dioxide emissions between high-density cities and their suburbs (for example, in New York) was the highest. Urban residents of New York can claim on average to produce nearly 15,000 pounds of carbon dioxide less than their suburban peers. Another negative aspect of suburban life is its stifling conformity and monotony of social experience. It was not just the nuts and bolts and the concrete foundations of suburban houses that got replicated street upon street, block upon block, and suburb upon suburb; it was everything from the shops and cultural life to peoples hopes, dreams, and aspirations. Suburbia gave birth to the strip mall, a retail establishment that is typically composed of a collection of national or global chain stores, all stocked with a centrally dictated, homogenous array of products. The isolation and lack of interaction in suburbs has also encouraged the popularity of television, a passively receptive medium for the viewer that, in the early days at least, offered an extremely limited scope of cultural exposure compared with the wealth of experiences available in the inner city. Meanwhile, much of the inner-city public sphere has been lost with suburban flight. The public sphere is the area of social life in which people come together to freely discuss and identify social problems. In the city, this has traditionally occurred around newsstands, in coffee houses, salons, theatres, meeting halls, and so on. Suburbia has not found a way to replace this special type of social experience, however. Social meeting points in the suburbs tend to be based exclusively around specific interests such as sports or cultural clubs, with no broad forms of daily social interaction. These points do not suggest the idea of suburbia itself is flawed, but that it has not been executed in a way that takes into account the full spectrum of human needs and desires. This likely reflects the hasty, thrown-together nature of early suburban development. With the baby boom rippling across Western countries and demand for family-friendly housing skyrocketing, developers and city planners were unable to develop sophisticated models. Now, however, we should take time to consider what has gone wrong and how we can reconfigure the suburb. How can we imbue suburban life with the lost sphere of public discussion and debate? How can people maintain their sought after privacy without sacrificing a sense of community? How can we use new technologies to make suburbs environmentally friendly? These are questions for which the developers of tomorrow will have to find answers, lest the dream of suburbia become the nightmare of disturbia.", "hypothesis": "People cannot relate to each other in suburbs because their lives are too different.", "gold_label": "contradiction"}
{"uid": "id_734", "premise": "There is no single pivotal moment that could be separated out from any other as the conception of the suburban lifestyle; from the early 1800s, various types of suburban development have sprung up and evolved in their own localised ways, from the streetcar suburbs of New York to the dormitory towns outside of London. It is William Levitt, however, who is generally regarded as the father of modem suburbia. During World War II, Levitt served in the United States Navy where he developed expertise in the mass construction of military housing, a process that he streamlined using uniform and interchangeable parts. In 1947, the budding developer used this utilitarian knowledge to begin work with his father and architect brother constructing a planned community on Long Island, New York. With an emphasis on speed, efficiency, and cost-effective production, the Levitts were soon able to produce over 30 units a day. William Levitt correctly predicted the demand for affordable, private, quiet, and comfortable homes from returning GIs after World War II and with the baby boom starting to kick in. All the original lots sold out in a matter of days, and by 1951, nearly 18,000 homes in the area had been constructed by the Levitt fit Sons Company. Levittown quickly became the prototype of mass- produced housing, spurring the construction of similar projects in Pennsylvania, New Jersey, and even Puerto Rico, followed by a new industry, and soon a new way of life and a new ideal for the American family. One of the major criticisms of suburbia is that it can lead to isolation and social dislocation. With properties spread out over great swathes of land, sealed off from one another by bushes, fences and trees, the emphasis of suburban life is placed squarely on privacy rather than community. In the densely populated urban settlements that predated suburbs (and that are still the predominant way of life for some people), activities such as childcare and household chores as well as sources of emotional and moral support were widely socialised. This insured that any one family would be able to draw on a pool of social resources from their neighbours, building cohabitants and family on nearby streets. Suburbia breaks these networks down into individual and nuclear family units resulting in an increase in anti-social behaviour even amongst the wealthy. Teens from wealthy suburban families, for example, are more likely to smoke, drink alcohol, and use drugs than their poorer urban peers, and are also more likely to experience depression and anxiety. Another major problem with the suburban lifestyle is its damaging ecological impact. The comparison of leafy, quiet, and low-density suburbs with life in the concrete towers of sooty, congested urban conurbations is actually quite misleading; as it turns out, if you want to be kind to the natural environment, the key is to stay away from it. Suburbia fails the environmental friendliness test on a number of counts. Firstly, due to their low population density, suburbs consume natural land at a much higher rate than high-density row housing or apartment buildings. Secondly, they encourage the use of personal motor vehicles, often at a rate of one per family member, at the expense of public transport. It is also much less efficient to provide electricity and water to individual suburban houses instead of individual units in an apartment building. In his comparison of urban and suburban pollution, Edward L. Glaeser concluded that we need to build more sky towers especially in California. Virtually everywhere, he found cities to be cleaner than suburbs. And the difference in carbon dioxide emissions between high-density cities and their suburbs (for example, in New York) was the highest. Urban residents of New York can claim on average to produce nearly 15,000 pounds of carbon dioxide less than their suburban peers. Another negative aspect of suburban life is its stifling conformity and monotony of social experience. It was not just the nuts and bolts and the concrete foundations of suburban houses that got replicated street upon street, block upon block, and suburb upon suburb; it was everything from the shops and cultural life to peoples hopes, dreams, and aspirations. Suburbia gave birth to the strip mall, a retail establishment that is typically composed of a collection of national or global chain stores, all stocked with a centrally dictated, homogenous array of products. The isolation and lack of interaction in suburbs has also encouraged the popularity of television, a passively receptive medium for the viewer that, in the early days at least, offered an extremely limited scope of cultural exposure compared with the wealth of experiences available in the inner city. Meanwhile, much of the inner-city public sphere has been lost with suburban flight. The public sphere is the area of social life in which people come together to freely discuss and identify social problems. In the city, this has traditionally occurred around newsstands, in coffee houses, salons, theatres, meeting halls, and so on. Suburbia has not found a way to replace this special type of social experience, however. Social meeting points in the suburbs tend to be based exclusively around specific interests such as sports or cultural clubs, with no broad forms of daily social interaction. These points do not suggest the idea of suburbia itself is flawed, but that it has not been executed in a way that takes into account the full spectrum of human needs and desires. This likely reflects the hasty, thrown-together nature of early suburban development. With the baby boom rippling across Western countries and demand for family-friendly housing skyrocketing, developers and city planners were unable to develop sophisticated models. Now, however, we should take time to consider what has gone wrong and how we can reconfigure the suburb. How can we imbue suburban life with the lost sphere of public discussion and debate? How can people maintain their sought after privacy without sacrificing a sense of community? How can we use new technologies to make suburbs environmentally friendly? These are questions for which the developers of tomorrow will have to find answers, lest the dream of suburbia become the nightmare of disturbia.", "hypothesis": "Suburban development fosters the use of both public and private forms of transport", "gold_label": "contradiction"}
{"uid": "id_735", "premise": "There is no single pivotal moment that could be separated out from any other as the conception of the suburban lifestyle; from the early 1800s, various types of suburban development have sprung up and evolved in their own localised ways, from the streetcar suburbs of New York to the dormitory towns outside of London. It is William Levitt, however, who is generally regarded as the father of modem suburbia. During World War II, Levitt served in the United States Navy where he developed expertise in the mass construction of military housing, a process that he streamlined using uniform and interchangeable parts. In 1947, the budding developer used this utilitarian knowledge to begin work with his father and architect brother constructing a planned community on Long Island, New York. With an emphasis on speed, efficiency, and cost-effective production, the Levitts were soon able to produce over 30 units a day. William Levitt correctly predicted the demand for affordable, private, quiet, and comfortable homes from returning GIs after World War II and with the baby boom starting to kick in. All the original lots sold out in a matter of days, and by 1951, nearly 18,000 homes in the area had been constructed by the Levitt fit Sons Company. Levittown quickly became the prototype of mass- produced housing, spurring the construction of similar projects in Pennsylvania, New Jersey, and even Puerto Rico, followed by a new industry, and soon a new way of life and a new ideal for the American family. One of the major criticisms of suburbia is that it can lead to isolation and social dislocation. With properties spread out over great swathes of land, sealed off from one another by bushes, fences and trees, the emphasis of suburban life is placed squarely on privacy rather than community. In the densely populated urban settlements that predated suburbs (and that are still the predominant way of life for some people), activities such as childcare and household chores as well as sources of emotional and moral support were widely socialised. This insured that any one family would be able to draw on a pool of social resources from their neighbours, building cohabitants and family on nearby streets. Suburbia breaks these networks down into individual and nuclear family units resulting in an increase in anti-social behaviour even amongst the wealthy. Teens from wealthy suburban families, for example, are more likely to smoke, drink alcohol, and use drugs than their poorer urban peers, and are also more likely to experience depression and anxiety. Another major problem with the suburban lifestyle is its damaging ecological impact. The comparison of leafy, quiet, and low-density suburbs with life in the concrete towers of sooty, congested urban conurbations is actually quite misleading; as it turns out, if you want to be kind to the natural environment, the key is to stay away from it. Suburbia fails the environmental friendliness test on a number of counts. Firstly, due to their low population density, suburbs consume natural land at a much higher rate than high-density row housing or apartment buildings. Secondly, they encourage the use of personal motor vehicles, often at a rate of one per family member, at the expense of public transport. It is also much less efficient to provide electricity and water to individual suburban houses instead of individual units in an apartment building. In his comparison of urban and suburban pollution, Edward L. Glaeser concluded that we need to build more sky towers especially in California. Virtually everywhere, he found cities to be cleaner than suburbs. And the difference in carbon dioxide emissions between high-density cities and their suburbs (for example, in New York) was the highest. Urban residents of New York can claim on average to produce nearly 15,000 pounds of carbon dioxide less than their suburban peers. Another negative aspect of suburban life is its stifling conformity and monotony of social experience. It was not just the nuts and bolts and the concrete foundations of suburban houses that got replicated street upon street, block upon block, and suburb upon suburb; it was everything from the shops and cultural life to peoples hopes, dreams, and aspirations. Suburbia gave birth to the strip mall, a retail establishment that is typically composed of a collection of national or global chain stores, all stocked with a centrally dictated, homogenous array of products. The isolation and lack of interaction in suburbs has also encouraged the popularity of television, a passively receptive medium for the viewer that, in the early days at least, offered an extremely limited scope of cultural exposure compared with the wealth of experiences available in the inner city. Meanwhile, much of the inner-city public sphere has been lost with suburban flight. The public sphere is the area of social life in which people come together to freely discuss and identify social problems. In the city, this has traditionally occurred around newsstands, in coffee houses, salons, theatres, meeting halls, and so on. Suburbia has not found a way to replace this special type of social experience, however. Social meeting points in the suburbs tend to be based exclusively around specific interests such as sports or cultural clubs, with no broad forms of daily social interaction. These points do not suggest the idea of suburbia itself is flawed, but that it has not been executed in a way that takes into account the full spectrum of human needs and desires. This likely reflects the hasty, thrown-together nature of early suburban development. With the baby boom rippling across Western countries and demand for family-friendly housing skyrocketing, developers and city planners were unable to develop sophisticated models. Now, however, we should take time to consider what has gone wrong and how we can reconfigure the suburb. How can we imbue suburban life with the lost sphere of public discussion and debate? How can people maintain their sought after privacy without sacrificing a sense of community? How can we use new technologies to make suburbs environmentally friendly? These are questions for which the developers of tomorrow will have to find answers, lest the dream of suburbia become the nightmare of disturbia.", "hypothesis": "A good principle for ecological preservation is to avoid human interference.", "gold_label": "entailment"}
{"uid": "id_736", "premise": "There is no single pivotal moment that could be separated out from any other as the conception of the suburban lifestyle; from the early 1800s, various types of suburban development have sprung up and evolved in their own localised ways, from the streetcar suburbs of New York to the dormitory towns outside of London. It is William Levitt, however, who is generally regarded as the father of modem suburbia. During World War II, Levitt served in the United States Navy where he developed expertise in the mass construction of military housing, a process that he streamlined using uniform and interchangeable parts. In 1947, the budding developer used this utilitarian knowledge to begin work with his father and architect brother constructing a planned community on Long Island, New York. With an emphasis on speed, efficiency, and cost-effective production, the Levitts were soon able to produce over 30 units a day. William Levitt correctly predicted the demand for affordable, private, quiet, and comfortable homes from returning GIs after World War II and with the baby boom starting to kick in. All the original lots sold out in a matter of days, and by 1951, nearly 18,000 homes in the area had been constructed by the Levitt fit Sons Company. Levittown quickly became the prototype of mass- produced housing, spurring the construction of similar projects in Pennsylvania, New Jersey, and even Puerto Rico, followed by a new industry, and soon a new way of life and a new ideal for the American family. One of the major criticisms of suburbia is that it can lead to isolation and social dislocation. With properties spread out over great swathes of land, sealed off from one another by bushes, fences and trees, the emphasis of suburban life is placed squarely on privacy rather than community. In the densely populated urban settlements that predated suburbs (and that are still the predominant way of life for some people), activities such as childcare and household chores as well as sources of emotional and moral support were widely socialised. This insured that any one family would be able to draw on a pool of social resources from their neighbours, building cohabitants and family on nearby streets. Suburbia breaks these networks down into individual and nuclear family units resulting in an increase in anti-social behaviour even amongst the wealthy. Teens from wealthy suburban families, for example, are more likely to smoke, drink alcohol, and use drugs than their poorer urban peers, and are also more likely to experience depression and anxiety. Another major problem with the suburban lifestyle is its damaging ecological impact. The comparison of leafy, quiet, and low-density suburbs with life in the concrete towers of sooty, congested urban conurbations is actually quite misleading; as it turns out, if you want to be kind to the natural environment, the key is to stay away from it. Suburbia fails the environmental friendliness test on a number of counts. Firstly, due to their low population density, suburbs consume natural land at a much higher rate than high-density row housing or apartment buildings. Secondly, they encourage the use of personal motor vehicles, often at a rate of one per family member, at the expense of public transport. It is also much less efficient to provide electricity and water to individual suburban houses instead of individual units in an apartment building. In his comparison of urban and suburban pollution, Edward L. Glaeser concluded that we need to build more sky towers especially in California. Virtually everywhere, he found cities to be cleaner than suburbs. And the difference in carbon dioxide emissions between high-density cities and their suburbs (for example, in New York) was the highest. Urban residents of New York can claim on average to produce nearly 15,000 pounds of carbon dioxide less than their suburban peers. Another negative aspect of suburban life is its stifling conformity and monotony of social experience. It was not just the nuts and bolts and the concrete foundations of suburban houses that got replicated street upon street, block upon block, and suburb upon suburb; it was everything from the shops and cultural life to peoples hopes, dreams, and aspirations. Suburbia gave birth to the strip mall, a retail establishment that is typically composed of a collection of national or global chain stores, all stocked with a centrally dictated, homogenous array of products. The isolation and lack of interaction in suburbs has also encouraged the popularity of television, a passively receptive medium for the viewer that, in the early days at least, offered an extremely limited scope of cultural exposure compared with the wealth of experiences available in the inner city. Meanwhile, much of the inner-city public sphere has been lost with suburban flight. The public sphere is the area of social life in which people come together to freely discuss and identify social problems. In the city, this has traditionally occurred around newsstands, in coffee houses, salons, theatres, meeting halls, and so on. Suburbia has not found a way to replace this special type of social experience, however. Social meeting points in the suburbs tend to be based exclusively around specific interests such as sports or cultural clubs, with no broad forms of daily social interaction. These points do not suggest the idea of suburbia itself is flawed, but that it has not been executed in a way that takes into account the full spectrum of human needs and desires. This likely reflects the hasty, thrown-together nature of early suburban development. With the baby boom rippling across Western countries and demand for family-friendly housing skyrocketing, developers and city planners were unable to develop sophisticated models. Now, however, we should take time to consider what has gone wrong and how we can reconfigure the suburb. How can we imbue suburban life with the lost sphere of public discussion and debate? How can people maintain their sought after privacy without sacrificing a sense of community? How can we use new technologies to make suburbs environmentally friendly? These are questions for which the developers of tomorrow will have to find answers, lest the dream of suburbia become the nightmare of disturbia.", "hypothesis": "In some countries, suburbs are more environmentally friendly than in the USA.", "gold_label": "neutral"}
{"uid": "id_737", "premise": "There is no single pivotal moment that could be separated out from any other as the conception of the suburban lifestyle; from the early 1800s, various types of suburban development have sprung up and evolved in their own localised ways, from the streetcar suburbs of New York to the dormitory towns outside of London. It is William Levitt, however, who is generally regarded as the father of modem suburbia. During World War II, Levitt served in the United States Navy where he developed expertise in the mass construction of military housing, a process that he streamlined using uniform and interchangeable parts. In 1947, the budding developer used this utilitarian knowledge to begin work with his father and architect brother constructing a planned community on Long Island, New York. With an emphasis on speed, efficiency, and cost-effective production, the Levitts were soon able to produce over 30 units a day. William Levitt correctly predicted the demand for affordable, private, quiet, and comfortable homes from returning GIs after World War II and with the baby boom starting to kick in. All the original lots sold out in a matter of days, and by 1951, nearly 18,000 homes in the area had been constructed by the Levitt fit Sons Company. Levittown quickly became the prototype of mass- produced housing, spurring the construction of similar projects in Pennsylvania, New Jersey, and even Puerto Rico, followed by a new industry, and soon a new way of life and a new ideal for the American family. One of the major criticisms of suburbia is that it can lead to isolation and social dislocation. With properties spread out over great swathes of land, sealed off from one another by bushes, fences and trees, the emphasis of suburban life is placed squarely on privacy rather than community. In the densely populated urban settlements that predated suburbs (and that are still the predominant way of life for some people), activities such as childcare and household chores as well as sources of emotional and moral support were widely socialised. This insured that any one family would be able to draw on a pool of social resources from their neighbours, building cohabitants and family on nearby streets. Suburbia breaks these networks down into individual and nuclear family units resulting in an increase in anti-social behaviour even amongst the wealthy. Teens from wealthy suburban families, for example, are more likely to smoke, drink alcohol, and use drugs than their poorer urban peers, and are also more likely to experience depression and anxiety. Another major problem with the suburban lifestyle is its damaging ecological impact. The comparison of leafy, quiet, and low-density suburbs with life in the concrete towers of sooty, congested urban conurbations is actually quite misleading; as it turns out, if you want to be kind to the natural environment, the key is to stay away from it. Suburbia fails the environmental friendliness test on a number of counts. Firstly, due to their low population density, suburbs consume natural land at a much higher rate than high-density row housing or apartment buildings. Secondly, they encourage the use of personal motor vehicles, often at a rate of one per family member, at the expense of public transport. It is also much less efficient to provide electricity and water to individual suburban houses instead of individual units in an apartment building. In his comparison of urban and suburban pollution, Edward L. Glaeser concluded that we need to build more sky towers especially in California. Virtually everywhere, he found cities to be cleaner than suburbs. And the difference in carbon dioxide emissions between high-density cities and their suburbs (for example, in New York) was the highest. Urban residents of New York can claim on average to produce nearly 15,000 pounds of carbon dioxide less than their suburban peers. Another negative aspect of suburban life is its stifling conformity and monotony of social experience. It was not just the nuts and bolts and the concrete foundations of suburban houses that got replicated street upon street, block upon block, and suburb upon suburb; it was everything from the shops and cultural life to peoples hopes, dreams, and aspirations. Suburbia gave birth to the strip mall, a retail establishment that is typically composed of a collection of national or global chain stores, all stocked with a centrally dictated, homogenous array of products. The isolation and lack of interaction in suburbs has also encouraged the popularity of television, a passively receptive medium for the viewer that, in the early days at least, offered an extremely limited scope of cultural exposure compared with the wealth of experiences available in the inner city. Meanwhile, much of the inner-city public sphere has been lost with suburban flight. The public sphere is the area of social life in which people come together to freely discuss and identify social problems. In the city, this has traditionally occurred around newsstands, in coffee houses, salons, theatres, meeting halls, and so on. Suburbia has not found a way to replace this special type of social experience, however. Social meeting points in the suburbs tend to be based exclusively around specific interests such as sports or cultural clubs, with no broad forms of daily social interaction. These points do not suggest the idea of suburbia itself is flawed, but that it has not been executed in a way that takes into account the full spectrum of human needs and desires. This likely reflects the hasty, thrown-together nature of early suburban development. With the baby boom rippling across Western countries and demand for family-friendly housing skyrocketing, developers and city planners were unable to develop sophisticated models. Now, however, we should take time to consider what has gone wrong and how we can reconfigure the suburb. How can we imbue suburban life with the lost sphere of public discussion and debate? How can people maintain their sought after privacy without sacrificing a sense of community? How can we use new technologies to make suburbs environmentally friendly? These are questions for which the developers of tomorrow will have to find answers, lest the dream of suburbia become the nightmare of disturbia.", "hypothesis": "There are numerous of ways of communication and interaction between people living in the suburbs.", "gold_label": "contradiction"}
{"uid": "id_738", "premise": "There is no task more difficult than that of ensuring the education of children in modern . Not only school, but also teachers and their roles have changed out of all recognition in the past few decades, thanks to the impact on teaching institutions by indoctrinating, and indoctrinated, reformist intellectuals bearing revolutionary ideas. To the perpetual indiscipline of youth has now been added the indiscipline of parents, many of whom interpret any reports of wrongdoing in school on the part of their offspring as a personal affront, or as the manifestation of the malice of teachers. As for the teachers themselves, whilst many are respectable and learned men and women, who view it as their vocation to induct their charges into a civilization and a way of behaving, others attempt to influence youth merely to further their political or ideological ends.", "hypothesis": "Some teachers who report children of wrongdoing do so because of malice, rather than nay legitimate reason.", "gold_label": "neutral"}
{"uid": "id_739", "premise": "There is no task more difficult than that of ensuring the education of children in modern . Not only school, but also teachers and their roles have changed out of all recognition in the past few decades, thanks to the impact on teaching institutions by indoctrinating, and indoctrinated, reformist intellectuals bearing revolutionary ideas. To the perpetual indiscipline of youth has now been added the indiscipline of parents, many of whom interpret any reports of wrongdoing in school on the part of their offspring as a personal affront, or as the manifestation of the malice of teachers. As for the teachers themselves, whilst many are respectable and learned men and women, who view it as their vocation to induct their charges into a civilization and a way of behaving, others attempt to influence youth merely to further their political or ideological ends.", "hypothesis": "Teacher with revolutionary ideas will attempt to influence their pupils for their own political ends.", "gold_label": "neutral"}
{"uid": "id_740", "premise": "There is no task more difficult than that of ensuring the education of children in modern . Not only school, but also teachers and their roles have changed out of all recognition in the past few decades, thanks to the impact on teaching institutions by indoctrinating, and indoctrinated, reformist intellectuals bearing revolutionary ideas. To the perpetual indiscipline of youth has now been added the indiscipline of parents, many of whom interpret any reports of wrongdoing in school on the part of their offspring as a personal affront, or as the manifestation of the malice of teachers. As for the teachers themselves, whilst many are respectable and learned men and women, who view it as their vocation to induct their charges into a civilization and a way of behaving, others attempt to influence youth merely to further their political or ideological ends.", "hypothesis": "Some of those working in education have their own hidden agendas.", "gold_label": "entailment"}
{"uid": "id_741", "premise": "There is no task more difficult than that of ensuring the education of children in modern society. Not only school, but also teachers and their roles have changed out of all recognition in the past few decades, thanks to the impact on teaching institutions by indoctrinating, and indoctrinated, reformist intellectuals bearing revolutionary ideas. To the perpetual indiscipline of youth has now been added the indiscipline of parents, many of whom interpret any reports of wrongdoing in school on the part of their offspring as a personal affront, or as the manifestation of the malice of teachers. As for the teachers themselves, whilst many are respectable and learned men and women, who view it as their vocation to induct their charges into a civilization and a way of behaving, others attempt to influence youth merely to further their political or ideological ends.", "hypothesis": "Some of those working in education have their own hidden agendas.", "gold_label": "neutral"}
{"uid": "id_742", "premise": "There is no task more difficult than that of ensuring the education of children in modern society. Not only school, but also teachers and their roles have changed out of all recognition in the past few decades, thanks to the impact on teaching institutions by indoctrinating, and indoctrinated, reformist intellectuals bearing revolutionary ideas. To the perpetual indiscipline of youth has now been added the indiscipline of parents, many of whom interpret any reports of wrongdoing in school on the part of their offspring as a personal affront, or as the manifestation of the malice of teachers. As for the teachers themselves, whilst many are respectable and learned men and women, who view it as their vocation to induct their charges into a civilization and a way of behaving, others attempt to influence youth merely to further their political or ideological ends.", "hypothesis": "Teacher with revolutionary ideas will attempt to influence their pupils for their own political ends.", "gold_label": "neutral"}
{"uid": "id_743", "premise": "There is no task more difficult than that of ensuring the education of children in modern society. Not only school, but also teachers and their roles have changed out of all recognition in the past few decades, thanks to the impact on teaching institutions by indoctrinating, and indoctrinated, reformist intellectuals bearing revolutionary ideas. To the perpetual indiscipline of youth has now been added the indiscipline of parents, many of whom interpret any reports of wrongdoing in school on the part of their offspring as a personal affront, or as the manifestation of the malice of teachers. As for the teachers themselves, whilst many are respectable and learned men and women, who view it as their vocation to induct their charges into a civilization and a way of behaving, others attempt to influence youth merely to further their political or ideological ends.", "hypothesis": "Some teachers who report children of wrongdoing do so because of malice, rather than nay legitimate reason.", "gold_label": "neutral"}
{"uid": "id_744", "premise": "There is no unifying theory to explain the experience of dreaming. Dreaming involves an altered state of consciousness that occurs during periods of REM (rapid eye movement) sleep. One of the most unusual features of this state is that most of the body's muscles are paralysed. The most common sleeping pattern is for a period of REM sleep to be preceded by four stages of non-REM sleep, and for this to repeat itself up to five times a night. Most adults and children, if woken during REM sleep, will report that they were dreaming. Whilst the physiological stages of sleeping may be similar across adults and young children, the potential complexity of a childs dreams develops as they age alongside their imagination. Its difficult to prove that a dream is taking place only after the fact can you know that you were dreaming. There are a small number of people, however, who do know when they are experiencing what is called a lucid dream. The scanning hypothesis posits that eyes move during REM sleep in accordance with the direction of gaze of ones dream. Research, for example with lucid dreamers, has shown that eyes do point towards the action that a dreamer, having a goal- orientated dream, describes.", "hypothesis": "Eye muscles are the only muscles that are not paralysed during REM sleep.", "gold_label": "neutral"}
{"uid": "id_745", "premise": "There is no unifying theory to explain the experience of dreaming. Dreaming involves an altered state of consciousness that occurs during periods of REM (rapid eye movement) sleep. One of the most unusual features of this state is that most of the body's muscles are paralysed. The most common sleeping pattern is for a period of REM sleep to be preceded by four stages of non-REM sleep, and for this to repeat itself up to five times a night. Most adults and children, if woken during REM sleep, will report that they were dreaming. Whilst the physiological stages of sleeping may be similar across adults and young children, the potential complexity of a childs dreams develops as they age alongside their imagination. Its difficult to prove that a dream is taking place only after the fact can you know that you were dreaming. There are a small number of people, however, who do know when they are experiencing what is called a lucid dream. The scanning hypothesis posits that eyes move during REM sleep in accordance with the direction of gaze of ones dream. Research, for example with lucid dreamers, has shown that eyes do point towards the action that a dreamer, having a goal- orientated dream, describes.", "hypothesis": "REM sleep tends to be preceded by non-REM sleep.", "gold_label": "entailment"}
{"uid": "id_746", "premise": "There is no unifying theory to explain the experience of dreaming. Dreaming involves an altered state of consciousness that occurs during periods of REM (rapid eye movement) sleep. One of the most unusual features of this state is that most of the body's muscles are paralysed. The most common sleeping pattern is for a period of REM sleep to be preceded by four stages of non-REM sleep, and for this to repeat itself up to five times a night. Most adults and children, if woken during REM sleep, will report that they were dreaming. Whilst the physiological stages of sleeping may be similar across adults and young children, the potential complexity of a childs dreams develops as they age alongside their imagination. Its difficult to prove that a dream is taking place only after the fact can you know that you were dreaming. There are a small number of people, however, who do know when they are experiencing what is called a lucid dream. The scanning hypothesis posits that eyes move during REM sleep in accordance with the direction of gaze of ones dream. Research, for example with lucid dreamers, has shown that eyes do point towards the action that a dreamer, having a goal- orientated dream, describes.", "hypothesis": "A child's dreams become more sophisticated as their imagination develops.", "gold_label": "entailment"}
{"uid": "id_747", "premise": "There is no unifying theory to explain the experience of dreaming. Dreaming involves an altered state of consciousness that occurs during periods of REM (rapid eye movement) sleep. One of the most unusual features of this state is that most of the body's muscles are paralysed. The most common sleeping pattern is for a period of REM sleep to be preceded by four stages of non-REM sleep, and for this to repeat itself up to five times a night. Most adults and children, if woken during REM sleep, will report that they were dreaming. Whilst the physiological stages of sleeping may be similar across adults and young children, the potential complexity of a childs dreams develops as they age alongside their imagination. Its difficult to prove that a dream is taking place only after the fact can you know that you were dreaming. There are a small number of people, however, who do know when they are experiencing what is called a lucid dream. The scanning hypothesis posits that eyes move during REM sleep in accordance with the direction of gaze of ones dream. Research, for example with lucid dreamers, has shown that eyes do point towards the action that a dreamer, having a goal- orientated dream, describes.", "hypothesis": "The scanning hypothesis states that the direction of a lucid dreamers eye movements reveals what the dream is about.", "gold_label": "contradiction"}
{"uid": "id_748", "premise": "There is no unifying theory to explain the experience of dreaming. Dreaming involves an altered state of consciousness that occurs during periods of REM (rapid eye movement) sleep. One of the most unusual features of this state is that most of the body's muscles are paralysed. The most common sleeping pattern is for a period of REM sleep to be preceded by four stages of non-REM sleep, and for this to repeat itself up to five times a night. Most adults and children, if woken during REM sleep, will report that they were dreaming. Whilst the physiological stages of sleeping may be similar across adults and young children, the potential complexity of a childs dreams develops as they age alongside their imagination. Its difficult to prove that a dream is taking place only after the fact can you know that you were dreaming. There are a small number of people, however, who do know when they are experiencing what is called a lucid dream. The scanning hypothesis posits that eyes move during REM sleep in accordance with the direction of gaze of ones dream. Research, for example with lucid dreamers, has shown that eyes do point towards the action that a dreamer, having a goal- orientated dream, describes.", "hypothesis": "REM sleep periods always occur after four non-REM sleep periods.", "gold_label": "contradiction"}
{"uid": "id_749", "premise": "There is nothing in England today with which we can compare the life of a fully enfranchised borough of the fifteenth century. The town of those earlier days, in fact, governed itself after the fashion of a little principality. Within the bounds which the mayor and citizens defined with perpetual insistence in their formal perambulation year after year, it carried on its isolated self-dependent life. The inhabitants defended their own territory, built and maintained their walls and towers, armed their own soldiers, trained them for service and held reviews of their forces at appointed times. They elected their own rulers and officials in whatever way they chose to adopt, and distributed among officers and councillors just such powers of legislation and administration as seemed good in their eyes. They drew up formal constitutions for the government of the community, and as time brought new problems and responsibilities, more were made, re-made and revised again; their ordinances with restless and fertile ingenuity, till they had made of their constitution a various medley of fundamental doctrines and general precepts and particular rules, somewhat after the fashion of an American state of modern times. In all concerns of trade, they exercised the widest powers, and bargained and negotiated and made laws as nations do on a grander scale today. They could covenant and confederate, buy and sell, deal and traffic after their own will; they could draw up formal treaties with other boroughs, and could admit them to or shut them out from all the privileges of their commerce; they might pass laws of protection or try experiments in free trade. Often, their authority stretched out over a wide district, and surrounding villages gathered to their markets and obeyed their laws; it might even happen in the case of a staple town that their officers controlled the main foreign trade of whole provinces.", "hypothesis": "In the 15 th century, towns drew up treaties to defend each other in times of attack.", "gold_label": "entailment"}
{"uid": "id_750", "premise": "There is nothing in England today with which we can compare the life of a fully enfranchised borough of the fifteenth century. The town of those earlier days, in fact, governed itself after the fashion of a little principality. Within the bounds which the mayor and citizens defined with perpetual insistence in their formal perambulation year after year, it carried on its isolated self-dependent life. The inhabitants defended their own territory, built and maintained their walls and towers, armed their own soldiers, trained them for service and held reviews of their forces at appointed times. They elected their own rulers and officials in whatever way they chose to adopt, and distributed among officers and councillors just such powers of legislation and administration as seemed good in their eyes. They drew up formal constitutions for the government of the community, and as time brought new problems and responsibilities, more were made, re-made and revised again; their ordinances with restless and fertile ingenuity, till they had made of their constitution a various medley of fundamental doctrines and general precepts and particular rules, somewhat after the fashion of an American state of modern times. In all concerns of trade, they exercised the widest powers, and bargained and negotiated and made laws as nations do on a grander scale today. They could covenant and confederate, buy and sell, deal and traffic after their own will; they could draw up formal treaties with other boroughs, and could admit them to or shut them out from all the privileges of their commerce; they might pass laws of protection or try experiments in free trade. Often, their authority stretched out over a wide district, and surrounding villages gathered to their markets and obeyed their laws; it might even happen in the case of a staple town that their officers controlled the main foreign trade of whole provinces.", "hypothesis": "Town life in the 15 th century is more comparable to the American state of modern times than England in modern times.", "gold_label": "entailment"}
{"uid": "id_751", "premise": "There is often considerable scientific disagreement both about available reserves of natural resources and about the extent of environmental damage caused by particular pollutants. Even where the scientific evidence is incontrovertible. There may be political conflict, based on different vested interests, over the degree to which particular environmental controls should be accepted. Governments may, for example, refrain from introducing effective control if they fear these will adversely affect company profitability or jobs, even where the environmental cost of not introducing controls are considerable.", "hypothesis": "There is always scientific debate around the facts regarding the reserves of natural resources.", "gold_label": "entailment"}
{"uid": "id_752", "premise": "There is often considerable scientific disagreement both about available reserves of natural resources and about the extent of environmental damage caused by particular pollutants. Even where the scientific evidence is incontrovertible. There may be political conflict, based on different vested interests, over the degree to which particular environmental controls should be accepted. Governments may, for example, refrain from introducing effective control if they fear these will adversely affect company profitability or jobs, even where the environmental cost of not introducing controls are considerable.", "hypothesis": "Parties with a vested interest are more influenced by politics than science when deciding whether to implement environmental controls.", "gold_label": "neutral"}
{"uid": "id_753", "premise": "There is often considerable scientific disagreement both about available reserves of natural resources and about the extent of environmental damage caused by particular pollutants. Even where the scientific evidence is incontrovertible. There may be political conflict, based on different vested interests, over the degree to which particular environmental controls should be accepted. Governments may, for example, refrain from introducing effective control if they fear these will adversely affect company profitability or jobs, even where the environmental cost of not introducing controls are considerable.", "hypothesis": "Very rarely is there conflict over the degree to which particular environmental controls should be accepted.", "gold_label": "contradiction"}
{"uid": "id_754", "premise": "There was considerable concern expressed by biochemists in 2002 when news emerged that traces of Acrylamide were found in a great many food stuffs, including daily basics such as bread, breakfast cereals and potato and cheese products. Acrylamide is widely found in many processed foods but it is also created during home cooking, in fact whenever sugar, found in so many foods, is heated and browns. Blood tests showed that it was present in high concentrations in the vast majority of people in the Western world. The few animal studies that had taken place suggested that Acrylamide is a carcinogen, but little was known about the toxicological consequences of ingesting the chemical daily and at the levels found in the general population. An urgent search began to establish what risk it posed to public health and how it might be removed from or reduced in food.", "hypothesis": "It can be inferred from the passage that even at trace levels if digested Acrylamide is toxic.", "gold_label": "contradiction"}
{"uid": "id_755", "premise": "There was considerable concern expressed by biochemists in 2002 when news emerged that traces of Acrylamide were found in a great many food stuffs, including daily basics such as bread, breakfast cereals and potato and cheese products. Acrylamide is widely found in many processed foods but it is also created during home cooking, in fact whenever sugar, found in so many foods, is heated and browns. Blood tests showed that it was present in high concentrations in the vast majority of people in the Western world. The few animal studies that had taken place suggested that Acrylamide is a carcinogen, but little was known about the toxicological consequences of ingesting the chemical daily and at the levels found in the general population. An urgent search began to establish what risk it posed to public health and how it might be removed from or reduced in food.", "hypothesis": "The likelihood of a potential health risk from the ingestion of Acrylamide would increase if it were found that, unlike in previous food scares, the option of removing from the shelves all foodstuffs in which it was present was not available because it is so widespread that there would be hardly anything left.", "gold_label": "contradiction"}
{"uid": "id_756", "premise": "There was considerable concern expressed by biochemists in 2002 when news emerged that traces of Acrylamide were found in a great many food stuffs, including daily basics such as bread, breakfast cereals and potato and cheese products. Acrylamide is widely found in many processed foods but it is also created during home cooking, in fact whenever sugar, found in so many foods, is heated and browns. Blood tests showed that it was present in high concentrations in the vast majority of people in the Western world. The few animal studies that had taken place suggested that Acrylamide is a carcinogen, but little was known about the toxicological consequences of ingesting the chemical daily and at the levels found in the general population. An urgent search began to establish what risk it posed to public health and how it might be removed from or reduced in food.", "hypothesis": "The author of the passage would most likely disagree that many of the questions posed in the passage are now close to being answered.", "gold_label": "neutral"}
{"uid": "id_757", "premise": "There were six passengers in a railway carriage, all travelling to Paul and Mary's wedding. The wedding was to be held at a Registry Office at 2pm. The passengers were all married couples. The following facts are known: The groom was the twin brother of one of the passengers. The bride was the sister of Susan, another of the passengers. Peter's only brother was marrying Mary.", "hypothesis": "The groom's twin brother was Peter.", "gold_label": "entailment"}
{"uid": "id_758", "premise": "There were six passengers in a railway carriage, all travelling to Paul and Mary's wedding. The wedding was to be held at a Registry Office at 2pm. The passengers were all married couples. The following facts are known: The groom was the twin brother of one of the passengers. The bride was the sister of Susan, another of the passengers. Peter's only brother was marrying Mary.", "hypothesis": "The wedding was in the morning.", "gold_label": "contradiction"}
{"uid": "id_759", "premise": "There were six passengers in a railway carriage, all travelling to Paul and Mary's wedding. The wedding was to be held at a Registry Office at 2pm. The passengers were all married couples. The following facts are known: The groom was the twin brother of one of the passengers. The bride was the sister of Susan, another of the passengers. Peter's only brother was marrying Mary.", "hypothesis": "Susan was married to Peter.", "gold_label": "neutral"}
{"uid": "id_760", "premise": "There were six passengers in a railway carriage, all travelling to Paul and Mary's wedding. The wedding was to be held at a Registry Office at 2pm. The passengers were all married couples. The following facts are known: The groom was the twin brother of one of the passengers. The bride was the sister of Susan, another of the passengers. Peter's only brother was marrying Mary.", "hypothesis": "Both the bride and groom had relatives on the train.", "gold_label": "entailment"}
{"uid": "id_761", "premise": "They are unable to fly in the true sense but the many species of penguin are all very adept swimmers. They literally fly underwater using their wings as flippers and their feet and tails to steer as they hunt fish and squid, which form the bulk of their diet. This extraordinary family of birds feed in the cold waters of the southern oceans (they are only found in the wild in the southern hemisphere). Their bodies are highly adapted both for their aquatic life and for the cold. Their feathers are short and dense to provide insulation and a highly waterproof layer. Their bones are not hollow like most birds but solid, making them stronger and less buoyant, helping them dive deep down to their prey. Like all birds they lay eggs and most species build nests, but some that live on sheet ice in the Antarctic, where there is no nest-building material, incubate their single egg on the top of their feet.", "hypothesis": "The sentiment of the passage can be captured by the statement that penguins are an extraordinary family of birds.", "gold_label": "entailment"}
{"uid": "id_762", "premise": "They are unable to fly in the true sense but the many species of penguin are all very adept swimmers. They literally fly underwater using their wings as flippers and their feet and tails to steer as they hunt fish and squid, which form the bulk of their diet. This extraordinary family of birds feed in the cold waters of the southern oceans (they are only found in the wild in the southern hemisphere). Their bodies are highly adapted both for their aquatic life and for the cold. Their feathers are short and dense to provide insulation and a highly waterproof layer. Their bones are not hollow like most birds but solid, making them stronger and less buoyant, helping them dive deep down to their prey. Like all birds they lay eggs and most species build nests, but some that live on sheet ice in the Antarctic, where there is no nest-building material, incubate their single egg on the top of their feet.", "hypothesis": "In the passage, solid bones are described as an adaptation for the cold southern climate.", "gold_label": "contradiction"}
{"uid": "id_763", "premise": "They are unable to fly in the true sense but the many species of penguin are all very adept swimmers. They literally fly underwater using their wings as flippers and their feet and tails to steer as they hunt fish and squid, which form the bulk of their diet. This extraordinary family of birds feed in the cold waters of the southern oceans (they are only found in the wild in the southern hemisphere). Their bodies are highly adapted both for their aquatic life and for the cold. Their feathers are short and dense to provide insulation and a highly waterproof layer. Their bones are not hollow like most birds but solid, making them stronger and less buoyant, helping them dive deep down to their prey. Like all birds they lay eggs and most species build nests, but some that live on sheet ice in the Antarctic, where there is no nest-building material, incubate their single egg on the top of their feet.", "hypothesis": "The passage states that penguins lay a single egg.", "gold_label": "contradiction"}
{"uid": "id_764", "premise": "They are unable to fly in the true sense but the many species of penguin are all very adept swimmers. They literally fly underwater using their wings as flippers and their feet and tails to steer as they hunt fish and squid, which form the bulk of their diet. This extraordinary family of birds feed in the cold waters of the southern oceans (they are only found in the wild in the southern hemisphere). Their bodies are highly adapted both for their aquatic life and for the cold. Their feathers are short and dense to provide insulation and a highly waterproof layer. Their bones are not hollow like most birds but solid, making them stronger and less buoyant, helping them dive deep down to their prey. Like all birds they lay eggs and most species build nests, but some that live on sheet ice in the Antarctic, where there is no nest-building material, incubate their single egg on the top of their feet.", "hypothesis": "Penguins are not unique in being flightless birds.", "gold_label": "neutral"}
{"uid": "id_765", "premise": "They are unable to fly in the true sense but the many species of penguin are all very adept swimmers. They literally fly underwater using their wings as flippers and their feet and tails to steer as they hunt fish and squid, which form the bulk of their diet. This extraordinary family of birds feed in the cold waters of the southern oceans (they are only found in the wild in the southern hemisphere). Their bodies are highly adapted both for their aquatic life and for the cold. Their feathers are short and dense to provide insulation and a highly waterproof layer. Their bones are not hollow like most birds but solid, making them stronger and less buoyant, helping them dive deep down to their prey. Like all birds they lay eggs and most species build nests, but some that live on sheet ice in the Antarctic, where there is no nest-building material, incubate their single egg on the top of their feet.", "hypothesis": "It can be inferred from the passage that you have to go to the southern hemisphere if you wish to see penguins in the wild.", "gold_label": "entailment"}
{"uid": "id_766", "premise": "Thin-film solar power The modernist box that won this years Solar Decathlon, a contest for solar-powered houses sponsored by Americas Department of Energy, had solar panels of the conventional, crystalline sort on its roof. But the walls were covered in solar cells made with thin coatings of silicon and other materials in the place of expensive slices of crystal. Thin film, as this technology is known, is still less popular than crystalline cells and its move to the mainstream has been a year or two away for a decade. But its time may have come at last. There are many exotic ideas involving thin film, from the solar shingles recently unveiled by Dow, a big chemical company, a roofs worth costs $27,000, to experimental prototypes of power-generating clothes, roads and cars. However, most thin film comes in the form of panels that resemble crystalline ones. They are roughly half as efficient, meaning that a panel must be twice as big to generate the same amount of power, but a third cheaper, watt for watt. So in places where there is no shortage of space, they are the natural option. Thin-film cells are also more versatile, since they can be mounted on a variety of materials including flexible plastics and fabrics. Like all solar cells, they are becoming more efficient: the decathletes of Team Germany, who designed the winning house, bragged that its north facade was covered in panels that could convert even indirect sunlight into electricity. Over the past year or so, thanks to a crash in demand tied to the recession and falling subsidies in big markets, the price of crystalline panels has fallen by 30-40%, undermining thin films relative advantage. Nonetheless, thin films share of the market has continued to rise: it is now almost half, compared with just 10% in 2004. The biggest force in the industry is a firm called First Solar, based in Arizona, a sunny American state. Like that of virtually all alternative-energy firms, its share price has suffered in the recession. But it has First Solar looks likely to continue to grow. Last month it signed a memorandum of understanding with China to install two gigawatts worth of panels in Inner Mongolia-a place with plenty of space. That is enough to power 3 million homes. Installation is due to begin next year and finish in 2019. That and other projects should consume all its output for several years to come. First Solars rivals are much smaller. But technological advances may yet catapult one to the fore, says Steve Milunovich, an analyst at Bank of America Merrill Lynch. First Solar makes its cells from a chemical called cadmium telluride. But firms such as Nanosolar, which is building factories in California and Germany, believe that a combination of copper, indium, gallium and selenium known as CIGS will prove cheaper to produce on a mass scale. Researchers at the University of California, meanwhile, hold out great hopes for cells made of organic chemicals. For the moment, however, the cheapest form of solar power is none of these, but the less glamorous solar-thermal power, which involves heating water with sunlight to make steam. Utilities are also keen to use lenses to increase the amount of sunlight hitting solar panels-a technique known as concentrating solar power. They still need subsidies or a high price on carbon emissions to make investments in any sort of solar power profitable. But the gap between solar and conventional power sources is becoming, well, thinner.", "hypothesis": "First solar is not yet listed on the S&P 500", "gold_label": "contradiction"}
{"uid": "id_767", "premise": "Thin-film solar power The modernist box that won this years Solar Decathlon, a contest for solar-powered houses sponsored by Americas Department of Energy, had solar panels of the conventional, crystalline sort on its roof. But the walls were covered in solar cells made with thin coatings of silicon and other materials in the place of expensive slices of crystal. Thin film, as this technology is known, is still less popular than crystalline cells and its move to the mainstream has been a year or two away for a decade. But its time may have come at last. There are many exotic ideas involving thin film, from the solar shingles recently unveiled by Dow, a big chemical company, a roofs worth costs $27,000, to experimental prototypes of power-generating clothes, roads and cars. However, most thin film comes in the form of panels that resemble crystalline ones. They are roughly half as efficient, meaning that a panel must be twice as big to generate the same amount of power, but a third cheaper, watt for watt. So in places where there is no shortage of space, they are the natural option. Thin-film cells are also more versatile, since they can be mounted on a variety of materials including flexible plastics and fabrics. Like all solar cells, they are becoming more efficient: the decathletes of Team Germany, who designed the winning house, bragged that its north facade was covered in panels that could convert even indirect sunlight into electricity. Over the past year or so, thanks to a crash in demand tied to the recession and falling subsidies in big markets, the price of crystalline panels has fallen by 30-40%, undermining thin films relative advantage. Nonetheless, thin films share of the market has continued to rise: it is now almost half, compared with just 10% in 2004. The biggest force in the industry is a firm called First Solar, based in Arizona, a sunny American state. Like that of virtually all alternative-energy firms, its share price has suffered in the recession. But it has First Solar looks likely to continue to grow. Last month it signed a memorandum of understanding with China to install two gigawatts worth of panels in Inner Mongolia-a place with plenty of space. That is enough to power 3 million homes. Installation is due to begin next year and finish in 2019. That and other projects should consume all its output for several years to come. First Solars rivals are much smaller. But technological advances may yet catapult one to the fore, says Steve Milunovich, an analyst at Bank of America Merrill Lynch. First Solar makes its cells from a chemical called cadmium telluride. But firms such as Nanosolar, which is building factories in California and Germany, believe that a combination of copper, indium, gallium and selenium known as CIGS will prove cheaper to produce on a mass scale. Researchers at the University of California, meanwhile, hold out great hopes for cells made of organic chemicals. For the moment, however, the cheapest form of solar power is none of these, but the less glamorous solar-thermal power, which involves heating water with sunlight to make steam. Utilities are also keen to use lenses to increase the amount of sunlight hitting solar panels-a technique known as concentrating solar power. They still need subsidies or a high price on carbon emissions to make investments in any sort of solar power profitable. But the gap between solar and conventional power sources is becoming, well, thinner.", "hypothesis": "When space is not a problem, its probably better to use crystalline films.", "gold_label": "contradiction"}
{"uid": "id_768", "premise": "Thin-film solar power The modernist box that won this years Solar Decathlon, a contest for solar-powered houses sponsored by Americas Department of Energy, had solar panels of the conventional, crystalline sort on its roof. But the walls were covered in solar cells made with thin coatings of silicon and other materials in the place of expensive slices of crystal. Thin film, as this technology is known, is still less popular than crystalline cells and its move to the mainstream has been a year or two away for a decade. But its time may have come at last. There are many exotic ideas involving thin film, from the solar shingles recently unveiled by Dow, a big chemical company, a roofs worth costs $27,000, to experimental prototypes of power-generating clothes, roads and cars. However, most thin film comes in the form of panels that resemble crystalline ones. They are roughly half as efficient, meaning that a panel must be twice as big to generate the same amount of power, but a third cheaper, watt for watt. So in places where there is no shortage of space, they are the natural option. Thin-film cells are also more versatile, since they can be mounted on a variety of materials including flexible plastics and fabrics. Like all solar cells, they are becoming more efficient: the decathletes of Team Germany, who designed the winning house, bragged that its north facade was covered in panels that could convert even indirect sunlight into electricity. Over the past year or so, thanks to a crash in demand tied to the recession and falling subsidies in big markets, the price of crystalline panels has fallen by 30-40%, undermining thin films relative advantage. Nonetheless, thin films share of the market has continued to rise: it is now almost half, compared with just 10% in 2004. The biggest force in the industry is a firm called First Solar, based in Arizona, a sunny American state. Like that of virtually all alternative-energy firms, its share price has suffered in the recession. But it has First Solar looks likely to continue to grow. Last month it signed a memorandum of understanding with China to install two gigawatts worth of panels in Inner Mongolia-a place with plenty of space. That is enough to power 3 million homes. Installation is due to begin next year and finish in 2019. That and other projects should consume all its output for several years to come. First Solars rivals are much smaller. But technological advances may yet catapult one to the fore, says Steve Milunovich, an analyst at Bank of America Merrill Lynch. First Solar makes its cells from a chemical called cadmium telluride. But firms such as Nanosolar, which is building factories in California and Germany, believe that a combination of copper, indium, gallium and selenium known as CIGS will prove cheaper to produce on a mass scale. Researchers at the University of California, meanwhile, hold out great hopes for cells made of organic chemicals. For the moment, however, the cheapest form of solar power is none of these, but the less glamorous solar-thermal power, which involves heating water with sunlight to make steam. Utilities are also keen to use lenses to increase the amount of sunlight hitting solar panels-a technique known as concentrating solar power. They still need subsidies or a high price on carbon emissions to make investments in any sort of solar power profitable. But the gap between solar and conventional power sources is becoming, well, thinner.", "hypothesis": "Team Germanys house won because of its ability to turn indirect sunlight into electricity.", "gold_label": "neutral"}
{"uid": "id_769", "premise": "Thin-film solar power The modernist box that won this years Solar Decathlon, a contest for solar-powered houses sponsored by Americas Department of Energy, had solar panels of the conventional, crystalline sort on its roof. But the walls were covered in solar cells made with thin coatings of silicon and other materials in the place of expensive slices of crystal. Thin film, as this technology is known, is still less popular than crystalline cells and its move to the mainstream has been a year or two away for a decade. But its time may have come at last. There are many exotic ideas involving thin film, from the solar shingles recently unveiled by Dow, a big chemical company, a roofs worth costs $27,000, to experimental prototypes of power-generating clothes, roads and cars. However, most thin film comes in the form of panels that resemble crystalline ones. They are roughly half as efficient, meaning that a panel must be twice as big to generate the same amount of power, but a third cheaper, watt for watt. So in places where there is no shortage of space, they are the natural option. Thin-film cells are also more versatile, since they can be mounted on a variety of materials including flexible plastics and fabrics. Like all solar cells, they are becoming more efficient: the decathletes of Team Germany, who designed the winning house, bragged that its north facade was covered in panels that could convert even indirect sunlight into electricity. Over the past year or so, thanks to a crash in demand tied to the recession and falling subsidies in big markets, the price of crystalline panels has fallen by 30-40%, undermining thin films relative advantage. Nonetheless, thin films share of the market has continued to rise: it is now almost half, compared with just 10% in 2004. The biggest force in the industry is a firm called First Solar, based in Arizona, a sunny American state. Like that of virtually all alternative-energy firms, its share price has suffered in the recession. But it has First Solar looks likely to continue to grow. Last month it signed a memorandum of understanding with China to install two gigawatts worth of panels in Inner Mongolia-a place with plenty of space. That is enough to power 3 million homes. Installation is due to begin next year and finish in 2019. That and other projects should consume all its output for several years to come. First Solars rivals are much smaller. But technological advances may yet catapult one to the fore, says Steve Milunovich, an analyst at Bank of America Merrill Lynch. First Solar makes its cells from a chemical called cadmium telluride. But firms such as Nanosolar, which is building factories in California and Germany, believe that a combination of copper, indium, gallium and selenium known as CIGS will prove cheaper to produce on a mass scale. Researchers at the University of California, meanwhile, hold out great hopes for cells made of organic chemicals. For the moment, however, the cheapest form of solar power is none of these, but the less glamorous solar-thermal power, which involves heating water with sunlight to make steam. Utilities are also keen to use lenses to increase the amount of sunlight hitting solar panels-a technique known as concentrating solar power. They still need subsidies or a high price on carbon emissions to make investments in any sort of solar power profitable. But the gap between solar and conventional power sources is becoming, well, thinner.", "hypothesis": "The price reduction of crystalline films has prevented thin films from gaining market share.", "gold_label": "contradiction"}
{"uid": "id_770", "premise": "Thin-film solar power The modernist box that won this years Solar Decathlon, a contest for solar-powered houses sponsored by Americas Department of Energy, had solar panels of the conventional, crystalline sort on its roof. But the walls were covered in solar cells made with thin coatings of silicon and other materials in the place of expensive slices of crystal. Thin film, as this technology is known, is still less popular than crystalline cells and its move to the mainstream has been a year or two away for a decade. But its time may have come at last. There are many exotic ideas involving thin film, from the solar shingles recently unveiled by Dow, a big chemical company, a roofs worth costs $27,000, to experimental prototypes of power-generating clothes, roads and cars. However, most thin film comes in the form of panels that resemble crystalline ones. They are roughly half as efficient, meaning that a panel must be twice as big to generate the same amount of power, but a third cheaper, watt for watt. So in places where there is no shortage of space, they are the natural option. Thin-film cells are also more versatile, since they can be mounted on a variety of materials including flexible plastics and fabrics. Like all solar cells, they are becoming more efficient: the decathletes of Team Germany, who designed the winning house, bragged that its north facade was covered in panels that could convert even indirect sunlight into electricity. Over the past year or so, thanks to a crash in demand tied to the recession and falling subsidies in big markets, the price of crystalline panels has fallen by 30-40%, undermining thin films relative advantage. Nonetheless, thin films share of the market has continued to rise: it is now almost half, compared with just 10% in 2004. The biggest force in the industry is a firm called First Solar, based in Arizona, a sunny American state. Like that of virtually all alternative-energy firms, its share price has suffered in the recession. But it has First Solar looks likely to continue to grow. Last month it signed a memorandum of understanding with China to install two gigawatts worth of panels in Inner Mongolia-a place with plenty of space. That is enough to power 3 million homes. Installation is due to begin next year and finish in 2019. That and other projects should consume all its output for several years to come. First Solars rivals are much smaller. But technological advances may yet catapult one to the fore, says Steve Milunovich, an analyst at Bank of America Merrill Lynch. First Solar makes its cells from a chemical called cadmium telluride. But firms such as Nanosolar, which is building factories in California and Germany, believe that a combination of copper, indium, gallium and selenium known as CIGS will prove cheaper to produce on a mass scale. Researchers at the University of California, meanwhile, hold out great hopes for cells made of organic chemicals. For the moment, however, the cheapest form of solar power is none of these, but the less glamorous solar-thermal power, which involves heating water with sunlight to make steam. Utilities are also keen to use lenses to increase the amount of sunlight hitting solar panels-a technique known as concentrating solar power. They still need subsidies or a high price on carbon emissions to make investments in any sort of solar power profitable. But the gap between solar and conventional power sources is becoming, well, thinner.", "hypothesis": "At this years Solar Decathlon, thin film covered the roof of the modernist box.", "gold_label": "contradiction"}
{"uid": "id_771", "premise": "Thin-film solar power The modernist box that won this years Solar Decathlon, a contest for solar-powered houses sponsored by Americas Department of Energy, had solar panels of the conventional, crystalline sort on its roof. But the walls were covered in solar cells made with thin coatings of silicon and other materials in the place of expensive slices of crystal. Thin film, as this technology is known, is still less popular than crystalline cells and its move to the mainstream has been a year or two away for a decade. But its time may have come at last. There are many exotic ideas involving thin film, from the solar shingles recently unveiled by Dow, a big chemical company, a roofs worth costs $27,000, to experimental prototypes of power-generating clothes, roads and cars. However, most thin film comes in the form of panels that resemble crystalline ones. They are roughly half as efficient, meaning that a panel must be twice as big to generate the same amount of power, but a third cheaper, watt for watt. So in places where there is no shortage of space, they are the natural option. Thin-film cells are also more versatile, since they can be mounted on a variety of materials including flexible plastics and fabrics. Like all solar cells, they are becoming more efficient: the decathletes of Team Germany, who designed the winning house, bragged that its north facade was covered in panels that could convert even indirect sunlight into electricity. Over the past year or so, thanks to a crash in demand tied to the recession and falling subsidies in big markets, the price of crystalline panels has fallen by 30-40%, undermining thin films relative advantage. Nonetheless, thin films share of the market has continued to rise: it is now almost half, compared with just 10% in 2004. The biggest force in the industry is a firm called First Solar, based in Arizona, a sunny American state. Like that of virtually all alternative-energy firms, its share price has suffered in the recession. But it has First Solar looks likely to continue to grow. Last month it signed a memorandum of understanding with China to install two gigawatts worth of panels in Inner Mongolia-a place with plenty of space. That is enough to power 3 million homes. Installation is due to begin next year and finish in 2019. That and other projects should consume all its output for several years to come. First Solars rivals are much smaller. But technological advances may yet catapult one to the fore, says Steve Milunovich, an analyst at Bank of America Merrill Lynch. First Solar makes its cells from a chemical called cadmium telluride. But firms such as Nanosolar, which is building factories in California and Germany, believe that a combination of copper, indium, gallium and selenium known as CIGS will prove cheaper to produce on a mass scale. Researchers at the University of California, meanwhile, hold out great hopes for cells made of organic chemicals. For the moment, however, the cheapest form of solar power is none of these, but the less glamorous solar-thermal power, which involves heating water with sunlight to make steam. Utilities are also keen to use lenses to increase the amount of sunlight hitting solar panels-a technique known as concentrating solar power. They still need subsidies or a high price on carbon emissions to make investments in any sort of solar power profitable. But the gap between solar and conventional power sources is becoming, well, thinner.", "hypothesis": "In the last three years, First Solars share price has increased more than Standard & Poors clean-energy index.", "gold_label": "entailment"}
{"uid": "id_772", "premise": "This Marvellous Invention. Of all mankinds manifold creations, language must take pride of place. Other inventions the wheel, agriculture, sliced bread may have transformed our material existence, but the advent of language is what made us human. Compared to language, all other inventions pale in significance, since everything we have ever achieved depends on language and originates from it. Without language, we could never have embarked on our ascent to unparalleled power over all other animals, and even over nature itself. But language is foremost not just because it came first. In its own right it is a tool of extraordinary sophistication, yet based on an idea of ingenious simplicity: this marvellous invention of composing out of twenty-five or thirty sounds that infinite variety of expressions which, whilst having in themselves no likeness to what is in our mind, allow us to disclose to others its whole secret, and to make known to those who cannot penetrate it all that we imagine, and all the various stirrings of our soul. This was how, in 1660, the renowned French grammarians of the Port-Royal abbey near Versailles distilled the essence of language, and no one since has celebrated more eloquently the magnitude of its achievement. Even so, there is just one flaw in all these hymns of praise, for the homage to languages unique accomplishment conceals a simple yet critical incongruity. Language is mankinds greatest invention except, of course, that it was never invented. This apparent paradox is at the core of our fascination with language, and it holds many of its secrets. Language often seems so skillfully drafted that one can hardly imagine it as anything other than the perfected handiwork of a master craftsman. How else could this instrument make so much out of barely three dozen measly morsels of sound? In themselves, these configurations of mouth p, f, b, v, t, d, k, g, sh, a, e and so on amount to nothing more than a few haphazard spits and splutters, random noises with no meaning, no ability to express, no power to explain. But run them through the cogs and wheels of the language machine, let it arrange them in some very special orders, and there is nothing that these meaningless streams of air cannot do: from sighing the interminable boredom of existence to unravelling the fundamental order of the universe. The most extraordinary thing about language, however, is that one doesnt have to be a genius to set its wheels in motion. The language machine allows just about everybody from pre-modern foragers in the subtropical savannah, to post-modern philosophers in the suburban sprawl to tie these meaningless sounds together into an infinite variety of subtle senses, and all apparently without the slightest exertion. Yet it is precisely this deceptive ease which makes language a victim of its own success, since in everyday life its triumphs are usually taken for granted. The wheels of language run so smoothly that one rarely bothers to stop and think about all the resourcefulness and expertise that must have gone into making it tick. Language conceals art. Often, it is only the estrangement of foreign tongues, with their many exotic and outlandish features, that brings home the wonder of languages design. One of the showiest stunts that some languages can pull off is an ability to build up words of breath-breaking length, and thus express in one word what English takes a whole sentence to say. The Turkish word ? to take one example, means nothing less than you are one of those whom we cant turn into a town-dweller. (In case you were wondering, this monstrosity really is one word, not merely many different words squashed together most of its components cannot even stand up on their own. ) And if that sounds like some one-off freak, then consider Sumerian, the language spoken on the banks of the Euphrates some 5,000 years ago by the people who invented writing and thus enabled the documentation of history. A Sumerian word like munintumaa (when he had made it suitable for her) might seem rather trim compared to the Turkish colossus above. What is so impressive about it, however, is not its lengthiness but rather the reverse the thrifty compactness of its construction. The word is made up of different slots, each corresponding to a particular portion of meaning. This sleek design allows single sounds to convey useful information, and in fact even the absence of a sound has been enlisted to express something specific. If you were to ask which bit in the Sumerian word corresponds to the pronoun it in the English translation when he had made it suitable for her, then the answer would have to be nothing. Mind you, a very particular kind of nothing: the nothing that stands in the empty slot in the middle. The technology is so fine-tuned then that even a non-sound, when carefully placed in a particular position, has been invested with a specific function. Who could possibly have come up with such a nifty contraption?", "hypothesis": "A complex idea can be explained more clearly in a sentence than in a single word.", "gold_label": "neutral"}
{"uid": "id_773", "premise": "This Marvellous Invention. Of all mankinds manifold creations, language must take pride of place. Other inventions the wheel, agriculture, sliced bread may have transformed our material existence, but the advent of language is what made us human. Compared to language, all other inventions pale in significance, since everything we have ever achieved depends on language and originates from it. Without language, we could never have embarked on our ascent to unparalleled power over all other animals, and even over nature itself. But language is foremost not just because it came first. In its own right it is a tool of extraordinary sophistication, yet based on an idea of ingenious simplicity: this marvellous invention of composing out of twenty-five or thirty sounds that infinite variety of expressions which, whilst having in themselves no likeness to what is in our mind, allow us to disclose to others its whole secret, and to make known to those who cannot penetrate it all that we imagine, and all the various stirrings of our soul. This was how, in 1660, the renowned French grammarians of the Port-Royal abbey near Versailles distilled the essence of language, and no one since has celebrated more eloquently the magnitude of its achievement. Even so, there is just one flaw in all these hymns of praise, for the homage to languages unique accomplishment conceals a simple yet critical incongruity. Language is mankinds greatest invention except, of course, that it was never invented. This apparent paradox is at the core of our fascination with language, and it holds many of its secrets. Language often seems so skillfully drafted that one can hardly imagine it as anything other than the perfected handiwork of a master craftsman. How else could this instrument make so much out of barely three dozen measly morsels of sound? In themselves, these configurations of mouth p, f, b, v, t, d, k, g, sh, a, e and so on amount to nothing more than a few haphazard spits and splutters, random noises with no meaning, no ability to express, no power to explain. But run them through the cogs and wheels of the language machine, let it arrange them in some very special orders, and there is nothing that these meaningless streams of air cannot do: from sighing the interminable boredom of existence to unravelling the fundamental order of the universe. The most extraordinary thing about language, however, is that one doesnt have to be a genius to set its wheels in motion. The language machine allows just about everybody from pre-modern foragers in the subtropical savannah, to post-modern philosophers in the suburban sprawl to tie these meaningless sounds together into an infinite variety of subtle senses, and all apparently without the slightest exertion. Yet it is precisely this deceptive ease which makes language a victim of its own success, since in everyday life its triumphs are usually taken for granted. The wheels of language run so smoothly that one rarely bothers to stop and think about all the resourcefulness and expertise that must have gone into making it tick. Language conceals art. Often, it is only the estrangement of foreign tongues, with their many exotic and outlandish features, that brings home the wonder of languages design. One of the showiest stunts that some languages can pull off is an ability to build up words of breath-breaking length, and thus express in one word what English takes a whole sentence to say. The Turkish word ? to take one example, means nothing less than you are one of those whom we cant turn into a town-dweller. (In case you were wondering, this monstrosity really is one word, not merely many different words squashed together most of its components cannot even stand up on their own. ) And if that sounds like some one-off freak, then consider Sumerian, the language spoken on the banks of the Euphrates some 5,000 years ago by the people who invented writing and thus enabled the documentation of history. A Sumerian word like munintumaa (when he had made it suitable for her) might seem rather trim compared to the Turkish colossus above. What is so impressive about it, however, is not its lengthiness but rather the reverse the thrifty compactness of its construction. The word is made up of different slots, each corresponding to a particular portion of meaning. This sleek design allows single sounds to convey useful information, and in fact even the absence of a sound has been enlisted to express something specific. If you were to ask which bit in the Sumerian word corresponds to the pronoun it in the English translation when he had made it suitable for her, then the answer would have to be nothing. Mind you, a very particular kind of nothing: the nothing that stands in the empty slot in the middle. The technology is so fine-tuned then that even a non-sound, when carefully placed in a particular position, has been invested with a specific function. Who could possibly have come up with such a nifty contraption?", "hypothesis": "Human beings might have achieved their present position without language.", "gold_label": "contradiction"}
{"uid": "id_774", "premise": "This Marvellous Invention. Of all mankinds manifold creations, language must take pride of place. Other inventions the wheel, agriculture, sliced bread may have transformed our material existence, but the advent of language is what made us human. Compared to language, all other inventions pale in significance, since everything we have ever achieved depends on language and originates from it. Without language, we could never have embarked on our ascent to unparalleled power over all other animals, and even over nature itself. But language is foremost not just because it came first. In its own right it is a tool of extraordinary sophistication, yet based on an idea of ingenious simplicity: this marvellous invention of composing out of twenty-five or thirty sounds that infinite variety of expressions which, whilst having in themselves no likeness to what is in our mind, allow us to disclose to others its whole secret, and to make known to those who cannot penetrate it all that we imagine, and all the various stirrings of our soul. This was how, in 1660, the renowned French grammarians of the Port-Royal abbey near Versailles distilled the essence of language, and no one since has celebrated more eloquently the magnitude of its achievement. Even so, there is just one flaw in all these hymns of praise, for the homage to languages unique accomplishment conceals a simple yet critical incongruity. Language is mankinds greatest invention except, of course, that it was never invented. This apparent paradox is at the core of our fascination with language, and it holds many of its secrets. Language often seems so skillfully drafted that one can hardly imagine it as anything other than the perfected handiwork of a master craftsman. How else could this instrument make so much out of barely three dozen measly morsels of sound? In themselves, these configurations of mouth p, f, b, v, t, d, k, g, sh, a, e and so on amount to nothing more than a few haphazard spits and splutters, random noises with no meaning, no ability to express, no power to explain. But run them through the cogs and wheels of the language machine, let it arrange them in some very special orders, and there is nothing that these meaningless streams of air cannot do: from sighing the interminable boredom of existence to unravelling the fundamental order of the universe. The most extraordinary thing about language, however, is that one doesnt have to be a genius to set its wheels in motion. The language machine allows just about everybody from pre-modern foragers in the subtropical savannah, to post-modern philosophers in the suburban sprawl to tie these meaningless sounds together into an infinite variety of subtle senses, and all apparently without the slightest exertion. Yet it is precisely this deceptive ease which makes language a victim of its own success, since in everyday life its triumphs are usually taken for granted. The wheels of language run so smoothly that one rarely bothers to stop and think about all the resourcefulness and expertise that must have gone into making it tick. Language conceals art. Often, it is only the estrangement of foreign tongues, with their many exotic and outlandish features, that brings home the wonder of languages design. One of the showiest stunts that some languages can pull off is an ability to build up words of breath-breaking length, and thus express in one word what English takes a whole sentence to say. The Turkish word ? to take one example, means nothing less than you are one of those whom we cant turn into a town-dweller. (In case you were wondering, this monstrosity really is one word, not merely many different words squashed together most of its components cannot even stand up on their own. ) And if that sounds like some one-off freak, then consider Sumerian, the language spoken on the banks of the Euphrates some 5,000 years ago by the people who invented writing and thus enabled the documentation of history. A Sumerian word like munintumaa (when he had made it suitable for her) might seem rather trim compared to the Turkish colossus above. What is so impressive about it, however, is not its lengthiness but rather the reverse the thrifty compactness of its construction. The word is made up of different slots, each corresponding to a particular portion of meaning. This sleek design allows single sounds to convey useful information, and in fact even the absence of a sound has been enlisted to express something specific. If you were to ask which bit in the Sumerian word corresponds to the pronoun it in the English translation when he had made it suitable for her, then the answer would have to be nothing. Mind you, a very particular kind of nothing: the nothing that stands in the empty slot in the middle. The technology is so fine-tuned then that even a non-sound, when carefully placed in a particular position, has been invested with a specific function. Who could possibly have come up with such a nifty contraption?", "hypothesis": "The Sumerians were responsible for starting the recording of events.", "gold_label": "entailment"}
{"uid": "id_775", "premise": "This Marvellous Invention. Of all mankinds manifold creations, language must take pride of place. Other inventions the wheel, agriculture, sliced bread may have transformed our material existence, but the advent of language is what made us human. Compared to language, all other inventions pale in significance, since everything we have ever achieved depends on language and originates from it. Without language, we could never have embarked on our ascent to unparalleled power over all other animals, and even over nature itself. But language is foremost not just because it came first. In its own right it is a tool of extraordinary sophistication, yet based on an idea of ingenious simplicity: this marvellous invention of composing out of twenty-five or thirty sounds that infinite variety of expressions which, whilst having in themselves no likeness to what is in our mind, allow us to disclose to others its whole secret, and to make known to those who cannot penetrate it all that we imagine, and all the various stirrings of our soul. This was how, in 1660, the renowned French grammarians of the Port-Royal abbey near Versailles distilled the essence of language, and no one since has celebrated more eloquently the magnitude of its achievement. Even so, there is just one flaw in all these hymns of praise, for the homage to languages unique accomplishment conceals a simple yet critical incongruity. Language is mankinds greatest invention except, of course, that it was never invented. This apparent paradox is at the core of our fascination with language, and it holds many of its secrets. Language often seems so skillfully drafted that one can hardly imagine it as anything other than the perfected handiwork of a master craftsman. How else could this instrument make so much out of barely three dozen measly morsels of sound? In themselves, these configurations of mouth p, f, b, v, t, d, k, g, sh, a, e and so on amount to nothing more than a few haphazard spits and splutters, random noises with no meaning, no ability to express, no power to explain. But run them through the cogs and wheels of the language machine, let it arrange them in some very special orders, and there is nothing that these meaningless streams of air cannot do: from sighing the interminable boredom of existence to unravelling the fundamental order of the universe. The most extraordinary thing about language, however, is that one doesnt have to be a genius to set its wheels in motion. The language machine allows just about everybody from pre-modern foragers in the subtropical savannah, to post-modern philosophers in the suburban sprawl to tie these meaningless sounds together into an infinite variety of subtle senses, and all apparently without the slightest exertion. Yet it is precisely this deceptive ease which makes language a victim of its own success, since in everyday life its triumphs are usually taken for granted. The wheels of language run so smoothly that one rarely bothers to stop and think about all the resourcefulness and expertise that must have gone into making it tick. Language conceals art. Often, it is only the estrangement of foreign tongues, with their many exotic and outlandish features, that brings home the wonder of languages design. One of the showiest stunts that some languages can pull off is an ability to build up words of breath-breaking length, and thus express in one word what English takes a whole sentence to say. The Turkish word ? to take one example, means nothing less than you are one of those whom we cant turn into a town-dweller. (In case you were wondering, this monstrosity really is one word, not merely many different words squashed together most of its components cannot even stand up on their own. ) And if that sounds like some one-off freak, then consider Sumerian, the language spoken on the banks of the Euphrates some 5,000 years ago by the people who invented writing and thus enabled the documentation of history. A Sumerian word like munintumaa (when he had made it suitable for her) might seem rather trim compared to the Turkish colossus above. What is so impressive about it, however, is not its lengthiness but rather the reverse the thrifty compactness of its construction. The word is made up of different slots, each corresponding to a particular portion of meaning. This sleek design allows single sounds to convey useful information, and in fact even the absence of a sound has been enlisted to express something specific. If you were to ask which bit in the Sumerian word corresponds to the pronoun it in the English translation when he had made it suitable for her, then the answer would have to be nothing. Mind you, a very particular kind of nothing: the nothing that stands in the empty slot in the middle. The technology is so fine-tuned then that even a non-sound, when carefully placed in a particular position, has been invested with a specific function. Who could possibly have come up with such a nifty contraption?", "hypothesis": "The Port-Royal grammarians did justice to the nature of language.", "gold_label": "entailment"}
{"uid": "id_776", "premise": "This Marvelous Invention Of all mankinds manifold creations, language must take pride of place. Other inventions the wheel, agriculture, sliced bread may have transformed our material existence, but the advent of language is what made us human. Compared to language, all other inventions pale in significance, since everything we have ever achieved depends on language and originates from it. Without language, we could never have embarked on our ascent to unparalleled power over all other animals, and even over nature itself. But language is foremost not just because it came first. In its own right it is a tool of extraordinary sophistication, yet based on an idea of ingenious simplicity: this marvellous invention of composing out of twenty-five or thirty sounds that infinite variety of expressions which, whilst having in themselves no likeness to what is in our mind, allow us to disclose to others its whole secret, and to make known to those who cannot penetrate it all that we imagine, and all the various stirrings of our soul. This was how, in 1660, the renowned French grammarians of the Port-Royal abbey near Versailles distilled the essence of language, and no one since has celebrated more eloquently the magnitude of its achievement. Even so, there is just one flaw in all these hymns of praise, for the homage to languages unique accomplishment conceals a simple yet critical incongruity. Language is mankinds greatest invention except, of course, that it was never invented. This apparent paradox is at the core of our fascination with language, and it holds many of its secrets. Language often seems so skillfully drafted that one can hardly imagine it as anything other than the perfected handiwork of a master craftsman. How else could this instrument make so much out of barely three dozen measly morsels of sound? In themselves, these configurations of mouth p, f, b, v, t, d, k, g, s, h, a, e and so on amount to nothing more than a few haphazard spits and splutters, random noises with no meaning, no ability to express, no power to explain. But run them through the cogs and wheels of the language machine, let it arrange them in some very special orders, and there is nothing that these meaningless streams of air cannot do: from sighing the interminable boredom of existence to unravelling the fundamental order of the universe. The most extraordinary thing about language, however, is that one doesnt have to be a genius to set its wheels in motion. The language machine allows just about everybody from pre-modern foragers in the subtropical savannah, to post-modern philosophers in the suburban sprawl to tie these meaningless sounds together into an infinite variety of subtle senses, and all apparently without the slightest exertion. Yet it is precisely this deceptive ease which makes language a victim of its own success, since in everyday life its triumphs are usually taken for granted. The wheels of language run so smoothly that one rarely bothers to stop and think about all the resourcefulness and expertise that must have gone into making it tick. Language conceals art. Often, it is only the estrangement of foreign tongues, with their many exotic and outlandish features, that brings home the wonder of languages design. One of the showiest stunts that some languages can pull off is an ability to build up words of breath-breaking length, and thus express in one word what English takes a whole sentence to say. The Turkish word fehirliliftiremediklerimizdensiniz, to take one example, means nothing less than you are one of those whom we cant turn into a town-dweller. (In case you were wondering, this monstrosity really is one word, not merely many different words squashed together most of its components cannot even stand up on their own. ) And if that sounds like some one-off freak, then consider Sumerian, the language spoken on the banks of the Euphrates some 5,000 years ago by the people who invented writing and thus enabled the documentation of history. A Sumerian word like munintumaa (when he had made it suitable for her) might seem rather trim compared to the Turkish colossus above. What is so impressive about it, however, is not its lengthiness but rather the reverse the thrifty compactness of its construction. The word is made up of different slots, each corresponding to a particular portion of meaning. This sleek design allows single sounds to convey useful information, and in fact even the absence of a sound has been enlisted to express something specific. If you were to ask which bit in the Sumerian word corresponds to the pronoun it in the English translation when he had made it suitable for her, then the answer would have to be nothing. Mind you, a very particular kind of nothing: the nothing that stands in the empty slot in the middle. The technology is so fine-tuned then that even a non-sound, when carefully placed in a particular position, has been invested with a specific function. Who could possibly have come up with such a nifty contraption?", "hypothesis": "A complex idea can be explained more clearly in a sentence than in a single word.", "gold_label": "neutral"}
{"uid": "id_777", "premise": "This Marvelous Invention Of all mankinds manifold creations, language must take pride of place. Other inventions the wheel, agriculture, sliced bread may have transformed our material existence, but the advent of language is what made us human. Compared to language, all other inventions pale in significance, since everything we have ever achieved depends on language and originates from it. Without language, we could never have embarked on our ascent to unparalleled power over all other animals, and even over nature itself. But language is foremost not just because it came first. In its own right it is a tool of extraordinary sophistication, yet based on an idea of ingenious simplicity: this marvellous invention of composing out of twenty-five or thirty sounds that infinite variety of expressions which, whilst having in themselves no likeness to what is in our mind, allow us to disclose to others its whole secret, and to make known to those who cannot penetrate it all that we imagine, and all the various stirrings of our soul. This was how, in 1660, the renowned French grammarians of the Port-Royal abbey near Versailles distilled the essence of language, and no one since has celebrated more eloquently the magnitude of its achievement. Even so, there is just one flaw in all these hymns of praise, for the homage to languages unique accomplishment conceals a simple yet critical incongruity. Language is mankinds greatest invention except, of course, that it was never invented. This apparent paradox is at the core of our fascination with language, and it holds many of its secrets. Language often seems so skillfully drafted that one can hardly imagine it as anything other than the perfected handiwork of a master craftsman. How else could this instrument make so much out of barely three dozen measly morsels of sound? In themselves, these configurations of mouth p, f, b, v, t, d, k, g, s, h, a, e and so on amount to nothing more than a few haphazard spits and splutters, random noises with no meaning, no ability to express, no power to explain. But run them through the cogs and wheels of the language machine, let it arrange them in some very special orders, and there is nothing that these meaningless streams of air cannot do: from sighing the interminable boredom of existence to unravelling the fundamental order of the universe. The most extraordinary thing about language, however, is that one doesnt have to be a genius to set its wheels in motion. The language machine allows just about everybody from pre-modern foragers in the subtropical savannah, to post-modern philosophers in the suburban sprawl to tie these meaningless sounds together into an infinite variety of subtle senses, and all apparently without the slightest exertion. Yet it is precisely this deceptive ease which makes language a victim of its own success, since in everyday life its triumphs are usually taken for granted. The wheels of language run so smoothly that one rarely bothers to stop and think about all the resourcefulness and expertise that must have gone into making it tick. Language conceals art. Often, it is only the estrangement of foreign tongues, with their many exotic and outlandish features, that brings home the wonder of languages design. One of the showiest stunts that some languages can pull off is an ability to build up words of breath-breaking length, and thus express in one word what English takes a whole sentence to say. The Turkish word fehirliliftiremediklerimizdensiniz, to take one example, means nothing less than you are one of those whom we cant turn into a town-dweller. (In case you were wondering, this monstrosity really is one word, not merely many different words squashed together most of its components cannot even stand up on their own. ) And if that sounds like some one-off freak, then consider Sumerian, the language spoken on the banks of the Euphrates some 5,000 years ago by the people who invented writing and thus enabled the documentation of history. A Sumerian word like munintumaa (when he had made it suitable for her) might seem rather trim compared to the Turkish colossus above. What is so impressive about it, however, is not its lengthiness but rather the reverse the thrifty compactness of its construction. The word is made up of different slots, each corresponding to a particular portion of meaning. This sleek design allows single sounds to convey useful information, and in fact even the absence of a sound has been enlisted to express something specific. If you were to ask which bit in the Sumerian word corresponds to the pronoun it in the English translation when he had made it suitable for her, then the answer would have to be nothing. Mind you, a very particular kind of nothing: the nothing that stands in the empty slot in the middle. The technology is so fine-tuned then that even a non-sound, when carefully placed in a particular position, has been invested with a specific function. Who could possibly have come up with such a nifty contraption?", "hypothesis": "Human beings might have achieved their present position without language.", "gold_label": "contradiction"}
{"uid": "id_778", "premise": "This Marvelous Invention Of all mankinds manifold creations, language must take pride of place. Other inventions the wheel, agriculture, sliced bread may have transformed our material existence, but the advent of language is what made us human. Compared to language, all other inventions pale in significance, since everything we have ever achieved depends on language and originates from it. Without language, we could never have embarked on our ascent to unparalleled power over all other animals, and even over nature itself. But language is foremost not just because it came first. In its own right it is a tool of extraordinary sophistication, yet based on an idea of ingenious simplicity: this marvellous invention of composing out of twenty-five or thirty sounds that infinite variety of expressions which, whilst having in themselves no likeness to what is in our mind, allow us to disclose to others its whole secret, and to make known to those who cannot penetrate it all that we imagine, and all the various stirrings of our soul. This was how, in 1660, the renowned French grammarians of the Port-Royal abbey near Versailles distilled the essence of language, and no one since has celebrated more eloquently the magnitude of its achievement. Even so, there is just one flaw in all these hymns of praise, for the homage to languages unique accomplishment conceals a simple yet critical incongruity. Language is mankinds greatest invention except, of course, that it was never invented. This apparent paradox is at the core of our fascination with language, and it holds many of its secrets. Language often seems so skillfully drafted that one can hardly imagine it as anything other than the perfected handiwork of a master craftsman. How else could this instrument make so much out of barely three dozen measly morsels of sound? In themselves, these configurations of mouth p, f, b, v, t, d, k, g, s, h, a, e and so on amount to nothing more than a few haphazard spits and splutters, random noises with no meaning, no ability to express, no power to explain. But run them through the cogs and wheels of the language machine, let it arrange them in some very special orders, and there is nothing that these meaningless streams of air cannot do: from sighing the interminable boredom of existence to unravelling the fundamental order of the universe. The most extraordinary thing about language, however, is that one doesnt have to be a genius to set its wheels in motion. The language machine allows just about everybody from pre-modern foragers in the subtropical savannah, to post-modern philosophers in the suburban sprawl to tie these meaningless sounds together into an infinite variety of subtle senses, and all apparently without the slightest exertion. Yet it is precisely this deceptive ease which makes language a victim of its own success, since in everyday life its triumphs are usually taken for granted. The wheels of language run so smoothly that one rarely bothers to stop and think about all the resourcefulness and expertise that must have gone into making it tick. Language conceals art. Often, it is only the estrangement of foreign tongues, with their many exotic and outlandish features, that brings home the wonder of languages design. One of the showiest stunts that some languages can pull off is an ability to build up words of breath-breaking length, and thus express in one word what English takes a whole sentence to say. The Turkish word fehirliliftiremediklerimizdensiniz, to take one example, means nothing less than you are one of those whom we cant turn into a town-dweller. (In case you were wondering, this monstrosity really is one word, not merely many different words squashed together most of its components cannot even stand up on their own. ) And if that sounds like some one-off freak, then consider Sumerian, the language spoken on the banks of the Euphrates some 5,000 years ago by the people who invented writing and thus enabled the documentation of history. A Sumerian word like munintumaa (when he had made it suitable for her) might seem rather trim compared to the Turkish colossus above. What is so impressive about it, however, is not its lengthiness but rather the reverse the thrifty compactness of its construction. The word is made up of different slots, each corresponding to a particular portion of meaning. This sleek design allows single sounds to convey useful information, and in fact even the absence of a sound has been enlisted to express something specific. If you were to ask which bit in the Sumerian word corresponds to the pronoun it in the English translation when he had made it suitable for her, then the answer would have to be nothing. Mind you, a very particular kind of nothing: the nothing that stands in the empty slot in the middle. The technology is so fine-tuned then that even a non-sound, when carefully placed in a particular position, has been invested with a specific function. Who could possibly have come up with such a nifty contraption?", "hypothesis": "The Sumerians were responsible for starting the recording of events.", "gold_label": "entailment"}
{"uid": "id_779", "premise": "This Marvelous Invention Of all mankinds manifold creations, language must take pride of place. Other inventions the wheel, agriculture, sliced bread may have transformed our material existence, but the advent of language is what made us human. Compared to language, all other inventions pale in significance, since everything we have ever achieved depends on language and originates from it. Without language, we could never have embarked on our ascent to unparalleled power over all other animals, and even over nature itself. But language is foremost not just because it came first. In its own right it is a tool of extraordinary sophistication, yet based on an idea of ingenious simplicity: this marvellous invention of composing out of twenty-five or thirty sounds that infinite variety of expressions which, whilst having in themselves no likeness to what is in our mind, allow us to disclose to others its whole secret, and to make known to those who cannot penetrate it all that we imagine, and all the various stirrings of our soul. This was how, in 1660, the renowned French grammarians of the Port-Royal abbey near Versailles distilled the essence of language, and no one since has celebrated more eloquently the magnitude of its achievement. Even so, there is just one flaw in all these hymns of praise, for the homage to languages unique accomplishment conceals a simple yet critical incongruity. Language is mankinds greatest invention except, of course, that it was never invented. This apparent paradox is at the core of our fascination with language, and it holds many of its secrets. Language often seems so skillfully drafted that one can hardly imagine it as anything other than the perfected handiwork of a master craftsman. How else could this instrument make so much out of barely three dozen measly morsels of sound? In themselves, these configurations of mouth p, f, b, v, t, d, k, g, s, h, a, e and so on amount to nothing more than a few haphazard spits and splutters, random noises with no meaning, no ability to express, no power to explain. But run them through the cogs and wheels of the language machine, let it arrange them in some very special orders, and there is nothing that these meaningless streams of air cannot do: from sighing the interminable boredom of existence to unravelling the fundamental order of the universe. The most extraordinary thing about language, however, is that one doesnt have to be a genius to set its wheels in motion. The language machine allows just about everybody from pre-modern foragers in the subtropical savannah, to post-modern philosophers in the suburban sprawl to tie these meaningless sounds together into an infinite variety of subtle senses, and all apparently without the slightest exertion. Yet it is precisely this deceptive ease which makes language a victim of its own success, since in everyday life its triumphs are usually taken for granted. The wheels of language run so smoothly that one rarely bothers to stop and think about all the resourcefulness and expertise that must have gone into making it tick. Language conceals art. Often, it is only the estrangement of foreign tongues, with their many exotic and outlandish features, that brings home the wonder of languages design. One of the showiest stunts that some languages can pull off is an ability to build up words of breath-breaking length, and thus express in one word what English takes a whole sentence to say. The Turkish word fehirliliftiremediklerimizdensiniz, to take one example, means nothing less than you are one of those whom we cant turn into a town-dweller. (In case you were wondering, this monstrosity really is one word, not merely many different words squashed together most of its components cannot even stand up on their own. ) And if that sounds like some one-off freak, then consider Sumerian, the language spoken on the banks of the Euphrates some 5,000 years ago by the people who invented writing and thus enabled the documentation of history. A Sumerian word like munintumaa (when he had made it suitable for her) might seem rather trim compared to the Turkish colossus above. What is so impressive about it, however, is not its lengthiness but rather the reverse the thrifty compactness of its construction. The word is made up of different slots, each corresponding to a particular portion of meaning. This sleek design allows single sounds to convey useful information, and in fact even the absence of a sound has been enlisted to express something specific. If you were to ask which bit in the Sumerian word corresponds to the pronoun it in the English translation when he had made it suitable for her, then the answer would have to be nothing. Mind you, a very particular kind of nothing: the nothing that stands in the empty slot in the middle. The technology is so fine-tuned then that even a non-sound, when carefully placed in a particular position, has been invested with a specific function. Who could possibly have come up with such a nifty contraption?", "hypothesis": "The Port-Royal grammarians did justice to the nature of language.", "gold_label": "entailment"}
{"uid": "id_780", "premise": "This passage aims to outline the debate regarding the benefit of protecting wilderness land, where mankind is unrepresented, versus using such lands for the good of mankind. Commentators suggest that mans use of such land, whether to build houses or reap the resources that can be extracted, diminishes the value of such spaces. Opposing this line of thought is the view that to corner off such spaces prevents human progress and limits the possibilities of expansion. In accordance with this line of thought, to limit the use of such resources increases their monetary value, placing those with limited resources at a disadvantage.", "hypothesis": "Preservation of wilderness land prevents human progress.", "gold_label": "entailment"}
{"uid": "id_781", "premise": "This passage aims to outline the debate regarding the benefit of protecting wilderness land, where mankind is unrepresented, versus using such lands for the good of mankind. Commentators suggest that mans use of such land, whether to build houses or reap the resources that can be extracted, diminishes the value of such spaces. Opposing this line of thought is the view that to corner off such spaces prevents human progress and limits the possibilities of expansion. In accordance with this line of thought, to limit the use of such resources increases their monetary value, placing those with limited resources at a disadvantage.", "hypothesis": "Expansion may be limited by the preservation of wilderness land.", "gold_label": "entailment"}
{"uid": "id_782", "premise": "This passage aims to outline the debate regarding the benefit of protecting wilderness land, where mankind is unrepresented, versus using such lands for the good of mankind. Commentators suggest that mans use of such land, whether to build houses or reap the resources that can be extracted, diminishes the value of such spaces. Opposing this line of thought is the view that to corner off such spaces prevents human progress and limits the possibilities of expansion. In accordance with this line of thought, to limit the use of such resources increases their monetary value, placing those with limited resources at a disadvantage.", "hypothesis": "Wilderness land provides future generations with natural substances", "gold_label": "contradiction"}
{"uid": "id_783", "premise": "This passage aims to outline the debate regarding the benefit of protecting wilderness land, where mankind is unrepresented, versus using such lands for the good of mankind. Commentators suggest that mans use of such land, whether to build houses or reap the resources that can be extracted, diminishes the value of such spaces. Opposing this line of thought is the view that to corner off such spaces prevents human progress and limits the possibilities of expansion. In accordance with this line of thought, to limit the use of such resources increases their monetary value, placing those with limited resources at a disadvantage.", "hypothesis": "By preventing the use of limited resources, their value increases.", "gold_label": "entailment"}
{"uid": "id_784", "premise": "This passage examines the view that the punishment of criminals is the underlying aim of the criminal justice system, rather than rehabilitation. When looking at the criminal justice system in the United Kingdom, statistics suggest that those convicted of crimes are more likely to re-offend if given a prison sentence than any other sentence, such as community orders or mandatory alcohol or drug dependency support. In addition, those with dependency problems are more likely to further develop their dependency in prison. However, many sectors of society continue to see non-custodial sentences as the easy way out for offender. In this way, the underlying aim of the criminal justice system continues to be attempting to punish rather than rehabilitate.", "hypothesis": "Community orders continue to be an easy way out for offenders.", "gold_label": "contradiction"}
{"uid": "id_785", "premise": "This passage examines the view that the punishment of criminals is the underlying aim of the criminal justice system, rather than rehabilitation. When looking at the criminal justice system in the United Kingdom, statistics suggest that those convicted of crimes are more likely to re-offend if given a prison sentence than any other sentence, such as community orders or mandatory alcohol or drug dependency support. In addition, those with dependency problems are more likely to further develop their dependency in prison. However, many sectors of society continue to see non-custodial sentences as the easy way out for offender. In this way, the underlying aim of the criminal justice system continues to be attempting to punish rather than rehabilitate.", "hypothesis": "Prisoners are 3x more likely to offend than those serving community orders.", "gold_label": "neutral"}
{"uid": "id_786", "premise": "This passage examines the view that the punishment of criminals is the underlying aim of the criminal justice system, rather than rehabilitation. When looking at the criminal justice system in the United Kingdom, statistics suggest that those convicted of crimes are more likely to re-offend if given a prison sentence than any other sentence, such as community orders or mandatory alcohol or drug dependency support. In addition, those with dependency problems are more likely to further develop their dependency in prison. However, many sectors of society continue to see non-custodial sentences as the easy way out for offender. In this way, the underlying aim of the criminal justice system continues to be attempting to punish rather than rehabilitate.", "hypothesis": "Illegal substances are easier to acquire in prison.", "gold_label": "neutral"}
{"uid": "id_787", "premise": "This passage examines the view that the punishment of criminals is the underlying aim of the criminal justice system, rather than rehabilitation. When looking at the criminal justice system in the United Kingdom, statistics suggest that those convicted of crimes are more likely to re-offend if given a prison sentence than any other sentence, such as community orders or mandatory alcohol or drug dependency support. In addition, those with dependency problems are more likely to further develop their dependency in prison. However, many sectors of society continue to see non-custodial sentences as the easy way out for offender. In this way, the underlying aim of the criminal justice system continues to be attempting to punish rather than rehabilitate.", "hypothesis": "Prisoners are more likely to offend than those serving community orders.", "gold_label": "entailment"}
{"uid": "id_788", "premise": "This passage is based on the popularity of websites. It compares figures published by Rankings Today, a publishing group which collects and analysis information on the popularity of products. Rankings Today note that such figures are based on the annual income generated by such websites and the number of visitors to websites, also known as website traffic. As a result of these figures, we can see that the two most popular types of website are price comparison sites and social networking sites. It is estimated that over three billion pounds in advertising is generated by such websites every year. As a result of this information, companies are better informed as to where they should advertise to reach the largest possible audience.", "hypothesis": "Rankings Today is a company which collects and provides information on social networking websites only.", "gold_label": "neutral"}
{"uid": "id_789", "premise": "This passage is based on the popularity of websites. It compares figures published by Rankings Today, a publishing group which collects and analysis information on the popularity of products. Rankings Today note that such figures are based on the annual income generated by such websites and the number of visitors to websites, also known as website traffic. As a result of these figures, we can see that the two most popular types of website are price comparison sites and social networking sites. It is estimated that over three billion pounds in advertising is generated by such websites every year. As a result of this information, companies are better informed as to where they should advertise to reach the largest possible audience.", "hypothesis": "Rankings Today is a company which provides information on how to achieve the greatest profit.", "gold_label": "neutral"}
{"uid": "id_790", "premise": "This passage is based on the popularity of websites. It compares figures published by Rankings Today, a publishing group which collects and analysis information on the popularity of products. Rankings Today note that such figures are based on the annual income generated by such websites and the number of visitors to websites, also known as website traffic. As a result of these figures, we can see that the two most popular types of website are price comparison sites and social networking sites. It is estimated that over three billion pounds in advertising is generated by such websites every year. As a result of this information, companies are better informed as to where they should advertise to reach the largest possible audience.", "hypothesis": "Rankings Today is a company which collects and provides information on products", "gold_label": "entailment"}
{"uid": "id_791", "premise": "This passage outlines common ways in which companies aim to resolve disputes between their workers. There are two main approaches to dispute resolution within a company. The first of these is the evaluation approach. This method encourages a meeting between the disputing parties to identify the issues between them. A neutral third party, often a team leader, listens to their issues and aims to find a reasonable compromise to impose upon the parties. There are often sanctions outlined for any breach of this compromise. The second way in which companies often resolve disputes between workers is through the facilitative approach. This method encourages open communication, identifying common ground and encourages the parties to the dispute themselves to find a solution, rather than a third party. A benefit of this approach is that the parties get to discuss their issues openly and provides an opportunity for each party to apologise and move forward.", "hypothesis": "The evaluation approach to problem solving is a method that companies use to assess an employees contribution.", "gold_label": "neutral"}
{"uid": "id_792", "premise": "This passage outlines common ways in which companies aim to resolve disputes between their workers. There are two main approaches to dispute resolution within a company. The first of these is the evaluation approach. This method encourages a meeting between the disputing parties to identify the issues between them. A neutral third party, often a team leader, listens to their issues and aims to find a reasonable compromise to impose upon the parties. There are often sanctions outlined for any breach of this compromise. The second way in which companies often resolve disputes between workers is through the facilitative approach. This method encourages open communication, identifying common ground and encourages the parties to the dispute themselves to find a solution, rather than a third party. A benefit of this approach is that the parties get to discuss their issues openly and provides an opportunity for each party to apologise and move forward.", "hypothesis": "The evaluation approach to problem solving is a method by which companies analyse potential new business partners.", "gold_label": "neutral"}
{"uid": "id_793", "premise": "This passage outlines common ways in which companies aim to resolve disputes between their workers. There are two main approaches to dispute resolution within a company. The first of these is the evaluation approach. This method encourages a meeting between the disputing parties to identify the issues between them. A neutral third party, often a team leader, listens to their issues and aims to find a reasonable compromise to impose upon the parties. There are often sanctions outlined for any breach of this compromise. The second way in which companies often resolve disputes between workers is through the facilitative approach. This method encourages open communication, identifying common ground and encourages the parties to the dispute themselves to find a solution, rather than a third party. A benefit of this approach is that the parties get to discuss their issues openly and provides an opportunity for each party to apologise and move forward.", "hypothesis": "The evaluation approach to problem solving requires a neutral third party to find a reasonable compromise.", "gold_label": "entailment"}
{"uid": "id_794", "premise": "This passage outlines common ways in which companies aim to resolve disputes between their workers. There are two main approaches to dispute resolution within a company. The first of these is the evaluation approach. This method encourages a meeting between the disputing parties to identify the issues between them. A neutral third party, often a team leader, listens to their issues and aims to find a reasonable compromise to impose upon the parties. There are often sanctions outlined for any breach of this compromise. The second way in which companies often resolve disputes between workers is through the facilitative approach. This method encourages open communication, identifying common ground and encourages the parties to the dispute themselves to find a solution, rather than a third party. A benefit of this approach is that the parties get to discuss their issues openly and provides an opportunity for each party to apologise and move forward.", "hypothesis": "The evaluation approach to problem solving allows the disputing parties to find a solution themselves,", "gold_label": "contradiction"}
{"uid": "id_795", "premise": "This passage outlines the debate regarding the usefulness of social networking websites as a marketing tool. One side of this debate suggests that such websites allow companies to reach the widest target audience possible, and as such, are a powerful advertising tool. In addition to this social networking sites, such as facebook, provide information such as age, occupation, relationship status, location and often personal likes. In this way, such websites provide companies with a large amount of information, allowing companies to target their product at their ideal with greater ease and efficiency. On the other side of the debate, critics suggest that such websites encourage the publication of personal information on a never before seen level. In this way, companies are in a position to take advantage of previously private information.", "hypothesis": "Social networking sites provide a powerful advertising tool", "gold_label": "entailment"}
{"uid": "id_796", "premise": "This passage outlines the debate regarding the usefulness of social networking websites as a marketing tool. One side of this debate suggests that such websites allow companies to reach the widest target audience possible, and as such, are a powerful advertising tool. In addition to this social networking sites, such as facebook, provide information such as age, occupation, relationship status, location and often personal likes. In this way, such websites provide companies with a large amount of information, allowing companies to target their product at their ideal with greater ease and efficiency. On the other side of the debate, critics suggest that such websites encourage the publication of personal information on a never before seen level. In this way, companies are in a position to take advantage of previously private information.", "hypothesis": "Social networking sites encourage the publication of private information.", "gold_label": "entailment"}
{"uid": "id_797", "premise": "This passage outlines the debate regarding the usefulness of social networking websites as a marketing tool. One side of this debate suggests that such websites allow companies to reach the widest target audience possible, and as such, are a powerful advertising tool. In addition to this social networking sites, such as facebook, provide information such as age, occupation, relationship status, location and often personal likes. In this way, such websites provide companies with a large amount of information, allowing companies to target their product at their ideal with greater ease and efficiency. On the other side of the debate, critics suggest that such websites encourage the publication of personal information on a never before seen level. In this way, companies are in a position to take advantage of previously private information.", "hypothesis": "Social networking is used as marketing tool.", "gold_label": "entailment"}
{"uid": "id_798", "premise": "This passage outlines the debate regarding the usefulness of social networking websites as a marketing tool. One side of this debate suggests that such websites allow companies to reach the widest target audience possible, and as such, are a powerful advertising tool. In addition to this social networking sites, such as facebook, provide information such as age, occupation, relationship status, location and often personal likes. In this way, such websites provide companies with a large amount of information, allowing companies to target their product at their ideal with greater ease and efficiency. On the other side of the debate, critics suggest that such websites encourage the publication of personal information on a never before seen level. In this way, companies are in a position to take advantage of previously private information.", "hypothesis": "Social networking sites place users in a vulnerable position.", "gold_label": "contradiction"}